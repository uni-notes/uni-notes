{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83d\udc4b Welcome!","text":"<p>Hi, I'm Thahir - I work with Data &amp; Machine Learning. Currently working as an Associate Analyst at Delivery Hero talabat.</p> <p>Over the last ~1.5 years, I've had the chance to contribute across airlines, FMCG, and e-commerce, building projects that help companies spot patterns, deal with uncertainty, make better decisions, and launch consumer-facing products. I love finding the balance between hitting algorithmic metrics and bigger business goals, and I've been lucky enough to do that at both global and regional levels.</p> <p>Along the way, I've built and deployed data products that draw from a mix of skills: data analytics, machine learning, stakeholder management, and financial modeling &amp; analysis. The tools I'm most comfortable with are Python and SQL for core work, with Scikit-learn and PyTorch on the ML side, plus Power BI and Sisense for dashboards and insights. For collaboration and quick delivery, I make heavy use of Excel/PowerPoint/Word and the Google Suite.</p>"},{"location":"#about-this-repo","title":"About this repo","text":"<p>This is a PWA using Mkdocs material theme. It serves as my knowledge base - a collection of notes on Math, Computer, Economics, Finance and so much more. Feel free to share with everyone you know!</p> <ul> <li>Check out the \ud83d\udcf1 Installation Guide to install now</li> <li>Use the navbar \u2b05\ufe0f to go through the website</li> <li>For changes/corrections, click the edit button \ud83d\udcdd at the top of any page</li> </ul>"},{"location":"#contributions","title":"\u2728 Contributions","text":"<p>A big thank you to all contributors, as this initiative would not be possible without their support! You can check out the progress of the project here.</p> <p>Want to join the initiative? Check out the guidelines and start contributing now! Collaborators will be mentioned for their contributions. </p>"},{"location":"#installation-guide","title":"Installation Guide","text":"Platform Installation Step Android Chrome - Click the three dots at the top right- Click <code>Install App</code> iOS Safari - Click share button in the bottom- Click <code>Add to Home Screen</code> iOS Chrome \u274c\ud83d\ude15 I hate this; open the link on Safari Windows Click the <code>+</code> icon in the address bar MacOS Chrome Click the <code>+</code> icon in the address bar MacOS Safari \u274c\ud83d\ude15 I hate this; open the link on Chrome"},{"location":"#performance-optimizations","title":"\u26a1\ufe0f Performance Optimizations","text":"<ul> <li>Network-first PWA (offline-use possible)</li> <li>Minifying &amp; combining CSS/JS</li> <li>Lazy loading images</li> <li>Prefetching links</li> <li>Using katex instead of mathjax</li> <li><code>content-visibility: auto</code></li> </ul>"},{"location":"#why-pwa","title":"Why PWA?","text":"<p>PWA are applications that have been designed to be capable, reliable, and installable with a single codebase.</p> <p>Using a PWA in this case allows the contributors of the website and I to ensure legible and understandable content, without worrying about the app development.</p> <p>For more details, check out Google's blog post</p>"},{"location":"#disclaimers","title":"\u26a0\ufe0f Disclaimers","text":"<ul> <li>Make sure to give due credit when sharing these notes, to help support this project :) Publishing this as your own without crediting and using the exact Open Software License 3.0 would be bypassing the license, and demeaning this project.</li> <li>This is meant to be a student-only knowledge sharing initiative - not a classroom portal.</li> <li>These notes are not affiliated to any university, club, association.</li> <li>Kindly note that since this is open source, and hence, correctness cannot be guaranteed.</li> </ul>"},{"location":"#forking","title":"Forking","text":"<p>There is no explicit git command to fork a repo, so you will need to fork using the <code>Fork</code>\u00a0button at the top of this repository page.</p>"},{"location":"#cloning","title":"Cloning","text":"<pre><code>git clone --single-branch --branch main https://github.com/uni-notes/uni-notes\n</code></pre>"},{"location":"#license","title":"License","text":"<p>Open Source Licence</p>"},{"location":"CONTRIBUTING/","title":"\ud83d\udcdd Contributing","text":"<p>Welcome to our open-source project! We love your input! We want to make contributing to this project as easy and transparent as possible, whether it's:</p> <ul> <li>Reporting a Bug</li> <li>Discussing the Current State of the Code</li> <li>Submitting a Fix</li> <li>Proposing New Features</li> <li>Becoming a Moderator</li> </ul> <p>We appreciate your interest in contributing to our repository. Before you get started, please take a moment to review the guidelines below.</p>"},{"location":"CONTRIBUTING/#guidelines","title":"\ud83d\ude80 Guidelines","text":"<ol> <li>Fork the repository and clone it locally.</li> <li>Create a new branch for your changes.</li> <li>Make your changes and test them locally. All notes must be in markdown only. If you're not familiar with markdown, please refer to this.</li> <li>If you're fixing a bug, please include a test case that demonstrates the bug.</li> <li>Submit a pull request (PR) to the <code>main</code> branch of the original repository. All pull requests must address an issue. Write clear and concise commit messages and pull request descriptions.</li> <li>Your PR will be reviewed by a moderator. If there are any requested changes, make them and push them to your branch, and your PR will be updated automatically.</li> <li>Once your changes are approved and merged, you can delete your branch.</li> </ol>"},{"location":"CONTRIBUTING/#issues-and-feature-requests","title":"\ud83e\udd14 Issues and Feature Requests","text":"<p>If you find a bug or have a feature request, please open an issue in the repository. Please provide a clear and concise description of the issue or request, and include any relevant information, such as error messages or steps to reproduce.</p>"},{"location":"CONTRIBUTING/#introducing-new-course-or-new-notes","title":"\ud83e\udd29 Introducing new Course (or) new notes?","text":"<ol> <li>Fork the repo:</li> <li>Go to the repo on GitHub and click on the \"Fork\" button in the top right corner.</li> <li> <p>This will create a copy of the repository under you GitHub account.</p> </li> <li> <p>Clone the forked repo:</p> </li> <li>Using your terminal or Command Prompt, navigate to the directory where you want to clone the repo.  But before, download &amp; install git on you machine.</li> <li> <p>Then use the following command to clone the repository to you local machine: <pre><code>git clone &lt;forked_repository_url&gt;\n</code></pre> Replace <code>&lt;forked_repository_url&gt;</code> with the URL of your forked repository. You can find this URL in the repository page of your forked repository on GitHub.</p> </li> <li> <p>Configure upstream remote:</p> </li> <li>Change to the cloned repository's directory using the <code>cd</code> command. </li> <li> <p>Then, add the original repository as the upstream remote so that you can fetch any changes made to the original repository.  Use the following command: <pre><code>git remote add upstream &lt;original_repository_url&gt;\n</code></pre></p> </li> <li> <p>Create a new branch: </p> </li> <li>Before making any changes, create a new branch to work on. This keeps your changes separate from the main branch. </li> <li> <p>Use the following command to create a new branch: <pre><code>git checkout -b &lt;branch_name&gt;\n</code></pre> Replace <code>&lt;branch_name&gt;</code> with a descriptive name for your branch.</p> </li> <li> <p>Add your new files: </p> </li> <li> <p>Place the new files you want to upload into the cloned repository's directory on your local machine.</p> </li> <li> <p>Stage the changes: </p> </li> <li> <p>Use the following command to stage the changes (including the new files) for commit: <pre><code>git add .\n</code></pre></p> </li> <li> <p>Commit your changes: </p> </li> <li> <p>Commit the changes with a descriptive commit message using the following command: <pre><code>git commit -m \"Your commit message\"\n</code></pre></p> </li> <li> <p>Push your changes: </p> </li> <li> <p>Push the committed changes to your forked repository on GitHub using the following command: <pre><code>git push origin &lt;branch_name&gt;\n</code></pre> Replace <code>branch_name</code> with the name of the branch you created earlier.</p> </li> <li> <p>Create a pull request: </p> </li> <li>Go to the repository page of your forked repository on GitHub. </li> <li>You should see a prompt to create a pull request for the branch you just pushed. </li> <li>Click on it and provide a clear title and description for your pull request. </li> <li>Submit the pull request.</li> </ol> <p>Once your pull request is approved, your changes will be merged into the original repository. \ud83e\udd73</p>"},{"location":"CONTRIBUTING/#additional-tips","title":"\ud83d\udca1 Additional Tips","text":"<ul> <li>Use tables over lists whenever possible. This helps in grouping related concepts.</li> </ul> <ul> <li>Use mermaid flowcharts to simplify processes, flows, trees. </li> </ul> <ul> <li>Use LaTeX for mathematical/scientifical expressions. (Blurry images are not cool \ud83d\ude14\ud83d\udc4e)</li> </ul> \\[ \\int x^2 = \\frac{x^3}{3} \\]"},{"location":"CONTRIBUTING/#license","title":"\u2696\ufe0f License","text":"<p>By contributing, you agree that your contributions will be licensed under Open Software License 3.0.</p> <p>Check the license here</p>"},{"location":"CONTRIBUTING/#conclusion","title":"\ud83d\udc4b Conclusion","text":"<p>We welcome contributions from everyone, and we appreciate your help in making our project better. Thank you for your support!</p>"},{"location":"General_Notes/","title":"General","text":""},{"location":"General_Notes/#general-notes","title":"General Notes","text":"<ul> <li> Work-life balance<ul> <li> Determine what's important: on your deathbed, what do you want to say that you have done</li> <li> Never have regrets: on your deathbed, don't have anything you'd wish that you had done</li> <li> Make key goals: personal &amp; professional</li> <li> Spend time with friends and family</li> <li> Take hare of health</li> <li> Complete work</li> <li> Cut everything else</li> <li> Profile your activities<ul> <li> Self-logging post hoc (end of the day) is notoriously unreliable</li> <li> Is your time spent aligned with your goals</li> <li> Organize and build systems</li> <li> How much is your time worth</li> </ul> </li> </ul> </li> <li> Professional<ul> <li> Interview<ul> <li> Interview<ul> <li> Be confident, not over-confident</li> <li> Make it clear that<ul> <li> you are great what you do</li> <li> you have lots to learn, as one cannot know everything</li> <li> you need hand-holding guidance</li> </ul> </li> </ul> </li> </ul> </li> <li> Understand the problem, don't immediately provide the solution<ul> <li> \"If you understand your solution better than the problem you're doing something wrong\" ~ Vincent Warmerdam</li> <li> Understand the final goal is not the solution itself, but the solving of the problem.</li> <li> Many a times people get caught up with the solution or just do their work as is without truly understanding the goal - mainly seen in the IT and AI industry.</li> <li> I believe the problem is not with the people, but a problem with the objectives set for the people in organizations - to finish as many tasks/tickets/publications as possible</li> </ul> </li> <li> Response if you don't know something,<ul> <li> \u274c \"I don't know\"</li> <li> \u2705 \"I am not aware; I will check and get back to you ASAP\"</li> </ul> </li> <li> Reuse, don't redo</li> <li> Decisions<ul> <li> Plan decisions for potential scenarios in advance as much as possible</li> <li> Spontaneous decisions are prone to biases</li> </ul> </li> <li> Time Management<ul> <li> </li> </ul> </li> <li> Never directly trust anything you read; always do the derivations &amp; test everything for yourself</li> <li> How to read a paper</li> <li> Always be prepared; new opportunities may arise any time</li> <li> Always be eager to continuously learn &amp; explore</li> <li> Be wary about the Hype Cycle</li> </ul> </li> </ul>"},{"location":"General_Notes/#hype-cycle","title":"Hype Cycle","text":"<p>Technology adoption cycle</p> <p></p> <p>Venture Capitalists know that 9/10 investments fail, but expect at least 1/10 makes enough money to compensate for the others</p>"},{"location":"General_Notes/#general-tasks-involved-in-job-roles","title":"General Tasks involved in Job Roles","text":"<p>O*Net</p>"},{"location":"General_Notes/#parts-of-profile","title":"Parts of Profile","text":"<ul> <li>Knowledge - Theory</li> <li>Skill - Practical</li> <li>Craft - Projects</li> <li>Experience - Time?</li> </ul>"},{"location":"1_Core/Bio_Lab/","title":"Lab","text":"<p>Here is the demonstration of every experiment in the biology lab. As of now I have only uploaded till midsem. </p> <p>PS : Please note that the links to videos on GDrive have been removed at the moment as they have been removed by the faculty. Once reuplaoded, will add them. </p> <ol> <li>Microscopy</li> <li>Isolation of Stomata</li> <li>Calculation of Mitotic Index</li> <li>Identification of Blood Group</li> <li>Total WBC Count</li> <li>Total RBC Count</li> <li>Estimation of Chlorophyll</li> <li>Micrometry</li> <li>Paper Chromatography</li> <li>Preparation of Onion Root Tip Sample (Refer Exp 3)</li> </ol>"},{"location":"1_Core/Bio_Lab/Exp_01/","title":"Exp 01","text":""},{"location":"1_Core/Bio_Lab/Exp_01/#microscopy-depends-on-specimen","title":"Microscopy [Depends on Specimen]","text":"<p>Fairly chill experiment, talks about the different parts of a microcope and how to use these parts. Also, involves looking at some basic slides and describing their overall strucutre. </p>"},{"location":"1_Core/Bio_Lab/Exp_02/","title":"Exp 02","text":""},{"location":"1_Core/Bio_Lab/Exp_02/#stomata-400x","title":"Stomata [400x]","text":""},{"location":"1_Core/Bio_Lab/Exp_02/#dicot-plant","title":"Dicot Plant:","text":"<ol> <li>We need lower epidermis, use cutter to isolate the tissue. </li> <li>Put one drop water and place the tissue. </li> <li>Now place cover slip in a tilted way such that there are no air bubbles. </li> <li>Now view it under microscope on 40x (4, 10, 40) magnification. </li> </ol> <p>Similar procedure for monocot except there is no upper and lower epidermis, either side works.  </p> <p>To calculate the stomatal density: </p> <ul> <li>Count the number of stomata in 3 different \"fields\" [x2, one for Monocot and other for Dicot]. </li> <li>Take the average of the 3 fields, and multiply it by 8 that will give you the stomatal density per mm^2. </li> </ul> <p>Q. Why are we multiplying by 8? </p>"},{"location":"1_Core/Bio_Lab/Exp_03/","title":"Exp 03","text":""},{"location":"1_Core/Bio_Lab/Exp_03/#calculation-of-mitotic-index-400x","title":"Calculation of Mitotic Index [400x]","text":"<ol> <li>Examine under 400x magnification. </li> <li>Pick a fieid where there's atleast one prophase, metaphase, anaphase, telophase. Count the total number of each type of cell. </li> <li>Identification : </li> <li>Prophase - Raisin, </li> <li>Metapahse - Concentrated in Center</li> <li>Anaphase - Concentrated in Sides</li> <li>Telophase - Raisins towards the edges. </li> <li>Go the center of the \"field\" count the number of cells in row an column with max count, multiplying those two numbers will give you the total cell count. Sum of the cells in phase can also be obtained. </li> <li>Number of Cells in Interphase = Total - Cells in Phase </li> <li>Find their corresponding percentages. </li> <li>Calculations: </li> <li>Mitotic Index = Number of Cells in Phase / Totoal Number of Cells.</li> <li>Generalized Version : Mitotic Index * 19 Hours</li> <li>Index of Cells = Number of Cells in that Phase / Total number of Cells in Phase</li> <li>Duration of Mitosis = Mitotic Index * Index of Cells</li> </ol>"},{"location":"1_Core/Bio_Lab/Exp_04/","title":"Exp 04","text":""},{"location":"1_Core/Bio_Lab/Exp_04/#micrometry-100x","title":"Micrometry [100x]","text":"<ol> <li>Place the calibration slide on the stage of the microscope. </li> <li>View the slide under 4x and 10x. </li> <li>Remove the light side lens, and place the ocular scale eyepiece on the right side lens. </li> <li>Observe which divisions correspond exactly with the divisions on the stage micrometer. </li> <li>Least Count of Stage of Micrometer is 0.01mm = 0.1 MicroMeter. </li> <li>Calculate the Calibration Constant: </li> <li>CC = (No. of Divisions in Stage Micrometer between two adjacent coincident points * Least Count) / Corr. no. of divisions on Ocular Microscope. </li> </ol>"},{"location":"1_Core/Bio_Lab/Exp_04/#measuring-specimens","title":"Measuring specimens:","text":"<ol> <li>Measure the Length and the Breadth of one cell of the given sample. Multuply the measured paramters by your calibration constant to obtain the final readings that in MicroMeters. </li> </ol>"},{"location":"1_Core/Bio_Lab/Exp_05/","title":"Exp 05","text":""},{"location":"1_Core/Bio_Lab/Exp_05/#total-white-blood-cell-count-100x","title":"Total White Blood Cell Count [100x]","text":"<ol> <li>Draw blood till 0.5 Mark in Thoma Dilution Pippete (with the white bead)</li> <li>Draw the RBC dilution flood up to 11 mark. Homogenize the sample for 2-3 min. </li> <li>Discard the first few drops of sample present at the tip as it only contains the dilution fluid. </li> <li>Charge the haemocytometer with the sample by gently touching the tip of the pippete of the counting platform. In contact with the edge of the cover slip, small amount of fluid will automatically by surface tension and capillary action. </li> <li>Wait for 5mins. </li> <li> <p>The WBCs are counted in 4 corners under 10x low power objective. You will see 16 boxes in each corner, apply the L - Rule. </p> </li> <li> <p>Total number of WBC's per MicroLiter is given by (D*N)/V</p> </li> <li>Dilution Factor is 10, Volume is 0.4 MicroLiter. </li> <li>Total Number of WBCs = N * 50 Cells</li> </ol> <p>Normal range of WBC in a human body is 5000 - 10000 cells/mm^3. </p>"},{"location":"1_Core/Bio_Lab/Exp_05/#common-reasons-for-false-high-results","title":"Common Reasons for False High Results:","text":"<ul> <li>Dilution Fluid taken below mark (Insufficient Dilution)</li> <li>Overloading</li> </ul>"},{"location":"1_Core/Bio_Lab/Exp_05/#common-reasons-for-false-low-results","title":"Common Reasons for False Low Results:","text":"<ul> <li>Excessive Dilution</li> <li>Insufficient Loading</li> </ul>"},{"location":"1_Core/Bio_Lab/Exp_06/","title":"Exp 06","text":""},{"location":"1_Core/Bio_Lab/Exp_06/#counting-of-rbcs-400x","title":"Counting of RBCs [400x]","text":"<ul> <li> <p>We use Hayem's Solution which is an isotonic fluid that that maintains tonicity, acts as a preservative and discourages clumping of blood. </p> </li> <li> <p>Draw blood gently up to 0.5 mark on the pipette. </p> </li> <li>Draw and fill in Hayem's fluid up to 101 mark and homogenize the blood with the fluid thoroughly by rotating the pipette in the horizontal position. The red bead aids in mixing. </li> <li>Discard the fiirst few drops of the fluid as it contains only dilution fluid. </li> <li>Charge the chamber with the sample by gently touching the tip of the pipette on the surface of the counting platform in contact with the edge of the cover slip. A small amount of fluid will be drawing in automatically by surface tension and capillary action. There should not be any air bubbles. </li> <li>Once the haemocytometer is charged, view it under 400x magnification. </li> <li> <p>Similar process as WBC Counting, we will only focus on the 4 corner squares. Each corner square has 16 boxes, we count the number of cells within each box using the L - Rule. </p> </li> <li> <p>Total number of WBC's per MicroLiter is given by (D*N)/V</p> </li> <li>Dilution Factor is 200, Volume is 0.02 MicroLiter. </li> <li>Total Number of WBCs = N * 10000 Cells</li> </ul>"},{"location":"1_Core/Bio_Lab/Exp_06/#common-reasons-for-false-high-results","title":"Common Reasons for False High Results:","text":"<ul> <li>Dilution Fluid taken below mark (Insufficient Dilution)</li> <li>Overloading</li> </ul>"},{"location":"1_Core/Bio_Lab/Exp_06/#common-reasons-for-false-low-results","title":"Common Reasons for False Low Results:","text":"<ul> <li>Excessive Dilution</li> <li>Insufficient Loading</li> </ul>"},{"location":"1_Core/Bio_Lab/Exp_07/","title":"Exp 07","text":""},{"location":"1_Core/Bio_Lab/Exp_07/#determination-of-blood-group-by-slide-agglutination-test-no-microscope","title":"Determination of Blood Group by Slide Agglutination Test [No Microscope]","text":"<ol> <li>Take a sample of blood and put 3 drops in different places in a slide. </li> <li>To the first drop of blood, add anti-serum A. </li> <li>To the second drop of blood, add anti-serum B. </li> <li> <p>To the third drop of blood, add anti-serum D. </p> </li> <li> <p>If there's agglutination in A, A is present. </p> </li> <li>If there's agglutination in B, B is present. </li> <li>If there's agglutination in D, it is +'ve. </li> <li>If there's no agglutination in D, it is -'ve. </li> <li>If there's agglutination only in D, it is O+'ve. </li> <li>If there's no agglutination in D, it is O-'ve. </li> </ol>"},{"location":"1_Core/Bio_Lab/Exp_08/","title":"Exp 08","text":""},{"location":"1_Core/Bio_Lab/Exp_08/#qualitative-estimation-of-chlorophyll","title":"Qualitative Estimation of Chlorophyll","text":"<ol> <li>Select tender green leaves. </li> <li>Wash them with water and dry them and weigh 100mg of leaf. </li> <li>Chop and Grind it well using a matter and pestle. </li> <li>Add 5ml acetone, since it is volatile in air, mix it fast and pour it back in the measuring thing.</li> <li>Now we centirfuge it, while doing that remember to have another liquid with same measurment of liquid on the exact opposite side such that there's a balance. The density of acetone and water are quite similar so as far as density is concerned, we are good to go. Put the setting on 5000rpm for 5min. (In Lab its 100x rpm, so look for 50 rpm)</li> <li>Fill the cuvette with 80% blank acetone solution. The volume of the cuvette is 4mL and it should be held on the transluscent sides. Conver the cuvette using the white top. Place it on the machine in such a way that the translucent side is facing us. Same process for the green sample. </li> <li>Getting absorbance: </li> <li>Make sure 100% mode (last button) is on and the reading is stable. </li> <li>Click on the first button for getting absorbance, it should say 0. </li> <li>Pull the black button until you here one click. You will get the reading. </li> </ol>"},{"location":"1_Core/Bio_Lab/Exp_08/#formulas","title":"Formulas:","text":"<ul> <li>Chlorophyll A: 12.25(A-663) - 2.55 (A-646)</li> <li>Chlorophyll B: 20.31(A-646) - 4.91 (A-663)</li> <li>Total : 17.76 (A-646)  + 7.34 (A-663)</li> </ul>"},{"location":"1_Core/Bio_Lab/Exp_09/","title":"Exp 09","text":""},{"location":"1_Core/Bio_Lab/Exp_09/#paper-chromatography","title":"Paper Chromatography","text":"<ol> <li>Add 6mL of mobile phase into chromatography chamber. Keep the chamber closed for 10 minutes. </li> <li>Now we prepare our chromatography paper (whatmann paper), make sure the scale doesn't touch the paper. Make a 6 x 4 cutout. Always hold the paper at the top. </li> <li>Now we draw a line 1cm above the bottom of the paper to mark the origin. Let us mark 3 equidistant points on the line. Mark them as A, B and M respectively. </li> <li>Dip the capillary tube on the PhenylAnaline solution, it will automaticlly draw up. Tap the tube on the spot A it will auto drop. </li> <li>Use another capillary tube for the next solution. Do the same for the mixture solution. On the paper mention your ID Number in the top right corner, and place the paper in the chromatograhy chamber till the mobile phase has covered \u00beth of your paper. Remove the chromatography paper and mark the dipped portion using a pencil. Then we have to airdry the paper. </li> <li> <p>Now we have to spray the ninhydrin spray. When you spray it be sure to not inhale the vapours yourself. After that we dry it in the oven. After drying we can notice different spots, we will mark the center of the spots and measure the distance between the origin to the center of the colored spots. </p> </li> <li> <p>Formula for RF Value: Distance travelled by the substance (spot) / Total distance travelled by solvent.</p> </li> </ol>"},{"location":"1_Core/Bio_Lab/Exp_10/","title":"Exp 10","text":""},{"location":"1_Core/Bio_Lab/Exp_10/#preparation-of-onion-root-tip-slide-for-calculation-of-mitotic-index-no-microscope-mandatory","title":"Preparation of Onion Root Tip Slide for Calculation of Mitotic Index [No Microscope] -- [Mandatory!!!]","text":"<ol> <li>Clean slide and cover slip</li> <li>Place onion root tip on the slide</li> <li>2-3 drops of HCl on the onion root tip such that it is fully covered. Let this remain for 15 minutes. Wipe it off gently once done. </li> <li>Wipe it off gently, and use nuclear stain (in our case -- Saffranin Blue), this imparts a pink color on the slide. Let this remain for 15 minutes. Wipe it off gently once done. </li> <li>Put a drop of water on the root tip and cover it uisng a cover slip, make sure to place the cover slip in a such a manner that there are no air bubbles. Remove the excess stain using a tissue. </li> <li>Gently tap the root tip using a pencil to produce a squashed homogenous effect. </li> </ol>"},{"location":"1_Core/Chem_Lab/","title":"Lab","text":"<p>No demonstration videos have been uplaoded for chemistry lab -- will have to rely on notes.  :/ </p>"},{"location":"1_Core/Chem_Lab/Exp_01/","title":"Exp 01","text":""},{"location":"1_Core/Chem_Lab/Exp_01/#preparation-and-charecterization-of-aspirin","title":"Preparation and Charecterization of Aspirin","text":"<ol> <li>Weigh 2g of Salicylic Acid. Transfer it to a dry 100mL beaker. </li> <li>4mL of Acetic Anhydride into 100mL beaker. </li> <li>5 Drops of conc. H2SO4 into 100ml beaker. [If excess H2SO4 is added the reaction gets suphonated and no product is formed.]</li> <li>Water Bath - Reaction mixture below the liquid level in the bath and water in boiling condition, continue for 20 mins. </li> <li>Add 10mL ice cold water, to hyrolyze the unreacted acetic anhydride. </li> <li>Chill in ice bath - occasionally swirling to cause precipitation. </li> <li>Add 25mL ice cold water. </li> <li>Scratch side of beaker with stirring rod to initialize crystallization. </li> <li>Filter, Dry, Weigh, Report. </li> <li>Report melting point. </li> </ol>"},{"location":"1_Core/Chem_Lab/Exp_02/","title":"Exp 02","text":""},{"location":"1_Core/Chem_Lab/Exp_02/#preparation-of-coordination-compound-tetrammine-sulphate-monohydrate","title":"Preparation of Coordination Compound Tetrammine Sulphate Monohydrate","text":"<ol> <li>1.6g CuSO4 salt in 5mL CuSO4 solution on a 250mL beaker. </li> <li>Add 10mL Ammonia Solution</li> <li>Add 15mL Ethanol dropwise till purple precipitate. </li> <li>Filter, Dry, Weigh. </li> </ol>"},{"location":"1_Core/Chem_Lab/Exp_03/","title":"Exp 03","text":""},{"location":"1_Core/Chem_Lab/Exp_03/#estimation-of-ferrous-sulphate-by-permanganometry","title":"Estimation of Ferrous Sulphate by Permanganometry","text":"<ol> <li>Weigh 1.4g of FeSO4.7H2O on watch glass. </li> <li>Transfer this amount into a 100mL volumetric flask. Add 10mL of dil. H2SO4</li> <li>Add enough volume of distilled water to the flask to make it reach the mark. </li> <li> <p>Calculate the Molarity of this solution. </p> </li> <li> <p>Fill the burette with KMnO4 Solution till 0. </p> </li> <li>Pipette 25mL of this standard solution in a conical flask. Add 10mL of silute H2SO4 to this. </li> <li> <p>Titrate till a light pink color is observed. Repeat twice for two concordant readings. </p> </li> <li> <p>Repeat this for the unknown solution. </p> </li> </ol>"},{"location":"1_Core/Computer_Programming/","title":"Computer Programming","text":"<p>This was very similar to the C++ course in CBSE 11<sup>th</sup>/12<sup>th</sup>, so haven't made detailed notes for this course, yet. Some basics have been provided though. </p>"},{"location":"1_Core/Computer_Programming/#explainer-video","title":"Explainer Video","text":"<p>This video covers till midsem</p>"},{"location":"1_Core/Computer_Programming/#labs","title":"Labs","text":"<p>This junior's repository SivaaB/BITSPil-CSF111 contains solutions to all the lab and tutorial sheets given in class. Thank you Sivaa! \u2728</p> <p>I will also be adding my lab codes in this folder. Later, based on user feedback, we can filter to the simplest codes.</p>"},{"location":"1_Core/Computer_Programming/01_Intro/","title":"01 Intro","text":""},{"location":"1_Core/Computer_Programming/01_Intro/#basics","title":"Basics","text":"<p>Digital data is in binary form.</p> <ul> <li>0/1 (bit)</li> <li>8 bits = 1 byte</li> <li>1024 bytes = 1KB</li> </ul> <p>When write a C program to perform a task, it gets converted into binary instructions which a computer can understand</p>"},{"location":"1_Core/Computer_Programming/01_Intro/#variables","title":"Variables","text":"<pre><code>int x; // declaration\nx=5; // initialization\n\nint x = 5; // combined\n</code></pre>"},{"location":"1_Core/Computer_Programming/01_Intro/#tokens","title":"Tokens","text":"<ul> <li> <p>atomic unit of a code</p> </li> <li> <p>Key words</p> <pre><code>return\n  void\n</code></pre> </li> <li> <p>Identifiers</p> <pre><code>int x = 3;\n</code></pre> </li> </ul>"},{"location":"1_Core/Computer_Programming/01_Intro/#code-block","title":"Code Block","text":"<p>group of code within <code>{ ... }</code></p>"},{"location":"1_Core/Computer_Programming/01_Intro/#structure","title":"Structure","text":"<pre><code>print(\"hi\")\nprint(\"hello\")\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n\nvoid print_on_screen()\n{\n  printf(\"hi\"); // ; = terminator\n}\n\nint main() // driver function of your program\n{\n  // code\n  print_on_screen();\n\n  int x = 4; // \n\n  return 0;\n}\n</code></pre>"},{"location":"1_Core/Computer_Programming/01_Intro/#data-types","title":"Data Types","text":""},{"location":"1_Core/Computer_Programming/01_Intro/#primitive","title":"Primitive","text":"<code>void</code> (nothing) 0 <code>boolean</code> True/Falsetrue/false 1 <code>char</code> \u2018H\u2019 1 %c <code>int</code> 34444 2 %d <code>float</code> 334545.345534 4 %f <code>double</code> 334545345534334545345534.334545345534334545345534 8 %"},{"location":"1_Core/Computer_Programming/01_Intro/#user-defined","title":"User-defined","text":"<p>(not in scope of current exam)</p>"},{"location":"1_Core/Computer_Programming/01_Intro/#math-operators","title":"Math Operators","text":"\\[ + - * / \\% \\] <ul> <li> <p><code>int</code>/<code>int</code> = <code>int</code></p> </li> <li> <p>B</p> </li> <li>^</li> <li>Multiplication/Division (whichever comes first)</li> <li>Addition/Subtraction (whichever comes first)</li> </ul>"},{"location":"1_Core/Computer_Programming/01_Intro/#type-casting","title":"Type Casting","text":"<p>change in data type of a variable for a momentary purpose</p> <p>implicit (automatic)</p> <p>int/int \\(\\to\\) int</p> <ul> <li>3/2 = 1.5</li> <li>3/2 = 1</li> </ul> <p>int/float \\(\\to\\) float</p> <ul> <li>larger data type</li> </ul> <pre><code>int x=5;\nfloat z = 5/(double) 5;\n</code></pre> <p>explicit(user-defined) type casting</p> <pre><code>int x = -5;\nint y = 2;\n\n-5/2; // -2.5 -2\n5/-2; // -2.5 -2\n\n5/-2.0f // -2.5\n</code></pre>"},{"location":"1_Core/Computer_Programming/01_Intro/#relational-operators","title":"Relational Operators","text":"\\[ &gt; , \\ge , &lt; , \\le, ==, \\ne, != \\] <ul> <li>\\(=\\) and \\(==\\)<ul> <li>assignment</li> <li>equality operator</li> </ul> </li> </ul> <pre><code>const float pi = 3.14;\n</code></pre>"},{"location":"1_Core/Computer_Programming/01_Intro/#logical-operators","title":"Logical Operators","text":"\\[ ! \\\\ \\&amp;\\&amp; \\\\ || \\] \\[ [!0 \\&amp;\\&amp; 1 || 3\\&amp;\\&amp;!1] \\] <pre><code>int main()\n{\n  int x;\n\n  // take input from user\n  scanf(\"%d\", &amp;x); // storing the value in the address of x\n\n  printf(\"%d\", x);\n\n\n  return 0;\n}\n\n// x = 5\n</code></pre> <pre><code>int main()\n{\n  int x = 5;\n\n  printf(\"%d\", ++x); // 6\n  printf(\"%d\", x); // 6\n\n  return 0;\n}\n</code></pre>"},{"location":"1_Core/Computer_Programming/02_Flow_Control/","title":"02 Flow Control","text":""},{"location":"1_Core/Computer_Programming/02_Flow_Control/#if-else","title":"if \u2026 else","text":"<p>conditional statement</p> <p>branching</p> <pre><code>flowchart TB\ndb{1==0}\n\ndb --- |Yes|nesnt\ndb --- |No|blah</code></pre> <pre><code>int x = 4;\nif (x == 5)\n{\n  printf(\"Yes\");\n  printf(\"hi\");\n}\n\nprint(\"outside everything\");\n</code></pre> <pre><code>outside everything\n</code></pre> <pre><code>if(x&gt;10)\n{\n if(y &lt; 10) \n {\n   printf(\"hi\");\n }\n}\nelse\n{\n  printf(\"hi\");\n}\n</code></pre> <pre><code>if(x&gt;10 &amp;&amp; y&lt;10)\n{\n   printf(\"hi\");\n}\nelse\n{\n  printf(\"hi\");\n}\n</code></pre> <pre><code>elif\n</code></pre> <pre><code>hi\noutside everything\n</code></pre> <p><code>for</code>, <code>if</code> and <code>else</code> go to the immediate next block</p> <pre><code>x = 5\nif x == 5:\n  print(\"yes\")\n  print(\"block 1\")\nelse:\n  print(\"no\")\n  print(\"block 2\")\n</code></pre>"},{"location":"1_Core/Computer_Programming/02_Flow_Control/#ternary-operator","title":"Ternary Operator","text":"<p>cooler way of doing if else</p> <pre><code>(y&lt;10)?(x=10):(x=0)\n</code></pre>"},{"location":"1_Core/Computer_Programming/02_Flow_Control/#switch","title":"Switch","text":"<pre><code>switch(s):\n{\n  case 1: something; break;\n  case 2: something; break;\n  default: something;\n}\n\nswitch(s):\n{\n  case 'a': something; break;\n  case 'b': something; break;\n  default: something;\n}\n</code></pre>"},{"location":"1_Core/Computer_Programming/03_Loops/","title":"03 Loops","text":""},{"location":"1_Core/Computer_Programming/03_Loops/#types","title":"Types","text":"<ul> <li><code>while</code><ul> <li>Entry-controlled loop</li> </ul> </li> <li><code>do...while</code><ul> <li>Exit-controlled loops</li> </ul> </li> <li><code>for</code></li> </ul>"},{"location":"1_Core/Computer_Programming/03_Loops/#components","title":"Components","text":"<ul> <li>Initialization<ul> <li>\\(n\\)</li> <li>\\(i\\)</li> </ul> </li> <li>Loop condition checked</li> <li>Code to execute is run</li> <li>Updation occurs</li> </ul> <pre><code>flowchart LR\n\ni[Initialization] --&gt; c[Condition] --&gt; Code --&gt; Updation --&gt; c</code></pre> <pre><code>/*\nint n = 10;\nint i = 1; // comesntenret\n\nfor (; ; )\n{\n\n  if(i&gt;n)\n    break;\n\n  // code\n\n  i++;\n}\n*/\n\nfor (int i = 1, n=10; i&lt;=n; i++)\n{\n\n}\n\nint i = 1, n=10;\nfor (; i&lt;=n; i++)\n{\n  ;// nothing happens\n}\n\nprintf(\"%d\", i); 11\n</code></pre> <pre><code>for (int i = 1, n=10; i&lt;=n; i++)\n  printf(\"%d\\n\", i);\n</code></pre> <pre><code>1\n2\n...\n9\n10\n</code></pre> <pre><code>for (int i = 1, n=10; i&lt;=n; i++)\n  printf(\"%d\\n\", i);\n  printf(\"%d\\n\", i);\n\nfor (int i = 1, n=10; i&lt;=n; i++)\n{\n  printf(\"%d\\n\", i);\n}\nprintf(\"%d\\n\", i);\n\n// here\n</code></pre> <pre><code>1\n2\n3\n...\n9\n10\n11\n</code></pre> <pre><code>for (int i = 1, n=10; i&lt;=n; i++)\n{\n  printf(\"%d\\n\", i);\n  printf(\"%d\\n\", i);\n}\n\n// here\n</code></pre> <pre><code>1\n1\n2\n2\n...\n9\n9\n10\n10\n</code></pre> <pre><code>int i, n;\nfor (i = 1, n=10; i&lt;=n; i++);\n  printf(\"%d\\n\", i);\n\nint i, n;\nfor (i = 1, n=10; i&lt;=n; i++)\n{\n ; \n}\n\nprintf(\"%d\\n\", i);\n</code></pre> <pre><code>11\n</code></pre> <pre><code>int i = 1, n = 10;\n\n// curly brace\n// run 10 times\nwhile(i&lt;=n)\n{\n print(\"hi\");\n i++;\n}\n</code></pre> <pre><code>int i = 1, n = 10;\n// curly brace\n\ndo\n{\n  // code\n  i++;\n} while (i&lt;n); // has semi-colon\n</code></pre> <pre><code>x=5, y=10\n</code></pre>"},{"location":"1_Core/Computer_Programming/03_Loops/#pyramid-example","title":"Pyramid example","text":"<pre><code>*\n*\n*\n*\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n\nint main()\n{\n  int n = 4; // no of lines\n  for (int i=1; i&lt;=n; i++) // run the loop 4 times\n  {\n    printf(\"*\\n\");\n  }\n\n  return 0;\n}\n</code></pre> <pre><code>*\n**\n***\n****\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n\nint main()\n{\n  printf(\"*\\n\");\n    printf(\"**\\n\");\n    printf(\"***\\n\");\n    printf(\"****\\n\");\n\n  return 0;\n}\n</code></pre> <ol> <li>DUMB</li> <li>Not scalable</li> <li>Not elegant</li> </ol> <p>Hence, we need loops (iterative statements)</p> <pre><code>#include &lt;iostream.h&gt;\n\nint main()\n{\n  for (int i=1; i&lt;=n; i++)\n  {\n    for (int j=1; j&lt;=i; j++)\n    {\n      printf(\"*\");\n    }\n\n    printf(\"\\n\");\n  }\n  return 0;\n}\n</code></pre>"},{"location":"1_Core/Computer_Programming/03_Loops/#jump-statements","title":"jump statements","text":"<ul> <li>break<ul> <li>exits the current loop</li> </ul> </li> <li>continue<ul> <li>skips the below code of the current iteration</li> <li>goes to the update segment of (for)loop</li> <li>in other loops, it goes to condition</li> <li>then continues as usual</li> </ul> </li> </ul> <pre><code>for (int i=1; i&lt;=5; i++)\n{\n  if(i==3)\n  {\n    break;\n    printf(\"%d\\n\", i);\n  }\n\n   printf(\"%d\\n\", i);\n}\n\n// come here\n</code></pre> <pre><code>1\n2\n</code></pre> <pre><code>for (int i=1; i&lt;=5; i++)\n{\n  if(i==3)\n  {\n    continue;\n    printf(\"%d\\n\", i);\n  }\n\n   printf(\"%d\\n\", i);\n}\n</code></pre> <pre><code>1\n2\n4\n5\n</code></pre> <pre><code>int i=1;\nwhile(i&lt;=5)\n{\n  if(i==3)\n  {\n    continue;\n    printf(\"%d\\n\", i);\n  }\n\n   printf(\"%d\\n\", i);\n\n  i++;\n}\n</code></pre> <pre><code>1\n2\n(infinite loop)\n</code></pre> <pre><code>int i=1;\ndo\n{\n  if(i==3)\n  {\n    continue;\n    printf(\"%d\\n\", i);\n  }\n\n   printf(\"%d\\n\", i);\n\n  i++;\n} while(i&lt;=5); // has terminator\n</code></pre> <pre><code>1\n2\n(infinite loop)\n</code></pre>"},{"location":"1_Core/Computer_Programming/03_Loops/#loop-printining-questions","title":"Loop Printining Questions","text":"<pre><code>int n = 4; // no of lines\nint j = 1;\nfor (int i=1; i&lt;=n; i++) // controls no of lines\n{\n  printf(\"%d\", j);\n  j++;\n\n}\n</code></pre> <pre><code>1\n2\n3\n4\n</code></pre> <pre><code>int n = 4; // no of lines\n\nfor (int i=1; i&lt;=n; i++) // controls no of lines\n{\n  int j = 1;\n  printf(\"%d\", j);\n  j++;\n}\n</code></pre> <pre><code>1\n1\n1\n1\n</code></pre>"},{"location":"1_Core/Computer_Programming/04_Arrays/","title":"04 Arrays","text":"<p>linear data structure</p> <p>primitive data structure</p> <p>arrays are 0-indexed</p> <ul> <li>index start from 0</li> </ul> <p>it is non-mutable (non-changeable)</p> <p>statically-allocated</p> <p>size of array is fixed</p> <p>array is similar to tuple in python, but only same data type</p> <p>collection of elements of the same data type</p>"},{"location":"1_Core/Computer_Programming/04_Arrays/#ne-list","title":"\\(\\ne\\) List","text":"<p>In python, list is a collection of elements of the same/different type</p> <pre><code>list = [2, \"hi\", 3, 4, 5]\n</code></pre>"},{"location":"1_Core/Computer_Programming/04_Arrays/#declarationcreation","title":"Declaration/Creation","text":"<pre><code>int array[10];\n\nchar array[10];\nfloat array[10];\ndouble array[10];\nconst int length = 10;\nint array[length];\n</code></pre>"},{"location":"1_Core/Computer_Programming/04_Arrays/#initialization","title":"Initialization","text":"<pre><code>array[0]= 1;\narray[1] = 2;\n\nint num;\nscanf(\"%d\", &amp;num);\narray[2] = num;\nscanf(\"%d\", &amp;num);\narray[3] = num;\n</code></pre> <pre><code>for(int i=0; i&lt;10; i++)\n{\n  int num;\n  scanf(\"%d\", &amp;num);\n  array[i] = num;\n}\n\n// no error\n</code></pre> <pre><code>for(int i=0; i&lt;10; i++)\n{\n  scanf(\"%d\", array[i]); // no &amp;\n}\n\n// no error\n</code></pre> <pre><code>for(int i=1; i&lt;=9; i++)\n{\n  scanf(\"%d\", &amp;num);\n  array[i] = num;\n}\n\n// no error\n</code></pre>"},{"location":"1_Core/Computer_Programming/04_Arrays/#display","title":"Display","text":"<pre><code>for(int i=0; i&lt;10; i++)\n{\n  printf(\"%d\\n\", array[i]);\n}\n</code></pre>"},{"location":"1_Core/Computer_Programming/04_Arrays/#example","title":"example","text":"<pre><code>#include &lt;iostream.h&gt;\n\nint main()\n{\n  int a[100]; // assuming a random number\n\n\n  // input no of elements\n  int n;\n  printf(\"Please enter no of elements that you are goint to input\");\n  scanf(\"%d\", &amp;n);\n\n  // input the elements\n  for(int i=0; i&lt;n; i++)\n  {\n    printf(\"Enter number at index %d: \", i);\n    scanf(\"%d\", a[i]);\n  }\n\n  // display marks &gt; 60\n  for(int i=0; i&lt;n; i++)\n  {\n    if(a[i] &gt; 60)\n      printf(\"%d\", a[i]);\n  }\n  // or\n  for(int i=0; i&lt;n; i++)\n  {\n    int num = a[i];\n    if(num &gt; 60)\n      printf(\"%d\", num);\n  }\n\n  return 0;\n}\n</code></pre>"},{"location":"1_Core/Computer_Programming/05_Pointers/","title":"05 Pointers","text":"<p>a variable that stores address</p> <p>name of an array is a pointer to the first element of that array</p>"},{"location":"1_Core/Electrical_Science/","title":"Electrical Science","text":"<p>I\u2019ve got the notes for these, but need someone to digitize them</p>"},{"location":"1_Core/Electrical_Science/01/","title":"Introduction","text":""},{"location":"1_Core/Electrical_Science/01/#electric-vs-electronic","title":"Electric vs Electronic","text":"Electric Electronic Signal Discrete Continuous Example Bulb Fan"},{"location":"1_Core/Engineering_Graphics/","title":"Engineering Graphics","text":"<p>This course has two parts, Part - 1 (for midsem) includes orthographic projections, isometric projections and straight lines. Part - 2 (for compre) includes projection of lines + solids, sectional view of solids and cutting of solids. </p> <p>A problem set wiith questions from the textbook are given a week before midsems and compre which are really helpful for preparation. The solutions to those problems have been provided by this junior's repository SivaaB/BITSPil-CSF111. Thank you Sivaa! \u2728</p>"},{"location":"1_Core/General_Biology/","title":"General Biology","text":"<p>This course is divided into two parts - one part includes introduction to biology, types of cell, different components of a cell, energy production in plants + animals, heridiitary and evolution ; the other part is post midsem. Part - 1 is all closed book. Part - 2 is all open book. So, preparation must be done accordingly. </p> <p>As of date, notes only upto midsem have been uploaded. Will proceed to put up notes for postmidsem portion as we progress thorugh the semester. </p>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/","title":"01 Getting introduced to biology and its scope","text":""},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#steps-in-biology-to-conclude-a-statement","title":"Steps in biology to conclude a statement:","text":"<p>Observation, Question, Hypothesis, Prediction, Experiment. (convert this into mermaid flowchart) If the experiment does not support hypothesis then make a new one. If it supports hypothesis, make new predictions. </p>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#mnemonic-for-remembering-oqhpe","title":"Mnemonic for remembering: [OQHPE]","text":"<ol> <li>**O**bservation</li> <li>**Q**uestion</li> <li>**H**ypothesis</li> <li>**P**rediction</li> <li>**E**xperiment</li> </ol>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#major-life-charecteristics","title":"Major life charecteristics","text":"<p>Order, Regulation, Growth and Development, Energy Processing, Response to Environment, Reproduction, Evolution. </p>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#mnemonic-for-remembering-orgerre","title":"Mnemonic for remembering: [ORGERRE]","text":"<ol> <li>**O**rder</li> <li>**R**egulation</li> <li>**G**rowth and Development</li> <li>**E**volution</li> <li>**R**esponse to Environment </li> <li>**R**eproduction </li> <li>**E**volution</li> </ol>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#major-themes-in-biology","title":"Major themes in biology","text":"<p>Energy Processsing, Structure and Function, Information Flow, Evolution, Interconnection to other systems. (Pnemonic : ESIEI)</p>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#mnemonic-for-remembering-esiei","title":"Mnemonic for remembering: [ESIEI]","text":"<ol> <li>**E**nergy Processing</li> <li>**S**tructure and Function</li> <li>**I**nformation Flow</li> <li>**E**volution</li> <li>**I**nterconnection to other systems.</li> </ol> <pre><code>graph LR;\n    A[Molecules and Atoms] --&gt; B[Organelles, Cells];\n    B --&gt; C[Tissues, Organs];\n    C --&gt; D[Organ System];\n    D --&gt; E[Organisms];\n    E --&gt; F[Population];\n    F --&gt; G[Communities];\n    G --&gt; H[Ecosystem];\n    H --&gt; I[Biosphere];</code></pre>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#eubacteria","title":"Eubacteria:","text":"<ul> <li>Small, Prokaryotic, Single celled organisms ranging from 1 - 10um. </li> <li>Lack nucleus and cell membrane bound organelles. </li> <li>Cell wall contains a complex organic molecule called peptidoglycan. </li> </ul>"},{"location":"1_Core/General_Biology/01_Getting_introduced_to_biology_and_its_scope/#archea","title":"Archea:","text":"<ul> <li>Prokaryotic</li> <li>Cell membrane has Isoprenes. </li> <li>Extremophiles </li> <li>Has large proportions of genes that are diff from eubacteria.</li> </ul> <p>Protists : Microscopic Organisims like Amoeba and Seaweed.</p> <p>Kingdoms are distinguished as:  - Plantae : Produce their own food.  - Animalia : Obtain food by ingesting and digesting.  - Fungi : Decomposers, obtain food by decomposing dead and decaying organic matter. </p> <p>Prokaryotes have:  - Pilli : Short projections for attachment to surfaces.  - Flagella : Long projections to propel them through their liquid environment.  - Capsules : Makes the bacteria's surface more slippery, helping it to escape engulfment by phagocytic cells.</p> <p>Only Animal cells have Lysomes and Plant Cells have Chloroplasts.</p>"},{"location":"1_Core/General_Biology/02_Components_of_the_Cell_and_its_Internal_Working/","title":"02 Components of the Cell and its Internal Working","text":""},{"location":"1_Core/General_Biology/02_Components_of_the_Cell_and_its_Internal_Working/#molecules-of-life-tb-order","title":"Molecules of Life [TB Order]","text":"<p>Animals store excess glucose in the form of Glycogen. </p> <p>Cellulose can't be digested by humans, and only ruminating animals like cows can do so through the help of the microorganisims in their intestines which help them break them down. Although we can't digest it, it is good for us as the lining of our intestines secrete mucus which allows food to pass freely.</p> <p>A pound of fat contains more than the twice the amount of energy as compared to a pound of carb. The downside is it's very hard to get rid of them as they are stored deep in our adipose tissues which swell or shrink as we deposit or withdraw fat from them.</p> <p>Unsaturated fatty acids are those which have fewer than the max number of hydrogen atoms. They appear bent. For a fat to be saturated all 3 components need to be straight.</p> <p>Sometimes a food manufacturer wants to use vegetable oil but wants the end product to be solid, in that case adds hydrogen, this process is called hydrogenation. Unfortunately, hydrogenation also leads to trans fat which are very detrimental to our health. Some fats like omega 3 are very healthy for us, these are found in foods like nuts and salmons.</p> <p>Cholesterol is a base steroid on top of which other hormones like testosterone is made. Anabolic steroids mimic testosterone, these are given to treat diseases like cancer and AIDS, but athletes abuse this and the use of this has dangerous side effects such as depression, liver damage, violent behavior.</p> <p>Changing one element's sequence in proteins can be very detrimental as it affects the proteins ability to function. Eg. Substitution of one amino acid in hemoglobin incorrectly results in sickle cell disease, an inherited blood disorder.</p> <p>High Fever are dangerous for this very reason as with the inc in temp, the proteins tend to lose their shape.</p>"},{"location":"1_Core/General_Biology/02_Components_of_the_Cell_and_its_Internal_Working/#linking-of-ribonucleic-acid-can-be-represented-as","title":"Linking of Ribonucleic Acid can be represented as:","text":"Base-1 Base-2 Adenosine Guanine Cytosine Thymine      / Uracil"},{"location":"1_Core/General_Biology/02_Components_of_the_Cell_and_its_Internal_Working/#difference-between-rna-and-dna","title":"Difference between RNA and DNA:","text":"Category DNA RNA Full name Deoxyribonucleic acid Ribonucleic acid Sugar Deoxyribose Ribose Bases Adenine (A), Guanine (G), Cytosine (G), Thymine (T) Adenine (A), Guanine (G), Cytosine (C), Uracil (U) Structure Double-stranded helix Single-stranded helix Function Stores genetic information Transfers genetic information and assists in protein synthesis"},{"location":"1_Core/General_Biology/02_Components_of_the_Cell_and_its_Internal_Working/#termninology-in-this-module","title":"Termninology in this module:","text":"Term Equivalent Starch Amylose Indigestible fibres Cellulose Animal starch Glycogen"},{"location":"1_Core/General_Biology/02_Components_of_the_Cell_and_its_Internal_Working/#a-tour-of-the-cell-tb-order","title":"A Tour of the Cell [TB Order]","text":"<p>Plasma Membrane:  - Made of Phospholipids which comprise of phospholipid bilayer, one for hydrophilic head and other for hydrophobic tail. - Inside the bilayer, it mostly comprises of proteins which regulates what goes in and out. It can freely move and is called Fluid Mossaic.</p> <p>Superbug : Ruptures the plasma membrane, causing a staph infection. Mostly occurs in schools, hospitals and gyms.</p> <p>Animal cells lack cell wall, but compensate w the help of an extracellular matrix (protein collagen).</p> <p>Nucleus :  - It is separated from the cytoplasm by a double membrane called the nuclear envelope. It has holes. - Long DNA molecules and associated proteins from fibres called chromatin are present, each chromatin fibre has one chromosome.</p> <p>Ribosomes : - Some case the proteins made by ribosomes are made in nucleus and are transported to the cytoplasm through the pores of the nuclear envelope, in other cases they are in the cytoplasm itself, making proteins that remain fluid within the cell, sometimes even connected to the ER.  - Cells that make a lot of proteins have a lot of ribosomes.</p> <p>Endoplasmic Reticulum:  - Rough ER : To make more plasma membrane, it can budd off. Cells that secrete a lot of protein such as your salivary glands, which secrete enzymes in your mouth are rich in rough ER.  - Smooth ER: Repro hormones are rich in smooth ER. They help in detoxification, example liver cells as well. This eventually strengthen's the body's tolerance to that drug, therefore requiring more dosage to have the same effect.</p> <p>Golgi Apparatus : Is the ship port of the cell. </p> <p>Lysomes: Safe area for animale cells to digest large proteins, nucleic acids .etc. without decomposing itself. It can also engulf  organelles within the cell, essentially recycling it. Heriditary disorders occur as a result of lysome storage disease.</p> <p>Vacuoles : Can pump out or accept water based on need. Central Vacuole comprises of more than half the volume of a mature plant cell. Some cells of flowering plants, in their vacuoles may have pigments present in them to attract pollinating insects. Other plants store toxic elements in their vacuoles to protect themselves against plant eating animals.</p> <p>Plants have both chloroplasts and mitochondria but animals only have mitochondria. </p> <p>Cytoskeleton shape is maintained using microtubules.</p> <p>Movement in Cells: - Cilia : Short hair liked strucutres that are many in number and move back and forth in a coordinated fashion. Eg - Cilia in windpipe that are responsible to sweep mucus in the respiratory system get damages due to smoking leading to respiratory complications in smokers. - Flagella : They are singular, whip - like structures that help in movement os sperms during fertilization. The problems with flagella often times lead to infertility problems. - Pilli : Helps in attachment to surfaces. </p>"},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/","title":"03 Genetic Regulation and the Process of Cloning","text":""},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/#genetic-regulation-and-the-process-of-cloning","title":"Genetic Regulation and the Process of Cloning","text":""},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/#introduction","title":"Introduction:","text":"<p>Gene Regulation : A mechanism that turns on certain genes while other genes remain turned off. </p> <p>Cells with same genetic information can develop into different types of cells through gene regulation. Regulating gene activity within cells allows for specialization. </p> <p>Genes determine the nucleotide sequence of specific mRNA molecules, and the mRNA in turn determines the specific sequence of amino acid in proteins. A gene that is being turned on is being transcribed into mRNA and that message is being translated into specific proteins. The overall process by which genetic information flows from genes to proteins is called Gene Expression. </p> <pre><code>graph TD;\nA(Genes)--&gt;B(Nucleotide Sequence of mRNA);\nB--&gt;C(Sequence of Amino Acid Proteins);</code></pre> <p>Notice that genes for \"housekeeping\" enzymes such as those that provide energy via glycolysis are always \"on\". Whereas, more specific genes for some proteins like insulin and haemoglobin are expressed only by a particular kind of cell. </p>"},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/#gene-regulation-in-bacteria","title":"Gene Regulation in Bacteria:","text":"<p>Bacteria regulate their genes in response to environmental changes. </p> <p>Natural Selection has favored bacterial that express only genes whose products are needed by the cell. For example, imagine  eschericihia coli living in your intestine. </p> <ul> <li>If you drink a milk shake, there will be a sudden rush of lactose. </li> <li>In response, E.Coli will express only three genes for enzymes that will enable the bacterium to digest this sugar. </li> <li>After the sugar has been digested, these genes are turned \"off\". </li> </ul> <p>An operon is a sequence of DNA containing a cluster of genes under the control of a single promoter. An operon consists of a POS - promoter, operator and structural genes that function in a highly coordinated manner. </p> <p>A lac-operon as discussed in the example given above is a segment of DNA containing adjacent genes including a SOR - structural gene, an operator gene and a regulatory gene. </p>"},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/#gene-regulation-in-eukaryotes","title":"Gene Regulation in Eukaryotes:","text":"<p>Eukaryotic chromosomes are highly condensed. This prevents gene expression as RNA polymerase and other transcription proteins cannot bind to DNA. </p> <p>Introns : Sequence of a eukaryotes genes that are not transcribed into a protein. </p> <p>Exons : Sequence of a gene's DNA that transcribes into protein's structures. </p>"},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/#genetic-regulation-occurs-at-several-levels-uirstp","title":"Genetic Regulation occurs at several levels: [UIRSTP]","text":"<ul> <li>Unpacking of DNA </li> <li>Initiation of Transcription </li> <li>RNA Processing </li> <li>Stability of RNA </li> <li>Translation </li> <li> <p>Protein Activation an Breakdown</p> </li> <li> <p>Unpacking of DNA : </p> </li> <li>When lactose is absent the repressor remains bound to the operator and RNA Polymerase is therefore prevented from moving down the lac operon transcribing its genes. </li> <li> <p>When lactose is present the repressor is converted to its inactive form, which does not bind to the operator. RNA Polymerase can therefore move past the operator and transcribe the necessary genes into a single mRNA. </p> </li> <li> <p>Initiation of Transcription : </p> </li> <li>Enhancers and Silencers : These are sequences on the DNA that are binding sites for proteins. Enhancers increase, Silencers decrease protein synthesis. </li> <li> <p>Transcription Factors (TFs) : Are proteins that control the available promoter sequence for transcription. TFs bind to DNA around the gene's promoter region and influence RNA polymerase's ability to start transcription. A particular gene will not be expressed if its TFs are not available.  </p> </li> <li> <p>Eukaryotic Transcription is so strictly regulated that TFs always guide RNA polymerase to the promoter sequence. </p> </li> <li> <p>Prokaryotic cells also use proteins to block or encourage transcription but not to the extent that this stratergy is used in eukaryotic cells. </p> </li> <li> <p>RNA Processing: </p> </li> <li>One gene can code for multiple RNAs, and thus multiple proteins. </li> <li> <p>Alternative splicing increases phenotype variation within species and among different species. </p> </li> <li> <p>RNA Stability: </p> </li> <li>The lifespan of a mRNA molecule determines how much of a protein is made of microRNAs (miRNAs). These are small ss RNA molecules that bind to the complementary sequences on mRNA molecule in the cytoplasm. After binding, some miRNA trigger breakdown of their target mRNA, whereas others block translation. </li> </ul> <p>Cells signal each other by direct contact or by the release of a substance from one cell that is taken up by another cell. The three stages are: [R.ST.R]</p> <ul> <li>Reception, whereby the signal molecule binds to the receptor. </li> <li>Signal Transduction, where the chemical signal results in a series of enzyme activations. </li> <li>Response, which is cellular responses. </li> </ul>"},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/#cloning-in-plants","title":"Cloning in Plants:","text":"<p>Tissues removed from the stem of Orchid Plant and placed in a growth medium may begin dividing and eventually grow into an adult plant. The new plant is a genetic duplicate of the parent plant. This process proves that mature plant cells can reverse their differentiation and develop in to all the specialized cells of an adult plant. </p>"},{"location":"1_Core/General_Biology/03_Genetic_Regulation_and_the_Process_of_Cloning/#reproductive-cloning-of-animals","title":"Reproductive Cloning of Animals:","text":"<p>This is achieved through Somantic Cell Nuclear Transplantation (SCNT) which involves replacing the nucleus of an egg cell or a zygote with a nucleus removed from an adult body cell. If the animal to be cloned is a mammal, further development of zygote requires implanting the early embryo in the uterus of a surrogate mother. The result will be the clone of the donor (not the surrogate mother). </p>"},{"location":"1_Core/General_Chemistry/","title":"General Chemistry","text":"<p>General Chemistry</p> <p>This course provides a comprehensive understanding of fundamental concepts and principles in chemistry.</p> <p>The notes are organized into three main sections: inorganic chemistry, organic chemistry, and physical chemistry.</p> <p>In addition, useful yt links and tutorial sheet answers are provided for all the tutorial sheets to enhance your understanding of the material.</p>"},{"location":"1_Core/General_Chemistry/01_In-Organic/","title":"01 In Organic","text":"<ul> <li>In-Organic<ul> <li> <p>Co-ordination chem</p> <ul> <li> <p>Handwritten notes (14 pg)</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Tutorial 1 (organic)</p> <p></p> <p></p> </li> <li> <p>Tutorial 2 (organic)</p> <p></p> <p></p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"1_Core/General_Chemistry/02_Organic/","title":"02 Organic","text":"<ul> <li> <p>Organic</p> <ul> <li> <p>Substitution and elimination reactions</p> <ul> <li> <p>Handwritten notes (17 pg)</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>https://www.youtube.com/watch?v=hz-fSXifP9w&amp;t=286s&amp;ab_channel=TheOrganicChemistryTutor very good video that explains everything in sub elimination nd provides a good table for easy learning</p> </li> <li>https://www.youtube.com/watch?v=qTc2uud7TVU&amp;ab_channel=TheOrganicChemistryTutor test review</li> </ul> </li> <li> <p>Addition reactions</p> <p>These reactions are exothermic because the electron density around the carbon atoms becomes polarized, making them more commercially viable.</p> <ul> <li> <p>Addition reactions</p> <ul> <li> <p>Addition rxn general mechanism</p> <ul> <li>Since carbocation is preferred stability is 3&gt;2&gt;1</li> <li> <p>Order of reactivity of Hydrogen halides is HF&lt;&lt;&lt;&lt;HCl&lt;HI where HI is the fastest because its always polarized</p> <p>F**i**C**kle **B**err**I</p> <p></p> </li> <li> <p> Constitutional isomers and regioselectivity</p> <p>Constitutional isomers</p> <p></p> </li> <li> <p> Markovnikovs rule</p> <ul> <li>Product with more branches is preferred</li> <li>H goes to Carbon atom with more Hydrogen ( rich becomes richer ) and the product we get is the major product</li> <li>major requires lower Gibbs free energy</li> <li> <p>Both back side and front side attack is possible therefore this results in the formation of a racemic mixture of two possible enantiomers, since the addition can occur from either side of the double bond.</p> <p></p> </li> </ul> </li> <li> <p> Stereochemistry of ionic addition to alkene</p> <p></p> </li> <li> <p> Anti- Markovnikovs rule</p> <p></p> <ul> <li>Peroxide has no effect on HI and HCl ( R-O-O-R is a peroxide )</li> <li>Chain initiation and chain propagation ( Formation of free radical and formation of Halo hydrocarbon )</li> </ul> <p></p> <p>https://www.youtube.com/watch?v=ZMcCvD5dDMU explains this</p> <p>Basically, Chain initiation happens first where bond is broken and we get roh and Br</p> <p>and then propogation happens where the Br we got from before  attacks to form a stable carbocation which is then attacked by HBR again to provide the hydrogen</p> </li> </ul> </li> <li> <p>Addition rxn with H2SO4 to form alcohol</p> <ul> <li> <p> Addition of H2SO4 to alkene</p> <p></p> <p>It is stereo-specific and follows markonikovs rule</p> </li> </ul> </li> <li> <p>Addition rxn with water</p> <ul> <li> <p> Acid catalyzed Hydration</p> <p>Follows Markovnikovs reaction</p> <p></p> </li> </ul> <p>Step 2 and 3 are fast follows markovnikovs</p> </li> <li> <p>Le Chatliers principle</p> <p>The hydration dehydration equilibria is altered  towards hydration \u2014&gt; alcohol \u2014&gt; adding dil. acid at low temp towards dehydration \u2014&gt; Alkene \u2014&gt; adding conc. acid at high temp</p> </li> <li> <p>Oxymercuration Hydration</p> <p>Regiospecific rxn </p> <p>follows markovnikovs rxn we get Oh , nabh4 removes the HgOAc</p> <p></p> </li> <li> <p>Hydro Boration Hydration rxn</p> <p>https://www.youtube.com/watch?v=RBwOfhS6mBM</p> <p>Boron is less e-ve than hydrogen that's why the oppo happens ,  concerted rxn</p> <p>first step u get tri alky bromine  2<sup>nd</sup> step u add h202</p> <p>Anti markovnikovs rxn</p> <p></p> <p>remember ch3 in back or front and Oh in front and back they will be oppo of each others positions</p> <p>(your alcohol and hydrogen should be on the same side)</p> <p>https://www.youtube.com/watch?v=PFwYIkkOyzA&amp;ab_channel=FrankWong helps alot</p> <p>https://www.youtube.com/watch?v=I-pmeHcjD8M&amp;ab_channel=Leah4sci</p> <p>Mechanism</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Electrophilic addition of Br2/Cl2 to Alkenes</p> <p>General rxn we get enantiomers</p> <p>https://www.youtube.com/watch?v=ZfOcYntQmlk&amp;list=RDCMUCEWpbFLzoYGPfuWUMFPSaoA&amp;start_radio=1&amp;rv=ZfOcYntQmlk&amp;t=6</p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Halo hydrin formation</p> </li> </ul> </li> </ul> <p></p> <p></p> <pre><code>- **Practice Qs + Tutorial**\n\n    ![Untitled 57](https://github.com/Muqaram0/Muqaram0/assets/130496042/01ffd97b-4ec7-495a-8af0-7cfcdaaa55da)\n\n    ![Untitled 58](https://github.com/Muqaram0/Muqaram0/assets/130496042/5fc7016a-f081-4a6a-988f-279eb2c671c7)\n\n    ![Untitled 59](https://github.com/Muqaram0/Muqaram0/assets/130496042/09629a50-0ef8-4314-882d-bbaea54640a1)\n\n    Fickle Beri :- Cl is more e-ve\n\n    ![Untitled 60](https://github.com/Muqaram0/Muqaram0/assets/130496042/9c39f85e-f3c4-48af-bc6f-538698234290)\n\n    ![Untitled 61](https://github.com/Muqaram0/Muqaram0/assets/130496042/dd3ade01-17b2-4b2c-8315-528839d2555e)\n</code></pre> </li> <li> <p>Aromaticity</p> <ul> <li> <p>Conditions to check for aromaticity</p> <ul> <li>Acidic strength is proportional to stability</li> <li>https://www.youtube.com/watch?v=qDZIvjcM_Gk&amp;list=PLaySzQJTCO1mdBoL-BLBfKrhgdwRpbOnx helpful video on this</li> <li>It has to be cyclic ( self-explanatory)</li> <li> <p>Planar</p> <p>Has to have a 2-D structure and not a 3D structure</p> <p>sp3 - tetrahedral is 3D and wont be aromatic ,  sp2 - trigonal planar is aromatic because flat</p> <p></p> </li> <li> <p>Conjugated at the ring</p> <p></p> <p>Should be able to follow resonance , in the other two figures it cant follow resonance because the carbon atom is sp3 hybridized and cant accept more ( mainly depends on the availability of the p orbital )</p> <p></p> <p></p> <p>             - Should follow huckels rule</p> <p>4n + 2 = pi electrons where n should be a whole number , if n is not a whole number then it is not aromatic</p> <p></p> <p>\ud83d\udca1SHORTCUT :- if there are even no. of electron pairs then we will get n as a fraction therefore not aromatic or we can say it does not obey huckels rule , if odd then its aromatic </p> <p>eg:- </p> <p></p> <p>11 pairs :- which is odd and therefore follows huckels rule no need to do lengthy calc</p> <p></p> <p>IMPORTANT :- Here it follows huckels rule because we are counting the lone pair from -ve charge also as an e- pair</p> </li> <li> <p>There are 3 classes :- Aromatic , Anti Aromatic and non aromatic</p> <p>Aromatic and Anti aromatic they both look the same but one follows huckels rule and the other does not</p> <p>Non aromatic don't follow all 4 properties </p> <p></p> </li> <li> <p>Heterocyclic aromatic compounds are compounds where not all are carbon atoms</p> <p>They want to be aromatic which means it wants to resonate </p> <p>check if the atom is participating in resonance or not , if its participating with a pi bond you don't add the electrons in , if its not participating you use the lone pair</p> <p>(or) if the atom has a pi bond you dont use the lone pair , if it does not have a pi bond you use the lone pair , if it has 2 lone pairs you use only one</p> <p></p> <p>eg:- </p> <p></p> <p></p> <p>we are not using the lone pair , that is why we wont count it in the huckel rule and get it as aromatic and not anti-aromatic</p> </li> </ul> </li> <li> <p>Annulenes</p> <ul> <li> <p>Nomenclature</p> <p></p> <p>Annulenes must have even number of electrons</p> <p>branches into two , either anti aromatic annulenes or aromatic annulenes (refer to huckels rule)</p> </li> <li> <p>Some examples</p> <p></p> <p>due to repulsion or ang. strain</p> <p>happens with [8] annulene, [10] annulene , [14] annulene and [18] annulene (non aromatic)</p> </li> </ul> </li> <li> <p>Practice Qs</p> <p></p> <p>notice how there is -ve charge (lone pair) after treating it with strong base</p> <p></p> <p>h) is anti atomaticc not aromatic*</p> <p></p> <p>order is pyridine&gt;pyrolidene&gt;pyrole not pyridene&gt;pyrole&gt;pyrolidene</p> <p>depends on basicity which depends on the no. of lp</p> <p>if we look at pyridine and pyrole , if we dont consider the lp it is less basic then pyrole , but because of the presence of lp it is more basic as it has more donating power now</p> <p>similarly, if we look at pyrole and pyrolidene pyrolidine will be more basic than pyrole because pyrole has less donating power as its lone pair is being used </p> </li> </ul> </li> <li> <p>Stereochem</p> <p>Stereochemistry</p> <ul> <li> <p>Identification of chirality or achirality</p> <p>https://www.youtube.com/watch?v=KztTL3FTcOw helpful video</p> <p></p> <p>It needs to have 4 different functional groups attached to the carbon atom for it to be chiral</p> <p>2^n is the max no. of stereomers you can have , where n is the no. of chiral centers </p> <p>if we have 2 chiral centers then molecule may or may not be chiral depending on the symmetry</p> <p></p> <p>Chiral means active , Achiral means inactive </p> </li> <li> <p>Diff. Types of Isomers</p> <ul> <li> <p>Types of isomers</p> <ul> <li> <p>Isomerism :- Different compound but same molecular formula</p> <p></p> </li> <li> <p>Constitutional Isomers :- Atoms have diff connectivity</p> <p></p> <p>IMPORTANT :- Numbering diff = constitutional isomer </p> </li> <li> <p>Stereoisomers :- Atoms differ in arrangement of their atoms in space</p> <p></p> </li> <li> <p>Enantiomers :- Non superimposable mirror images</p> <p></p> </li> <li> <p>Diastereomers :- Non superimposable non mirror images</p> <p></p> </li> <li> <p>Cis-trans geometric isomers</p> <p></p> </li> </ul> </li> <li> <p>Some examples</p> </li> </ul> <p></p> <p></p> <p>Achiral can never be enantiomer instead its a meso compound ( have a plane of symmetry )</p> <p></p> <p>All chiral centers change in enantiomers</p> <p></p> <p></p> <p>They are the same  because of achirality</p> <p></p> <p>Constitutional isomers ^</p> <p>https://www.youtube.com/watch?v=KztTL3FTcOw helpful vid</p> <ul> <li>Chirality<ul> <li>Diff functional group on Carbon</li> <li>Absence of Planar ( Internal Symmetry \u2014&gt; condition for chirality )</li> </ul> </li> <li>Chirality Center<ul> <li>Asymmetric Carbon atom</li> <li>Stereocenter :- when the interchange of 2 groups gives stereoisomers ( Asymmetric carbons and cis-trans isomers )</li> <li>Achirality :- When the images can be superimposed and has a plane of symmetry</li> </ul> </li> </ul> </li> <li> <p>Cahn Ingold Prelog priority system + R and S configuration</p> <p>Fancy name for what reason </p> <p>https://www.youtube.com/watch?v=yzfcrwJ37kI helpful video</p> <p></p> <p>3 chiral centers therefore using 2^n there will be 8 possible stereomers</p> <p></p> <p>Chiral carbon will have 4 different functional groups , to assign it a R or S order we rank the Functional groups using the priority system</p> <p>Priority is based on atomic no. </p> <p>I&gt;Br&gt;Cl&gt;S&gt;F&gt;O&gt;N&gt;13C&gt;12C&gt;2H1&gt;1H1</p> <p>assign numbers to each atom and count from 1 to 4 , 4<sup>th</sup> group should be in the back </p> <p>if anti- clockwise we assign it S config and if clock wise we give it R config R:-rolling\u2014&gt; clockwise</p> <p>atomic no:- of carbon is 6</p> <p></p> <p></p> <p></p> <p>switch the configuration from R to S or S to R  if the last hydrogen atom is not in the Back (hatched wedge)</p> <p>Nomenclature</p> <p></p> <p>for double and triple bonds you open them up</p> <p></p> <p>here it was not shown if H is in the front or the back , so we do the double flip ( interchange oppo groups ) to get the position of H</p> <p>         - Fischer's Projection</p> <p></p> <p>groups on the horizontal edge are in the front and groups on vertical ends are in the back</p> </li> <li> <p>Optical Activity and Specific Rotation</p> <p>Enantiomers rotate the plane polarised light in oppo. direction, but same no. of degrees </p> <p>Clockwise :- Dextro rotatory (+)</p> <p>Anti-Clockwise :- Levo rotatory (-) levo-left</p> <p>S makes light go right , R makes light go left</p> <ul> <li> <p>Specific rotation</p> <p>alpha = observed rotation</p> <p>l = path length</p> <p>C = concentration</p> <p>)</p> <p>Q. When one of the enantiomers of 2-butanol is placed in a polarimeter, the observed rotation is 4.05 degrees anti-clockwise . The soln. was made by diluting 6g of 2-butanol to a total of 40ml , and the solution was placed into 200mm polarimeter tube for measurement . Determine the specific rotation for this enantiomer of 2-Butanol.</p> <p></p> </li> </ul> </li> <li> <p>Racemic mixtures</p> <p></p> <p>will not rotate polarized light because equal amounts of left polarizing and right polarizing light is there in the mixture </p> </li> <li> <p>E/Z system</p> <p>https://www.youtube.com/watch?v=frtnEDTSzi8 helpful video</p> <p></p> <p>when highest priority group is on same side we get Z isomer  (Zame) (Zusammen)</p> <p>when highest priority group is on oppo. sides we get E isomer (OppositE) (Entgegen)</p> <p></p> </li> <li> <p>Practice Qs + Tutorial</p> <p></p> </li> </ul> </li> <li> <p>Conformational Analysis</p> <ul> <li> <p>Basic</p> <p>Conformations:- Different Spatial arrangements that a molecule can adapt due to rotation about the internal bonds </p> <p>Conformers:- Structurers that differ based on rotation</p> <p>Conformational analysis :- Study of energy changes that occur during rotations</p> <p></p> </li> <li> <p>Newmanns Projection</p> <p></p> <p></p> </li> <li> <p>Energy</p> <p>\u2022 \u00a0Torsional strain is an increase in energy caused by electron-electron repulsions between the eclipsing C-H bonds</p> <p>Why is staggered more stable than eclipse?</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>The chair conformation is very stable because it eliminates angle strain\u00a0 and torsional strain (all hydrogens on adjacent C atoms are staggered)</p> <p></p> <p></p> <p></p> <p>Axial is less stable than Equatorial pos because it minimizes steric repulsion</p> <p></p> <p>Axial becomes Equatorial and vice versa numbering changes  </p> <p>up stays up and down stays down they dont change</p> <p> if we go from form A to B the numbering shifts to the next carbon clockwise</p> <p>if vice versa then numbering shifts back and anti clockwise</p> <p>The bigger arrow shows that the equilibrium favors the more stable product</p> </li> <li> <p>Problems</p> <p></p> <p></p> <p></p> <p>bulky group on equatorial thats why more stable than bulky group on axial</p> <p></p> <p></p> </li> <li> <p>Tutorial</p> <p>https://apps.dso.iastate.edu/si/documentdb/spring_2016/CHEM_331_Kraus_ihazlett_331_Worksheet_Week_4_Key_2_.pdf very useful worksheet</p> <p>https://www.garybreton.com/CHM_223HF/ewExternalFiles/4_6 KEY.pdf Very useful worksheet</p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"1_Core/General_Chemistry/03_Physical/","title":"03 Physical","text":"<ul> <li> <p>Physical Chem</p> <ul> <li> <p>Quantum theory</p> <ul> <li>Energy can be transferred between systems in discrete amts only</li> <li>Radiation (light) has a particle character</li> <li> <p>Electron has a wave character</p> <ul> <li> <p>Planks Law</p> <p>The internal modes of atoms and molecules can posses only certain energies </p> <p>the modes are quantized</p> <p>E=nhv</p> </li> <li> <p>Light as a particle</p> <p>The photoelectric effect</p> <ul> <li>No electrons are ejected regardless of the intensity of the radiation unless its frequency exceeds a threshold value characteristic of the metal</li> <li>The kinetic energy of the ejected electron increases linearly with the frequency of the incident radiation but is independent of the intensity of radiation</li> <li>Even at low light intensities, electrons are ejected immediately if the frequency is above the threshold</li> <li> <p>According to conversation of energy,</p> <p></p> <p>where \u00bdmeV^2 is the kinetic energy of the ejected electron </p> <p>hv is the energy of the photon </p> <p>theta is the work function ( characteristic of the metal ) - energy required to remove an electron from the metal \u201cto infinity and beyond\u201d</p> <p>hv no photoejection where h is 6.626 x 10^-34 <li> <p>Electron as a wave</p> <p>Davisson-Germer experiment </p> <ul> <li>Diffraction of electrons by a single crystal of Ni</li> <li>Diffraction is the interference caused by an object in the path of waves</li> <li>Depending on whether the interference is constructive or destructive , the result is a region of enhanced or diminished intensity  of the wave</li> <li>particles are wave-like             - Wave-Particle Duality</li> </ul> <p>Any particle travelling with a linear momentum p=mv should have a wavelength lambda.</p> <p></p> <p>particle with high linear momentum has short wavelength </p> </li> <li> <p>Matter wave and de Broglie's relation</p> <p>Matter wave is expressed as </p> <p></p> <p>The de-broglie relation implies that the wavelength of a matter wave should decrease as the particles speed increases</p> <p>Large particles only manifest their particle nature and never their wave nature because their momenta will be so high due big mass making their wavelengths very small </p> </li> <li> <p>Dynamics of microscopic systems</p> <p>According to classical mechanics a particle has specific trajectory</p> <p>position and momenta are specified at each instant</p> <p>According to quantum mechanics a particle cannot have specific trajectory</p> <p>The wavefunction determines the probability distribution , darker the area higher the probability of finding the particle </p> <p></p> </li> <li> <p>Schrodinger's Equation</p> <p>The schrodingers equation for a single particle of mass m moving with energy E in one dimension is </p> <p></p> </li> <li> <p>Physical Significance of wave function</p> <p>The born interpretation</p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Uncertainty principle</p> <p>It is impossible to specify simultaneously , with arbitrary precision, both the momentum and the position of a particle</p> <p></p> </li> <li> <p>Application of quantum physics</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Atomic Structure</p> <ul> <li> <p>Hydrogenic atoms</p> <p>A hydrogenic atom is a one-electron atom </p> <p>Schrodinger equation can be solved for them and their structures can be discussed exactly</p> <p>Spectrum of atomic hydrogen </p> <p></p> <p></p> <p></p> <p>Boundary condition</p> <ul> <li>The wavefunction must not become infinite anywhere</li> <li>it must repeat itself ( like the particle on the surface of a sphere )</li> </ul> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Quantum numbers</p> <p></p> </li> <li> <p>Spectral transition and rules</p> <p></p> <p></p> </li> </ul> </li> <li> <p>Tutorial Quantum + Atomic + Practice qs</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>     - Chemical bonding</p> <p></p> <p></p> <p></p> <p></p> <p>Molecular orbital theory</p> <p></p> <p></p> <p></p> <p>show 1s2 also</p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Molecular spectroscopy</p> <ul> <li> <p>Vibrational spectroscopy</p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Electronic transitions</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p>sigma to anti sigma in saturated</p> <p>n to anti sigma in saturated with lone pairs</p> <p>pi to anti pi in unsaturated</p> <p>n to anti pi in unsaturated with lone pairs</p> <p></p> <p></p> <p></p> </li> </ul> </li> <li> <p>Chemical kinetics</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Tutorial Chemical bonding + spectro + kinetics</p> <p></p> <p></p> <p></p> <p></p> <p>Correction :- B2H6 is IR active because of selection rule</p> <p>In quantum mechanics, a selection rule is a criterion that determines whether a particular physical process or transition is allowed or forbidden. It specifies the conditions under which a transition can occur between two energy states of a system. In the context of spectroscopy, selection rules determine which types of transitions are observable in a particular spectroscopic technique, such as infrared (IR) spectroscopy.</p> <p>IR spectroscopy is based on the absorption or emission of infrared radiation by molecules. It involves transitions between different vibrational energy levels of the molecules. The selection rule for IR activity is known as the electric dipole selection rule. According to this rule, for a molecule to exhibit an infrared absorption, the vibrational mode must result in a change in the molecular dipole moment.</p> <p>Now, let's consider the molecule B2H6, which is called diborane. Diborane consists of two boron atoms (B) and six hydrogen atoms (H). In this molecule, the B-B bond is symmetrical, and the H atoms are arranged symmetrically around the boron atoms. Due to this symmetry, some vibrational modes of B2H6 do not result in a net change in the dipole moment of the molecule and, therefore, do not produce infrared absorption. These modes are said to be \"IR inactive.\"</p> <p>However, there are vibrational modes in B2H6 that do result in a change in the dipole moment and satisfy the electric dipole selection rule. For example, the bending vibrations of the BH3 groups and the stretching vibrations of the B-H bonds involve changes in dipole moment and are therefore IR active. These modes can be observed in the infrared spectrum of B2H6.</p> <p>In summary, the selection rule for IR activity requires a change in the molecular dipole moment for a vibrational mode to be observable in the infrared spectrum. B2H6 exhibits IR activity for certain vibrational modes that involve changes in the dipole moment, such as the bending and stretching vibrations</p> <p></p> <p>Correction :- Beneze - pi to anti pi and sigma to anti sigma</p> <p>Acetone:- n to anti pi , pi to anti pi , n to anti sigma , sigma to anti sigma</p> <p></p> <p></p> <p></p> <p></p> <p></p> </li> <li> <p>Thermodynamics</p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> </li>"},{"location":"1_Core/Math_1/","title":"Math 1","text":"<p>This course is mainly about vector calculus</p>"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/","title":"01 Polar Coordinates and Conic Sections","text":""},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#polar-coordinates","title":"Polar Coordinates","text":"<p>In polar coordinate system, we locate a point with reference to:</p> <ol> <li>pole a fixed point    (usually fixed at the origin)</li> <li>initial ray a fixed line, passing through the pole    (usually \\(+x\\) axis)</li> </ol> <p>Let </p> <ul> <li>\\(r\\) - directed distance of the point from pole<ul> <li>\\(r &gt; 0\\) forward</li> <li>\\(r &lt; 0\\) backward</li> </ul> </li> <li>\\(\\theta\\) - directed angle of radius vector from the initial ray<ul> <li>\\(\\theta &lt; 0\\) anti-clockwise</li> <li>\\(\\theta &gt; 0\\) clockwise</li> </ul> </li> <li>\\(P(r, \\theta)\\) - corresponding point</li> </ul> <p></p>"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#circle-through-pole","title":"Circle Through Pole","text":"\\[ r = \\pm a, \\quad 0 \\le \\theta \\le 2 \\pi \\] <p>represents a circle with center @pole and radius \\(a\\). Sign can be either, because it is the same circle traversed in the opposite direction</p>"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#straight-line-through-pole","title":"Straight line through pole","text":"\\[ \\theta = \\theta_0, \\quad - \\infty &lt; r &lt; \\infty \\]"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#idk","title":"IDK","text":"\\(r\\) \\(\\theta\\) Diagram const const point const inequality arc inequality const straight line segment inequality inequality region"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#cartesian-iff-polar","title":"Cartesian \\(\\iff\\) Polar","text":"<p>Consider the point \\(P(x, y) \\iff P(r, \\theta)\\)</p> \\[ \\begin{aligned} x &amp;= r \\cos\\theta \\\\ y &amp;= r \\sin\\theta \\\\ r^2 &amp;= x^2 + y^2 \\\\ \\theta &amp;= \\tan^{-1} \\left( \\frac y x \\right) \\end{aligned} \\]"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#symmetry","title":"Symmetry","text":"<p>Let \\(r = f(\\theta)\\) be a polar curve</p>"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#x-axis","title":"X-axis","text":"<p>\\(P(r, \\theta)\\) and \\(P'(r, - \\theta)\\) lie on same graph</p> Symmetry about Vary theta \\(P(r, \\theta)\\) lies on the same graph as or \\(P(r, \\theta)\\) lies on the same graph as X-axis \\(0 \\le \\theta \\le \\pi\\) \\(P'(r, -\\theta)\\) \\(P'(-r, \\pi -\\theta)\\) Y-axis \\(\\frac{-\\pi} 2 \\le \\theta \\le \\frac \\pi 2\\) \\(P'(-r, -\\theta)\\) \\(P'(r, \\pi -\\theta)\\) Origin \\(0 \\le \\theta \\le \\frac \\pi 2\\) \\(P'(-r, \\theta)\\) \\(P'(r, \\pi + \\theta)\\)"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#shapes","title":"Shapes","text":""},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#limacon","title":"Limacon","text":"\\[ r = a \\pm b \\cos\\theta \\\\ \\text{ or } \\\\ r = a \\pm b \\sin\\theta \\] \\(\\frac a b\\) Type \\(&lt;1\\) inner loop \\(=1\\) cardioid \\(&gt;1\\) outer loop"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#roses","title":"Roses","text":"\\[ \\begin{aligned} r &amp;= a \\cos(n\\theta) \\\\ &amp;\\text{ or } \\\\ r &amp;= a \\sin(n\\theta) \\\\ \\text{No of petals } N &amp;= \\begin{cases} n, &amp;  n = \\text{odd} \\\\ 2n, &amp; n = \\text{even} \\end{cases} \\\\ \\text{Axis of first petal } \\theta &amp;=  \\begin{cases} 0 &amp;  r = a \\textcolor{orange}{\\cos}(n \\theta) \\\\ \\dfrac \\pi {2n} &amp; r = a \\textcolor{orange}{\\sin} (n \\theta) \\end{cases} \\\\ \\text{Length of petals} &amp;= a \\\\ \\text{Angular Gap between axes of petals} &amp;= \\frac{2 \\pi}{N} \\end{aligned} \\]"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#lemmiscates","title":"Lemmiscates","text":"\\[ r^2 = a \\cos\\theta \\\\ \\text{ or } \\\\ r^2 = a \\sin\\theta \\\\ \\]"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#straight-line","title":"Straight Line","text":"\\[ r \\cos(\\theta-\\theta_0) = r_0 \\] <ul> <li>\\(P(r, \\theta)\\) is any point on given line</li> <li>\\(P_0(r_0, \\theta_0)\\) is foot of \\(\\perp\\)r from the pole</li> </ul>"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#circle","title":"Circle","text":"\\[ r^2 + {r_0}^2 - 2 r r_0 \\cos(\\theta - \\theta_0) = a^2 \\\\ \\] <ul> <li>\\(P(r, \\theta)\\) is any point on circle</li> <li>\\(P_0(r_0, \\theta_0)\\) is center of circle</li> <li>\\(a\\) is radius</li> </ul>"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#radius-passing-through-pole","title":"Radius passing through pole","text":"\\[ r_0 = a\\\\ r = 2a cos(\\theta - \\theta_0) \\]"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#center-lies-on-axis","title":"Center lies on axis","text":"Center at \\(r\\) \\((a,0)\\) \\(2a \\cos \\theta\\) \\((-a,0)\\) \\(-2a \\cos \\theta\\) \\((a, \\frac \\pi 2)\\) \\(2a \\sin \\theta\\) \\((a, -\\frac \\pi 2)\\) \\(-2a \\sin \\theta\\)"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#area-under-curve","title":"Area under curve","text":"<p>For a polar curve \\(r = f(\\theta), \\alpha \\le \\theta \\le \\beta\\)</p> \\[ A = \\frac12 \\int\\limits_{\\theta = \\alpha}^\\beta r^2 \\cdot d\\theta \\] <p>For area bounded by the curves \\(r_1 = f_1(\\theta), r_2 = f_2(\\theta), \\alpha \\le \\theta \\le \\beta\\) such that \\(r_1 &lt; r_2\\)</p> \\[ A = \\frac12 \\int\\limits_{\\theta = \\alpha}^\\beta {r_2}^2 - {r_1}^2 \\cdot d\\theta \\]"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#length-of-curve","title":"Length of curve","text":"<p>For a curve \\(r = f(\\theta), \\alpha \\le \\theta \\le \\beta\\) traversed exactly once from \\(\\theta = \\alpha \\to \\beta\\)</p> \\[ L = \\int\\limits_{\\theta = \\alpha}^\\beta \\sqrt{ r^2 + (r')^2 } \\cdot d\\theta \\qquad \\left[ r' = \\frac{dr}{d \\theta} \\right] \\]"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#conic-sections","title":"Conic Sections","text":"<p>Let</p> <ul> <li>\\(P(r, \\theta)\\) be any point on the conic section with focus at origin</li> <li>\\(e = \\dfrac{ \\text{Distance bw focii} }{ \\text{Distance bw vertices} }\\)</li> </ul> Directrix \\(r\\) \\(x = a\\) \\(\\frac{ke}{1 + e \\cos\\theta}\\) \\(x = -a\\) \\(\\frac{ke}{1 - e \\cos\\theta}\\) \\(y = a\\) \\(\\frac{ke}{1 + e \\sin\\theta}\\) \\(y = -a\\) \\(\\frac{ke}{1 - e \\sin\\theta}\\)"},{"location":"1_Core/Math_1/01_Polar_Coordinates_and_Conic_Sections/#shapes_1","title":"Shapes","text":"\\(e\\) Shape \\(0 &lt; e &lt; 1\\) Ellipse \\(e = 1\\) Parabola \\(e &gt; 1\\) Hyperbola <p>For ellipse,</p> \\[ k = a \\left[ \\frac 1 e - e \\right] \\]"},{"location":"1_Core/Math_1/02_Limits_and_Continuity/","title":"02 Limits and Continuity","text":""},{"location":"1_Core/Math_1/02_Limits_and_Continuity/#limits","title":"Limits","text":"<p>Let \\(f\\) be defined @ all points in some neighborhood of a point \\(x_0\\)</p> <p>Then \\(L = \\lim\\limits_{x \\to x_0} f(x)\\) is limit for \\(f(x)\\) when \\(x \\to x_0\\) if for a given \\(\\epsilon &gt; 0\\), there exists a \\(\\delta &gt; 0\\) such that \\(|x-x_0| &lt; \\delta \\implies |f(x)-L| &lt; \\epsilon\\)</p>"},{"location":"1_Core/Math_1/02_Limits_and_Continuity/#finding-delta","title":"Finding \\(\\delta\\)","text":"<ol> <li>Solve the inequality \\(f(x) - L &lt; \\epsilon\\) for \\(x\\)</li> <li>Find an interval \\((a, b)\\) such that \\(a \\le x_0 \\le b\\)</li> <li>Choose \\(\\delta = \\min (x_0-a, b - x_0)\\)</li> </ol> <p>This choice places the interval \\((x_0 - \\delta, x_0 + \\delta)\\) within \\((a, b)\\)</p>"},{"location":"1_Core/Math_1/02_Limits_and_Continuity/#one-sided-limits","title":"One-sided Limits","text":"<p>Let \\(f\\) be defined at all points in the neigborhood of \\(x_0\\) (in particular to right of \\(x_0\\)), then \\(f\\) is said to have the right-hand limit \\(L\\), when \\(x\\) approaches \\(x_0\\) from the right if the following conditions are satisfied:</p> <p>For a given \\(\\epsilon &gt; 0\\), there exists a \\(\\delta &gt; 0\\) such that</p> <ul> <li>\\(x_0 &lt; x &lt; x_0 + \\delta\\)</li> <li>\\(|f(x) - L| &lt; \\epsilon\\)</li> </ul> <p>The limit is represented as</p> \\[ L = \\lim_{x \\to {x_0}^+} f(x) = f({x_0}^+) \\] <p>Similarly, we define the left-hand limit</p> <p>While working on one-sided problms, we proceed as follows</p> \\[ \\begin{aligned} f({x_0}^+) &amp;= \\lim_{h \\to 0} f(x_0 + h), &amp; h &gt; 0 \\\\ f({x_0}^-) &amp;= \\lim_{h \\to 0} f(x_0 - h), &amp; h &gt; 0 \\end{aligned} \\]"},{"location":"1_Core/Math_1/02_Limits_and_Continuity/#continuity","title":"Continuity","text":"<p>A function \\(f(x)\\) is continuous @ a point \\(x_0\\) if the following conditions are satisfied</p> <ol> <li>\\(f(x_0)\\) exists</li> <li>\\(\\lim_{x \\to x_0} f(x)\\) (Both LHL and RHL) exists</li> <li>\\(\\lim_{x \\to x_0} f(x) = f(x_0)\\)</li> </ol>"},{"location":"1_Core/Math_1/02_Limits_and_Continuity/#note","title":"Note","text":"<p>If \\(f\\) and \\(g\\) are continuous functions in a domain \\(D\\), then the following functions are also continuous in all points of F</p> \\[ \\begin{aligned} f \\pm g \\\\ fg \\\\ \\frac f g \\\\ kf, &amp; (k \\text{=  const}) \\end{aligned} \\] <p>The following functions are known to be continuous in their domain of definition</p> <ol> <li>polynomial</li> <li>exponential</li> <li>trignometric</li> </ol>"},{"location":"1_Core/Math_1/03_Vector_Calculus/","title":"03 Vector Calculus","text":""},{"location":"1_Core/Math_1/03_Vector_Calculus/#vector-valued-functions","title":"Vector Valued Functions","text":"<p>The motion of a particle moving space is given by</p> \\[ \\vec r = x(t) \\cdot \\hat i + y(t) \\cdot \\hat j + z(t) \\cdot \\hat k, \\\\ a \\le t \\le b, \\quad a, b \\in R \\]"},{"location":"1_Core/Math_1/03_Vector_Calculus/#limits","title":"Limits","text":"<p>\\(\\vec r(t)\\) has a limit \\(\\vec L\\) as \\(t\\) approaches \\(t_0\\) if the following is satisfied For every \\(\\epsilon &gt; 0\\), there exists a \\(\\delta &gt; 0\\) such that \\(0&lt;|t - t_0|&lt; \\delta \\implies | \\vec r(t) - \\vec L | &lt; \\epsilon\\)</p> <p>The limit is denoted as</p> \\[ \\lim_{t \\to t_0} \\vec r(t) = \\vec L \\]"},{"location":"1_Core/Math_1/03_Vector_Calculus/#continuity","title":"Continuity","text":"<p>\\(r(t)\\) is continuous @ \\(t = t_0\\) if</p> <ol> <li>\\(\\vec r(t_0)\\) exists</li> <li>\\(\\lim_{t \\to t_0} \\vec r(t)\\) exists</li> <li>\\(\\lim_{t \\to t_0} \\vec r(t) = \\vec r(t_0)\\)</li> </ol>"},{"location":"1_Core/Math_1/03_Vector_Calculus/#derivative","title":"Derivative","text":"\\[ \\frac{dr}{dt} = \\lim_{\\Delta t \\to 0} \\frac{     \\vec r(t + \\Delta t) - \\vec r(t) }{\\Delta t} \\] Quantity Velocity \\(\\frac{d \\vec r}{d t}\\) Acceleration \\(\\frac{d \\vec V}{d t}\\) \\(\\frac{d^2 \\vec r}{d t^2}\\) Speed \\(\\vert\\vec V\\vert\\) Direction \\(\\frac{\\vec V}{\\vert\\vec V\\vert}\\)"},{"location":"1_Core/Math_1/03_Vector_Calculus/#note","title":"Note","text":"<p>Velocity = Speed \\(\\times\\) Direction</p> <p>The path of a particle is said to be smooth if</p> <ol> <li>\\(\\frac{d \\vec r}{d t} \\ne 0\\)</li> <li>\\(\\frac{d \\vec r}{d t}\\) is continuous</li> </ol> <p>If \\(\\vec u\\) is a vector of constant length, then \\(\\vec u \\cdot \\frac{d \\vec u}{d t} = 0\\) (circle, perpendicular, cos 90 = 0)</p> <p>The path of a particle is gievn by eliminating the parameter \\(t\\) from \\(x, y, z\\) eg: The path of a particle having \\(\\vec r(t) = \\cos t \\cdot \\hat i + \\sin t \\hat j, \\quad t \\in I\\)</p> \\[ \\begin{aligned} x^2 + y^2 &amp;= \\cos^2 t + \\sin^2 t \\\\ &amp;= 1 \\end{aligned} \\] <p>Therefore, this path is a circle with radius = 1</p>"},{"location":"1_Core/Math_1/03_Vector_Calculus/#angle-between-vectors","title":"Angle Between Vectors","text":"\\[ \\begin{aligned} \\cos \\theta &amp;= \\frac{     \\vec a \\cdot \\vec b }{     |\\vec a| |\\vec b| } \\\\ \\theta &amp;= \\cos^{-1} \\left( \\frac{     \\vec a \\cdot \\vec b }{     |\\vec a| |\\vec b| } \\right) \\end{aligned} \\]"},{"location":"1_Core/Math_1/03_Vector_Calculus/#arc-length","title":"Arc Length","text":"<p>If</p> <ul> <li>\\(\\vec r(t)\\) is a smooth curve, traversed exactly once from \\(t=a \\to b\\)</li> <li>\\(\\vec V\\) is the velocity vector</li> </ul> \\[ L = \\int\\limits_a^b  |\\vec V(t)| \\cdot dt \\] <p>Length is basically the integral of speed</p>"},{"location":"1_Core/Math_1/03_Vector_Calculus/#arc-length-parameter","title":"Arc Length Parameter","text":"<p>If \\(\\vec r(t) \\quad t \\ge t_0\\) is a smooth curve, then arc length parameter wrt base point @ \\(t=0\\) is</p> \\[ L = \\int\\limits_{\\tau = t_0}^t  |\\vec V(\\tau)| \\cdot d \\tau \\]"},{"location":"1_Core/Math_1/03_Vector_Calculus/#special-vectors","title":"Special Vectors","text":"Vector Symbol Unit Tangent Vector \\(\\hat T\\) \\(\\frac{ \\frac{d \\vec r}{dt} }{\\vert\\frac{d \\vec r}{dt}\\vert}\\) \\(\\frac{\\vec V}{\\vert \\vec V \\vert}\\) Principle Unit Normal Vector \\(\\hat N\\) \\(\\frac{ \\frac{d \\vec T}{dt} }{\\vert\\frac{d \\vec T}{dt}\\vert}\\) Curvature Rate of change in direction of curve, wrt arc length \\(k\\) \\(\\frac{d \\vec T}{d s}\\) \\(\\frac{1}{\\vert \\vec V \\vert} \\cdot \\vert\\frac{d \\hat T} {dt}\\vert\\) Radius of Curvature \\(\\rho\\) \\(\\frac{1}{k}\\) <p>Curvature @ any point on a</p> <ul> <li>straight line is 0</li> <li>smaller circle will be greater than that of a larger one</li> </ul>"},{"location":"1_Core/Math_1/03_Vector_Calculus/#components-of-vector","title":"Components of Vector","text":"<p>If \\(\\vec a = a_t \\cdot \\hat T + a_N \\cdot \\hat N\\), then</p> Component Symbol Tangential \\(a_T\\) \\(\\frac{d \\vertV \\vert}{dt}\\) Normal \\(a_N\\) \\(k \\vertV\\vert^2\\) \\(\\sqrt{\\vert\\vec a\\vert^2 - {a_T}^2}\\)"},{"location":"1_Core/Math_1/03_Vector_Calculus/#note_1","title":"Note","text":"<p>If speed is contant</p> <ul> <li>\\(a_T = 0\\)</li> <li>all acceleration wil be in direction of \\(\\hat N\\)</li> </ul> <p>\\(a_T\\) only exists when objects speed up / slow down</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/","title":"04 Partial Derivatives","text":""},{"location":"1_Core/Math_1/04_Partial_Derivatives/#functions-of-several-variables","title":"Functions of Several Variables","text":"<p>Let \\(D\\) be the set of all \\(n\\) tuples of the form \\((x_1, x_2, \\dots , x_n)\\), where \\(x_1, x_2, \\dots, x_n\\) are real numbers. A function on \\(D\\) is a rule \\(f\\) that assigns a number \\(w = f(x_1, x_2, \\dots, x_n)\\) for each element in \\(D\\).</p> <p>If there exists only number \\(w\\) for each element in \\(D\\), then it is said to be a single-valued function. If more than one \\(w\\) exists, then it is said to be a many-valued function.</p> <p>While finding domain \\(D\\)</p> <ul> <li>we include all the points which make the function \\(f\\) well-defined</li> <li>neglect the values which make \\(w\\) a complex or undefined number</li> </ul>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#neighborhood","title":"Neighborhood","text":"<p>A neighborhood of a point \\(P_0(x_0, y_0)\\) is a circular disc, with centre @ \\(P_0\\) and radius \\(r\\), where \\(r\\) is a small +ve number.</p> <p>If</p> <ul> <li>\\(r= \\epsilon\\), \\(\\epsilon\\) neighborhood</li> <li>\\(r = \\delta\\), \\(\\delta\\) neighborhood</li> </ul> <p>In 3 dimensions, we replace circular disk with an open spherical ball with centre @ \\(P_0\\)</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#types-of-points","title":"Types of points","text":"<p>Let \\(S\\) be a non-empty set in the XY plane . A point \\(P_0(x_0, y_0)\\) is said to be</p> Point Condition Interior there exists a neighborhood of \\(P_0\\) which lies completely inside \\(S\\) Boundary every neighborhood of \\(P_0\\) contains points of \\(S\\) and points outside \\(S\\) Exterior there exists a neighborhood of \\(P_0\\) completely outside \\(S\\)"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#types-of-sets","title":"Types of Sets","text":"Characteristic Open contains interior points only Closed contains interior and all boundary points Bounded lies completely inside an open disk of finite radius Unbounded cannot be enclosed inside open disk of finite radius <p>\\(XY\\) plane is both open and closed.</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#level","title":"Level","text":"<p>For a function \\(f(x, y)\\) and constant \\(c\\),</p> Equation Level Curve \\(f(x, y) = c\\) Level Surface \\(f(x, y, z) = c\\)"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#limits","title":"Limits","text":"<p>Let \\(f\\) be a function defined at all points in the some neighborhood f \\((x_0, y_0)\\). We say that \\(f\\) has a limit \\(L\\), when the point \\((x, y)\\) approaches \\((x_0, y_0)\\) if for every \\(\\epsilon &gt; 0\\), there exists a \\(\\delta &gt; 0\\) such that</p> \\[ \\begin{aligned} 0 &lt; \\text{ D b/w } (x, y) \\text{ and } (x_0, y_0) &amp;&lt; \\delta \\\\ 0 &lt; \\sqrt{ (x-x_0)^2 + (y-y_0)^2 } &amp;&lt; \\delta \\\\ | f(x,y) - L | &amp;&lt; \\epsilon \\\\ \\implies L &amp;= \\lim_{(x, y) \\to (x_0, y_0)} f(x, y) \\end{aligned} \\] <p>Here, \\((x, y)\\) approaches \\((x_0, y_0)\\) in an infinite number of ways.</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#2-path-test","title":"2 Path Test","text":"<p>TO show that the limit of \\(f(x, y)\\) does not exist @ \\((x_0, y_0)\\), we find 2 different paths through which the value of limits are different.</p> <p>We choose the path as \\(y = mx^n\\) or \\(x = m y^n\\), where \\(m\\) and \\(n\\) are constants. The choice depends on the problem. We try to obtain a final limit in terms of \\(m\\)</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#continuity","title":"Continuity","text":"<p>A function \\(f(x, y)\\) is continuous at \\((x_0, y_0)\\) if</p> <ol> <li>\\(f(x_0, y_0)\\) exists</li> <li>\\(\\lim_{(x, y) \\to (x_0, y_0)} f(x,y)\\) exists</li> <li>\\(\\lim_{(x, y) \\to (x_0, y_0)} f(x,y) = f(x_0, y_0)\\)</li> </ol> <p>The following functions are continuous in their domain of definition</p> <ol> <li>Polynomial</li> <li>Exponential</li> <li>Circular</li> <li>Trignometric</li> </ol>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#partial-derivatives","title":"Partial Derivatives","text":"<p>Let \\(f(x,y)\\) be a function of 2 variables.</p> <p>Provided the limit exists, the partial derivative of \\(f\\) wrt \\(x\\) is denoted and defined by</p> \\[ \\begin{aligned} \\frac{\\partial f}{\\partial x} &amp;= \\lim_{\\Delta x \\to 0} \\frac{ f(x + \\Delta x, \\ y) - f(x, y) }{\\Delta x} \\\\ \\frac{\\partial f}{\\partial y} &amp;= \\lim_{\\Delta y \\to 0} \\frac{ f(x, \\ y + \\Delta y) - f(x, y) }{\\Delta y} \\end{aligned} \\] <p>We define higher order partial derivatives as</p> \\[ \\begin{aligned} f_x &amp;= \\frac{\\partial^2 f}{\\partial x^2} &amp;= \\frac{\\partial}{\\partial x}\\left[ \\frac{\\partial f}{\\partial x} \\right] \\\\ f_{xy} &amp;=\\frac{\\partial^2 f}{\\partial x \\partial y} &amp;= \\frac{\\partial}{\\partial x}\\left[ \\frac{\\partial f}{\\partial y} \\right] \\\\ f_{xy} &amp;= f_{yx} \\\\ f_{xx} &amp;= (f_x)_x \\end{aligned} \\]"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#laplace-equation","title":"Laplace Equation","text":"<p>If \\(u\\) is a function</p> \\[ u_{xx} + u_{yy} + u_{zz} = 0 \\]"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#chain-rule","title":"Chain Rule","text":"<p>If \\(w = f(x, y)\\) a function where \\(x, y\\) are themselves functions of</p> <ul> <li>an independent parameter \\(t\\)</li> </ul> \\[ \\frac{dw}{dt} = \\left( \\frac{\\partial w}{\\partial x} \\cdot \\frac{dx}{dt} \\right) + \\left( \\frac{\\partial w}{\\partial y} \\cdot \\frac{dy}{dt}  \\right) \\] <ul> <li>2 independent parameters \\(u, v\\)</li> </ul> \\[ \\begin{aligned} \\frac{\\partial w}{\\partial u} &amp;= \\left( \\frac{\\partial w}{\\partial x} \\cdot \\frac{\\partial x}{\\partial u} \\right) + \\left( \\frac{\\partial w}{\\partial y} \\cdot \\frac{\\partial y}{\\partial u} \\right) \\\\ \\frac{\\partial w}{\\partial v} &amp;= \\left( \\frac{\\partial w}{\\partial x} \\cdot \\frac{\\partial x}{\\partial v} \\right) + \\left( \\frac{\\partial w}{\\partial y} \\cdot \\frac{\\partial y}{\\partial v} \\right) \\end{aligned} \\]"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#implicit-differentiation","title":"Implicit Differentiation","text":"<p>Let \\(y\\) be a function of \\(x\\), expressed as an implicit relation \\(f(x, y) = 0\\).</p> <p>Differentiating partially wrt \\(x\\)</p> \\[ \\begin{aligned} \\frac{\\partial f}{\\partial x} + \\left( \\frac{\\partial f}{\\partial y} \\cdot \\frac{dy}{dx} \\right) &amp;= 0 \\\\ \\implies \\frac{dy}{dx} &amp;= \\frac{-\\partial f / \\partial x}{\\partial f / \\partial y} \\\\ &amp;= \\frac{- f_x}{f_y} \\end{aligned} \\] <p>If \\(z\\) is a function of \\(x\\) and \\(y\\), given by an implicit relation \\(f(x,y,z) = 0\\)</p> \\[ \\begin{aligned} z_x &amp;= \\frac{-f_x}{f_z} \\\\ z_y &amp;= \\frac{-f_y}{f_z} \\end{aligned} \\]"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#gradient-vector","title":"Gradient Vector","text":"<p>Let \\(f = f(x,y)\\) be a function. Then the gradient of \\(f\\)</p> \\[ \\begin{aligned} \\text{grad } f &amp;= \\nabla f \\\\ &amp;= f_x \\cdot \\hat i + f_y \\cdot \\hat j \\end{aligned} \\] <p>\\(\\nabla\\) is the vector differential operator</p> <p>\\(\\nabla f\\) acts along the normal at any point to the level curve of \\(f\\)</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#directional-derivative","title":"Directional Derivative","text":"<p>Let \\(f\\) be a function defined at all pionts in some neighborhood of \\(P_0(x_0, y_0)\\). Then, provided the limit exists, the directional derivative of \\(f\\) in the direction of \\(\\vec a = a_1 \\hat i + a_2 \\hat j\\) is given by</p> \\[ \\begin{aligned} \\text{DD} &amp;= (D_{\\hat u} f)_{P_0} \\\\ &amp;= \\lim_{s \\to 0} \\frac{f(x_0 + su_1, y_0 + su_2) - f(x_0, y_0)}{s} \\\\ &amp;= \\nabla f \\cdot \\hat u \\\\ \\nabla f &amp;= ( \\nabla f )_{P_0} \\\\ \\hat u &amp;= u_1 \\hat i + u_2 \\hat j, \\text{ unit vector in direction of } \\vec a \\\\ &amp;= \\frac{\\vec A}{|\\vec A|} \\end{aligned} \\]"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#notes","title":"Notes","text":"Direction f DD \\(\\nabla f\\) increases more rapidly \\(\\vert  \\nabla f  \\vert\\) \\(- \\nabla f\\) decreases more rapidly \\(- \\vert  \\nabla f  \\vert\\) \\(\\perp \\text{to } (\\nabla f) \\text{ or } (-\\nabla f)\\) no change 0"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#tangent-plane","title":"Tangent Plane","text":"<p>Let \\(f = f(x, y, z)\\). Then, the equation of the tangent plane passing through a point \\(P_0(x_0, y_0, z_0)\\) is given by</p> \\[ (x - x_0) {f_x}_{(P_0)} + (y - y_0) {f_y}_{(P_0)} + (z - z_0) {f_z}_{(P_0)} = 0 \\]"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#normal-line","title":"Normal Line","text":"<p>The equations of normal line at \\(P_0\\) are given by</p> \\[ \\begin{aligned} x &amp;= x_0 + t {f_x}_{(P_0)} \\\\ y &amp;= y_0 + t {f_y}_{(P_0)} \\\\  z &amp;= z_0 + t {f_z}_{(P_0)} \\end{aligned}, \\quad t \\text{ is some parameter} \\]"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#linearisation","title":"Linearisation","text":"<p>Let \\(f(x, y, z)\\) be a function and \\(P_0(x_0, y_0, z_0)\\) be any point in the domain of definition. Then, the linearisation of \\(f\\) about \\(P_0\\) is given by</p> \\[ L(x, y, z) = f(P_0) + (x - x_0){f_x}_{(P_0)} + (y - y_0){f_y}_{(P_0)} + (z - z_0){f_z}_{(P_0)} \\] <p>At all continuous points, \\(f\\) and \\(L\\) are the same.</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#extreme-values-of-a-function","title":"Extreme Values of a Function","text":"<p>Let \\(f(x,y)\\) be a function, and \\((a,b)\\) be a point.</p> <p>Absolute maximum is the point at which \\(f\\) is max; absolute minimum is the point at which \\(f\\) is minimum. They are obtained by evaluating \\(f\\) at all local minima/maxima and comparing the values.</p> Local Point Characteristic Maximum \\(f(a, b) &gt; f(x, y), \\quad \\forall (x, y)\\) in the neighborhood of \\((a,b)\\) Minimum \\(f(a, b) &lt; f(x, y), \\quad \\forall (x, y)\\) in the neighborhood of \\((a,b)\\) Saddle \\(f\\) increases in some directions and decreases in other directions at \\((a, b)\\)"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#finding-local-points","title":"Finding local points","text":"<p>At point \\((a, b)\\)</p> \\[ \\begin{aligned} 1. &amp; f_x = 0 \\text{ and } f_y = 0 \\\\ 2. &amp; r = f_{xx}, s = f_{xy}, t = f_{yy}, \\\\ &amp; D = rt - s^2 \\end{aligned} \\] \\(D\\) \\(r\\) \\((a, b)\\) &gt; 0 &lt; 0 Maximum &gt; 0 &gt; 0 Minimum &lt; 0 - Saddle = 0 - Test Fails <p>Note: In the above table, we can replace \\(r\\) by \\(t\\) as well.</p>"},{"location":"1_Core/Math_1/04_Partial_Derivatives/#constrained-maxima-minima","title":"Constrained maxima, minima","text":"<p>We extremise a function \\(f(x, y, z)\\) subject to constraint/condition \\(\\phi(x, y, z) = 0\\). We then proceed as follows</p> <ol> <li>From Lagrange\u2019s function, \\(\\lambda =\\) Lagrange\u2019s multiplier constant</li> </ol> \\[ F(x, y, z) = f + \\lambda \\phi \\] <ol> <li>The extreme values are given by</li> </ol> \\[ F_x = F_y = F_z = 0 \\] <ol> <li>Solve the equations for \\(x, y, z, \\lambda\\)</li> </ol> <p>Note</p> <ol> <li>By Lagrange\u2019s method, we cannot find whether \\(f\\) has a maximum or minimum</li> <li>If \\(f\\) is to be extremised subject to constraints \\(\\phi_1 = \\phi_2 = 0\\), then the Lagrange\u2019s function becomes</li> </ol> \\[ F = f + \\lambda_1 \\phi_1 + \\lambda_2 \\phi_2 \\]"},{"location":"1_Core/Math_1/05_Multiple_Integrals/","title":"05 Multiple Integrals","text":""},{"location":"1_Core/Math_1/05_Multiple_Integrals/#double-integrals","title":"Double Integrals","text":"<p>represented by</p> \\[ I = \\iint f(x, y) \\ dy \\ dx \\] <p>The limits of outer integral will always be constants.</p> Direction of entry parallel to axis 1<sup>st</sup> Integral 2<sup>nd</sup> Integral \\(X\\) \\(x\\) \\(y\\) \\(Y\\) \\(y\\) \\(x\\)"},{"location":"1_Core/Math_1/05_Multiple_Integrals/#changing-order-of-integration","title":"Changing order of integration","text":"<ol> <li>Obtain the new limits</li> <li>Evaluate the integrals</li> </ol>"},{"location":"1_Core/Math_1/05_Multiple_Integrals/#cartesian-integral-iff-polar-integral","title":"Cartesian Integral \\(\\iff\\) Polar Integral","text":"<p>Let \\(f\\) be defined in a domain \\(R\\) in the \\(XY\\) plane. Then</p> \\[ \\begin{aligned} \\iint\\limits_{R} f(x, y) \\ dA &amp; = \\iint\\limits_{R'} f(r \\cos\\theta, r \\sin\\theta) \\cdot r \\ dr \\ d\\theta \\\\ \\text{where } x &amp;= r \\cos\\theta, y = r \\sin\\theta, dA = dx \\ dy \\end{aligned} \\] <p>Note: First integrate wrt to \\(r\\), then \\(\\theta\\)</p>"},{"location":"1_Core/Math_1/05_Multiple_Integrals/#triple-integrals","title":"Triple Integrals","text":"<p>represented by</p> \\[ I = \\iiint f(x, y, z) \\ dz \\ dy \\ dx \\]"},{"location":"1_Core/Math_1/06_Vector_Integrals/","title":"06 Vector Integrals","text":""},{"location":"1_Core/Math_1/06_Vector_Integrals/#line-integrals","title":"Line Integrals","text":"<p>Let \\(f(x, y, z)\\) be a function whose domain consists of a smooth curve \\(C: \\vec r(t) = x(t) \\hat i + y(t) \\hat j + z(t) \\vec k\\). Then, then line integral of \\(f\\) over \\(C\\) is given by</p> \\[ \\int\\limits_C f(x, y, z) \\ ds = \\int\\limits_C f(x, y, z) \\cdot |\\vec V| \\ dt \\] <p>because displacement s = \\(\\int\\) velocity = \\(\\int\\) speed x direction</p> <p>Note</p> <ol> <li>We aevaluate the integral by converting the integral in terms of a parameter \\(t\\), or writing in terms of any one variable \\(x\\) or \\(y\\) or \\(z\\) alone</li> <li>A curve is smooth if \\(\\frac{d \\vec r}{dt} \\ne 0\\) and \\(\\frac{d \\vec r}{dt}\\) is a constant</li> <li>A closed curve which doesn\u2019t cross itself is called a simple closed curve</li> <li>If \\(C\\) is a simple closed curve enclosing a region \\(R\\), then +ve direction is that direction through which one walks such that the enclosed region on their left</li> </ol>"},{"location":"1_Core/Math_1/06_Vector_Integrals/#work-done","title":"Work Done","text":"<p>The work done by a force field \\(\\vec F = M \\hat i + N \\hat j + P \\vec k\\) along curve \\(C: x \\hat i + y \\hat j + z \\hat k, a \\le t \\le b\\) is</p> \\[ \\begin{aligned} W &amp;= \\int\\limits_C \\vec F \\cdot d \\vec r \\\\ &amp;= \\int\\limits_C (M \\ dx + N \\ dy + P \\ dz) \\ dt \\end{aligned} \\] <p>The above integral is also referred to as the circulation of vector \\(\\vec F\\) in fluid flow problems.</p>"},{"location":"1_Core/Math_1/06_Vector_Integrals/#conservative-forced-field","title":"Conservative Forced Field","text":"<p>If the line integral is independent of the path of integration, then \\(\\vec F\\) is said to conservative/irrotational.</p> <p>A force \\(\\vec F = M \\hat i + N \\hat j + P \\vec k\\) is conservative</p> <ol> <li> \\[    \\begin{aligned}    M_y &amp;= N_x \\\\      P_y &amp;= N_z \\\\      P_x &amp;= M_z    \\end{aligned}    \\] </li> <li> <p>there exists a scalar potential function \\(\\phi(x, y, z)\\) such that</p> </li> </ol> \\[ \\begin{aligned} \\vec F &amp;= \\nabla \\phi \\\\ \\text{where } \\nabla \\phi &amp;= \\phi_x \\hat i + \\phi_y \\hat j + \\phi_z \\hat k \\end{aligned} \\] <ol> <li>If \\(C\\) is any path joining A and B</li> </ol> \\[ \\begin{aligned} W &amp;= \\int\\limits_C \\vec F \\cdot d \\vec r \\\\    &amp;= \\phi(B) - \\phi(A) \\end{aligned} \\]"},{"location":"1_Core/Math_1/06_Vector_Integrals/#greens-theorem-in-a-plane","title":"Green\u2019s Theorem in a Plane","text":"<p>Let \\(\\vec F = M \\hat i + N \\hat j\\) be a vector-valued function defined at all points in a region \\(R\\) in the \\(XY\\) plane, bounded by a simple closed curve C. Then, the counter-clockwise circulation of \\(\\vec F\\) or flux or tangential form of Green\u2019s theorem is given by</p> \\[ \\begin{aligned} \\oint\\limits_C \\vec F \\cdot d \\vec r &amp;= \\int\\limits_C M \\ dx + N \\ dy \\\\ &amp;= \\iint\\limits_R  \\left( \\frac{\\partial N}{\\partial x} - \\frac{\\partial M}{\\partial y} \\right) \\ dx \\ dy \\end{aligned} \\]"},{"location":"1_Core/Math_1/06_Vector_Integrals/#gauss-divergence-theorem","title":"Gauss Divergence Theorem","text":"<p>Let \\(F = M \\hat i + N \\hat j + P \\hat k\\) be a vector-valued function, defined at all points of closed surface \\(S\\), enclosing a volume \\(V\\). Then, the outward-drawn flux of \\(\\vec F\\) is given by</p> \\[ \\begin{aligned} \\iint_S \\vec F \\cdot \\vec n \\cdot ds &amp;= \\iiint (\\text{div } \\vec F) \\ dv \\\\ \\text{where } (\\text{div } \\vec F) &amp;= \\nabla \\cdot \\vec F \\\\ &amp;= \\frac{\\partial M}{\\partial x} + \\frac{\\partial N}{\\partial y} + \\frac{\\partial P}{\\partial z} \\\\ \\vec n &amp;= \\frac{\\nabla \\phi}{ |\\nabla \\phi| } \\\\ &amp;\\text{(unit outward-drawn normal vector to surface S)}\\\\ \\phi &amp;= \\phi(x, y, z) \\\\ &amp;\\text{(equation of surface S)} \\end{aligned} \\]"},{"location":"1_Core/Math_1/06_Vector_Integrals/#stokes-theorem","title":"Stoke\u2019s Theorem","text":"<p>If \\(\\vec F = M \\hat i + N \\hat j + P \\vec k\\) is defined on all points on an open surface bounded by a simple curve \\(C\\),</p> \\[ \\begin{aligned} \\int \\limits_C \\vec F \\cdot dr &amp;= \\iint \\limits_S (\\text{curl } \\vec F) \\cdot \\hat n \\cdot ds \\\\ \\text{where } (\\text{curl } \\vec F) &amp;= \\vec V \\times \\vec F \\\\ &amp;= \\begin{vmatrix} \\hat i &amp; \\hat j &amp; \\hat k \\\\ \\frac{\\partial}{\\partial x} &amp; \\frac{\\partial}{\\partial y} &amp; \\frac{\\partial}{\\partial z} \\\\ M &amp; N &amp; P \\end{vmatrix} \\end{aligned} \\]"},{"location":"1_Core/Math_1/07_Infinite_Series/","title":"07 Infinite Series","text":""},{"location":"1_Core/Math_1/07_Infinite_Series/#infinite-series","title":"Infinite Series","text":"<p>Let \\(\\set{a_n}_{n \\in \\mathbb{Z^+}}\\) be a sequence. Then \\(\\sum\\limits_{n = 1}^\\infty a_n = a_1 + a_2 + \\dots\\) is called a series.</p> <p>If the series has a finite number of terms, it is called a finite series; otherwise it is called an infinite series.</p> <p>A finite series is always convergent.</p> <p>A infinite series may/ may not be convergent</p> Series Type \\(1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\dots + \\frac{x^n}{n!} = e^x\\) Converges to \\(e^x\\) \\(1 + 1 + \\dots\\) Divergent \\(1 + \\frac12 + \\dots + \\frac1n\\) Divergent \\(1 - 1 + 1 - 1 +  \\dots\\) Neither convergent/divergentit is an alternating series which oscilates <p>If we are able to find the sum of a series, then the series converges to the sum \\(S_n = \\dfrac{a}{1 - r}\\)</p> <ul> <li>if sum is finite, then convergent series</li> <li>else, divergent series</li> </ul>"},{"location":"1_Core/Math_1/07_Infinite_Series/#series-of-ve-terms","title":"Series of +ve Terms","text":"<p>Consider series \\(\\sum\\limits_{n = 1}^\\infty a_n = a_1 + a_2 + \\dots + a_n\\). This series is a series of +ve terms as \\(a_n \\ge 0, \\forall n\\).</p> <p>We use the following tests.</p>"},{"location":"1_Core/Math_1/07_Infinite_Series/#ntextth-term-test","title":"\\(n^\\text{th}\\) Term Test","text":"\\[ \\lim\\limits_{n \\to \\infty} a_n =  \\begin{cases} \\ne 0 &amp; \\text{Divergent} \\\\ = 0 &amp; \\text{Test fails} \\end{cases} \\]"},{"location":"1_Core/Math_1/07_Infinite_Series/#important-results","title":"Important Results","text":"<ul> <li>Geometric sum \\(a + ar + ar^2 + \\dots\\)<ul> <li>converges to \\(\\dfrac{a}{1 - r}, |r| &lt; 1\\)</li> <li>diverges</li> </ul> </li> </ul> Converges Diverges Geometric Series \\(a + ar + ar^2 + \\dots\\) \\(\\vert  r \\vert  &lt; 1\\)converges to \\(\\dfrac{a}{1-r}\\) \\(\\vert  r  \\vert \\ge 1\\) p-series \\(\\sum\\limits_{n = 1}^\\infty \\dfrac{1}{n^p}\\) \\(p &gt; 1\\) \\(p \\le 1\\) \\[ \\begin{aligned} \\lim\\limits_{n \\to \\infty} \\frac{ \\ln \\vert n\\vert  }{n} &amp;= 0 \\quad (\\ln \\vert  n  \\vert \\text{ always } &lt; n, \\text{ so den reaches } \\infty \\text{ faster} ) \\\\ \\lim\\limits_{n \\to \\infty} x^{\\frac{1}{n}} &amp;= 1 \\\\ \\lim\\limits_{n \\to \\infty} n^{\\frac{1}{n}} &amp;= 1 \\\\ (x^0 = n^0 &amp;= 1) \\\\ \\lim\\limits_{n \\to \\infty} \\left( 1 + \\frac x n \\right)^n &amp;= e^x \\\\ \\lim\\limits_{n \\to \\infty} x^n &amp;= 0 \\text{ if } |x| &lt; 1 \\\\ \\lim\\limits_{n \\to \\infty} \\frac{x^n}{n!} &amp;= 0 \\\\ (n! &amp;&gt; x^n),  \\text{ when } n \\text{ is large so den reaches } \\infty \\text{ faster} \\end{aligned} \\]"},{"location":"1_Core/Math_1/07_Infinite_Series/#integral-test","title":"Integral Test","text":"<p>This test can be applied when \\(a_n = f(n)\\) is integrable</p> <p>Let</p> <ul> <li>\\(\\sum a_n\\) be a series of +ve terms</li> <li>\\(a_n = f(n)\\) where \\(f\\) is<ul> <li>continuous</li> <li>+ve</li> <li>decreasing function of \\(n\\), for some \\(n \\ge N\\)</li> </ul> </li> </ul> <p>Then by integral test, \\(\\int\\limits_N^\\infty f(x) \\ dx\\) and \\(\\sum\\limits_N^\\infty a_n\\) converge/diverge together</p> \\(I\\) Finite Converges(basically \\(S_n\\) is finite number) Infinite Diverges"},{"location":"1_Core/Math_1/07_Infinite_Series/#ratio-test","title":"Ratio Test","text":"<p>Used when series contains factorials like \\(n!, (2n)!\\)</p> <p>Let \\(\\sum a_n\\) be a series of +ve terms.</p> <p>Let \\(\\lim\\limits_{n \\to \\infty} \\dfrac{a_{n+1}}{a_n} = k\\)</p> \\(k\\) \\(&lt; 1\\) Converges \\(&gt; 1\\) Diverges \\(0, 1\\) Test Fails"},{"location":"1_Core/Math_1/07_Infinite_Series/#root-test","title":"Root Test","text":"<p>Used when series contains terms with exponents, such as \\(n^n, n^{n+1}, n^\\frac1n\\)</p> <p>Let \\(\\lim\\limits_{n \\to \\infty} (a_n)^\\frac1n = k\\)</p> \\(k\\) \\(&lt; 1\\) Converges \\(&gt; 1\\) Diverges \\(1\\) Test Fails"},{"location":"1_Core/Math_1/07_Infinite_Series/#limit-comparison-test","title":"Limit Comparison Test","text":"<p>Best used when \\(a_n\\) is a fraction of polynomial, ie \\(a_n = \\frac{P(n)}{Q(n)}\\), where \\(P, Q\\) are polynomials in terms of \\(n\\)</p> <p>Let</p> <ul> <li> <p>\\(\\sum a_n\\) be a series of +ve terms</p> </li> <li> <p>\\(\\sum b_n\\) be a known series (we know if it converges/diverges)</p> <ul> <li> <p>We choose \\(b_n = \\dfrac{1}{n^{q-p}}\\), where</p> </li> <li> <p>P = degree of numerator</p> </li> <li> <p>Q = degree of denominator</p> </li> <li> <p>If \\(b_n\\) is a p-series of the form \\(\\sum \\dfrac{1}{n^p}\\) |   \\(p\\)   |           | | :-----: | :-------: | |  \\(&gt; 1\\)  | converges | | \\(\\le 1\\) | diverges  |</p> </li> <li>\\(\\lim\\limits_{n \\to \\infty} \\frac{a_n}{b_n} = k\\)</li> </ul> </li> </ul> <p>Then</p> Given \\(k = c (\\ne 0)\\) both \\(\\sum a_n\\) and \\(\\sum b_n\\) converge \\(k = 0, \\sum b_n\\) converges \\(\\sum a_n\\) converges \\(k \\to \\infty, \\sum b_n\\) diverges \\(\\sum a_n\\) diverges"},{"location":"1_Core/Math_2/","title":"Math 2","text":"<p>This course is mainly about</p> <ul> <li>Matrix Operations</li> <li>Complex Numbers</li> <li>Complex Integrals</li> </ul>"},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/","title":"01 System of Linear Equations","text":""},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/#elementary-row-operations","title":"Elementary Row Operations","text":"\\[ A = \\begin{bmatrix} 1 &amp; 2 &amp; -1 \\\\ -9 &amp; 6 &amp; 4 \\\\7 &amp; 3 &amp; -1 \\end{bmatrix}_{3 \\times 3} \\] <ul> <li> <p>Any 2 rows can be interchanged</p> <p>\\(R_1 \\iff R_2\\) - Any row can be multiplied/divided by any number other than 0</p> <p>\\(R_1 \\to 2R_1\\) - Any row can be added/subtracted to any row</p> <p>\\(R_1 \\to R_1 \\pm 2 R_2\\)</p> </li> </ul>"},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/#ref","title":"REF","text":"<p>Reduced Echelon Form</p> <p>Upper \\(\\triangle\\)r matrix</p> <ul> <li> <p>1<sup>st</sup> non-zero elment in a row should be 1</p> <p>(called as leading one) - Leading one should occur to the right side of previous rows\u2019 leading one(s) - If there is any zero row, it should be the last row   otherwise, we need to interchange rows to ensure this rule</p> </li> </ul> <p>example</p> \\[ \\begin{bmatrix} 1 &amp; 4 &amp; 5 &amp; 3 \\\\ 0 &amp; 1 &amp; 2 &amp; 8 \\\\0 &amp; 0 &amp; 1 &amp; 5 \\end{bmatrix} \\quad \\begin{bmatrix} 1 &amp; 4 &amp; 3 &amp; 5 \\\\ 0 &amp; 1 &amp; 8 &amp; 2 \\\\0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\]"},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/#rref","title":"RREF","text":"<p>diagonal matrix</p> <p>is the REF matrix where the elements of the columns of the leading ones (other than itself) are 0.</p> \\[ \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 3\\\\ 0 &amp; 1 &amp; 0 &amp; 8\\\\0 &amp; 0 &amp; 1 &amp; 5 \\end{bmatrix} \\quad \\begin{bmatrix} 1 &amp; 0 &amp; 5 &amp; 0\\\\ 0 &amp; 1 &amp; 8 &amp; 0\\\\0 &amp; 0 &amp; 0 &amp; 1 \\end{bmatrix} \\]"},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/#rank","title":"Rank","text":"<p>no of non-zero rows of a matrix in REF/RREF</p>"},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/#gauss-methods","title":"Gauss Methods","text":"Method Form Gauss Elimination REF Gauss Jordan RREF <ol> <li>Write equation in matrix form \\(AX = B\\), where<ul> <li>\\(A\\) is coefficients matrix</li> <li>\\(B\\) is constant matrix</li> <li>\\(X\\) is variable matrix</li> </ul> </li> </ol> <p>Converted augmented matrix = \\([A | B]\\) into REF</p> <ol> <li> <p>Cases</p> <p>\\(n\\) is the number of unknown variables</p> </li> </ol> Rank(A\\vert B) \\(\\ne\\) rank(A) no solutions \\(=\\) rank(A) \\(= n\\) unique solutions \\(=\\) rank(A) \\(&lt; n\\) infinite solutions <ol> <li> <p>Back Substitution</p> <p>Degree of freedom = no of vars - no of equations</p> </li> </ol>"},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/#homogeneous-linear-system","title":"Homogeneous Linear System","text":"<p>There will always be a solution.</p> <p>If there is unique solution, it is always all 0s. This is called as trivial solution.</p>"},{"location":"1_Core/Math_2/01_System_of_Linear_Equations/#inverse-of-matrix","title":"Inverse of matrix","text":"<p>If \\(A\\) and \\(B\\) are 2 non-singular matrices such that \\(|A| \\ne 0\\), then \\(A^{-1} = B \\iff A\\cdot B = I\\)</p> <p>\\(I\\) is identity matrix</p> \\[ \\begin{aligned} I_{2 \\times 2} &amp;= \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{bmatrix} \\\\ I_{3 \\times 3} &amp;= \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\0 &amp; 0 &amp; 1 \\end{bmatrix} \\end{aligned} \\] <p>To find inverse</p> <ul> <li>use row transformations to convert \\([A:I] \\to [I:B]\\)</li> <li>then \\(B = A^{-1}\\)</li> </ul> <p>If \\(A\\) is singular, inverse does not exist</p>"},{"location":"1_Core/Math_2/02_Vector_Spaces/","title":"02 Vector Spaces","text":""},{"location":"1_Core/Math_2/02_Vector_Spaces/#set","title":"Set","text":"<p>collection of well-defined elements</p>"},{"location":"1_Core/Math_2/02_Vector_Spaces/#vector-space","title":"Vector Space","text":"<p>A non-empty set \\(V\\) with binary operations \\(\\oplus\\) and \\(\\odot\\), which satisfies the following rules</p> Law Closure Law wrt Addition \\(\\forall u,v \\in V, \\quad \\vec u \\oplus \\vec v \\in V\\) Commutative Law wrt Addition \\(\\vec u \\oplus v = \\vec v \\oplus u\\) Associative Law wrt Addition \\((\\vec u \\oplus \\vec v) \\oplus \\vec w = \\vec u \\oplus (\\vec v \\oplus \\vec w)\\) Existence of additive identity For \\(\\vec u \\in V\\), there exists \\(\\vec 0 \\in V\\) such that\\(\\vec 0 \\oplus \\vec u = \\vec u \\oplus \\vec 0 = \\vec u\\)\\(\\vec 0\\) is not necessarily \\((0, 0)\\) Existence of additive inverse For \\(\\vec u \\in V\\), there exists \\(-u \\in V\\) such that\\(\\vec u \\oplus (- \\vec u) =   (-\\vec u) \\oplus \\vec u = \\vec 0\\) Closure Law wrt multiplication For any scalar \\(\\alpha\\) (any real no) and \\(\\vec u \\in V\\)\\(\\alpha \\odot \\vec u \\in V\\) Distributive Law (Right-Side) For \\(u, v \\in V\\) and scalar \\(\\alpha\\)\\(\\alpha \\odot (\\vec u \\oplus \\vec v) = (\\alpha \\odot \\vec u) \\oplus (\\alpha \\odot \\vec v)\\) Distributive Law (Left-Side) For \\(u \\in V\\) and scalars \\(\\alpha, \\beta\\)\\((\\alpha + \\beta) \\odot \\vec u = (\\alpha \\odot \\vec u ) \\oplus (\\beta \\odot \\vec u)\\) Distributive Law (Variation) For \\(u \\in V\\) and scalars \\(\\alpha, \\beta\\)\\((\\alpha \\beta) \\odot \\vec u = \\alpha \\odot (\\beta \\odot \\vec u)\\) Existence of unity For \\(u \\in V\\)\\(1 \\odot \\vec u = \\vec u\\)"},{"location":"1_Core/Math_2/02_Vector_Spaces/#known-vector-spaces","title":"Known Vector Spaces","text":"<ul> <li>Real numbers</li> <li>\\(R_2, R_3, R_n\\)</li> <li>matrices</li> <li>polynomials<ul> <li>form \\(ax^n + bx^{n-1} + \\dots + \\alpha, \\quad a, b \\in R, \\quad n \\in Z\\)</li> <li>\\(P_n\\) means degree of the polynomial \\(\\le n\\)</li> </ul> </li> <li>continuous functions</li> </ul>"},{"location":"1_Core/Math_2/02_Vector_Spaces/#subspace","title":"Subspace","text":"<p>Let \\(S \\subset V\\) vector space. Then, \\(S\\) is a subspace if</p> <ol> <li>\\(\\vec 0 \\in S\\)</li> <li>\\(\\forall u, v \\in S, \\quad u \\oplus v \\in S\\)</li> <li>\\(\\forall u \\in S, \\quad \\alpha \\odot u \\in S\\)</li> </ol> <p>Trick to identify is if sum of powers of multiplicative terms is 1 For eg, \\(x^a y^b + w^c z^d\\) is subspace if \\(a + b= 1, c + d = 1\\)</p>"},{"location":"1_Core/Math_2/02_Vector_Spaces/#polynomial","title":"Polynomial","text":"<p>\\(P_n\\) is a polynomial where degree \\(\\le n\\)</p> <p>For eg, even \\((1 + x)\\) is \\(P_3\\), as degree \\(= 1 \\le 3\\)</p>"},{"location":"1_Core/Math_2/03_Linear-Dependence%2C_Span%2C_Basis/","title":"03 Linear Dependence, Span, Basis","text":""},{"location":"1_Core/Math_2/03_Linear-Dependence%2C_Span%2C_Basis/#linearly-dependentindependent","title":"Linearly-Dependent/Independent","text":"<p>Let \\(\\alpha_1 u_1 + \\alpha_2 u_2 + \\dots + \\alpha_n u_n = \\vec 0\\)</p> Condition Conclusion \\(\\alpha_1 = \\alpha_2 = \\alpha_3 = \\dots = 0\\) Independent else Dependent"},{"location":"1_Core/Math_2/03_Linear-Dependence%2C_Span%2C_Basis/#working","title":"Working","text":"<ol> <li> <p>Column-wise</p> </li> <li> Condition Solution Conclusion \\(r(A) = n\\) unique \\((0, 0, \\dots)\\) independent else infinitely-many dependent </li> </ol>"},{"location":"1_Core/Math_2/03_Linear-Dependence%2C_Span%2C_Basis/#span","title":"Span","text":"<p>Let \\(\\vec v = \\alpha_1 u_1 + \\alpha_2 u_2 + \\dots + \\alpha_n u_n\\)</p>"},{"location":"1_Core/Math_2/03_Linear-Dependence%2C_Span%2C_Basis/#working_1","title":"Working","text":"<ol> <li>Column-wise</li> <li> Condition Solution Conclusion \\(r(A) = r(A:B) = n\\) unique span \\(r(A) = r(A:B) &lt; n\\) infinite span else not span </li> </ol>"},{"location":"1_Core/Math_2/03_Linear-Dependence%2C_Span%2C_Basis/#basis","title":"Basis","text":"<ol> <li>\\(S\\) is Linearly-independent \u2013&gt; row-wise working</li> <li>\\(S\\) spans \\(V\\) \u2013&gt; dim(\\(V\\)) = no of vectors in \\(S\\)</li> </ol> <p>Note: \\(\\vec 0\\) has no basis</p>"},{"location":"1_Core/Math_2/03_Linear-Dependence%2C_Span%2C_Basis/#dimension","title":"Dimension","text":"<p>no of unknowns</p> <p>no of vectors in its basis</p> <p>dim \\((\\vec 0)= 0\\)</p>"},{"location":"1_Core/Math_2/04_Linear_Transformations/","title":"04 Linear Transformations","text":""},{"location":"1_Core/Math_2/04_Linear_Transformations/#linear-transformations","title":"Linear Transformations","text":"<p>Consider a linear transformation</p> \\[ L:  \\underbrace{U}_{\\text{Domain}} \\to \\underbrace{W}_{\\text{Codomain}} \\]"},{"location":"1_Core/Math_2/04_Linear_Transformations/#properies","title":"Properies","text":"<ol> <li>\\(L(O_u) = O_w\\)</li> <li>\\(L(\\vec u \\oplus \\vec v) = L(\\vec u) + L(\\vec v)\\)</li> <li>\\(L(\\alpha \\odot u) = \\alpha \\cdot L(\\vec u)\\)</li> </ol>"},{"location":"1_Core/Math_2/04_Linear_Transformations/#tricks","title":"Tricks","text":"<p>A transformation is not Linear Transformation if</p> <ul> <li>Power \\(\\ne\\) 1 or 0</li> <li>there is modulus(absolute value)</li> <li>determinant</li> </ul>"},{"location":"1_Core/Math_2/04_Linear_Transformations/#kernel","title":"Kernel","text":"\\[ S = \\set{ \\vec u: L(\\vec u) = O_w } \\] <p>Set of all input values</p>"},{"location":"1_Core/Math_2/04_Linear_Transformations/#range","title":"Range","text":"\\[ S = \\set{ L(\\vec u) } \\] <p>Set of all output values</p>"},{"location":"1_Core/Math_2/04_Linear_Transformations/#properties","title":"Properties","text":"Property Condition One-one Kernel = \\(\\set{O_u}\\) Onto dim(range) = dim(codomain)"},{"location":"1_Core/Math_2/04_Linear_Transformations/#dimension-theorem","title":"Dimension Theorem","text":"\\[ \\text{ dim(range) + dim(kernel) = dim(U) } \\]"},{"location":"1_Core/Math_2/05_Eigen_Values%2C_Vectors/","title":"05 Eigen Values, Vectors","text":""},{"location":"1_Core/Math_2/05_Eigen_Values%2C_Vectors/#eigen-values","title":"Eigen Values","text":"<p>are the values of \\(\\lambda\\) that satisfy equation</p> \\[ | A - \\lambda I | = 0 \\]"},{"location":"1_Core/Math_2/05_Eigen_Values%2C_Vectors/#properties","title":"Properties","text":"<ol> <li>Eigen values of upper/lower \\(\\triangle\\)r matrix = diagonal elements</li> <li>No of eigen values = order of A</li> <li>Sum of eigen values = Sum of diagonal elements</li> <li>Product of eigen values = \\(|A|\\)</li> <li>If eigen values of \\(A = \\lambda\\), then</li> </ol> Matrix Eigen Value \\(A^{-1}\\) \\(\\frac{1}{\\lambda}\\) \\(A^n\\) \\(\\lambda^n\\) \\(A^T\\) \\(\\lambda\\)"},{"location":"1_Core/Math_2/05_Eigen_Values%2C_Vectors/#eigen-vectors","title":"Eigen Vectors","text":"<p>are the values of \\(X\\) that satisfies equation</p> \\[ (A - \\lambda I) X = 0 \\] <p>Eigen vector(s) of \\(A\\) = eigen vector(s) of \\(A^{-1}, A^n, A^T\\)</p>"},{"location":"1_Core/Math_2/05_Eigen_Values%2C_Vectors/#working","title":"Working","text":"Scenario Method Repeating eigen values back substitution else Cramer\u2019s rule for 2 independent rows"},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/","title":"06 Intro to Complex Calculus","text":""},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/#complex-numbers","title":"Complex Numbers","text":"\\[ z = x + iy \\] <p>Make sure that all calculations are in radian</p>"},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/#properties","title":"Properties","text":"\\[ \\begin{aligned} |z| &amp;= \\sqrt{x^2 + y^2} \\\\ |z_1 \\cdot z_2| &amp;= |z_1| \\cdot |z_2| \\\\ \\left| \\frac{z_1}{z_2} \\right| &amp;= \\frac{ |z_1| }{ |z_2| } \\\\ \\bar z &amp;= x - iy \\\\ |\\bar z| &amp;= |z| \\\\ \\bar{ |z| }^2 &amp;= z \\cdot \\bar z \\\\ \\frac{z + \\bar z}{2} &amp;= \\text{Re}(z) \\\\ \\frac{z - \\bar z}{2i} &amp;= \\text{Im}(z) \\\\ \\overline{z_1 \\pm z_2} &amp;= \\bar z_1 \\pm \\bar z_2 \\\\ \\overline{z_1 \\cdot z_2} &amp;= \\bar z_1 \\cdot \\bar z_2 \\\\ \\overline{\\left( \\frac{z_1}{z_2} \\right)} &amp;= \\frac{\\bar z_1}{\\bar z_2} \\end{aligned} \\]"},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/#circles","title":"Circles","text":"\\(\\vert  z  \\vert = r\\) circle with radius \\(r\\) @ \\((0, 0)\\) \\(\\vert  z-z_0  \\vert = r\\) circle with radius \\(r\\) @ \\(z_0\\)"},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/#triangle-inequality","title":"Triangle Inequality","text":"Upper Bound Lower Bound \\(\\vert  z_1 \\pm z_2 \\vert  \\le \\vert  z_1 \\vert  + \\vert  z_2 \\vert\\) \\(\\vert  z_1 \\pm z_2 \\vert  \\ge \\text{abs} (\\vert  z_1 \\vert  - \\vert  z_2  \\vert )\\) <p>abs refers to absolute value</p>"},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/#argument","title":"Argument","text":"\\[ \\begin{aligned} \\text{arg } z &amp;= \\left| \\frac{y}{x} \\right| \\\\ \\text{Arg } z &amp;= \\text{Principle Value of arg } z\\\\ \\text{arg}(z_1 \\cdot z_2) &amp;= \\text{arg}(z_1) + \\text{arg}(z_2) \\\\ \\text{arg}\\left( \\frac{z_1}{z_2} \\right) &amp;= {\\text{arg}(z_1)} - {\\text{arg}(z_2)} \\end{aligned} \\]"},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/#polar-form","title":"Polar Form","text":"\\[ \\begin{aligned} z &amp;= r \\cdot e^{i \\theta} \\\\ &amp;= r (\\cos \\theta + i \\sin \\theta) \\end{aligned} \\]"},{"location":"1_Core/Math_2/06_Intro_to_Complex_Calculus/#root","title":"Root","text":"\\[ \\begin{aligned} c &amp;= (r \\cdot e^{i\\theta})^{\\frac{1}{n}} \\\\ &amp;= r^{\\frac{1}{n}} \\cdot e^{\\frac{i\\theta}{n}} \\\\ &amp;= r^{\\frac{1}{n}} \\Bigg(     \\cos \\left(\\frac{\\theta}{n}\\right) + i \\sin \\left(\\frac{\\theta}{n}\\right) \\Bigg) \\\\ r &amp;= |z| \\\\ \\frac{\\theta}{n} &amp;= \\frac{\\text{Arg }z + 2k\\pi}{n}, k \\in [0, n) \\\\ e^{i(n\\theta)} &amp;= \\cos(n\\theta) + i \\sin(n\\theta) \\\\ e^{-i(n\\theta)} &amp;= \\cos(n\\theta) - i \\sin(n\\theta) \\end{aligned} \\]"},{"location":"1_Core/Math_2/07_Complex_Regions/","title":"07 Complex Regions","text":""},{"location":"1_Core/Math_2/07_Complex_Regions/#connected-set","title":"Connected Set","text":"<p>A set where any 2 points can be joined without leaving the set</p> <p>Refer to Types of Sets</p> <ul> <li>open' = closed</li> <li>closed' = open</li> </ul>"},{"location":"1_Core/Math_2/07_Complex_Regions/#domain","title":"Domain","text":"<p>a set that is both open and connected.</p>"},{"location":"1_Core/Math_2/07_Complex_Regions/#limitaccumulation-point","title":"Limit/Accumulation Point","text":"<p>Deleted neighborhood of \\(z_0\\) contains atleast one point of \\(S\\)</p> <p>closed set has all limit points</p> <p>all interior points and boundary points are limit points</p>"},{"location":"1_Core/Math_2/07_Complex_Regions/#properties-of-functions","title":"Properties of Functions","text":""},{"location":"1_Core/Math_2/07_Complex_Regions/#differentiable","title":"Differentiable","text":"<p>Consider derivative equation</p> \\[ f'(z) = \\lim_{\\Delta z \\to 0} \\frac{ f(z + \\Delta z) - f(z) }{ \\Delta z } \\] <p>A function is said to differentiable if \\(f'(z)\\) is unique</p>"},{"location":"1_Core/Math_2/07_Complex_Regions/#analytic","title":"Analytic","text":"<p>Differentiable @ \\(z_0\\) and its neighborhood</p>"},{"location":"1_Core/Math_2/07_Complex_Regions/#entire","title":"Entire","text":"<p>Analytic Everywhere</p>"},{"location":"1_Core/Math_2/07_Complex_Regions/#harmonic","title":"Harmonic","text":"<p>\\(u\\) is harmonic if it satisfied Laplace equation, ie</p> \\[ u_{xx} + u_{yy} = 0 \\] <p>If \\(f(z) = u+iv\\), then</p> <ul> <li>\\(f(z)\\) is analytic<ul> <li>Put \\(y = 0, x = z \\to f(z) = f(x)\\) for shortcut</li> </ul> </li> <li>real and imaginary parts are harmonic</li> <li>\\(v\\) is harmonic conjugate of \\(u\\)</li> </ul>"},{"location":"1_Core/Math_2/07_Complex_Regions/#hyperbolic-function","title":"Hyperbolic Function","text":"\\[ \\begin{aligned} \\cos(ix) &amp;= \\cosh(x) &amp; \\sin(ix) &amp;= i \\sinh(x) \\\\ \\cosh(x) &amp;= \\frac{e^x + e^{-x}}{2} &amp; \\sinh(x) &amp;= \\frac{e^x - e^{-x}}{2} \\\\ \\sinh'(x) &amp;= \\cosh(x) &amp; \\cosh'(x) &amp;= \\sinh(x) \\end{aligned} \\] \\[ \\cosh^2(x) - \\sinh^2(x) = 1 \\]"},{"location":"1_Core/Math_2/07_Complex_Regions/#cr-equation","title":"CR Equation","text":"<p>Consider \\(f(z) = u + iv\\)</p> Rectangular Polar \\(u_x = v_y\\) \\(u_r = \\frac{1}{r} v_\\theta\\) \\(u_y = - v_x\\) \\(u_\\theta = -r v_r\\) Continuous \\(u_x, u_y, v_x, v_y\\) \\(u_r, u_\\theta, v_r, v_\\theta\\) \\(f'(z)\\) \\(u_x + i v_x\\) \\((u_r + i v_r) e^{-i \\theta}\\)"},{"location":"1_Core/Math_2/08_Elementary%2C_Exponential_Functions/","title":"08 Elementary, Exponential Functions","text":""},{"location":"1_Core/Math_2/08_Elementary%2C_Exponential_Functions/#ez","title":"\\(e^z\\)","text":"\\[ \\begin{aligned} |e^z| &amp;= e^x \\\\ e^{z + (2k \\pi) i} &amp;= e^z \\end{aligned} \\]"},{"location":"1_Core/Math_2/08_Elementary%2C_Exponential_Functions/#log-z","title":"\\(\\log z\\)","text":"\\[ \\begin{aligned} \\log z &amp;= \\ln r + i \\theta \\\\ &amp;= \\ln r + i[\\text{Arg}(z) + 2k\\pi] \\\\ \\text{Log} z &amp;= \\ln r + i[\\text{Arg}(z)] \\end{aligned} \\]"},{"location":"1_Core/Math_2/08_Elementary%2C_Exponential_Functions/#complex-exponents","title":"Complex Exponents","text":"\\[ \\begin{aligned} z &amp;= e^{\\log z} \\\\ z_c &amp;= e^{c \\log z} \\\\ PV(z^c) &amp;= e^{c \\text{ Log} z} \\end{aligned} \\]"},{"location":"1_Core/Math_2/09_Complex_Integrals/","title":"09 Complex Integrals","text":""},{"location":"1_Core/Math_2/09_Complex_Integrals/#line-integral","title":"Line Integral","text":"<p>For \\(\\int f(z) \\ dz\\), put \\(z = r \\cdot e^{i \\theta}\\)</p>"},{"location":"1_Core/Math_2/09_Complex_Integrals/#ml-inequality","title":"ML Inequality","text":"<p>maximum value / upper bound of integral</p> \\[ \\left| \\int_C f(z) \\ dz \\right| \\le M \\times L \\] <p>where</p> <ul> <li>\\(M =\\) max value of \\(f(z)\\)</li> <li>\\(L =\\) length of contour \\(C\\)</li> </ul>"},{"location":"1_Core/Math_2/09_Complex_Integrals/#theorems","title":"Theorems","text":"Theorem Cauchy-Goursat Cauchy-Integral Cauchy-Integral for derivatives Cauchy Residue Condition \\(f(z)\\) is analytic inside/on \\(C\\) - \\(f(z)\\) is analytic inside/on \\(C\\)- \\(z_0\\) is a point inside \\(C\\) - \\(f(z)\\) is analytic inside/on \\(C\\)- \\(z_0\\) is a point inside \\(C\\) Identity \\(\\int_C f(z) \\ dz = 0\\) \\(\\int_C \\frac{f(z)}{z-z_0} dz = 2 \\pi i \\cdot f(z_0)\\) \\(\\int_C \\frac{f(z)}{(z-z_0)^{n+1}} dz = \\frac{2 \\pi i}{n!} \\times f^{(n)}(z_0)\\) $\\int_C f(z)  dz = 2 \\pi i \\times \\ [\\text{Sum of residues at poles lying inside/on } C]$ add for multiple points \u274c \u2705 \u2705 Theorem Condition Identity add for multiple points Cauchy-Goursat \\(f(z)\\) is analytic inside/on \\(C\\) \\(\\int_C f(z) \\ dz = 0\\) \u274c Cauchy-Integral - \\(f(z)\\) is analytic inside/on \\(C\\)- \\(z_0\\) is a point inside \\(C\\) \\(\\int_C \\frac{f(z)}{z-z_0} dz = 2 \\pi i \\cdot f(z_0)\\) \u2705 Cauchy-Integral for derivatives - \\(f(z)\\) is analytic inside/on \\(C\\)- \\(z_0\\) is a point inside \\(C\\) \\(\\int_C \\frac{f(z)}{(z-z_0)^{n+1}} dz = \\frac{2 \\pi i}{n!} \\times f^{(n)}(z_0)\\) \u2705 Cauchy Residue \\(\\int_C f(z) \\ dz = 2 \\pi i \\times (\\sum R)\\) \u274c <p>\\(\\sum R =\\) Sum of residues at poles lying inside/on \\(C\\)</p>"},{"location":"1_Core/Math_2/09_Complex_Integrals/#residue","title":"Residue","text":"Type \\(R\\) Simple Pole \\(\\lim_{z \\to z_0} (z-z_0) f(z)\\) Pole of order \\(m\\) \\(\\dfrac{1}{m-1} \\times \\dfrac{d^{m-1}}{dz^{m-1}} [(z-z_0)^m f(z)]_{z = z_0}\\) \\(\\dfrac{P(z_0)}{\\textcolor{orange}{Q}(z_0)}, P(z_0) \\ne 0, Q(z_0) = 0\\) \\(\\dfrac{P(z_0)}{\\textcolor{orange}{Q'}(z_0)}\\)"},{"location":"1_Core/Math_2/09_Complex_Integrals/#laurents-series","title":"Laurent\u2019s Series","text":"\\[ \\begin{aligned} f(z) &amp;= \\sum_0^\\infty a_n (z-z_0)^n + \\underbrace{     \\sum_1^\\infty \\frac{b_n}{(z - z_0)^n} }_\\text{Principal Part} \\\\ a_n &amp;= \\frac{1}{2 \\pi i} \\times \\int \\frac{f(z)}{(z-z_0)^{     \\textcolor{orange}{n}+1 }} \\\\ b_n &amp;= \\frac{1}{2 \\pi i} \\times \\int \\frac{f(z)}{(z-z_0)^{     \\textcolor{orange}{-n}+1 }}  \\end{aligned} \\] <p>The following equation is only valid if \\(0 &lt; |z| &lt; 1\\)</p> \\[ \\begin{aligned} (1+z)^{-1} &amp;= 1 - z + z^2 - z^3 + \\dots \\\\ (1-z)^{-1} &amp;= 1 + z + z^2 + z^3 + \\dots \\\\(1+z)^{-2} &amp;= 1 - 2z + 3z^2 - 4z^3 + \\dots \\\\(1-z)^{-2} &amp;= 1 + 2z + 3z^2 + 4z^3 + \\dots \\end{aligned} \\]"},{"location":"1_Core/Math_2/09_Complex_Integrals/#singular-points","title":"Singular Points","text":"<p>Take all \\(n\\) points \\((\\pm n\\pi, \\pm 2n\\pi, \\dots)\\)</p>"},{"location":"1_Core/Math_2/09_Complex_Integrals/#isolated-point","title":"Isolated Point","text":"<p>No other singular point in close neighborhood</p>"},{"location":"1_Core/Math_2/09_Complex_Integrals/#poles","title":"Poles","text":"<p>isolated points are poles too</p> <p>poles of order \\(m=1\\) are simple poles</p>"},{"location":"1_Core/Physics_Lab/","title":"Lab","text":"<p>Here is the demonstration of every experiment in the physics lab. </p> <ol> <li>Collisions - I</li> <li>Collisions - II</li> <li>Collisions - III</li> <li>Atwood's Machine</li> <li>Diffraction for Single Slit</li> <li>Diffraction for Double Slit</li> <li>Conservation of Energy</li> <li>Fine Strucutre</li> <li>Friction</li> <li>Photoelectric Effect</li> <li>Rotational Inertia</li> <li>Vibration</li> </ol>"},{"location":"1_Core/Probability_%26_Statistics/","title":"Probability &amp; Statistics","text":"<p>This is an introductory course into Probability, Distributions, and Statistics</p>"},{"location":"1_Core/Probability_%26_Statistics/#references","title":"References","text":"<ul> <li> Statistics Review | Chris Mack | University of Texas</li> <li> MIT RES.6-012 Introduction to Probability</li> <li> 6.041 Probabilistic Systems Analysis and Applied Probability</li> <li> MIT 18.650 Statistics for Applications, Fall 2016</li> <li> Stanford CS109 Introduction to Probability for Computer Scientists</li> <li> A Student's Guide to Bayesian Statistics | Ben Lambert</li> <li> Bayesian Statistics | Ben Lambert | Oxford</li> <li> Statistics Courses | Penn State University</li> <li> Nonparametric Statistics | FourthZ</li> <li> Bayesian Statistics | Jingchen Monika Hu</li> <li> Statistical Testing and Experiments | Applied AI Course</li> <li> Statistics as a Career | University of Nebraska-Lincoln</li> <li> Bootstrap Methods and Their Application | Chris Bilder</li> <li> Computational Statistics | Chris Bilder</li> <li> Mathematical Statistics | Chris Bilder</li> <li> Extreme Value Statistics</li> <li> Probability &amp; Measure | Cache Lack Math &amp; Stats Lectures</li> <li> Extreme Value Theory | Zak Varty</li> <li> Statistical Inference | Brian Caffo</li> <li> Math Biostat Boot Camp 1 | Brian Caffo</li> <li> Math Biostat Boot Camp 2 | Brian Caffo</li> <li> Statistics | Christian M\u00f8ller Pedersen</li> <li> STATS 203 - Large Sample Theory (Fall 2020) | JSB UCLA</li> <li> Introductory Statistics | Amelia McNamara</li> <li> Statistics Fundamentals | StatQuest</li> <li> The Metalog Distributions</li> <li> Rare event estimation | Patrick Laub</li> <li> Algorithms for Rare event simulation | Patrick Laub</li> <li> Bayesian Stats | Frank Edwards</li> <li> Probability and Statistics | University of Utah</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/01_Intro/","title":"Introduction","text":""},{"location":"1_Core/Probability_%26_Statistics/01_Intro/#goals","title":"Goals","text":"<ol> <li>Summary statistics: Describe/summarize a large set of data with a few \u2018statistics\u2019</li> <li>Statistical inference: Use sample data to infer population characteristics</li> </ol>"},{"location":"1_Core/Probability_%26_Statistics/01_Intro/#probability-vs-statistics","title":"Probability vs Statistics","text":"<ul> <li>Probability: Predict behavior of sample given known knowledge of population</li> <li>Statistics: Infer properties of population given knowledge of sample</li> </ul> <p>The two are tied together by sampling distribution</p>"},{"location":"1_Core/Probability_%26_Statistics/01_Intro/#approaches","title":"Approaches","text":"Frequentist Bayesian Probability Limiting case of repeated measurements Subjective, based degree of certainty in the event Data Random variable Constant Model parameters Unknown constant Unknown random variable Basis Weak law of large numbersAssumes IID Limitations Not optimal for rare events Intervals Confidence IntervalsWith large number of repeated samples, \\(\\alpha \\%\\) of such calculated confidence intervals would include the true value of the parameter Credible IntervalsEstimated parameter has a \\(95 \\%\\) probability of falling within the given interval Statistics Use prior belief to systematically update knowledge after experiment, through Bayes theorem"},{"location":"1_Core/Probability_%26_Statistics/01_Intro/#formulae","title":"Formulae","text":"\\[ \\begin{aligned} P(S) &amp;=1 \\\\ 0 \\le P(A) &amp;\\le 1 \\\\ P(A') &amp;= 1 - P(A) \\\\ P(A \\cup B) &amp;= P(A) + P(B) - P(A \\cap B) \\\\ P(A \\cup B \\cup C) &amp;= P(A) + P(B) + P(C) - P(A \\cap B) - P(B \\cap C) - P(A \\cap C) + P(A \\cap B \\cap C) \\\\ P(A \\cap B') &amp;= P(A) - P(A \\cap B) \\\\ &amp;= P(A \\cup B) - P(B) \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/01_Intro/#cases","title":"Cases","text":"Case Property Mutually-Exclusive \\(P(A \\cap B) = 0\\) Mutually-Exhaustive \\(P(A \\cup B) = 1\\) Independent \\(P(A \\cap B) = P(A) \\cdot P(B)\\) <p>2 events are independent if one event does not affect the occurance of the other</p>"},{"location":"1_Core/Probability_%26_Statistics/01_Intro/#no-of-ways","title":"No of ways","text":"When to use No of ways of selection Product Rule there are \\(k\\) elements, and each have different ways of selection \\(n_1 \\times n_2 \\times \\dots \\times n_k\\) Permutation some sort of ordering \\(nP_r = \\frac{n!}{(n-r)!}\\) Combination \\(nP_r = \\frac{n!}{r!(n-r)!}\\) Indistinguishable Objects there are \\(k\\) objects, such that \\(x_1 + x_2 + \\dots + x_k = n\\), where \\(x_1, x_2, \\dots\\) are the no of elements of that type \\(\\frac{n!}{x_1 ! \\times x_2 ! \\times \\dots \\times x_k !}\\)"},{"location":"1_Core/Probability_%26_Statistics/01_Intro/#conditional-probability","title":"Conditional Probability","text":"<p>Probability of A given B is the probability of A occuring given that A has already occured</p> \\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\quad P(B) \\ne 0 \\]"},{"location":"1_Core/Probability_%26_Statistics/02_Bayes_Theorem/","title":"02 Bayes Theorem","text":""},{"location":"1_Core/Probability_%26_Statistics/02_Bayes_Theorem/#bayes-theorem","title":"Bayes\u2019 Theorem","text":"<p>It determines the probability of an event with uncertain knowledge.  </p> \\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\] <p>where - \\(P(A|B)\\) = posterior, - \\(P(B|A)\\) = likelihood, - \\(P(A)\\) = prior probability - \\(P(B)\\) = marginal probability </p>"},{"location":"1_Core/Probability_%26_Statistics/02_Bayes_Theorem/#general-formula","title":"General Formula","text":"\\[ \\begin{aligned} P(A_i|B) &amp;= \\frac{P(A_i \\land B)}{P(B)} \\\\ &amp;= \\frac{P(B | A_i) \\cdot P(A_i)}{\\sum\\limits_{j=1}^{n} P(B|A_j) \\cdot P(A_j)} \\\\ \\end{aligned} \\] <p>where \\(A_1, A_2, \\dots, A_n\\) are all mutually exclusive events</p>"},{"location":"1_Core/Probability_%26_Statistics/02_Bayes_Theorem/#conditions","title":"Conditions","text":"<ol> <li>Events must be disjoint (no overlapping)</li> <li>Events must be exhaustive: they combine to include all possibilities</li> </ol>"},{"location":"1_Core/Probability_%26_Statistics/02_Bayes_Theorem/#phrases","title":"Phrases","text":"<ul> <li>\u201cout of\u201d</li> <li>\u201cof those who\u201d</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/02_Bayes_Theorem/#_1","title":"02 Bayes Theorem","text":""},{"location":"1_Core/Probability_%26_Statistics/02_Random_Variables/","title":"Random Variables","text":""},{"location":"1_Core/Probability_%26_Statistics/02_Random_Variables/#types-of-random-numbers","title":"Types of Random Numbers","text":"Can be produced by computers Easy to implement Truly Random \u274c Quasi-Random \u2705 \u274c Pseudo-Random \u2705 \u2705"},{"location":"1_Core/Probability_%26_Statistics/02_Random_Variables/#random-distribution-functions","title":"Random Distribution Functions","text":"PDF Probability Density Function CDF Cumulative Density Function"},{"location":"1_Core/Probability_%26_Statistics/02_Random_Variables/#central-limit-theorem","title":"Central Limit Theorem","text":"<p>PDF of sample mean with sample size \\(n&gt;30\\) tends to normal distribution, regardless of what the underlying distribution is</p> \\[ \\bar x \\sim N \\left(\\mu, \\frac{\\sigma^2}{n} \\right) \\] <p>Interpretation: Given a sufficiently large sample</p> <ol> <li>Mean of sample means \\(\\approx\\) normal-distribution</li> <li>Mean of sample means \\(\\approx\\) population mean</li> <li>Variance of sample means \\(\\approx\\) Population Variance/Sample Size</li> </ol>"},{"location":"1_Core/Probability_%26_Statistics/02_Random_Variables/#moment-generating-function","title":"Moment-Generating Function","text":"<p>For a random variable \\(x\\) $$ \\begin{aligned} M_x(t) &amp;= E[ e^{tx} ] \\ \\implies \\underbrace{\\dfrac{d^{(k)} M_x}{dt^{(k)}} (0)}{\\text{k th derivative } } &amp;= \\underbrace{E(x^k)} \\ \\implies M_x(t) &amp;= \\sum_{k=0}^\\infty \\dfrac{t^k}{k!} m_k, &amp; m_k = E(x^k) \\ t &amp;\\in R, k \\in Z \\end{aligned} $$ Note: Does not exist for all distributions (for eg: Log-Normal) $$ \\begin{aligned} x, y \\text{ have same dist} &amp;\\iff M_x(t) = M_y(t) \\ x, y \\text{ have same dist} &amp;\\implies {m_k}_x = {m_k}_y &amp; \\text{(Converse not necessarily true)} \\end{aligned} $$ For a sequence of random variables $x_1, x_2, \\dots, $}</p> \\[ M_{X_i}(t) \\to M_X(t) \\implies P(X_i \\le x) \\to P(X \\le x) \\]"},{"location":"1_Core/Probability_%26_Statistics/02_Random_Variables/#large-of-large-numbers","title":"Large of Large Numbers","text":"<p>Consider iid rv \\(x_1, \\dots, x_n\\) with mean and variance \\(\\mu, \\sigma^2\\) $$ x = \\dfrac{\\sum x_i}{n} , n \\to \\infty \\implies E(x) \\to \\mu_x $$</p> <ul> <li>This is how casinos\u2019 make money for blackjack, as they have a higher expected value compared to the player</li> <li>But does not apply for Poker, as the casino makes money from round fees, since Poker is played against players, not the casino</li> </ul> \\[ P(\\vert X-\\mu \\vert \\ge \\epsilon) \\le \\dfrac{\\sigma^2}{n \\epsilon^2} \\]"},{"location":"1_Core/Probability_%26_Statistics/02_Random_Variables/#averaging-distributions","title":"Averaging Distributions","text":"<p>Given \\(n\\) identically-distributed RVs with variance \\(\\sigma^2\\) and correlation \\(\\rho\\), the variance of the mean is $$ {\\sigma^2}' = \\rho \\sigma^2 + (1 - \\rho)\\dfrac{\\sigma^2}{n} $$</p>"},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/","title":"03 Discrete Random Variables","text":""},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/#discrete-random-variables","title":"Discrete Random Variables","text":"<p>takes finite/countably-infinite no of values</p>"},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/#pdf","title":"PDF","text":"\\[ \\begin{aligned} f(x) &amp;= P(X = x) \\\\ f(x) &amp;\\ge 0 \\\\ \\sum f(x) &amp;= 1 \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/#cdf","title":"CDF","text":"\\[ \\begin{aligned} F(x) &amp;= P(X \\le x) \\\\ &amp;= \\sum\\limits_0^x f(x) \\\\ P(a \\le X \\le b) &amp;= \\sum\\limits_a^b f(x) \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/#terms","title":"Terms","text":"Notation Formula \\(E(x)\\) \\(\\mu\\) \\(\\sum x \\cdot f(x)\\) \\(E(x^2)\\) \\(\\sum x^2 \\cdot f(x)\\) \\(V(x)\\) \\(\\sigma^2\\) \\(E(x^2) - [E(x)]^2\\) \\(\\text{SD}(x)\\) \\(\\sigma\\) \\(\\sqrt {V(x)}\\) Normalised Variable \\(z\\) \\(\\dfrac{x - E(x)}{\\text{SD}}\\) \\[ \\begin{aligned} E(k) &amp;= k &amp; E(kx) &amp;= k \\cdot E(x) &amp; E(z) &amp;= 0\\\\ V(k) &amp;= 0 &amp; V(kx) &amp;= k^2 \\cdot V(x) &amp; V(z) &amp;= 1 \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/#distributions","title":"Distributions","text":"Distribution Comment Application Assumptions \\(f(x)\\) \\(\\mu\\) \\(\\sigma^2\\) Bernoulli - 2 outcomes Independent &amp; identical trial \\(p\\) \\(p(1-p)\\) Binomial \\(n\\) indepedent Bernoulli events w/ replacement Coin flips Independent &amp; identical trials \\(nC_x \\cdot p^x \\cdot (1-p)^{n-x}\\) \\(np\\) \\(np(1-p)\\) Hypergeometric \\(n\\) dependent Bernoulli trials without replacement \\(f(x) = \\frac{MC_x \\times (N-M) C_{(n-x)} }{NC_n}\\) \\(\\text{max}\\Big(0, n- (N-m) \\Big) \\le x \\le \\text{min}(n, M)\\) \\(n \\left(\\dfrac M N \\right)\\) \\(\\left( \\dfrac{N-n}{N-1} \\right) \\cdot n \\cdot \\dfrac M N \\left( 1 - \\dfrac M N \\right)\\) Geometric Negative binomial dist with \\(r=1\\)No of failures before first success Negative Binomial 'Rare' discrete phenomenon in continuous interval Counts, RatesRisk Follows Poisson Process \\(f_x(x) = \\begin{cases} \\begin{pmatrix} x-1\\\\ r-1 \\end{pmatrix} p^r q^{x-r}, &amp; x= r, r+1, \\dots  \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(\\dfrac{rq}{p}\\) \\(\\dfrac{rq}{p^2}\\)\\(\\mu + \\dfrac{\\mu^2}{k}\\) Poisson Negative Binomial with:variance = mean = constantPoisson approximates Binomial when- \\(p \\to 0\\)- \\(n \\to \\infty\\) Counts, RatesRisk Follows Poisson Process \\(\\dfrac {e^{-\\mu} \\times \\mu^x}{x!}\\) \\(\\lambda = \\alpha t\\) \\(\\mu\\)"},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/#rate-parameter-alpha","title":"Rate Parameter \\((\\alpha)\\)","text":"<p>Occurences per unit interval</p> <p>\\(\\alpha = \\dfrac 1 \\beta\\)</p> <p>(\\(\\beta\\) will be discussed in next topic)</p>"},{"location":"1_Core/Probability_%26_Statistics/03_Discrete_Random_Variables/#poisson-process","title":"Poisson Process","text":"<ul> <li>Average time between events \\(\\lambda\\) is constant</li> <li>Average time between events \\(\\lambda\\) is known</li> <li>Rate of occurrence \\(\\alpha\\) is constant<ul> <li>Probability of \\(k\\) arrivals in an interval is constant</li> </ul> </li> <li>Occurence of events are independent of each other</li> <li>Memory-less process<ul> <li>\\(f(x \\vert T \\le t + \\Delta t)\\) is independent of \\(f(x \\vert T \\le t)\\)</li> </ul> </li> <li>Events cannot occur simultaneously; there is at least a tiny interval between events</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/04_Continuous_Random_Variables/","title":"Continuous Random Variable","text":"<p>takes value on a continuum of scale, ie, can take any decimal value</p>"},{"location":"1_Core/Probability_%26_Statistics/04_Continuous_Random_Variables/#pdf","title":"PDF","text":"\\[ \\begin{aligned} f(x) &amp;\\ge 0 \\\\ \\int f(x) \\ \\mathrm{d} x &amp;= 1 \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/04_Continuous_Random_Variables/#cdf","title":"CDF","text":"\\[ \\begin{aligned} F(x) &amp;= P(X \\le x) \\\\ &amp;= \\int\\limits_{- \\infty}^x f(x) \\ \\mathrm{d} x \\\\ P(a \\le X \\le b) &amp;= P(a &lt; x &lt; b) \\\\ &amp;= \\int\\limits_a^b f(x) \\ \\mathrm{d} x \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/04_Continuous_Random_Variables/#terms","title":"Terms","text":"Formula \\(E(x)\\) \\(\\int x \\cdot f(x) \\ \\mathrm{d} x\\) \\(E(x^2)\\) \\(\\int x^2 \\cdot f(x) \\ \\mathrm{d} x\\) <p>(others are the same as discrete)</p>"},{"location":"1_Core/Probability_%26_Statistics/04_Continuous_Random_Variables/#distributions","title":"Distributions","text":"Distribution Comment Application Assumption \\(f(x)\\) Mean\\(\\mu\\) Variance\\(\\sigma^2(x)\\) Median Mode Skewness Kurtosis Symmetry Diagram Uniform \\(\\begin{cases} \\frac 1 {B-A} &amp; A \\le x \\le B \\\\ 0 &amp; \\text{elsewhere} \\end{cases}\\) \\(\\dfrac {B+A} 2\\) \\(\\dfrac 1 {12} (B-A)^2\\) \u2705 Normal/Gaussian/Bell-Curve/\\(z\\) \\(\\dfrac {1}{\\sigma \\sqrt{2\\pi}} \\exp \\left\\{ \\dfrac {-1}{2} \\left(\\dfrac{x-\\mu}{\\sigma} \\right)^2 \\right\\}\\) \\(\\begin{aligned} P(x&lt;k) &amp;= P \\left(z&lt;\\frac{k-\\mu}{\\text{SD}} \\right) \\\\ P(x&gt;k) &amp;= P(x &lt; -k) \\end{aligned}\\) \\(\\mu\\)Standard: 0 \\(\\sigma^2\\)Standard: 1 \\(\\mu\\) \\(\\mu\\) 0 3 \u2705 Gumbel/Type 1 Extreme Value Normal distribution with skew and fatter tails \\(\\exp \\Bigg[ - \\exp \\left( \\dfrac{-(x-\\mu)}{\\sigma} \\right ) \\Bigg]\\) \\(\\mu + \\sigma \\gamma_e\\)\\(\\gamma_e \\approx 0.577\\) (Euler\u2019s constant) \\(\\dfrac{\\pi^2 \\sigma^2}{6}\\) Log-Normal Log of distribution is NormalType of gumbel distribution? \\(\\log_b f \\sim N(\\mu, \\sigma^2)\\)\\(\\ln f \\sim N(\\mu, \\sigma^2)\\) \\(b ^ {\\{\\mu + \\sigma^2/2 \\}}\\)\\(\\exp \\{\\mu + \\sigma^2/2 \\}\\) \\((b^{\\sigma^2} - 1) b ^{\\{ 2 \\mu + \\sigma^2 \\}}\\)\\((\\exp \\{\\sigma^2\\} - 1) \\exp \\{ 2 \\mu + \\sigma^2 \\}\\) \\(b^\\mu\\)\\(e^\\mu\\) \\(b^{\\{\\mu - \\sigma^2 \\}}\\)\\(\\exp \\{\\mu - \\sigma^2 \\}\\) Student\\(t\\) Tends to normal distribution for large dof \\(\\dfrac{\\bar x-\\mu}{s/\\sqrt{n}}\\) 0 &gt;1 \u2705 Binomial \\(\\to\\) Normal Approx \\(np \\ge 10\\) or \\(n(1-p) \\ge 10\\) Normal distribution \\(\\begin{aligned} x' &amp;= x \\pm 0.5 \\\\ z &amp;= \\frac{x' - \\mu}{\\text{SD}} \\end{aligned}\\) \\(np\\) \\(np(1-p)\\) Gamma PDF of \\(\\sum \\limits_i N_i(0, \\sigma_i^2)\\), where \\(N_i\\) is independent of \\(N_j, \\ \\forall i \\ne j\\) Time between \\(n\\) occurrences of event Follows Poisson Process \\(\\dfrac{1}{B^\\alpha \\lceil\\alpha} \\cdot x^{\\alpha-1} \\cdot \\exp \\left(\\dfrac{-x}{\\beta} \\right)\\) \\(\\alpha \\beta\\) \\(\\alpha \\beta^2\\) Chi-Square\\(\\chi^2\\) Gamma with \\(\\sigma_i^2=1, \\forall i\\) \\(\\dfrac{(n-k)s^2}{\\sigma^2}\\)\\(\\lambda = \\sum_{i=1}^n \\mu_i^2\\) \\((n-k)+\\lambda\\) \\(2[(n-k) + 2 \\lambda]\\) Exponential Gamma with- \\(n=1\\)- Shape = 1- Scale \\(=\\dfrac{1}{\\lambda}\\) Time between successive/consecutive occurrences of event Follows Poisson Process \\(\\lambda \\cdot \\exp(-\\lambda x)\\) \\(\\dfrac 1 \\lambda  = \\beta\\) \\(\\dfrac 1 {\\lambda^2} = \\beta^2\\) Power Law \\(L(x) \\cdot x^{-(\\alpha-1)}; x &gt; x_\\min\\) Pareto Power law with \\(\\alpha =1.16\\)Average value of those whose value is greater than \\(y\\) is \\(y\\) times the constant \\(\\lambda/(\\lambda-1)\\)\\(\\lambda\\) controls the thickness of tail Size distributionSizes of citiesIncomeFamily namesPopularitySocial network patternsCrime per convictSizes of large earthquakesPower outages \\(P(X &gt; x) = \\begin{cases} (x_m/x)^\\lambda, &amp; x \\ge x_m \\\\ 1, &amp; x &lt; x_m \\end{cases}\\)Top \\(q\\)th percentiles share = \\((q/100)^{(\\lambda-1)/\\lambda}\\) \\(1 - F(x) = \\bar F(x) = P(X&gt;x)\\) Zipf Pareto with \\(\\lambda=1\\) Empirical city sizeFirm sizeEquivalent to relationship of slope of -1 between log rank of city (based on city size) and log of population Laplacian/Double-Exponential Distribution of diff of two iid exponential vars \\(\\dfrac{1}{2b} \\exp \\left( \\dfrac{- \\vert x-\\mu \\vert}{b} \\right)\\) Logistic/Sigmoid \\(\\dfrac{1}{b} \\times \\dfrac{\\exp \\left(\\dfrac{-(x-\\mu)}{b} \\right)}{1+\\exp \\left(\\dfrac{- (x-\\mu )}{b} \\right)}\\) \\(F(x) = \\dfrac{1}{1+\\exp \\left(\\dfrac{-(x-\\mu)}{b} \\right)}\\) \\(0\\) \\(b\\dfrac{\\pi}{\\sqrt{3}}\\) \\(3+1.2\\) Tweedie <ul> <li>DOF = Degrees of freedom</li> <li>\\(n\\) for sampling</li> <li>\\(n-k-1\\) for regression</li> <li>\\(\\lambda\\) = mean no of occurances per unit time   \\(\\lambda = \\alpha\\text{(poisson)}\\)</li> <li>\\(\\beta\\) = mean time b/w occurances   \\(\\beta = \\frac 1 \\lambda = \\frac 1 {\\alpha\\text{(poisson)}}\\)</li> <li>\\(\\alpha\\) = shape parameter   it is the average number of occurrences of an event</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/04_Continuous_Random_Variables/#delta-approach","title":"Delta Approach","text":"\\[ \\begin{aligned} \\dfrac{\\hat x - x}{\\widehat {\\text{SE}}(\\hat x)} \\sim N(0, \\sigma^2) \\\\ \\implies \\dfrac{g(\\hat x) - g(x)}{g'(\\hat x) \\cdot \\widehat {\\text{SE}} (\\hat x)} \\sim N(0, \\sigma^2) \\end{aligned} \\] <p>If \\(x \\sim N(0, \\sigma^2)\\) and \\(\\tilde x = g(x)\\), then \\(\\sigma^2(\\tilde x) = \\Big( g'(x) \\Big)^2 \\sigma^2(x)\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/05_Joint_Distributions/","title":"05 Joint Distributions","text":"\\[ \\begin{aligned} f(x, y) &amp;= P(X=x, Y=y) \\\\ &amp;= P(x \\cap y) \\\\ F(x,y) &amp;= P(X \\le x, Y \\le y) \\\\ f(x, y) &amp;\\ge 0 \\\\ f(x|y) &amp;= \\frac{f(x, y)}{f(y)} \\end{aligned} \\] Discrete Continuous PDF \\(\\sum\\limits_x \\sum\\limits_y f(x, y) = 1\\) \\(\\int\\limits_x \\int\\limits_y f(x, y) \\ \\mathrm{d} y \\mathrm{d} x = 1\\) CDF \\(\\sum\\limits_0^x \\sum\\limits_0^y f(x, y)\\) \\(\\int\\limits_{- \\infty}^x \\int\\limits_{- \\infty}^y f(x, y) \\ \\mathrm{d} y \\mathrm{d} x\\) \\(f(x)\\) \\(\\sum\\limits_y f(x,y)\\) \\(f(x) = \\int\\limits_y f(x,y) \\ \\mathrm{d} y \\mathrm{d} x\\) \\(f(y)\\) \\(\\sum\\limits_x f(x,y)\\) \\(\\int\\limits_x f(x,y) \\ \\mathrm{d} y \\mathrm{d} x\\) \\(E(x, y)\\) \\(\\sum\\limits_x \\sum\\limits_y xy \\cdot f(x, y)\\) \\(\\int\\limits_x \\int\\limits_y xy \\cdot f(x, y) \\ \\mathrm{d} y \\mathrm{d} x\\) \\(E(x)\\) \\(\\sum\\limits_x x \\cdot f(x,y)\\) \\(\\int\\limits_x x \\cdot f(x,y) \\ \\mathrm{d} y \\mathrm{d} x\\) \\(E(y)\\) \\(\\sum\\limits_y y \\cdot f(x,y)\\) \\(\\int\\limits_y y \\cdot f(x,y) \\ \\mathrm{d} y \\mathrm{d} x\\)"},{"location":"1_Core/Probability_%26_Statistics/05_Joint_Distributions/#covariance","title":"Covariance","text":"\\[ \\begin{aligned} \\text{Cov} (x,y) &amp;= E(x,y) - E(x) \\cdot E(y) \\\\ &amp;=  \\begin{cases} &gt;0 &amp; \\text{directly-dependent} \\\\ 0 &amp; \\text{independent}\\\\&lt;0 &amp; \\text{inversely-dependent} \\end{cases} \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/05_Joint_Distributions/#independence","title":"Independence","text":"\\[ \\begin{aligned} f(x,y) &amp;= f(x) \\cdot f(y) \\\\ E(x, y) &amp;= E(x) \\cdot E(y) \\\\ \\text{Cov}(x,y) &amp;= 0 \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/","title":"Sampling","text":"<p>Used when it is not feasible to analyze the entire population</p> <p>Estimation: Using the sample to estimate population parameter(s)</p>"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#population-v-sample","title":"Population v Sample","text":"Property Population Sample Definition comprises of all units pertaining to a particular characteristic under study is a part of a population, which is selected such that it is representative of the entire population Size \\(N\\) \\(n\\) Mean \\(\\mu\\) \\(\\bar x = \\dfrac {\\sum_i^n x_i}{n}\\) Variance \\(\\sigma^2\\) \\(s^2 = \\dfrac {\\sum_i^n (x_i-\\bar x)^2}{n \\textcolor{hotpink}{-1}}\\) Standard Deviation \\(\\sigma\\) \\(s\\)"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#relations","title":"Relations","text":"\\[ \\begin{aligned} \\mathbb E(\\bar x) &amp;= \\mu \\\\ \\mathbb E[s^2_x] &amp;= \\sigma^2_x \\\\ \\\\ s^2_{\\bar x} &amp;= \\frac{\\sigma^2_x}{n} , s_{\\bar x} = \\frac{\\sigma_x}{\\sqrt n} \\\\ z_\\text{sample} &amp;= \\frac{\\bar x - \\mu_x}{\\sigma_x/\\sqrt n } \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#bessels-correction","title":"Bessel\u2019s Correction","text":"<p>$$ \\begin{aligned} \\text{Var}(x) &amp;= E[(x)^2] - (E[x])^2 \\ \\implies E[(x)^2] &amp;= \\sigma^2 + \\mu^2 \\ \\ \\text{Var}(\\bar x) &amp;= E[(\\bar x)^2] - (E[\\bar x])^2 \\ \\implies E[(\\bar x)^2] &amp;= \\dfrac{\\sigma^2}{n} + \\mu^2 \\ \\ \\implies \\sigma^2 &amp;= s^2_\\text{uncorrected} + \\text{Bias} \\ &amp;= s^2_\\text{uncorrected} + \\dfrac{\\sigma^2}{n} \\</p> <p>\\implies \\sigma^2 &amp;= s^2_\\text{uncorrected} \\times \\dfrac{n}{\\text{DOF}} \\ &amp;= s^2_\\text{uncorrected} \\times \\underbrace{\\dfrac{n}{n-1} }_{\\mathclap{\\text{Bessel's Correction}}} \\end{aligned} $$</p> <p>Reasoning</p> <ul> <li>Degrees of freedom: We lose a degree of freedom when estimating \\(\\bar x\\)</li> <li>Bias correction: While sampling with small sample size, less probable elements don\u2019t show up which gives us an underestimated sample dispersion</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#sample-vs-population-standard-deviation","title":"Sample vs Population Standard Deviation","text":""},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#for-different-distributions","title":"For Different Distributions","text":"<p>Higher the skew of population distribution, larger the sample size required to approximate the sample size to the population</p>"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#for-the-different-population-size","title":"For the different population size","text":"<p>Sample vs Population SD does not depend on population size</p>"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#interval-estimation","title":"Interval Estimation","text":"<p>Confidence % \\(= 1- \\alpha\\)</p> <p>Most common is \\(95\\%\\) confidence interval estimate</p> \\[ \\begin{aligned} 1 - \\alpha &amp;= 0.95 \\\\ \\alpha &amp;= 0.05 \\\\ \\alpha/\\small 2 &amp;= 0.025 \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#population-mean","title":"Population mean","text":"\\(\\sigma^2\\) \\(n\\) statistic \\(\\mu\\) known any \\(z = \\dfrac {\\bar x - \\mu}{\\sigma / \\sqrt n}\\) \\(\\bar x \\pm z_{\\alpha/\\small 2} \\cdot \\dfrac \\sigma {\\sqrt n}\\) unknown \\(&gt;30\\) \\(z = \\dfrac {\\bar x - \\mu}{s/ \\sqrt n}\\) \\(\\bar x \\pm z_{\\alpha/\\small 2} \\cdot \\dfrac s {\\sqrt n}\\) unknown \\(\\le 30\\) \\(t = \\dfrac {\\bar x - \\mu}{s / \\sqrt n}\\) \\(\\bar x \\pm t_{\\small n-1, \\alpha/\\small 2} \\cdot \\dfrac s {\\sqrt n} \\\\(n-1) \\to \\text{deg of freedom}\\) \\[ \\begin{aligned} n &amp;= \\left( \\frac{z_{\\alpha/\\small 2} \\cdot \\sigma}{w} \\right)^2 \\\\ &amp;= \\left( \\frac{z_{\\alpha/\\small 2} \\cdot s}{w} \\right)^2 \\end{aligned} \\] <p>where</p> <ul> <li>\\(n\\) is sample size</li> <li>\\(w\\) is distance from \\(\\mu\\) = \\(\\frac{\\text{interval width}}{2}\\)</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#proportion","title":"Proportion","text":"\\[ \\begin{aligned} p &amp;= \\hat p \\pm z_{\\alpha/\\small2} \\sqrt {\\frac{\\hat p \\hat q}{n}} \\\\ \\hat p &amp;= \\frac x n = \\frac{\\text{Favorable no of cases}}{\\text{Total no of cases}} \\\\ \\hat q &amp;= 1 - \\hat p \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#population-variance-sd","title":"Population Variance / SD","text":"\\[ \\begin{aligned} \\sigma^2 &amp;= \\left[ \\frac{(n-1)s^2}{\\chi^2_{(n-1), (\\alpha/\\small 2)}}, \\frac{(n-1)s^2}{\\chi^2_{(n-1), (1-\\alpha/\\small 2)}} \\right] \\\\ \\sigma &amp;= \\sqrt {\\sigma^2} \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#inequalities","title":"Inequalities","text":"<p>Let \\(x\\) be a random variable such that \\(x_i \\in [a, b]\\)</p> <p>Consider</p> <ul> <li>sample size \\(n\\)</li> <li>\\(\\epsilon &gt; 0\\)</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#hoeffdings-inequality","title":"Hoeffding\u2019s Inequality","text":"\\[ \\begin{aligned} P (\\vert \\hat \\mu \u2212 \\mu \\vert &gt; \\epsilon) &amp; \\le 2 \\exp \\left[ \\dfrac{-2 n \\epsilon^2}{(b-a)^2} \\right] \\\\ \\sum_{b}^B P (\\vert \\hat \\mu_b \u2212 \\mu_b \\vert &gt; \\epsilon) &amp; \\le 2 \\exp \\left[ \\dfrac{-2 n \\epsilon^2}{(b-a)^2} \\right] \\times B \\end{aligned} \\] <p>where</p> <ul> <li>\\(\\mu\\) is any parameter and \\(\\hat \\mu\\) is its estimate</li> <li>\\(n&gt;0\\)</li> <li>\\(\\epsilon &gt; 0\\)</li> <li>\\(B=\\) no of \u2018bins\u2019</li> </ul> <p>Notes</p> <ul> <li>We want low \\(P (\\vert \\hat \\mu \u2212 \\mu \\vert &gt; \\epsilon)\\)</li> <li>Even though \\(P (\\vert \\hat \\mu \u2212 \\mu \\vert &gt; \\epsilon)\\) will depend on \\(\\mu\\), the bound is independent of \\(\\mu\\)</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/06_Sampling_Distributions/#vapnik-chervonenkis-inequality","title":"Vapnik-Chervonenkis Inequality","text":"\\[ P (\\vert \\bar x \u2212 \\mu \\vert &gt; \\epsilon) \\le 4 \\cdot m_h(2n) \\cdot \\exp \\left[ \\dfrac{-1}{8} n \\epsilon^2 \\right] \\] <p>Where \\(m_h(n) = 2^n\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/","title":"Hypothesis Testing","text":""},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#objective","title":"Objective","text":"<p>Hypothesis testing involves testing the following question</p> <p>Is the estimated value sufficiently close to stated value?</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#hypothesis","title":"Hypothesis","text":"<ul> <li>Simple Hypothesis<ul> <li>Single Tailed</li> <li>\\(\\beta_2 &gt; 0.3\\)</li> </ul> </li> <li>Composite Hypothesis<ul> <li>2 Tailed</li> <li>Bi-Directional</li> <li>Useful when not sure about the direction</li> <li>\\(\\beta_2 \\ne 0.3\\)</li> </ul> </li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#idk","title":"IDK","text":""},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#null-hypothesis-h_0","title":"Null Hypothesis \\((H_0)\\)","text":"<p>Your initial statement</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#alternative-hypothesis-h_1","title":"Alternative Hypothesis \\((H_1)\\)","text":"<p>[Usually] complement of your initial statement</p> <p>Also called as Maintained Hypothesis. It acts as the fallback in case null hypothesis is proven to be false.</p> <p>Then the value of \\(y\\) is taken to be the value obtained from the sample</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#number-of-hypotheses","title":"Number of Hypotheses","text":"<p>If \\(n =\\) no of independent variables, the number of hypothesis is \\(2n + 1\\)</p> <p>\\(+1\\) is due to intercept(constant)</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#steps","title":"Steps","text":"<ol> <li> <p>Formula hypotheses</p> </li> <li> <p>Determine if one/two tailed test</p> </li> <li> <p>Construct a \\(100(1-\\alpha) \\ \\%\\) confidence interval for \\(\\beta_2\\)</p> </li> <li> <p>Determine critical values</p> </li> <li> <p>Determine rules to accept/reject null hypothesis</p> </li> <li> <p>Compare estimate-value with critical region</p> </li> <li> <p>Conclusion</p> <ul> <li>If it lies within critical region, accept null hypothesis</li> <li>If it lies outside critical region, reject null hypothesis</li> <li>accept alternate hypothesis</li> <li>\\(\\beta_2\\) will take the sample value</li> </ul> </li> </ol>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#confidence-interval","title":"Confidence Interval","text":"\\[ \\begin{aligned} (1-\\alpha) &amp;= P(- t_{\\alpha/2} \\le \\textcolor{hotpink}{t} \\le +t_{\\alpha/2}) \\\\ \\textcolor{hotpink}{t} &amp;= \\frac{\\hat \\beta_2 - \\beta_2}{\\sigma(\\hat \\beta_2)} \\end{aligned} \\] \\[ (1-\\alpha) = P(\\hat \\beta_2  t) \\] <ul> <li>\\(\\alpha =\\) level of significance</li> <li>\\((1-\\alpha) =\\) Confidence coefficient</li> </ul> <p>Construct the confidence interval for \\(t\\) distribution, with \\((n-2)\\) degrees of freedom. This is because we have 2 unknowns.</p> <p></p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#level-of-significance","title":"Level of Significance","text":"<p>Tolerance level for error</p> <p>This is</p> <ul> <li>probability of committing type 1 error</li> <li>probability of rejecting null hypothesis, and then getting sample value as the actual value just by chance</li> </ul> Field Conventional \\(\\alpha\\) Conventional \\((1 - \\alpha) \\%\\) Pure Sciences 0.01 99% Social Sciences 0.05 95% Psychology 0.10 90%"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#normal-distribution","title":"Normal Distribution","text":"<ul> <li>\\(95 \\%\\) values lies within 1 standard deviation on each side from the center</li> <li>\\(2.5 \\%\\) values lies outside 1 standard deviation on left side</li> <li>\\(2.5 \\%\\) values lies outside 1 standard deviation on right side</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#errors","title":"Errors","text":"Type 1 Type 2 Error of Rejecting correct null hypothesis Accepting incorrect null hypothesis Meaning False Negative False Positive Measured by \\(\\alpha\\)(Level of Significance) Happens when Sample is not a good representation of population"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#statistical-equivalence","title":"Statistical Equivalence","text":"<p>0.5 can be statistically = 0, or not; depends on the context</p> \\[ \\begin{aligned} P(\\text{rejecting } H_0) &amp;\\propto |t| \\\\ &amp;\\propto \\text{Deviation of sample value from true value} \\end{aligned} \\] \\[ t = 0 \\implies \\hat \\beta_2 = \\beta_2 \\]"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#p-value","title":"p-Value","text":"<p>Observed level of significance</p> <p>\\(\\text{p value} \\le \\alpha \\implies\\) Reject null hypothesis</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#t2-rule","title":"\\(t=2\\) Rule","text":"<p>For degree of freedom \\(\\ge 20\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#2-tailed","title":"2 Tailed","text":"<p>\\(H_0: \\beta_2 = 0, H_0: \\beta_2 \\ne 0\\) </p> <p>If \\(|t| &gt; 2 \\implies p \\le 0.05 \\implies\\) reject \\(H_0\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#1-tailed","title":"1 Tailed","text":"<p>\\(H_0: \\beta_2 = 0, H_0: \\beta_2 &gt; 0\\) or \\(H_0: \\beta_2 = 0, H_0: \\beta_2 &lt; 0\\) </p> <p>If \\(|t| &gt; 1.73 \\implies p \\le 0.05 \\implies\\) reject \\(H_0\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#why-t-distribution","title":"Why \\(t\\) distribution?","text":"<p>\\(t\\) distribution is a variant of \\(z\\) distribution</p> <ul> <li>For small samples, we use \\(t\\) dist</li> <li>For large sample, we use \\(z\\) dist</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#idk_1","title":"IDK","text":"<p>\\(\\alpha\\)</p> <ul> <li>level of significance</li> <li>size of critical region</li> </ul> <p>Confidence level = \\((1-\\alpha) \\times 100 \\%\\)</p> <p>The entire distribution is divided into 2 regions</p> <ol> <li>Critical Region    Region of rejection of \\(H_0\\)    it is decided based on \\(H_1\\)</li> <li>Acceptance Region    Region of acceptance of \\(H_0\\)</li> </ol> \\[ \\begin{aligned} &amp; H_0: \\beta_j = 0 \\\\ &amp; {\\tiny \\text{ that includes other all predictors and nothing else}} \\\\ \\\\ &amp; H_1: \\text{o.w} \\end{aligned} \\] <ul> <li>Rejection of \\(H_0 \\centernot \\implies \\beta\\)  significantly different from 0. Therefore, to assess magnitude of \\(\\beta\\), confidence intervals are more useful than \\(p\\)-values</li> <li>Rejection of \\(H_0\\) does not mean that \\(x\\) has a significant causal effect on \\(y\\). Statistical significance \\(\\centernot \\implies\\) scientific, real-world significance. The most important variables are not those with the smallest p-values.</li> <li>The t\u2212test can be thought of as checking whether adding \\(x_j\\) really improves predictions in a model that contains other specified predictors</li> <li>95% CI = \\(\\text{LL}, \\text{UL} \\centernot \\implies \\text{Pr}(\\beta \\in [\\text{LL, UL}]) = 0.95\\)</li> <li>Correct interpretation: a 95% CI for \\(\\beta\\) means that if     we estimate our model on many independent random samples drawn     from the same population and construct \\(\\text{CI}_m = [\\text{LL}_m, \\text{UL}_m]\\) on each sample, then 95% of these \\(\\{ CI_m \\}\\) will contain \\(\\beta\\)</li> </ul> \\[ L(H1, \\hat H_1) = \\begin{cases} 0, &amp; H_1 = \\hat H_1 \\\\ 95, &amp; H_1 = 0, \\hat H_1 = 1 \\\\ 5, &amp; H_1 = 1, \\hat H_1 = 0 \\end{cases} \\]"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#p-value_1","title":"P-Value","text":"<p>P-value is not the conditional probability of \\(H_0\\). It is actually the probability of \\(H_0\\) being true based only on the observed data set (without incorporating prior knowledge) $$ \\begin{aligned} p \\text{-value} &amp;\\ne P(H_0 = \\text{True} \\vert D) \\ p \\text{-value} &amp;= P(D \\vert H_0 = \\text{True} )\\ &amp;= \\text{Pr}(\\vert t \\vert \\ge \\vert t(\\hat \\beta)  \\vert H_0) \\end{aligned} $$</p> \\[ \\begin{aligned} \\text{What actually} &amp; \\text { needed}\\\\ P(H_0 = \\text{True} \\vert D) &amp;= \\dfrac{P(D \\vert H_0) \\cdot P(H_0)}{P(D)} \\\\ &amp;= \\dfrac{p \\cdot P(H_0)}{P(D)} \\\\ &amp;= \\dfrac{p \\cdot P(H_0)}{p \\cdot P(H_0) + (1-p) \\cdot P(H_1)} \\end{aligned} \\] <p>where \\(D\\) is the data</p> <p>When \\(P(H_1) &lt; 0.1\\), we may need the p\u2212value to be much smaller than the conventional threshold of \\(\\alpha = 0.05\\) in order to \u201cconfidently\u201d reject \\(H_0\\)</p> <ul> <li>For example, concluding that a coin is biased would require a significant number of one-sided results </li> </ul> <p>Hypothesis tests are only valid for large sample size, as they are based on the asymptotic properties of test statistics.  Hence, Bootstrapping can be used to obtain more accurate p\u2212value estimates</p> <p></p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#population-mean","title":"Population Mean","text":"\\[ \\begin{aligned} H_0: \\mu &amp;= \\mu_0 &amp; &amp;\\text{(Null Hypothesis)} \\\\ H_1: \\mu &amp;&lt; \\mu_0, \\mu \\ne \\mu_0, \\mu &gt; \\mu_0 &amp; &amp;\\text{(Alternative Hypothesis)} \\\\ \\end{aligned} \\] \\(\\sigma^2\\) \\(n\\) Test Statistic/Probability Distribution known any \\(z_c = \\frac{\\bar x - \\mu_0}{\\sigma/\\sqrt n}\\) unknown \\(&gt;30\\) \\(z_c = \\frac{\\bar x - \\mu_0}{s/ \\sqrt n}\\) unknown \\(\\le 30\\) \\(t_c = \\frac{\\bar x - \\mu_0}{s / \\sqrt n}\\)"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#critical-region","title":"Critical Region","text":"Left-Tailed Two-Tailed Right-Tailed \\(H_1\\) \\(\\mu &lt; \\mu_0\\) \\(\\mu \\ne \\mu_0\\) \\(\\mu &gt; \\mu_0\\) p-value \\(F(z_c)\\) \\(\\alpha(t-\\text{dist})\\) \\(2[ F(-z_c) ]\\) \\(2 \\alpha(t-\\text{dist})\\) \\(F(-z_c)\\) \\(\\alpha(t-\\text{dist})\\) Cases Accept \\(H_1\\) if \\(\\begin{aligned} z_c &amp; \\le -z_\\alpha \\\\ t_c &amp;\\le -t_{(n-1), \\alpha} \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\) Accept \\(H_1\\) if \\(\\begin{aligned} z_c \\le -z_{\\alpha/2} &amp;\\text{ or } z_c \\ge +z_{\\alpha/2}\\\\ t_c \\le -t_{(n-1), (\\alpha/2)} &amp;\\text{ or } t_c \\ge +t_{(n-1), (\\alpha/2)} \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\) Accept \\(H_1\\) if \\(\\begin{aligned} z_c &amp;\\ge +z_\\alpha \\\\ t_c &amp;\\ge +t_{(n-1), \\alpha} \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\)"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#proportion","title":"Proportion","text":"\\[ \\begin{aligned} H_0: p &amp;= p_0 &amp; &amp;\\text{(Null Hypothesis)} \\\\ H_1: p &amp;&lt; p_0, p \\ne p_0, p &gt; p_0 &amp; &amp;\\text{(Alternative Hypothesis)} \\\\ z_c &amp;= \\frac{\\hat p - p_0}{     \\sqrt{ \\frac{p_0(1-p_0)}{n} } } &amp; &amp; \\hat p = \\frac x n = \\text{Estimated value of } p\\\\ \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#critical-region_1","title":"Critical Region","text":"Left-Tailed Two-Tailed Right-Tailed \\(H_1\\) \\(p &lt; p_0\\) \\(p \\ne p_0\\) \\(p &gt; p_0\\) p-value \\(F(z_c)\\) \\(2[ F(-z_c) ]\\) \\(F(-z_c)\\) Cases Accept \\(H_1\\) if \\(\\begin{aligned}z_c &amp;\\le -z_\\alpha \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\) Accept \\(H_1\\) if \\(\\begin{aligned} z_c \\le -z_{\\alpha/2} &amp;\\text{ or } z_c \\ge +z_{\\alpha/2} \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\) Accept \\(H_1\\) if \\(\\begin{aligned} z_c &amp;\\ge +z_\\alpha \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\)"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#variancesd","title":"Variance/SD","text":"\\[ \\begin{aligned} H_0: \\sigma^2 &amp;= \\sigma^2_0 &amp; &amp;\\text{(Null Hypothesis)} \\\\ H_1: \\sigma^2 &amp;&lt; \\sigma^2_0, \\sigma^2 \\ne \\sigma^2_0, \\sigma^2 &gt; \\sigma^2_0 &amp; &amp;\\text{(Alternative Hypothesis)} \\\\ \\chi_c^2 &amp;= (n-1) \\frac{s^2}{\\sigma_0^2} \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#critical-region_2","title":"Critical Region","text":"Left-Tailed Two-Tailed Right-Tailed \\(H_1\\) \\(p &lt; p_0\\) \\(p \\ne p_0\\) \\(p &gt; p_0\\) p-value 1 - \\(\\alpha\\)(table) 1 - \\(\\alpha\\)(table) 1 - \\(\\alpha\\)(table) Cases Accept \\(H_1\\) if \\(\\begin{aligned}\\chi_c^2 &amp;\\le \\chi^2_{(n-1), (1-\\alpha)}  \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\) Accept \\(H_1\\) if \\(\\begin{aligned}\\chi_c^2 \\le \\chi^2_{(n-1), (1-\\alpha/2)} &amp;\\text{ or } \\chi_c^2 \\ge \\chi^2_{(n-1), (\\alpha/2)} \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\) Accept \\(H_1\\) if \\(\\begin{aligned}\\chi_c^2 &amp;\\ge \\chi^2_{(n-1), \\alpha}  \\\\ p &amp;\\le \\alpha \\end{aligned}\\)else accept \\(H_0\\)"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#errors_1","title":"Errors","text":"\\(H_0\\) is true \\(H_0\\) is false \\(H_0\\) is incorrect Reject \\(H_0\\) Type 1 Error = \\(\\alpha\\) Correct Type 3 ErrorRight answer to the wrong question Accept \\(H_0\\) Correct Type 2 Error = \\(\\beta\\) <p>Type 1 error is alright, but Type 2 error is dangerous</p> <ul> <li>\\(\\alpha\\) = P(reject \\(H_0\\) | \\(H_0\\) is true)</li> <li>\\(\\beta\\) = P(accept \\(H_0\\) | \\(H_0\\) is false)</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#power-of-test","title":"Power of Test","text":"\\[ \\text{Power of Test} = 1 - \\beta \\] <p>Greater the power of test, the better means that we can more accurately detect when \\(H_0\\) is false</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#information-content-of-statistical-nonsignificance","title":"Information Content of Statistical (Non)Significance","text":"<p>Statistical result is informative only when it has the potential to substantially change our beliefs. The discrepancy between a prior and a posterior distribution thus provides a basic measure of the informativeness of a statistical result.</p> <p>Using this measure, non-significant results are often more informative than significant results in scenarios common in empirical economics.</p> <p>Hence, null need not always be \\(H_0: \\beta = 0\\). It can be what is prior known. This can be implemented in ridge regression by using a prior known value</p> <ul> <li>Beliefs on the causal effect of a policy intervention are usually better described by a continuous distribution rather than a distribution with significant probability mass at point zero.</li> </ul> <p>When \\(P(H_0)\\) is low, statistical significance often carries little information; non-significance is highly informative, because in this case, non-significance is more \u201csurprising\u201d and induces a larger change in the posterior belief $$ \\underbrace{1 - \\dfrac{p(\\beta \\vert R=0)}{p(\\beta)}}\\text{INS} \\ = \\dfrac{P(R=1)}{P(R=0)} \\times \\underbrace{1 - \\dfrac{p(\\beta \\vert R=1)}{p(\\beta)}}\\text{IS} $$ where</p> <ul> <li>\\(R=H_0 \\text{ rejected}\\) at given significance level</li> <li>\\(P(R = 1)\\) is the prior probability of rejection of the null</li> <li>\\(P(R = 1) = \\int P(R = 1 \\vert \\beta)  \\cdot p(\\beta) \\cdot d\\theta\\)</li> <li>\\(\\text{INS}\\) = Informativeness of non-significance</li> <li>\\(\\text{IS}\\) = Informativeness of significance</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#takeaways","title":"Takeaways","text":"<ul> <li>Non-significance is more informative than significance as long as   \\(P(R = 1) &gt; 0.5\\)</li> <li>As \\(n\\) inc and \\(p(\\beta=0)\\) dec, \\(p(R=1)\\) increases</li> <li>Thus, as datasets get larger, and because there are rarely reasons to put significant priors on \\(\\theta=0\\), non-significant results will be more informative in empirical studies in economics</li> <li>When \\(n\\) is very large, without prior probability mass at the point null, significance carries no information</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#statistical-significance-filter","title":"Statistical Significance Filter","text":"<p>Publication Bias</p> <p>Only the extreme significant cases of the study make it through to the publication, and hence are not a representative sample of all empirical findings.</p> <p></p> \\[ E[\\hat \\beta \\vert \\text{significant} &gt;&gt; \\beta] \\] <p>The power of test is low; The null hypothesis is false, but fails to be rejected \\((1-\\alpha \\% )\\) of the time</p> <p>Lower power leads to high exaggeration ratios, ie if the estimate is statistically significant, it must be at least \\(a\\) times higher than the true effect size</p> <p>Type \\(S\\) error probability: if the error is statistically-significant, but has the wrong sign</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#multiple-testing","title":"Multiple Testing","text":"<p>Multiple comparisons</p> <p>If you perform multiple hypothesis tests, the probability of at least one producing a statistically-significant result at the significance level \\(\\alpha\\) due to chance, is necessarily greater than \\(\\alpha\\)</p> <p>Multiple hypothesis fallacy: \"Strategy\" in rolling dice that maximizes the number</p> <p>When testing \\(m\\) hypotheses</p> Meaning Preferred for Formula FWER (Family-wise Error Rate)Joint Type 1 Error Probability of \\(\\ge 1\\) False Positives among all tested hypotheses Decision of single choice- only one car produced- only one investment strategy chosen \\(1 - (1-\\alpha)^m\\) FPR (False Positive Rate)FDR (False Discovery Rate) Expected proportion of FP among accepted hypotheses FDR is preferred for large quantity decision: many cars produced"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#fwer","title":"FWER","text":"<p>$$ \\begin{aligned} \\text{FWER} &amp;= P(\\ge 1 \\text{ FP}) \\ &amp;= 1 - P(0 \\text{ FP}) \\ &amp;= 1 - P(\\text{not falsely rejecting any null hypothesis}) \\ &amp;= 1 - P(\\cap_{j=1}^m \\text{not falsely rejecting } H_{0j}) \\end{aligned} $$ where \\(m\\) is the number of tests conducted (ie model specifications tested)</p> <p>Assuming tests are independent $$ \\begin{aligned} \\text{FWER} &amp; \\approx 1 - \\prod_{j=1}^m P (\\text{not falsely rejecting } H_{0j}) \\ &amp; \\approx 1 - \\prod_{j=1}^m (1-\\alpha) \\ &amp; \\approx 1 - (1-\\alpha)^m \\end{aligned} $$</p> <p></p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#corrections","title":"Corrections","text":"Correction \\(p_{k, \\text{adjusted}} = \\text{Correction Factor} \\times p_{k, }\\)Correction Factor Disadvantages FWER Bonferroni \\(m\\) Very strict in avoiding False PositivesMay lead to False Negatives Holm \\(m - (k-1)\\) Very strict in avoiding False PositivesMay lead to False Negatives FDR Benjamini-Hochberg \\(m \\times \\dfrac{1}{k}\\) Benjamini-Yekutieli \\(m \\times \\dfrac{1}{k} \\times \\sum\\limits_{i=1}^m \\left(\\dfrac{1}{j}\\right)\\) <p>\\(k=\\) index in sorted list</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#bonferroni-correction","title":"Bonferroni Correction","text":"<p>Bounds the FWER at below \\(\\alpha\\) by setting the significance threshold for each individual test as \\(\\alpha/m\\)</p> <p>$$ 1 - \\left(1 - \\dfrac{\\alpha}{m} \\right)^m \\le \\alpha $$ It is conservative, as it is assumes independent tests.</p> <p>For large \\(m\\), it leads to a significant loss of power, ie higher probability of false negative</p>"},{"location":"1_Core/Probability_%26_Statistics/07_Hypothesis_Testing/#holm-correction","title":"Holm Correction","text":"<ol> <li>Compute \\(p\\)-values \\(p_1, p_2, \\dots, p_m\\) for the \\(m\\) null hypotheses \\(H_{01}, H_{02}, \\dots, H_{0m}\\)</li> <li>Order the \\(m\\) \\(p\\)-values in ascending order of magnitude to obtain \\(p = \\{ p_{(1)}, p_{(2)}, \\dots, p_{(m)} \\}\\) such that \\(p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}\\)</li> <li>Adjust \\(p\\) values where \\(k=\\) index in sorted list</li> <li>Reject \\(H_{0k} \\ \\forall k\\) that satisfy \\(p_{k, \\text{adjusted}} \\le \\alpha\\)</li> </ol> <pre><code>from statsmodels.stats.multitest import multipletests\n\nmethod = \"holm\" # \"bonferroni\", \"fdr_bh\", \"fdr_by\"\nmultipletests(p_values, method = method).pvals_corrected\n</code></pre>"},{"location":"1_Core/Probability_%26_Statistics/08_Regression/","title":"Regression","text":"<p>used to predict for the dependent variable on the basis of past information available on dependent and independent variables.</p> <p>The estimated regression line is given by</p> \\[ \\begin{aligned} \\hat y &amp;= b_0 + b_1 x \\\\ b_1 &amp;= \\frac{     n \\ \\sum (xy) - \\sum x \\sum y }{     n \\ \\sum x^2 - \\Big( \\sum x \\Big)^2 } \\\\ b_0 &amp;= \\bar y - b_1 \\bar x \\\\ \\bar x &amp;= \\frac{\\sum x} n \\\\ \\bar y &amp;= \\frac{\\sum y} n \\end{aligned} \\] Term Meaning \\(y\\) dependent variable \\(x\\) independent variable \\(b_0\\) y-intercept \\(b_1\\) slope \\(\\hat y\\) estimated value \\(\\bar x\\) mean of \\(x\\) \\(\\bar y\\) mean of \\(y\\)"},{"location":"1_Core/Probability_%26_Statistics/08_Regression/#correlation","title":"Correlation","text":"<p>gives the degree of linear relationship between 2 vars</p> <p>Properties</p> <ul> <li>Dimensionless</li> <li>Symmetric: \\(r(x, y)=r(y, x)\\)</li> <li>\\(r \\in [-1, +1]\\)</li> </ul> \\[ r(x, y) = \\dfrac{\\text{cov}(x, y)}{\\sigma_x \\sigma_y} \\]"},{"location":"1_Core/Probability_%26_Statistics/08_Regression/#pearsons-correlation","title":"Pearson\u2019s Correlation","text":"<p>Also called product moment correlation $$ \\begin{aligned} r &amp;= \\dfrac{1}{n-1} \\sum_{i=1}^n z_{xi} z_{yi} \\ &amp;= \\dfrac{     \\sum (x_i - \\bar x)(y_i - \\bar y) }{ \\sqrt{\\sum (x_i - \\bar x)^2 \\sum (y_i - \\bar y)^2} } \\ &amp;= \\dfrac{     n \\sum(xy) - \\sum x \\sum y }{     n     \\sqrt{\\sum (x^2) - \\big(\\sum x \\big)^2 }     \\sqrt{ \\sum (y^2) - \\big(\\sum y \\big)^2 } } \\end{aligned} $$</p> <p>Measures whether 2 vars are above/below mean at the same time</p>"},{"location":"1_Core/Probability_%26_Statistics/08_Regression/#robust-correlation","title":"Robust correlation","text":"<ul> <li>Replace mean/sum with median</li> <li>Replace square with abs</li> </ul> \\[ \\begin{aligned} r &amp;= \\dfrac{     \\text{med} \\{ \\ (x_i - \\tilde x)(y_i - \\tilde y) \\ \\} }{ \\text{med} (x_i - \\tilde x) \\times \\text{med} (y_i - \\tilde y) } \\end{aligned} \\] <p>where \\(\\tilde x = \\text{med} (x)\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/08_Regression/#spearman-correlation","title":"Spearman Correlation","text":""},{"location":"1_Core/Probability_%26_Statistics/08_Regression/#modified-correlation","title":"Modified Correlation","text":"<p>Setting the center as origin \\(\\implies \\bar x=\\bar y=0\\)</p> <ul> <li>Contributes +vely if both vars are positive</li> <li>Contributes +vely if both vars are negative</li> <li>Contributes -vely if both vars are opposing sign</li> </ul> \\[ r_0 = \\dfrac{     \\sum x_i y_i }{ \\sqrt{\\sum (x_i)^2 \\sum (y_i)^2} } \\] <p>Useful for comparing time-series, returns, etc</p> Type Correlation Strength Weak \\(\\vert  r  \\vert \\le 0.5\\) Moderate \\(0.5 &lt; \\vert  r  \\vert &lt; 0.8\\) Strong \\(\\vert  r  \\vert \\ge 0.8\\) Direction Directly \\(r &gt; 0\\) Inversely \\(r &lt; 0\\)"},{"location":"1_Core/Probability_%26_Statistics/08_Regression/#similarity-to-dissimilarity","title":"Similarity to Dissimilarity","text":"<p>\\(\\sqrt{2(1-r)}\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/08_Regression/#coefficient-of-determination","title":"Coefficient of Determination","text":"<p>\\(R^2\\) value is used for non-linear regression. It shows how well data fits within the regression.</p> <p>It has a range of \\([0, 1]\\). Higher the better.</p> \\[ \\begin{aligned} R^2 &amp;= 1 - \\frac{ \\text{SS}_{res} }{ \\text{SS}_{tot} } \\\\ \\text{SS}_\\text{res} &amp;= \\sum\\limits_{i=1}^n (y_i - \\hat y)^2 \\\\ \\text{SS}_\\text{tot} &amp;= \\sum\\limits_{i=1}^n (y_i - \\bar y)^2 \\\\ \\bar y &amp;= \\frac{1}{n} \\sum\\limits_{i=1}^n y_i \\end{aligned} \\] <p>where</p> Symbol Meaning \\(\\text{SS}_\\text{res}\\) Residual sum of squares \\(\\text{SS}_\\text{tot}\\) Total sum of squaresProportional to variance of the data"},{"location":"1_Core/Probability_%26_Statistics/09_Distribution_Tests/","title":"Distribution Tests","text":""},{"location":"1_Core/Probability_%26_Statistics/09_Distribution_Tests/#normality","title":"Normality","text":"<ul> <li>Histogram with Kernel Density Estimation</li> <li>Q-Q Plots</li> <li>Moment tests</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/09_Distribution_Tests/#jaque-bera-test","title":"Jaque-Bera Test","text":"<p>Tests for skewness and kurtosis combined $$ \\left[ \\dfrac{\\mu_3}{\\text{SE}(\\mu_3)} \\right]^2 +  \\left[ \\dfrac{\\mu_4}{\\text{SE}(\\mu_4')} \\right]^2 \\sim \\chi^2_2 $$</p>"},{"location":"1_Core/Probability_%26_Statistics/09_Distribution_Tests/#shapiro-wilk-test","title":"Shapiro-Wilk Test","text":"<p>\\(H_0:\\)\u00a0Sample \\(x\\)\u00a0comes from normal-distribution</p> <p>Characteristics of test</p> <ul> <li>Defined for \\(n \\ge 3\\)</li> <li>Best power for a given significance compared to other popular tests</li> </ul> <p>Limitations</p> <ul> <li>This test is sample-size biased</li> <li>Small sample size doesn't have enough information to conclude with high certainty</li> <li>For a large dataset, even a small departure from normality will trigger a rejection</li> <li>hence normal Q-Q plot should be used to confirm test results</li> <li>Failure to reject \\(H_0\\), ie accepting \\(H_1\\) is not proof that the distribution is normal</li> <li>Rejecting \\(H_0\\) does not tell you how much the distribution differs from normal distribution</li> </ul> <p>Test statistic</p> <ul> <li>\\(w \\in (0, 1]\\)</li> <li>Very similar to correlation coefficient of a normal \\(Q-Q\\) plot</li> <li>\\(w\\) independent of location and scale of \\(x\\)</li> </ul> \\[ w = \\dfrac{(\\sum a_i x_i)^2}{\\sum (x_i - \\bar x)^2} \\] <p>where</p> <ul> <li>\\(x_i=\\) \\(i\\)th smallest value</li> <li>\\(a_i=\\)\u00a0Shapiro-Wilk Constant</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/09_Distribution_Tests/#note","title":"Note","text":"<ul> <li>All tests are very sensitive to outliers</li> <li>One outlier: distribution appears skewed</li> <li>Two symmetric outliers: distribution appears to have heavy tails</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/09_Distribution_Tests/#_1","title":"Distribution Tests","text":""},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/","title":"Comparing Samples","text":""},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#t-distribution-dof","title":"\\(t\\) Distribution DOF","text":"\\[ \\text{DOF} = \\dfrac{ \\Big[ \\sum_{i=1}^2 (s_i^2/n_i) \\Big]^2 }{ \\sum_{i=1}^2 \\dfrac{(s_i/n_i)^2}{n_i - 1} } \\]"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#comparing-means","title":"Comparing Means","text":"<p>Using central-limit theorem, sampling distribution\u2019s mean is normally-distributed, else t-distributed</p>"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#hat-sigma_1-ne-hat-sigma_2","title":"\\(\\hat \\sigma_1 \\ne \\hat \\sigma_2\\)","text":"<p>Given</p> <ul> <li>\\((\\bar x_1, s_1)\\)</li> <li>\\((\\bar x_2, s_2)\\)</li> </ul> \\[ \\begin{aligned} z \\text{ or } t &amp;= \\dfrac{(\\bar x_1 - \\bar x_2) - E[(\\bar x_1 - \\bar x_2)]}{\\sigma^2(\\bar x_1 - \\bar x_2)} \\\\ &amp;= \\dfrac{     (\\bar x_1 - \\bar x_2) - (\\hat \\mu_1 - \\hat \\mu_2) }{ \\sqrt{     \\sum_{i=1}^2 \\dfrac{s_i^2}{n_i} + 2 \\rho_{12} s_1 s_2 } } \\end{aligned} \\] <p>Simplification: Is \\(\\mu_1\\) and \\(\\mu_2\\) statistically different? \\(\\implies (\\hat \\mu_1 - \\hat \\mu_2)=0\\)</p>"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#hat-sigma_1-hat-sigma_2","title":"\\(\\hat \\sigma_1 = \\hat \\sigma_2\\)","text":"<p>Pooled samples: If we are confident that the population variance are same, we can pool all data to make one estimate of the population variance</p> \\[ \\begin{aligned} s^2_{12} &amp;= \\dfrac{ (n_1-1) s^2_1 + (n_2-1) s^2_2 }{ (n_1-1) + (n_2-1) } \\end{aligned} \\]"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#pairing","title":"Pairing","text":"<p>Matched Samples</p> <p>Compare samples before and after treatment $$ d_i = y_{i, T=1} - y_{i, T=0} $$ \\(T=\\) treatment variable $$ \\begin{aligned} z &amp;= \\dfrac{ \\bar d - \\hat \\mu_d }{ s_d/\\sqrt{n} } \\end{aligned} $$</p>"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#inference","title":"Inference","text":"<ul> <li>If \\(z\\) or \\(t\\) within 95% 2-sided confidence interval centered around 0, then both series are similar</li> <li>Else, dissimilar</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#comparing-variances","title":"Comparing Variances","text":"<p>Assumes that the population distribution is Normal</p> <p>There is no central-limit theorem that can be applied here $$ \\begin{aligned} F &amp;= \\dfrac{s<sup>2_1/\\sigma</sup>2_1}{s<sup>2_2/\\sigma</sup>2_2} \\ &amp; \\sim F(n_1-1, n_2-1)  \\end{aligned} $$</p>"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#correct-sampling","title":"Correct Sampling","text":"<ul> <li>Random sampling: When evaluating treatment, every subject must have equal probability of receiving treatment</li> <li>Equal sample sizes fore each treatment products optimal test</li> <li>Pairing can be used eliminate effect of uncontrolled variable</li> </ul>"},{"location":"1_Core/Probability_%26_Statistics/10_Comparing_Samples/#standard-error-of-mean","title":"Standard error of mean","text":"Error bars overlap Error bars contain both the sample means Inference \u2705 \u2705 Strong evidence that populations are not different \u2705 \u274c No strong evidence that populations are not different \u274c \u274c Strong evidence that populations are different"},{"location":"1_Core/Technical_Report_Writing/","title":"Technical Report Writing","text":"<p>This course has been divided into 2 sub-components.</p> Part Topics Professor A SentencesEffective writingPreparing questionnaries Dr. Shazi B Paragraph writingIEEE citations Dr. Sayantan <p>For Compres, Part A + Introduction and Part B + Discussion Questions can be expected.</p>"},{"location":"1_Core/Technical_Report_Writing/01_Part_A/","title":"Part - A","text":""},{"location":"1_Core/Technical_Report_Writing/01_Part_A/#types-of-sentences","title":"Types of Sentences","text":""},{"location":"1_Core/Technical_Report_Writing/01_Part_A/#on-the-basis-of-structure","title":"On the basis of structure:","text":"Type of Sentence Structure Example Simple Sentence One independent clause \"She ran.\" Can have small conjunction between two words \"She ran and jumped.\" Compound Sentence Two or more independent clauses \"She ran, and he jumped.\" Joined by FANBOYS conjunction (For, And, Nor, Between, Or, Yet, So) \"She ran, and he jumped, but he fell.\" Complex Sentence One independent clause \"She ran to the store.\" One dependent clause (starts with some \"complex\" word) \"After she ran to the store, she went home.\" Compound-Complex Sentence Two or more independent clauses \"She ran to the store, and he jumped over the fence.\" One dependent clause \"After she ran to the store, she went home, but he stayed outside.\""},{"location":"1_Core/Technical_Report_Writing/01_Part_A/#mnemonic-for-remembering-classification-of-sentences-on-the-basis-of-form-scqrc","title":"Mnemonic for remembering classification of sentences on the basis of form: [SCQRC]","text":"<ol> <li>**S**tatement </li> <li>**C**ommand </li> <li>**Q**uestion </li> <li>**R**equest </li> <li>**C**ommand</li> </ol>"},{"location":"1_Core/Technical_Report_Writing/01_Part_A/#mnemonic-for-remembering-classification-of-sentences-on-the-basis-of-function-dniee","title":"Mnemonic for remembering classification of sentences on the basis of function: [DNIEE]","text":"<ol> <li>**D**escriptive </li> <li>**N**arrative </li> <li>**I**llocutionary </li> <li>**E**xpository </li> <li>**E**xclamatory</li> </ol>"},{"location":"1_Core/Technical_Report_Writing/01_Part_A/#effective-sentence-making","title":"Effective Sentence Making:","text":"<p>Check for the following - - Should not be too connotative (negative)  - Precise (mention names)  - Concise (difficult to approximate \u2192 estimate)  - Plainness (don't use complicated words)  - Avoid Cliches, Jargons, Foreign Words  - Avoid gender biased words (mankind \u2192 humanity) - Avoid too many nouns (Window Sash Installation Company \u2192 the company that installs window sashes)</p>"},{"location":"1_Core/Technical_Report_Writing/01_Part_A/#questionnaires","title":"Questionnaires:","text":"<ul> <li>Open Ended ( How would you describe this flavor of ice cream? ) </li> <li>Close Ended ( Do you think this ice cream is too rich in flavor? )</li> <li>Multiple Choice </li> <li>Checklist</li> <li>Ranking </li> <li>Short Answer </li> <li>Scale</li> </ul> <p>Misc points to remember:  - Double Barreled Question : How have teachers and students reacted to the new 30min lunch break?  - Leading Question : Do you think the new cafeteria lunch menu offers a better variety of healthy foods than the old one? - Minimum Number of Respondents is Total Size / 10</p>"},{"location":"1_Core/Technical_Report_Writing/02_Part_B/","title":"Part - B","text":""},{"location":"1_Core/Technical_Report_Writing/02_Part_B/#paragraph-writing","title":"Paragraph Writing","text":""},{"location":"1_Core/Technical_Report_Writing/02_Part_B/#types-of-pragraphs","title":"Types of Pragraphs:","text":"<ul> <li>Descriptive </li> <li>Example </li> <li>Process</li> <li>Opinion</li> <li>Narrative </li> </ul>"},{"location":"1_Core/Technical_Report_Writing/02_Part_B/#structure","title":"Structure:","text":"<ul> <li>Topic Sentence (What is the need to discuss the topic) </li> <li>Body </li> <li>Conclusion of Topic Sentence (Therefore we need it)</li> </ul>"},{"location":"1_Core/Technical_Report_Writing/02_Part_B/#abstract-writing","title":"Abstract Writing","text":"<ul> <li>Why we chose this topic?</li> <li>Problem Statement </li> <li>Solutions </li> <li>Impact and Outcome of the research. </li> </ul> <p>Thoughts should be expressed keeping [Approach \u2192 Method \u2192 Technique] order in mind. </p>"},{"location":"1_Core/Technical_Report_Writing/02_Part_B/#ieee-format","title":"IEEE Format:","text":"<ul> <li>Title in \" \" </li> <li>Journal must be underlined with Pencil </li> <li>Author Name is Eg. S Balamurugan</li> <li>Editor comes after journal </li> <li>\"Place : Publishing Press name\"</li> <li>Volume (vol), Issue (no), Page (pp), Year, DOI</li> </ul>"},{"location":"1_Core/Technical_Report_Writing/03_Sample_Report_%26_Slides/","title":"Sample Report and Slides","text":"<p>Observe the feedback from the professors, and improve on those points.</p> Topic Report Slides CyberSecurity and Data Leak Detection(Graded best of 2022-23 Sem 2) Report Slides The Problems of the Web and How to fix them Report <p>The CyberSecurity report has been provided by a junior. Thank you Sivaa! \u2728</p>"},{"location":"1_Core/Thermodynamics/","title":"Thermodynamics","text":"<p>Taught by Dr. Shashank Khurana, Asst HOD of Mechanical Eng Dept.</p> <p>This course deals with </p> <ul> <li>Properties of different substances</li> <li>Flow of heat and work, and its applications</li> </ul>"},{"location":"1_Core/Thermodynamics/01_Intro/","title":"01 Intro","text":""},{"location":"1_Core/Thermodynamics/01_Intro/#pressure","title":"Pressure","text":"\\[ \\begin{aligned} P &amp;= \\frac F A \\\\ &amp;= \\rho g h \\\\ P_\\text{abs}  &amp;= P_\\text{atm} + P_\\text{gage} \\\\ &amp;= P_\\text{atm} - P_\\text{vac} \\\\ 1 \\text{ bar} &amp;= 100 \\text{ kPa} \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/01_Intro/#manometer","title":"Manometer","text":"<p>Denser fluid will be below</p> \\[ \\begin{aligned} P_\\text{a} &amp;= P_\\text{b} \\\\ P_{g_1} + \\rho_1 g h_1 &amp;= P_{g_2} + \\rho_2 g h_2 \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/01_Intro/#terms","title":"Terms","text":"Term Meaning Specific Gravity SG = \\(\\frac \\rho { \\rho_\\ce{H2O} }\\) Cycle Initial and final properties are the same Steady Flow Properties are independent of time Uniform Flow Properties are independent of location"},{"location":"1_Core/Thermodynamics/02_Pure_Substances%2C_Ideal_Gases/","title":"02 Pure Substances, Ideal Gases","text":""},{"location":"1_Core/Thermodynamics/02_Pure_Substances%2C_Ideal_Gases/#pure-substances","title":"Pure Substances","text":""},{"location":"1_Core/Thermodynamics/02_Pure_Substances%2C_Ideal_Gases/#graph","title":"Graph","text":""},{"location":"1_Core/Thermodynamics/02_Pure_Substances%2C_Ideal_Gases/#points","title":"Points","text":"Point Meaning \\(x\\) left(f) compressed/subcooled liquid N/A f saturated liquid 0 f-g saturated liquid-vapor mixture \\(0&lt;x&lt;1\\) g saturated vapor 1 right(g) superheated vapor N/A c critical point"},{"location":"1_Core/Thermodynamics/02_Pure_Substances%2C_Ideal_Gases/#terms","title":"Terms","text":"Term Meaning Formula \\(h_\\text{fg}\\) latent heat of vaporisation \\(h_g - h_f\\)(or use table) \\(\\Delta h\\) specific heat extracted \\(m \\times h_\\text{fg}\\) \\(x\\) Quality Fraction \\(\\frac{m_\\text{vap}}{m_\\text{tot}}\\)"},{"location":"1_Core/Thermodynamics/02_Pure_Substances%2C_Ideal_Gases/#compressed-liquid","title":"Compressed liquid","text":"<p>Properties are independent of pressure</p> <p>Therefore, at a given temperature</p> <ul> <li>\\(\\nu \\approx \\nu_f\\)</li> <li>\\(u \\approx u_f\\)</li> <li>\\(h \\approx h_f\\)</li> </ul>"},{"location":"1_Core/Thermodynamics/02_Pure_Substances%2C_Ideal_Gases/#ideal-gases","title":"Ideal Gases","text":"\\[ \\begin{aligned} PV  &amp;= mRT \\\\ &amp;= n R_u T \\\\ m &amp;= \\frac{PV}{RT} \\\\ \\rho &amp;= \\frac{P}{RT} \\\\ R &amp;= \\frac{R_u}{M}, M = \\text{Molar Mass (kg/mol)} \\\\ R_u &amp;= 0.8314 \\ \\mathrm{kJ/mol \\cdot K} \\\\ &amp;= 8.314  \\ \\mathrm{J/mol \\cdot K} \\\\ \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/03_Heat_and_Work/","title":"03 Heat and Work","text":""},{"location":"1_Core/Thermodynamics/03_Heat_and_Work/#addable-quantities","title":"Addable Quantities","text":"<ul> <li>mass</li> <li>volume</li> <li>U</li> <li>H</li> <li>\\(u\\) for closed system</li> </ul> <p>note that specific quanties like \\(h, u\\) can not be added</p>"},{"location":"1_Core/Thermodynamics/03_Heat_and_Work/#work","title":"Work","text":""},{"location":"1_Core/Thermodynamics/03_Heat_and_Work/#spring","title":"Spring","text":"\\[ \\begin{aligned} F &amp;= kx \\\\ W &amp;= \\frac{1}{2} k x^2 \\\\ &amp;= \\frac12 k ({x_2} ^2 - {x_1}^2) \\\\ \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/03_Heat_and_Work/#electric","title":"Electric","text":"\\[ \\begin{aligned} \\dot W &amp;= VI \\\\ W &amp;= VI \\Delta t \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/03_Heat_and_Work/#boundary-work","title":"Boundary Work","text":"<p>Note that temperature should be in \\(K\\) (Kelvin)</p> \\[ W_\\text{out, b} = \\int \\limits_{v_1}^{v_2} P \\cdot dv \\] Type Condition(s) \\(W_b\\) Isochoric \\(V = c\\) \\(0\\) Isobaric \\(P = c\\) \\(P_1(V_2 - V_1)\\) \\(mP_1(\\nu_2 - \\nu_1)\\) Isothermal \\(\\begin{aligned} T &amp;= c \\\\ PV &amp;= mRT \\\\ P_1 V_1 &amp;= P_2 V_2 \\end{aligned}\\) \\(P_i V_i \\ \\ln \\vert  \\frac{V_2}{V_1} \\vert  \\\\ P_i V_i \\ \\ln \\vert  \\frac{P_1}{P_2} \\vert\\) \\(mRT \\ \\ln \\vert  \\frac{V_2}{V_1} \\vert\\) \\(mRT \\ \\ln \\vert  \\frac{P_1}{P_2}  \\vert\\) Polytropic \\(\\begin{aligned} P V^n &amp;= c \\\\ P_1 (V_1)^n &amp;= P_2 (V_2)^n \\\\ \\frac{P_1}{P_2} &amp;= \\left( \\frac{V_2}{V_1} \\right)^n  \\end{aligned}\\) \\(\\frac{P_2 V_2 - P_1 V_1}{1-n}\\) \\(\\frac{mR(T_2 - T_1)}{1-n}\\)"},{"location":"1_Core/Thermodynamics/03_Heat_and_Work/#sign-convention","title":"Sign Convention","text":"Quantity Sign \\(Q_\\text{in}\\) + \\(Q_\\text{out}\\) - \\(W_\\text{in}\\) - \\(W_\\text{out}\\) + expansion + compression -"},{"location":"1_Core/Thermodynamics/04_Closed_Systems/","title":"04 Closed Systems","text":""},{"location":"1_Core/Thermodynamics/04_Closed_Systems/#first-law","title":"First Law","text":"\\[ \\begin{aligned} \\delta Q - \\delta W &amp;= dU \\\\ Q_\\text{net} - W_\\text{net} &amp;= \\Delta U \\\\ \\dot Q_\\text{net} - \\dot W_\\text{net} &amp;= \\frac{\\mathrm{d} E_\\text{sys}}{dt}  &amp; \\left(\\ne \\frac{\\Delta U}{\\Delta t} \\right) \\\\ \\text{For a cycle, } Q_\\text{net} &amp;= W_\\text{net} &amp; (\\Delta U = 0) \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/04_Closed_Systems/#specific-heat","title":"Specific Heat","text":"\\[ \\begin{aligned} \\Delta u &amp;= \\int \\limits_{T_1}^{T_2} C_V \\cdot \\mathrm{d} T \\\\ &amp;= u[T_2] - u[T_1] &amp; \\text{(A.7)}\\\\ \\text{For Solids and Liquids, } \\Delta u &amp;= C_V \\Delta T \\\\ \\text{For Insulated Rigid Tank, } \\Delta u &amp;= \\Delta U = 0 &amp; (Q_\\text{net} = W_\\text{net}  = 0) \\\\ \\Delta h &amp;= \\int \\limits_{T_1}^{T_2} C_P \\cdot \\mathrm{d} T \\\\ &amp;= h[T_2] - h[T_1] &amp; \\text{(A.8)} \\\\ C_V &amp;= C_P - R \\\\ C_P &amp;= \\sum_0^3 C_n \\theta^n  &amp; \\left( \\theta = \\frac{T[K]}{1000} \\right) \\\\ &amp;= C_0 + C_1 \\theta + C_2 \\theta^2 + C_3 \\theta^3 \\\\ \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/05_Control_Volume/","title":"05 Control Volume","text":""},{"location":"1_Core/Thermodynamics/05_Control_Volume/#flow-rates","title":"Flow Rates","text":"\\[ \\begin{aligned} \\dot V &amp;= vA \\\\ \\dot m &amp;= \\rho \\dot V = \\rho vA \\\\ &amp;= \\frac{\\dot V}{\\nu} = \\frac{vA}{\\nu} \\\\ \\Big( PV &amp;= mRT, m = PV, \\rho = \\frac{P}{RT} \\Big) \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#flow-work","title":"Flow Work","text":"<p>\\(W_\\text{f} = PV\\)</p> <p>For non-flowing fluid (fluid that remains inside tank), Flow work = 0</p>"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#conservation-of-mass","title":"Conservation of Mass","text":"\\[ \\begin{aligned} \\sum m_\\text{in} - \\sum m_\\text{out} &amp;= \\Delta m \\\\ \\sum \\dot m_\\text{in} - \\sum \\dot m_\\text{out} &amp;= \\frac{\\mathrm{d} m}{\\mathrm{d} t} \\\\ \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#conservation-of-energy","title":"Conservation of Energy","text":"\\[ \\begin{aligned} E_\\text{in} - E_\\text{out} &amp;= \\Delta E_\\text{cv} \\\\ \\dot E_\\text{in} - \\dot E_\\text{out} &amp;= \\frac{\\mathrm{d} E_\\text{cv}}{\\mathrm{d} t} \\\\ \\dot Q_\\text{net} - \\dot W_\\text{net} + \\dot E_\\text{m, in} - \\dot E_\\text{m, out} &amp;= \\frac{\\mathrm{d} E_\\text{cv}}{\\mathrm{d} t} \\\\ \\dot E_\\text{in} &amp;= \\dot m \\left[ h + \\frac{v^2}{2000} + gz \\right] &amp; (h = u + P\\nu) \\\\ &amp;= \\dot m \\left[ u + \\frac{v^2}{2000} + gz \\right]  &amp; \\text{(non-flowing)} \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#steady-flow","title":"Steady Flow","text":"<p>Properties within the control volume remain constant with time</p>"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#mass","title":"Mass","text":"\\[ \\begin{aligned} \\frac{\\mathrm{d} m_\\text{cv}}{\\mathrm{d} t} &amp;= 0 \\\\ \\sum \\dot m_\\text{in} &amp;= \\sum \\dot m_\\text{out} \\\\ \\dot m_1 &amp;= \\dot m_2 \\\\ \\rho_1 v_1 A_1 &amp;= \\rho_2 v_2 A_2 \\\\ \\frac{v_1 A_1}{\\nu_1} &amp;= \\frac{v_2 A_2}{\\nu_2} \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#energy","title":"Energy","text":"\\[ \\begin{aligned} \\frac{\\mathrm{d} E_\\text{cv}}{\\mathrm{d} t} &amp;= 0 \\\\ \\dot E_\\text{m, in} &amp;= \\dot E_\\text{m, out} \\\\ \\dot Q_\\text{net} - \\dot W_\\text{net} + \\dot E_\\text{m ,in} &amp;= \\dot E_\\text{m, out} \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#steady-flow-devices","title":"Steady Flow Devices","text":"Device \\(v\\) \\(P\\) \\(T\\) Work Nozzle inc dec Diffuser dec inc Turbinethermal \\(\\to\\) mechanical \\(\\dot W_\\text{in} = 0\\) Compressor inc inc \\(\\dot W_\\text{out} = 0\\) Throttling valve(isenthalpic) dec dec \\(\\dot W_\\text{in}  = \\dot W_\\text{out} = 0\\) \\(\\begin{aligned} h_1 &amp;= h_2 \\\\ u_1 + P_1 \\nu_1 &amp;= u_2 + P_2 \\nu_2 \\end{aligned}\\)"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#unsteadytransient-flow","title":"Unsteady/Transient Flow","text":""},{"location":"1_Core/Thermodynamics/05_Control_Volume/#mass_1","title":"Mass","text":"\\[ \\begin{aligned} m_\\text{in} - m_\\text{out} &amp;= \\Delta m_\\text{cv} \\\\ &amp;= m_2 - m_1 \\\\ \\dot m_\\text{in} - \\dot m_\\text{out} &amp;= \\frac{\\mathrm{d} m_\\text{cv}}{\\mathrm{d} t} \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/05_Control_Volume/#energy_1","title":"Energy","text":"\\[ \\begin{aligned} E_\\text{in} - E_\\text{out} &amp;= \\Delta E_\\text{cv} \\\\ Q_\\text{net} - W_\\text{net} + E_\\text{m, in} - E_\\text{m, out} &amp;= \\Delta E_\\text{cv} \\\\ \\Delta E_\\text{cv} &amp;= m_2 e_2 - m_1 e_1 \\\\ e &amp;= h + \\frac{v^2}{2000} + gz \\end{aligned} \\]"},{"location":"1_Core/Thermodynamics/06_2nd_Law/","title":"06 2nd Law","text":""},{"location":"1_Core/Thermodynamics/06_2nd_Law/#terms","title":"Terms","text":"Term Meaning Formula \\(\\eta\\) Efficiency \\(\\frac{\\text{Desired Output}}{\\text{Input}}\\) COP Coefficient of Performance \\(\\frac{\\text{Desired Output}}{\\text{Input}}\\) \\(q\\) Calorific/Heating Value \\(\\frac Q m\\) Gravimetric mass terms"},{"location":"1_Core/Thermodynamics/06_2nd_Law/#devices","title":"Devices","text":"Device Purpose Heat Engine - Heat \\(\\to\\) Work- cycle $\\begin{aligned} \\eta_{\\small\\text{HE}} &amp;= \\frac{W_\\text{net, out}}{Q_\\text{H}} \\ &amp;= 1 - \\frac{Q_\\text{L}}{Q_\\text{H}} \\end{aligned}$ \\(\\eta_\\text{HE} &lt; 1\\)Kelvin-Plank Statement \\(\\begin{aligned} \\Delta U &amp;= 0 \\\\ Q_\\text{net} &amp;= W_\\text{net} \\\\ W_\\text{net, out} &amp;= Q_\\text{in} - Q_\\text{out} \\\\ &amp;= Q_\\text{H} - Q_\\text{L} \\end{aligned}\\) Refridgerator - maintain cool temp- Reverse HE $\\begin{aligned} \\text{COP}R &amp;= \\frac{Q\\text{L}}{Q_\\text{net, in}} \\ &amp;= \\frac{1}{ \\frac{Q_\\text{H}}{Q_\\text{L}} - 1 } \\end{aligned}$ \\(\\text{COP}_R\\) can be &gt; 1 Heat Pump - maintain warm temp- Reverse HE $\\begin{aligned} \\text{COP}{HP} &amp;= \\frac{Q\\text{H}}{W_\\text{net, in}} \\ &amp;= \\frac{1}{ 1 - \\frac{Q_\\text{L}}{Q_\\text{H}} } \\end{aligned}$ \\(\\begin{aligned} \\text{COP}_{HP} &amp;= \\text{COP}_{R} + 1 \\\\ \\text{COP}_{HP} &amp;&gt; \\text{COP}_{R} \\end{aligned}\\) <pre><code>flowchart LR\n\nsubgraph Heat Engine\ndirection LR\na([Warm]) --&gt;\n|Q&lt;sub&gt;H&lt;/sub&gt;| b[System] --&gt;\n|Q&lt;sub&gt;L&lt;/sub&gt;| c([Cool])\n\nb --&gt; |W&lt;sub&gt;net&lt;/sub&gt;| d[ ]\nend\n\nsubgraph Refridgerator/Heat Pump\ndirection LR\nr([Cool]) --&gt;\n|Q&lt;sub&gt;L&lt;/sub&gt;| q[System] --&gt;\n|Q&lt;sub&gt;H&lt;/sub&gt;| p([Warm])\ns[ ] --&gt; |W&lt;sub&gt;net&lt;/sub&gt;| q\nend</code></pre>"},{"location":"1_Core/Thermodynamics/06_2nd_Law/#carnot-cycle","title":"Carnot Cycle","text":"<p>For Heat Engine</p> <p>Adiabatic means polytropic process with**out** heat transfer</p> Transition Characteristic Constant Signs Work 1 - 2 Isothermal ExpansionHeat Absorbed \\(PV = c\\) $W_{12} &gt; 0 \\ Q_\\text{H} &gt; 0$ \\(P_1 V_1 \\ln \\vert  \\frac{V_2}{V_1} \\vert\\) \\(P_2 V_2 \\ln \\vert  \\frac{P_1}{P_2}  \\vert\\) 2 - 3 Adiabatic Expansion \\(PV^\\gamma = c\\) \\(W_{23} &gt; 0\\) \\(\\frac{P_3 V_3 - P_2 V_2}{1-n}\\) 3 - 4 Isothermal CompressionHeat Released \\(PV = c\\) $W_{34} &lt; 0 \\ Q_\\text{L} &lt; 0$ \\(P_3 V_3 \\ln \\vert  \\frac{V_4}{V_3} \\vert\\) \\(P_4 V_4 \\ln \\vert  \\frac{P_3}{P_4}  \\vert\\) 4 - 1 Adiabatic Compression \\(PV^\\gamma = c\\) \\(W_{41} &lt; 0\\) \\(\\frac{P_1 V_1 - P_4 V_4}{1-n}\\) \\[ \\begin{aligned} W_\\text{net, out} &amp;= W_{12} + W_{23} + W_{34} + W_{41} \\\\ \\eta &amp;= \\frac{W_\\text{net, out}}{Q_\\text{H}} \\\\ &amp;= 1 - \\frac{Q_\\text{L}}{Q_\\text{H}} \\\\ &amp;= 1 - \\frac{T_L}{T_H} \\end{aligned} \\] <p>Make sure of the signs when calculating \\(W_\\text{net, out}\\)</p>"},{"location":"1_Core/Thermodynamics/06_2nd_Law/#reverse-carnot-cycle","title":"Reverse Carnot Cycle","text":"<p>For Refridgerator, Heat Pump</p> <p>\\(Q_\\text{L} &gt; 0, Q_\\text{H} &lt; 0\\)</p> \\[ \\begin{aligned} W_\\text{net, in} &amp;= W_{12} + W_{23} + W_{34} + W_{41} \\\\ \\text{COP}_R &amp;= \\frac{Q_\\text{L}}{W_\\text{net, in}} \\\\ \\text{COP}_{HP} &amp;= \\frac{Q_\\text{H}}{W_\\text{net, in}} \\end{aligned} \\]"},{"location":"1_Core/Workshop/","title":"Workshop","text":"<p>This course has 2 components. One for weekly lecture classes and the other for weekly workshop sessions. You can find the last minute exam reviewal notes under Lecture, and demonstration videos for every experiment under Lab. </p> <p>As of date these notes cover up to midsem for lecture, demonstration videos covers the entire coursework. </p>"},{"location":"1_Core/Workshop/lab/","title":"Lab","text":"<ol> <li>Vertical Milling</li> <li>Shaper Experiment</li> <li>Drilling &amp; Tapping</li> <li>Horizontal Milling</li> <li>Lathe</li> <li>Wood Working</li> <li>Gas Welding</li> <li>Arc Welding</li> <li>Foundry</li> <li>CNC Lathe Programming</li> <li>CNC Milling Programming</li> </ol>"},{"location":"1_Core/Workshop/lecture/","title":"Lecture","text":""},{"location":"1_Core/Workshop/lecture/#ch1-manufacturing-processes","title":"Ch1 Manufacturing Processes:","text":"<p>Casting : Material is given desired shape by melting. Machining : The process of removing unwated material from the surface of a material. Forming : The process which involves the deformation of a substance by going beyond its yeild strength to obtain desired shape. Powder Metallurgy : Fine powdered materials are pressed into desired shapes + heated and are placd in controlled environements to bond and get the finished product. Joining : Two or more pieced are joined together to produce the required shape. Two types are permenant joining and temporary joining.   </p>"},{"location":"1_Core/Workshop/lecture/#ch2-engineering-materials","title":"Ch2 Engineering Materials:","text":"<p>Loading : Tensile Loading (pull) + Compressive Loading (Push)</p> <p>Stress and Strain : - Stress : Sujected to external/resisting forces.     - Tensile     - Compressive     - Shear - Strain : Ratio of change in dimension to original dimension. </p> <p>Poisson's Ratio = \\(\\frac{\\text{Lateral Strain}}{\\text{Longitudinal Stress}}\\)</p> <p>Toughness vs Hardness vs Resilience | Property | Definition | Measurement | |------------|----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------| | Toughness | Measure of Energy a material can absorb before it fractures. It is measured by the area under the stress-strain curve. | Area under the stress-strain curve | | Hardness | Property of a surface to resist abrasion or indentation. | - | | Resilience | Capacity of a material to absorb energy elastically. Upon removal of the load the energy stored is given off. | Triangular area under the elastic portion of the stress-strain curve. |</p> <p>Creep vs Fatigue :</p> <ul> <li>Creep: Time-dependent failure due to prolonged time under load. </li> <li>Fatigue: Unexpected and sudden failure that can occur under the yield point.</li> </ul>"},{"location":"1_Core/Workshop/lecture/#ch3-measurments-in-manufacturing","title":"Ch3 Measurments in Manufacturing:","text":"<p>Metrology : Science and process of ensuring the measurement meets specified degrees of both accuracy and precision. </p> <p>Measurement : Is the process of comparision of an unknown quanitity with a known quantity.</p> <p>Inspection : Examination of a component to determine wether it meets specified needs or not.</p> <p>Gauging : The proces of determining wheter the dimension is within specified limits or not. </p> <p>Testing : The process to know the perofmance of a product. </p> <p>Accuracy : The closeness of the measured value to the true value.</p> <p>Precision : The closeness of two or measured values to each other. </p> <p>Tolerance : The permissible deviation of a dimension from the desired size is known as tolerance. </p> <p>Surface Finish : The amount of geometric irregularities produced on the surface of a component during a manufacturing process.  </p>"},{"location":"1_Core/Workshop/lecture/#ch4-material-removal-process","title":"Ch4 Material Removal Process:","text":"Mechanism of Material Removal Description Depth of Cut D1-D2/2 Feed By how much distance the cutting tool must advance for each revolution of work. Cutting Speed The speed at which the workpiece moves with respect to the tool. S = Pi * D(mm) * N / 1000 Roughing Operation A large chunk to be removed without considering perfection. Finishing Operation Only a small portion is removed keeping final touches in middle. MRR 1000 * V * d * f Turning Excess material is removed by giving a depth of cut to its diameter. Facing Used to cut a flat surface perpendicular to the work piece's rotational axis. It is used to reduce the length of the workpiece. The length the workpiece travels is called the radius of the job. The depth of the cut is along the axis of the job. Knurling To produce regular patterns on the surface of metals. It is the process of pressing the metal hard enough to cause plastic deformation of metal into peaks and troughs. Low cutting speed and feed can be used w/ plenty of coolant. MRR is very low. Grooving Narrow grooves on Cylindrical Shapes, the diameter of the surface is slightly reduced. Cutting speed is slow. Depth of cut is given but no feed. Parting It is the operation of cutting a workpiece into 2 parts. The workpiece is rotated at a slow speed and the parting tool is fed perpendicular. NOTE: If a slow feed is used it will run for 2-3 revolutions without cutting and will suddenly bite the machine, this is undesired and is called hogging. Chamfering It is the operation of beveling (smoothening) the sharp edges of a workpiece to avoid injuries. It is used at an angle of 45 degrees."},{"location":"2_Core/Data_Structures_%26_Algorithms/","title":"Data Structures &amp; Algorithms","text":"Class Instructor Lecture Dr. Pranav M. Pawar Tutorial Dr. Pranav M. Pawar Practical Dr. Vijaykumar <p>This course covers tools and techniques to store and retrieve data while ensuring performance and efficiency.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/","title":"01 Algorithms","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#definitions","title":"Definitions","text":"Word Definition Algorithm step-by-step procedure to solve a problem in finite time Program implementation of algorithm in a programming language Data Structure Organization of data needed to solve the problem"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#algorithms","title":"Algorithms","text":"<pre><code>graph LR\ni[/Input/] --&gt;\nAlgorithm --&gt;\no[/Output/]</code></pre> <p>Algorithmic outputs always depend on the input.</p> <p>For example, binary search requires a sorted list as input.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#efficiency-of-algorithm","title":"Efficiency of Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#complexity","title":"Complexity","text":"<p>Determined by</p> <ol> <li>Space complexity (Space used)</li> <li>Time complexity (Running Time)</li> </ol> <p>This is more important</p> <p>Both of the above are defined as a function of input size</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#cases","title":"Cases","text":"<ul> <li>Worst</li> <li>Average</li> <li>Best</li> <li>Amortized (Sequence opertions applied to input size \\(n\\)\u00a0averaged over time)</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#experimentalemperical-analysis","title":"Experimental/Emperical Analysis","text":"<ol> <li>Write the program for the algorithm</li> <li>Run the program with different input sizes</li> <li>Measure running time</li> </ol> <p>For eg, in Java we can use <code>System.currentTimeMillis()</code> 4. Plot the result</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#limitations","title":"Limitations","text":"<ol> <li>We need to implement and test</li> <li>Same programming language must be used to compare 2 algorithms</li> </ol> <p>Because our interpretation of the efficiency may vary with different programming languages 3. Only limited set of input is possible 4. Same h/w &amp; s/w should be used to compare 2 algorithms</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#theoreticalmathematical-analysis","title":"Theoretical/Mathematical Analysis","text":"<ol> <li>Use pseudocode</li> <li>Determine the primitive operations</li> </ol> <p>We assume that each primitive operation takes 1 unit of time. 3. Define running time as a function of input size \\(n\\)</p> <pre><code>Algorithm arrayMax(a, n)\n    Input array A of n integers\n    Output maximum element of A\n\n    currentMax &lt;- A[0]\n    for i&lt;-1 to (n-1) do\n        if A[i] &gt; currentMax then\n            currentMax &lt;-A[i]\n\n    return currentMax\n</code></pre> Primitive Operations currentMax &lt;- A[0] 2- getting A[0] from memory- assignment for i \\(\\leftarrow\\) 1 to (n-1) \\(n+1\\)comparison A[i] &gt; currentMax \\(2(n-1)\\) currentMax &lt;-A[i] \\(2(n-1)\\) {increment counter i} \\(2(n-1)\\)1. add2. assign return currentMax 1 Total \\(7n-2\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#advantage","title":"Advantage","text":"<ul> <li>acknowledges all possible inputs</li> <li>evaluate speed of algorithm independent of hardware/software used</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#pseudocode","title":"Pseudocode","text":"<p>Simple representation of your program</p> <ul> <li>High-level description of algorithm</li> <li>more structured than english, but less detailed than a program</li> <li>hides program design issues</li> </ul> <p>All mathematical formatting like \\(n^2\\) (subscript) is allowed</p> Notation Meaning if \u2026 then \u2026 [else \u2026] Control Flow while \u2026 do (more are there, please complete this Thahir) \\(\\leftarrow\\) Assignment = Equality (like ==) &gt;, &lt;, \u2026 Comparison <p>eg</p> <pre><code>Algorithm arrayMax(A, n)\n    Input array A of n integers\n    Output maximum element of A\n\n    currentMax &lt;- A[0]\n    for i&lt;-1 to (n-1) do\n        if A[i] &gt; currentMax then\n            currentMax &lt;-A[i]\n\n    return currentMax\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#notations","title":"Notations","text":"<p>All notations take the worst-case scenario</p> <p>Let \\(f(n)\\) be the algorithm for which we are finding the notation</p> Notation Purpose Condition \\(O(\\ g(n) \\ )\\) Upper Bound \\(f(n) \\le c \\cdot g(n)\\) \\(o(\\ g(n) \\ )\\) Strict Upper Bound \\(f(n) &lt; c \\cdot g(n)\\) \\(\\Omega(\\ g(n) \\ )\\) Lower Bound \\(f(n) \\ge c \\cdot g(n)\\) \\(\\omega(\\ g(n) \\ )\\) Strict Lower Bound \\(f(n) &gt; c \\cdot g(n)\\) \\(\\Theta(\\ g(n) \\ )\\) Tight 2-Sided Bounds \\(c_1 \\cdot g(n) \\le f(n) \\le c_2 \\cdot g(n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#big-oh-notation","title":"Big Oh notation","text":"<p>Most commonly-used notation</p> <p>we neglect the constant factors</p> <p>examples:</p> \\[ O(1) &lt; O(\\log n) &lt; O(n) &lt; O(n \\log n) &lt; O(n^2 \\log n) &lt; O(n^2) &lt; \\dots &lt; O(2^n), O(e^n) \\] <pre><code>// O(n)\nfor(int i = 0; i&lt;n; i++)\n\nfor(int i = 0; i&lt;n; i--)\n\n// O(n^2)\nfor(int i = 0; i&lt;n; i++)\n  for(int i = 0; i&lt;n; j++)\n\n// O( n(n+1)/2 ) = O(n^2)\nfor(int i = 0; i&lt;n; i++)\n  for(int j = 0; j&lt;i; j++)\n\n// O(log_2 n)\nfor(int i = 1; i&lt;n; i*=2)\n\nfor(int i = 1; i&lt;n; i/=2)\n\n// O(log_b n)\nfor(int i = 1; i&lt;n; i*=b)\n\nfor(int i = 1; i&lt;n; i/=b)\n\n// O(n log_2 n)\nfor(int i = 0; i&lt;n; i++)\n    for(int i = 0; i&lt;n; i/=2)\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/01_Algorithms/#math-required","title":"Math Required","text":"<ol> <li> <p>Summations</p> </li> <li> <p>Log formulae</p> </li> </ol> \\[ \\begin{aligned} \\log xy  &amp;= \\log x + \\log y \\\\    \\log \\left( \\frac{x}{y} \\right) &amp;= \\log x - \\log y \\\\   \\log x^n &amp;= n \\log x \\end{aligned} \\] <ol> <li> <p>Proof Techniques</p> </li> <li> <p>Basic Probability</p> </li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/02_Data_Structures/","title":"02 Data Structures","text":"Stack Queue Circular Queue Principle LIFO (Last in first out) FIFO (First in First out) FIFO Operations Push, Pop Enqueue, Dequeue Enqueue, Dequeue Insertion \\(t = t+1\\) \\(R = R+1\\) \\(R = (R+1) \\% n\\) Deletion \\(t = t-1\\) \\(F = F+1\\) \\(F = (F+1) \\% n\\) Size(not capacity) \\(t+ 1\\) \\((R - F)\\) \\([n - F+R)] \\% n\\) Overflow \\(t=n-1\\) \\(R=n\\) size \\(= n-1\\) Underflow \\(t=-1\\) \\(F=n\\) size \\(= 0\\) Time Complexity \\(O(1)\\) Space Complexity \\(O(1 \\times \\text{element size})\\) <p>Queue and CQ implementation is different in this course. What we studied in 12<sup>th</sup> grade is actually better, but we have to follow the textbook.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/03_Stacks/","title":"03 Stacks","text":"<p>Data is stored one over the other</p> <p>\\(t\\) is a variable that refers to the top. Initial value is -1 (stack empty)</p> Operation Return Type Function push(element) void inserts element at top position pop() element removes topmost element and returns the removed element top() element returns the topmost element size() int returns no of elements isEmpty() boolean checks if empty <pre><code>Algorithm push(element)\n        if t = n-1\n            overflow\n        t = t + 1\n        a[t] = element\n\nAlgorithm pop()\n        if t = -1\n            underflow\n        t = t - 1\n        return a[t]\n\nAlgorithm size()\n    return (t+1)\n\nAlgorithm top()\n    return a[t]\n\nAlgorithm isEmpty()\n    if t = -1\n        return true\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/03_Stacks/#applications","title":"Applications","text":"<ol> <li>browsing history</li> <li>undo sequence</li> <li>chain of method calls in JVM (java virtual machine)</li> <li>Evaluation and conversion of expressions (infix, post-fix, pre-fix)</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/03_Stacks/#infix-to-postfix","title":"Infix \\(\\to\\) PostFix","text":"Token Stack Output a a + + a c ac - - ac+"},{"location":"2_Core/Data_Structures_%26_Algorithms/03_Stacks/#rules","title":"Rules","text":"Input Output HIN \\(\\leftarrow\\) LCIN HOUT, ALL OUT LIN \\(\\leftarrow\\) HCIN No change"},{"location":"2_Core/Data_Structures_%26_Algorithms/03_Stacks/#priority","title":"Priority","text":"Arithmetic Logical \\(()\\) NOT ^ AND \\(*/\\) OR \\(+-\\) <p>If what is coming in and what is already in have the same priority, then the one inside is considered as the higher priority</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/03_Stacks/#postfix-to-infix","title":"PostFix \\(\\to\\) Infix","text":"<p>Simple rules</p> Token Stack Action 3 3 Push 3 2 3, 2 Push 2 5 3, 2, 5 Push 5 ^ 3, 32 Pop \\(2, 5\\); Push \\(2^5\\) + 35 Pop \\(3, 32\\); Push \\(3+32\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/03_Stacks/#balancing-of-symbols","title":"Balancing of Symbols","text":"<p>We\u2019re basically checking if all the brackets are matched</p> <pre><code>while there are symbols in the expression do\n    if symbol is variable\n        do nothing\n    if symbol is opening\n        push it to the stack\n    if symbol is closing symbol\n        if stack is empty\n            invalid\n        else\n            valid\n\nif stack is empty   // once evaluation of expression is over\n    valid\nelse\n    invalid\n</code></pre> Token Stack Reason"},{"location":"2_Core/Data_Structures_%26_Algorithms/04_Queues/","title":"04 Queues","text":"<p>Front and Rear are two variables</p> Operation Return Type Function enqueue(element) void inserts element at rear position dequeue() element removes frontmost element and returns the removed element front() element returns the frontmost element rear() element returns the rearmost element size() int returns no of elements isEmpty() boolean checks if empty"},{"location":"2_Core/Data_Structures_%26_Algorithms/04_Queues/#college-implementation","title":"College Implementation","text":"<ul> <li>\\(f\\) shows the index of the first element</li> <li>\\(r\\) shows the free-space available to insert the next element   (index immediately after the last inserted element)</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/04_Queues/#linear-queue","title":"Linear Queue","text":"<p>Textbook</p> <pre><code>Algorithm enqueue(o)\n    if r=N then\n        return Error\n    else\n    Q[r]\u2190 o\n    r \u2190 r+1\n\nAlgorithm dequeue()\n    if f=r then\n        return Error\n    else\n        e \u2190 Q[f]\n        Q[f] \u2190 null\n        f \u2190 f+1\n        return e\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/04_Queues/#circular-queue","title":"Circular Queue","text":"<pre><code>Algorithm size()\n    return (n-f+r) mod n\n\nAlgorithm isEmpty()\n    if f = r\n        return true\n    else\n        return false\n\nAlgorithm front()\n    if isEmpty() then\n        return Error\n    else\n        return Q[f]\n\nAlgorithm dequeue()\n    if isEmpty() then\n        return Error\n\n    o \u2190 Q[f]\n    Q[f] \u2190 null\n    f \u2190 (f+1) % n\n\n    return o\n\nAlgorithm enqueue(o)\n    if size()= n-1 then\n        return Error\n    Q[r] \u2190 o\n    r \u2190 (r+1) % n\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/04_Queues/#questions","title":"Questions","text":"Operation \\(A[0]\\) \\(A[1]\\) \\(A[2]\\) F R Exception Output"},{"location":"2_Core/Data_Structures_%26_Algorithms/04_Queues/#applications","title":"Applications","text":"<ul> <li>buffers</li> <li>multi-threading priority</li> <li>data transfer priority</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/","title":"05 Lists","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#linkedlist","title":"LinkedList","text":"<p>better than arrays in some aspects, because</p> <ul> <li>you can add/delete elements in runtime</li> <li>capacity can be modified in runtime</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#logical-address","title":"Logical Address","text":"<p>index in the array, visible to user</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#physical-address","title":"Physical Address","text":"<p>address in the memory</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#singly-linkedlist","title":"Singly LinkedList","text":"<p>consists of</p> <ul> <li>data</li> <li>pointer to the next location</li> </ul> \\[ \\fbox{D} \\fbox{P} \\quad \\fbox{D} \\fbox{P} \\quad \\fbox{D} \\fbox{/} \\] <p>In the above diagram</p> <ul> <li>D = data</li> <li>P = pointer</li> <li>/ = null pointer</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#inserting-at-tail","title":"Inserting at tail","text":"<ol> <li>allocate a new node</li> <li>enter element</li> <li>set node point to null</li> <li>make previous node point to current node</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#removing-at-tail","title":"Removing at tail","text":"<ol> <li>set 2<sup>nd</sup> last node point to null</li> <li>de-allocate the memory (Java takes care of this automatically)</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#implementation","title":"Implementation","text":"<pre><code>class Node\n{\n  int d; // data\n  Node p; // pointer\n\n  Node()\n  {\n    d = 0;\n    p = null;\n  }\n\n  Node(int data, Node ptr)\n  {\n    d = data;\n    p = ptr;\n  }\n  void setLink(Node ptr)\n  {\n    p = ptr;\n  }\n  void setData(int data)\n  {\n    d = data;\n  }\n  Node getLink()\n  {\n    return p;\n  }\n  int getData()\n  {\n    return d;\n  }\n}\n\nclass LinkedList\n{\n  static Node start;\n  static Node end;\n  static int size;\n\n  LinkedList()\n  {\n    start = null;\n    end = null;\n    size = 0;\n  }\n\n  int getSize()\n  {\n    return size;\n  }\n\n  boolean isEmpty()\n  {\n    return (getSize() == 0);\n  }\n\n  void insertAtStart(int val)\n  {\n    Node n = new Node(val, null);\n\n    if(size == 0) // inserting for the first time\n    {\n      end = n;\n    }\n    else\n    {\n      n.setLink(start); // set the link to the previous start\n    }\n\n    start = n; // this is the new start\n    size++;\n  }\n\n  void insertAtEnd(int val)\n  {\n    Node n = new Node(val, null);\n    if(size == 0)\n    {\n      start = n;\n    }\n    else\n    {\n      end.setLink(n);\n    }\n\n    end = n;\n    size++;\n  }\n\n  void insertAtIndex(int val, int index)\n  {\n    Node n = new Node(val, null);\n\n    // traversal\n    Node cur = start; // current node\n\n    int i = 0;\n    while(n != null)\n    {\n      if(i == index)\n      {\n        n.p = cur.p;\n        cur.p = n;\n        break;\n      }\n      else\n      {\n        cur = cur.getLink();\n        i++;\n      }\n\n      size++;\n    }\n\n    void deleteAtIndex(int index)\n    {\n      Node n = start;\n      int i = 0;\n\n      while(n!=null)\n      {\n        if(i == index-1)\n        {\n          n.p = ?????????????\n        }\n        else\n        {\n          n = n.getLink();\n          i++;\n        }\n      }\n\n      size++;\n    }\n    public void display()\n    {\n      Node n = start;\n      while(n!=null)\n      {\n        System.out.println(n.data);\n        n = \n      }\n    }\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#stacked-ll","title":"Stacked LL","text":"<p>implementing stack using linked list, rather than arrays</p> <pre><code>class StackedLL\n{\n  Node top;\n  StackedLL()\n  {\n    top = null;\n  }\n  void push(int data)\n  {\n    insertAtEnd(data);\n  }\n  void pop()\n  {\n        deleteAtEnd();\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#queued-ll","title":"Queued LL","text":"<pre><code>class QueuedLL\n{\n    Node f, r; \n  StackedLL()\n  {\n    f = null;\n    r = null;\n  }\n  void enqueue(int data)\n  {\n    insertAtEnd(data);\n  }\n  void pop()\n  {\n        deleteAtStart();\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#double-linked-list","title":"Double Linked List","text":"<p>DLL Practicals </p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#circular-linked-list","title":"Circular Linked List","text":"<p>Used for dynamic circular queues to schedule tasks in OS</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#single","title":"Single","text":"<p>Tail points to head</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/05_Lists/#double","title":"Double","text":"<p><code>TailFrontPointer</code> points to head</p> <p><code>HeadBackPointer</code> points to tail</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/06_Searching/","title":"06 Searching","text":"<p>returns</p> <ul> <li>index, if found</li> <li>\\(-1\\), if not found</li> </ul> <p>Space Complexity = \\(O(1)\\)</p> Linear Search Binary Search Working Go through each element of array and compare Divide the array into half each time Worst-Case Time Complexity \\(O(n)\\) \\(O(\\log_2 n)\\) Average-Case Time Complexity \\(O(n)\\) \\(O(\\log_2 n)\\) Best-Case Time Complexity \\(O(1)\\) \\(O(1)\\) Requires Sorted List \u274c \u2705 <p>Search Practicals</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/","title":"07 Sorting","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#algorithms","title":"Algorithms","text":"Algorithm Working In-Place Worst Avg Best Bubble elements swapped with bubble \u2705 \\(O(n^2)\\) \\(O(n^2)\\) \\(O(n)\\) Selection swap current element with smallest \u2705 \\(O(n^2)\\) \\(O(n^2)\\) \\(O(n)\\) Merge Recursive Divide-Conquer \u274c \\(O(n \\log_2 n)\\) \\(O(n \\log_2 n)\\) \\(O(n \\log_2 n)\\) Quick Recursive Divide-Conquer Partition array around pivot \u2705 \\(O(n^2)\\) \\(O(n \\log_2 n)\\) \\(O(n \\log_2 n)\\) Insertion key compared with previous elements \u2705 \\(O(n^2)\\) \\(O(n^2)\\) \\(O(n)\\) Bucket bucket of pointers to linked lists \u274c \\(O(n^2)\\) \\(O(n+k)\\) \\(O(n + k)\\) Radix tuple-based \u2705 \\(O \\Big( (T(n) \\Big)\\) Heap Max-heap \u2705 \\(O(n \\log_2 n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#bubble-sort","title":"Bubble Sort","text":"<ul> <li>The \\(j\\) loop acts as a controller for no of times the inner loop runs</li> <li>The \\(i^{th}\\) element acts as the value stored in the \u2018bubble\u2019</li> </ul> <pre><code>for(int j=1; j&lt;=n-1; j++)\n    for(int i=0; i&lt;n-1; i++)\n        if(a[i+1]&lt;a[i])\n        {\n            t = a[i+1];\n            a[i+1] = a[i];\n            a[i] = t;\n        }\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#selection-sort","title":"Selection Sort","text":"<p>useful when memory write is a costly operation</p> <pre><code>for (j=0; j&lt;n-1; j++)\n{\n    m = a[j];\n    pos = j;\n\n    for(i=j+1; i&lt;n; i++)\n        if(a[i]&lt;m)\n        {\n            m = a[i];\n            pos = i;\n        }\n\n    a[pos] = a[j];\n    a[j] = m;\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#merge-sort","title":"Merge Sort","text":"<ol> <li>Divide the list</li> <li>Recursively sort the divisions</li> <li>Merge the divisions</li> </ol> <p>Let \\(p, r, q\\) denote left, right, and middle indices</p> <pre><code>Algorithm mergeSort(A, p, r)\n    if p &lt; r\n    q \u2190 floor((p + r)/2)\n\n    mergeSort (A, p, q) // first half\n    mergeSort (A, q+1, r) // second half\n\n    mergeAsc(A, p, q, r) // or mergeDesc(A, p, q, r)\n\nAlgorithm mergeAsc(A, p, q, r)\n  n1 \u2190 q-p+1\n  n2 \u2190 r-q\n\n  Let L[0\u2026(n1-1)] // int[] l = new int[n1]\n  Let R[0\u2026(n2-1)] // int[] r = new int[n2]\n\n  for i \u2190 0 to n1-1\n      L[i] \u2190 A[p+i]\n  for i \u2190 0 to n2-1\n      R[i] \u2190 A[q+i+1]\n\n  i \u2190 0\n  j \u2190 0\n  k \u2190 p\n\n  while i&lt;n1 and j&lt;n2\n      if L[i] &lt;= R[j] // &gt;= for mergeDesc\n          A[k] \u2190 L[i]\n          i \u2190 i+1\n      else\n          A[k] \u2190 R[j]\n          j \u2190 j+1\n      k \u2190 k+1\n\n  while i&lt;n1\n      A[k] \u2190 L[i]\n      i \u2190 i+1\n      k \u2190 k+1\n\n  while j&lt; n2\n      A[k] \u2190 R[j]\n      j \u2190 j+1\n      k \u2190 k+1\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#quick-sort","title":"Quick Sort","text":"<p>After each iteration, the pivot element will move to its correct position</p> <pre><code>Algorithm quickSort(a, p, r)\n    if(p&lt;r)\n        q = partition(a, p, r)\n        quickSort(a, p, q - 1)  // Before pivot\n        quickSort(a, q + 1, r) // After pivot\n        // the reason q is left out is cuz it is already placed in its correct position\n\nAlgorithm partition(a, p, r)\n    pivot = a[r] // assuming last element as pivot\n    i = p - 1\n\n    for j=p to r-1\n        if a[j] &lt;= pivot\n            i = i+1\n            swap a[i] and a[j]\n\n    swap a[i+1] with pivot\n    return i+1 // this is the new position of the pivot element\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#randomized-quick-sort","title":"Randomized Quick Sort","text":"<p>The randomness reduces the worst-case complexity</p> <pre><code>Algorithm randomizedQuickSort(a, p, r)\n    if(p&lt;r)\n        q = randomizedPartition(a, p, r)\n\n        randomizedQuickSort(arr, p, q - 1)  // Before pivot\n            randomizedQuickSort(arr, q + 1, r) // After pivot\n\nAlgorithm randomizedPartition(a, p, r)\n    i = random(p, r)\n    exchange a[r] with a[i]\n    return partition(a, p, r)\n    // same as regular quick sort partition\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#insertion-sort","title":"Insertion Sort","text":"<pre><code>Algorithm insertionSort(a, n)\n    for i = 1 to n // important\n        key &lt;- a[i]\n        j &lt;- i-1\n        while j&gt;=0 and a[j] &gt; key\n            a[j+1] &lt;- a[j]\n            j &lt;- j-1\n        a[j+1] &lt;- key\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#bucket-sort","title":"Bucket Sort","text":"<p>Complexity goes down, as now you\u2019ll only be sorting subarrays.</p> <pre><code>function bucketSort(array, k) is\n  buckets \u2190 new array of k empty lists\n  M \u2190 the maximum key value in the array\n\n  for i = 1 to length(array) do\n    insert array[i] into buckets[floor(k \u00d7 array[i] / M)]\n\n  for i = 1 to k do\n    insertionSort(buckets[i])\n\n  return the concatenation of buckets[1], ...., buckets[k]\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#textbook","title":"Textbook","text":"<pre><code>Algorithm bucketSort(a, n)\n    buckets &lt;- array of linked lists\n    max &lt;- maximum key value in the array\n\n    for each entry e in S do\n        k &lt;- key of e\n        remove e from s\n        insert e at the end of bucket[k]\n\n    for i&lt;-0 to n-1 do\n        for each entry e in bucket[i] do\n            remove e from b[i]\n            insert e at the end of S\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#radix-sort","title":"Radix Sort","text":"<p>Lexicographical sort</p> <p>Tuple-based sorting for multi-dimensional element.</p> <pre><code>Algorithm radixSort(s)\n    INPUT sequence s of d-tuples\n    OUTPUT sequence s sorted lexicographically\n\n    bucketSort(S, Comparator)\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/07_Sorting/#heap-sort","title":"Heap Sort","text":"<ol> <li>Build a heap (\\(n\\) steps)</li> <li>Repeat (\\(n\\) times)</li> <li>Remove the root node and place in the last index</li> <li>Rebuild max-heap</li> </ol> <pre><code>void heapSort(int[] a)\n{\n  buildHeap(a, a.length);\n\n  for(int i = n-1; i&gt;=0; i--)\n  {\n    swap(a[0], a[i]);\n    maxHeapify(a, i, 0)\n  }\n}\n</code></pre> Sort Direction Heap Type Ascending Max-Heap Descending Min-Heap"},{"location":"2_Core/Data_Structures_%26_Algorithms/08_Hashing/","title":"08 Hashing","text":"<p>Data structure to store key-element pairs. Each key-element pair is called an item.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/08_Hashing/#benefits","title":"Benefits","text":"<ol> <li>data encryption</li> <li>Search optimization, by reducing the search space</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/08_Hashing/#parts","title":"Parts","text":"<ol> <li>Hash Function</li> <li>Bucket/Array (called dictionary/table)</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/08_Hashing/#types","title":"Types","text":"Hashing Hash Function Use Component \\(\\sum x_n\\) Polynomial \\(\\sum x_{n} a^{n}\\) Unique code Division \\(k \\% n\\) Reduce code size \\(k=\\) key (element)\\(n =\\) prime (unique code) MAD \\((a k + b) \\% n\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/08_Hashing/#finding-remainder-in-calculator","title":"Finding Remainder in calculator","text":"<p>Mode &gt; Bases &gt; Decimal</p> <p>Remainder = Dividend - (Divisor * Quotient) = Dividend - (Divisor * \\(\\frac{\\text{Dividend}}{\\text{Divisor}}\\))</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/08_Hashing/#reason","title":"Reason","text":"<p>Dividend = (Divisor * Quotient) + Remainder</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/08_Hashing/#example","title":"Example","text":"\\[ \\begin{aligned} &amp;  10 \\% 3 \\\\ &amp;= 10 - \\left( 3 * \\frac{10}{3} \\right) \\\\ &amp;= 10 - ( 3 * 3 ) \\\\ &amp;= 10 - 9 \\\\ &amp;= 1 \\end{aligned} \\]"},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/","title":"09 Collision Handling","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/#collision-handling","title":"Collision Handling","text":"<p>eliminates collisions in hashing</p> Collision Search Complexity Disadvantage Separate Chaining array with \\(N\\) buckets pointing to linked lists \\(O(n)\\) memory wastage Linear Probing \\((i + j )\\% N\\) \\(O(1)\\) clustering Quadratic Probing \\((i + j^2) \\% N\\) some elements may not be able to stored Double Hashing <p>Problem with probing is the possibility of full bucket</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/#linear-probing-search","title":"Linear Probing Search","text":"<ol> <li> <p>Compute \\(i = h(k)\\)</p> </li> <li> <p>Start at array cell \\(a[i]\\)</p> </li> <li> <p>Probe consecutive locations until</p> </li> </ol> return case present not present empty cell <p>something more</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/#double-hashing","title":"Double Hashing","text":"<p>use a secondary hash function \\(d(k)\\)</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/#hashing","title":"Hashing","text":"\\[ \\begin{aligned} h(k) &amp;= k \\% N \\\\ d(k) &amp;= q - k \\% q \\\\ \\end{aligned} \\] <p>where</p> <ol> <li>\\(q\\) is prime and \\(q &lt; N\\)</li> <li>\\(N\\) is the no of elements</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/#bucket-placement","title":"Bucket Placement","text":"\\[ \\begin{aligned} \\text{index} = \\Big( i+ jd(k) \\Big) \\% N \\\\ i &amp;= h(k) \\\\ j &amp;= 0, 1,\\dots \\end{aligned} \\]"},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/#load-factor","title":"Load Factor","text":"\\[ \\lambda = \\frac{n}{N} \\] <ul> <li>\\(n\\) is the no of keys</li> <li>\\(N\\) is the no of buckets</li> </ul> <p>Load Factor should preferably be \\(\\lambda &lt; 0.75\\), or atleast \\(\\lambda &lt; 1\\)</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/09_Collision_Handling/#rehashing","title":"Rehashing","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/","title":"10 Trees","text":"<p>Hierarchical data structure</p> <p>Very useful for organization of data</p> <p>Used for computing spaced used by a directory\u2019s files and sub-directories.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/#properties","title":"Properties","text":"<p>Refer to Trees in Discrete Structures </p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/#subtrees","title":"Subtrees","text":"<p>Tree consisting of a node, and maybe even descendants</p> <pre><code>flowchart TB\nA --&gt; B &amp; C &amp; sd\nsubgraph sd[Sub Tree]\n    D[\" \"]\nend</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/#height","title":"Height","text":"<p>maxDepth + 1</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/#tree-adt","title":"Tree ADT","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/#tree-using-linked-list","title":"Tree using Linked List","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/#bst-using-linked-list","title":"BST using Linked List","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/10_Trees/#bst-using-arrays","title":"BST using Arrays","text":"<pre><code>Algo\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/","title":"11 Binary Trees","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#binary-tree","title":"Binary Tree","text":"<pre><code>flowchart TB\n\nsubgraph ct[Complete Tree]\n    direction TB\n    p --&gt; q &amp; r\n    q --&gt; s &amp; t\n    r --&gt; u &amp; v\nend\n\nsubgraph pt[Proper Tree]\n    direction TB\n    a --&gt; b &amp; c\n    b --&gt; d &amp; e\nend</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#binary-search-tree","title":"Binary Search Tree","text":"<p>Inorder traversal goes through elements in ascending order</p> <p>Operations Complexity: \\(O(\\log_2 n)\\)</p> <pre><code>flowchart TB\n6 --&gt; 5 &amp; 7\n\n7 --&gt; 0[\" \"] &amp; 8\n8 --&gt; -1[\" \"] &amp; 9\n\n5 --&gt; 3 &amp; 4\n3 --&gt; 1 &amp; 2</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#insertion","title":"Insertion","text":"<p>If the element already exists in BST, then traverse left once and then right once</p> <pre><code>flowchart LR\n\nBefore -.-&gt; After\n\nsubgraph Before\ndirection TB\nz[4] --&gt; x[2] &amp; y[3]\nx --&gt; w[1] &amp; l[\" \"]\nend\n\nsubgraph After\ndirection TB\n4 --&gt; 2 &amp; 3\n2 --&gt; 1 &amp; k[\" \"]\n1 --&gt; -1[\" \"] &amp; a[2]\nend</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#deletion","title":"Deletion","text":"<pre><code>Algorithm delete(w, v)\n    find(w, v)\n\n    if isExternal()\n        remove w\n    if isInternal\n        Find smallest descendant d of w\n        Replace w with d\n        remove d in the leaf node\n</code></pre> <p>For internal node, you can replace \\(w\\) with the</p> <ul> <li>smallest element from right subtree</li> <li>largest element from left subtree</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#depth","title":"Depth","text":"<p>Calculating depth is \\(O\\Big(1 + \\text{depth(v)} \\Big)\\)</p> <pre><code>Algorith depth(v)\n    if isRoot(v)\n        return 0\n    else\n        return 1 + depth( parent(v) )\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#height","title":"Height","text":"<p>Height is kinda like the reverse of depth</p> <pre><code>Algorith depth(v)\n    if isExternal(v)\n        return 0\n    else\n        h = 0\n        for each w children(v) do\n            h = \n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#properties","title":"Properties","text":"Notation Meaning \\(n\\) no of nodes \\(e\\) no of external nodes \\(i\\) no of internal nodes \\(h\\) height \\[ \\begin{aligned} e &amp;= i+1 \\\\ n &amp;= 2e - 1 \\\\ h &amp;\\le i \\\\ h &amp;\\le (n-1)/2 \\end{aligned} \\] \\[ \\begin{aligned} h+1 &amp;\\le e \\le 2^h \\\\ h &amp;\\le i \\le 2^h - 1 \\\\ 2h+1 &amp;\\le i \\le 2^{h+1} - 1 \\\\ one more \\end{aligned} \\] \\[ \\begin{aligned} h &amp;\\ge \\log_2 e \\\\ h &amp;\\ge \\log_2(n_1) -1 \\\\ i &amp;\\le 2^i \\end{aligned} \\]"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#expressions","title":"Expressions","text":"<pre><code>Algorithm printExpression(v)\n    if isInternal(v)\n        print(\"(\")\n        printExpression(leftChild(v))\n    print(v.element())\n    if isExternal(v)\n        printExpression(rightChild(v))\n        print(\")\")\n\nAlgorithm evaluateExpression()\n    something\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#euler-tour-traversal","title":"Euler Tour Traversal","text":"Node Type Traversed Internal Thrice External Once"},{"location":"2_Core/Data_Structures_%26_Algorithms/11_Binary_Trees/#application","title":"Application","text":"<p>Computing number of descendants of a node</p> <pre><code>Algo countDescendants(t, v)\n    count = t.counter\n    somethign\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/","title":"12 Heap","text":"<p>Based on complete binary trees</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#types","title":"Types","text":"Type Property Min-Heap \\(v \\le\\) descendants Max-Heap \\(v \\ge\\) descendants"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#implementation","title":"Implementation","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#array","title":"Array","text":"<ol> <li>Root = 0</li> <li>Left Child = \\(2i+1\\)</li> </ol> <p>Consider a node with index \\(i\\)</p> Node Value Root of entire tree 0 Left Child \\(2i+1\\) Right Child \\(2i+2\\) Parent \\((i-1)/2\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#linked-list","title":"Linked List","text":"\\[ \\fbox{l} \\fbox{data} \\fbox{r} \\fbox{parent} \\notag \\]"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#insertion","title":"Insertion","text":"<ol> <li>Find insertion point</li> <li>Store there</li> <li>Verify heap property</li> <li>if not satisfied, up bubbling</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#deletion","title":"Deletion","text":"<ol> <li>Remove the root element (We cannot remove a particular element)</li> <li>Replace node with the last node of the subtree</li> <li>Verify Heap property</li> <li>if not satisfied, down bubbling</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#heapification","title":"Heapification","text":"<p>up/down heap bubbling</p> <ol> <li>compare 2 elements</li> <li>swap if condition is not satisfied</li> </ol> <pre><code>void maxHeapify(int[] a, int n, int i)\n{\n  int largest = i, // assuming root is the largest\n        l = (2*i) + 1,\n        r = (2*i) + 2;\n\n  if(l&lt;n &amp;&amp; a[l]&gt;a[largest])\n    largest = l;\n\n  if(r&lt;n &amp;&amp; a[r]&gt;a[largest])\n    largest = r;\n\n  if(largest != i)\n    // swap root with largest node\n    swap(a[i], a[largest])\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#applications","title":"Applications","text":"<ol> <li>Heap Sort</li> <li>Order Statistics</li> <li>Priority Queue</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/12_Heap/#priority-queue","title":"Priority Queue","text":"<ul> <li>Max-Heap for max-priority queue</li> <li>Min-Heap for min-priority queue</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/","title":"13 Graphs","text":"<p>Graphs in Discrete Structures </p> <p>Graphs without parallel edges and self loops are called as simple graphs.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#representations","title":"Representations","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#adjacency-matrix-array","title":"Adjacency Matrix (Array)","text":"<p>\\(O(n^2)\\)</p> 9 7 40 60 9 1 0 1 0 7 1 1 1 1 40 0 0 1 1 6 0 1 0 1"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#adjacency-list-linked-list","title":"Adjacency List (Linked List)","text":"<p>More efficient, as \\(O(n)\\)</p> <p>(diagram)</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#applications","title":"Applications","text":"<ol> <li>Networks<ul> <li>Computer Networks</li> <li>Transportation</li> </ul> </li> <li>Computer Vision    Pixels</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#connected-graphcomponents","title":"Connected Graph/Components","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#traversals","title":"Traversals","text":"BFS DFS Breadth First Depth First Queue Stack"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#trick-to-remember","title":"Trick to remember","text":"<p>If the person is a Queue-t, they\u2019ll take your breadth away.</p> <p>If it is a stack, it has a depth associated with it.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#single-source-shortest-path","title":"Single Source Shortest Path","text":"<p>Path from a single start point to every other point in the graph</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#dijkstras-algorithm","title":"Dijkstra\u2019s algorithm","text":"<p>each step has connected components</p> <p>Time complexity: \\(O(v^2)\\)</p> <p>If you use minimum priority queue, it\u2019ll be \\(O(v+e \\log v)\\)</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#disavantages","title":"Disavantages","text":"<p>It requires</p> <ol> <li>Simple graph</li> <li>Connected graph</li> <li>Positive Weights only</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#minimum-spanning-tree","title":"Minimum Spanning Tree","text":"<p>Refer Discrete Structures</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#prims-algorithm","title":"Prim\u2019s Algorithm","text":"<p>Refer Discrete Structures</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/13_Graphs/#kruskals-algorithm","title":"Kruskal\u2019s Algorithm","text":"<p>Refer Discrete Structures</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/","title":"14 Tries","text":"<p>advanced form of tree, mainly used for Text Processing</p> Property of Try Depends on Height 1 + length of longest string Width no of strings"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#types","title":"Types","text":"<p>Consider S = {cat, curry, bat, bees, catalyst}</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#standard","title":"Standard","text":"<p>Stored using regular usual representation of tree</p> <pre><code>flowchart TB\n\n0(( )) --- 1((b)) &amp; 2((c))\n\n1 --- 3((a)) &amp; 4((e))\n\n3 --- 5((t))\n\n4 --- 6((e)) --- 7((s))\n2 --- 8((a)) &amp; 9((u))\n\n8 --- 10((t)) --- 11((a)) --- 12((l)) --- 13((y)) --- 14((s)) --- 15((t))\n\n9 --- 16((u)) --- 17((r)) --- 18((r)) --- 19((y))</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#compressed","title":"Compressed","text":"<p>Stored using compact representation</p> <pre><code>flowchart TB\n1(( )) --- 2((b)) &amp; 3((c))\n\n2 --- 4((at)) &amp; 5((ees))\n\n3 --- 6((at)) &amp; 7((urry))\n\n6 --- 8((alyst))</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#suffix","title":"Suffix","text":"<p>It is a compressed trie of suffixes for every character of a single word. Used for testing DNA sequencing \\((ATCG)\\).</p> <p>Consider <code>BANANA</code></p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#generation","title":"Generation","text":"<pre><code>flowchart TB\n\nroot2(( )) --&gt;\nA &amp; NA &amp; BANANA \n\nA --&gt; NA1[NA] --&gt; NA2[NA]\nNA --&gt; NA3[NA]</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#addressing","title":"Addressing","text":"<pre><code>flowchart TB\nsomething</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#encoding-trie","title":"Encoding Trie","text":"<p>Left is 0. Right is 1.</p> <p>Leaves store characters.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#huffman-tree","title":"Huffman Tree","text":"<p>Uses huffman encoding</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#aim","title":"Aim","text":"<p>Assign the minimum key to the character with the maximum frequency.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#steps","title":"Steps","text":"<ol> <li> <p>Calculate frequency of each character for input string</p> </li> <li> <p>Build tree, by grouping based on minimum frequencies</p> </li> <li> <p>Generate key/code of tree, taking left as 0 and right as 1</p> </li> <li> <p>Calculate the average no of code/key using</p> </li> </ol> \\[ \\text{Average Code Size} = \\frac{ \\sum\\limits_i \\text{Frequency}_i * \\text{No of Bits}_i }{ \\sum\\limits_i \\text{Frequency}_i } \\]"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#example","title":"Example","text":"<p>Consider input string <code>abracadabra</code></p> Letter Frequency a 5 b 2 c 1 d 1 r 2 <pre><code>flowchart TB\n11 --- |0| 1[a]\n11 --- |1| 6\n\n6 --- |0| 2\n6 --- |1| 4\n\n2 --- |0| c\n2 --- |1| d\n\n4 --- |0| b\n4 --- |1| r</code></pre> Letter Code a 0 b 110 c 100 d 101 r 111 <p>Average code size = 2.09</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/14_Tries/#compact-representation","title":"Compact Representation","text":"<p>Each string is added into an array of strings.</p> <p>Each node of the tree contains <code>(string_index, substring_start_index, substring_end_index)</code></p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/15_AVL/","title":"15 AVL","text":"<p>Balanced BST that reduce the worst-case time complexity from linear to logarithmic.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/15_AVL/#balance-factor","title":"Balance Factor","text":"\\[ BF = \\text{Height of left subtree} - \\text{Height of right subtree} \\] <p>Leaves are always balanced, as they have a balanced factor of 0.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/15_AVL/#balanced-tree","title":"Balanced Tree","text":"<p>Tree with balanced factor \\(\\{ -1, 0, +1 \\}\\)</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/15_AVL/#unbalanced-oversettextrotationlongrightarrow-balanced","title":"Unbalanced \\(\\overset{\\text{rotation}}{\\longrightarrow}\\) Balanced","text":"<p>Rotation Mechanism</p> Unbalanced Type of Rotation LL RR RR LL LR LR RL RL <pre><code>flowchart\n\nsubgraph Balanced\ndirection TB\np((2)) --- q((1)) &amp; r((3))\nend\nsubgraph LR Unbalanced\ndirection TB\na((3)) --- b((1)) &amp; c(( ))\n\nb --- d(( )) &amp; e((2))\nend\nsubgraph LL Unbalanced\ndirection TB\nf((3)) --- g((2)) &amp; h(( ))\n\ng --- i((1)) &amp; j(( ))\nend\n\nsubgraph RR Unbalanced\ndirection TB\nk((3)) --- l(( )) &amp; m((4))\n\nm --- n(( )) &amp; o((5))\nend\n\nsubgraph RL Unbalanced\ndirection TB\ns((3)) --- t(( )) &amp; u((5))\n\nu --- v((4)) &amp; w(( ))\nend</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/15_AVL/#time-complexity","title":"Time Complexity","text":"Operation Compexity Restructure \\(O(1)\\) Search \\(O(\\log_2 n)\\) Insertion \\(O(\\log_2 n)\\) Deletion \\(O(\\log_2 n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/16_B_Tree/","title":"16 B Tree","text":"<p>Generalized and ordered BST, where each node contains children as linked list, rather than just elements.</p> <p>It is used for data storage and access in hard disks.</p> <p></p> Feature Formula Order \\(n\\) Max No of Children \\(n\\) Max No of Keys \\(n-1\\) Middle element \\(\\left \\lceil \\dfrac{n}{2} \\right \\rceil\\)<sup>th</sup> element <p>There is no minimum for B Tree.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/16_B_Tree/#direction","title":"Direction","text":"<p>It is grown in an upward direction, because</p> <ul> <li>insertion occurs only in the leaf nodes</li> <li>ensure balanced tree (as it will be hard to balance once the B Tree is already built)</li> </ul>"},{"location":"2_Core/Data_Structures_%26_Algorithms/16_B_Tree/#limitations","title":"Limitations","text":"<p>It has high space complexity, as many locations are empty.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/16_B_Tree/#complexity","title":"Complexity","text":"Operation Compexity Restructure \\(O(1)\\) Search \\(O(\\log_2 n)\\) Insertion \\(O(\\log_2 n)\\) Deletion \\(O(\\log_2 n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/17_Tensors/","title":"Tensors","text":"<p>(Not for exam)</p> <p>Tensors are \\(n\\)-dimensional arrays, which keep track of the gradient of each element in the array.</p> <p>They are optimized for parallel computing and GPU-utilization, but more memory-intensive than regular arrays.</p> <p>In lazy mode, the operations are not executed until required</p> <p>Each tensor has</p> <ul> <li>ID</li> <li>List of inputs</li> <li>operation performed</li> <li>cached_data_output</li> </ul> <p>Tracking gradients is expensive, so</p> <pre><code>x = ndl.Tensor(\n    [1],\n  dtype = \"float32\"\n)\n\nsum = 0\nfor i in range(100):\n  sum += (x**2).detach()\n</code></pre> <p>Not using <code>detach()</code> will result in tracking the inputs and operations performed unnecessarily</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/17_Tensors/#broadcasting","title":"Broadcasting","text":"<p>Efficient, as it does not copy any data</p> <p>Rather than repeating the same value multiple times for matrix multiplication</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/","title":"00 Practice Lab","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#java-file-handling","title":"Java File Handling","text":"<pre><code>import java.io.File;\nimport java.io.FileNotFoundException;\nimport java.io.PrintWriter;\nimport java.util.Scanner;\npublic class f {\n  public static void main(String[] args) throws\n  FileNotFoundException {\n    //Scanner method of reading files (Since JDK 4)\n    //Open file for reading contents\n    System.out.println( &amp; quot; Your file should be placed at: &amp; quot; +\n      System.getProperty( &amp; quot; user.dir &amp; quot;));\n    Scanner readMyFile = new Scanner(new File(args[0]));\n    //Open file for writing content\n    System.out.println( &amp; quot; Output file will be created at: &amp; quot; +\n      System.getProperty( &amp; quot; user.dir &amp; quot;));\n    PrintWriter writeToMyFile = new PrintWriter(new File(args[1]));\n    while (readMyFile.hasNext()) {\n      // Read the content of input file\n      // Read 3 integers\n      int a = readMyFile.nextInt();\n      int b = readMyFile.nextInt();\n      int c = readMyFile.nextInt();\n      //Read the string\n      String name = readMyFile.next(); //not\n      readMyFile.nextLine()\n      //Read a float\n      float f = readMyFile.nextFloat();\n      //Display the content of input file\n      System.out.printf( &amp; quot; % d % d % d % s % f % n &amp; quot;, a, b, c, name, f);\n      //You can also use System.out.print to display one data\n      type at a time.\n      /*\n      * %n is a new line character appropriate to the\n      platform running the application.\n      * You should always use %n, rather than \\n.\n      */\n      //Write data to file\n      int result = (a * a) + (b * b) + (c * c);\n      System.out.format( &amp; quot;\n        (a * a + b * b + c * c) = % d % s % f % n &amp; quot;,\n        result, name, f);\n      writeToMyFile.format( &amp; quot;\n        (a * a + b * b + c * c) = % d % s %\n        f % n &amp; quot;, result, name, f);\n      /*\n\n      6\n\n      * Again writeToMyFile.print can be use to write one\n      data type at a type.\n      */\n    }\n    readMyFile.close();\n    writeToMyFile.close();\n  }\n}\n/* now try to read inputs for these fields from keyboard */\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#programming-language","title":"Programming Language","text":"<p>Both the below programs were made using Java.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#question-1","title":"Question 1","text":"<p>Write a program in your favorite programming language (C/C++/JAVA) to determine if a given Input Number is PERFECT or DEFICIENT or ABUNDANT. Assume that the input number is in the range 1 \u2013 32768 (inclusive at both sides).</p> <p>A number (consider only positive integers) is perfect if it is equal to the sum of its proper divisors. For example, 6 is a perfect number, because its proper divisors are 1, 2, and 3(note that we do not include the number itself), and 1+2+3=6.</p> <p>A number is de\ufb01cient if the sum of its proper divisors is less than the number. For example, 8 is de\ufb01cient, because its proper divisors are 1, 2, and 4, and 1 + 2 + 4 = 7, which is less than 8.</p> <p>A number is abundant if the sum of its proper divisors is greater than the number. For example, 12 is abundant, because 1 + 2 + 3 + 4 + 6 = 16, which is greater than 12.</p> <p>Write a program that prompts the user for a number, then determines whether the number is perfect, de\ufb01cient, or abundant. Your program should continue to prompt the user for numbers until a 0 is provided as input. An example session:</p> <pre><code>Enter an integer (0 to quit): 7\n7 is deficient.\nEnter an integer (0 to quit): 12\n12 is abundant.\nEnter an integer (0 to quit): 6\n6 is perfect.\nEnter an integer (0 to quit): 0\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#algorithm","title":"Algorithm","text":"<ol> <li>Input number</li> <li>Find factors and their sum</li> <li> <p>Check the various cases. If sum of factors is</p> </li> <li> <p>\\(=\\) number, then perfect</p> </li> <li>\\(&lt;\\) number, then deficient</li> <li>\\(&gt;\\) number, then abundant</li> <li>Print the result</li> </ol> <pre><code>pseudocode\n</code></pre> <p>Time complexity is \\(O(n)\\), because of the <code>for</code> loop.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#code","title":"Code","text":"<pre><code>import java.util.Scanner;\n\nclass q\n{\n  public static void checker(int num)\n  {\n    int factorSum = 0;\n\n    for(int i = 1; i&lt;num; i++)\n      if(num % i == 0)\n        factorSum += i;\n\n    String text = \"\";\n    if (factorSum == num)\n      text = \"Perfect\";\n    else if (factorSum &lt; num)\n      text = \"Deficient\";\n    else if (factorSum &gt; num)\n      text = \"Abundant\";\n    System.out.println( num + \" is \" + text + \" number\");\n  }\n  public static void main( String args[] )\n  {\n    Scanner inp = new Scanner( System.in );\n\n    checker(7);\n    checker(12);\n    checker(6);\n\n    System.out.println(\"\\nInput a number of your wish:\");\n    int input = inp.nextInt();\n    checker(input);\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#inputoutput","title":"Input/Output","text":"<pre><code>7 is Deficient number\n12 is Abundant number\n6 is Perfect number\n\nInput a number of your wish:\n18\n18 is Abundant number\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#question-2","title":"Question 2","text":"<p>Write a program that inputs two fractions in the form a/b and c/d, and outputs their sum in the form p/q cancelled down to its simplest form. Here, you can read the values of a,b,c,d as input from keyboard and show the output in the simplest form. i.e. numerator / denominator.</p> <pre><code>Input:\u00a05/6\u00a01/10 Output: 14/15\nInput:\u00a02/3\u00a04/6 Output: 4/3\nInput: 1/2\u00a03/4 Output: 5/4\nInput: 1/2\u00a01/2 Output: 1/1\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#algorithm_1","title":"Algorithm","text":"<ol> <li>Input numbers</li> <li>Obtain the numerator and denominator by cross-multiplication</li> <li>Simplify the numerator and denominator</li> <li>Print the result</li> </ol> <pre><code>pseudocode\n</code></pre> <p>Time Complexity is \\(O(n)\\), because of the <code>for</code> loop.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#code_1","title":"Code","text":"<pre><code>import java.util.Scanner;\n\nclass q02 {\n  public static void checker(int a, int b, int c, int d)\n  {\n    int p = a*d + b*c,\n      q = b*d;\n\n    int pSim = p,\n      qSim = q;\n\n    for(int i = Math.min(p, q); i&gt;=2; i--)\n      if(p%i == 0 &amp;&amp; q%i == 0)\n      {\n        pSim = p/i;\n        qSim = q/i;\n        break;\n      }\n\n    System.out.println(\"\\n\" + pSim + \"/\" + qSim);\n  }\n  public static void main(String[] args) {\n    Scanner inp = new Scanner( System.in );\n    int a, b, c, d;\n    System.out.println(\"\\nEnter your values\");\n    System.out.println(\"a\"); a = inp.nextInt();\n    System.out.println(\"b\"); b = inp.nextInt();\n    System.out.println(\"c\"); c = inp.nextInt();\n    System.out.println(\"d\"); d = inp.nextInt();\n\n    checker(a, b, c, d);\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/00_Practice_Lab/#inputoutput_1","title":"Input/Output","text":"<pre><code>Enter your values\na\n5\nb\n6\nc\n1\nd\n10\n\n14/15\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/","title":"01 Stacks","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#question","title":"Question","text":"<p>Write a C/C++/JAVA program to perform the following actions on a STACK implemented using arrays / array of structures:</p> <ol> <li>Implement PUSH operation in a STACK for N (N &gt;= 5) STUDENT RECORDS. Each STUDENT RECORD should store &lt;IDNO, NAME, DOB,CGPA&gt;. You have to read each STUDENT record from an input file \u201cstudentin.dat\u201d stored locally in your directory and the PUSH it into the stack, one at a time. (You can use vi editor to create input data file. Make sure that the input data file contains at least 5 records).</li> <li>Implement the POP operation for the STACK in LIFO order and display all the records on the standard output (screen). Also, write the output results into an external file \u201cstudentout.dat\u201d.</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#algorithm","title":"Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#pseudocode","title":"Pseudocode","text":"<pre><code>Algorithm push\n        INPUT read student records from file\n        OUTPUT student records to stack\n\n        while inputFile has records\n      if top = n\n        overflow\n      else\n        top &lt;- top + 1\n        studentArray[top] &lt;- record\n\nAlgorithm pop\n        INPUT student records from stack\n        OUTPUT write student records to file\n\n        while studentArray has records\n        print record\n        write to outputFile\n        top &lt;- top - 1\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#time-complexity","title":"Time Complexity","text":"Algorithm Complexity push \\(O(n)\\) pop \\(O(n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#source-code","title":"Source Code","text":"<pre><code>// Ahmed Thahir 2020A7PS0198U\n\npackage Programs;\n\nimport java.io.File;\nimport java.io.FileNotFoundException;\nimport java.io.PrintWriter;\nimport java.util.Scanner;\n\npublic class p01 \n{\n  static int top = -1;\n  static int capacity = 10;\n  static String[] students = new String[capacity];\n\n  public static void push() throws FileNotFoundException\n  {\n    String inputFile = \"h:\\\\\nMy Drive\\\\\nNotes\\\\\nSem 4\\\\\n02 DSA\\\\\nPracticals\\\\\nPrograms\\\\\n\"\n      + \"studentin.dat\";\n    Scanner readMyFile = new Scanner( new File(inputFile) );\n\n    while (readMyFile.hasNext()) \n    {\n      if(top != capacity)\n      {\n        top = top + 1;\n        students[top] = readMyFile.nextLine();\n      }\n    }\n\n    readMyFile.close();\n  }\n\n  public static void pop() throws FileNotFoundException\n  {\n    String outputFile = \"h:\\\\\nMy Drive\\\\\nNotes\\\\\nSem 4\\\\\n02 DSA\\\\\nPracticals\\\\\nPrograms\\\\\n\"\n      + \"studentout.dat\";\n    PrintWriter writeToMyFile = new PrintWriter( new File(outputFile) );\n\n    while(top != -1)\n    {\n      System.out.println(students[top]);\n      writeToMyFile.format(\"%s \\n\", students[top]);\n\n      top = top-1;\n    }\n\n    writeToMyFile.close();\n  }\n\n  public static void main(String[] args) throws FileNotFoundException\n  {\n    push();\n    pop();\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#test-cases","title":"Test Cases","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#input","title":"Input","text":"<pre><code>2021A7PS001 AAAA 1/1/2000 7.50\n2021A7PS002 BBBB 2/1/2000 9.20\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS005 EEEE 5/1/2000 9.25\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/01_Stacks/#output","title":"Output","text":"<pre><code>2021A7PS005 EEEE 5/1/2000 9.25\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS002 BBBB 2/1/2000 9.20\n2021A7PS001 AAAA 1/1/2000 7.50\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/","title":"02 Circular Queues","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#question","title":"Question","text":"<p>Write a C/C++ program to perform the following actions on a QUEUE implemented using arrays / array of structures / array-lists (which is viewed circularly):</p> <ol> <li>Implement ENQUEUE(o) operation in a QUEUE for N (N &gt;= 5) STUDENT RECORDS. Each STUDENT RECORD should store <code>&lt;IDNO, NAME, DOB, CGPA&gt;</code>. You have to read each STUDENT record from an input file \u201cstudentin.dat\u201d stored locally in your directory and insert it into the queue, one at a time. (You can use vi editor to create input data file. Make sure that the input data file contains at least 5 records).</li> <li>Implement the DEQUEUE() operation for the QUEUE in FIFO order and display all the records on the standard output (screen display). Also, write the output results into an external file \u201cstudentout.dat\u201d.</li> <li>Display the student names (NAME field) whose CGPA is less than 9.</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#algorithm","title":"Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#pseudocode","title":"Pseudocode","text":"<pre><code>Algorithm enqueue\n        INPUT read student records from file\n        OUTPUT student records to queue\n\n        while inputFile has records\n            if (F = 0 and R = n-1) or (F=R+1)\n                overflow\n            else if (F = -1 and R = -1)\n                F &lt;- 0\n                R &lt;- 0\n            else if (R = n-1)\n                R &lt;- 0\n            else\n                R &lt;- R+1\n\n            a[R] &lt;- element\n\nAlgorithm dequeue\n        INPUT student records from queue\n        OUTPUT write student records to file\n\n        while studentArray has records\n                record &lt;- a[F]\n                print record\n                write to outputFile\n\n                F &lt;- F+1\n\nAlgorithm displayNames\n        INPUT student records from queue\n        OUTPUT write student records to file\n\n        while studentArray has records\n                record &lt;- a[F]\n\n                if(cgpa &lt; 9.0)\n                    print name\n\n                F &lt;- F+1\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#time-complexity","title":"Time Complexity","text":"Algorithm Complexity enqueue \\(O(n)\\) dequeue \\(O(n)\\) displayNames \\(O(n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#source-code","title":"Source Code","text":"<pre><code>// Ahmed Thahir 2020A7PS0198U\n\npackage Programs;\nimport java.io.File;\nimport java.io.FileNotFoundException;\nimport java.io.PrintWriter;\nimport java.util.Scanner;\n\npublic class p02\n{\n  static int f, r, n = 10;\n  static String[] students = new String[n];\n\n  public static void enqueue() throws FileNotFoundException\n  {\n    f = -1;\n    r = -1;\n\n    String inputFile = \"h:\\\\\nMy Drive\\\\\nNotes\\\\\nSem 4\\\\\n02 DSA\\\\\nPracticals\\\\\nPrograms\\\\\n\"\n      + \"studentin.dat\";\n    Scanner readMyFile = new Scanner( new File(inputFile) );\n\n    while (readMyFile.hasNext()) \n    {\n      if( (f == 0 &amp;&amp; r == n-1) || f == r+1 )\n      {\n        // overflow\n      }\n      else if (f == -1 &amp;&amp; r == -1)\n      {\n        f = 0;\n        r = 0;\n      }\n      else if (r == n-1)\n        r = 0;\n      else\n        r++;\n\n      students[r] = readMyFile.nextLine();\n    }\n\n    readMyFile.close();\n  }\n\n  public static void dequeue() throws FileNotFoundException\n  {\n    String outputFile = \"h:\\\\\nMy Drive\\\\\nNotes\\\\\nSem 4\\\\\n02 DSA\\\\\nPracticals\\\\\nPrograms\\\\\n\"\n      + \"studentout.dat\";\n    PrintWriter writeToMyFile = new PrintWriter( new File(outputFile) );\n\n    while( !(f == -1 &amp;&amp; r == -1) )\n    {\n      System.out.println(students[f]);\n      writeToMyFile.format(\"%s \\n\", students[f]);\n\n      if (F == n-1)\n                F = 0;\n      else if (F == R)\n      {\n        F = -1;\n        R = -1;\n      }\n      else\n                F = F+1;\n    }\n\n    writeToMyFile.close();\n  }\n\n  public static void displayNames() throws FileNotFoundException\n  {\n    enqueue();\n\n    while( !(f == -1 &amp;&amp; r == -1) )\n    {\n      String[] strArray = students[f].split(\" \");  \n      float cgpa = Float.parseFloat( strArray[strArray.length -1] );\n      String name;\n\n      if(cgpa &lt; 9f)\n      {\n        name = strArray[1];\n        System.out.println(name);\n      }\n\n      if (F == n-1)\n                F = 0;\n      else if (F == R)\n      {\n        F = -1;\n        R = -1;\n      }\n      else\n                F = F+1;\n    }\n  }\n\n  public static void main(String[] args) throws FileNotFoundException\n  {\n    enqueue();\n    dequeue();\n    displayNames();\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#test-cases","title":"Test Cases","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#input","title":"Input","text":"<pre><code>2021A7PS001 AAAA 1/1/2000 7.50\n2021A7PS002 BBBB 2/1/2000 9.20\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS005 EEEE 5/1/2000 9.25\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/02_Circular_Queues/#output","title":"Output","text":"<pre><code>2021A7PS001 AAAA 1/1/2000 7.50\n2021A7PS002 BBBB 2/1/2000 9.20\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS005 EEEE 5/1/2000 9.25\nAAAA\nDDDD\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/","title":"03 DLL","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#question","title":"Question","text":"<p>Write a C/C++/JAVA program to perform the following actions on a DOUBLY LINKED LIST:</p> <ol> <li>Implement insertLast(o) operation in a DLL for N (say N= 5) RECORDS of DATA SET (Student Record). You have to read each record of data set from an input file \u201cstudentin.dat\u201d stored locally in your directory and the insert it into the DLL, one at a time. (You can use vi/joe editor to create input data file. Make sure that the input data file contains at least 5 records).</li> <li>Implement the remove(p) operation for the DLL for any one record, by interactively asking for its position p from standard input (keyboard).</li> <li>Traverse the List in forward direction (beginning to end) and display all records on the standard output (display).</li> <li>Traverse the List in reverse direction (end to beginning) and display all records on the standard output (display).</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#algorithm","title":"Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#pseudocode","title":"Pseudocode","text":"<pre><code>Algorithm insertLast(d)\n    INPUT read student records from file\n    OUTPUT student records to DLL\n\n    if size = 0\n        start = inserted element\n    else\n        inserted element's back link = existing element\n        existing element's front link = inserted element\n\n    end = n\n    size = size + 1\n\nAlgorithm remove(p)\n    INPUT student records of DLL\n    INPUT position of element to be removed\n    OUTPUT deleted element\n\n    if size = 0\n        empty list\n    else if p &gt; size\n        position out of bounds\n    else\n        current element = start\n        while current element is not null\n        if current element index = p\n            Print deleted element\n            previous element's front link = next element\n            next element's back link = previous element\n\n            current element's back and front link = null\n        else\n            current element = current element's front link\n            increment i\n\nAlgorithm traverseForward\n    INPUT student records of DLL\n    OUTPUT forward traversed list\n\n    if size = 0\n        List Empty\n    else\n        current element = start\n        while current element is not null\n            Print current element\n            current element = current element's front link\n\nAlgorithm traverseBackward\n    INPUT student records of DLL\n    OUTPUT backward traversed list\n\n    if size = 0\n        List Empty\n    else\n        current element = end\n        while current element is not null\n            Print current element\n            current element = current element's back link\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#time-complexity","title":"Time Complexity","text":"Algorithm Complexity insertLast \\(O(n)\\) remove \\(O(n)\\) traverseForward \\(O(n)\\) traverseBackward \\(O(n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#extra-note","title":"Extra Note","text":"<p>I was initially thinking of assigning an index for each node, but that will increase the amount of steps for each process, because the processor has to update the index of elements any time a change happens to the list.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#source-code","title":"Source Code","text":"<pre><code>// Ahmed Thahir 2020A7PS0198U\n\npackage Programs;\nimport java.io.File;\nimport java.io.FileNotFoundException;\nimport java.util.Scanner;\n\nclass Node\n{\n  Node bp; // back pointer\n  String d; // data\n  Node fp; // front pointer\n\n  Node()\n  {\n    bp = null;\n    fp = null;\n  }\n\n  Node(String val)\n  {\n    this();\n    d = val;\n  }\n\n  Node(Node bptr, String data, Node fptr)\n  {\n    bp = bptr;\n    d = data;\n    fp = fptr;\n  }\n\n  void setBp(Node ptr)\n  {\n    bp = ptr;\n  }\n\n  void setFp(Node ptr)\n  {\n    fp = ptr;\n  }\n\n  void setData(String data)\n  {\n    d = data;\n  }\n\n  Node getBp()\n  {\n    return bp;\n  }\n\n  String getData()\n  {\n    return d;\n  }\n\n  Node getFp()\n  {\n    return fp;\n  }\n}\n\nclass DLL // Double Linked List\n{\n  static Node start;\n  static Node end;\n  static int size;\n\n  DLL()\n  {\n    start = null;\n    end = null;\n    size = 0;\n  }\n\n  public static void insertLast(String d)\n  {\n    Node n = new Node(d);\n    if(size == 0)\n    {\n      start = n;\n    }\n    else\n    {\n      n.setBp(end); // link new node's back to the existing node\n      end.setFp(n); // link existing node's front to the new node\n    }\n\n    end = n;\n    size++;\n  }\n\n  public static void remove(int pos)\n  {\n    int index = pos-1;\n\n    if(size == 0)\n    {\n      System.out.println(\"Empty\");\n    }\n    else if (index &gt;= size)\n    {\n      System.out.println(\"Index out of bounds\");\n    }\n    else\n    {\n      Node n = start;\n      int i = 0;\n      while( n!=null )\n      {\n        if(i == index)\n        {\n          System.out.println( \"Deleting: \" + n.getData() );\n\n          // link the previous and next one with each other\n          Node prev = n.getBp();\n          Node next = n.getFp();\n          prev.setFp(next);\n          next.setBp(prev);\n\n          // unlink the deleted node\n          n.setBp(null);\n          n.setFp(null);\n\n          break;\n        }\n        else\n        {\n          n = n.getFp();\n          i++;\n        }\n      }\n    }\n  }\n\n  public static void traverseForward()\n  {\n    if(size == 0)\n    {\n      System.out.println(\"List Empty\");\n    }\n    else\n    {\n      System.out.println(\"\\n\" + \"Traversing Forward\");\n\n      Node n = start;\n      while( n!=null )\n      {\n        System.out.println( n.getData() );\n        n = n.getFp();\n      }\n    }\n  }\n\n  public static void traverseBackward()\n  {\n    if(size == 0)\n    {\n      System.out.println(\"List Empty\");\n    }\n    else\n    {\n      System.out.println(\"\\n\" + \"Traversing Backward\");\n\n      Node n = end;\n      while( n!=null )\n      {\n        System.out.println( n.getData() );\n        n = n.getBp();\n      }\n    }\n  }\n}\n\npublic class p03\n{\n  static String rel = \"h:\\\\\nMy Drive\\\\\nNotes\\\\\nSem 4\\\\\n02 DSA\\\\\nPracticals\\\\\nPrograms\\\\\n\";\n  static String inputFile = rel +\n    \"studentin.dat\";\n  static String outputFile = rel +\n    \"studentout.dat\";\n\n  DLL students = new DLL();\n\n  public static void main(String[] args) throws FileNotFoundException\n  {\n    Scanner readMyFile = new Scanner( new File(inputFile) );\n    System.out.println(\"Reading from File\");\n    while (readMyFile.hasNext()) \n    {\n      String o = readMyFile.nextLine();\n      System.out.println(o);\n      DLL.insertLast(o);\n    }\n    readMyFile.close();\n\n    System.out.println(\"\\n\" + \"Enter position (1, 2, ...) to remove\");\n    Scanner inp = new Scanner(System.in);\n    int p = inp.nextInt();\n    inp.close();\n    DLL.remove(p);\n\n    DLL.traverseForward();\n    DLL.traverseBackward();\n  }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#test-cases","title":"Test Cases","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#input","title":"Input","text":"<pre><code>2021A7PS001 AAAA 1/1/2000 7.50\n2021A7PS002 BBBB 2/1/2000 9.20\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS005 EEEE 5/1/2000 9.25\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/03_DLL/#output","title":"Output","text":"<pre><code>Reading from File\n2021A7PS001 AAAA 1/1/2000 7.50\n2021A7PS002 BBBB 2/1/2000 9.20\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS005 EEEE 5/1/2000 9.25\n\nEnter position (1, 2, ...) to remove\n2\nDeleting: 2021A7PS002 BBBB 2/1/2000 9.20\n\nTraversing Forward\n2021A7PS001 AAAA 1/1/2000 7.50\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS005 EEEE 5/1/2000 9.25\n\nTraversing Backward\n2021A7PS005 EEEE 5/1/2000 9.25\n2021A7PS004 DDDD 4/1/2000 8.75\n2021A7PS003 CCCC 3/1/2000 9.60\n2021A7PS001 AAAA 1/1/2000 7.50\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/04_Search/","title":"04 Search","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/04_Search/#question","title":"Question","text":"<p>Write a C/C++/JAVA program to perform the following: 1. Initialize 10000 unique, positive and consecutive integers whose values are in the range \\([0-9999]\\), and store them in serial/ascending order in an array <code>A[10000]</code>. i.e. you are already initializing the array in the sorted order using an iterative statement. 2. Implement the Linear Search and Binary Search algorithms and DISPLAY the <code>&lt;position in the array, search_time&gt;</code> for the following test cases: \\(5000, 9997, 50000\\)</p> <p>(assume index of the first element in array is 0)</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/04_Search/#algorithm","title":"Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/04_Search/#pseudocode","title":"Pseudocode","text":"<pre><code>Algorithm linearSearch()\n    OUTPUT position of data\n\n    pos &lt;- -1\n    for i&lt;-0 to (n-1) do\n        if a[i] = data\n            pos = i\n    return pos\n\nAlgorith binarySearch()\n    OUTPUT position of searched element\n\n    pos &lt;- -1\n    f &lt;- 0\n    l &lt;- n-1\n\n    while f &lt;= l\n        if a[m] &lt; data\n            f = m+1\n        else if a[m] &gt; data\n        l = m-1\n    else\n        pos = i\n  return pos\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/04_Search/#time-complexity","title":"Time Complexity","text":"Algorithm Complexity linearSearch \\(O(n)\\) binarySearch \\(O(\\log_2 n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/04_Search/#source-code","title":"Source Code","text":"<pre><code>// Ahmed Thahir 2020A7PS0198U\npackage Programs;\nclass p04\n{\n    static int n = 10000;\n    static int n1 = 5000,\n        n2 = 9997,\n        n3 = 50000;\n    static int[] a = new int[n];\n\n    static float linearSearchTime, binarySearchTime;\n\n    public static void initialize()\n    {\n        for(int i = 0; i&lt;n; i++)\n        a[i] = i;\n    }\n\n    public static int linearSearch(int d)\n    {\n        int pos = -1;\n        long startTime = System.nanoTime();\n\n        for(int i = 0; i&lt;n; i++)\n            if(a[i] == d)\n            {\n                pos = i;\n                break;\n            }\n\n        long endTime = System.nanoTime();\n        linearSearchTime = (endTime - startTime)/1000f;\n        return pos;\n    }\n\n    public static int binarySearch(int d)\n    {\n        int pos = -1;\n        long startTime = System.nanoTime();\n\n        int f = 0, l = n-1, m;\n        while(f &lt;= l)\n        {\n            m = (f+l)/2;\n\n            if(a[m] &lt; d)\n            f = m + 1;\n            else if ( a[m] &gt; d)\n            l = m - 1;\n            else // a[m] == d\n            {\n                pos = m;\n                break;\n            }\n        }\n\n        long endTime = System.nanoTime();\n        binarySearchTime = (endTime - startTime)/1000f;\n\n        return pos;\n    }\n\n    public static void linearSearchDisplay()\n    {\n        System.out.println( \n        \"Linear Search \\n\" +\n        \"Input \\t Index \\t Search Time(microsec) \\n\" +\n        n1 + \"\\t\" + linearSearch(n1) + \"\\t\" + linearSearchTime + \"\\n\" +\n        n2 + \"\\t\" + linearSearch(n2) + \"\\t\" + linearSearchTime + \"\\n\" +\n        n3 + \"\\t\" + linearSearch(n3) + \"\\t\" + linearSearchTime + \"\\n\"\n        );\n    }\n\n    public static void binarySearchDisplay()\n    {\n        System.out.println(\n        \"Binary Search \\n\" +\n        \"Input \\t Index \\t Search Time(microsec) \\n\" +\n        n1 + \"\\t\" + binarySearch(n1) + \"\\t\" + binarySearchTime + \"\\n\" +\n        n2 + \"\\t\" + binarySearch(n2) + \"\\t\" + binarySearchTime + \"\\n\" +\n        n3 + \"\\t\" + binarySearch(n3) + \"\\t\" + binarySearchTime + \"\\n\"\n        );\n    }\n\n    public static void main(String[] args)\n    {\n        initialize();\n        linearSearchDisplay();\n        binarySearchDisplay();\n    }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/04_Search/#test-cases","title":"Test Cases","text":"<pre><code>Linear Search \nInput   Index   Search Time(microsec) \n5000    5000    108.2\n9997    9997    221.8\n50000   -1      220.7\n\nBinary Search \nInput   Index   Search Time(microsec) \n5000    5000    2.1\n9997    9997    1.1\n50000   -1      0.7\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/05_Merge_Sort/","title":"05 Merge Sort","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/05_Merge_Sort/#question","title":"Question","text":"<p>IMPLEMENTATION of MERGE-SORT (use Recursive Version) using key field (descending order)</p> <ol> <li>Initialize 10000 positive, integer, Random Numbers whose values are in the range [0-9999] and store them in in an input array A[10000]. i.e. you are initializing the array with random numbers using an iterative statement. (you can use built-in random number generator function. assume that duplicate values are permitted).</li> <li>Implement the Merge-Sort Algorithm (recursive version) to sort in descending order. Measure the time to do sorting: use built-in timer function.</li> <li>Store the output in a text file: <code>mergeout.txt</code></li> <li>Display the first 7 records and last 7 records of the output file. (use unix commands <code>head -7 mergeout.txt</code> <code>tail -7 mergeout.txt</code>)</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/05_Merge_Sort/#algorithm","title":"Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/05_Merge_Sort/#pseudocode","title":"Pseudocode","text":"<pre><code>Algorithm mergeSort(A, p, r)\n    if p &lt; r\n    q \u2190 floor( (p + r)/2 )\n\n    mergeSort (A, p, q)\n    mergeSort (A, q+1, r)\n\n    mergeAsc(A, p, q, r) // or mergeDesc(A, p, q, r)\n\nAlgorithm mergeDesc(A, p, q, r)\n  n1 \u2190 q-p+1\n  n2 \u2190 r-q\n\n  Let L[0\u2026(n1-1)]\n  Let R[0\u2026(n2-1)]\n\n  for i \u2190 0 to n1-1\n      L[i] \u2190 A[p+i]\n  for i \u2190 0 to n2-1\n      R[i] \u2190 A[q+1+i]\n\n  i \u2190 0\n  j \u2190 0\n  k \u2190 p\n\n  while i&lt;n1 and j&lt;n2\n      if L[i] &gt;= R[j]\n          A[k] \u2190 L[i]\n          i \u2190 i+1\n      else\n          A[k] \u2190 R[j]\n          j \u2190 j+1\n      k \u2190 k+1\n\n  while i&lt;n1\n      A[k] \u2190 L[i]\n      i \u2190 i+1\n      k \u2190 k+1\n\n  while j&lt; n2\n      A[k] \u2190 R[j]\n      j \u2190 j+1\n      k \u2190 k+1\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/05_Merge_Sort/#time-complexity","title":"Time Complexity","text":"Algorithm Complexity mergeSort \\(O(n \\log_2 n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/05_Merge_Sort/#source-code","title":"Source Code","text":"<pre><code>// Ahmed Thahir 2020A7PS0198U\nimport java.io.File;\nimport java.io.FileNotFoundException;\nimport java.io.PrintWriter;\n\nclass p05\n{\n    static int n = 10000;\n    static int[] a = new int[n];\n    static String outputFile = \"h:\\\\\nMy Drive\\\\\nNotes\\\\\nSem 4\\\\\n02 DSA\\\\\nPracticals\\\\\n\"\n      + \"mergeout.txt\";\n\n    static float sortTime;\n\n    public static void initialize()\n    {\n        for(int i = 0; i&lt;n; i++)\n            a[i] = (int) ( Math.random() * n );\n    }\n\n    public static void mergeSort(int[] a, int p, int r)\n    {\n        if(p&lt;r)\n        {\n            int q = (p+r)/2;\n            // automatically floor, cuz java doesn't typecast into decimal\n\n            mergeSort(a, p, q);\n            mergeSort(a, q+1, r);\n\n            mergeDesc(a, p, q, r);\n        }\n    }\n\n    public static void mergeDesc(int[] a, int p, int q, int r)\n    {\n        int n1 = (q-p) + 1,\n        n2 = r-q;\n\n        int[] L = new int[n1],\n        R = new int[n2];\n\n        for (int i = 0; i &lt; n1; i++)\n        L[i] = a[p+i];\n        for (int j = 0; j &lt; n2; j++)\n        R[j] = a[q+1+j];\n\n        int i = 0,\n        j = 0,\n        k = p;\n\n        while (i&lt;n1 &amp;&amp; j&lt;n2)\n        {\n            if(L[i] &gt;= R[j])\n            // will be &lt;= for ascending\n            {\n                a[k] = L[i];\n                i++;\n            }\n            else\n            {\n                a[k] = R[j];\n                j++;\n            }\n            k++;\n        }\n        while(i&lt;n1)\n        {\n            a[k] = L[i];\n            i++;\n            k++;\n        }\n        while(j&lt;n2)\n        {\n            a[k] = R[j];\n            j++;\n            k++;\n        }\n    }\n\n    public static void display()\n    {\n        int z = 7;\n\n        System.out.println(\"Head\");\n        for(int i = 0; i&lt;z; i++)\n            System.out.println(a[i]);\n\n        System.out.println(\"\\nTail\");\n        for(int i = n-z; i&lt;n; i++)\n            System.out.println(a[i]);\n    }\n    public static void write() throws FileNotFoundException\n    {\n        PrintWriter writeToMyFile = new PrintWriter( new File(outputFile) );\n        for(int i = 0; i&lt;n; i++)\n            writeToMyFile.format(\"%s\\n\", a[i]);\n    }\n    public static void main(String[] args) throws FileNotFoundException\n    {       \n        initialize();\n\n        long startTime = System.nanoTime();\n\n        mergeSort(a, 0, n-1);\n\n        long endTime = System.nanoTime();\n        sortTime = (endTime - startTime)/1000f;\n        System.out.println(\"Sort Time: \" + sortTime + \" microsec\\n\");\n\n        display();\n        write();\n    }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/05_Merge_Sort/#test-cases","title":"Test Cases","text":"<pre><code>Sort Time: 3771.6 microsec\n\nHead\n9998\n9998\n9997\n9996\n9996\n9993\n9987\n\nTail\n6\n4\n4\n3\n1\n0\n0\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/","title":"06 Hashing","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#question","title":"Question","text":"<p>Write an algorithm and C/C++/JAVA program to perform the following.</p> <p>It is required to store various strings in a HASH TABLE. The hash function is defined as follows:</p> <p>Read in strings from an input text file (source.txt) and calculate hash value for each string using the hash function given below. You can permit collisions, in case if they occur [i.e. one or more strings can map to the same hash value; you can store them in the same sub-list corresponding to the computed hash value]. </p> <p>Assume that the input string has English alphabets (upper case and lower case) and digits. Note the range of ASCII values for A-Z is 65-90, a-z is 97-122 and digits 0-9 is 48-57.</p> <p>HASH FUNCTION for an input string is defined as follows:</p> \\[ \\Bigg( \\left( \\sum \\text{alphabets' ASCII} + 2 \\sum \\text{digits' ASCII} \\right) * 17 + 5 \\Bigg) \\% 6 \\] <p>Note: MOD(%) denotes modulus operator (i.e. remainder after division)</p> <p>Example Input String : Az9 Hash Value</p> \\[ \\begin{aligned} &amp;= \\Big((65 + 122 + 2*57) *17 + 5 \\Big) \\% 6 \\\\ &amp;= (301*17 +5) \\% 6 \\\\ &amp;= 5122 \\% 6 \\\\ &amp;= 4 \\end{aligned} \\] <ol> <li>Compute the hash values for each of the following twenty input strings and display the values. Note: you can read each input string from a text file (one string in each line).</li> <li>Display the contents of the Hash Table showing the elements of each sub-list.</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#algorithm","title":"Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#pseudocode","title":"Pseudocode","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#time-complexity","title":"Time Complexity","text":"Algorithm Complexity sum \\(O(n)\\) hash \\(O(1)\\) displaySublists \\(O(n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#source-code","title":"Source Code","text":"<pre><code>// Ahmed Thahir 2020A7PS0198U\n\nimport java.io.File;\nimport java.io.FileNotFoundException;\nimport java.util.Scanner;\n\npublic class p06\n{\n    static String[] subList = new String[6];\n\n    public static void init()\n    {\n        for(int i=0; i&lt;6; i++)\n        subList[i] = \"\";\n    }\n\n    public static int sum(String str, char c)\n    {\n        int sum = 0;\n        int n = str.length();\n        if(c == 'c')\n        {\n            for (int i = 0; i &lt; n; i++)\n            {\n                if( (str.charAt(i) &gt;= 65 &amp;&amp; str.charAt(i) &lt;= 90) || (str.charAt(i) &gt;= 97 &amp;&amp; str.charAt(i) &lt;= 122) )\n                sum += str.charAt(i);\n            }\n        }\n        else if (c == 'n')\n        {\n            for (int i = 0; i &lt; n; i++)\n            {\n                if( (str.charAt(i) &gt;= 48) &amp;&amp; (str.charAt(i) &lt;= 57) )\n                sum += str.charAt(i);\n            }\n        }\n\n        return sum;\n    }\n    public static int hash(String record, int csum, int nsum)\n    {\n        int hash = ( (csum + 2*nsum) * 17 + 5 ) % 6;\n        return hash;\n    }\n\n    public static void input() throws FileNotFoundException\n    {\n        String inputFile = \"source.txt\";\n        Scanner readMyFile = new Scanner( new File(inputFile) );\n\n        while (readMyFile.hasNext()) \n        {\n            String record = readMyFile.nextLine();\n            int csum = sum(record, 'c');\n            int nsum = sum(record, 'n');\n\n            int hash = hash(record, csum, nsum);\n            subList[hash] += record + \" \";\n\n            System.out.println(\"The hash value of \" + record + \" is \" + hash);\n        }\n\n        readMyFile.close();\n    }\n\n    public static void displaySubsets()\n    {\n        System.out.println(\"\\n\\n\");\n        for(int i = 0; i&lt;6; i++)\n        {\n            System.out.println(\"The subset of \" + i + \" is \" + subList[i]);\n        }\n    }\n\n    public static void main(String[] args) throws FileNotFoundException\n    {\n        init();\n        input();\n        displaySubsets();\n    }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#test-cases","title":"Test Cases","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#input","title":"Input","text":"<pre><code>M2y\nN3x\nF4w\nO5v\nD2u\nA2t\nK5y\nM6z\nN7a\nY3w\nb2Y\ne3X\nf4W\nc5V\nd2U\na2T\nJ5Y\nm6Z\nn7A\ny3W\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/06_Hashing/#output","title":"Output","text":"<pre><code>The Hash value of M2y is 1\nThe Hash value of N3x is 5\nThe Hash value of F4w is 0\nThe Hash value of O5v is 2\nThe Hash value of D2u is 2\nThe Hash value of A2t is 0\nThe Hash value of K5y is 3\nThe Hash value of M6z is 4\nThe Hash value of N7a is 2\nThe Hash value of Y3w is 1\nThe Hash value of b2Y is 0\nThe Hash value of e3X is 2\nThe Hash value of f4W is 0\nThe Hash value of c5V is 2\nThe Hash value of d2U is 2\nThe Hash value of a2T is 0\nThe Hash value of J5Y is 0\nThe Hash value of m6Z is 4\nThe Hash value of n7A is 2\nThe Hash value of y3W is 1\n\nThe Subset of 0 : F4w A2t b2Y f4W a2T J5Y\nThe Subset of 1 : M2y Y3w y3W\nThe Subset of 2 : O5v D2u N7a e3X c5V d2U n7A\nThe Subset of 3 : K5y\nThe Subset of 4 : M6z m6Z\nThe Subset of 5 : N3x\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/","title":"07 BST","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#question","title":"Question","text":"<p>Write an algorithm and C/C++/JAVA program for the following problem:</p> <ol> <li>Create a Binary Search Tree (Ordered Binary Tree) to store <code>&lt;IDNo, Name, CGPA&gt;</code> for \\(n\\) students (say \\(n=20\\) record at least)<ul> <li>Read from a text file</li> <li>Copy each record into nodes in the tree</li> <li>Assume IDNO is the primary key.</li> </ul> </li> <li>Perform INORDER Traversal of the above tree and show output.</li> <li>Perform PREORDER Traversal of the above tree and show output.</li> <li>Perform POSTORDER Traversal of the above tree and show output.</li> </ol>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#algorithm","title":"Algorithm","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#pseudocode","title":"Pseudocode","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#time-complexity","title":"Time Complexity","text":"Algorithm Complexity insert() \\(O(\\log n)\\) inFix() \\(O(n)\\) preFix \\(O(n)\\) postFix \\(O(n)\\)"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#source-code","title":"Source Code","text":"<pre><code>// Ahmed Thahir 2020A7PS0198U\n\nimport java.util.*;\nimport java.io.*;\n\nclass Node { \n    String key; \n    String name;\n    float CGPA;\n    Node left, right; \n\n    public Node(String data, String n, float c){ \n        key = data; \n        name = n;\n        CGPA = c;\n        left = right = null; \n    } \n}\n\nclass BST\n{ \n    Node root; \n\n    BST(){ \n        root = null; \n    } \n\n    void insert(String key, String name, float c)  { \n        root = insertRecursive(root, key, name, c); \n    } \n\n    Node insertRecursive(Node root, String key, String name, float c) { \n        if (root == null) { \n            root = new Node(key, name, c);\n        } \n        else if (key.compareTo(root.key)&lt;0)\n            root.left = insertRecursive(root.left, key, name, c);\n        else if (key.compareTo(root.key)&gt;0)    \n            root.right = insertRecursive(root.right, key, name , c);\n\n    return root; \n    } \n\n\n    void inFix() { \n        inFixRecursive(root); \n    } \n\n    void inFixRecursive(Node root) { \n        if (root != null) { \n            inFixRecursive(root.left); \n            System.out.print(root.key + \" \"); \n            System.out.print(root.name + \" \"); \n            System.out.println(root.CGPA + \" \"); \n            inFixRecursive(root.right); \n        } \n    } \n\n    void postFix() { \n        postFixRecursive(root); \n    } \n\n    void postFixRecursive(Node root) { \n        if (root != null) { \n            postFixRecursive(root.left); \n            postFixRecursive(root.right); \n            System.out.print(root.key + \" \"); \n            System.out.print(root.name + \" \"); \n            System.out.println(root.CGPA + \" \"); \n        } \n    }\n\n    void preFix() { \n        preFixRecursive(root); \n    } \n\n    void preFixRecursive(Node root) { \n        if (root != null) { \n            System.out.print(root.key + \" \"); \n            System.out.print(root.name + \" \"); \n            System.out.println(root.CGPA + \" \"); \n            preFixRecursive(root.left); \n            preFixRecursive(root.right); \n        } \n    }\n}\nclass p07\n{\n    public static void main(String[] args) throws FileNotFoundException\n    {\n        Scanner readMyFile = new Scanner(new File(\"input.txt\"));\n        BST bst = new BST(); \n\n        while(readMyFile.hasNext())\n        {\n            String key = readMyFile.next();\n            String name = readMyFile.next();\n            float CGPA = readMyFile.nextFloat();\n            bst.insert(key, name, CGPA); \n        }\n        System.out.println(\"InFix traversal:\"); \n        bst.inFix(); \n        System.out.println(\"\\n\\nPreFix traversal:\"); \n        bst.preFix(); \n        System.out.println(\"\\n\\nPostFix traversal:\"); \n        bst.postFix();\n    } \n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#test-cases","title":"Test Cases","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#input","title":"Input","text":"<pre><code>2019A7PS096U AA 7.6\n2019A7PS103U BB 7.5\n2019A7PS107U CC 7.4\n2019A7PS140U DD 7.3\n2019A3PS135U EE 8.5\n2019A3PS410U FF 8.4\n2019A7PS001U GG 8.3\n2019A7PS003U HH 8.2\n2019A7PS023U II 8.1\n2019A7PS034U JJ 8.0\n2019A7PS042U KK 7.9\n2019A7PS054U LL 7.8\n2019A7PS091U MM 7.7\n2019A7PS281U NN 9.1\n2019A7PS424U OO 9.0\n2019A3PS019U PP 8.9\n2019A3PS080U QQ 8.8\n2019A7PS153U RR 7.2\n2019A7PS209U SS 7.1\n2019A3PS113U TT 8.6\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/07_BST/#output","title":"Output","text":"<p><code>: InFix traversal: 2019A3PS019U PP 8.9  2019A3PS080U QQ 8.8  2019A3PS113U TT 8.6  2019A3PS135U EE 8.5  2019A3PS410U FF 8.4  2019A7PS001U GG 8.3  2019A7PS003U HH 8.2  2019A7PS023U II 8.1  2019A7PS034U JJ 8.0  2019A7PS042U KK 7.9  2019A7PS054U LL 7.8  2019A7PS091U MM 7.7  2019A7PS096U AA 7.6  2019A7PS103U BB 7.5  2019A7PS107U CC 7.4  2019A7PS140U DD 7.3  2019A7PS153U RR 7.2  2019A7PS209U SS 7.1  2019A7PS281U NN 9.1  2019A7PS424U OO 9.0  PreFix traversal: 2019A7PS096U AA 7.6  2019A3PS135U EE 8.5  2019A3PS019U PP 8.9  2019A3PS080U QQ 8.8  2019A3PS113U TT 8.6  2019A3PS410U FF 8.4  2019A7PS001U GG 8.3  2019A7PS003U HH 8.2  2019A7PS023U II 8.1  2019A7PS034U JJ 8.0  2019A7PS042U KK 7.9  2019A7PS054U LL 7.8  2019A7PS091U MM 7.7  2019A7PS103U BB 7.5  2019A7PS107U CC 7.4  2019A7PS140U DD 7.3  2019A7PS281U NN 9.1  2019A7PS153U RR 7.2  2019A7PS209U SS 7.1  2019A7PS424U OO 9.0  PostFix traversal: 2019A3PS113U TT 8.6  2019A3PS080U QQ 8.8  2019A3PS019U PP 8.9  2019A7PS091U MM 7.7  2019A7PS054U LL 7.8  2019A7PS042U KK 7.9  2019A7PS034U JJ 8.0  2019A7PS023U II 8.1  2019A7PS003U HH 8.2  2019A7PS001U GG 8.3  2019A3PS410U FF 8.4  2019A3PS135U EE 8.5  2019A7PS209U SS 7.1  2019A7PS153U RR 7.2  2019A7PS424U OO 9.0  2019A7PS281U NN 9.1  2019A7PS140U DD 7.3  2019A7PS107U CC 7.4  2019A7PS103U BB 7.5  2019A7PS096U AA 7.6</code></p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/08_Heaps/","title":"08 Heaps","text":"<p>Heap Sort Practicals covers all the concepts required for this.</p>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/09_Heap_Sort/","title":"09 Heap Sort","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/09_Heap_Sort/#code","title":"Code","text":"<pre><code>class Heap\n{\n    String[] nodes = new String[100];\n    int size = 0;\n\n    Heap()\n    {\n        nodes[0] = \"\";\n    }\n\n    int parent(int pos)\n    {\n        return pos/2;\n    }\n    int lc(int pos)\n    {\n        return 2*pos;\n    }\n    int rc(int pos)\n    {\n        return 2*pos + 1;\n    }\n\n    void swap(int a, int b)\n    {\n        String t = nodes[a];\n        nodes[a] = nodes[b];\n        nodes[b] = t;\n    }\n\n    void insert(String data)\n    {\n        size++;\n\n        nodes[size] = data;\n\n        int cur = size;\n        while(\n            nodes[cur].compareTo(nodes[parent(cur)]) &gt; 0\n        )\n        {\n            swap(cur, parent(cur));\n            cur = parent(cur);\n        }\n    }\n\n    void max_heapify(int size, int root)\n    {\n        int largest = root,\n                l = lc(root),\n                r = rc(root);\n\n        if(\n            l&lt;size &amp;&amp; nodes[l].compareTo(nodes[largest])&gt;0\n        )\n            largest = l;\n        if(\n            r&lt;size &amp;&amp; nodes[r].compareTo(nodes[largest])&gt;0\n        )\n            largest = r;\n\n        if(root != largest)\n        {\n            swap(root, largest);\n            max_heapify(size, largest);\n        }\n    }\n\n    void sort()\n    {\n        // build heap\n        for(int i = size; i&gt;=0; i--)\n        {\n            swap(i, 0);\n            max_heapify(i, 0);\n        }\n    }\n\n    void display()\n    {\n        for(int i=0; i&lt;=size; i++)\n        {\n            if(nodes[i].length() &gt; 0)\n                System.out.print(nodes[i] + \" \");\n        }\n    }\n}\n\nclass p06\n{\n    public static void main(String[] args)\n    {\n        Heap heap = new Heap();\n\n        heap.insert(\"CC\");\n        heap.insert(\"DF\");\n        heap.insert(\"MM\");\n        heap.insert(\"AB\");\n        heap.insert(\"ZX\");\n        heap.insert(\"PQ\");\n        heap.insert(\"LR\");\n        heap.display();\n\n        System.out.println();\n        heap.sort();\n        heap.display();\n    }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/09_Heap_Sort/#input","title":"Input","text":"<pre><code>RR\nBB\nYY\nGG\nNN\nQQ\nMM\nPP\nBB\nAA\nKT\nUV\nVV\nGG\nQQ\nMN\nPQ\nRS\nTU\nYM\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/09_Heap_Sort/#output","title":"Output","text":"<pre><code>YY YM VV UV RS TU RR QQ NN PQ KT GG BB QQ GG MM MN BB PP AA\nAA BB BB GG GG KT MM MN NN PP PQ QQ QQ RR RS TU UV VV YM YY\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/10_DFS/","title":"10 DFS","text":""},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/10_DFS/#just-the-graph-building-outgoing-nodes-part","title":"Just the graph building + outgoing nodes part","text":"<pre><code>import java.util.ArrayList;\n\nclass Graph\n{\n    int size;\n    ArrayList adj[];\n\n    Graph(int size)\n    {\n        this.size = size;\n\n        adj = new ArrayList[size];\n\n        for(int i = 0; i&lt;size; i++)\n        {\n            adj[i] = new ArrayList&lt;Integer&gt;();\n        }\n    }\n\n    void insert(int u, int v)\n    {\n        int ul = u-65;\n        int vl = v-65;\n        adj[ul].add(vl);\n    }\n\n    void outgoing(char from)\n    {\n        System.out.println(\"Nodes outgoing from \" + from);\n\n        int u = (char)(from) - 65;\n        for(int i=0; i&lt;adj[u].size(); i++)\n        {\n            int v = (int) adj[u].get(i);\n            char ch = (char) (v + 65);\n            System.out.println(ch);\n        }\n    }\n}\n\nclass p06\n{\n    public static void main(String[] args)\n    {\n        Graph graph = new Graph(8);\n\n        graph.insert('A', 'B');\n        graph.insert('A', 'E');\n        graph.insert('B', 'C');\n        graph.insert('D', 'E');\n        graph.insert('A', 'D');\n\n        graph.outgoing('A');\n    }\n}\n</code></pre>"},{"location":"2_Core/Data_Structures_%26_Algorithms/Practicals/10_DFS/#output","title":"Output","text":"<pre><code>Nodes outgoing from A\nB\nE\nD\n</code></pre>"},{"location":"2_Core/Database_Systems/","title":"Database Systems","text":"<p>This course covers concepts of database design, querying and transactions. mySQL was the querying language taught.</p>"},{"location":"2_Core/Database_Systems/#references","title":"References","text":"<ul> <li>DBS Dr Sapna Sadhwani | BITS Pilani Dubai Campus</li> <li>SQL Window Functions | Maven Analytics </li> </ul>"},{"location":"2_Core/Database_Systems/01_Theory/","title":"01 Theory","text":""},{"location":"2_Core/Database_Systems/01_Theory/#parts-of-table","title":"Parts of Table","text":"<p>Rows - Records/Tuples</p> <p>Columns - Fields/Attributes</p>"},{"location":"2_Core/Database_Systems/01_Theory/#drawbacks-of-file-system-spreadheets","title":"Drawbacks of File System (Spreadheets)","text":"<ol> <li>Data redundancy and inconsistency</li> <li>duplication of information in different files</li> <li>different file formats</li> <li>Difficulty in accessing data</li> <li>Data isolation</li> <li>multiple files (scattered all over the place)</li> <li>Integrity problems    Data validation and constraints is difficult</li> <li>Collaboration is difficult</li> <li>Uncontrolled Access</li> <li>Security Problems</li> </ol>"},{"location":"2_Core/Database_Systems/01_Theory/#abstraction","title":"Abstraction","text":"<p>Data hiding</p> Level of Abstraction Physical Level describes how record is stored Logical Level describes what data is stored, and the relationship between data View Level describes information hiding"},{"location":"2_Core/Database_Systems/01_Theory/#view-of-data","title":"View of data","text":""},{"location":"2_Core/Database_Systems/01_Theory/#idk","title":"IDK","text":"<p>Schema is the skeleton of the table (without data)</p> <p>Instances is the content of the table (similar to tuples)</p>"},{"location":"2_Core/Database_Systems/01_Theory/#entity-relationship-model","title":"Entity-Relationship Model","text":"<p>Entity is a table</p> <p>Relation is the primary key??</p>"},{"location":"2_Core/Database_Systems/02_ER/","title":"02 ER","text":""},{"location":"2_Core/Database_Systems/02_ER/#database-paradigms","title":"Database Paradigms","text":"<ul> <li>Relational (tables)</li> <li>Hierarchical (like tree)</li> <li>Network (interconnected)</li> <li>Object Oriented </li> <li>Object-Relational</li> <li>ER (Entity-Relationship)</li> <li>NoSQL</li> </ul>"},{"location":"2_Core/Database_Systems/02_ER/#er-model","title":"ER Model","text":"<p>A database can be modelled as</p> <ul> <li>entity set</li> <li>relationship sets</li> </ul>"},{"location":"2_Core/Database_Systems/02_ER/#terms","title":"Terms","text":"Term Meaning Example Entity unique object specific person, company Entity Set set of entities Attributes properties/features of an entity/relationship name, age Composite Attributes sub-attributes first name, last name Relationship association among several entites Relationship Sets set of relationships Degree of Relationship Set no of entity sets that participate in a relationship set Mapping Cardinalities Type of mapping One-OneOne-ManyMany-OneMany-Many"},{"location":"2_Core/Database_Systems/02_ER/#er-diagram","title":"ER Diagram","text":""},{"location":"2_Core/Database_Systems/02_ER/#symbols","title":"Symbols","text":"Shape Meaning Rectangle Entity Set Double Rectangle Weak Entity Setentity without a primary key Diamond Relationship Set Double Diamond Weak Relationship Setrelation connecting a weak entity with something else Dashed ellipse derived attribute Double ellipse multi-valued attribute Underline primary key attribute Triangle \u2018is-a\u2019 relation Lines - link attribute to entity set- link entity set to relationship set \\(\\to\\) one \\(-\\) many"},{"location":"2_Core/Database_Systems/02_ER/#idk","title":"IDK","text":"<p>Super key is any key that can uniquely identify a record</p> <p>We don\u2019t have to include foreign key for a relation</p> <p>it is implied that the primary keys of the connected entities are the foreign keys for the relation</p>"},{"location":"2_Core/Database_Systems/02_ER/#disjoint-is-a","title":"Disjoint \u2018is-a\u2019","text":"<p>can be either this or that</p>"},{"location":"2_Core/Database_Systems/03_SQL/","title":"03 SQL","text":""},{"location":"2_Core/Database_Systems/03_SQL/#sql","title":"SQL","text":"<p>is a non-procedural language</p>"},{"location":"2_Core/Database_Systems/03_SQL/#database","title":"Database","text":"<p>keywords are not case-sensitive</p> <pre><code>create database dbName;\nshow databases;\nuse dbName;\n</code></pre>"},{"location":"2_Core/Database_Systems/03_SQL/#ddl","title":"DDL","text":"<p>Data Definition Language</p> <p>work with structure</p> <pre><code>## Create Table\ncreate table tableName(\n  col1 dataType(size),\n  col2 dataType(size),\n  col3 dataType(size)\n);\n\ndrop table student;\n</code></pre>"},{"location":"2_Core/Database_Systems/03_SQL/#constraints","title":"Constraints","text":"<ol> <li>Primary Key</li> <li>Foreign key</li> <li>Cascading</li> <li>not null</li> </ol> <pre><code>create table tableName(\n  col1 dataType(size),\n  col2 dataType(size),\n  col3 dataType(size),\n  col4 dataType(size),\n\n  primary key(col1, col2),\n  foreign key(col3),\n  not null(col4),\n  on delete cascade(col1, col2, col3, col4)\n);\n\nALTER TABLE department ADD PRIMARY KEY (dept_name);\n\nalter table orders modify column purch_amt float(10,5);\n</code></pre>"},{"location":"2_Core/Database_Systems/03_SQL/#dml","title":"DML","text":"<p>Data Manipulation Language</p> <p>work with entries</p> <pre><code>## Display properties of table\ndescribe Students;\n\n## Insert\ninsert into Students values(1, \"Thahir\", \"Database Systems\");\n\n## Insert Multiple\ninsert into Students values\n(1, \"Thahir\", \"Database Systems\"),\n(2, \"Blah\", null),\n(3, \"Blah\", null);\n</code></pre>"},{"location":"2_Core/Database_Systems/03_SQL/#deletion","title":"<code>deletion</code>","text":"<pre><code>delete\nfrom instructor;\n\ntruncate instructor;\n\ndelete\nfrom instructor\nwhere deptName = \"Finance\";\n\ndelete\nfrom instructor\nwhere deptName in (\n    select deptName\n  from departments\n  where building = \"Watson\"\n);\n\ndelete\nfrom instructor\nwhere salary &lt; (\n    select avg(salary)\n  from instructor\n);\n</code></pre>"},{"location":"2_Core/Database_Systems/03_SQL/#update","title":"<code>update</code>","text":"<pre><code>update instructor\nset salary = salary * 1.03\nwhere salary &gt; 100000;\n\nupdate instructor\nset salary = case when salary &lt;=10000\n    then salary * 1.05\n    else salary * 1.03;\n\nupdate student\nset totCreds = (\n    select sum(credits)\n  from takes\n  where takes.cid = (\n    select course.cid\n    from course\n  )\n    and student.id = takes.id\n    and takes.grade != 'F'\n    and takes.grade is not null\n);\n\nupdate student\nset totCreds set null somethign is here\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/","title":"04 SQL Select","text":""},{"location":"2_Core/Database_Systems/04_SQL_Select/#select","title":"<code>select</code>","text":"<pre><code>## Display values of table\nselect * from tableName;\nselect * from tableName where id = 11;\n\nselect name, salary/12 as monthlySalary from tableName;\n\n## unique\nselect distinct city from table;\nselect count(distinct city) from table;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#subqueries","title":"Subqueries","text":"<pre><code>age + salary\nage - salary\nage * salary\nage / salary\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#clauses","title":"Clauses","text":"<p>connectives</p>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#logical","title":"logical","text":"<pre><code>and\nor\nnot\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#as","title":"<code>as</code>","text":"<pre><code>select name, courseId\n    from instructors as i, teaches as t\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#where","title":"<code>where</code>","text":"<pre><code>where id = 11;\nwhere Student.instructor = Teacher.name;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#like","title":"<code>like</code>","text":"<p>for string operations</p> <pre><code>where name like \"a%\"; ## no character/any number of characters\nwhere name like \"a_\"; ## 1 character\n\n## we can create our own escape characters\nwhere name like \"100\\%\" escape '\\';\nwhere name like \"100&amp;%\" escape '&amp;';\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#having","title":"<code>having</code>","text":"<p>for group by clause</p> <pre><code>group by age having name like \"a%\";\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#between","title":"<code>between</code>","text":"<p>inclusive on both sides</p> <pre><code>select * from Student\n    where age between 15 and 20 ## range is [15, 20]\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#operations","title":"Operations","text":""},{"location":"2_Core/Database_Systems/04_SQL_Select/#merge","title":"Merge","text":"<pre><code>select * from students, players\n    where students.id = players.id;\n\nselect name, courseId\n    from instructors as i, teaches as t\n    where i.id = t.id;\n\nselect * from Student\n    where (age, name) = (15, \"Thahir\")\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#cartesian-product","title":"Cartesian Product","text":"<pre><code>select * from students, teachers;\n</code></pre> <p>For every record of <code>students</code>, there will be every possible combination with <code>teachers</code></p> <pre><code>select * from teachers, students;\n</code></pre> <p>For every record of <code>teachers</code>, there will be every possible combination with <code>students</code></p>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#ordering","title":"Ordering","text":"<pre><code>select name from instructor order by name asc;\nselect name from instructor order by name desc;\n</code></pre> <p>if 2 people have the same name, the 2<sup>nd</sup> condition (here, age) will be given priority</p> <pre><code>select name from instructor order by name desc, age desc;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#calculus","title":"Calculus","text":"<p>TRC = Tuple Relation Calculus</p> <p>DRC = Domain Relation Calculus</p>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#semantic-representation","title":"Semantic Representation","text":"<pre><code>select A1, A2, ..., Am\n    from R1, R2, ..., Rn\n    where P\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#mathematical-representation","title":"Mathematical Representation","text":"\\[ \\Pi_{A_1, A_2, \\dots, A_m} \\bigg( \\sigma_{P} \\Big( R_1 \\times R_2 \\times \\dots \\times R_n \\Big) \\bigg) \\] Symbol Meaning \\(\\Pi\\) Projection \\(A_1, A_2, \\dots, A_m\\) Attributes (Columns) \\(\\sigma\\) Selection \\(P\\) Predicate (<code>where</code> condition) \\(R_1, R_2, \\dots, R_n\\) Relations"},{"location":"2_Core/Database_Systems/04_SQL_Select/#set-operations","title":"Set Operations","text":"Operation Meaning <code>union</code> a or b \\(A \\cup B\\) <code>intersect</code> a and b \\(A \\cap B\\) <code>except</code> a but not b \\(A \\cap B'\\) <pre><code>select cno from courses\n    where age\n\n(select id from Student where age &gt;= 15)\nexcept\n(select id from Student where age &lt; 20);\n\n## equivalent of \nselect * from Student where age between 15 and 20;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#logic","title":"Logic","text":"<ul> <li>True (1)</li> <li>False (0)</li> <li>Unknown (X - don\u2019t care)</li> </ul> <p>Any comparison with <code>null</code> gives unknown for eg,</p> <ul> <li><code>age &gt; null</code></li> <li><code>age &lt;&gt; null</code></li> <li><code>age = null</code></li> </ul>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#aggregate-functions","title":"Aggregate Functions","text":"<pre><code>count(*)\ncount(city)\ncount(distinct city)\n\nmax(salary)\nmin(salary)\n\nsum(salary)\navg(salary)\n</code></pre> <pre><code>select sum(salary)\n    from Teachers;\n\nselect dept, sum(salary)\n    from Teachers\n    where age &gt; 25\n    group by dept\n    having avg(salary) &gt; 45000;\n</code></pre> <p>The grouping attribute must be displayed as well, otherwise it won\u2019t make sence when viewing the table.</p> <p><code>count(*)</code> is the only aggregate function that does not ignore <code>null</code>, because some other fields might be filled. But, if there are only <code>null</code> values in the entire table, then even <code>count(*)</code> will return 0.</p>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#predicate-order","title":"Predicate Order","text":"<ol> <li>where (before grouping)</li> <li>having (after grouping)</li> </ol>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#subqueries_1","title":"Subqueries","text":"Clause Meaning <code>in</code> exact match <code>some</code> like <code>or</code> gate <code>all</code> like <code>and</code> gate <code>exists</code> less strict version of <code>in</code> <code>not exists</code> 0 <code>unique</code> at most once (0/1)"},{"location":"2_Core/Database_Systems/04_SQL_Select/#in","title":"<code>in</code>","text":"<pre><code>select count(distinct cid) from instructor\n    where semester = \"Fall\" and year = 2009 and\n        cid in (\n            select cid from instructor where semester = \"Spring\" and year = 2010\n        );\n\n## equivalent to\nselect distinct i1.cid\n    from instructor i1, instructor i2\n    where i1.semester = \"Fall\" and\n    i1.year = 2009 and\n    i2.semester = \"Spring\" and\n    i2.year = 2010 and\n    i1.cid = i2.cid;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#some","title":"<code>some</code>","text":"<pre><code>select distinct name from instructor\n    where age &gt; some (select age from instructor);\n\n    where age not &gt; some (select age from instructor);\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#all","title":"<code>all</code>","text":"<p>not all = not in</p> <pre><code>select distinct name from instructor\n    where age &gt; all (select age from instructor);\n\n    where age not &gt; all (select age from instructor);\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#exists","title":"<code>exists</code>","text":"<pre><code>select cid\nfrom section as s\nwhere semester = \"Fall\" and year = 2009\n    and exists\n    (\n        select * from section as T\n        where semester = \"Spring\" and year = 2010\n        and s.cid = t.cide\n    );\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#not-exists","title":"<code>not exists</code>","text":"<pre><code>select distinct s.id, s.name\nfrom student as s\nwhere not exists\n(\n    (select course_id from course where dept_name = \"Biology\")\n    except\n    (select t.course)\n)\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#unique","title":"<code>unique</code>","text":"<pre><code>select t.cid from course as t\nwhere unique(select r.cid from section as r where t.cid = r.)\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#from-subqueries","title":"<code>from</code> subqueries","text":"<pre><code>select deptName, avgSalary\nfrom (\n  select deptName, avg(salary) as avgSalary\n  from Instructors\n  group by deptName\n)\nwhere age &gt; 30;\n\n## equivalent to\n\nselect deptName, avg(salary) as avgSalary\nfrom Instructors\ngroup by deptName\nhaving age &gt; 30;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#with-clause","title":"<code>with</code> clause","text":"<pre><code>with maxTable(year, budget) as (\n    select max(year), max(budget) from department\n) ## no semi-colon\nselect department.name\nfrom department, maxTable\nwhere department.budget = maxTable.budget;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#scalar-subquery","title":"Scalar Subquery","text":"<pre><code>select deptName, (\n    select count(*)\n  from instructor\n  where department.deptName = instructor.deptName\n) as numInstructors\nfrom department;\n\n## equivalent\n\nselect department.deptName, count(*) as numInstructors\n    from instructor, department\n    where department.deptName = instructor.deptName\n    group by deptName;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#views","title":"Views","text":"<p>Temporary table</p> <pre><code>create view view_name as\nselect *\nfrom students;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#cte-with-clause","title":"CTE <code>with</code> Clause","text":"<p>Temporary view, which you only need once.</p> <p>Useful when you need just an extra column, and for Recursive CTE.</p> <pre><code>with table_with_dpr as\n(\n    select\n    *,\n    dob - today() as AGE\n)\nselect *\nwhere AGE &gt; 30;\n</code></pre>"},{"location":"2_Core/Database_Systems/04_SQL_Select/#recursive-cte","title":"Recursive CTE","text":"<pre><code>with recursive cte (id, name, parent_id) as\n(\n  select     id,\n             name,\n             parent_id\n  from       products\n  where      parent_id = 19\n  union all\n  select     p.id,\n             p.name,\n             p.parent_id\n  from       products p\n  inner join cte\n          on p.parent_id = cte.id\n)\nselect * from cte;\n</code></pre>"},{"location":"2_Core/Database_Systems/05_Intermediary/","title":"05 Intermediary","text":""},{"location":"2_Core/Database_Systems/05_Intermediary/#join","title":"Join","text":"<p>1<sup>st</sup> table\u2019s order is always followed.</p> Outer Inner Natural working uses <code>null</code> for missing values selects all rows from both tables as long as there is a match between the columns. only common tuples with only the left table Returns records that have matching values in both tables condition a column name in both the tables must be same common table repeated \u2705 \u2705 \u274c <pre><code>select *\nfrom t1 left outer join t2 on t1.roll = t2.rollNum;\n\nselect *\nfrom t1 inner join t2 on t1.roll = t2.rollNum;\n\nselect *\nfrom t1 natural join t2;\n</code></pre>"},{"location":"2_Core/Database_Systems/05_Intermediary/#outer-join","title":"Outer Join","text":"Left Outer Join Right Outer Join Full outer Join Left table\u2019s tuples will occur once Right table\u2019s tuples will occur once Returns all records from the left table, and the matched records from the right table Returns all records from the right table, and the matched records from the left table Returns all records when there is a match in either left or right table"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/","title":"06 Miscelaneous SQL","text":""},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#referential-integrity","title":"Referential Integrity","text":"<p>Ensuring that the tuples in foreign table are in the main tables as well.</p>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#cascading","title":"Cascading","text":""},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#check-clause","title":"Check Clause","text":""},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#complex","title":"Complex","text":"<p>However, subqueries in check clause is not supported. Hence, triggers are preferred</p>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#indexing","title":"Indexing","text":"<p>speeds up querying, by using the indexes instead of looking at all records</p> <pre><code>create table student(\n    id int(4)\n  primary key(id);\n);\n\ncreate index idIndex on student(id);\n\nselect id\nfrom student\nwhere age &gt; 10;\n</code></pre>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#user-defined-types","title":"User-Defined Types","text":"<pre><code>create type dollars as numeric(12, 2) final\n\ncreate table department(\n    budget dollars;\n)\n</code></pre>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#domains","title":"Domains","text":"<pre><code>create domain name char(20) not null\n</code></pre>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#large-object-types","title":"Large-Object Types","text":"<p>Photos, videos, files are stored as a large object.</p> blob clob binary large object character large object large collection of uninterpreted binary data character dat <p>(some point)</p>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#authorization","title":"Authorization","text":"<ul> <li>Read (select)</li> <li>References (allow to create foreign key)</li> <li>Insert</li> <li>Update</li> <li>Delete</li> <li>Index</li> <li>Resources</li> <li>Alteration</li> <li>Drop</li> </ul>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#granting","title":"Granting","text":"<pre><code>grant &lt;privilegeList&gt; on tableName/viewName to &lt;userList&gt;\n\ngrant select on instructor to user1, user2, user3\ngrant all privileges instructor to user1, user2, user3\n\ncreate view geo_view as (select * from instructor where deptName = \"Geology\");\ngrant select on geo_view to geo_staff;\n</code></pre>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#revoking","title":"Revoking","text":"<pre><code>revoke &lt;privilegeList&gt; on tableName/viewName from &lt;userList&gt;\n\nrevoke select on instructor from user1, user2, user3\nrevoke all privileges instructor from user1, user2, user3\n</code></pre>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#roles","title":"Roles","text":"<pre><code>create role roleName;\ngrant roleName to userName;\n\ncreate role instructor;\ngrant instructor to Sapna;\n</code></pre> <p>Priveleges can be granded/revoked from roles as well</p> <pre><code>grant select on takes to instructor;\n</code></pre>"},{"location":"2_Core/Database_Systems/06_Miscelaneous_SQL/#chain-of-roles","title":"Chain of roles","text":"<pre><code>create role dean;\ngrant instructor to dean;\ngrant dean to Kumar;\n</code></pre>"},{"location":"2_Core/Database_Systems/07_Relational_Model/","title":"07 Relational Model","text":"<p>Relations are unordered</p> <p>Database is a collection of relations</p>"},{"location":"2_Core/Database_Systems/07_Relational_Model/#keys","title":"Keys","text":"<p>a superkey is a key that is sufficient to uniquely identify a tuple of each possible relation</p>"},{"location":"2_Core/Database_Systems/07_Relational_Model/#schema-diagram","title":"Schema Diagram","text":"<p>shows the different relations</p> <p></p>"},{"location":"2_Core/Database_Systems/07_Relational_Model/#design","title":"Design","text":"<p>The logical schema depicts the structure of the database, showing the tables, columns, and relationships with other tables in the database, and is a direct mapping of the Entity-Relationship diagram. The physical schema is created by actually generating the tables, columns, and relationships in the relational database management software (RDBMS) i.e SQL queries to create the database tables and relationships define</p>"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/","title":"08 Relational Algebra","text":""},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#query-languages","title":"Query Languages","text":"<p>Procedural</p> <p>Non-Procedural</p>"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#relational-algebra","title":"Relational Algebra","text":"Operator Symbol select \\(\\sigma\\) project \\(\\pi\\) union \\(\\cup\\) set difference \\(-\\) cartesian product \\(\\times\\) rename \\(\\rho_x(E)\\) natural/inner join \\(\\Join\\) left outer join \u27d5 right outer join \u27d6 full outer join \u27d7 sum \\(_\\text{Semester} \\ g_\\text{sum(age)}({student})\\) average \\(_\\text{Semester} \\ g_\\text{avg(age)}({student})\\)"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#merging","title":"Merging","text":"<p>\\(\\sigma_{A=B} T_1 \\times T_2 (\\text{instructor})\\)</p>"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#insertion","title":"Insertion","text":"\\[ \\begin{aligned} &amp;\\text{account} \\leftarrow \\text{account } \\cup \\{ \\\\ &amp;\\text{(\u201cAhmed\", A-973, 1200)} \\\\ &amp;\\text{(\u201cThahir\", A-193, 1300)} \\\\ &amp;\\} \\end{aligned} \\]"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#update","title":"Update","text":"\\[ \\begin{aligned} &amp;\\text{account} \\leftarrow \\Pi (something) \\end{aligned} \\]"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#additional-operations","title":"Additional operations","text":"<p>Not exactly part of relational algebra, but </p> <ol> <li>Set Intersection</li> <li>Natural Join</li> <li>Division</li> <li>Assignment</li> </ol>"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#division","title":"Division","text":"<p>Find all guests names who have a booking with all tour agencies located in Dubai.</p> <ul> <li>Column - common to A&amp;B</li> <li>Tuples - records of A having the same records in B</li> </ul> \\[ \\begin{aligned} R \u00f7 S = &amp; \\\\ \\{ \\quad &amp; t[a_1,...,a_n] : \\quad t \\in R \\\\ &amp; \\land \\forall s \\in S \\Big( (t[a_1, \\dots ,a_n] \\cup s) \\in R \\Big) \\quad \\} \\end{aligned} \\]"},{"location":"2_Core/Database_Systems/08_Relational_Algebra/#view","title":"View","text":"\\[ \\begin{aligned} &amp;\\text{create view allCustomers as} \\\\ &amp;\\Pi_\\text{branchName, customerName} (     \\text{depositor$\\Join$account} ) \\\\ &amp;\\Pi_\\text{branchName} ( \\\\ &amp;\\sigma \\text{ something}\\\\ &amp;) \\end{aligned} \\]"},{"location":"2_Core/Database_Systems/09_Relational_Calculus/","title":"09 Relational Calculus","text":""},{"location":"2_Core/Database_Systems/09_Relational_Calculus/#tuple-relational-calculus-trc","title":"Tuple Relational Calculus (TRC)","text":"<p>Display loans over $1200</p> \\[ \\{ t | t \\in \\text{loan} \\land t[\\text{amount}] &gt; 1200 \\} \\] <p>Display loan number for every loan &gt; $1200</p> \\[ \\begin{aligned} \\{ t | \\exists s \\in \\text{loan} ( \\\\  &amp;&amp; t[\\text{loanNumber}] &amp;= s[\\text{loanNumber}] \\\\ &amp;&amp; \\land s[\\text{amount}] &amp;&gt; 1200 \\\\ ) \\} \\end{aligned} \\] <p>Names of customers having loan at Perry branch \u201d</p> \\[ \\begin{aligned} \\{ &amp; t | \\textcolor{purple}{ \\underbrace{     \\exists b \\in \\text{borrower} \\land \\exists l \\in \\text{loan} }_\\text{from}} ( \\\\  &amp; \\textcolor{hotpink}{ \\underbrace{t.cn = b.cn}_\\text{select}} , \\\\  &amp; \\textcolor{orange}{\\underbrace{l.bn = \\text{\u201cPerry\"} \\land l.ln = b.ln}_\\text{where} \\\\ } &amp;) \\} \\end{aligned} \\]"},{"location":"2_Core/Database_Systems/09_Relational_Calculus/#domain-relational-calculus-drc","title":"Domain Relational Calculus (DRC)","text":"<p>Display loans over $1200</p> \\[ \\{ \\textcolor{purple}{\\underbrace{&lt;l, b, a&gt;}_\\text{select}} | \\textcolor{hotpink}{\\underbrace{&lt;l, b, a&gt; \\in \\text{loan}}_\\text{from}} \\land \\textcolor{orange}{\\underbrace{a &gt; 1200}_\\text{where}} \\} \\] <p>Display names of customers having loan &gt; $1200</p> \\[ \\{ &lt;n&gt; | \\exists l, b, a something \\} \\]"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/","title":"10 Functions, Triggers","text":""},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#functions","title":"Functions","text":"<p>returns a single value</p> <pre><code>create function deptCountFunc(deptName varchar(30)) returns integer\nbegin\n    declare dCount integer;\n\n    select count(*) into dCount\n    from instructor\n    where instructor.deptName = deptCountFunc.deptName;\n\n    return dCount;\nend\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#invokation","title":"Invokation","text":"<p>can be called within a query only</p> <pre><code>select deptName\nfrom instructor\nwhere deptCountFunc(\"Physics\") &gt; 5;\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#table-function","title":"Table Function","text":"<p>function that returns a table</p> <pre><code>create function instructorOf(deptName char(20)) returns table (\n  id varchar(5),\n  name varchar(20),\n  deptName varchar(20),\n  salary numeric (10, 2)\n)\n    return table(\n    select id, name, deptName, salary\n    from instructor\n    where instructor.deptName = instructorOf.deptName;\n  );\n</code></pre> <pre><code>select name\nfrom instructorOf(\"Physics\");\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#procedure","title":"Procedure","text":"<p>is like a void function that returns nothing</p> <pre><code>create procedure deptCountProc (in deptName varchar(20),\n                                out dCount integer)\nbegin\n    select count(*) into dCount\n    from instructor\n    where instructor.deptName = deptCountProc.deptName;\nend\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#invokation_1","title":"Invokation","text":"<p>can be called anywhere</p> <ul> <li> <p>within a query, or</p> </li> <li> <p>outside everything else</p> </li> </ul> <pre><code>declare dCount integer;\ncall deptCountProc(\"Physics\", dCount);\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#loops","title":"Loops","text":""},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#while","title":"<code>while</code>","text":"<pre><code>while &lt;booleanExpression&gt; do\n    ; statements\nend while\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#repeat","title":"<code>repeat</code>","text":"<p>is like <code>do while</code> in CPP</p> <pre><code>repeat\n    ; statements\nuntil &lt;booleanExpression&gt;\nend repeat\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#for","title":"<code>for</code>","text":"<p>Find the budget of all departments</p> <pre><code>declare totalBudget integer default 0;\nfor\n    i as\n        select budget from department\n    do\n        set totalBudget = totalBudget + i.budget\nend for\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#triggers","title":"Triggers","text":"<p>statement that is executed automatically as a side effect of a modication of the database</p> <pre><code>show triggers;\n</code></pre>"},{"location":"2_Core/Database_Systems/10_Functions%2C_Triggers/#referencing","title":"Referencing","text":"<ul> <li><code>referencing old row as orow</code> - updates and deletes</li> <li><code>referencing new row as nrow</code> - updates and inserts</li> </ul> <pre><code>create trigger setnullTrigger\nbefore update of takes\nreferencing new row as nrow\nfor each row\nwhen(nrow.grade = \"\")\nbegin atomic\n  set nrow.grade = null\n  set nrow.attendance = 0\nend;\n</code></pre> <pre><code>create trigger creditsEarned\nafter update of takes on(grade)\nreferencing new row as nrow\nreferencing old row as orow\nfor each row\nwhen nrow.grade != 'F' and nrow.grade is not null\n and (orow.grade = 'F' or orow.grade is null)\nbegin atomic\n    update student\n    set totCred = totCred + (\n    select credits\n    from course\n    where course.cid = nrow.cid\n  )\n  where student.id = nrow.id;\nend;\n</code></pre> <p><code>begin atomic</code> means update everywhere</p>"},{"location":"2_Core/Database_Systems/11_Database_Design/","title":"11 Database Design","text":"<p>A good database ensures there is no redundancy or anomalies.</p> A Bad Table ID Name CourseID CourseName CourseCredits 198 Ahmed 212 DBMS 3 199 Jameel 212 DBMS 3 200 Azra 212 DBMS 3 201 Habi 212 DBMS 3 202 Azhar 213 OOPS 3"},{"location":"2_Core/Database_Systems/11_Database_Design/#bad-practices","title":"Bad Practices","text":"<p>Increase time and space complexity of database operations.</p>"},{"location":"2_Core/Database_Systems/11_Database_Design/#redundancy","title":"Redundancy","text":"<p>The same data is present in multiple places.</p> <p>Note: It may be intentional for data backup.</p>"},{"location":"2_Core/Database_Systems/11_Database_Design/#anomaly","title":"Anomaly","text":""},{"location":"2_Core/Database_Systems/11_Database_Design/#updation","title":"Updation","text":"<p>If <code>courseName</code> and <code>courseCredits</code> change for <code>212</code>, all the records have to be changed.</p>"},{"location":"2_Core/Database_Systems/11_Database_Design/#insertion","title":"Insertion","text":"<p>If a new course comes up, but there are no students, then <code>courseID</code> cannot be entered into the bad table, as primary key (ID) will be <code>null</code>.</p>"},{"location":"2_Core/Database_Systems/11_Database_Design/#deletion","title":"Deletion","text":"<p>If I delete <code>ID 202</code>, then I\u2019ll lose details about the <code>courseId 213</code></p>"},{"location":"2_Core/Database_Systems/11_Database_Design/#keys","title":"Keys","text":"Superkey Primary Key Candidate Key Attribute(s) that can uniquely identify all attributes in a table. Primary key is a minimal super key. Key that can be a primary key."},{"location":"2_Core/Database_Systems/11_Database_Design/#decomposition","title":"Decomposition","text":"<ol> <li>Atomize every table wrt an entity</li> <li>Connect those tables using relational tables with foreign key</li> </ol> <p>Prevents</p> <ol> <li>Redundancy</li> <li>Anomaly</li> </ol>"},{"location":"2_Core/Database_Systems/11_Database_Design/#normalization","title":"Normalization","text":"<p>It is the process of structuring a database, usually a relational database, in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity.</p> <p>Sometimes, it\u2019s not feasible to re-create an entire database design. In those cases, we will have to normalize tables into a more appropriate design.</p> Prime Non-Prime attributes in the candidate key other attribute"},{"location":"2_Core/Database_Systems/11_Database_Design/#candidate-key","title":"Candidate Key","text":"<p>A key/combination of keys that can help either directly/indirectly derive all attributes of a table.</p>"},{"location":"2_Core/Database_Systems/11_Database_Design/#functional-dependency","title":"Functional Dependency","text":"<p>Gives a unique tuple as the output</p> <p>idk what this means: A key can be a functional dependancy, but the vice-versa does not hold</p>"},{"location":"2_Core/Database_Systems/11_Database_Design/#partial-dependency","title":"Partial Dependency","text":"<p>Consider a key combination as (name, age)</p> <p>Query possible with just name</p> <p>Subset of candidate key can derive non-prime attributes</p> \\[ p \\to np \\]"},{"location":"2_Core/Database_Systems/11_Database_Design/#transitive-dependency","title":"Transitive Dependency","text":"<p>Non prime attributes gives non-prime</p> \\[ np \\to np \\]"},{"location":"2_Core/Database_Systems/11_Database_Design/#full-dependency","title":"Full Dependency","text":"<p>Query possible only with (name, age) combination</p> <p>Subset of candidate key cannot derive non-prime attributes</p> \\[ f(a, b) = y \\implies f(a) \\ne y, f(b) \\ne y \\]"},{"location":"2_Core/Database_Systems/11_Database_Design/#normal-forms","title":"Normal Forms","text":"1NF 2NF 3NF BCNF 4NF 5NF No Multi-Valued Attributes \u2705 \u2705 \u2705 \u2705 \u2705 \u2705 No Partial Dependency \u2705 \u2705 \u2705 \u2705 \u2705 No Transitive Dependency \u2705 \u2705 \u2705 \u2705 LHS = Candidate/Super Key \u2705 \u2705 \u2705 No Multi-Attribute Dependency \u2705 \u2705 Lossless Decomposition \u2705"},{"location":"2_Core/Database_Systems/11_Database_Design/#1nf","title":"1NF","text":""},{"location":"2_Core/Database_Systems/11_Database_Design/#given","title":"Given","text":"sid sname course 01 A CC, CP, OOP 02 B CP, DB 03 C DB"},{"location":"2_Core/Database_Systems/11_Database_Design/#normalized","title":"Normalized","text":"<p>We can turn into 2 tables</p> sid sname 01 A 02 B 03 C sid course 01 CP 01 CC 01 OOP 02 CP 02 DB 03 DB"},{"location":"2_Core/Database_Systems/11_Database_Design/#finding-candidate-key","title":"Finding Candidate Key","text":"<ol> <li> <p>Find the keys with no incoming    these compulsorily have to be in the combination, because there is no other way to reach them</p> </li> <li> <p>Find the transitive closures of all</p> <ul> <li> <p>attributes</p> </li> <li> <p>combination of failure keys</p> </li> </ul> </li> <li> <p>List out all keys</p> </li> <li> <p>Candidate keys are only the keys that are </p> </li> </ol>"},{"location":"2_Core/Database_Systems/11_Database_Design/#3nf","title":"3NF","text":"<p>every functional dependency \\(A \\to B\\) contains</p> <ul> <li>superkey \\(A\\)</li> <li>prime attribute \\(B\\)</li> </ul>"},{"location":"2_Core/Database_Systems/11_Database_Design/#armstrongs-inference-rules","title":"Armstrong\u2019s Inference Rules","text":"<p>\\(\\to\\) means derives</p> Rule Condition Inference Reflexive \\(y \\subset x\\) \\(x \\to y\\) Augmentation \\(x \\to y\\) \\(xz \\to yz\\) Transitive \\(x \\to y, y \\to z\\) \\(x \\to z\\) Decomposition \\(x \\to yz\\) \\(x \\to y, x \\to z\\) Union \\(x \\to y, x \\to z\\) \\(x \\to yz\\) Psuedotransitivity \\(x \\to y, wy \\to z\\) \\(wx \\to z\\)"},{"location":"2_Core/Database_Systems/11_Database_Design/#canonical-minimal-cover","title":"Canonical Minimal Cover","text":"<p>Removing one/more functional dependencies when a set of functional dependencies are given, ensuring that 5NF is still maintained.</p>"},{"location":"2_Core/Database_Systems/12_Indexing/","title":"12 Indexing","text":""},{"location":"2_Core/Database_Systems/12_Indexing/#indexing","title":"Indexing","text":"<p>We are trying to improve searching performance</p>"},{"location":"2_Core/Database_Systems/12_Indexing/#b-tree-indexing","title":"B+ Tree Indexing","text":"<p>Internal nodes contain indices</p> <p>Leaf nodes contain values</p>"},{"location":"2_Core/Database_Systems/12_Indexing/#advantage","title":"Advantage","text":"<ol> <li>Dynamic</li> <li>Faster than other forms of indexing</li> </ol>"},{"location":"2_Core/Database_Systems/12_Indexing/#structure","title":"Structure","text":"<pre><code>flowchart TB\nx --- a[&lt; x] &amp; c[&amp;#8805 x]</code></pre>"},{"location":"2_Core/Database_Systems/12_Indexing/#formulae","title":"Formulae","text":"IDK Formula Order \\(n\\) Min No of Children/Pointers \\(\\left \\lceil \\dfrac{n}{2} \\right \\rceil\\) Max No of Children/Pointers \\(n\\) Min No of Keys \\(\\left \\lceil \\dfrac{n}{2} \\right \\rceil - 1\\) Max No of Keys \\(n-1\\) Middle element \\(\\left \\lceil \\dfrac{n}{2} \\right \\rceil\\)<sup>th</sup> element"},{"location":"2_Core/Database_Systems/12_Indexing/#insertion","title":"Insertion","text":"<p>If there are 2 middle elements, we push the bigger one to the top.</p>"},{"location":"2_Core/Database_Systems/12_Indexing/#deletion","title":"Deletion","text":"<p>Minimum element of the right subtree will go up; basically the element next to the deleted element in the bottom linked list</p> <p>If the key goes less than the minimum key, then we have to borrow the</p> <ul> <li>maximum element of the left side, or</li> <li>minimum element of the right side</li> </ul> <p>if that\u2019s not possible, merge upward</p>"},{"location":"2_Core/Database_Systems/12_Indexing/#hashing","title":"Hashing","text":"<p>Technique to store values in a more accessible form.</p> Hashing Type Technique Using Open Chaining Linked List Closed Linear Quadratic"},{"location":"2_Core/Database_Systems/12_Indexing/#load-factor","title":"Load Factor","text":"\\[ \\text{LF} = \\frac{R}{} \\] <p>where \\(R\\) means Records</p>"},{"location":"2_Core/Database_Systems/12_Indexing/#linear-hashing","title":"Linear Hashing","text":""},{"location":"2_Core/Database_Systems/12_Indexing/#extendible-hashing","title":"Extendible Hashing","text":"<p>This technique is used to minimize the re-hashing costs in normal hashing, which arise due to collisions.</p> Component Meaning Memory Hash Function Hash Table Main Bucket Bins that are formatted similar to B+ Tree Leaves Disk (Secondary) Bucket Size max number of elements in the buckets(will be given) Depth Number of MSB bits required to differentiate Buckets <p>If local depth of filled page \\(\\ge\\) global depth</p> <ol> <li>double the hash table size</li> <li>allocate space for an additional bin</li> <li>re-distribute filled page indices</li> </ol> Case Action Local \\(&lt;\\) Global Local \\(=\\) Global double the hash table size Local \\(&gt;\\) Global 1. allocate space for an additional bin2. re-distribute filled page indices <p></p> <p>The number of combinations that will be connected to each bucket will be the remaining combination of the unused bits. For eg, \\(01\\) bucket will have 2 unused bits, so there will be 4 combinations</p>"},{"location":"2_Core/Database_Systems/12_Indexing/#bitmap","title":"Bitmap","text":"<p>Very easy bro</p> <p>The no of records will be the number of bits.</p>"},{"location":"2_Core/Database_Systems/12_Indexing/#limitations","title":"Limitations","text":"<p>For large database, we need a lot of bits.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/","title":"13 Transactions","text":"<p>single logical unit of work formed by a set of operations.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#operations","title":"Operations","text":"<ul> <li><code>read(a)</code></li> <li><code>write(a)</code></li> </ul> <p>where <code>a</code> is a resource.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#conflicts","title":"Conflicts","text":"<p>occurs when resources are in shareable mode.</p> <p>2 operations conflict if they are</p> <ul> <li>on the same object/resource</li> <li>by different transactions</li> <li>atleast 1 transaction is a write</li> </ul>"},{"location":"2_Core/Database_Systems/13_Transactions/#transaction-states","title":"Transaction States","text":"<ol> <li>active</li> <li>partially-commited</li> <li>committed</li> <li>failed</li> <li>aborted</li> <li>terminated</li> </ol> <pre><code>flowchart LR\n\na[Active]\npc[Partially-Committed]\nf[Failed]\nab[Aborted]\nt[Terminated]\n\na --&gt;\n|R/W| pc --&gt;\n|Permanently Store| Committed --&gt;\nt\n\na --&gt;\n|Failure|f --&gt;\n|Roll Back|ab --&gt; t\n\npc --&gt;|Failure| f</code></pre>"},{"location":"2_Core/Database_Systems/13_Transactions/#acid","title":"ACID","text":"<p>Good features of a database. Relational databases are ACID-compliant, but NoSQL aren\u2019t</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#atomicity","title":"Atomicity","text":"<p>Transaction status should be binary - occured/not occured. No transaction must not occur partially.</p> <p>If any sub-steps of a transaction(Operation/Query) fails, the whole transaction must fail and the database must be in the same state as the original.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#consistency","title":"Consistency","text":"<p>Correct data is ensured through constraints.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#isolation","title":"Isolation","text":"<p>Concurrent-Execution Safe</p> <p>Simultaneous transactions must be considered as multiple sequential transactions.</p> <p>Transactions must be one-one.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#durability","title":"Durability","text":"<p>Committed transactions must be stored to a non-volatile memory, to prevent loss of data.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#commit","title":"Commit","text":"<p>Storing update into permanent memory.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#concurrency-problems","title":"Concurrency Problems","text":"<p>Conflicts that occur when simultaneous transactions occur.</p> Problem Description Solution Blind Write Dirty-read uncommited transactions are read - Serial Scheduling- values should be stored only after committing Unrepeatable read multiple reads of the same parameter without a commit Lost Update a later write committed first is preferred over the first write committed second, when multiple writes occur simultaneously Nothing really, just how it works Phantom Read - transaction 1 reads- some other transaction deletes- transaction 1 tries reading, but can\u2019t find"},{"location":"2_Core/Database_Systems/13_Transactions/#solutions","title":"Solutions","text":"<p>Before any write occurs, always do a read.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#types-of-schedules","title":"Types of Schedules","text":""},{"location":"2_Core/Database_Systems/13_Transactions/#serial","title":"Serial","text":"<p>Schedule where each transaction occurs one after the other.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#parallel","title":"Parallel","text":"<p>Multiple schedules happen at the same time?</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#concurrentinterleaved","title":"Concurrent/Interleaved","text":"<p>Helps improve Throughput</p> <p>Schedule where each transaction overlapping over each other.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#serializable","title":"Serializable","text":"<p>Non-serial schedule that can be converted into serial schedule.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#conflict-serializable","title":"Conflict Serializable","text":"<p>Serializable schedule that is possible, only after removing conflicts.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#equivalent","title":"Equivalent","text":"<p>Represented as \\(S \\equiv S'\\)</p> <p>A serial and non-serial schedule which can be converted to each other.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#conflict-equivalent","title":"Conflict Equivalent","text":"<p>Conflict Serializable schedule, such that conflicting-pairs occur in the same way as initially.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#view-serializable","title":"View Serializable","text":"<p>2 schedules \\(S, S'\\) that meet the following criteria. The transaction that</p> <ol> <li>performs first read for a resource in \\(S\\) must do the same in \\(S'\\)</li> <li>reads resource written by another transaction in \\(S\\) must do the same in \\(S'\\)</li> <li>performs final write for a resource in \\(S\\) must do the same in \\(S'\\)</li> </ol>"},{"location":"2_Core/Database_Systems/13_Transactions/#eliminating-conflicts","title":"Eliminating Conflicts","text":""},{"location":"2_Core/Database_Systems/13_Transactions/#precedence-graph","title":"Precedence Graph","text":"<p>Shows which transaction is dependent on which other transactions(s).</p> <pre><code>flowchart RL\n\nt1((T1))\nt2((T2))\nt3((T3))\nt2 --&gt;|z| t1\nt2 --&gt;|y| t3\n\nt3 --&gt;|x| t1</code></pre>"},{"location":"2_Core/Database_Systems/13_Transactions/#interpretations","title":"Interpretations","text":""},{"location":"2_Core/Database_Systems/13_Transactions/#serializability","title":"Serializability","text":"Loop/Cycle Simple Graph Serializable? \u274c \u2705 <p>The above example is serializable.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#order","title":"Order","text":"<p>Order will start from the transaction with indegree = 0</p> <p>In above example, order will be \\(T_2 \\to T_3 \\to T_1\\)</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#blind-write","title":"Blind Write","text":"<p>without even reading the value, you are writing.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#throughput","title":"Throughput","text":"<p>Work done per unit time.</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#2-phase-locking-concurrency-control","title":"2 Phase Locking Concurrency Control","text":"Lock Mode Type Number Shareable Read Max Capacity (50, 100, \u2026) Exclusive Write 1"},{"location":"2_Core/Database_Systems/13_Transactions/#lock-manager","title":"Lock Manager","text":"<p>Manages locks on data items</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#lock-table","title":"Lock Table","text":"<p>used by lock manager blah blah</p>"},{"location":"2_Core/Database_Systems/13_Transactions/#graph","title":"Graph","text":""},{"location":"2_Core/Database_Systems/13_Transactions/#types","title":"Types","text":"Hold lock throughout Strict Rigorous Read \u274c \u2705 Write \u2705 \u2705"},{"location":"2_Core/Database_Systems/13_Transactions/#well-formed-transaction","title":"Well Formed Transaction","text":"<ul> <li>Data item must be locked before reading/writing.</li> <li>Should not try to<ul> <li>unlock free resource</li> <li>lock already-locked resource</li> </ul> </li> </ul>"},{"location":"2_Core/Database_Systems/Practicals/00_Intro/","title":"00 Intro","text":""},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#creating-connection","title":"Creating Connection","text":"<ol> <li>Open Workbench</li> <li>Click +</li> <li>Enter any connection name (i put my uni ID 2020A7PS0198U)</li> <li>Enter hostname as 172.16.100.8</li> <li>Enter username as collegeid (like 2020A7PS0198U)</li> </ol>"},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#jdbc","title":"JDBC","text":""},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#creation","title":"Creation","text":"<ol> <li>File &gt; New Project</li> <li>Java with Ant</li> <li>Next &gt; Finish</li> </ol>"},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#code","title":"Code","text":"<pre><code>package jdbc;\nimport java.sql.*;\n\npublic class JavaApplication7 {\n    public static void main(String[] args) {\n        query(\"salesman\");\n        query(\"instructor\");\n        query(\"takes\");\n\n    query(\"salesman\", \"salesman_id &gt; 5003\");\n    }\n  public static void query(String table)\n  {\n    query(table, \"\");\n  }   \n    public static void query(String table, String where)\n    {\n        try\n        {\n            String url = \"jdbc:mysql://172.16.100.8/20200198db\",\n                user = \"2020A7PS0198U\",\n                password = \"a\",\n                query = \"select * from \" + table;\n                        if(where!=\"\")\n                            query += \" where \" + where;\n\n            System.out.println(query + \" \ud83d\ude0a\");\n\n            Class.forName(\"com.mysql.cj.jdbc.Driver\");\n            Connection con = DriverManager.getConnection(url, user, password);\n            Statement stmt = con.createStatement();\n            ResultSet rs = stmt.executeQuery(query); \n            while(rs.next())\n            {\n                String col1 = rs.getString(1),\n                    col2 = rs.getString(2);\n                System.out.println(col1 + \" \" + col2);\n            }\n\n            rs.close();\n            stmt.close();\n            con.close();\n\n            System.out.println(\"\");\n        }\n        catch(Exception e)\n        {\n            System.out.println(\"Something Happened \ud83e\udd23\");\n        }\n    }   \n}\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#output","title":"Output","text":"<pre><code>select * from salesman \ud83d\ude0a\n5001 James Hoog\n5002 Nail Knite\n5003 Lauson Hen\n5005 Pit Alex\n5006 Mc Lyon\n5007 Paul Adam\n\nselect * from instructor \ud83d\ude0a\n102 ABC\n103 DEF\n104 GHI\n\nselect * from takes \ud83d\ude0a\n198 CS F111\n199 Bio F111\n200 Mech F111\n201 111\n\nselect * from salesman where salesman_id &gt; 5003 \ud83d\ude0a\n5005 Pit Alex\n5006 Mc Lyon\n5007 Paul Adam\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#gui","title":"GUI","text":""},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#steps","title":"Steps","text":""},{"location":"2_Core/Database_Systems/Practicals/00_Intro/#code_1","title":"Code","text":"<pre><code>private void jButton1ActionPerformed(java.awt.event.ActionEvent evt) {                                         \n  String salesman_id = jTextField1.getText(),\n  name = jTextField2.getText(),\n  city = jTextField3.getText(),\n  commission = jTextField4.getText();\n\n  String table = \"salesman\",\n  values = \"'\" + salesman_id + \"', '\" + name + \"', '\" + city + \"', \" + commission + \"'\";\n\n  insertQuery(table, values);\n}                                        \n\npublic void insertQuery(String table, String values)\n{\n  try\n  {\n    String url = \"jdbc:mysql://172.16.100.8/20200198db\",\n    user = \"2020A7PS0198U\",\n    password = \"a\",\n    query = \"insert into \" + table + \" values(\"  + values + \")\";\n\n    System.out.println(query);\n\n    Class.forName(\"com.mysql.cj.jdbc.Driver\");\n    Connection con = DriverManager.getConnection(url, user, password);\n    Statement stmt = con.createStatement();\n    stmt.executeUpdate(query);\n\n    stmt.close();\n    con.close();\n\n    //                        JOptionPane.showMessageDialog(this, query);\n  }\n  catch(Exception e)\n  {\n    System.out.println(\"Something Happened \ud83e\udd23\");\n  }\n}   \n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/01/","title":"01","text":""},{"location":"2_Core/Database_Systems/Practicals/01/#initialization","title":"Initialization","text":"<pre><code>use 20200198db;\nset foreign_key_checks = 0;\ndrop table if exists Students;\nset foreign_key_checks  = 1;\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/01/#queries","title":"Queries","text":"<pre><code>CREATE TABLE Students\n(\n  ROLL_NO int,\n  NAME varchar(20),\n  SUBJECT varchar(20)\n);\n</code></pre> <pre><code>DESC Students;\n</code></pre> <pre><code>INSERT INTO Students VALUES (198, \"Thahir\", \"OOPS\");\n</code></pre> <pre><code>INSERT INTO Students (ROLL_NO, NAME, SUBJECT) VALUES\n(198, \"Ahmed\", \"DSA\"),\n(231, \"Ram\", \"DSA\");\n</code></pre> <pre><code>SELECT * FROM Students;\nSELECT ROLL_NO FROM Students;\nSELECT * FROM Students ORDER BY ROLL_NO;\nSELECT * FROM Students ORDER BY ROLL_NO desc;\n</code></pre> <pre><code>ALTER TABLE Students ADD (AGE int,COUNTRY varchar(40));\nALTER TABLE Students DROP COLUMN AGE;\nALTER TABLE Students MODIFY COUNTRY varchar(20);\n\nalter table table_name drop primary key, add primary key(k1, k2, k3);\n</code></pre> <pre><code>DELETE FROM Students WHERE NAME = 'Ram';\nDELETE FROM Students WHERE AGE = 20;\n</code></pre> <pre><code>DROP TABLE Students;\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/02/","title":"02","text":""},{"location":"2_Core/Database_Systems/Practicals/02/#initialization","title":"Initialization","text":"<pre><code>use 20200198db;\nset foreign_key_checks = 0;\ndrop table if exists department, student, course, advisor, instructor, teaches, takes, prereq;\nset foreign_key_checks  = 1;\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/02/#questions","title":"Questions","text":"<ol> <li>Create a table for the following.    department(dept_name, building, budget)</li> </ol> <pre><code>create table department(\n  dept_name varchar(20),\n  building int(4),\n  budget float(10)\n);\n</code></pre> <ol> <li> <p>Alter the above table to add primary key.</p> <pre><code>ALTER TABLE department ADD PRIMARY KEY (dept_name);\n</code></pre> </li> <li> <p>Create the following tables with primary key and foreign key constraints     | Table                                                       | FK                                                           |     | ----------------------------------------------------------- | ------------------------------------------------------------ |     | Student(SID, name, dept_name, total_credit)          | dept_name                                                    |     | course(course_id, title, dept_name , credits)        | dept_name                                                    |     | instructor(IID, name, dept_name, salary)             | dept_name                                                    |     | teaches(IID, course_id, sec_id, semester, year)      | course_id, instructor(IID)                                   |     | takes(SID, course_id, sec_id, semester, year, grade) |                                                              |     | advisor(SID, IID)                                    | IID references instructor (IID), SID references student (SID) |     | prereq(course_id, prereq_id)                  | course_id references course(course_id), prereq_id references course(course_id) |</p> <p><pre><code>create table student(\n  SID int(4), \n  name varchar(20), \n  dept_name varchar(20), \n  total_credit int(4),\n\n  PRIMARY KEY(SID),\n  FOREIGN KEY (dept_name) REFERENCES department(dept_name)\n);\n\ncreate table course(\n  course_id varchar(20),\n  title varchar(20),\n  dept_name varchar(20),\n  credits int(4),\n\n  PRIMARY KEY(course_id),\n  FOREIGN KEY (dept_name) REFERENCES department(dept_name)\n);\n\ncreate table instructor(\n  IID int(4),\n  name varchar(20),\n  dept_name varchar(20),\n  salary int(4),\n\n  PRIMARY KEY(IID),\n  FOREIGN KEY (dept_name) REFERENCES department(dept_name)\n);\n\ncreate table teaches(\n  IID int(4),\n  course_id varchar(20),\n  sec_id int(4),\n  semester int(4) check (semester between 1 and 2),\n  year int(4),\n\n  PRIMARY KEY(IID),\n  FOREIGN KEY (course_id) REFERENCES course(course_id) ON DELETE CASCADE,\n  FOREIGN KEY (IID) REFERENCES instructor(IID) ON DELETE CASCADE\n);\n\ncreate table takes(\n  SID int(4),\n  course_id varchar(20),\n  sec_id int(4),\n  semester int(4) check (semester between 1 and 2),\n  year int(4),\n  grade varchar(1),\n\n  PRIMARY KEY(SID)\n);\n\ncreate table advisor(\n  SID int(4),\n  IID int(4),\n\n  PRIMARY KEY (SID),\n  FOREIGN KEY (IID) REFERENCES instructor(IID) ON DELETE CASCADE,\n  FOREIGN KEY (SID) REFERENCES student(SID) ON DELETE CASCADE\n);\n\ncreate table prereq(\n  course_id varchar(20),\n  prereq_id int(4),\n\n  PRIMARY KEY (prereq_id, course_id),\n  FOREIGN KEY (course_id) REFERENCES course(course_id) ON DELETE CASCADE,\n  FOREIGN KEY (prereq_id) REFERENCES course(course_id) ON DELETE CASCADE\n);\n</code></pre> 4. Alter the Instructor table to set 10,0000/- as default salary</p> </li> </ol> <pre><code>alter table instructor ALTER salary SET DEFAULT 10000;\n</code></pre> <ol> <li>Insert some rows into all of the above tables</li> </ol> <pre><code>insert into department values\n(\"Computer\", 7, 20000),\n(\"Biotech\", 9, 50000),\n(\"Mechanical\", 3, 70000);\n\ninsert into student values\n(198, \"Thahir\", \"Computer\", 100),\n(199, \"Someone\", \"Biotech\", 90),\n(200, \"Blah\", \"Mechanical\", 50);\n\ninsert into course values\n(\"CS F111\", \"OOPS\", \"Computer\", 3),\n(\"Mech F111\", \"Thermodynamics\", \"Mechanical\", 3),\n(\"Bio F111\", \"Gen Bio\", \"Biotech\", 3);\n\ninsert into instructor values\n(102, \"ABC\", \"Computer\", 5000),\n(104, \"GHI\", \"Mechanical\", 6050.9),\n(103, \"DEF\", \"Biotech\", 7000);\n\ninsert into teaches values\n(102, \"CS F111\", 3, 2, 2020),\n(103, \"Bio F111\", 2, 1, 2020),\n(104, \"Mech F111\", 1, 2, 2019);\n\ninsert into takes values\n(198, \"CS F111\", 3, 2, 2020),\n(199, \"Bio F111\", 2, 1, 2020),\n(200, \"Mech F111\", 1, 2, 2019);\n\ninsert into advisor values\n(198, 102),\n(199, 103),\n(200, 104);\n\ninsert into prereq values\n(\"CS F111\", \"Bio F111\"),\n(\"Mech F111\", \"Bio F111\");\n</code></pre> <ol> <li>Insert a row into \u2018takes\u2019 table with the semester value as 3 or above and view the effect of constraints.</li> </ol> <pre><code>insert into takes values\n(201, 111, 3, 10, 2019, 'D');\n</code></pre> <ol> <li>Delete some rows to view the effect of foreign key constraints.</li> </ol> <pre><code>delete from student;\n</code></pre> <ol> <li>TRUNCATE and DROP tables.</li> </ol> <pre><code>drop table prereq;\nTRUNCATE TABLE advisor;\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/03/","title":"03","text":""},{"location":"2_Core/Database_Systems/Practicals/03/#initialization","title":"Initialization","text":"<pre><code>use 20200198db;\nset foreign_key_checks = 0;\ndrop table if exists salesman, customer, orders;\nset foreign_key_checks  = 1;\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/03/#tables","title":"Tables","text":"<p>Create the three tables given below and answer the following queries</p>"},{"location":"2_Core/Database_Systems/Practicals/03/#salesman","title":"<code>salesman</code>","text":"salesman_id name city commission 5001 James Hoog New York 0.15 5002 Nail Knite Paris 0.13 5005 Pit Alex London 0.11 5006 Mc Lyon Paris 0.14 5003 Lauson Hen 0.12 5007 Paul Adam Rome 0.13"},{"location":"2_Core/Database_Systems/Practicals/03/#customer","title":"<code>customer</code>","text":"customer_id cust_name city grade salesman_id 3002 Nick Rimando New York 100 5001 3005 Graham Zusi California 200 5002 3001 Brad Guzan London 5005 3004 Fabian Johns Paris 300 5006 3007 Brad Davis New York 200 5001 3009 Geoff Camero Berlin 100 5003 3008 Julian Green London 300 5002 3003 Jozy Altidor Moscow 200 5007"},{"location":"2_Core/Database_Systems/Practicals/03/#orders","title":"<code>orders</code>","text":"ord_no purch_amt ord_date customer_id salesman_id 70001 150.50 2012-10-05 3005 5002 70009 270.65 2012-09-10 3001 5005 70002 65.26 2012-10-05 3002 5001 70004 110.50 2012-08-17 3009 5003 70007 948.50 2012-09-10 3005 5002 70005 2400.6 2012-07-27 3007 5001 70008 5760.00 2012-09-10 3002 5001 70010 1983.43 2012-10-10 3004 5006 70003 2480.40 2012-10-10 3009 5003 70012 250.45 2012-06-27 3008 5002 70011 75.29 2012-08-17 3003 5007 70013 3045.60 2012-04-25 3002 5001 <pre><code>create table salesman(\n  salesman_id int(4),\n  name varchar(20),\n  city varchar(20),\n  commission float(10, 5),\n\n  PRIMARY KEY(salesman_id)\n);\n\ncreate table customer(\n  customer_id int(4),\n  cust_name varchar(20),\n  city varchar(20),\n  grade int(4),\n  salesman_id int(4),\n\n  PRIMARY KEY(customer_id),\n  FOREIGN KEY(salesman_id) REFERENCES salesman(salesman_id) on delete cascade\n);\n\ncreate table orders(\n  ord_no int(5),\n  purch_amt float(10, 5),\n  ord_date date,\n  customer_id int(4),\n  salesman_id int(4),\n\n  PRIMARY KEY(ord_no),\n  FOREIGN KEY(salesman_id) REFERENCES salesman(salesman_id) on delete cascade\n);\n\ninsert into salesman values\n  (5001, \"James Hoog\", \"New York\", 0.15),\n  (5002, \"Nail Knite\", \"Paris\", 0.13),\n  (5005, \"Pit Alex\", \"London\", 0.11),\n  (5006, \"Mc Lyon\", \"Paris\", 0.14),\n  (5003, \"Lauson Hen\", null, 0.12),\n  (5007, \"Paul Adam\", \"Rome\", 0.13);\n\ninsert into customer values \n    (3002, \"Nick Rimando\", \"New York\", 100, 5001),\n    (3005, \"Graham Zusi\", \"California\", 200, 5002),\n    (3001, \"Brad Gusan\", \"London\", null, 5005),\n    (3004, \"Fabian Johns\", \"Paris\", 300, 5006),\n    (3007, \"Brad Davis\", \"New York\", 200, 5001),\n    (3009, \"Geoff Camero\", \"Berlin\", 100, 5003),\n    (3008, \"Julian Green\", \"London\", 300, 5002),\n    (3003, \"Jozy Altidor\", \"Moscow\", 200, 5007);\n\ninsert into orders values\n  (70001, 150.5, \"2012-10-05\", 3005, 5002),\n  (70009, 270.65, \"2012-09-10\", 3001, 5005),\n  (70002, 65.26, \"2012-10-05\", 3002, 5001),\n  (70004, 110.5, \"2012-08-17\", 3009, 5003),\n  (70007, 948.5, \"2012-09-10\", 3005, 5002),\n  (70005, 2400.6, \"2012-07-27\", 3007, 5001),\n  (70008, 5760, \"2012-09-10\", 3002, 5001),\n  (70010, 1983.43, \"2012-10-10\", 3004, 5006),\n  (70003, 2480.4, \"2012-10-10\", 3009, 5003),\n  (70012, 250.45, \"2012-06-27\", 3008, 5002),\n  (70011, 75.29, \"2012-08-17\", 3003, 5007),\n  (70013, 3045.6, \"2012-04-25\", 3002, 5001);\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/03/#questions","title":"Questions","text":"<ol> <li>Write a query to find those customers with their name and those salesmen with their name and city who lives in the same city.</li> </ol> <pre><code>select customer.city as City, cust_name as Customer, salesman.name as Salesperson\n from customer, salesman\n where customer.salesman_id = salesman.salesman_id\n         and customer.city = salesman.city;\n</code></pre> <ol> <li>Write a SQL statement to find the names of all customers along with the salesmen who works for them.</li> </ol> <pre><code>select cust_name as Customer, salesman.name as Salesperson\n from customer, salesman\n where customer.salesman_id = salesman.salesman_id;\n</code></pre> <ol> <li>Write a SQL statement to display all those orders by the customers not located in the same cities where their salesmen live.</li> </ol> <pre><code>select *\n from orders\n where (orders.customer_id, orders.salesman_id) in (\n    select customer.customer_id, salesman.salesman_id\n     from customer, salesman\n     where customer.city != salesman.city\n  );\n</code></pre> <ol> <li>Write a SQL statement that finds out each order number followed by the name of the customers who made the order.</li> </ol> <pre><code>select ord_no as \"Order Number\", cust_name as Customer\n from orders, customer\n where orders.customer_id = customer.customer_id;\n</code></pre> <ol> <li>Write a SQL statement that sorts out the customer and their grade who made an order. Each of the customers must have a grade and served by at least a salesman, who belongs to a city.</li> </ol> <pre><code>select cust_name as Customer, grade as Grade\n from customer\n where grade is not null\n     and salesman_id is not null\n order by grade desc;\n</code></pre> <ol> <li>Write a query that produces all customers with their name, city, salesman and commission, who served by a salesman and the salesman works at a rate of the commission within 12% to 14%.</li> </ol> <pre><code>select cust_name as Customer, customer.city, salesman.name, salesman.commission as commission\n from customer, salesman\n where customer.salesman_id = salesman.salesman_id\n     and salesman.commission between 0.12 and 0.14;\n</code></pre> <ol> <li>Write a SQL statement that produces all orders with the order number, customer name, commission rate and earned commission amount for those customers who carry their grade is 200 or more and served by an existing salesman.</li> </ol> <pre><code>select ord_no as \"Order Number\", cust_name as Customer, commission as \"Commission Rate\", (commission * purch_amt) as \"Earned Commission\"\n from orders, customer, salesman\n where orders.customer_id = customer.customer_id\n     and orders.salesman_id = salesman.salesman_id\n     and grade &gt; 200\n     and customer.salesman_id is not null;\n</code></pre> <ol> <li>Write a query to display all customers with a grade above 100.</li> </ol> <pre><code>select cust_name as Customer\nfrom customer\nwhere grade &gt; 100;\n</code></pre> <ol> <li>Write a query statement to display all customers in New York who have a grade value above 100.</li> </ol> <pre><code>select cust_name as Customer\nfrom customer\nwhere city = \"New York\"\n and grade &gt; 100;\n</code></pre> <ol> <li> <p>Write a SQL statement to display all the customers, who are either belongs to the city New York or not had a grade above 100.</p> <pre><code>select cust_name as Customer\nfrom customer\nwhere (city = \"New York\") or (grade &lt;= 100);\n</code></pre> </li> <li> <p>Write a SQL query to display those customers who are neither belongs to the city New York nor grade value is more than 100.</p> <pre><code>select cust_name as Customer\nfrom customer\nwhere not(city = \"New York\" or grade &gt; 100);\n</code></pre> </li> <li> <p>Write a SQL statement to display either those orders which are not issued on date 2012-09-10 and issued by the salesman whose ID is 5005 and below, or those orders which purchase amount is 1000.00 and below.</p> <pre><code>select *\nfrom orders\nwhere not(\n    ord_date &lt; 2012-09-10\n    and salesman_id in (select salesman_id from salesman where salesman_id &lt;= 5005)\n    )\n    or purch_amt &lt;= 1000;\n</code></pre> </li> </ol>"},{"location":"2_Core/Database_Systems/Practicals/04/","title":"04","text":"<p>Same tables as 03.</p>"},{"location":"2_Core/Database_Systems/Practicals/04/#queries","title":"Queries","text":"<ol> <li>Write a query to find salesmen with all information who lives in the city where any of the customers lives.</li> </ol> <pre><code>select salesman.name as Salesperson\nfrom salesman\nwhere salesman_id is not null\n and salesman.name is not null\n    and salesman.city is not null\n    and salesman.commission is not null\n and salesman.city i some(\n     select customer.city from customer\n  );\n</code></pre> <ol> <li>Write a query to display all the orders that had amounts that were greater than at least one of the orders on September 10<sup>th</sup> 2012.</li> </ol> <pre><code>select *\nfrom orders\nwhere orders.purch_amt &gt; some(\n  select purch_amt\n  from orders\n  where ord_date = 2012-09-10\n);\n</code></pre> <ol> <li>Write a query to display all orders with an amount smaller than any amount for a customer in London.</li> </ol> <pre><code>select *\nfrom orders\nwhere orders.purch_amt &lt; some (\n  select purch_amt\n  from orders\n  where orders.customer_id in (\n     select customer.customer_id\n    from customer\n    where city = \"London\"\n  )\n);\n</code></pre> <ol> <li>Write a query to display only those customers whose grade are, in fact, higher than every customer in New York.</li> </ol> <pre><code>select cust_name as Customer\nfrom customer\nwhere grade = (\n  select max(grade)\n  from customer\n  where city = \"New York\"\n);\n</code></pre> <ol> <li>Write a query to get all the information for those customers whose grade is not as the grade of customer who belongs to the city London.</li> </ol> <pre><code>select *\nfrom customer\nwhere grade not in (\n  select grade\n  from customer\n  where city = \"London\"\n);\n</code></pre> <ol> <li>Write a query to display all the orders from the orders table issued by the salesman 'Paul Adam'.</li> </ol> <pre><code>select *\nfrom orders\nwhere salesman_id = (\n select salesman_id\n  from salesman\n  where name = \"Paul Adam\"\n);\n</code></pre> <ol> <li>Write a query to display all the orders for the salesman who belongs to the city London.</li> </ol> <pre><code>select *\nfrom orders\nwhere salesman_id = (\n select salesman_id\n  from salesman\n  where city = \"London\"\n);\n</code></pre> <ol> <li>Write a query to display all the orders which values are greater than the average order value for 10<sup>th</sup> October 2012.</li> </ol> <pre><code>select *\nfrom orders\nwhere purch_amt &gt; (\n select avg(purch_amt)\n  from orders\n  where ord_date = \"2012-10-10\"\n);\n</code></pre> <ol> <li>Write a query to display the commission of all the salesmen servicing customers in Paris.</li> </ol> <pre><code>select distinct commission\nfrom salesman\nwhere city = \"Paris\";\n</code></pre> <ol> <li> <p>Write a query to display all customers with orders on October 5, 2012.</p> <pre><code>select cust_name as Customer\nfrom customer\nwhere customer.customer_id in (\n    select orders.customer_id\n  from orders\n  where ord_date = \"2012-10-05\"\n);\n</code></pre> </li> </ol>"},{"location":"2_Core/Database_Systems/Practicals/05/","title":"05","text":"<p>Use Joins</p> <ol> <li>Write a SQL statement to know which salesman are working for which customer.</li> </ol> <pre><code>select name as Salesperson, cust_name as Customer\nfrom salesman inner join customer\non salesman.salesman_id=customer.salesman_id;\n</code></pre> <ol> <li>Write a SQL statement to find the list of customers who appointed a salesman for their jobs who gets a commission from the company is more than 12%.</li> </ol> <pre><code>select customer.cust_name as Customer\nfrom customer natural join salesman\nwhere salesman.commission &gt; 0.12;\n</code></pre> <ol> <li>Write a SQL statement to find the list of customers who appointed a salesman for their jobs who does not live in the same city where their customer lives, and gets a commission is above 12%.</li> </ol> <pre><code>select distinct customer.cust_name as Customer\nfrom customer join salesman\nwhere salesman.city != customer.city\n  and salesman.commission &gt; 0.12;\n</code></pre> <ol> <li>Write a SQL statement to make a join on the tables salesman, customer and orders in such a form that the same column of each table will appear once and only the relational rows will come.</li> </ol> <pre><code>select *\nfrom salesman natural join customer natural join orders;\n</code></pre> <ol> <li>Write a SQL statement to make a list in ascending order for the customer who works either through a salesman or by own.</li> </ol> <pre><code>select customer.cust_name as Customer\nfrom customer\norder by customer.cust_name asc;\n</code></pre> <ol> <li>Write a SQL statement to make a cartesian product between salesman and customer i.e. each salesman will appear for all customer and vice-versa.</li> </ol> <pre><code>select *\nfrom customer left outer join salesman\non customer.salesman_id = salesman.salesman_id;\n</code></pre> <p>Create course, prereq tables &amp; insert the values as given in the following tables</p>"},{"location":"2_Core/Database_Systems/Practicals/05/#course","title":"<code>course</code>","text":"course_id title dept_name credits BIO-301 Genetics Biology 4 CS-190 Game Design Comp. Sci. 4 CS-315 Robotics Comp. Sci. 3"},{"location":"2_Core/Database_Systems/Practicals/05/#prereq","title":"<code>prereq</code>","text":"course_id prereq_id BIO-301 BIO-101 CS-190 CS-101 CS-347 CS-101 <pre><code>use 20200198db;\nset foreign_key_checks = 0;\ndrop table if exists course, prereq;\nset foreign_key_checks  = 1;\n\ncreate table course (\n  course_id varchar(20),\n  title varchar(20),\n  dept_name varchar(20),\n  credits int,\n\n  primary key(course_id)\n);\n\ncreate table prereq (\n  course_id varchar(20),\n  prereq_id varchar(20),\n\n  primary key(course_id, prereq_id)\n##   foreign key(course_id) references course(course_id),\n##   foreign key(prereq_id) references course(course_id)\n);\n\ninsert into course values\n(\"BIO-301\", \"Genetics\" , \"Biology\", 4),\n(\"CS-190\", \"Game Design\", \"Comp. Sci.\", 4),\n(\"CS-315\", \"Robotics\", \"Comp. Sci.\", 3);\n\ninsert into prereq values\n(\"BIO-301\", \"BIO-101\"),\n(\"CS-190\", \"CS-101\"),\n(\"CS-347\", \"CS-101\");\n</code></pre> <ol> <li>Perform left outer join to get the following output.</li> </ol> course_id title dept_name credits prereq_id BIO-301 Genetics Biology 4 BIO-101 CS-190 Game Design Comp. Sci. 4 CS-101 CS-315 Robotics Comp. Sci. 3 <code>null</code> <pre><code>select *\nfrom course\nnatural left outer join prereq;\n</code></pre> <ol> <li>Perform right outer join to get the following output.</li> </ol> course_id title dept_name credits prereq_id BIO-301 Genetics Biology 4 BIO-101 CS-190 Game Design Comp. Sci. 4 CS-101 CS-347 <code>null</code> <code>null</code> <code>null</code> CS-101 <pre><code>select course_id, title, dept_name, credits, prereq_id\nfrom course\nnatural right outer join prereq;\n</code></pre> <ol> <li>Perform full outer join to get the following output.</li> </ol> course_id title dept_name credits prere_id BIO-301 Genetics Biology 4 BIO-101 CS-190 Game Design Comp. Sci. 4 CS-101 CS-315 Robotics Comp. Sci. 3 <code>null</code> CS-347 <code>null</code> <code>null</code> <code>null</code> CS-101 <pre><code>select *\nfrom course\nfull join prereq;\n## only thing that worked\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/06/","title":"06","text":"<p>Use the sample database named <code>sakila</code> and its tables in MySQL Workbench for this week\u2019s lab. Create views for the following queries. Name of the view should be in the format \u201cV1_YourStudentID\u201d for the first query. (For ex. V1_2019A7PS0001). You can view the list of tables in the sakila database using \u2018Show tables\u2019 as given in the following screenshot.</p> <pre><code>use sakila;\nshow tables;\n</code></pre> <ol> <li>Create a view to find all actors whose last name contain the letters GEN.</li> </ol> <pre><code>drop view if exists ActorGEN;\n\ncreate view ActorGEN as\nselect first_name as 'First Name', last_name as 'Last Name'\nfrom actor\nwhere last_name like \"%GEN%\";\n\nselect * from ActorGEN;\n</code></pre> <ol> <li>Create a view to display the country_id and country columns of the following  countries: Afghanistan, Bangladesh, and China using <code>in</code>.</li> </ol> <pre><code>drop view if exists countriesView;\n\ncreate view countriesView as\nselect country_id, country\nfrom country\nwhere country in (\"Afghanistan\", \"Bangladesh\", \"China\");\n\nselect * from countriesView;\n</code></pre> <ol> <li>Create a view to List each film and the number of actors who are listed for that  film. Use tables film_actor and film. Use inner join.</li> </ol> <pre><code>drop view if exists filmActors;\n\ncreate view filmActors as\nselect title as 'Film', count(actor_id) as 'Number of Actors'\nfrom film\n inner join film_actor\n on film.film_id = film_actor.film_id\ngroup by film.film_id;\n\nselect * from filmActors;\n</code></pre> <ol> <li>Create a view to List the last names of actors, as well as how many actors have  that last name.</li> </ol> <pre><code>drop view if exists actorLastNames;\n\ncreate view actorLastNames as\nselect last_name as 'Last Name', count(last_name) as 'No of People'\nfrom actor\ngroup by last_name;\n\nselect * from actorLastNames;\n</code></pre> <ol> <li>Create a view to List last names of actors and the number of actors who have  that last name, but only for names that are shared by at least two actors</li> </ol> <pre><code>drop view if exists actorLastNamesIDK;\n\ncreate view actorLastNamesIDK as\nselect last_name as 'Last Name', count(last_name) as 'No of People'\nfrom actor\ngroup by last_name\nhaving count(last_name) &gt;= 2;\n\nselect * from actorLastNamesIDK;\n</code></pre> <ol> <li>Create a view to display the first and last names, as well as the address, of each staff member. Use the tables staff and address. Use Join.</li> </ol> <pre><code>drop view if exists staffStuff;\n\ncreate view staffStuff as\nselect first_name as 'First Name', last_name as 'Last Name', \naddress as 'Address'\nfrom staff\n inner join address\n on staff.address_id = address.address_id;\n\nselect * from staffStuff;\n</code></pre> <ol> <li>Create a view to Use subqueries to display all actors who appear in the film  Alone Trip.</li> </ol> <pre><code>drop view if exists AloneTripActors;\n\ncreate view AloneTripActors as\nselect concat(first_name, \" \", last_name) as Actor\nfrom actor\nwhere actor.actor_id in (\n select film_actor.actor_id\n  from film_actor\n  where film_actor.film_id = (\n    select film.film_id\n    from film\n    where title = \"Alone Trip\"\n  )\n);\n\nselect * from AloneTripActors;\n</code></pre> <ol> <li>Create a view to Display the most frequently rented movies in descending order.</li> </ol> <pre><code>drop view if exists FreqRentedMovies;\n\ncreate view FreqRentedMovies as\nselect title as 'Film', count(rental_id) as 'Number of Rentals'\nfrom film\n inner join inventory\n on inventory.film_id = film.film_id\n inner join rental\n on rental.inventory_id = inventory.inventory_id\ngroup by title\norder by count(rental_id) desc;\n\nselect * from FreqRentedMovies;\n</code></pre> <ol> <li>Create a view to Write a query to display for each store its store ID, city, and country.</li> </ol> <pre><code>drop view if exists StoreView;\n\ncreate view StoreView as\nselect store_id as 'Store ID', city as City, country as Country\nfrom store\n inner join address\n     on address.address_id = store.address_id\n inner join city\n     on city.city_id = address.city_id\n inner join country\n     on country.country_id = city.country_id;\n\nselect * from StoreView;\n</code></pre> <ol> <li> <p>Drop any of the views you created.</p> <pre><code>drop view StoreView;\n</code></pre> </li> </ol>"},{"location":"2_Core/Database_Systems/Practicals/07/","title":"07","text":"<pre><code>use 20200198db;\nset foreign_key_checks = 0;\ndrop table if exists employee, dept, department, deptSalary;\ndrop procedure if exists updateSalary;\nset foreign_key_checks  = 1;\n\ncreate table dept(\n  dnumber integer,\n  dname varchar(20),\n\n  primary key(dnumber)\n);\n\ninsert into dept values\n(1, \"Payroll\"),\n(2, \"TechSupport\"),\n(3, \"Research\");\n\ncreate table employee(\n  id integer,\n  name varchar(20),\n  superId integer,\n  salary float(10, 4),\n  bdate date,\n  dno integer,\n\n  primary key(id),\n  foreign key(dno) references dept(dnumber)\n);\n\ninsert into employee values\n(1, \"john\", 3, 100000, \"1960-01-01\", 1),\n(2, \"mary\", 3, 50000, \"1964-12-01\", 3),\n(3, \"bob\", null, 80000, \"1974-02-07\", 3),\n(4, \"tom\", 1, 50000, \"1978-01-17\", 2),\n(5, \"bill\", null, null, \"1985-01-20\", 1);\n</code></pre> <pre><code>create table deptSalary as\nselect dnumber, 0 as totalSalary from dept;\n\ndelimiter \\\\\ncreate procedure updateSalary(IN paraml int)\nbegin\n    update deptSalary\n    set totalSalary = (\n        select sum(salary) from employee where dno = paraml\n    )\n    where dnumber = paraml;\nend; \\\\\ndelimiter ;\ncall updateSalary(1);\ncall updateSalary(2);\ncall updateSalary(3);\n\nselect * from deptSalary;\n\nselect * from employee;\ndrop function if exists giveRaise;\ndelimiter \\\\\ncreate function giveRaise(oldval double, amount double)\nreturns double\ndeterministic\nbegin\n    declare newval double;\n    set newval = oldval * (1+amount);\n    return newval;\nend \\\\\ndelimiter ;\n\nselect name, salary, giveRaise(salary, 0.1) as newsal from employee;\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/08/","title":"08","text":"<pre><code>use 20200198db;\nset foreign_key_checks = 0;\n\nset foreign_key_checks  = 1;\n</code></pre> <pre><code>## To Print \u201cHello World!\u201d\ndrop procedure if exists HelloWorld;\ndelimiter //\nCREATE PROCEDURE HelloWorld()\nBEGIN\nSELECT \"Hello World!\";\nEND; //\ndelimiter ;\nCALL HelloWorld();\n</code></pre> <pre><code>## To Print \u201cHello (with given name)\u201d using function\ndrop function if exists HelloName;\nCREATE FUNCTION HelloName(name VARCHAR(100))\nRETURNS VARCHAR(120) DETERMINISTIC\nRETURN CONCAT(\"Hello \", name);\nSET @fn_res = HelloName(\"BPDC\");\n\nselect @fn_res;\n</code></pre> <pre><code>## function to compute square\ndrop function if exists compute_square_fn;\ndelimiter //\ncreate function compute_square_fn(number int)\nreturns int\nbegin\nreturn number * number;\nend //\ndelimiter ;\nselect compute_square_fn(3);\n</code></pre> <pre><code>## function to compute area of circle\ndrop function if exists compute_circle_area;\ndelimiter //\ncreate function compute_circle_area(radius int)\nreturns float DETERMINISTIC\nbegin\nreturn 3.14*radius * radius;\nend\n//\ndelimiter ;\nselect compute_circle_area(4);\n</code></pre> <pre><code>## Control Statements\ndrop table if exists t;\ncreate table t(s1 int);\nINSERT INTO t VALUES (17);\n</code></pre> <pre><code>drop procedure if exists p12;\ndelimiter //\nCREATE PROCEDURE p12 (IN parameter1 INT)\nBEGIN\nDECLARE variable1 INT;\nSET variable1 = parameter1 + 1;\nIF variable1 = 0 THEN\n\nINSERT INTO t VALUES (17);\nEND IF;\nIF parameter1 = 0 THEN\n\nUPDATE t SET s1 = s1 + 1 where s1 = 17;\nELSE\nUPDATE t SET s1 = s1 + 2 where s1 = 17;\nEND IF;\nEND; //\n\ndelimiter ;\nCALL p12(1);\n</code></pre> <pre><code>## switch case\ndrop procedure if exists p13;\ndelimiter //\nCREATE PROCEDURE p13 (IN parameter1 INT)\nBEGIN\nDECLARE variable1 INT;\nSET variable1 = parameter1 + 1;\nCASE variable1\nWHEN 0 THEN\nINSERT INTO t VALUES (17);\nWHEN 1 THEN\nINSERT INTO t VALUES (18);\nELSE\nINSERT INTO t VALUES (19);\n\nEND CASE;\nEND; //\ndelimiter ;\nCALL p13(0);\nselect * from t;\n</code></pre> <pre><code>## while loop\ndrop procedure if exists p14;\ndelimiter //\nCREATE PROCEDURE p14 ()\nBEGIN\nDECLARE v INT;\nSET v = 0;\nWHILE v &lt; 5 DO\n\nINSERT INTO t VALUES (v);\n\nSET v = v + 1;\nEND WHILE;\nEND; //\ndelimiter ;\nCALL p14();\nselect * from t;\n</code></pre> <pre><code>## do-while loop\ndrop procedure if exists p15;\ndelimiter //\nCREATE PROCEDURE p15 ()\nBEGIN\nDECLARE v INT;\nSET v = 5;\nREPEAT\n\nINSERT INTO t VALUES (v);\n\nSET v = v + 1;\nUNTIL v &gt;= 10\nEND REPEAT;\nEND; //\ndelimiter ;\nCALL p15();\nselect * from t;\n</code></pre> <pre><code>## loop ... end loop\ndrop procedure if exists p16;\ndelimiter //\nCREATE PROCEDURE p16 ()\nBEGIN\nDECLARE v INT;\nSET v = 10;\nloop_label: LOOP\n\nINSERT INTO t VALUES (v);\n\nSET v = v + 1;\nIF v &gt;= 15 THEN\n\nLEAVE loop_label;\nEND IF;\nEND LOOP;\n\nEND; //\ndelimiter ;\nCALL p16();\n\nselect * from t;\n</code></pre> <pre><code>## display even-valued rows\nSELECT * FROM t WHERE MOD(s1, 2) = 0;\n</code></pre> <pre><code>## display odd-valued rows\nSELECT * FROM t WHERE MOD(s1, 2) != 0;\n</code></pre> <pre><code>## Use \u201cCASE\u201d to insert or update\ndrop procedure if exists assignment;\ndelimiter //\nCREATE PROCEDURE assignment (IN parameter1 INT, in parameter2 INT)\nBEGIN\nCASE parameter2\nWHEN 1 THEN\nINSERT INTO t VALUES (parameter1/parameter2);\nWHEN 2 THEN\nINSERT INTO t VALUES (parameter1/parameter2);\nELSE\nINSERT INTO t VALUES (parameter1);\n\nEND CASE;\nEND; //\ndelimiter ;\nCALL assignment(10, 0);\nCALL assignment(10, 1);\nCALL assignment(10, 2);\nselect * from t;\n</code></pre>"},{"location":"2_Core/Database_Systems/Practicals/09/","title":"09","text":"<ol> <li>Trigger to update the total salary of a department when a new employee is hired</li> </ol> <pre><code>drop trigger if exists update_salary_on_insert;\n\ndelimiter \\\\\ncreate trigger update_salary_on_insert\nafter insert on employee\nfor each row\nbegin\n if new.dno is not null then\n     update deptSalary\n        set totalSalary = totalSalary + new.salary\n        where dnumber = new.dno;\n    end if;\nend \\\\\ndelimiter ;\n\nselect * from deptSalary;\ninsert into employee value(6, \"Lucy\", null, 90000, \"1981-01-01\", 1);\nselect * from deptSalary;\ninsert into employee values(7, \"George\", null, 45000, \"1971-11-11\", null);\nselect * from deptSalary;\n</code></pre> <ol> <li>Trigger to update the total salary of a department when an employee tuple is modified    (Adding/subtracting the difference is not safe, as there may be cases where the employee shifts to different department)</li> </ol> <pre><code>drop trigger if exists update_salary_on_update;\n\ndelimiter \\\\\ncreate trigger update_salary_on_update\nafter update on employee\nfor each row\nbegin\n if old.dno is not null then\n     update deptSalary\n        set totalSalary = totalSalary - old.salary\n        where dnumber = old.dno;\n    end if;\n    if new.dno is not null then\n     update deptSalary\n        set totalSalary = totalSalary + new.salary\n        where dnumber = new.dno;\n    end if;\nend \\\\\ndelimiter ;\n\nselect * from deptSalary;\nupdate employee set salary = 100000 where id = 6;\nselect * from deptSalary;\n</code></pre> <ol> <li>Trigger to update the total salary of a department when an employee tuple is deleted</li> </ol> <pre><code>drop trigger if exists update_salary_on_delete;\n\ndelimiter \\\\\ncreate trigger update_salary_on_delete\nbefore delete on employee\nfor each row\nbegin\n if old.dno is not null then\n     update deptSalary\n        set totalSalary = totalSalary - old.salary\n        where dnumber = old.dno;\n    end if;\nend \\\\\ndelimiter ;\n\nselect * from deptSalary;\ndelete from employee where id = 6;\nselect * from deptSalary;\ndelete from employee where id = 7;\nselect * from deptSalary;\n</code></pre>"},{"location":"2_Core/Digital_Design/","title":"Digital Design","text":"Class Instructor Lecture Dr. Swarnalatha Tutorial Dr. Vilas Gaidhane Practical Dr. Jagadish Nayak <p>This course is about deriving and implementing logic circuits (such as adders) and sequential circuits such as counters.</p> <p>This course is a pre-requisite to understanding Microprocessors and Interfacing in the next semester.</p>"},{"location":"2_Core/Digital_Design/01_Intro/","title":"01 Intro","text":""},{"location":"2_Core/Digital_Design/01_Intro/#binary-constants","title":"Binary constants","text":"<p>0 = off/high-level voltage</p> <p>1 = on/low-level voltage</p>"},{"location":"2_Core/Digital_Design/01_Intro/#logic-system","title":"Logic system","text":"<p>There is 10% tolerance</p>"},{"location":"2_Core/Digital_Design/01_Intro/#positive","title":"Positive","text":"<ul> <li>0 =  0v ()</li> <li>1 = 5v (4.5v - 5v)</li> </ul>"},{"location":"2_Core/Digital_Design/01_Intro/#negative","title":"Negative","text":"<ul> <li>0 = 0v</li> <li>1 = </li> </ul>"},{"location":"2_Core/Digital_Design/01_Intro/#pulse-notations","title":"Pulse Notations","text":""},{"location":"2_Core/Digital_Design/01_Intro/#rise-time","title":"Rise time","text":"<p>Time from 10% to 90% V</p>"},{"location":"2_Core/Digital_Design/01_Intro/#fall-time","title":"Fall Time","text":"<p>Time from 90% to 10% V</p>"},{"location":"2_Core/Digital_Design/01_Intro/#pulse-width","title":"Pulse Width","text":"<p>Time from 50% V of one end to 50% V of the other end</p>"},{"location":"2_Core/Digital_Design/01_Intro/#duty-cycle","title":"Duty Cycle","text":"<p>T = time period = T<sub>on</sub> + T<sub>off</sub></p>"},{"location":"2_Core/Digital_Design/01_Intro/#verilog","title":"Verilog","text":"<p>Verifying logic</p> <p>Hardware Description language</p> <p>Execution of lines in program happens concurrently</p>"},{"location":"2_Core/Digital_Design/01_Intro/#ports","title":"Ports","text":"<p>Input, outputs, wires, registers</p>"},{"location":"2_Core/Digital_Design/01_Intro/#multiple-bits","title":"Multiple Bits","text":"<p>Create an array</p> <p>In verilog, arrays are numbered in reverse</p> <pre><code>input[3:0] a; // 4bit          3 2 1 0\ninput[7:0] b; // 8bit  7 6 5 4 3 2 1 0\n\na = 4'b0000;\nb = 8'b1010100;\n</code></pre>"},{"location":"2_Core/Digital_Design/01_Intro/#modelling","title":"Modelling","text":""},{"location":"2_Core/Digital_Design/01_Intro/#types","title":"Types","text":"Gate level Dataflow Behavior Modelling Structural low level medium level high level definining gates mathematical (arithmetic/boolean) operations describe the behavior of the circuit custom gates or inbuilt gate like and(), or(), nand() <code>assign</code> 2 structures procedures - <code>initial</code>, <code>always</code> 2types of module instantiation <code>or(y, a, b);</code><code>or(z, c, d);</code> <code>assign y = a|b;</code><code>assign z = c|d;</code> <code>if(a==0 &amp;b==0)</code><code>y = 0</code> <code>else</code><code>y = 1</code> <code>or g1(y, a, b);</code><code>or g2(z, c, d);</code> <code>initial</code> <code>always</code> runs statement only once, during the entire simulation run continuous infinite loop Starts at t = 0 t = 0 <pre><code>initial\n  begin\n    statement;\n  end\n\nalways\n  begin\n    statement;\n  end\n\n//behavioral\n//example\nalways\n  #5 A = ~A; // invert every 5 nanoseconds\n\nalways\n  begin\n    #2 a = 1;\n    #3 a = 0;\n  end\n</code></pre>"},{"location":"2_Core/Digital_Design/01_Intro/#examples","title":"Examples","text":"<ol> <li>y = a or b or c</li> </ol> <pre><code>module or_gate(A, B,C, y); // ports, initialisation\n  input A, B, C; // declaration\n  output y; // declaration\n\n  // description, always (output, input)\n  or(y, A, B, C); // gate level modelling\n  assign y = A|B|C; // data flow modelling\n  end module\n</code></pre> <ol> <li>p = s', q = I<sub>0</sub>S, r = I<sub>1</sub>S    y = q+r</li> </ol> <pre><code>module circuit_1(I0, I1, S, y);\n    input I0, I1, s;\n  output y;\n  wire p, q, r;\n\n  not #1 G1(p, s); // #1 = time delay of 1ns\n  and #2 G2(q, i0, p); // #2 = time delay of 2ns\n  and #2 g3(r, s, i1);\n  or #2 g4(y, q, r);\n  end module\n</code></pre> <ol> <li>p = s', q = I<sub>0</sub>S, r = I<sub>1</sub>S    y = q+r    Dataflow</li> </ol> <pre><code>module circuit_1(I0, I1, S, y);\n input I0, I1, s;\n  output y;\n  wire p, q, r;\n\n  assign #1 p = Ns;\n  assign #2 q = i0 &amp; p;\n  assign #2 r = i1 &amp; s;\n  assign #2 y = q | r;\n\n  end module\n</code></pre> <ol> <li>Behavioral     <pre><code>module or_behavior(a,b,z);\n  output reg z;\n  always @ * // (a or b) // sensitivity list\n    begin\n      if (a == 1'b0 &amp; b == 1'b0) // 1 bit binary\n                z = 1'b0;\n      else\n        z = 1'b1;\n    end\nendmodule\n\nalways @ * begin   \n  case(s)\n    2'b00: // statement\n    2'b01: // statement\n    2'b10: // statement\n    2'b11: // statement\n  endcase\nend\n</code></pre></li> </ol>"},{"location":"2_Core/Digital_Design/01_Intro/#breadboard","title":"Breadboard","text":""},{"location":"2_Core/Digital_Design/02_Gates/","title":"02 Gates","text":""},{"location":"2_Core/Digital_Design/02_Gates/#gates","title":"Gates","text":"a b a' \\(a \\cdot b\\) a + b a nand b a nor b a xor b a xnor b 0 0 1 0 0 1 1 0 1 0 1 0 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 1 1 1 0 0 0 1"},{"location":"2_Core/Digital_Design/02_Gates/#verilog-codes","title":"Verilog Codes","text":"<pre><code>module gates(y, a, b);\n  input a, b;\n  output y;\n  wire andg, org, notg, nandg, norg, xorg, xnorg;\n\n  assign andg = a &amp; b;\n  assign org = a | b;\n  assign notg = ~a;\n\n  assign nandg = ~ (a&amp;b);\n  assign norg = ~ (a|b);\n\n  assign xorg = a^b;\n  assign xnorg = ~(a^b);\n\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/02_Gates/#bubbled-gates","title":"Bubbled Gates","text":"<p>inputs to the gates are negated</p> Bubbled AND Bubbled OR Function \\(y = a' \\cdot b'\\) \\(y = a' + b'\\) Another name Negative AND Negative OR equivalent to NOR NAND"},{"location":"2_Core/Digital_Design/02_Gates/#verilog","title":"Verilog","text":"<pre><code>module gates(y, a, b);\n  input a, b;\n  output y;\n  wire band, bor;\n\n  assign band = ~a &amp; ~b;\n  assign bor = ~a | ~b;\n\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/02_Gates/#universal-gates","title":"Universal Gates","text":"<p>NAND &amp; NOR are called universal gates because we can implement all other gates with just these 2</p>"},{"location":"2_Core/Digital_Design/02_Gates/#for-not","title":"for NOT","text":"<p>for NAND and OR, just split a single input into 2 wires and pass it through the gate</p> <pre><code>module gates(y, z, a, b);\n  input a, b;\n  output y, z;\n\n  assign y = nand(a, b);\n  assign z = nor(a, b);\n\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/02_Gates/#for-or","title":"for OR","text":"<p>NOR</p> <ol> <li>use a gate</li> <li>complement the output</li> </ol> <p>NAND</p> <ol> <li>complement a, b individually </li> <li>Complement the output using another gate</li> </ol> <pre><code>module gates(y, a, b);\n  input a, b;\n  output y;\n  wire p, q;\n\n  assign p = nor(a, b); // (a+b)'\n  assign y = nor(p, p); // a+b\n\n  assign p = nand(a, a); // a'\n  assign q = nand(b, b); // b'\n  assign y = nand(p, q); // (a' . b')' = a + b\n\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/02_Gates/#for-and","title":"for AND","text":"<p>NAND</p> <ol> <li>use a gate</li> <li>complement the output using another gate</li> </ol> <p>NOR</p> <ol> <li>complement a, b invidually</li> <li>Complement the output using another gate</li> </ol> <pre><code>module gates(y, a, b);\n  input a, b;\n  output y;\n  wire p, q;\n\n  assign p = nand(a, b); // (a*b)'\n  assign y = nand(p, p); // a*b\n\n  assign p = nor(a, a); // a'\n  assign q = nor(b, b); // b'\n  assign y = nor(p, q); // (a' + b')' = a * b\n\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/03_Number_Systems/","title":"03 Number Systems","text":""},{"location":"2_Core/Digital_Design/03_Number_Systems/#number-systems","title":"Number Systems","text":"<p>\\(d_{n-1} \\dots d_2 \\ d_1 \\ d_0 . d_{-1} \\ d_{-2}\\)</p> <ul> <li>\\(d_{n-1} \\to d_0\\) = integer part</li> <li>\\(d_{-1} \\to \\dots\\) = fraction part</li> <li> <p>\\(d_{n-1}\\) = MSD (most significant digit)</p> </li> <li> <p>\\(d_0\\) = LSD (least significant digit)</p> </li> </ul> Decimal Binary Octal Hexa 10 2 8 16 Groups of 3bits Groups of 4bits Decimal Binary Octal Hexa 0 0 0 0 1 1 1 1 2 10 2 2 3 11 3 3 4 100 4 4 5 101 5 5 6 110 6 6 7 111 7 7 8 1000 10 8 9 1001 11 9 10 1010 12 A 11 1011 13 B 12 1100 14 C 13 1101 15 D 14 1110 16 E 15 1111 17 F"},{"location":"2_Core/Digital_Design/03_Number_Systems/#binary","title":"Binary","text":"<p>Bit = each digit</p> <p>Nibble = group of 4bits</p> <p>Byte = group of 8bits</p> Unsigned Signed Magnitude 1's comp 2's comp Range \\(+(2^n - 1)\\) \\(-(2^{n-1} - 1) \\longleftrightarrow +(2^{n-1} - 1)\\) \\(-(2^{n-1} - 1) \\longleftrightarrow +(2^{n-1} - 1)\\) \\(-(2^{n-1} - 1) \\longleftrightarrow +2^{n-1}\\) +ve regular same as unsigned same as unsigned same as unsigned -ve - invert MSD Bit-by-bit complement of unsigned 1. Bit-by-bit complement of unsigned2. Add 1 +ve MSD 0 0 0 0 -ve MSD - 1 1 1 <pre><code>// 1s comp\nmodule ones(a,y);\n  input[3:0] a; // 4bits (0 to 3)\n  output[3:0] y;\n  assign y = ~a;\nendmodule\n\n// 2s comp\nmodule twos(a,y);\n  input[3:0] a; // 4bits (0 to 3)\n  output[3:0] y;\n  assign y = (~a) + 1;\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/03_Number_Systems/#decimal","title":"Decimal","text":""},{"location":"2_Core/Digital_Design/03_Number_Systems/#octal","title":"Octal","text":""},{"location":"2_Core/Digital_Design/03_Number_Systems/#hexadecimal","title":"Hexadecimal","text":""},{"location":"2_Core/Digital_Design/04_Codes/","title":"04 Codes","text":""},{"location":"2_Core/Digital_Design/04_Codes/#bcd","title":"BCD","text":"<p>Binary Coded Decimal</p> <p>Each digit of decimal will be represented in 4bit binary</p> <p>To convert a number &gt; 9, we add 6 (tutorial)</p> <p>Eg: 33 = 0011 0011</p>"},{"location":"2_Core/Digital_Design/04_Codes/#gray-code","title":"Gray Code","text":"<p>Reflection/Unit distance code</p> <p>Mirror the halfway horizontally</p> <p>just a way to send information in a private method</p>"},{"location":"2_Core/Digital_Design/04_Codes/#1-bit","title":"1 Bit","text":"<p>0</p> <p>1</p>"},{"location":"2_Core/Digital_Design/04_Codes/#2-bit","title":"2 Bit","text":"<p>0 0 = 0</p> <p>0 1 = 1</p> <p>1 1 = 2</p> <p>1 0 = 3</p>"},{"location":"2_Core/Digital_Design/04_Codes/#3-bit","title":"3 Bit","text":"<p>0 0 0 = 0</p> <p>0 0 1</p> <p>0 1 1</p> <p>0 1 0</p> <p>1 1 0</p> <p>1 1 1</p> <p>1 0 1</p> <p>1 0 0</p>"},{"location":"2_Core/Digital_Design/04_Codes/#xor-gate-shortcut","title":"XOR gate Shortcut","text":"<p>odd one detector</p>"},{"location":"2_Core/Digital_Design/04_Codes/#binary-to-gray","title":"Binary to Gray","text":"<ol> <li>convert into binary</li> <li>do XOR of</li> <li>Bring 1<sup>st</sup> digit down as it is</li> <li>do XOR of adjacent elements</li> </ol>"},{"location":"2_Core/Digital_Design/04_Codes/#gray-to-binary","title":"Gray to Binary","text":"<ol> <li>bring 1<sup>st</sup> digit down as it is</li> <li>do XOR diagonally after that</li> </ol>"},{"location":"2_Core/Digital_Design/04_Codes/#error-detection-and-code-correction","title":"Error detection and code correction","text":"<p>Parity is a technique to convert codes with even no of 1s or odd no of 1s by adding an extra bit.</p> <p>Parity Bit is added in MSD position</p> <p>we add a 1, if the number violates the parity type</p>"},{"location":"2_Core/Digital_Design/04_Codes/#even-parity-generator","title":"Even parity generator","text":"<p>we need even no of 1s</p> <p>value of binary with even no doesn't get affected</p> <p>XOR gate</p> a b c even parity odd parity 0 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 0 <p>Eg</p> <ol> <li>_ 0 0 1 0 0 1 (even no of 1s)    0 0 0 1 0 0 1</li> <li>_ 0 0 1 0 1 1 (odd no of 1s)    1 0 0 1 0 1 1</li> </ol> <p>Circuit contains 2 XOR gates, or we can just do with one </p>"},{"location":"2_Core/Digital_Design/04_Codes/#even-parity-checker","title":"Even Parity Checker","text":"<p>Checking if the parity being sent along with the bits is correct or not</p> <p>Circuit contains 3 XOR gates</p> <p>If there is no error, c = 0 If there is error, then c = 1</p> P X Y Z CheckerC 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0"},{"location":"2_Core/Digital_Design/04_Codes/#odd-parity-generator","title":"Odd parity generator","text":"<p>Circuit contains 2 XOR gates and 1 final not gate</p> <p>or XNOR gate</p>"},{"location":"2_Core/Digital_Design/04_Codes/#odd-parity-checker","title":"Odd parity checker","text":""},{"location":"2_Core/Digital_Design/04_Codes/#disadvantage-of-odd-and-even-parity","title":"Disadvantage of odd and even parity","text":"<p>we cannot find out where the error is present</p> <p>eg: 1001 is correct even parity but if the other end receives 0101, it is still correct by even parity, but it's not the same value</p>"},{"location":"2_Core/Digital_Design/04_Codes/#hamming-code","title":"Hamming Code","text":"<p>\\(A(t, m)\\)</p> <p>eg: A (7, 4) means 7 total bits, 4 message bits; this means there are 3 parity bits</p> <p>given no \\(= m_1 m_2 \\dots m_m\\) (b = the bit)</p> <p>Advantage</p> <ol> <li>we can generate parity</li> <li>check parity</li> <li>if there is any error, we can correct</li> </ol>"},{"location":"2_Core/Digital_Design/04_Codes/#no-of-parities","title":"No of Parities","text":"<p>\\(2^p \\ge p + m + 1\\)</p> <ul> <li>p = no of parity bits</li> <li>m = no of message bits</li> </ul> <p>final message will have (m+p) no of bits</p>"},{"location":"2_Core/Digital_Design/04_Codes/#position-of-parity","title":"Position of parity","text":"<p>Parities are added in the place of 2 powers, ie, \\(2^0, 2^1, 2^2, 2^3, \\dots\\), ie</p> <ul> <li>1<sup>st</sup> position</li> <li>2<sup>nd</sup> position</li> <li>4<sup>th</sup> position</li> <li>8<sup>th</sup> position</li> <li>so on</li> </ul>"},{"location":"2_Core/Digital_Design/04_Codes/#example","title":"Example","text":"1 2 3 4 5 6 7 p1 p2 m1 p4 m2 m3 m4"},{"location":"2_Core/Digital_Design/04_Codes/#value-of-parity","title":"Value of Parity","text":"<p>For even parity</p> <p>For 3 parities, create a table of 3bit input and wherever there is one is the positions of the parities</p> <ul> <li>\\(P_1 \\to 1, 3, 5, 7\\)</li> <li>\\(P_2 \\to 2, 3, 6, 7\\)</li> <li>\\(P_3 \\to 4, 5, 6, 7\\)</li> </ul> <p>For 4 parities, create a table of 4bit input and wherever there is one is the positions of the parities</p> <ul> <li>\\(P_1 \\to 1, 3, 5, 7, 9\\)</li> <li>\\(P_2 \\to\\)</li> <li>\\(P_3 \\to\\)</li> <li> <p>\\(P_4 \\to\\)</p> </li> <li> <p>A (7, 4) (total, message) is received as 1 0 1 0 1 1 1. Determine the correct code when even parity exists.</p> </li> <li>1 0 0 1 1 0 1 0</li> </ul>"},{"location":"2_Core/Digital_Design/04_Codes/#verilog-for-hamming","title":"Verilog for Hamming","text":"<p>m1 = D0, m2 = D1,\\(m_n = D_{n-1}\\) </p> <pre><code>module hamming_code(t, m);\n  input[3:0] m;\n  output[6:0] t;\n  wire p1, p2, p3;\n  assign p1 = (m[0] ^ m[1] ^ m[3]); // 1 3 5 7\n  assign p2 = (m[0] ^ m[2] ^ m[3]); // 2 3 6 7\n  assign p3 = (m[1] ^ m[2] ^ m[3]); // 4 5 6 7\n\n  assign t = {p1, p2, m[0], p3, m[1], m[2], m[3]};\n</code></pre>"},{"location":"2_Core/Digital_Design/05_Boolean/","title":"05 Boolean","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#boolean-laws","title":"Boolean Laws","text":"Law Formula Complementation \\(\\bar0 = 1\\)\\(\\bar1 = 0\\)\\(\\bar{\\bar{x}} = x\\) and \\(x \\cdot 1 = x\\)\\(x \\cdot 0 = 0\\)\\(x \\cdot x = x\\)\\(x \\cdot \\bar x = 0\\) or \\(x + 0 = x\\)\\(x + 1 = 1\\)\\(x + x = x\\)\\(x + \\bar x = 1\\) commutative \\(x + y = y + x\\)\\(xy = yx\\) Associative \\(x+(y+z) = (x+y)+z\\)\\(x(yz) = (xy) z\\) Distributive \\(x(y+z) = xy + xz\\)\\(x + yz = (x+y)(x+z)\\) Demorgan's \\(\\overline{x+y} = \\bar x \\cdot \\bar y\\)\\(\\overline{x \\cdot y} = \\bar x + \\bar y\\)"},{"location":"2_Core/Digital_Design/05_Boolean/#duality-principle","title":"Duality Principle","text":"<p>We can obtain the dual of any boolean expression by</p> <ol> <li>operators are interchanged</li> <li>and -&gt; or</li> <li>or -&gt; and</li> <li>identity elements are inverted</li> <li>1 -&gt; 0</li> <li>0 -&gt; 1</li> </ol>"},{"location":"2_Core/Digital_Design/05_Boolean/#boolean-functions","title":"Boolean Functions","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#sop-sigma","title":"SOP (\\(\\Sigma\\))","text":"<p>Sum of Product</p> <p>Represented by NAND gate</p> \\[ \\begin{aligned} f(a,b,c) &amp;= ab + bc \\\\ g(a,b,c) &amp;= a'b + b'c \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/05_Boolean/#pos-pi","title":"POS (\\(\\pi\\))","text":"<p>Product of Sum</p> <p>Represented by NOR gate</p> \\[ \\begin{aligned} f(a,b,c) &amp;= (a+b)(b+c) \\\\ g(a,b,c) &amp;= (a'+b)(b'+c) \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/05_Boolean/#canonical-form","title":"Canonical Form","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#literal","title":"Literal","text":"<p>Each variable within a term of a Boolean expression.</p>"},{"location":"2_Core/Digital_Design/05_Boolean/#minterms","title":"Minterms","text":"<p>SOP</p> \\[ m_0 + m_1 + m_2 + \\dots \\] <p>Minterm (0) is targeted \\(x' = 0, x = 1\\), Minterms are wherever the output is 1</p> <p>Denoted by m<sub>0,1,2</sub></p> <p>They are \\(2^n\\) possible combinations of AND terms, n = no of literals</p> <p>in AND terms, a literal is</p> <ul> <li> <p>primed if its value is 0 (complemented)</p> </li> <li> <p>unprimed if its value is 1</p> </li> </ul> <p>so that the AND of all literals are always 1</p>"},{"location":"2_Core/Digital_Design/05_Boolean/#2-variable-minterm","title":"2 variable minterm","text":"\\[ 2^2 = 4 \\] x y Minterm Notation 0 0 x'y' m<sub>0</sub> 0' 0' = 1 0 1 x'y m<sub>1</sub> 0' 1 = 1 1 0 xy' m<sub>2</sub> 1 0' = 1 1 1 xy m<sub>3</sub> 1 1 = 1"},{"location":"2_Core/Digital_Design/05_Boolean/#3-var-minterm","title":"3 var minterm","text":"\\[ 2^3 = 8 \\] 0 0 0 x'y'z' m<sub>0</sub> 0 0 1 x'y'z m<sub>1</sub> 0 1 0 x'yz' m<sub>2</sub> 0 1 1 x'yz m<sub>3</sub> 1 0 0 xy'z' m<sub>4</sub> 1 0 1 xy'z m<sub>5</sub> 1 1 0 xyz' m<sub>6</sub> 1 1 1 Xyz m<sub>7</sub>"},{"location":"2_Core/Digital_Design/05_Boolean/#maxterms","title":"Maxterms","text":"<p>POS</p> \\[ M_0 \\cdot M_1 \\cdot M_3 \\cdot \\dots \\] <p>Maxterm (1) is targeted \\(x' = 1, x = 0\\), maxterms are wherever the output is 0</p> <p>Denoted by M<sub>0,1,2</sub></p> <p>In maxterms, there are\\(2^n\\) of OR terms</p> <p>In OR terms, literal is</p> <ul> <li>Primed if value is 1</li> <li>unprimed if value is 0</li> </ul> <p>so that all the OR of all literals is 0</p> x y Maxterm Notation 0 0 x + y M<sub>0</sub> 0 + 0 = 0 0 1 x + y' M<sub>1</sub> 0 + 1' = 0 1 0 x' + y M<sub>2</sub> 1' + 0 = 0 1 1 x' + y' M<sub>3</sub> 1' + 1' = 0"},{"location":"2_Core/Digital_Design/05_Boolean/#3-var-minterm_1","title":"3 var minterm","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#statements","title":"Statements","text":"<ul> <li>Any given functions can be expressed in canonical form without using truth table</li> <li>For sum of minterms<ul> <li>insert sum of missing literal and its complement</li> <li>AND operation b/w terms</li> <li>expand</li> </ul> </li> <li>For product of maxterms, insert product of missing literal and its complement with OR operation, and expand</li> </ul> <p>basically,</p> \\[ \\begin{aligned}  &amp; \\ xyz + xy \\\\ =&amp; \\ xyz + xy(z+z') \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/05_Boolean/#k-map","title":"K-Map","text":"<p>Karnaugh map</p> <p>uses grey code, as only 1 bit changes from one place to the next</p> <p>pictorial form of truth table used to simplify Boolean functions</p> <p>made up of squares All the squares represent minterm, or all represent maxterm</p>"},{"location":"2_Core/Digital_Design/05_Boolean/#minterm","title":"Minterm","text":"<p>Result will be SOP</p>"},{"location":"2_Core/Digital_Design/05_Boolean/#maxterm","title":"Maxterm","text":"<p>Result will be POS</p>"},{"location":"2_Core/Digital_Design/05_Boolean/#2-var-kmap","title":"2 Var KMap","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#3-var-kmap","title":"3 Var KMap","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#4-var-kmap","title":"4 Var KMap","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#simplification-of-boolean-using-kmap","title":"Simplification of Boolean using KMap","text":""},{"location":"2_Core/Digital_Design/05_Boolean/#minterm_1","title":"Minterm","text":"<ul> <li>Each square with a 1 is an implicant</li> <li>Combine adjacent implicants to form prime implicant</li> </ul>"},{"location":"2_Core/Digital_Design/05_Boolean/#rules-for-kmap-grouping","title":"Rules for KMap grouping","text":"<ol> <li>Group size can be in terms of \\(2^n\\)</li> <li>Try to always group in the max size</li> <li>In a group, there should be at least one minterm(1)/maxterm(0) which is not a part of any other group    Otherwise, it will be a redundant group</li> </ol>"},{"location":"2_Core/Digital_Design/05_Boolean/#dont-care-condition","title":"Don't care condition","text":"<p>represents undefined function</p> <p>The don't care terms are represented as \\(X\\)</p> <p>Consider the don't care terms as</p> <ul> <li>1 for maxterm</li> <li>0 for minterm</li> </ul> <p>for minterm KMap, you can consider the don't care terms as 1 for maxterm KMap, you can consider the don't care terms as 0</p> <p>Not all don't care terms are necessary to be grouped, but if inclusion leads to larger groups of minterms, then include them also to minimize the function</p> <p>When grouping, make sure that is at least one real minterm/maxterm in every group</p>"},{"location":"2_Core/Digital_Design/05_Boolean/#idk","title":"IDK","text":"<ul> <li>AOI - AND OR inverter - SOP</li> <li>OAI - OR AND inverter - POS</li> </ul>"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/","title":"06 Digital Circuits","text":""},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#digital-circuits","title":"Digital circuits","text":"<ul> <li>combinational circuits</li> <li>sequential circuits</li> </ul> Combinational Sequential output depends on input inputpresent state storage \u274c \u2705 memory \u274c \u2705 Feedback(recursive input) \u274c \u2705"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#applications-of-combinational-circuits","title":"Applications of combinational circuits","text":"<ol> <li>Arithmetic and logic functions</li> <li>adder</li> <li>subtractor</li> <li>comparator</li> <li>PLD (Programmable Logic Device)</li> <li>Data Transmission</li> <li>multiplexer</li> <li>de-multiplexer</li> <li>encoder</li> <li>decoder</li> <li>code conversion</li> <li>Binary</li> <li>BCD</li> <li>7-Segment</li> </ol>"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#sequential-logic-circuit","title":"Sequential Logic Circuit","text":"<p>output depends on present inputs and past outputs (feedback)</p> <p>sequential circuit will have storage elements to store the past outputs so that they can be fed back to the input</p> <p>therefore, sequential circuit can be expressed as a combinational circuit with storage and feedback element</p> <pre><code>flowchart LR\nInputs --&gt; c[Combinational Circuit] --&gt; Outputs --&gt; s[Storage Element] --&gt; c</code></pre>"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#states","title":"States","text":"<ul> <li> <p>Present state</p> </li> <li> <p>Next state</p> </li> </ul>"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#examples","title":"Examples","text":"<ol> <li>counters</li> <li>shift registers</li> <li>sequence detector</li> <li>function generator</li> </ol>"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#clock","title":"Clock","text":"<p>is a periodic square pulse</p> <p>has 3 features</p> <ol> <li>rising(+ve) edge \\(( \\to )\\) \\((\\uparrow)\\)    not ideal, but alright for trigger because it is only for a short duration, but requires power</li> <li>level(neutral) edge \u2014    worst for trigger because large power required and duration is for \\(t\\) seconds</li> <li>falling(-ve) edge \\((\\to)\\) with a bubble \\((\\downarrow)\\)    best for trigger because it is only for a short duration and requires least power</li> </ol> <p>always low logic design is the best as it requires the least power</p>"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#types-of-sequential-circuits","title":"Types of Sequential Circuits","text":"<ol> <li>+ve trigger/sensitive</li> <li>Level trigger/sensitive</li> <li>-ve trigger/sensitive</li> </ol>"},{"location":"2_Core/Digital_Design/06_Digital_Circuits/#storage-elements","title":"Storage elements","text":"Latches FlipFlops Clock \u274c \u2705 Sync Type Asynchronous Asynchronous/Synchronous Trigger Type Level Edge"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/","title":"07 AdderSubtractor","text":""},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#adders","title":"Adders","text":""},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#half-adder","title":"Half-Adder","text":"<p>Combination circuit that performs arithmetic sum of 2 single bit binary</p> <p>Limitation: Adding carry is not possible</p> x y C S 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 <p>\\(S = x \\oplus y, C= xy\\)</p> <pre><code>module half_adder(s, c, a, b);\n    input a, b;\n  output s, c;\n\n  xor(s, a, b);\n  and(c, a, b);\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#full-adder","title":"Full Adder","text":"<p>Arithmetic sum of 3 bit binary</p> x y c S C 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 <ul> <li>\\(S = x \\oplus y \\oplus c\\)</li> <li>\\(C = xy + c(x \\oplus y)\\)</li> </ul> <pre><code>module fullAdder(sum, carry, a, b, c);\n  input a, b, c;\n  output sum, carry;\n  wire p, q, r;\n\n  xor(sum, a, b, c);\n\n  and(p, a, b)\n  xor(q, a, b);\n  and(r, q, c);\n  or(carry, p, r);\n</code></pre>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#full-adder-using-half-adders","title":"Full adder using half adders","text":"<p>2 half adders</p> <p>We need the algebraic expressions as full adder, but using 2 half adders</p> <p>Verilog code in slide 12</p>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#4-bit-binary-adder","title":"4 bit binary adder","text":"<p>also called as</p> <ul> <li>4 bit ripple adder</li> <li>4 bit parallel adder</li> </ul> <p>binary adder performs arithmetic sum of two binary nos</p> <p>to add two n bit binary nos, n no of full adders are required</p> C3 C2 C1 C0 \\(C_{in}\\) A3 A2 A1 A0 (+) B3 B2 B1 B0 S3 S2 S1 S0"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#diagram","title":"Diagram","text":""},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#subtractors","title":"Subtractors","text":""},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#half-subtractor","title":"Half Subtractor","text":"x y B D 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 0 <ul> <li>\\(D = x'y + xy' = x \\oplus y\\)</li> <li>\\(B = x'y\\)</li> </ul> <pre><code>module halfSub(D, B, x, y);\n    input x, y;\n  output D, B;\n\n    assign D = x ^ y;\n  assign B = ~x + y;\n\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#full-subtractor","title":"Full Subtractor","text":"x y b D B 0 0 0 0 0 0 0 1 1 1 0 1 0 1 1 0 1 1 0 1 1 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1 <ul> <li>\\(D = x \\oplus y \\oplus b\\)</li> <li>\\(B = x'y + b(x \\oplus y)'\\)</li> </ul>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#full-subtractor-using-half-subtractor","title":"Full Subtractor using half-subtractor","text":"<p>2 half-subtractors</p>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#binary-subtraction","title":"Binary Subtraction","text":"<p>Practically, binary subtraction is performed only in 2\u2019s complement form. Therefore, subtractor circuit is not of much use.</p> <p>\\(A - B = A + \\underbrace{(-B)}_\\text{2's complement}\\)</p> <p>The complement of binary can be obtained using XOR gate</p>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#parallel-subtractor","title":"Parallel subtractor","text":"<p>Binary subtractor using 2\u2019s complement</p>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#diagram_1","title":"Diagram","text":""},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#other","title":"Other","text":""},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#4-bit-binary-parallel-addersubtractor","title":"4 bit binary parallel adder/subtractor","text":"<p>\\(V = c_2 \\oplus c_3\\)</p> <p>V denotes the overflow</p> <ul> <li>addition<ul> <li>M = C<sub>0</sub> = 0</li> <li>no change to the inputs by the XOR gate</li> <li>Eg: \\(B_0 \\oplus 0 = B_0\\)</li> <li>S = A + B + M = A + B + 0 = A + B</li> <li>V = 0 means no overflow</li> <li>V = 1 means overflow</li> </ul> </li> <li>subtraction<ul> <li>M = C<sub>0</sub> = 1</li> <li>the inputs will get complemented by the XOR gate</li> <li>Eg:\\(B_0 \\oplus 1 = {B_0}'\\)</li> <li>S = A + 1s comp of B + C = A + 1s comp of B + 1 = A + 2s comp of B</li> <li>V = 0 means no overflow</li> <li>V = 1 means overflow</li> </ul> </li> </ul>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#bcd-adder","title":"BCD Adder","text":"<ul> <li>valid values are from 0-9</li> <li>10-15 are invalid (and hence will be don\u2019t care condition)</li> </ul> <p>we use 8 4 2 1 coding method</p> <p>max possible sum of 2 BCD digits\\(= \\underbrace{1}_\\text{carry} + 9 + 9 = 19\\)</p> <ul> <li>Sum &lt;= 9 without carry<ul> <li>no correction is needed</li> <li>2+3 = 5</li> </ul> </li> <li>Sum &gt; 9 without carry<ul> <li>then add 6</li> <li>5+7 = 12</li> </ul> </li> <li>Sum &lt;= 9 with carry<ul> <li>then add 6</li> <li>8 + 8</li> </ul> </li> </ul> <p>We need two 4bit parallel adders</p> <p>Whenever the output is undefined, we have to consider that case as don\u2019t care</p> <ul> <li>for eg, for BCD, we take 10-15 places as don\u2019t-care</li> </ul> <p>if z8, z4, z2, z1, and k are the outputs of the first adder, then:</p> Decimal k z8 z4 z2 z1 Corrected Binary Sum BCD Sum 0 0 0 0 0 0 No correction 0000 \u2026 No correction Same as binary 9 0 1 0 0 1 No correction 1001 10 0 1 0 1 0 + 0110 0001 0000 \u2026 + 0110 16 1 0 0 0 0 + 0110 0001 0110 17 1 0 0 0 1 + 0110 0001 0111 18 1 0 0 1 0 + 0110 0001 1000 19 1 0 0 1 1 + 0110 0001 1001 <p>\\(C = z_2 z_8 + z_4 z_8 + k\\)</p>"},{"location":"2_Core/Digital_Design/07_AdderSubtractor/#circuit","title":"Circuit","text":""},{"location":"2_Core/Digital_Design/08_Comparator/","title":"08 Comparator","text":""},{"location":"2_Core/Digital_Design/08_Comparator/#comparatormagnitude-checker","title":"Comparator/Magnitude checker","text":"<p>used to check if a binary number is less than/equal to/greater than another binary no</p>"},{"location":"2_Core/Digital_Design/08_Comparator/#1-bit-comparator","title":"1 bit comparator","text":"x y G E L 0 0 0 1 0 0 1 0 0 1 1 0 1 0 0 1 1 0 1 0 <p>\\(L = x'y, E = x \\odot y, G = xy'\\)</p>"},{"location":"2_Core/Digital_Design/08_Comparator/#2-bit-comparator","title":"2 Bit Comparator","text":"A_1 A_0 B_1 B_0 G E L 0 0 0 0 1 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 <ul> <li>\\(G = A_1 {B_1}' + A_0 A_1 {B_0}' + A_0 {B_0}' {B_1}'\\)</li> <li>\\(E = (A_1 \\odot B_1) (A_2 \\odot B_2)\\)</li> <li>\\(L = {A_1}' B_1  + {A_0}' {A_1}' B_0 + {A_0}' B_0 B_1\\)</li> </ul>"},{"location":"2_Core/Digital_Design/08_Comparator/#3-bit-comparator","title":"3 Bit Comparator","text":"<ul> <li>E<ul> <li>\\(x_2 = A_2 \\odot B_2 \\quad (A_2 = B_2)\\)</li> <li>when \\(A_2 = 0, B_2 = 0, A_2 = 1, B_2 = 1\\)</li> <li>\\(x_1 = A_1 \\odot B_1 \\quad (A_1 = B_1)\\)</li> <li>\\(x_0 = A_0 \\odot B_0 \\quad (A_0 = B_0)\\)</li> <li>\\(E = x_2 \\cdot x_1 \\cdot x_0 = (A_2 \\odot B_2) \\cdot (A_1 \\odot B_1) \\cdot (A_0 \\odot B_0)\\)</li> </ul> </li> <li>L<ul> <li>if \\(A_2 &lt; B_2\\)</li> <li>\\(A_2 = 0, B_2 = 1 \\implies {A_2}' B_2\\)</li> <li>if \\(A_2 = B_2, A_1 &lt; B_1\\)</li> <li>\\(x_2\\) and\\(A_1 = 0, B_1 = 1 \\implies {A_1}' B_1\\)</li> <li>\\(x_2 \\cdot {A_1}' B_1\\)</li> <li>if \\(A_2 = B_2, A_1 = B_1, A_0 &lt; B_0\\)</li> <li>\\(x_2, x_1\\) and\\(A_0 = 0, B_0 = 1 \\implies {A_0}' {B_0}\\)</li> <li>\\(x_2 \\cdot x_1 \\cdot {A_0} B_0\\)</li> <li>\\(\\therefore, L = {A_2}' B_2 + x_2 {A_1}' B_1 + x_2 x_1 {A_0}' B_0\\)</li> </ul> </li> <li>G<ul> <li>\\(G = A_2 {B_2}' + x_2 A_1 {B_1}' + x_2 x_1 A_0 {B_0}'\\)</li> </ul> </li> </ul>"},{"location":"2_Core/Digital_Design/08_Comparator/#4-bit-comparator","title":"4 bit comparator","text":"<p>\\(E = x_3 x_2 x_1 x_0\\)</p>"},{"location":"2_Core/Digital_Design/08_Comparator/#diagram","title":"Diagram","text":""},{"location":"2_Core/Digital_Design/09_DecoderEncoder/","title":"09 DecoderEncoder","text":""},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#decoder","title":"Decoder","text":"<p>converts binary numbers into decimal</p> <ul> <li>from n input lines</li> <li>to \\(2^n\\) unique output lines</li> </ul> <p>Decoder maps the value of the input to the subscript ?? Idk the exact word</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#applications","title":"Applications","text":"<ol> <li>7 segment displays (parkings, counters, etc)</li> <li>selection in memories</li> <li>de-compressing files</li> </ol>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#active","title":"Active","text":"<p>output -not input- gets affected</p> Active High Active Low on output 1 0 off output 0 1 gate AND NAND"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#enabled","title":"Enabled","text":"<p>basically the switch for the decoder</p> <p>Apart from the regular inputs, there is another input called \u2018enabled\u2019, which takes values high/low</p> <p>Controls whether the circuit is on/off</p> <ul> <li>enabled high - e = 1 enables the decoder</li> <li>enabled low - e = 0 enables the decoder</li> </ul>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#2-to-4-line-decoder","title":"2 to 4 line decoder","text":"<p>also called \u20181 of 4 decoder\u2019</p> <p>\\(n = 2; 2^n = 4\\)</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#active-high","title":"Active High","text":"x y d0 d1 d2 d3 0 0 1 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0 0 1 <p>\\(d_0 = x'y', d_1 = x'y, d_2 = xy', d_3 = xy\\)</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#active-low","title":"Active low","text":"x y d0 d1 d2 d3 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 <p>(Everything will be complemented)</p> <p>\\(d_0 = (x'y')', d_1 = (x'y)', d_2 = (xy')', d_3 = (xy)'\\)</p> <p>we could also use OR gate? \\(d_0 = x+y, d_1 = x+y', d_2 = x'+y, d_3 = x'+y'\\)</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#decoder-with-enabled","title":"Decoder with enabled","text":"<p>x means don\u2019t-care</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#enabled-high-active-high","title":"Enabled High, Active High","text":"e x y d0 d1 d2 d3 0 x x 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 0 0 0 1 <p>\\(d_0 = ex'y', d_1 = ex'y, d_2 = exy', d_3 = exy\\)</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#enabled-low-active-high","title":"Enabled Low, Active High","text":"e x y d0 d1 d2 d3 1 x x 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 1 <p>\\(d_0 = e'x'y', d_1 = e'x'y, d_2 = e'xy', d_3 = e'xy\\)</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#3-to-8-line-decoder","title":"3 to 8 line decoder","text":"<p>\\(n = 3, 2^n = 8\\)</p> <p>also called as</p> <ul> <li>\u20181 of 8\u2019 decoder</li> <li>binary to octal decoder (not a mistake - octal is a subspace of decimal)</li> </ul> x y z d0 d1 d2 d3 d4 d5 d6 d7 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1 <p>\\(d_0 = x'y'z', d_1 = x'y'z, d_2 = x'yz', d_3 = x'yz, d_4 = xy'z', d_5 = xy'z, d_6 = xyz', d_7 = xyz\\)</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#4-16-decoder-using-3-8-decoder","title":"4-16 decoder using 3-8 decoder","text":"<p>requires</p> <ol> <li> <p>two 3-8 decoders    \\(x,y,z\\) as inputs</p> </li> <li> <p>\\(w\\) as enabled</p> <ul> <li> <p>1 enabled low</p> </li> <li> <p>1 enabled high</p> </li> </ul> </li> </ol> w x y z Output 0 0 0 0 d0 0 0 0 1 d1 0 0 1 0 d2 0 0 1 1 d3 0 1 0 0 d4 0 1 0 1 d5 0 1 1 0 d6 0 1 1 1 d7 1 0 0 0 d8 1 0 0 1 d9 1 0 1 0 d10 1 0 1 1 d11 1 1 0 0 d12 1 1 0 1 d13 1 1 1 0 d14 1 1 1 1 d15"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#4-16-decoder-using-2-4-decoders","title":"4-16 decoder using 2-4 decoders","text":"\\[ 16/ \\textcolor{orange}4 = 4,  4/ \\textcolor{orange} 1 = 1 \\\\ req = 4 + 1 = 5 \\] <p>we need 5 decoders in total</p> <p>idk exactly</p> <p></p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#diagram","title":"Diagram","text":""},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#combinational-logic-implementation-using-decoder","title":"Combinational Logic implementation using decoder","text":"<p>Example: full adder</p> <p>\\(S = \\sum(1,2,4,7), C = \\sum(3,5,6,7)\\)</p> <ul> <li>3 inputs</li> <li>3-8 decoder</li> <li>2 or gates</li> </ul> <p>refer the gates notes to use different gates</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#encoder","title":"Encoder","text":"<p>converts decimal numbers into binary</p> <p>is a combination circuit that performs inverse operation of a decoder</p> <p>has \\(2^n\\) inputs and \\(n\\) outputs</p> <p>is used to minimize data (compress)</p> <p>only 1 input will be high</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#4-2-encoder-active-high","title":"4-2 encoder, active high","text":"D3 D2 D1 D0 E1 E0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0 1 1 <p>\\(E_1 = D_2+D_3, E_0 = D_1 + D_3\\)</p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#8-3-encoder-active-high","title":"8-3 Encoder, Active High","text":"D7 D6 D5 D4 D3 D2 D1 D0 E2 E1 E0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 1 1 <ul> <li>\\(E_2 = D_4 + D_5 + D_6 + D_7\\)</li> <li>\\(E_1 = D_3 + D_4 + D_6 + D_7\\)</li> <li>\\(E_0 = D_1 + D_3 + D_5 + D_7\\)</li> </ul>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#valid-line","title":"Valid Line","text":"<ul> <li>\\(V=0\\)<ul> <li>output is invalid</li> <li>inputs are inactive</li> <li>the outputs are not inspected and hence the output will be don\u2019t care condition</li> </ul> </li> <li>\\(V=1\\)<ul> <li>output is valid</li> <li>at least 1 input is active</li> </ul> </li> </ul>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#priority-encoder","title":"Priority Encoder","text":"<p>encoder that includes priority function</p> <p>helps the encoder give preference to the highest </p>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#4-2-encoder","title":"4-2 encoder","text":"<p>order of preference will be\\(\\underbrace{D_3}_\\text{highest} &gt; D_2 &gt; D_1 &gt; \\underbrace{D_0}_\\text{lowest}\\)</p> D3 D2 D1 D0 E1 E0 V 0 0 0 0 X X 0 0 0 0 1 0 0 1 0 0 1 X 0 1 1 0 1 X X 1 0 1 1 X X X 1 1 1 <p>Because of don\u2019t care condition, we have to consider 0s as well for the equations (figure it out on your own)</p> <ul> <li>\\(E_1 = D_2{D_3}' + D_3\\)</li> <li>\\(E_0 = D_1{D_2}'{D_3}' + D_3\\)</li> <li>\\(V = D_0 + D_1 + D_2 + D_3\\)</li> </ul>"},{"location":"2_Core/Digital_Design/09_DecoderEncoder/#8-3-encoder","title":"8-3 Encoder","text":"<p>order of preference will be \\(\\underbrace{D_7}_\\text{highest} &gt; \\ldots &gt; \\underbrace{D_0}_\\text{lowest}\\)</p> D7 D6 D5 D4 D3 D2 D1 D0 E2 E1 E0 V 0 0 0 0 0 0 0 0 X X X 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 X 0 0 1 1 0 0 0 0 0 1 X X 0 1 0 1 0 0 0 0 1 X X X 0 1 1 1 0 0 0 1 X X X X 1 0 0 1 0 0 1 X X X X X 1 0 1 1 0 1 X X X X X X 1 1 0 1 1 X X X X X X X 1 1 1 1"},{"location":"2_Core/Digital_Design/10_MuxDemux/","title":"10 MuxDemux","text":""},{"location":"2_Core/Digital_Design/10_MuxDemux/#multiplexer-mux","title":"Multiplexer (MUX)","text":"<p>also called as data selector</p> <p>Combinational circuit</p> <p>Digital switch</p> <ul> <li>\\(2^n\\) inputs</li> <li>1 output</li> <li>\\(n\\) selection lines</li> </ul>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#applications","title":"Applications","text":"<ol> <li>servers</li> <li>multiple devices are connected to just a single server</li> <li>telecommunication</li> </ol>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#2-1-mux","title":"2-1 Mux","text":"<ul> <li>2 inputs </li> <li>1 output</li> <li>1 selection line</li> </ul> S0 M 0 \\(i_0\\) 1 \\(i_1\\) <p>\\(M = i_0 {s_0}' + i_1 s_0\\)</p>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#4-1-mux","title":"4-1 Mux","text":"<ul> <li>4 inputs</li> <li>1 output</li> <li>2 selection lines </li> </ul> s0 s1 M 0 0 \\(i_0\\) 0 1 \\(i_1\\) 1 0 \\(i_2\\) 1 1 \\(i_3\\) <p>\\(Y = i_0 {s_0}' {s_1}' + i_1 {s_0}' s_1 + i_2 s_0 {s_1}' + i_3 s_0 s_1\\)</p>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#8-1-mux","title":"8-1 Mux","text":"<ul> <li>8 inputs</li> <li>1 output</li> <li>3 selection lines</li> </ul>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#16-1-mux","title":"16-1 Mux","text":"<ul> <li>16 inputs</li> <li>1 output</li> <li>4 selection lines</li> </ul>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#simplifying-mux","title":"Simplifying mux","text":"<ol> <li>draw truth table</li> <li>Choose variable(s) as selection lines</li> <li>other variable(s) as mux i/p</li> <li>write the function in terms of the mux i/p    (easier than drawing kmap)</li> </ol>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#building-mux-using-smaller","title":"Building Mux using smaller","text":"<ol> <li>divide \\(n_1\\) by \\(n_2\\)</li> <li>no of muxes = sum of quotients</li> </ol> <p>positions of s1 and s2 are important</p> <p>MSD will be the selection line for the last mux</p>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#4x1-using-2-1","title":"4x1 using 2-1","text":"\\[ n_\\text{req} = 4 \\\\ n_\\text{available} = 2 \\\\ 4/2 = 2, 2/2 = 1 \\implies \\text{no of muxes} = 2 + 1 = 3 \\]"},{"location":"2_Core/Digital_Design/10_MuxDemux/#8x1-using-2-1","title":"8x1 using 2-1","text":"\\[ n_\\text{req} = 8 \\\\ n_\\text{available} = 2 \\\\ 8/2 = 4, 4/2 = 2, 2/2 = 1 \\implies \\text{no of muxes}= 4 + 2 + 1 = 7 \\]"},{"location":"2_Core/Digital_Design/10_MuxDemux/#8x1-using-4x1-and-2x1","title":"8x1 using 4x1 and 2x1","text":"<p>two 4x1 and one 2x1</p> <p>\\(8/4 = 2; 2/2 = 1\\)</p>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#16x1-using-4x1","title":"16x1 using 4x1","text":"\\[ n_\\text{req} = 16 \\\\ n_\\text{available} = 4 \\\\ 16/4 = 4, 4/4 = 1 \\implies \\text{no of muxes}= 4 + 1 = 5 \\]"},{"location":"2_Core/Digital_Design/10_MuxDemux/#diagram","title":"Diagram","text":""},{"location":"2_Core/Digital_Design/10_MuxDemux/#de-multiplexer-de-mux","title":"De-multiplexer (De-mux)","text":"<p>it is a digital switch with</p> <ol> <li>1 input</li> <li>\\(n\\) selection lines</li> <li>determines which output is connected to the input</li> <li>\\(2^n\\) multiple outputs</li> </ol>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#1-2","title":"1-2","text":"S0 D0 D1 0 i 0 1 0 i <p>\\(D_0 = i {S_0}', D_1 = iS_0\\)</p>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#1-4","title":"1-4","text":"s0 s1 D0 D1 D2 D3 0 0 i 0 0 0 0 1 0 i 0 0 1 0 0 0 i 0 1 1 0 0 0 i <p>\\(D_0 = i {s_0}'{s_1}', D_1 = i{s_0}'s_1, D_2 = i s_0 {s_1}', D_3 = i s_0 s_1\\)</p>"},{"location":"2_Core/Digital_Design/10_MuxDemux/#diagram_1","title":"Diagram","text":""},{"location":"2_Core/Digital_Design/11_Latches/","title":"11 Latches","text":"<p>Latches are usually level triggered</p>"},{"location":"2_Core/Digital_Design/11_Latches/#sr-latch","title":"SR Latch","text":"<p>used to store 0s and 1s applied as 2 inputs called \u2018set\u2019 and \u2018reset\u2019</p> <p>has 2 stable states</p> <ol> <li>SET state - Q = 1, Q\u2019 = 0</li> <li>RESET state - Q = 0, Q\u2019 = 1</li> </ol> <p>can be constructed using</p> <ul> <li>2 cross-coupled NOR gates, or</li> <li>2 cross-coupled NAND gates</li> </ul> <p>NOR-based and NAND-based are reverse of each other</p>"},{"location":"2_Core/Digital_Design/11_Latches/#nor-based","title":"NOR-based","text":"<p>\\(Q_{n+1} = (r + Q'_n)', Q'_{n+1} = (s + Q_n)'\\)</p>"},{"location":"2_Core/Digital_Design/11_Latches/#simplified-truth-table","title":"Simplified Truth Table","text":"s r \\(Q_n\\) \\(Q_{n+1}\\) 0 0 X \\(Q_n\\) 0 1 X 0 (reset) 1 0 X 1 (set) 1 1 X invalid (0, X)"},{"location":"2_Core/Digital_Design/11_Latches/#nand-based","title":"NAND-Based","text":"<p>active-low input latch, because if any of the input is 0, output is 1</p> <p>\\(Q_{n+1} = (s \\cdot Q'n)', Q'_{n+1} = (r \\cdot Q_n)'\\)</p>"},{"location":"2_Core/Digital_Design/11_Latches/#simplified-truth-table_1","title":"Simplified Truth Table","text":"s r \\(Q_n\\) \\(Q_{n+1}\\) 0 0 X invalid (1, X) 0 1 X 1 (set) 1 0 X 0 (reset) 1 1 X \\(Q_n\\) (no change)"},{"location":"2_Core/Digital_Design/11_Latches/#with-enabled","title":"With Enabled","text":"<p>We use NAND SR latch with enabled input</p> <p>The truth table is similar to NOR Latch</p> e s r \\(Q_n\\) \\(Q_{n+1}\\) 0 X X X No change 1 0 0 X \\(Q_n\\) 1 0 1 X 0 (reset) 1 1 0 X 1 (set) 1 1 1 X invalid (0, X) <p>\\(Q_{n+1} = (s' \\cdot Q'n)', Q'_{n+1} = (r' \\cdot Q_n)'\\)</p>"},{"location":"2_Core/Digital_Design/11_Latches/#d-latch","title":"D-Latch","text":"<p>Also called as delay/transparent latch</p> <p>In SR latch, when the inputs are compliment of each other, then the output is either set state or reset state</p> <p>The complimentary input conditions can be achieved by adding an inverter to one of the inputs of SR Latch</p> <p>Now, the SR Latch has a single input called D</p> <p>\\(D \\to S, D' \\to R\\)</p> <p>used as a base for storage device in digital systems</p> e d \\(Q_n\\) \\(Q_{n+1}\\) 0 X X No change 1 0 X 0 1 1 X 1 <p>\\(Q_{n+1} = (d' \\cdot Q'n)', Q'_{n+1} = (d \\cdot Q_n)'\\) cuz \\(s = d \\implies s' = d' \\quad r = d' \\implies r' = d\\)????</p> <p>\\(Q_{n+1} = d\\), right?</p>"},{"location":"2_Core/Digital_Design/11_Latches/#diagram","title":"Diagram","text":""},{"location":"2_Core/Digital_Design/12_FlipFlops/","title":"12 FlipFlops","text":""},{"location":"2_Core/Digital_Design/12_FlipFlops/#flip-flops","title":"Flip Flops","text":"<p>flip fl==o==p; cl==o==ck</p> <p>in latches with enabled, it is observed that inputs are recognized only when enabled is 1. Therefore, it is possible to replace enabled with a momentary pulse called clock so that the inputs can be recognized only for a specified time. Such a device is called a flipflop.</p> <p>(c means clock)</p> <p>FF are usually edge triggered</p> <p>the below truth tables are for positive trigger</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#sr-flip-flop","title":"SR Flip Flop","text":"<p>almost identical compared to SR Latch, just that there is a clock </p> c s r \\(Q_n\\) \\(Q_{n+1}\\) 0 X X X No change 1 0 0 X \\(Q_n\\) 1 0 1 X 0 (reset) 1 1 0 X 1 (set) 1 1 1 X invalid (0) s r \\(Q_n\\) \\(Q_{n+1}\\) 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 X 1 1 1 X"},{"location":"2_Core/Digital_Design/12_FlipFlops/#expression","title":"Expression","text":"<p>\\(Q_{n+1} = S + R' Q_n\\) (simplified using KMap)</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#d-flip-flop","title":"D-Flip Flop","text":"<p>also called as transparent flip flop</p> c d \\(Q_n\\) \\(Q_{n+1}\\) 0 X X No change 1 0 X 0 1 1 X 1 d \\(Q_n\\) \\(Q_{n+1}\\) 0 1 0 0 0 0 1 0 1 1 1 1"},{"location":"2_Core/Digital_Design/12_FlipFlops/#expression_1","title":"Expression","text":"<p>\\(Q_{n+1} = d\\) (simplified using KMap)</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#jk-flip-flop","title":"JK Flip Flop","text":"<p>SR replaced with JK</p> <p>Output of </p> <ul> <li>\\(Q'\\) will be another input of first NAND gate</li> <li>\\(Q\\) will be another input of second NAND gate</li> </ul> c j k \\(Q_n\\) \\(Q_{n+1}\\) 0 X X X No change 1 0 0 X \\(Q_n\\) 1 0 1 X 0 (reset) 1 1 0 X 1 (set) 1 1 1 X \\(\\overline{Q}_n\\) (toggle condition) j k \\(Q_n\\) \\(Q_{n+1}\\) 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 0 <p>\\(Q_{n+1} = j Q'_n + k' Q_n\\)</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#t-flip-flop","title":"T Flip Flop","text":"<p>Toggle Flip Flop</p> <p>similar to XOR gate</p> <p>We only want 00 and 11</p> <p>Remove J and K, add T</p> c t \\(Q_n\\) \\(Q_{n+1}\\) 0 X X No change 1 0 X \\(Q_n\\) 1 1 X \\(\\overline{Q}_n\\) (toggle condition) t \\(Q_n\\) \\(Q_{n+1}\\) 0 0 0 0 1 1 1 0 1 1 1 0 <p>\\(Q_{n+1} = T \\oplus Qn\\)</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#ff-with-preset-and-resetclear","title":"FF with Preset and Reset/clear","text":""},{"location":"2_Core/Digital_Design/12_FlipFlops/#active-high","title":"Active High","text":"P R FF Response 0 0 Normal FF 0 1 Q = 0 1 0 Q = 1 1 1 Not used"},{"location":"2_Core/Digital_Design/12_FlipFlops/#active-low","title":"Active Low","text":"P R FF Response 0 0 Not used 0 1 Q = 1 1 0 Q = 0 1 1 Normal FF"},{"location":"2_Core/Digital_Design/12_FlipFlops/#diagrams","title":"Diagrams","text":""},{"location":"2_Core/Digital_Design/12_FlipFlops/#verilog","title":"Verilog","text":"<pre><code>module srff(q,qbar, s, r, c);\n  input s, r, c;\n  output q, qbar;\n  wire nand1, nand2;\n\n  nand(nand1, s, c);\n  nand(nand2, r, c);\n\n  nand(q, nand1, qbar);\n  nand(qbar, nand2, q);\nendmodule\n\nmodule testbench;\n  reg s, r, c; // reg means storage\n  wire q, qbar;\n\n  initial begin\n    c = 1'b1;\n    repeat(2) #200 c = ~c;\n  end\n\n  initial begin\n    s = 1'b0;\n    repeat(8) #25 s = ~s;\n  end\n\n  initial begin\n    r = 1'b1;\n    repeat(13) #15 r = ~r;\n  end\nendmodule\n</code></pre> <p>Dlatch using</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#blocking","title":"Blocking","text":"<pre><code>module dLatch(input d, c, output reg q, qbar);\n  always @ (d, c);\n    if(c) begin\n      #4 q = d;\n      #4 qbar = ~d;\n    end\nendmodule\n</code></pre>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#non-blocking","title":"Non-Blocking","text":""},{"location":"2_Core/Digital_Design/12_FlipFlops/#timing-diagram","title":"Timing Diagram","text":"<p>basically the graph thingy</p> <p>you\u2019ll do it obviously</p> <p></p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#excitation-table","title":"Excitation Table","text":"<p>one FF var will be reverse of the other helpful for JK and SR</p> <p>helps us to perform flip-flop conversions</p> <p>In regular truth tables, (j,k, Qn) are inputs and Qn+1 is output in excitation table, Qn and Qn+1 are inputs and j and k are outputs</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#jk-ff","title":"JK FF","text":"j k \\(Q_n\\) \\(Q_{n+1}\\) 0 0 X \\(Q_n\\) 0 1 X 0 1 0 X 1 1 1 X \\(\\overline{Q}_n\\) \\(Q_n\\) \\(Q_{n+1}\\) j k 0 0 0 X 0 1 1 X 1 0 X 1 1 1 X 0"},{"location":"2_Core/Digital_Design/12_FlipFlops/#t-ff","title":"T FF","text":"<p>similar to XOR gate</p> T \\(Q_n\\) \\(Q_{n+1}\\) 0 0 0 0 1 1 1 0 1 1 1 0 \\(Q_n\\) \\(Q_{n+1}\\) T 0 0 0 0 1 1 1 0 1 1 1 0"},{"location":"2_Core/Digital_Design/12_FlipFlops/#d-ff","title":"D FF","text":"D \\(Q_n\\) \\(Q_{n+1}\\) 0 0 0 0 1 0 1 0 1 1 1 1 \\(Q_n\\) \\(Q_{n+1}\\) D 0 0 0 0 1 1 1 0 0 1 1 1"},{"location":"2_Core/Digital_Design/12_FlipFlops/#sr-ff","title":"SR FF","text":"s r \\(Q_n\\) \\(Q_{n+1}\\) 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 1 1 0 1 1 1 1 0 X (Invalid) 1 1 1 X (Invalid) \\(Q_n\\) \\(Q_{n+1}\\) S R 0 0 0 X 0 1 1 0 1 0 0 1 1 1 X 0"},{"location":"2_Core/Digital_Design/12_FlipFlops/#conversion","title":"Conversion","text":"<ol> <li>Identify source and destination FF</li> <li>Tables</li> <li>Draw Truth table for destination FF</li> <li>extend it (change X into 0 and 1)</li> <li>Draw excitation table of source FF</li> <li>Merge both the tables</li> <li>Draw KMap which provides expression for conversion with</li> <li>inputs as<ol> <li>source FF input vars</li> <li>\\(Q_n\\)</li> </ol> </li> <li>output as dest FF input vars</li> <li>Draw circuit according to KMap</li> </ol>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#sr-using-d","title":"SR using D","text":"<p>\\(S = D, R = D'\\)</p>"},{"location":"2_Core/Digital_Design/12_FlipFlops/#sr-using-jk","title":"SR using JK","text":"<p>\\(S = j Q'_n, R = k Q_n\\)</p>"},{"location":"2_Core/Digital_Design/13_FSM/","title":"13 FSM","text":""},{"location":"2_Core/Digital_Design/13_FSM/#finite-state-machine-fsm","title":"Finite State Machine (FSM)","text":""},{"location":"2_Core/Digital_Design/13_FSM/#state","title":"State","text":"<p>Condition of a sequential circuit based on state variables</p> <p>Flip flop acts as state register, used to store values of states</p>"},{"location":"2_Core/Digital_Design/13_FSM/#types","title":"Types","text":"Moore Model Mealy Model Output is F of states only inputs and states i/p affects o/p? N may affect states required to implement F more fewer Synchronisation with clock Y N"},{"location":"2_Core/Digital_Design/13_FSM/#state-equations","title":"State Equations","text":"<p>set of equations that describe the next state as a function of present state and inputs \\(NS = f(PS, ip)\\)</p>"},{"location":"2_Core/Digital_Design/13_FSM/#variables","title":"Variables","text":"<p>inputs, outputs, state vars are functions of time</p> <ul> <li>inputs/outputs (only small)<ul> <li>NS \\(x(t), y(t)\\)</li> <li>PS \\(x(t+1), y(t+1)\\)</li> </ul> </li> <li>flip-flop outputs (capital or small)<ul> <li>NS \\(A(t), B(t),  a(t), b(t)\\)</li> <li>PS \\(A(t+1), B(t+1), a(t+1), b(t+1)\\)</li> </ul> </li> </ul>"},{"location":"2_Core/Digital_Design/13_FSM/#characteristic-equations","title":"Characteristic Equations","text":"<p>equation for the input and outputs of flipflops</p> Flip Flop Type \\(Q(t+1)\\) D D JK \\(jQ\u2019 + k\u2019Q\\) T \\(T \\oplus Q\\)"},{"location":"2_Core/Digital_Design/13_FSM/#state-table","title":"State Table","text":"<p>is the listing of next states and outputs(not necessary) for all combinations of input and present state</p> <p>total no of combinations = \\(2^{m+n}\\), where</p> <ul> <li>\\(m =\\) no of state vars</li> <li>\\(n =\\) no of input vars</li> </ul> PS Input NS Output"},{"location":"2_Core/Digital_Design/13_FSM/#state-diagram","title":"State Diagram","text":"<p>has circles representing all possible states</p> <p>do this last in the exam, if possible</p> Moore Mealy circle has states, output states arrow has input input, output"},{"location":"2_Core/Digital_Design/13_FSM/#state-reduction","title":"State Reduction","text":"<p>Designing of SC from a given state diagram</p> <p>It is possible to obtain the same input-output relation with another state diagram with fewer states. Reduction has many advantages</p> <ol> <li>fewer flipflops</li> <li>cost is minimized</li> <li>easier maintainance</li> </ol> <p>In design specification, the states will be represented as alphabets. It is necessary to assign binary codes for practical implication</p>"},{"location":"2_Core/Digital_Design/13_FSM/#state-assignment-techniques","title":"State Assignment Techniques","text":"<p>There are different ways of assigning codes into the states</p> <ol> <li>Binary code</li> <li>Grey code</li> <li>One-hot code</li> <li>In \\(n\\) bit code, only one bit is 1 and the remaining are 0s</li> <li>basically decoder output is fed in for assigning</li> </ol> <p>unused states will be X (don\u2019t care condition)</p>"},{"location":"2_Core/Digital_Design/13_FSM/#design","title":"Design","text":"<p>Sequential circuit can be designed using any flip flop</p> <p>the design starts with specification, which includes a word description, inputs and outputs of the circuit</p>"},{"location":"2_Core/Digital_Design/13_FSM/#steps","title":"Steps","text":"<ol> <li>state diagram</li> <li>state table</li> <li>if necessary, reduce the no of states and obtain the new state table</li> <li>assign codes to the states</li> <li>binary coded state table</li> <li>choose type of flip flop</li> <li>simplify flipflop input-output equation using kmap</li> <li>logic diagram</li> </ol> <p>design using </p> <ul> <li>d FF   next state can be obtained directly from the state table from the knowledge of present state and input</li> <li>jk or t FF   excitation table is formed to determine the inputs of FF for the next state output</li> </ul>"},{"location":"2_Core/Digital_Design/13_FSM/#sequence-detector","title":"Sequence Detector","text":"<p>There\u2019s 2 types:</p> <ol> <li>Overlapping</li> <li>non-overlapping</li> </ol> <p>eg: 1001 sequence detector</p>"},{"location":"2_Core/Digital_Design/13_FSM/#moore-non-overlapping","title":"Moore non-overlapping","text":"<pre><code>flowchart LR\n0((s0/0))\n1((s1/0))\n\n2((s2/0))\n3((s3/0))\n4((s4/1))\n\n0 --&gt;|1| 1 --&gt;|0| 2 --&gt;|0| 3 --&gt;|1| 4 --&gt; |1| 1\n\n0 --&gt;|0| 0\n1 --&gt;|1| 1\n2 --&gt;|1| 1\n3 --&gt;|0 &lt;br /&gt; reset - wrong sequence| 0\n4 --&gt; |0 &lt;br /&gt; reset for next 1001| 0</code></pre>"},{"location":"2_Core/Digital_Design/13_FSM/#moore-overlapping","title":"Moore Overlapping","text":"<pre><code>flowchart LR\n0((s0/0))\n1((s1/0))\n\n2((s2/0))\n3((s3/0))\n4((s4/1))\n\n0 --&gt;|1| 1 --&gt;|0| 2 --&gt;|0| 3 --&gt;|1| 4 --&gt;|0| 2\n\n1 --&gt;|1| 1\n2 --&gt;|1| 1\n3 --&gt;|0| 0\n4 --&gt;|1 &lt;br /&gt; restart for next 1001| 1</code></pre>"},{"location":"2_Core/Digital_Design/13_FSM/#mealy-non-overlapping","title":"Mealy non-overlapping","text":"<pre><code>flowchart LR\n0((s0))\n1((s1))\n2((s2))\n3((s3))\n\n0 --&gt;|1/0| 1 --&gt;|0/0| 2 --&gt;|0/0|3 --&gt;|1/1 &lt;br /&gt; Detected output| 0\n\n0 --&gt;|0/0| 0\n1 --&gt;|1/0| 1\n2 --&gt;|1/0| 1\n3 --&gt;|0/0 &lt;br /&gt; Reset - Wrong Sequence| 0</code></pre>"},{"location":"2_Core/Digital_Design/13_FSM/#mealy-overlapping","title":"Mealy Overlapping","text":"<pre><code>flowchart LR\n0((s0))\n1((s1))\n2((s2))\n3((s3))\n\n0 --&gt;|1/0| 1 --&gt;|0/0| 2 --&gt;|0/0|3 --&gt;|1/1 &lt;br /&gt; overlapping| 1\n\n0 --&gt;|0/0| 0\n1 --&gt;|1/0| 1\n2 --&gt;|1/0| 1\n3 --&gt;|0/0| 0</code></pre>"},{"location":"2_Core/Digital_Design/14_Registers/","title":"14 Registers","text":""},{"location":"2_Core/Digital_Design/14_Registers/#registers","title":"Registers","text":"<p>binary storage device consisting of group of flipflops</p> <ul> <li>each flipflop in a register can store 1 bit binary</li> <li>for \\(n\\) bits, we need \\(n\\) flipflops</li> </ul> <p>the frequency of the clocks are what determine the speed</p> <p>this is what we talk about in \u2018over-clocking\u2019</p>"},{"location":"2_Core/Digital_Design/14_Registers/#4-bit-register-using-d-ff","title":"4 bit register using D-FF","text":""},{"location":"2_Core/Digital_Design/14_Registers/#register-w-parallel-load-control","title":"Register w/ \\(\\parallel\\) load control","text":""},{"location":"2_Core/Digital_Design/14_Registers/#load-0","title":"Load = 0","text":"<p>\\(Q\\) is fed back to the D FF</p> <p>@ every clock pulse, output is re-written</p>"},{"location":"2_Core/Digital_Design/14_Registers/#load-1","title":"Load = 1","text":"<p>sets/overwrites the previous value with new inputted value</p>"},{"location":"2_Core/Digital_Design/14_Registers/#shift-register","title":"Shift Register","text":"<p>a register capable of shifting binary information from 1 flip flop to another</p> \\[ \\fbox 1 \\fbox 0 \\fbox 1 \\] <p>Input and output can be serial/parallel</p> <ol> <li>SISO</li> <li>SIPO</li> <li>PISO</li> <li>PIPO</li> </ol>"},{"location":"2_Core/Digital_Design/14_Registers/#shift-right","title":"Shift-Right","text":"clk i/p \\(Q_2\\) \\(Q_1\\) \\(Q_0\\) 0 0 0 0 0 1 0 0 0 0 2 1 1 0 0 3 1 1 1 0 4 - 0 1 1 5 - 0 0 1"},{"location":"2_Core/Digital_Design/14_Registers/#other-types","title":"Other Types","text":""},{"location":"2_Core/Digital_Design/14_Registers/#bidirectional-shift","title":"Bidirectional Shift","text":""},{"location":"2_Core/Digital_Design/14_Registers/#rotate-shift","title":"Rotate Shift","text":""},{"location":"2_Core/Digital_Design/14_Registers/#right","title":"Right","text":""},{"location":"2_Core/Digital_Design/14_Registers/#left","title":"Left","text":""},{"location":"2_Core/Digital_Design/14_Registers/#universal-shift-register","title":"Universal Shift Register","text":"<p>contains</p> <ul> <li>features<ul> <li>clock pulse</li> <li>reset/clear</li> <li>four 4 x 1 mux for modes</li> <li>No change</li> <li>Shift Left</li> <li>Shift Right</li> <li>Parallel load</li> <li>four d flipflops</li> </ul> </li> <li>inputs<ul> <li>serial input for shift-left</li> <li>serial input for shift-right</li> </ul> </li> </ul>"},{"location":"2_Core/Digital_Design/14_Registers/#ringshift-register-counter","title":"Ring/Shift-Register Counter","text":"<ul> <li>circular shift-register</li> <li>mod(n) counter</li> </ul> <p>in addition to regular SISO register </p> <ul> <li>the last FF output will be the first FF input</li> <li>only one FF is set (value = 1) at a time</li> <li>all others are cleared (value = 0)</li> </ul> clk pulse i/p \\(Q_3\\) \\(Q_2\\) \\(Q_1\\) \\(Q_0\\) 0 (initial stage) - 1 0 0 0 1 0 0 1 0 0 2 0 0 0 1 0 3 0 0 0 0 1 4 1 1 0 0 0 <p>if \\(n =\\) no of flipflops</p> <ul> <li>the no of distinguished states = mod(ring counter) = \\(n\\)</li> <li>to achieve a cycle, input is required \\(n\\) times</li> </ul> <pre><code>flowchart LR\n1000 --&gt; 0100 --&gt; 0010 --&gt; 0001 --&gt; 1000</code></pre>"},{"location":"2_Core/Digital_Design/14_Registers/#ring-counter-using-decoder","title":"Ring Counter using decoder","text":"<ol> <li>one 2 bit counter</li> <li>one \\(2 \\times 4\\) decoder</li> <li>four AND gates</li> </ol>"},{"location":"2_Core/Digital_Design/14_Registers/#johnson-counter","title":"Johnson Counter","text":"<p>other names</p> <ul> <li>Twisted Ring counter</li> <li>Switched Ring Tail counter</li> <li>mod(2n) counter</li> </ul> <p>same as ring counter, but</p> <ul> <li>first i/p \\(= Q'_0\\)</li> <li>any no of 0s/1s is possible</li> </ul> <p>if \\(n =\\) no of flipflops,</p>"},{"location":"2_Core/Digital_Design/14_Registers/#-no-of-states-2n","title":"- no of states = \\(2n\\)","text":"clk pulse i/p \\(Q_3\\) \\(Q_2\\) \\(Q_1\\) \\(Q_0\\) 0 - 0 0 0 0 1 1 1 0 0 0 2 1 1 1 0 0 3 1 1 1 1 0 4 1 1 1 1 1 5 0 0 1 1 1 6 0 0 0 1 1 7 0 0 0 0 1 8 0 0 0 0 0 <pre><code>flowchart LR\n0000 --&gt; 1000 --&gt; 1100 --&gt; 1110 --&gt;\n1111 --&gt; 0111 --&gt; 0011 --&gt; 0001 --&gt; 0000</code></pre>"},{"location":"2_Core/Digital_Design/14_Registers/#diagrams","title":"Diagrams","text":""},{"location":"2_Core/Digital_Design/15_Counters/","title":"15 Counters","text":""},{"location":"2_Core/Digital_Design/15_Counters/#counter","title":"Counter","text":"<p>is a register that goes through a prescribed sequence of states, upon the application of clock pulse</p> <p>mod of a counter = no of states</p> <p>Features</p> <ol> <li>active low clock</li> <li>active low reset</li> <li>FF: JK/T</li> </ol>"},{"location":"2_Core/Digital_Design/15_Counters/#binary-counter","title":"Binary Counter","text":"<p>follows a binary counting sequence (normal without any zigzag)</p> bits no of FF counting possibility no of states counter name \\(n\\) \\(n\\) \\(0 \\to 2^{n-1}\\) \\(2^n\\) \\(mod(2^n)\\) 2 2 \\(0 \\to 3\\) \\(4\\) mod 4 3 3 \\(0 \\to 7\\) \\(8\\) mod 8 <p>\\(mod(N)\\) counter that divides input frequency by \\(n\\) is called as \u2018divided-by-\\(n\\)\u2019 counter</p>"},{"location":"2_Core/Digital_Design/15_Counters/#types","title":"Types","text":""},{"location":"2_Core/Digital_Design/15_Counters/#counting-method","title":"Counting method","text":"<ol> <li>up-counter \\((0 \\to n)\\)</li> <li>down-counter \\((n \\to 0)\\)</li> </ol>"},{"location":"2_Core/Digital_Design/15_Counters/#types_1","title":"Types","text":"Asynchoronous Synchoronous clk pulse for flipflops different same inputs on Synonym Ripple steps for design directly multiple non-binary counter possible?zigzag - (0, 5, 6, 3, 7) N Y"},{"location":"2_Core/Digital_Design/15_Counters/#2-bit-ripple-w-neg-trigger","title":"2-bit ripple w/ neg trigger","text":"<p>ripple means asynchoronous</p> <p>storeable values \\(= 0, 1, 2, 3\\)</p> <p>\\(c_1 = Q_0\\)</p>"},{"location":"2_Core/Digital_Design/15_Counters/#upcounter","title":"upcounter","text":"clk \\(A_1\\) \\(A_0\\) 0 (initial cond) 0 0 1 0 1 2 1 0 3 1 1 4 0 0"},{"location":"2_Core/Digital_Design/15_Counters/#down-counter","title":"down counter","text":"clk \\(A_1\\) \\(A_0\\) 0 (initial cond) 0 0 1 1 1 2 1 0 3 0 1 4 0 0 <p>When m = 0, the circuit acts as an upcounter; m = 1 down counter??????????</p> <pre><code>flowchart\n\nsubgraph Up\n    p[00] --&gt; q[01] --&gt; r[10] --&gt; s[11] --&gt; p\nend\n\nsubgraph Down\n    a[00] --&gt;    d[11] --&gt;    c[10] --&gt; b[01] --&gt; a\nend</code></pre>"},{"location":"2_Core/Digital_Design/15_Counters/#idk","title":"IDK","text":""},{"location":"2_Core/Digital_Design/15_Counters/#for-2nd-ff","title":"For 2<sup>nd</sup> FF","text":"counter Trigger clk up Neg \\(Q\\) up Pos \\(Q'\\) down Neg \\(Q'\\) down Pos \\(Q\\) up/down Neg \\(M \\odot Q\\) M = 1 (up)M = 0 (down) up/down Pos \\(M \\oplus Q\\) M = 1 (up)M = 0 (down)(same)"},{"location":"2_Core/Digital_Design/15_Counters/#4-bit-ripple-w-neg-trigger","title":"4-bit ripple w/ neg trigger","text":""},{"location":"2_Core/Digital_Design/15_Counters/#upcounter_1","title":"upcounter","text":"clk \\(A_3\\) \\(A_2\\) \\(A_1\\) \\(A_0\\) 0 (initial cond) 0 0 0 0 1 0 0 0 1 2 0 0 1 0 3 0 0 1 1 \u2026 15 1 1 1 1 16 0 0 0 0"},{"location":"2_Core/Digital_Design/15_Counters/#bcd-ripple-counter","title":"BCD Ripple Counter","text":"<p>also called as decade</p> <p>requires</p> <ul> <li>4 FF</li> <li>NAND gate</li> <li>OR gate</li> </ul> clk \\(A_3\\) \\(A_2\\) \\(A_1\\) \\(A_0\\) 0 (initial cond) 0 0 0 0 1 0 0 0 1 2 0 0 1 0 3 0 0 1 1 \u2026 9 1 0 1 0 10 0 0 0 0 \u2026 X X X X"},{"location":"2_Core/Digital_Design/15_Counters/#4-decade-counter","title":"4 decade counter","text":"<p>also called as 4 digit BCD counter</p> <p>mod 10 counter</p> <p>contains four BCD counters</p>"},{"location":"2_Core/Digital_Design/15_Counters/#custom-mod-counters","title":"Custom mod counters","text":"<p>not all states are used</p> <ol> <li>Find no of FF    the required no of FF is the smallest \\(n\\) that satisfies    \\(N \\le 2^n\\), where<ul> <li>\\(N =\\) no of states</li> <li>\\(n =\\) no of FF</li> </ul> </li> <li>Write the counting sequence of the counter</li> <li>Draw the truth table</li> <li>If necessary, find the minimal expression for reset condition, using KMAP</li> </ol>"},{"location":"2_Core/Digital_Design/15_Counters/#design-of-mod6-asynchoronous-counter","title":"Design of mod6 asynchoronous counter","text":""},{"location":"2_Core/Digital_Design/15_Counters/#cascading-of-ripple-counter","title":"Cascading of Ripple Counter","text":"<p>If we have 2 counters mod M and mod N, then the resulting cascaded ripple counter will be mod(MxN)</p> <p>The MSB of the first(left) counter is connected to the clock of the second (right) counter</p>"},{"location":"2_Core/Digital_Design/15_Counters/#synchoronous-counter","title":"Synchoronous Counter","text":""},{"location":"2_Core/Digital_Design/15_Counters/#design","title":"Design","text":"<ol> <li> <p>identify the no of FF</p> </li> <li> <p>counting sequence and state diagram</p> </li> <li> <p>choice of FF, excitation table</p> </li> <li> <p>minimal expression for excitation (KMAP)</p> </li> <li> <p>kmap is drawn for J,K or T wrt the corresponding Present state variables</p> </li> <li> <p>Logic Diagram</p> </li> </ol>"},{"location":"2_Core/Digital_Design/15_Counters/#3-bit-upcounter","title":"3 Bit upcounter","text":""},{"location":"2_Core/Digital_Design/15_Counters/#3-bit-downcounter","title":"3 Bit downcounter","text":"\\(Q_3(t)\\) \\(Q_2(t)\\) \\(Q_1(t)\\) \\(Q_3(t+1)\\) \\(Q_2(t+1)\\) \\(Q_1(t+1)\\) J3 K3 J2 K2 J1 K1 0 0 0 1 1 1 1 X 1 X 1 X 1 1 1 1 1 0 X 0 X 0 X 1 1 1 0 1 X 0 X 1 1 X 1 0 1 1 X 0 0 X X 1 1 0 0 0 X 1 1 X 1 X 0 1 1 0 0 X X 0 X 1 0 1 0 0 0 X X 1 1 X 0 0 1 0 0 X 0 X X 1 PS\\(Q_3 Q_2 Q_1\\) NS\\(Q_3 Q_2 Q_1\\) \\(J_3\\) \\(K_3\\) \\(J_2\\) \\(K_2\\) \\(J_1\\) \\(K_1\\) 000 111 111 110 110 101 101 100 100 011 011 010 010 001 001 000 \\[ \\begin{aligned} J_1 &amp;= ? &amp; K_1 &amp;= ? \\\\ J_2 &amp;= ? &amp; K_2 &amp;= ? \\\\ J_3 &amp;= Q_2' Q_1' &amp; K_3 &amp;= Q_2' Q_1' \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/15_Counters/#updown","title":"up/down","text":"<pre><code>flowchart LR\n\n000 --&gt; |1|001\n001 --&gt; |0|000</code></pre> <ul> <li>\\(m = 0 \\to\\) downcounter</li> <li>\\(m=1 \\to\\) upcounter</li> </ul> PS\\(Q_3 Q_2 Q_1\\) \\(m\\) NS\\(Q_3 Q_2 Q_1\\) \\(J_3\\) \\(K_3\\) \\(J_2\\) \\(K_2\\) \\(J_1\\) \\(K_1\\) 000 0 111 1 X 1 X 1 X 000 1 001 0 X 0 X 1 X 001 0 000 0 X 0 X X 1 001 1 010 0 X 1 X X 1 010 0 010 0 X X 1 1 X 010 1 011 0 X X 0 1 X 011 0 010 0 X X 0 X 1 011 1 100 1 X X 1 X 1 100 0 011 X 1 1 X 1 X 100 1 101 X 0 0 X 1 X 101 0 100 X 0 0 X X 1 101 1 110 X 0 1 X X 1 110 0 101 X 0 X 1 1 X 110 1 111 X 0 X 0 1 X 111 0 110 X 0 X 0 X 1 111 1 000 X 1 X 1 X 1 <p>4 variable KMAP</p> \\[ \\begin{aligned} J_1 &amp;= 1 &amp; K_1 &amp;= 1 \\\\ J_2 &amp;= Q_1 \\odot M &amp; K_2 &amp;= Q_1 \\odot M \\\\ J_3 &amp;= Q_2 \\odot Q_1 \\odot  m &amp; K_3 &amp;= Q_2 \\odot Q_1 \\odot  m \\\\ \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/15_Counters/#bcd-upcounter","title":"BCD upcounter","text":"PS\\(Q_4 Q_3 Q_2 Q_1\\) NS\\(Q_4 Q_3 Q_2 Q_1\\) \\(J_4\\) \\(K_4\\) \\(J_3\\) \\(K_3\\) \\(J_2\\) \\(K_2\\) \\(J_1\\) \\(K_1\\) 0000 0001 0 X 0 X 0 X 1 X 0001 0010 0 X 0 X 1 X X 1 0010 0011 0 X 0 X X 0 1 X 0011 0100 0 X 1 X X 1 X 1 0100 0101 0 X X 0 0 X 1 X 0101 0110 0 X X 0 1 X X 1 0110 0111 0 X X 0 X 0 1 X 0111 1000 1 X X 1 X 1 X 1 1000 1001 X 0 0 X 0 X 1 X 1001 0000 X 1 0 X 0 X X 1 1010 - 1011 - 1100 - 1101 - 1110 - 1111 - <p>10-15 are unused states</p> \\[ \\begin{aligned} J_1 &amp;= 1 &amp; K_1 &amp;= 1 \\\\ J_2 &amp;= Q_4' Q_1 &amp; K_2 &amp;= Q_1 \\\\ J_3 &amp;= Q_2 Q_1 &amp; K_3 &amp;= Q_2 Q_1 \\\\ J_4 &amp;= Q_3 Q_2 Q_1 &amp; K_4 &amp;= Q_1 \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/15_Counters/#special-conditions","title":"Special Conditions","text":""},{"location":"2_Core/Digital_Design/15_Counters/#lockoutdeadlock","title":"Lockout/Deadlock","text":"<p>Both PS and NS are unused states</p>"},{"location":"2_Core/Digital_Design/15_Counters/#self-start","title":"Self-Start","text":"<p>When a system is switched on and enters an unused state, and then after a few clock pulses, the system enters a used state</p>"},{"location":"2_Core/Digital_Design/15_Counters/#steps","title":"Steps","text":"<ol> <li>Fill up unused state as present state</li> <li>Fill up FF i/p based on the equation obtained from KMAP</li> <li>Fill up the next state (using excitation wrt present state and FF ip)</li> </ol>"},{"location":"2_Core/Digital_Design/15_Counters/#question","title":"Question","text":"<p>Does design of a synchoronous BCD counter using JK FF have lockout condition?</p> <p>unused states = {10, 11, 12, 13, 14, 15}</p> <p>= {1010, 1011, 1100, 1101, 1110, 1111}</p> Unused PS\\(Q_4 Q_3 Q_2 Q_1\\) \\(J_4\\) \\(K_4\\) \\(J_3\\) \\(K_3\\) \\(J_2\\) \\(K_2\\) \\(J_1\\) \\(K_1\\) NS\\(Q_4 Q_3 Q_2 Q_1\\) 10 1010 0 0 0 0 0 0 1 1 1011 11 11 1011 0 1 1 1 1 0 1 1 0100 4 12 1100 0 0 0 0 0 0 1 1 1101 13 13 1101 0 1 0 0 0 1 1 1 0110 6 14 1110 0 0 0 0 0 0 1 1 1111 15 1111 1 1 1 1 1 1 1 1 0000 <pre><code>flowchart LR\n\nsubgraph Used\n    0 --&gt; 1 --&gt; 2 --&gt; 3 --&gt; 4 --&gt; 5 --&gt; 6 --&gt; 7 --&gt; 8 --&gt; 9 --&gt; 0\nend\n\nsubgraph Unused\n    10 --&gt; 11 --&gt; 4\n    12 --&gt; 13 --&gt; 6\n    14 --&gt; 15 --&gt; 0\nend</code></pre> <p>From unused state, the counter goes to used state after a few clock pulses and counts in a normal way</p> <p>Hence, it is self-starting</p>"},{"location":"2_Core/Digital_Design/15_Counters/#mod-6-counter","title":"Mod 6 counter","text":"<pre><code>flowchart LR\n000 --&gt; 001 --&gt; 010 --&gt; 011 --&gt; 100 --&gt; 101 --&gt; 000</code></pre> PS\\(Q_3 Q_2 Q_1\\) NS\\(Q_3 Q_2 Q_1\\) \\(J_3\\) \\(K_3\\) \\(J_2\\) \\(K_2\\) \\(J_1\\) \\(K_1\\) 0 000 001 1 001 010 2 010 011 3 011 100 4 100 101 5 101 000 6 110 X X X X X X X 7 111 X X X X X X X <p>unused states will be represented as don\u2019t care in the KMAP</p> \\[ \\begin{aligned} J_1 &amp;= 1 &amp; K_1 &amp;= 1 \\\\ J_2 &amp;= Q_3' Q_1 &amp; K_2 &amp;= Q_1 \\\\ J_3 &amp;= Q_2 Q_1 &amp; K_3 &amp;= Q_1 \\\\ \\end{aligned} \\] Unused PS\\(Q_3 Q_2 Q_1\\) \\(J_3\\) \\(K_3\\) \\(J_2\\) \\(K_2\\) \\(J_1\\) \\(K_1\\) NS\\(Q_3 Q_2 Q_1\\) 6 110 0 0 0 0 1 1 111 7 7 111 1 1 0 1 1 1 000 0 <p>Self-start</p> <p>Design a type D counter that goes through the states \\(0, 1, 2, 4, 0, \\dots\\) , such that the unused states must always go to 0 on the own next clock pulse</p> <pre><code>flowchart LR\nsubgraph Used\n    0 --&gt; 1 --&gt; 2 --&gt; 4 --&gt; 0\nend\nsubgraph Unused\n    3 &amp; 5 &amp; 6 &amp; 7 --&gt; 0\nend</code></pre> <p>because of the given next states for the unused states, we cannot write it as don\u2019t care for them</p> PS\\(Q_3 Q_2 Q_1\\) NS\\(Q_3 Q_2 Q_1\\) \\(D_3\\) \\(D_2\\) \\(D_1\\) 0 000 001 0 0 1 1 001 010 0 1 0 2 010 100 1 0 0 3 011 000 0 0 0 4 100 000 0 0 0 5 101 000 0 0 0 6 110 000 0 0 0 7 111 000 0 0 0 \\[ D_1 = Q_3' Q_2' Q_1' \\\\ D_2 = Q_3' Q_2' Q_1 \\\\ D_3 = Q_3' Q_2 Q_1' \\] <p>Using a JK counter, count \\(3, 4, 6, 7, 3, \\dots\\)</p> PS\\(Q_3 Q_2 Q_1\\) NS\\(Q_3 Q_2 Q_1\\) \\(D_3\\) \\(D_2\\) \\(D_1\\) 0 000 - X X X 1 001 - X X X 2 010 - X X X 3 011 100 1 0 0 4 100 101 1 0 1 5 101 110 1 1 0 6 110 111 1 1 1 7 111 011 0 1 1 <p>Is Johnson counter lockout or self-start?</p> Unused PS\\(Q_4 Q_3 Q_2 Q_1\\) NS\\(Q_4 Q_3 Q_2 Q_1\\) 2 0010 1001 9 4 0100 1010 10 5 0101 0010 2 6 0110 1011 11 9 1001 0100 4 10 1010 1100 13 11 1011 0101 5 13 1101 0110 6 <p>Lockout condition</p>"},{"location":"2_Core/Digital_Design/15_Counters/#diagrams","title":"Diagrams","text":""},{"location":"2_Core/Digital_Design/16_Memory/","title":"16 Memory","text":""},{"location":"2_Core/Digital_Design/16_Memory/#memory","title":"Memory","text":"<p>storage device</p> <p>stores binary information</p>"},{"location":"2_Core/Digital_Design/16_Memory/#memory-cell","title":"Memory cell","text":"<p>Basic storage device that stores 1 bit</p> <p>works when enabled/select = 0, no read/write operations occur</p> Memory Enable Read/Write Enabled = 1 0 X No operations allowed 1 0 Write to selected word 1 1 Read from selected word"},{"location":"2_Core/Digital_Design/16_Memory/#memory-location","title":"Memory location","text":"<p>group of 8 cells to store a byte</p> <p>we can read/write</p>"},{"location":"2_Core/Digital_Design/16_Memory/#other-stuff","title":"Other stuff","text":"<p>16 bits = 1 word???</p>"},{"location":"2_Core/Digital_Design/16_Memory/#memory-address","title":"Memory Address","text":"<p>unique binary number for every memory location</p> <p>\\(n\\) bit binary address can generate \\(2^n\\) different binary addresses</p> <p>Hence, for \\(n=10\\), we can have 1024 addresses this is called as 1 kilo location</p> <p>Similarly, for \\(n=11\\), we can have \\(2 \\times 1024\\) addresses this is 2 kilo locations</p>"},{"location":"2_Core/Digital_Design/16_Memory/#1-kb-memory-unit","title":"1 KB Memory Unit","text":"\\[ \\underbrace{1 K}_\\text{Memory Storage} \\times \\underbrace{8}_\\text{Word Size/ Data Lines} \\] <ul> <li>Memory Storage = \\(1024 = 2^{10}\\)</li> <li>address lines \\(n = 10\\)</li> <li> <p>Data lines \\(m = 8\\)</p> <ul> <li>8 data input lines</li> <li>8 data output lines</li> </ul> </li> <li> <p>1 enabled line</p> </li> </ul> \\[ \\begin{aligned} \\text{Capactity} &amp;= m \\times 2^n \\text{ bits} \\\\ &amp;= \\frac{m \\times 2^n}{8 \\times 1024} \\text{ KiloBytes} \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/16_Memory/#8k-x-16","title":"8K x 16","text":"<ol> <li> <p>16 data input lines, 16 data output lines</p> </li> <li> <p>13 address lines</p> </li> </ol> \\[ \\begin{aligned} 2^n &amp;= 8 \\times 2^{10} \\\\ &amp;= 2^3 \\times 2^{10} \\\\ &amp;= 2^{13} \\\\ \\implies n &amp;= 13 \\end{aligned} \\] <ol> <li>Capacity = 16KB</li> </ol> \\[ \\begin{aligned} \\text{Capactity} &amp;= m \\times 2^n \\text{ bits} \\\\    &amp;= \\frac{16 \\times 2^{13}}{8 \\times 1024} \\text{ KiloBytes} \\\\    &amp;= 16 \\text{ KB} \\end{aligned} \\]"},{"location":"2_Core/Digital_Design/16_Memory/#operations","title":"Operations","text":"Read Write Address line Address line Enabled line Enabled line Read control Write control Data line Data line"},{"location":"2_Core/Digital_Design/16_Memory/#types-of-semi-conductor-memory","title":"Types of Semi-conductor Memory","text":"<ol> <li>RAM</li> <li>ROM</li> </ol> RAM ROM Full form Random Access Memory Read-Only Memory Read Y Y Write Y N Types 1. Dynamic - Refreshing Logic2. Static 1. OTP - One time Programmable2. EP - Eraseable Programmable+ UV - Ultraviolet+ EE - Electrically Erasable Volatile? Y"},{"location":"2_Core/Digital_Design/16_Memory/#address-decoding","title":"Address Decoding","text":"<p>we need</p> <ul> <li>\\(n\\) and gates</li> <li>\\(n \\to 2^n\\) decoder</li> <li>something or gates</li> </ul>"},{"location":"2_Core/Digital_Design/16_Memory/#4-x-4-ram","title":"4 x 4 RAM","text":"<ul> <li>\\(n = 2\\) address lines</li> <li>\\(m = 4\\) data lines</li> </ul> <p>We need</p> <ul> <li>four and gates</li> <li>one 2x4 decoder</li> <li>four or gates</li> </ul> <p>The four OR gates acts as buffer -  gives high current level and helps in sending information for long distances</p>"},{"location":"2_Core/Digital_Design/16_Memory/#1k-ram","title":"1K RAM","text":"<ul> <li>\\(=2^{10}\\)</li> <li>\\(n=10\\) address lines</li> <li>\\(m=\\)</li> </ul>"},{"location":"2_Core/Digital_Design/16_Memory/#coincident-decoding","title":"Coincident Decoding","text":"<p>instead of using one large decoder, we will use two equal smaller decoders. This allows us to minimize the no of and gates</p> <p>one decoder acts as MSD rows(X), and the other acts as LSD columns (Y)</p> <p>data gets stored at \u2018crossing points\u2019</p> <p>eg: instead of one \\(10 \\times 2^{10}\\), we will use two \\(5 \\times 2^{32}\\)</p> <p>we will only need \\(2 \\times 32 = 64\\) and gates</p>"},{"location":"2_Core/Digital_Design/16_Memory/#address-multiplexing","title":"Address Multiplexing","text":"<p>RAS - Row Address Select, CAS - Column Address Select</p> <p>eg: instead of one \\(10 \\times 2^{10}\\), we will use two \\(5 \\times 2^{32}\\) decoders; we can further simplify this by sending</p>"},{"location":"2_Core/Digital_Design/16_Memory/#-one-5bit-address","title":"- one 5bit address","text":"<p>Instead of sending </p>"},{"location":"2_Core/Digital_Design/16_Memory/#rom","title":"ROM","text":"<ul> <li>\\(n\\) address lines</li> <li>\\(m\\) data output lines (no inputs)</li> </ul> <p>every cross point is considered to be a fuse point</p> <ul> <li>if fuse exists, it is logic 1   it is represented as \\(\\times\\) at crossing points</li> <li>else, it is logic 0</li> </ul>"},{"location":"2_Core/Digital_Design/16_Memory/#32-x-8-rom","title":"32 x 8 ROM","text":"<ul> <li>\\(2^5 \\times 8\\)</li> <li>\\(n = 5\\) address lines</li> <li>\\(m = 5\\) data output lines</li> </ul>"},{"location":"2_Core/Digital_Design/16_Memory/#comb-circuit-using-rom","title":"Comb circuit using ROM","text":"<ol> <li>a circuit inputs a 3 bit binary and outputs a binary equal to the square of input no</li> </ol> A2 A1 A0 B5 B4 B3 B2 B1 B0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 1 <p>To minimize, we can take \\(B_0 = A_0, B_1 = 0\\)</p> <p>So instead of \\(8 \\times 6\\) ROM, we can minimize to \\(8 \\times 4\\) ROM</p>"},{"location":"2_Core/Digital_Design/16_Memory/#pld","title":"PLD","text":"<p>Programmable logic devices</p> <ol> <li>PROM  (Programmable ROM)</li> <li>PAL (Programmable Array Logic)</li> <li>PLA</li> </ol>"},{"location":"2_Core/Digital_Design/16_Memory/#pla","title":"PLA","text":"<p>Programmable Logic Array</p> <p>diagram is important</p> <p>here, X denotes a 0 or 1 - it just denotes a connection (different from ROM)</p> <p>used to implement a boolean function in SOP form</p> <p>it consists of</p> <ul> <li>\\(n\\) inputs   every input is provided with<ul> <li>buffer</li> <li>inverter</li> </ul> </li> <li>\\(k\\) AND gates   takes care of Product terms</li> <li>\\(m\\) OR gates   takes care of Sum terms</li> <li>\\(m\\) XOR gates   used to generate normal/complement of output; this is like adder/subtractor</li> </ul> <pre><code>flowchart LR\ni[/Input/] --&gt; AND --&gt; OR --&gt; XOR --&gt; o[/Output/]</code></pre>"},{"location":"2_Core/Digital_Design/16_Memory/#pla-with-3-ip-4-product-terms-2-outputs","title":"PLA with 3 i/p, 4 product terms, 2 outputs","text":"<p>Fig 7.14</p> <p>Outputs of AND gate</p> <ol> <li>AB\u2019</li> <li>AC</li> <li>BC</li> <li>\\(A\u2019BC\u2019\\)</li> </ol> <p>Outputs of OR gate</p> <ol> <li>\\(AB\u2019 + AC + A\u2019BC\u2019\\)</li> <li>\\(AC + BC\\)</li> </ol> <p>Outupts of XOR gates</p> <ol> <li>\\(F_1 = AB\u2019 + AC + A\u2019BC\u2019\\)</li> <li>\\(F_2 = (AC + BC)'\\), as other input is 1 and hence, the output gets complemented</li> </ol>"},{"location":"2_Core/Digital_Design/16_Memory/#pla-programming-table","title":"PLA Programming Table","text":"<p>converts a diagram into a table</p> <p>there is no 0 for outputs</p> Product Term Inputs(connected to AND)a b c Outputs(connected to OR)\\(F_1 F_2\\)(T) \u00a9 1 AB\u2019 1 0 - 1 - 2 AC 1 - 1 1 1 3 BC - 1 1 - 1 4 \\(A\u2019BC\u2019\\) 0 1 0 1 -"},{"location":"2_Core/Digital_Design/16_Memory/#convert-the-following-into-pla-diagram","title":"Convert the following into PLA diagram","text":"A B C \\(F_1\\) \\(F_2\\) 0 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 1 <ul> <li>\\(F_1(T)\\) is just the normal one</li> <li>\\(F_1(c)\\) means getting the same output as \\(F_1(T)\\) with complemented inputs<ul> <li>so we have to invert the inputs</li> <li>complement the entire thing</li> </ul> </li> </ul> \\[ \\begin{aligned} F_1(T) &amp;= \\sum (0,1, 2, 4) \\\\ &amp;= A'B' + B'C' + A'C' \\\\ F_1(C) &amp;= \\bigg( \\sum (3, 5, 6, 7) \\bigg)' \\\\ &amp;=  \\\\ F_2(T) &amp;= \\sum (0, 5, 6, 7) \\\\ &amp;= \\\\ F_2(c) &amp;= \\bigg( \\sum (1, 2, 3, 4) \\bigg)' \\\\ &amp;= \\end{aligned} \\] <p>We are gonna select \\(F_1(c)\\) and \\(F_2(T)\\), as they have the maximum no of common terms</p> Product Term Inputs outputs\\(F_1 F_2\\)\u00a9 (T) 1 AB 1 1 - 1   1 2 AC 1 - 1 1   1 3 BC - 1 1 1     - 4 A\u2019B\u2019C\u2019 0 0 0 -   1 <p>Draw diagram</p>"},{"location":"2_Core/Discrete_Structures/","title":"Discrete Structures for Computer Science","text":"<p>This course is about relations, graph theory, and Combinatorics</p>"},{"location":"2_Core/Discrete_Structures/#references","title":"References","text":"<ul> <li> Discrete Structures | BITS Pilani Dubai Campus</li> <li> Network Science | Leonid Zhukov</li> <li> Structural Analysis and Visualization of Networks | Leonid Zhukov</li> <li> Complex Network : Theory and Application | IIT</li> </ul>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/","title":"01 Sets and Relations","text":""},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#set","title":"Set","text":"<p>A set is a collection of elements</p> <ul> <li>\\(A \\cup B\\)</li> <li>\\(A \\cap B\\)</li> <li>\\(A - B = A \\cap B'\\)</li> </ul>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#power-set","title":"Power Set","text":"<p>Set of all subsets</p> <p>No of elements in subsets \\(|A| = n( \\ P(A) \\ ) = 2^n\\) </p> <p>Always includes \\(\\phi\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#functions","title":"Functions","text":"<p>If A has m elements and B has n elements, then the number of \\(f: A \\to B\\) is\\(n^m\\), because each of the m elements can relate to n elements, so no of functions \\(= \\underbrace{ n \\times n \\times \\dots}_{m \\text{ times} } = n^m\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#types","title":"Types","text":""},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#one-one-injective","title":"One-one (injective)","text":"<p>Every element has exactly one image</p> <p>if \\(f(x)= f(y) \\implies x=y\\)</p> <p>if \\(x \\ne y \\rightarrow f(x) \\ne f(y)\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#onto-surjective","title":"Onto (surjective)","text":"<p>Range = codomain, ie every element of B should have a pre-image</p> <p>x should be able to be expressed in terms of y let \\(f(x) = y  \\implies x = g(y)\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#bijective","title":"Bijective","text":"<p>a function that is both one-one and onto</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#properties","title":"Properties","text":""},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#domain","title":"Domain","text":"<p>The set of values that the input can take, ensuring that the function is defined</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#codomain","title":"Codomain","text":"<p>The set that the codomain is related to</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#range","title":"Range","text":"<p>The set of values that the output can take, ensuring that the function is defined</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#composition","title":"Composition","text":"<p>\\(g \\circ f \\ (x) = g(\\ f(x) \\ )\\)</p> <p>Domain of \\(g \\circ f \\ (x) = \\set{x \\in \\text{domain } f | f(x) \\in \\text{domain } g}\\)</p> <p>\\(g \\circ f \\ (x)\\) not necessarily equal to \\(f \\circ g \\ (x)\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#relation","title":"Relation","text":"<p>A relation between two sets is a collection of ordered pairs containing one object from each set.</p> <p>Consider a binary relation \\(R \\subseteq A \\times B\\), where \\(A \\times B = \\{ (a,b)/ a \\in A, b \\in B \\}\\). If A and B contain \\(m\\)and \\(n\\) elements respectively, then A x B contains \\(m \\times n\\) elements</p> <p>Consider \\(R \\subseteq A \\times A\\), where \\(A \\times A = \\{(a,b) / a \\in A, b \\in A \\}\\). If A has n elements, then A x A contains \\(n^2\\) elements</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#complement-of-relation","title":"Complement of relation","text":"<p>if \\(R \\subseteq A \\times A,\\) then its complement is \\(R' = \\set{A \\times A} - R\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#properties-of-relations","title":"Properties of Relations","text":""},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#reflexivity","title":"Reflexivity","text":"<p>\\((a, a) \\in R, \\forall a \\in R\\)</p> <p>Self loop at all vertices</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#irreflexivity","title":"Irreflexivity","text":"<p>\\((a,a) \\in R, \\forall a \\in R\\)</p> <p>Self loop at no vertex</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#symmetry","title":"Symmetry","text":"<p>\\((a,b) \\in R \\implies (b,a) \\in R\\)</p> <p>Requires self loops everywhere; otherwise it is not symmetric</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#asymmetry","title":"Asymmetry","text":"<p>\\((a, b) \\in R \\implies (b,a) \\notin R\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#antisymmetric","title":"Antisymmetric","text":"<ul> <li> <p>\\((a, b) \\in R, (b, a) \\in R \\implies a = b\\)</p> </li> <li> <p>\\((a, b) \\in R, a \\ne b \\implies (b,a) \\notin R\\) </p> </li> </ul> <p>No pair of vertices are connected in both directions, and there are self-loops</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#transitive","title":"Transitive","text":"<p>\\((a, b) \\in R, (b, c) \\in R \\implies (a, c) \\in R\\)</p> <p>Asymmetry \\(\\implies\\) Anti-symmetry, but not vice-versa</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#notes","title":"Notes","text":"<p>if R is asymmetric, it is irreflexive</p> <p>if R is transitive and irreflexive, it is asymmetric</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#equivalence-relation","title":"Equivalence Relation","text":"<p>Relation which is</p> <ol> <li>Reflexive</li> <li>Symmetric</li> <li>Transitive</li> </ol> <p>or</p> <ol> <li>reflexive</li> <li>circular</li> </ol>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#no-of-unique-equivalence-relations","title":"No of unique equivalence relations","text":"<ul> <li>\\(n = 4 \\to 15\\)</li> <li>\\(n = 5 \\to 52\\)</li> </ul> <p>15 and 52 are called bell numbers</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#equivalence-class","title":"Equivalence Class","text":"<p>Equivalence relation R divides/partitions A into disjoint union of non-empty subsets called as equivalence classes</p> <p>it is denoted by [any element of the main set] \\([x], x \\in A\\)</p> <p>naming is not unique</p> <p>eg: [0], [1], [x], [y], [January]</p> <p>\\(A= \\set{1, 2, 3}, \\quad R = \\set{(1,1), (1,2), (2,3)}\\) \\([1] = \\set{1, 2}, [2] = \\set{3}\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#properties_1","title":"Properties","text":"<ul> <li>\\(x \\ R \\ y \\implies [x] = [y],\\) even if \\(x \\ne y\\)</li> <li>\\(x, y \\in A \\implies [x] = [y] \\text{ or } [x] \\cap [y] = \\phi\\)</li> </ul>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#converse","title":"Converse","text":"<p>If P is partition of A into non-empty disjoint subsets, then P is the set of equivalence classes for the equivalence relation E defined on A by </p> <p>\\(a \\ R \\ b \\iff\\) a and b belong to the same subset of P</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#examples-of-equivalence-relation","title":"Examples of Equivalence Relation","text":""},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#congruence-modulo","title":"Congruence modulo","text":"<p>returns the remainder basically <code>x % m</code> in programming (smallest result)</p> <p>\\(x \\equiv y(mod \\ m), \\text{ if } x = y + am, \\quad  a, m \\in \\mathbb{Z} \\\\ \\implies x \\% m = y\\)</p> <p>eg:\\(12 \\equiv 2 (mod \\ 5), -12 = 3(mod \\ 5)\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#conclusions","title":"Conclusions","text":"<ol> <li>\\(m\\) divides \\(x-y\\)</li> <li>\\(x \\equiv y(mod \\ m) \\implies y \\equiv x (mod \\ m)\\)</li> <li>\\(\\equiv (mod \\ m)\\) divides \\(\\mathbb{Z}\\) into \\(m\\) equivalence classes    \\(\\Z_m = [0], [1], [2], \\dots, [m-1]\\)</li> <li>\\([0]\\) contains the set of all elements that return 0 as remainder, when divided by m</li> <li>\\([m] = [0], [m+1] = [1], \\dots\\)</li> <li>\\([x] + [y] = [x+y], [x][y] = [xy], -[x] = [-x]\\)</li> </ol>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#circular","title":"Circular","text":"<p>A relation r on a set A is said to be circular if \\((a,b) \\in R \\text{ and }(b,c) \\in R \\implies (c,a) \\in R\\)</p> <p>R is reflexive &amp; circular \\(\\iff\\) R is an equivalence relation</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#operations-on-relations","title":"Operations on Relations","text":"<ul> <li> <p>\\(R_1 - R_2 = \\{ (a,b)| (a,b) \\in R_1 \\text{ and } (a,b) \\notin R_2 \\}\\) \\(R_1 - R_2 \\subseteq R_1\\)</p> </li> <li> <p>\\(R_1 \\cup R_2 = \\{ (a,b)| (a,b) \\in R_1 \\text{ or } (a,b) \\in R_2 \\}\\)</p> </li> <li> <p>\\(R_1 \\cap R_2 = \\{ (a,b)| (a,b) \\in R_1 \\text{ and } (a,b) \\in R_2 \\}\\)</p> </li> <li> <p>\\(R^{-1} = \\{ (b,a) | (a,b) \\in R \\}\\)</p> </li> </ul>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#notes_1","title":"Notes","text":"Property of \\(R_1\\) and \\(R_2\\) alone Property of \\(R_1 \\cup R_2\\) Property of \\(R_1 \\cup R_2\\) Reflexive and Symmetric same same Transitive not necessary same Equivalence not necessary same Anti-symmetric not necessary same Partial-ordering not necessary same"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#composition-of-relations","title":"Composition of Relations","text":"<p>Let \\(R \\subseteq A \\times B\\) and \\(S \\subseteq B \\times C\\)</p> <p>Then, the composition of \\(R\\) and \\(S\\) is \\(R \\circ S = \\{(x,z) | (x,y) \\in R \\text{ and } (y,z) \\in S \\}\\)</p> <p>\\(R \\circ S \\ne S \\circ R\\)</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#composition-of-relation-on-itself","title":"Composition of relation on itself","text":"<ul> <li>\\(R \\circ R\\) can be denoted by \\(R^2\\)</li> <li>\\(R^2 \\circ R\\) can be denoted by \\(R^3\\)</li> <li>\\(R^k \\circ R^l = R^{k+l}, \\quad k,l \\ge 1\\)</li> </ul>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#transitive-closure","title":"Transitive Closure","text":"<p>\\(R^+ = R \\cup R^2 \\cup \\dots \\cup R^n\\) </p> <p>\\(R^+\\) is the smallest relation containing R that is transitive</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#transitive-reflexive-closure","title":"Transitive Reflexive Closure","text":"<p>\\(R^* = R^+ \\cup \\set{ (a,a) | \\textcolor{orange}{\\forall} a \\in A }\\) (add all reflexive elements whether or not they exist in the relation)</p> <p>\\(*\\) is more than + so it is transitive and reflexive</p>"},{"location":"2_Core/Discrete_Structures/01_Sets_and_Relations/#symmetric-closure","title":"Symmetric Closure","text":"<p>\\(R \\cup R^{-1} = \\set{(x,y), (y,x) \\ | \\ (x, y) \\in \\textcolor{orange}{R}, (y,x) \\in \\textcolor{orange}{R^{-1}} }\\)  (only add those symmetric elements that exist in the relation and its inverse)</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/","title":"02 Digraph","text":""},{"location":"2_Core/Discrete_Structures/02_Digraph/#digraph","title":"Digraph","text":"<p>Directed Graph</p> <p>A digraph G is defined as (V, E), if \\(E \\subseteq V \\times V\\), where V = vertices set of G, E = edge set of G</p> <p>\"edge incident from 1 to 3\"</p> <p>Every element of set is a vertex of digraph; every relation is an edge of digraph</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#indegree","title":"Indegree","text":"<p>no of edges incident TO vertex</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#outdegree","title":"Outdegree","text":"<p>no of edges incident FROM vertex</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#subgraph","title":"Subgraph","text":"<p>\\(G' = (V', E')\\) is a subgraph of \\(G = (V, E)\\) if \\(V' \\subseteq V\\) and \\(E' \\subseteq E \\cap(V' \\times V')\\) // not sure</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#graph-isomorphism","title":"Graph Isomorphism","text":"<p>\\(G_1 = (V_1, E_1)\\) and\\(G_2 = (V_2, E_2)\\) are isomorphic if there is one-one and onto function f between them that preserves adjacency</p> <p>\\(f: V_1 \\to V_2\\), where \\(f\\) preserves adjacency \\(E_2 = \\{ (f(v), f(w)) | (v, w) \\in E_1 \\}\\)</p> <p>// not sure // You have to check if they have the same properties (like reflexivity, symmetry, etc...); otherwise the 2 graphs won't maintain adjacency</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#adjacency","title":"Adjacency","text":"<p>x and y are adjacent vertices if they are connected to each other</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#preservation-of-adjacency","title":"Preservation of adjacency","text":"<p>if x adjacent to y, then f(x) and f(y) should also be adjacent to each other</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#features-of-isomorphism-digraphs","title":"Features of isomorphism digraphs","text":"<p>If G1 and G2 are isomorphic</p> <ol> <li>no of vertices equal in G1 and G2</li> <li>no of edges equal in G1 and G2</li> <li>degree spectrum of G1 and G2 are same</li> </ol> <p>However, converse isn't necessarily true - the above 3 features don't necessarily imply isomorphism</p>"},{"location":"2_Core/Discrete_Structures/02_Digraph/#degree-spectrum","title":"Degree Spectrum","text":"<p>... of a graph is set of indegree and outdegree for all vertices of a digraph</p> <p>For every V:(i,j) where i = indegree and j = outdegree of vertex V.</p> <p>Then degree spectrum of the graph \\(= \\{ (i,j) | i=\\text{indegree}, j = \\text{outdegree} \\}\\)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/","title":"03 Ordering Relations","text":""},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#ordering-relations-lattices","title":"Ordering Relations &amp; Lattices","text":""},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#partially-ordered-setsposets","title":"Partially-ordered sets(POSETS)","text":"<p>A relation R defined on a set S is said to be partially ordered if it is</p> <ol> <li>reflexive</li> <li>Anti-symmetric (uni-directional)</li> <li>Transitive</li> </ol> <p>Then (S, R) is a POSET.</p> <p>Eg: \\((\\mathbb{Z}, \\le), (\\mathbb{Z}, \\ge), (\\mathbb{Z}^+ , /), (P(S) , \\subseteq)\\)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#notes","title":"Notes","text":"<ol> <li> <p>Any partial ordering relation is denoted by \\(\\preceq\\)</p> </li> <li> <p>if \\(a \\prec b\\) denotes that \\(a \\preceq b\\) but \\(a \\ne b\\)</p> </li> <li> <p>if R is a partial order relation on S, the R<sup>-1</sup> is also a partial order relation on S, where \\(R^{-1} = \\{ (b, a) | (a,b) \\in R \\}\\)    (S, R<sup>-1</sup>) is called the dual of (S, R)</p> </li> <li> <p>Let\\(a, b \\in S\\) where \\((S, \\preceq)\\) is a POSET.    a and b are said to be comparable, if either \\(a \\preceq b\\) or \\(b \\preceq a\\)    otherwise a and b are not comparable</p> </li> </ol> <p>Eg: \\((\\mathbb{Z}^+, /)\\)    (2, 10) , (16, 8) is comparable; but (2, 7) isn't comparable as neither 2 nor 7 can divide each other</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#totally-ordered-set","title":"Totally ordered Set","text":"<p>\\(\\preceq\\) is a totally-ordered relation if every 2 elements of S is comparable, and S is a totally-ordered set</p> <p>Eg: \\((Z, \\le), (D_8,/)\\) (divisors of 8)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#not-totally-ordered","title":"Not totally ordered","text":"<p>eg: \\((Z^+, /), (D_{12}, /)\\) (divisors of 12)</p> <p>D<sub>n</sub>: set of all positive divisors of positive integer n it is always a POSET, but not necessarily a TOSET</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#well-ordered-set","title":"Well Ordered Set","text":"<p>A relation that is</p> <ol> <li>totally ordered</li> <li>every subset of S has least element in the Hasse diagram    doesn't have to be the least mathematically, such as the case of \\((Z^-, \\ge)\\)</li> </ol> <p>WOSET \\(\\implies\\) TOSET not all TOSETs are WOSETs, but all finite TOSETs are</p> <p>Eg: \\((N, \\le), (Z^+, \\le), (Z^-, \\ge)\\) \\((Z^-, \\le)\\) is TOSET but not WOSET, as there is no subset (\\(- \\infin\\) is the least element)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#posethasse-diagram","title":"POSET/HASSE Diagram","text":"<ol> <li>draw from lower to upper direction</li> <li>no loops</li> <li>eliminate edges that are implied by transitiveness</li> <li>no arrows</li> </ol>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#elements","title":"Elements","text":""},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#minimal-elements","title":"Minimal elements","text":"<p>indegree = 0 (excluding self)</p> <p>a is a minimal element in S if there is no \\(b \\in S\\) such that \\(b \\preceq a\\)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#maximal-elements","title":"Maximal elements","text":"<p>outdegree = 0 (excluding self)</p> <p>a is a maximal element in S if there is no \\(b \\in S\\) such that \\(a \\preceq b\\)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#least-element","title":"Least element","text":"<p>Element a is called least element of S, if \\(a \\preceq b, \\forall b \\in S\\)</p> <p>The lowermost element of Hasse diagram</p> <p>It has to be unique - ie the only minimal element</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#greatest-element","title":"Greatest Element","text":"<p>Element a is called greatest element of S if \\(b \\preceq a, \\forall b\\in S\\) </p> <p>The uppermost element of Hasse diagram</p> <p>It has to be unique - ie the only maximal element</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#summary","title":"Summary","text":"<p>Minimal and maximal points are end points that are related to all elements of the question set B, while least and greatest point are unique end point related to all elements of the question set B</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#bounds","title":"Bounds","text":"<p>Let A be a subset of S</p> <p>Bound is a set of the above elements</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#upper-bound","title":"Upper bound","text":"<p>If u is an element of S such that \\(a \\preceq u, \\forall a \\in A\\), then u is called upper bound of A</p> <p>should be related to both a and b</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#lubsupremum","title":"LUB/Supremum","text":"<p>Least upper bound</p> <p>L==U==B/S==u==premum</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#lower-bound","title":"Lower bound","text":"<p>If \\(l\\) is an element of S such that \\(l \\preceq a, \\forall a \\in A\\), then \\(l\\) is called lower bound of A</p> <p>should be related to both a and b</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#glbinfimum","title":"GLB/Infimum","text":"<p>Greatest lower bound</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#lattice","title":"Lattice","text":"<p>If the HASSE diagram starts and ends with a single point, it's called as a lattice.</p> <p>A lattice is a POSET \\((S, \\preceq)\\) in which each pair of elements has</p> <ol> <li>LUB    LUB of a and b: \\(a \\lor b\\) (join of {a, b}) -&gt; sup(a, b)</li> <li>GLB    GUB of a and b: \\(a \\land b\\) (meet of {a,b}) -&gt; inf(a,b)</li> </ol> <p>eg: \\((D_6, /)\\)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#examples","title":"Examples","text":"\\[ \\left(P(S), \\subseteq\\right)\\\\ A, B \\in P(S): A \\lor B = A \\cup B, A \\land B = A \\cap B \\] \\[ \\left(P(S), \\supseteq \\right)\\\\ A, B \\in P(S): A \\lor B = A \\cap B, A \\land B = A \\cup B \\] \\[ \\left(P(S), \\le\\right)\\\\ A, B \\in P(S): A \\lor B = \\text{max}(A,B), A \\land B = \\text{min}(A,B) \\] \\[ \\left(D_n, / \\right)\\\\ A, B \\in D_n: A \\lor B = \\text{lcf}(A,B), A \\land B = \\text{hcf}(A,B) \\]"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#semi-lattice","title":"Semi-Lattice","text":""},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#join-semi-lattice","title":"Join Semi-Lattice","text":"<p>Lattice with only LUB</p> <p>multiple starting points</p> <p>Eg: \\(( \\{2, 3, 60,180\\},  /)\\)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#meet-semi-lattice","title":"Meet Semi-Lattice","text":"<p>Lattice with only GLB</p> <p>multiple ending points</p> <p>Eg: \\((I_{12}, /)\\)</p>"},{"location":"2_Core/Discrete_Structures/03_Ordering_Relations/#properties-of-lattices","title":"Properties of Lattices","text":"<p>Let \\((L, \\lor, \\land)\\) be an algebraic system defined by lattice \\((L, \\preceq)\\)</p> <ol> <li>Idempotency</li> <li>\\(a \\land a = a\\)</li> <li>\\(a \\lor a = a\\)</li> <li>Commutative</li> <li>\\(a \\land b = b \\and a\\)</li> <li>\\(a \\lor b = b \\lor a\\)</li> <li>Associative</li> <li>\\((a \\land b) \\land c = a \\land (b \\land c)\\)</li> <li>\\((a \\lor b) \\lor c = a \\lor (b \\lor c)\\)</li> <li>Absorption    (opposite operation)</li> <li>\\(a \\land (a \\lor b) = a\\)</li> <li>\\(a \\lor (a \\land b) = a\\)</li> <li>Distributive (not all lattices are distributable)</li> <li>\\(a \\land (b \\lor c) = (a \\land b) \\lor (a \\land c)\\)</li> <li>\\(a \\lor (b \\land c) = (a \\lor b) \\land (a \\lor c)\\)</li> <li>Consistency    \\(a \\land b = a \\text{ and } a \\lor b = b\\)</li> </ol>"},{"location":"2_Core/Discrete_Structures/04_Graphs/","title":"04 Graphs","text":""},{"location":"2_Core/Discrete_Structures/04_Graphs/#graphs","title":"Graphs","text":"<p>Here, we are talking about undirected graphs</p> <p>All undirected graphs are symmetric</p> <p>Adjacency matrix of non-directed graph is a symmetric matrix \\((A = A')\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#basic-concepts","title":"Basic Concepts","text":"<p>A graph is represented as \\(G = (V, E)\\) where</p> <ul> <li>V = set of vertices</li> <li>E = set of edges; the edges are undirected</li> </ul> <p>Loops are allowed; graph with no loops is called as simple/loop-free graph</p> <p>maximum degree of a vertex in a simple graph \\(= |V| - 1\\)</p> <p>\\(|V(g)| = |V| =\\) order of G = no of vertices in the graph G</p> <p>\\(|E(g)| = |E| =\\) size of G = no of edges in the graph G</p> <p>No of edges \\(= \\frac{\\sum deg(v_i)}{2}\\)</p> <p>n vertices can only have \\(n-1\\) adjacent vertices</p> <p>Graphic sequence = deg sequence from which valid graph is possible Non-graphic sequence = deg sequence from which graph is not possible</p> <p>no of labelled graphs on a given set of n vertices \\(= 2^{nC_2}\\) out of them, \\((nC_2)C_m\\) contain m edges</p> <p>when n = 3, 4 non-isomorphic graphs are possible when n = 4, 11 non-isomorphic graphs are possible</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#multigraph","title":"Multigraph","text":"<p>is a graph with more than one edge b/w a pair of vertices</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#degree-sequence","title":"Degree Sequence","text":"<p>is the set of degrees of the vertices</p> <p>Loop is taken as an increment of two (as it starts and ends at the same place)</p> <p>it is written in ascending order: from lowest degree to highest degree \\(\\delta(G) \\to \\Delta (G)\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#regular-graph","title":"Regular Graph","text":"<p>loop-free graphs where every vertex has the same degree</p> <p>\\(\\delta(G) = \\Delta(G)\\)</p> <p>The name of the graph \\(= (|V| - 1)\\) Regular graph Eg: for 5 vertices graph, if all the 5 vertices are connected to the others, then the name will be \"4 - regular graph\"</p> <p>\\(|E| = \\frac{n \\times d}{2}, d =\\) the degree of every vertex</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#theorems","title":"Theorems","text":""},{"location":"2_Core/Discrete_Structures/04_Graphs/#non-directed-graph","title":"Non-directed graph","text":"<p>If \\(V = {v_1, v_2, v_3, \\dots, v_n}\\) is the vertex set of a non-directed graph, then \\(\\sum\\limits_{i=1}^n deg(v_i) = 2 |E|\\)</p> <p>Each element contributes a count of one to the degree of each of the two vertices on which it is incident</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#directed-graph","title":"Directed Graph","text":"<p>\\(\\sum\\limits_{i=1}^n deg^+(v_i) = \\sum\\limits_{i=1}^n deg^-(v_i) = |E|\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#cor1","title":"Cor(1)","text":"<p>In any non-directional graph, there is an even number of vertices of odd degree </p> <p>If W: set of vertices of G with odd degree, U: set of vertices of G with even degree</p> \\[ \\sum\\limits_i deg(V_i) = 2|E| \\\\ \\sum\\limits_{i \\in W} deg(V_i) + \\underbrace{ \\sum\\limits_{i \\in U} deg(V_i)}_\\text{even} = \\underbrace{2|E|}_\\text{even} \\\\ \\implies \\sum\\limits_{i \\in W} deg(V_i) \\text{ is also even} \\] <p>But W contains all vertices with odd degree. \\(\\therefore,\\) the no of vertices in W should be even. Hence, |W| is also even.</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#cor2","title":"Cor(2)","text":"<p>If \\(k = \\delta (G)\\) is the minimum degree of all vertices of G, then \\(k|V| \\le \\sum\\limits_{i=1}^n deg(v_i)\\)</p> <p>In particular, if G is a k-regular graph (where the degree of all the vertices is k), then \\(k|V| = \\sum\\limits_{i=1}^n deg(v_i) = 2|E|\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#path","title":"Path","text":"<p>In a graph G, a sequence P of zero/more edges of the form \\(\\set{v_0, v_1}, \\set{v_1, v_2}, \\dots, \\set{v_{n-1}, v_n}\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#graphical-representation","title":"Graphical Representation","text":"<pre><code>graph LR\nv0 --- v1 --- v2 --- ... --- Vn-1 --- Vn</code></pre> <p>is called a path from \\(v_0\\) to \\(v_n\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#length","title":"Length","text":"<p>the number of edges in path p</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#notes","title":"Notes","text":"<p>In a path, vertices and edges</p> <ol> <li>may be repeated</li> <li>If \\(v_0 = v_n\\), then path p is closed    \\(v_0 = v_n\\), then path p is open</li> <li>a path p is itself a graph, ie, subgraph of G</li> <li>\\(V(P) \\subseteq V(G)\\)</li> <li>\\(E(P) \\subseteq E(G)\\)</li> <li>Path may have no edges at all</li> <li>length = 0 \\((V(P) = \\set{v_0})\\)</li> <li>trivial path (simple, closed path)</li> </ol>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#simple-path","title":"Simple path","text":"<p>Path with all distinct edges and vertices end points(vertices) of a closed path are exempted from this condition</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#circuit","title":"Circuit","text":"<ol> <li>closed path</li> <li>length \\(\\ge 1\\)</li> <li>no repeated edges</li> <li>end points are equal (is repeated?)</li> <li>it may have repeated vertices</li> </ol>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#cycle","title":"Cycle","text":"<p>simple circuit no repeated vertices (except start and end points)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#wheel","title":"Wheel","text":"<p>Cycle with 1 vertex connected to all other vertices the vertex doesn\u2019t necessarily have to be inside the cycle</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#complete-graph-k_n","title":"Complete Graph \\(k_n\\)","text":"<p>every vertex is connected with every other vertex</p> <p>if \\(|V| = n\\), deg of every vertex \\(= n-1\\)</p> <pre><code>graph LR\n\nsubgraph k1\n    a(( ))\nend\n\nsubgraph k2\n    b(( )) --- c(( ))\nend\n\nsubgraph k3\n    d(( )) --- e(( )) --- f(( )) --- d\nend\n\nsubgraph k4\n    g(( )) --- h(( )) --- i(( )) --- j(( )) --- g\n    h --- j\n    i --- g\nend</code></pre>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#linear-graphs-l_n","title":"Linear graphs \\(L_n\\)","text":"<p>Open graph \\(|V| = n\\)</p> <pre><code>graph LR\n\nsubgraph L2\n    a(( )) --- b(( ))\nend\n\nsubgraph L5\n    c(( )) --- d(( )) --- e(( )) --- f(( )) --- g(( ))\nend</code></pre> Closed Open Circuit Cycle Wheel Regular graph Complete Graph \\vert V \\vert n n n n n n deg of vertex d n-1 \\vert E \\vert n n-1 n n \\(\\frac{n \\times d}{2}\\) \\(\\frac{n(n-1)}{2} = nC_2\\)"},{"location":"2_Core/Discrete_Structures/04_Graphs/#theorem","title":"Theorem","text":"<p>In a graph G, every u-v path contains a simple u-v path</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#proof","title":"Proof","text":"<p>Mathematical induction</p> <p>Taking a u-v path. It can either be</p> <ul> <li> <p>closed</p> <p>obviously contains a trivial path (of length 0)</p> <p>simple path</p> </li> <li> <p>open</p> <p>Consider an open u-v path</p> <p>To show it contains a simple u-v path</p> <pre><code>graph LR\nu((u / v0)) --- v1((v1)) --- v2((...)) --- v((v / vn))</code></pre> <p>Proof by induction on the length of path p</p> <ul> <li> <p>Length = 1 (basic)</p> </li> <li> <p>then path p is open as it contains only one edge</p> </li> <li> <p>length = k, where \\(1 \\le k \\le n\\) (induction hypothesis)</p> </li> <li> <p>assume that when the length is k, then u-v path contains a simple u-v</p> </li> <li> <p>length = n+1 (induction proof)</p> </li> <li> <p>trying to prove that it contains a simple path (using the induction hypothesis)</p> <p><code>mermaid graph LR u((u / v0)) --- v1((v1)) --- v2((...)) --- vn((vn)) --- v((v / vn+1))</code></p> <p>this path</p> <ul> <li>has no repeated vertices \\(\\implies\\) it is simple</li> </ul> </li> <li> <p>contains repeated vertices</p> <ul> <li>Let \\(v_i = v_j\\) be the vertices for \\(i &lt; j\\) \\(v_0 - v_1 - \\ldots - v_i - v_{i+1} - \\ldots - v_j - v_{j+1} - \\ldots - v_{n+1}\\)</li> <li>remove \\(v_{i+1} - \\ldots - v_j\\) from P</li> </ul> </li> <li> <p>now, \\(v_{0} - v_1 - \\ldots - v_i - v_{j+1} - \\ldots - v_{n+1}\\) is a simple path</p> </li> </ul> </li> </ul> <p>Hence, proved</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#isomorphism","title":"Isomorphism","text":"<p>denoted by \\(\\cong\\)</p> <p>2 graphs G1 and G2 are isomorphic if there is a function \\(f: V(G_1) \\to V(G_2)\\) such that</p> <ol> <li>f is one-one</li> <li>f is onto</li> <li>f preserves adjacency of vertices</li> <li>\\(\\forall (u,v) \\in E(G_1) \\implies (f(u), f(v)) \\in E(G_2)\\)</li> </ol> <p>f need not be unique; there can be various mappings that preserve adjacency</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#implications-of-isomorphism","title":"Implications of isomorphism","text":"<ol> <li>\\(| V(G_1) | = | V(G_2) |\\)</li> <li>\\(| E(G_1) | = | E(G_2) |\\)</li> <li>deg seq(G1) = deg seq(G2)</li> <li>Loops: \\((v,v) \\in E(G_1) \\implies (\\ f(v), f(v) \\ ) \\in E(G_2)\\)</li> <li>if there is a cycle of length n in G1, ie \\(v_0 - v_1 - \\ldots - v_k (=v_0)\\)    then \\(f(v_0) - f(v_1) - \\ldots - f(v_k) (=f(v_0))\\) is also a cycle of length n in G2</li> <li>Cycle vector \\(\\set{c_1, c_2, \\dots, c_k}\\) of G = cycle vector \\(\\set{d_1, d_2, \\dots, d_k}\\) where</li> <li>cn = cycle of length n</li> <li>dn = cycle of length n</li> <li>the induced subgraphs (by a set W) of isomorphic graphs are also isomorphic</li> <li>even the complements of the graphs are isomorphic</li> </ol>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#incident-matrix","title":"Incident Matrix","text":"<p>Let G = (V, E) be an undirected graph with n vertices and m edges</p> <p>\\(B_{n \\times m} = [b_{ij}]\\) is called the incident matrix of G, where</p> \\[ b_{ij} = \\begin{cases} 1, \\text{ when } e_j \\text{ is incident on } v_i \\\\ 0, \\text{ otherwise} \\end{cases} \\]"},{"location":"2_Core/Discrete_Structures/04_Graphs/#subgraph","title":"Subgraph","text":"<p>H is a subgraph of G \\(\\iff V(H) \\subseteq V(G)\\) and \\(E(H) \\subseteq E(G)\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#spanning-subgraph","title":"Spanning subgraph","text":"<p>\\(\\iff V(H) = V(G)\\) and \\(E(H) \\subseteq E(G)\\)</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#minimal-spanning-subgraph","title":"Minimal Spanning subgraph","text":"<p>spanning subgraph with minimum no of edges required to make the graph connected</p> <p>removal of any edge makes the subgraph disconnected</p> <p>need not be a unique; there can many variations of subgraphs with the above property</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#induced-subgraph","title":"Induced Subgraph","text":"<p>it\u2019s the subgraph using only vertices contained in set W and all the pre-existing edges</p> <p>If \\(W \\subseteq G\\), then the subgraph induced by W in G is the one with the vertices set W and contains all edges connecting a pair of vertices in W</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#complement-of-graph","title":"Complement of graph","text":"<p>If H is a simple graph with n vertices, then complement denoted as \\(\\bar H\\) of H is the complement of H in \\(k_n\\), where \\(k_n =\\) complete graph with n vertices</p> <p>\\(V(\\bar H) = V(H)\\)</p> <p>2 vertices in \\(\\bar H\\) are adjacent/connected only if they are not adjacent/connected in H</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#complement-of-subgraph","title":"Complement of subgraph","text":"<p>\\(\\bar H = G - H\\)</p> <ul> <li>\\(V(\\bar H) = V(H)\\)</li> <li>\\(E(\\bar H) = E(G) - E(H)\\)</li> </ul>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#operations-on-graphs","title":"Operations on Graphs","text":"<ul> <li> <p>\\(G_1 \\cap G_2\\) is a graph with</p> <ul> <li>vertices set \\(V(G_1) \\cap V(G_2)\\)</li> <li>edge set \\(E(G_1) \\cap E(G_2)\\)</li> </ul> </li> <li> <p>\\(G_1 \\cup G_2\\) is a graph with</p> <ul> <li>vertices set \\(V(G_1) \\cup V(G_2)\\)</li> <li>edge set \\(E(G_1) \\cup E(G_2)\\)</li> </ul> </li> <li>\\(\\bar G \\cup G = k_n\\)</li> <li>\\(\\bar G \\cap G = N_7\\), where \\(N_7\\) is a null graph (with vertices but no edges)</li> </ul>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#connected-graph","title":"Connected graph","text":"<p>if there is a path from any vertex to any other vertex in that graph</p> <p>ie every vertex is of degree\\(\\ge 1\\)</p> <p>otherwise it is disconnected</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#bipartite-graph","title":"Bipartite Graph","text":"<p>is a simple graph in which V(G) can be partitioned into 2 sets M and N, such that</p> <ol> <li>if vertex \\(v \\in M,\\) then it can only be adjacent to vertices in N</li> <li>If vertex \\(v \\in N,\\) then it can only be adjacent to vertices in M</li> <li>\\(M \\cap N = \\phi\\)</li> <li>\\(M \\cup N = V(G)\\)</li> </ol> <p>When drawing the graph, by convention, M comes up and N comes down</p>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#properties","title":"Properties","text":"<ol> <li>\\(\\sum\\limits_{v \\in M} deg(v) = \\sum\\limits_{v \\in n} deg(v)\\)</li> <li>A bipartite graph contains no odd cycles</li> <li>Every subgraph of a bipartite graph is also bipartite</li> <li>each edge joins a vertex in M to a vertex in N</li> </ol>"},{"location":"2_Core/Discrete_Structures/04_Graphs/#complete-bipartite-graph","title":"Complete Bipartite graph","text":"<p>Every vertex of M is connected to every vertex of N, and vice-versa</p> <p>G is denoted as \\(k_{m, n}\\)</p> <p>if \\(|M| = m, |N| = n\\), then \\(|V(G)| = m+n, |E(G)| = mn\\)</p> <p>in order to traverse a cycle, you need to traverse even no of edges</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/","title":"05 Trees","text":""},{"location":"2_Core/Discrete_Structures/05_Trees/#trees","title":"Trees","text":"<p>is a simple graph such that there is a unique simple non-directed path (which are not closed) between each pair of vertices</p> <ol> <li>always connected</li> <li>no cycles/circuits</li> </ol> <p>order of tree \\(= |V|\\)</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#properties","title":"Properties","text":"<ol> <li>Trivial tree is a graph with one vertex</li> <li>In every non-trivial tree, there is at least 2 vertices of degree 1</li> <li>A tree with n vertices has exactly \\((n-1)\\) edges</li> <li>If 2 non-adjacent vertices of a tree T are connected by adding an edge, then the resulting graph will contain a cycle; hence, no more a cycle</li> <li>G is a tree \\(\\iff\\) G has no cycles and \\(|E| = |V| - 1\\)</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#rooted-trees","title":"Rooted Trees","text":"<p>is a tree in which there is one designated vertex called as the root</p> <p>level(root) = 0; index(root) = 1</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#directed-tree","title":"Directed Tree","text":"<p>is a rooted tree containing a root from which there is a directed path to each vertex</p> <p>contains hierarchical levels, measured by no of edges away from the root</p> <p>level of a path = length of the path required to reach the vertex from the root</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#spanning-tree","title":"Spanning Tree","text":"<p>Tree containing all vertices of source graph, and minimum required edges to span the entire graph.</p> <p>It is a subgraph of G</p> <p>It is obtained by removing cycles</p> <p>Height of spanning tree = max level</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#minimum-spanning-tree","title":"Minimum Spanning Tree","text":"<p>spanning tree with minimum sum of weights</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#finding-spanning-tree","title":"Finding Spanning Tree","text":"<p>for small trees, we can perform directly; we need to use algorithms for large trees</p> <p>(check mail of Tut 7)</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#depth-first-searchback-track-algorithm","title":"Depth-First search/Back-Track algorithm","text":"<p>(write T={} step-by-step and backtracking)</p> <ol> <li>pick an arbitrary vertex as the root</li> <li>add 1 adjacent vertex and edge at a time</li> <li>avoid formation of cycles</li> <li>if you come across something that contradicts, perform backtrack</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#breadth-first-search-algorithm","title":"Breadth-First Search algorithm","text":"<ol> <li>pick an arbitrary vertex as the root</li> <li>add multiple adjacent vertices and edges (try to get more vertices with max edges)</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#prims-algorithm","title":"Prim\u2019s Algorithm","text":"<p>used for weighted spanning graphs Eg: GMaps</p> <ol> <li>start with minimum edge (e,f)</li> <li>select next minimum edge, which is incident to the either vertex of the starting edge</li> <li>if you have 2 edges with the same priority, take the alphabetically</li> <li>then add the other ones too after the above one</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#kruskals-algorithm","title":"Kruskal\u2019s Algorithm","text":"<ol> <li>start with minimum edge</li> <li>do minimum edges that aren\u2019t even incident(don\u2019t connect them you dummy), making sure that you don\u2019t get cycles</li> </ol> <p>Independent of starting address</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#prim-vs-kruskal","title":"Prim vs Kruskal","text":"Prim Kruskal Starting Edge \u2705 \u274c Chooses ___ at every edge nearest/cheapest neighbor cheapest edge Better for ___ graph Denser Sparse Insertion of vertices \ud83d\udc4d \ud83d\udc4e <p>Pr***i***m - start***i***ng edge</p> <p>Krusk***a***l - ***a***ny</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#trees-terminology","title":"Trees terminology","text":""},{"location":"2_Core/Discrete_Structures/05_Trees/#cut-edgebridge","title":"Cut edge/Bridge","text":"<p>The edge you remove which makes the graph disconnected</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#cut-vertex","title":"Cut Vertex","text":"<p>The vertex you remove which makes the graph disconnected (obviously, even the edges associated with the vertex is also removed)</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#branchinternal-vertex","title":"Branch/Internal Vertex","text":"<p>Vertex with degree &gt; 1</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#leafterminal-vertex","title":"Leaf/Terminal Vertex","text":"<p>vertex with degree 1</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#forest","title":"Forest","text":"<p>Any graph without cycles</p> <p>need not be connected graph</p> <p>All trees are forest; not vice-versa Trees are components of forest</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#parts-of-rooted-directed-tree","title":"Parts of Rooted Directed Tree","text":"<ul> <li>Root</li> <li>Children</li> <li>Parents</li> <li>Descendants</li> <li>Ancestors</li> <li>Leaves</li> <li>Branches</li> </ul>"},{"location":"2_Core/Discrete_Structures/05_Trees/#binary-tree","title":"Binary Tree","text":"<p>tree where every vertex has at most 2 children</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#regular-binary-tree","title":"Regular Binary Tree","text":"<p>tree where every vertex has 0 or 2 children</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#ordering","title":"Ordering","text":"<p>Labels are given to edges</p> <ul> <li>Left edge = 0</li> <li>Right edge = 1</li> </ul>"},{"location":"2_Core/Discrete_Structures/05_Trees/#binary-string-equivalent-of-a-node","title":"Binary String equivalent of a node","text":"<ol> <li>Write edge ordering from the root to the node</li> <li>Add 1 as MSD</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#level-order-indexing","title":"Level-order indexing","text":"<p>Root \\(\\to 1\\) (different from level; level of root is 0)</p> <p>other vertices are designated as (assuming index of parent = p)</p> <ul> <li>left child \\(\\to 2p\\) </li> <li>right child \\(\\to 2p + 1\\)</li> </ul> <p>however, for irregular binary tree, some indices might be skipped</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#level-of-a-node","title":"Level of a node","text":"<p>if \\(i\\) is the index of a node</p> <p>Level = floor(\\(\\log i\\)) (ie, lower integer value)</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#complete-binary-tree","title":"Complete Binary Tree","text":"<p>consider a binary with \\(|V|=n\\)</p> <p>if the index set of a binary tree is \\([1,n]\\), then the binary tree is called as a complete binary</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#characteristics","title":"Characteristics","text":"<ol> <li>Regular</li> <li>Ordered</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#fields","title":"Fields","text":"<ol> <li>Data science</li> <li>Searching</li> <li>Efficient Logic and Computing</li> <li>eliminates the need for parenthesis</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#operationexpression-tree","title":"Operation/Expression Tree","text":"<p>Mathematical operations and expression can be represented</p> <p>consists of</p> <ol> <li>operators (branches)</li> <li>operands (leaves)</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#traversal-algorithms","title":"Traversal Algorithms","text":""},{"location":"2_Core/Discrete_Structures/05_Trees/#pre-order-traversal","title":"Pre-order traversal","text":"<p>polish expression</p> <p>basically prefix</p> <p>\\(a+b \\to +ab\\)</p> <p>Algorithm</p> <ol> <li>Visit the root</li> <li>recursively traverse the left subtree</li> <li>recursively traverse the right subtree</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#post-order-traversal","title":"Post-order traversal","text":"<p>Reverse-polish expression</p> <p>basically post-fix</p> <p>\\(a+b \\to ab+\\)</p> <p>Algorithm</p> <ol> <li>Visit the root</li> <li>recursively traverse the right subtree</li> <li>recursively traverse the left subtree</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#in-order-traversal","title":"In-order traversal","text":"<p>basically in-fix</p> <p>\\(a+b\\)</p> <p>Algorithm</p> <ol> <li>recursively traverse the left subtree</li> <li>Visit the root</li> <li>recursively traverse the right subtree</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#binary-search-tree","title":"Binary Search Tree","text":"<p>Sort Tree</p> <p>every node has a value called as key</p> <p>has parent, left child, right child</p>"},{"location":"2_Core/Discrete_Structures/05_Trees/#properties_1","title":"Properties","text":"<ol> <li>left key &lt; parent key</li> <li>Right key &gt; parent key</li> </ol>"},{"location":"2_Core/Discrete_Structures/05_Trees/#diagram","title":"Diagram","text":""},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/","title":"06 Planar Graphs","text":""},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#planar-graph","title":"Planar Graph","text":"<ol> <li>either the graph itself or at least one isomorphic form of the graph is a plane graph (can be drawn on a plane surface)</li> <li>no crossover of edges</li> </ol> <p>eg:</p> <ul> <li>Complete Graphs \\(k_n\\) \\(n \\le 4\\)</li> <li>\\(Q_3\\)</li> <li>Bipartite graph \\(k_{m,n}\\)   either \\(m \\le 2\\) or \\(n \\le 2\\)</li> </ul> <p>Non-planar graphs eg</p> <ul> <li>\\(k_5\\) and larger</li> <li>\\(k_{3,3}\\)<ul> <li>find longest cycle</li> <li>draw it as a circle</li> </ul> </li> </ul>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#uses","title":"Uses","text":"<p>coloring, classification, analysis of graphs</p> <p>Plane form helps identify different phases (connected regions) of a planar graph</p>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#degree-of-region","title":"Degree of Region","text":"<p>\\(|R|\\) = No of edges in the boundary of that region</p> <p>cut edge is counted twice</p>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#dual-of-planar-graph","title":"Dual of Planar Graph","text":"<ul> <li>every region will become vertices of the dual, and vice versa   if G is primal graph and G* is the dual,<ul> <li>\\(|R^*| = |V|\\)</li> <li>\\(|V^*| = |R|\\)</li> </ul> </li> <li>if 2 regions have common boundary line, then the corresponding new vertices of the dual graph will get connected to each other</li> </ul>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#theorems","title":"Theorems","text":"<p>If G is a planar graph, then</p> <ol> <li>\\(\\sum deg(r_i) = 2|E|\\)</li> <li>\\(3|R| \\le 2|E|\\)</li> <li>if G is a connected planar graph, then \\(|V| - |E| + |R| = 2\\)</li> <li>\\(|E| \\le 3|V| - 6\\)</li> <li>There exists a vertex v in G such that \\(deg(v) \\le 5\\)</li> </ol>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#eulers-theorem-for-planar-graphs","title":"Euler\u2019s theorem for planar graphs","text":"<p>\\(|V| - |E| + |R|= 2\\)</p>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#polyhedral-graphs","title":"Polyhedral Graphs","text":"<p>connected planar graphs</p> <ul> <li>\\(deg(v_i) \\ge 3\\)</li> <li>\\(deg(r_i) \\ge 3\\)</li> <li>using degree of region theorem,<ul> <li>\\(3|V| \\le 2|E|\\)</li> <li>\\(3|R| \\le 2|E|\\)</li> </ul> </li> </ul> <p>eg: \\(k_4, Q_3\\)</p>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#eulerian-graph","title":"Eulerian Graph","text":"<p>Graph with at least one Eulerian circuit</p> Eulerian Circuit Eulerian Path Path Type closed open passes every edge of original graph exactly once exactly once passes every vertex of original graph at least once at least once repeated vertices allowed allowed"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#cases","title":"Cases","text":"<ul> <li>All vertices are of even degree - both possible</li> <li>Only 2 vertices are of odd degree and the rest are even degree - eulerian path possible not circuit</li> <li>All vertices are of odd degree - both not possible</li> </ul>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#hamiltonian-graph","title":"Hamiltonian Graph","text":"<p>Graph with at least one Hamiltonian cycle</p> Hamiltonian Cycle Hamiltonian Path Path Type simple, closed simple, closed passes every edge of original graph exactly once exactly once passes every vertex of original graph exactly once exactly once repeated vertices not allowed not allowed when we have cut edge, possible? not possible possible"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#diracs-theorem","title":"Dirac\u2019s Theorem","text":"<p>A simple graph with n vertices \\((n \\ge 3)\\) and \\(deg(v_i) \\ge \\frac n 2\\) has a Hamiltonian circuit eg: \\(k_n, n \\ge 3\\)</p> <p>this is not a necessacity for existence of hamiltonian circuit; the converse is not necessarily true eg: cycle of \\(n\\) vertices each of deg 2; there obviously is hamiltonian circuit even though dirac\u2019s theorem isn\u2019t satisfied</p>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#dual-graph","title":"Dual graph","text":"<p>dual graph is a graph where the</p> <ul> <li>vertices are the regions of primal graph</li> <li>regions are the vertices of primal graph</li> </ul>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#properties","title":"Properties","text":"<p>If \\(G(V,E,R) \\implies G^*(V^*,E^*,R^*)\\), where G is primal and G* is dual graph</p> <ol> <li>\\(|V^*| = |R|\\)</li> <li>\\(|R^*| = |V|\\)</li> <li>\\(|E^*| = |E|\\)</li> <li>\\(deg(r_i) = deg(r^*_i)\\)</li> <li>Dual graph is always planar</li> <li>there is a cut vertex placed in region \\(r \\implies\\) you will get a self loop at \\(v^*\\) of G, where \\(v^*\\) represents the corresponding vertex of \\(r\\)</li> </ol>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#graph-coloring","title":"Graph Coloring","text":"<p>A coloring of a simple graph is the assignment of a color to each vertex of the graph such that no 2 adjacent vertices are assigned the same color.</p>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#chromatic-number-of-g","title":"Chromatic number of G","text":"<p>\\(\\chi (G) =\\) the least number of colors need for coloring G</p> <p>eg:</p> <ul> <li>Star graph requires only 2 colors</li> <li>\\(k_n\\) requires \\(n\\) colors</li> <li>\\(k_{m,n}\\) requires only 2 colors</li> <li>\\(C_n\\) (cycle of \\(n\\) vertices) requires<ul> <li>2 colors when n = even</li> <li>3 colors when n = odd</li> </ul> </li> </ul>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#theorem","title":"Theorem","text":"<p>For a planar graph,</p> <p>The chromatic number is no greater than 4, ie \\(\\chi(G) \\le 4\\)</p> <p>no proof for this</p>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#coloring-rules","title":"Coloring Rules","text":"<ol> <li>\\(\\chi \\le |V|\\)</li> <li>a triangle/triangular subgraph \\((C_3)\\) requires 3 colors</li> <li>if some subgraph of \\(G\\) requires \\(k\\) colors, then    \\(X(G) \\ge k\\)</li> <li>if deg\\((v) = d\\), then d colors are required to color the vertices adjacent to v</li> <li>\\(\\chi(G) = max \\{ \\chi(C)\\) where C is a connected component of G</li> <li>every \\(k\\) chromatic graph \\((\\chi(G) = k)\\) has atleast \\(k\\) vertices such that the \\(deg(v_i) \\ge k-1\\)</li> <li>For any graph \\(G, \\chi(G) \\le 1 + \\Delta(G)\\) \\(\\Delta(G)\\) is the largest degree of any vertex in G</li> <li>\\(\\chi(G) \\ge \\frac{|V|}{ |V| - \\delta(G) }\\) \\(\\delta(G)\\) is the largest degree of any vertex in G</li> </ol>"},{"location":"2_Core/Discrete_Structures/06_Planar_Graphs/#properties-of-chromatic-number","title":"Properties of chromatic number","text":"<ol> <li> <p>\\(k\\)-critical graph is a graph where</p> <ul> <li>\\(\\chi(G) = k\\)</li> <li>\\(\\chi(G-V) = k-1\\)</li> </ul> </li> </ol> <p>possible only if \\(\\delta(G) \\ge k-1\\)</p> <ol> <li> <p>G is 1-chromatic, then G is totally disconnected</p> </li> <li> <p>\\(\\chi(G) = 2 \\iff\\) G is bipartite graph \\(\\iff\\) every cycle of G has even length</p> </li> <li> <p>otherwise it will be a triangular subgraph and hence \\(\\chi\\) has to be 3</p> </li> <li> <p>\\(\\chi(G) \\le \\Delta(G) + 1\\)</p> </li> <li> <p>For complete graphs, \\(\\chi(G) = \\Delta + 1\\)</p> </li> <li> <p>For other graphs, \\(\\chi(G) &lt; \\Delta + 1\\)</p> </li> <li> <p>If G1, G2, \u2026 Gk are disconnected components of graph G, then \\(\\chi(G) = max\\set{\\chi(G_i)}\\)</p> </li> <li> <p>Every tree with \\(|V| \\le 2\\) is 2-chromatic</p> </li> <li> <ul> <li>\\(\\chi(G) \\ge 3 \\iff\\) G has a cycle of odd length</li> <li>\\(\\chi(G) = 2 \\iff\\) G has no cycle of odd length  (we already learnt this for bipartite graphs)</li> </ul> </li> <li> <p>Every connected k-connected graph contains a critical k-chromatic graph</p> </li> <li> <p>Only type of 3-critical graph is \\(C_{2n+1}\\)</p> </li> </ol>"},{"location":"2_Core/Discrete_Structures/08_Pigeon_Hole/","title":"08 Pigeon Hole","text":""},{"location":"2_Core/Discrete_Structures/08_Pigeon_Hole/#summary","title":"Summary","text":"\\[ \\begin{aligned} r &amp;= \\left\\lceil \\frac n k \\right \\rceil \\\\ n &amp;= k(r-1) + 1 \\\\ k &amp;= \\left\\lceil \\frac n r \\right \\rceil \\\\ \\end{aligned} \\]"},{"location":"2_Core/Discrete_Structures/08_Pigeon_Hole/#pigeon-hole-principle","title":"Pigeon Hole Principle","text":"<p>if \\(m\\) holes are assigned for \\(n\\) pigeons, and \\(m&lt;n\\), then atleast one hole will have atleast 2 pigeons</p> <p>in other words, if \\(k+1\\) or more objects are places into \\(k\\) boxes, then there is atleast one box containing two or more objects.</p> <p>if \\(n\\) objects are placed in \\(k\\) boxes, then there is atleast one box with atleast \\(\\lceil \\frac n k \\rceil\\) objects</p> <ul> <li>ceiling \\(\\lceil x \\rceil\\) means that \\(x\\) is rounded up</li> <li>floor \\(\\lfloor x \\rfloor\\) means that \\(x\\) is rounded down</li> </ul>"},{"location":"2_Core/Discrete_Structures/08_Pigeon_Hole/#reason","title":"Reason","text":"<p>A function from a finite set to a smaller finite set cannot be one-one, and hence there will be 2 elements in the domain that have the same image in the co-domain.</p>"},{"location":"2_Core/Discrete_Structures/08_Pigeon_Hole/#application","title":"Application","text":"<p>Minimum no of objects \\(n\\) to be distributed among \\(k\\) boxes such that \\(r\\) objects must be in one of the boxes is given by \\(n = k(r-1) + 1\\)</p> <p>here, \\(r \\le \\lceil \\frac{n}{k} \\rceil\\)</p> <p>This is reversed statement of Pigeon Hole statements</p>"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/","title":"09 Inclusion Exclusion","text":""},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#principle-of-inclusion-exclusion","title":"Principle of Inclusion-Exclusion","text":"<p>\\(n(A)\\) can also be represented as \\(|A|\\)</p>"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#basic-counting","title":"Basic Counting","text":""},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#sum-rule","title":"Sum Rule","text":"<p>Let \\(A_1 , A_2, \\dots, A_n\\) be disjoint(mutually-exclusive) sets</p> <p>\\(n (A_1 \\cup A_2 \\cup \\dots \\cup A_n) = n(A_1) + n(A_2) + \\dots + n(A_n)\\)</p> <p>OR operation</p>"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#product-rule","title":"Product Rule","text":"<p>\\(n (A_1 \\cap A_2 \\cap \\dots \\cap A_n) = n(A_1) \\times n(A_2) \\times \\dots \\times n(A_n)\\)</p> <p>AND operation</p>"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#inclusion-exclusion","title":"Inclusion-Exclusion","text":"<ul> <li>\\(n(A \\cup B) = 1 \\iff\\) mutually-exhaustive</li> <li>\\(n(A \\cap B) = 0 \\iff\\) mutually-exclusive</li> </ul> <p>Formulae</p> <ol> <li> <p>\\(n(A \\cup B) = n(A) + n(B) - n(A \\cap B)\\)</p> </li> <li> \\[    \\begin{aligned}    n(A \\cup B \\cup C)&amp;= n(A) + n(B) + n(C) \\\\    &amp; \\qquad - n(A \\cap B) - n(B \\cap C) - n(A \\cap C) \\\\   &amp; \\qquad + n(A \\cap B \\cap C)    \\end{aligned}    \\] </li> <li> <p>\\(A' = S - A\\)</p> </li> <li> <p>Demorgan</p> </li> <li> <p>\\((A \\cup B)' = A' \\cap B'\\)</p> </li> <li>\\((A \\cap B)' = A' \\cup B'\\)</li> </ol> \\[ \\begin{aligned} |A'| &amp;= |U| - |A| \\\\ |A-B| &amp;= |A \\cup B'| \\\\ &amp;= |A| - |A\\cup B| \\\\ |A \\cap B \\cap C'| &amp;= |A \\cap B| - |A \\cap B \\cap C| \\\\ |A \\cap B' \\cap C| &amp;= |A \\cap C| - |A \\cap B \\cap C| \\\\ |A \\cap B' \\cap C'| &amp;= |B' \\cap C'| - |A' \\cap B' \\cap C'| \\end{aligned} \\]"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#gen-principle","title":"Gen Principle","text":"\\[ \\begin{aligned} \\vert  A_1 \\cup A_2 \\cup \\ldots \\cup A_n  \\vert  &amp;= S_1 - S_2 + S_3 - \\ldots + (-1)^{n-1} S_n \\\\ &amp;= \\sum\\limits_{i = 1}^n |A_i| - \\sum\\limits_{i,j} |A_i \\cap A_j| + \\sum\\limits_{i, j, k} |A_i \\cap A_j \\cap A_k| \\\\ &amp; \\qquad + \\ldots + (-1)^{n-1} |A_1 \\cap A_2 \\cap \\dots \\cap A_n| \\end{aligned} \\]"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#selection","title":"Selection","text":"Permutation Combination ordered? Y N with rep \\(n^r\\) \\(V(n,r)\\) without rep \\(nP_r = \\frac{n!}{(n-r)!}\\) \\(nC_r = \\frac{n!}{r!\\ (n-r)!} = nC_{n-r}\\) <p>\\(nC_r = nP_r = 0 \\iff n&lt;r\\)</p> <p>The no of \\(r\\) combinations of \\(n\\) distinct objects with unlimited repetitions</p> \\[ \\begin{aligned} &amp;= V(n,r) \\\\ &amp;= (n-1+r)C_r &amp;= (n-1+r)C_{n-1} \\\\ &amp;= \\frac{(n-1+r)!}{r! \\ (n-1)!} \\end{aligned} \\] <p>Uses</p> <ul> <li>This is the no of ways of distributing \\(r\\) similar balls into \\(n\\) number boxes</li> <li>no of non-negative integer solutions of \\(x_1 + x_2 + \\dots + x_n = r\\)</li> <li>no of binary nos with \\((n-1)\\) ones and \\(r\\) zeros</li> </ul>"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#integral-solutions","title":"Integral Solutions","text":"<p>The no of non-negative integer solutions is given by \\(V(n,r)\\)</p> \\[ \\set{ x_1 a_1, x_2 a_2, \\dots, x_n a_n } \\iff x_1 + x_2 + \\dots + x_n = r \\]"},{"location":"2_Core/Discrete_Structures/09_Inclusion-Exclusion/#derangement","title":"Derangement","text":"<p>special type of permutation of any \\(n\\) objects such that no number takes it\u2019s own place</p> <p>\\(i_1, i_2, \\dots, i_n \\iff i_1 \\ne 1, i_2 \\ne 2, i_n \\ne n\\)</p> <p>normally, for any arrangement of \\(n\\) numbers, no of arrangements = \\(n!\\)</p> <p>\\(D_n =\\) no of derangments possible for derangement of \\(n\\) numbers</p> \\[ \\begin{aligned} D_1 &amp;= 0 \\\\ D_2 &amp;= 1 \\\\ D_3 &amp;= 2 \\qquad \\set{(3, 1, 2), (2, 3, 1)} \\\\ \\vdots &amp; \\\\ D_n &amp;= n! \\left[ 1- \\frac{1}{1!}  + \\frac{1}{2!} - \\frac{1}{3!} + \\dots + (-1)^n \\frac{1}{n!} \\right] \\\\ &amp;= n! \\left[ 1 + \\sum_{i=1}^n (-1)^i \\frac{1}{i!} \\right] \\end{aligned} \\]"},{"location":"2_Core/Discrete_Structures/11_Groups/","title":"11 Groups","text":""},{"location":"2_Core/Discrete_Structures/11_Groups/#order-of-an-element","title":"Order of an element","text":""},{"location":"2_Core/Discrete_Structures/11_Groups/#for-oplus","title":"For \\(+, \\oplus\\)","text":"<p>Regular/modulo addition operator</p> <p>\\(x \\oplus y =\\) ??</p> <p>what positive number multiplied gives the product as the identity element</p>"},{"location":"2_Core/Discrete_Structures/11_Groups/#for-times-otimes","title":"For \\(\\times, \\otimes\\)","text":"<p>Regular/modulo multiplication operator</p> <p>what number raised to gives the final answer as the identity element</p>"},{"location":"2_Core/Discrete_Structures/11_Groups/#for-both","title":"For Both","text":"<p>If \\(a \\in G\\), G is a group, then the order of \\(a\\) is the order of the cyclic group</p>"},{"location":"2_Core/Discrete_Structures/11_Groups/#cosets-lagranges-theorem","title":"COSETS &amp; Lagrange\u2019s Theorem","text":"<p>Let</p> <ul> <li>\\(G\\) be a group</li> <li>\\(H\\) be its subgroup</li> <li>\\(a \\in G\\)</li> <li> <p>\\(h \\in H\\)</p> </li> <li> <p>COSETS may be duplicated, but we are only concerned about disjoint COSETS</p> </li> <li>Union of disjoint COSETS will be \\(G\\)</li> <li>no of elements in COSET = no of elements in \\(H\\)</li> </ul> Left COSET Right COSET \\(+\\) \\(a + H = \\set{a + h, h \\in H}\\) \\(H + a = \\set{h + a, h \\in H}\\) \\(\\oplus\\) \\(\\times\\) \\(a H = \\set{a \\times h}\\) \\(Ha = \\set{h \\times a}\\) \\(\\otimes\\)"},{"location":"2_Core/Discrete_Structures/11_Groups/#theorems","title":"Theorems","text":"<p>If \\(b \\in G, b \\ne a\\)</p> <ol> <li>\\(a \\in H \\iff aH = H\\)</li> <li>\\(aH = bH \\iff a^{-1} b \\in H\\)</li> <li>\\(a \\in bH \\iff a^{-1} \\in H b^{-1}\\)</li> <li>\\(a \\in bH \\iff aH = bH\\)</li> </ol> <p>\\(^{-1}\\) means inverse (could be additive or multiplicative inverse)</p>"},{"location":"2_Core/Discrete_Structures/11_Groups/#lagranges-theorem","title":"Lagrange\u2019s Theorem","text":"<p>Let \\(G\\) be a finite group of order \\(n\\) and \\(H\\) be any subgroup of \\(G\\). Then the order of H divides the order of \\(G\\).</p> <p>\\([G:H]\\) = index of H = no of distinct left COSETS of H in G</p> <p>Let \\(r\\) be index of H. Let \\(|G| = n,|H| = m\\). Then \\(n = mr \\implies \\frac n m = r\\). Clearly, \\(m\\) divides \\(n\\)</p>"},{"location":"2_Core/Discrete_Structures/11_Groups/#application","title":"Application","text":"<p>A cyclic group can only have subgroups with no of elements which divides the </p> <p>eg: \\((Z_7, \\oplus_7)\\) can only have subgroups having no of elements dividing \\(7\\). So, it can either be \\(&lt;1&gt;\\) or \\(&lt;7&gt;\\).</p>"},{"location":"2_Core/Logic_in_CS/","title":"Logic in CS","text":"Class Instructor Lecture Dr. Siddhaling Urolagin Tutorial Dr. Siddhaling Urolagin <p>This course is about using various \u2018logic\u2019 techniques to perform proofs and deductions.</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/","title":"01 Propositional Logic","text":""},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#propositional-symbols","title":"Propositional Symbols","text":"Symbol Meaning \\(\\top\\) True \\(\\bot\\) False \\(\\land, \\lor\\) and, or (whichever comes first) \\(\\to\\) implies \\(\\vdash\\) Conclusion"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#natural-deduction","title":"Natural Deduction","text":"<p>\\(\\phi_1, \\phi_2, \\dots\\) are Premises</p> <p>\\(\\psi\\) is Conclusion</p> <p>\\(\\phi_1, \\phi_2, \\dots, \\phi_n \\vdash\\psi\\) is called sequent</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#rules","title":"Rules","text":"<ol> <li>\\(\\frac{\\phi \\quad \\psi}{\\phi \\land \\psi} \\quad (\\land i)\\)</li> <li>\\(\\frac{\\phi \\land \\psi}{\\phi}, \\frac{\\phi \\land \\psi}{\\psi} \\quad (\\land e_1, \\land e_2)\\)</li> <li>\\(\\frac{\\phi}{\\lnot \\lnot \\phi} \\quad(\\lnot \\lnot i)\\)</li> <li>\\(\\frac{\\lnot \\lnot \\phi}{\\phi} \\quad(\\lnot \\lnot e)\\)</li> <li>\\(\\frac{     \\begin{bmatrix} \\phi \\\\ \\vdots \\\\ \\psi    \\end{bmatrix}    }{\\phi \\to \\psi} \\quad (\\to i)\\)</li> <li>\\(\\frac{\\phi \\quad \\phi \\to \\psi}{\\psi} \\quad (\\to e)\\)</li> <li>\\(\\frac{\\lnot \\psi \\quad \\phi \\to \\psi}{\\lnot \\phi}\\) (MT)</li> <li>\\(\\frac{\\phi}{\\phi \\lor \\psi}, \\frac{\\psi}{\\phi \\lor \\psi} \\quad (\\lor i_1, \\lor i_2)\\)</li> <li>\\(\\frac{\\phi \\lor \\psi \\quad     \\begin{bmatrix}    \\phi \\\\ \\vdots \\\\ \\chi    \\end{bmatrix}    \\begin{bmatrix}    \\psi \\\\ \\vdots \\\\ \\chi    \\end{bmatrix}    }{\\chi} \\quad (\\lor e)\\)</li> <li>Copy rule</li> <li>\\(\\frac{\\begin{bmatrix}     \\phi \\\\ \\vdots \\\\ \\bot     \\end{bmatrix}     }{\\lnot \\phi} \\quad (\\lnot i)\\)</li> <li>\\(\\frac{\\begin{bmatrix}     \\lnot \\phi \\\\ \\vdots \\\\ \\bot     \\end{bmatrix}     }{\\phi}\\) PBC</li> <li>\\(\\frac{\\phi \\quad \\lnot \\phi}{\\bot} \\quad (\\lnot e)\\)</li> <li>\\(\\frac{\\bot}{\\phi} \\quad (\\bot e)\\)</li> <li>\\(\\frac{}{\\phi \\lor \\lnot \\phi}\\)(LEM)</li> </ol>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#equivalence-relation","title":"Equivalence Relation","text":"<p>If a formula can be proved in both directions, then it is called as an equivalence relation.</p> <p>Denoted by \\(\\dashv \\vdash\\)</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#wff","title":"WFF","text":"<p>Well-formed formula</p> <p>There's brackets for every operation</p> <p>\\((p \\land (\\lnot q)) \\to (p \\lor (q \\lor (\\lnot r) ))\\)</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#parse-tree","title":"Parse Tree","text":"<p>Shows the order at which the terms and operations are parsed</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#semantic-entailment","title":"Semantic entailment","text":"<p>\\(\\phi \\models \\psi\\)</p> <p>this means that whenever\\(\\phi\\) is true, \\(\\psi\\) is true</p> <p>ie \\(\\phi \\to \\psi\\) is true for all cases</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#soundness","title":"Soundness","text":"<p>if ND is true, then even semantic entailment is true</p> <p>\\(\\phi \\vdash \\psi \\implies \\phi \\models \\psi\\)</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#completeness","title":"Completeness","text":"<p>if semantic entailment is true, then even ND is true</p> <p>\\(\\phi \\models \\psi \\implies \\phi \\vdash \\psi\\)</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#semantic-equivalence","title":"Semantic equivalence","text":"<p>\\(\\phi \\equiv \\psi\\)</p> <p>\\(\\phi \\models \\psi\\) and \\(\\psi \\models \\phi\\)</p> <p>both have the same truth table</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#interpretation","title":"Interpretation","text":"<p>assigning values (putting inputs)</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#valuation","title":"Valuation","text":"<p>getting outputs</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#tautology","title":"Tautology","text":"<p>function whose output is always true</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#valid","title":"Valid","text":"<p>true for all interpretations</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#satisfiable","title":"Satisfiable","text":"<p>true for at least one interpretation</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#conclusions","title":"Conclusions","text":"<ul> <li>A is valid \\(\\iff \\lnot A\\) is un-satisfiable</li> <li>A is satisfiable \\(\\iff \\lnot A\\) is invalid</li> </ul>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#cnf","title":"CNF","text":"<p>basically POS</p> <ol> <li>literal - variable</li> <li>clause</li> <li>formula</li> </ol> <p>\\(\\underbrace{ ( \\underbrace{p}_\\text{literal} \\lor q) \\land \\underbrace{(r \\lor s)}_\\text{clause}  }_\\text{formula}\\)</p> <p>if \\(p\\) and \\(p\u2019\\) both exist within all clauses, all clauses are true then formula is valid</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#implies-conversion","title":"Implies Conversion","text":"<p>\\(p \\to q = \\lnot p \\lor q\\)</p>"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#horn-clauses","title":"Horn Clauses","text":"<p>useful for checking satisfiability</p> <p>only contains \\(\\land\\) and \\(\\to\\)</p> <p>every clause contains \\(\\to\\)</p> <p>cannot contain</p> <ul> <li>\\(\\lor\\)</li> <li>\\(\\lnot\\)</li> </ul> \\[ \\underbrace{ ( \\underbrace{p}_\\text{proposition} \\land q \\to s)  \\land  \\underbrace{( \\underbrace{ p \\land q \\land r }_\\text{assumption}\\to s)}_\\text{clause} }_\\text{formula} \\]"},{"location":"2_Core/Logic_in_CS/01_Propositional_Logic/#checking-satisfiability","title":"Checking Satisfiability","text":"<p>we just have to check if there exists atleast one combination of variables such that the entire formula is true.</p> <p>if nothing is possible, then it is false.</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/","title":"02 Predicate Logic","text":""},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#predicate-logic","title":"Predicate Logic","text":"<ul> <li>\\(\\exists\\) there exists (at least one)   similar to \\(\\lor\\)</li> <li>\\(\\forall\\) for all   similar to \\(\\land\\)</li> </ul>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#predicates","title":"Predicates","text":"<p>return true or false</p> <p>all caps</p> <p>eg:</p> <ul> <li>MAN(x): x is a man   // returns T/F</li> <li>ADULT(x): x is an adult   // returns T/F</li> </ul>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#functions","title":"Functions","text":"<p>returns object</p> <p>eg:</p> <ul> <li>mother(x)   // returns the mother of x (object)</li> <li>age(x)   // returns the age of x (integer)</li> </ul> <p>All predicates are functions, but not all functions are predicates</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#variables","title":"Variables","text":"<p>they can occur in 2 places</p> <ol> <li>along with \\(\\forall\\) and \\(\\exists\\)</li> <li>eg: \\(\\forall x, \\exists y\\)</li> <li>as leaf nodes (terminal vertices)</li> <li>\\(x, y\\)</li> </ol>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#bounded-variables","title":"Bounded variables","text":"<p>under \\(\\forall\\) or \\(\\exists\\) in parse tree</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#free-variables","title":"Free variables","text":"<p>are not under any restrictions they can be substituted/replaced by bounded/free variables</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#substitution","title":"Substitution","text":"<p>\\(\\phi[t/x]\\) means that \\(t\\) replaces free variable \\(x\\)</p> <p>\\(t\\) can be anything - bounded/free var for eg:</p> <ul> <li>\\(t = t\\)</li> <li>\\(t = f(x,y)\\)</li> <li>\\(t = g(x,y,z)\\)</li> </ul> <p>any of the above can replace free variable</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#nd","title":"ND","text":"<ol> <li>\\(= e\\)</li> <li>\\(a=b, b = c \\implies a = c\\)</li> <li> <p>Basically transitiveness</p> </li> <li> <p>\\(\\forall e\\)</p> </li> <li>\\(\\frac{\\forall x \\ \\phi}{ \\phi [x_0/x] }\\)</li> <li>if \\(\\phi\\) is true for all \\(x\\), then we can replace \\(x\\) by \\(x_0\\) in \\(\\phi\\), and conclude that \\(\\phi[x_0/x]\\) is also true</li> <li> <p>eg: if all students are teens, then a student Ahmed is also a teen</p> </li> <li> <p>\\(\\forall i\\)</p> </li> <li> <p>\\(\\frac{       \\begin{bmatrix}       x_0 \\\\ \\vdots \\\\ \\phi       \\end{bmatrix}       }{\\forall x}\\)</p> </li> <li>assumption box</li> <li> <p>if we prove that a student is a teen, then all students are teens (considering that all \\(x\\), ie students are identical)</p> </li> <li> <p>\\(\\exists i\\)</p> </li> <li> \\[       \\frac{       \\phi[t/x]       }{\\exists x \\quad \\phi} \\quad       \\exists x \\quad i       \\] </li> <li> <p>We can deduce \\(\\exists x \\quad \\phi\\) whenever we have \\(\\phi[t/x]\\); \\(t\\) has to be free for \\(x\\) in \\(\\phi\\)</p> </li> <li>\\(\\exists e\\)</li> <li> \\[       \\frac{       \\exists x \\ \\phi \\quad       \\begin{bmatrix}       x_0 \\quad \\phi[x_0/x] \\\\       \\vdots \\\\       \\chi       \\end{bmatrix}       }{\\chi} \\quad \\exists x \\quad e       \\] </li> <li> <p>if \\(\\exists x \\quad \\phi\\) is true, there should be atleast one value of \\(x\\) for which \\(\\phi\\) is true</p> </li> <li> <p>Let \\(x_0\\) represent those values</p> </li> <li> <p>Substituting \\(x_0\\) for \\(x\\), we arrive at formula \\(\\chi\\)</p> </li> <li> <p>we then conclude \\(\\chi\\)</p> </li> </ol>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#quantifier-equivalences","title":"Quantifier equivalences","text":"<ol> <li>De-Morgan\u2019s rule</li> </ol> <p>Convert bw \\(\\forall\\) and \\(\\exists\\) when there is negation      - \\(\\lnot \\forall x (\\phi) \\dashv \\vdash \\exists x (\\lnot \\phi)\\)      - \\(\\lnot \\exists x (\\phi) \\dashv \\vdash \\forall x (\\lnot \\phi)\\) 2. Distributive    1. \\(\\forall x (\\phi) \\land \\forall x(\\psi) \\dashv \\vdash \\forall x (\\phi \\land \\psi)\\)    2. \\(\\exists x (\\phi) \\lor \\exists x (\\psi) \\dashv \\vdash \\exists(\\phi \\lor \\psi)\\) 3. Commutative    1. \\(\\forall x \\forall y (\\phi) \\dashv \\vdash \\forall y \\forall x (\\phi)\\)    2. \\(\\exists x \\exists y (\\phi) \\dashv \\vdash \\exists y \\exists x (\\phi)\\)</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#idk","title":"IDK","text":"Symbol Term Meaning \\(P\\) predicate \\(l\\) lookup table gives us environment environment conditions \\(\\mathbb M\\) Model shows relations \\(\\models\\) Semantic Entailment \\(\\models_l\\) Models wrt lookup table \\(l\\) \\(\\Gamma\\) Set of formulae Arity no of vars/relations??"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#properties","title":"Properties","text":""},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#compactness","title":"Compactness","text":"<p>let \\(\\Gamma\\) is a set of formulae in predicate logic.</p> <p>If all finite subsets of \\(\\Gamma\\) are satisfiable, then \\(\\Gamma\\) is satisfiable</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#godels-completeness-theorem","title":"Godel\u2019s Completeness Theorem","text":""},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#underdesirablility","title":"Underdesirablility","text":"<p>If there are a large instances, it will be hard to determine the validity of a formula. This is called as undesirability.</p>"},{"location":"2_Core/Logic_in_CS/02_Predicate_Logic/#verification","title":"Verification","text":"<ol> <li>framework for modelling</li> <li>specification language - eg: Predicate logic</li> <li>verification language - eg: ND</li> </ol> Verification Type Proof-Based \\(\\Gamma \\vdash \\phi\\) Model Based \\(\\mathbb M \\models \\phi\\)"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/","title":"03 Temporal Logic","text":""},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#temporal-logic","title":"Temporal Logic","text":""},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#time","title":"Time","text":"Linear Time Branching Time sequential conditional infinite straight line infinite tree branches N Y"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#temporal-connectives","title":"Temporal Connectives","text":""},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#state-quantifiers","title":"State Quantifiers","text":"<p>For both LTL and CTL</p> Symbol Meaning \\(X\\) ne==X==t state \\(F\\) some ==F==uture state, including the current state XF some future state, from the next state onwards \\(G\\) all future states, including the current state (==G==lobally) XG all future states, from the next state onwards \\(U\\) ==U==ntil \\((&lt;)\\)\\(\\phi U \\psi\\) means that \\(\\phi\\) is true initially and then suddenly \\(\\psi\\) becomes true. anything after that doesn\u2019t matter \\(R\\) ==R==elease\\(\\phi R \\psi\\) means that both \\(\\phi\\) and \\(\\psi\\) occur once together. anything after that doesn\u2019t matter \\(W\\) ==W==eak-until \\((\\le)\\)(not really sure)"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#path-quantifiers","title":"Path Quantifiers","text":"<p>(only for CTL) | Symbol | Meaning                 | | -----: | ----------------------- | |      A | for ==A==ll paths       | |      E | there ==E==xists a path |</p>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#operator-precedence","title":"Operator Precedence","text":"<ol> <li>Unary operators</li> <li>Temporal binary operators</li> <li>Non-temporal binary operators</li> </ol>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#states","title":"States","text":"\\[ \\underbrace{s_0  \\underbrace{\\to}_\\text{transition} s_1}_\\text{path} \\] <p>State diagram </p> <p>\\(\\mathcal{P}\\) is the power set</p>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#paths-pi","title":"Paths (\\(\\pi\\))","text":"<p>\\(\\pi^i\\) is the path originating from state \\(s_i\\)</p>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#deadlock","title":"Deadlock","text":"<p>state having no further transitions</p>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#removing-deadlock","title":"Removing deadlock","text":"<p>add a another state \\(s_d\\) which has a self-loop</p>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#state-diagram","title":"State Diagram","text":"<pre><code>flowchart LR\n        s0 --&gt; s1 &amp; s2\n        s1 --&gt; s1</code></pre>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#unwinding","title":"Unwinding","text":"<p>Representing a state diagram using a binary tree is called as unwinding</p> <pre><code>flowchart TB\ns0 --&gt; s1 &amp; s2\ns1 --&gt; s[s1]</code></pre>"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#ctl-equivalences","title":"CTL Equivalences","text":"Paths States Universal Quantifier A G Existential Quantifier E F \\[ \\begin{aligned} \\lnot AF \\phi &amp;= EG \\lnot \\phi \\\\ \\lnot EF \\phi &amp;= AG \\lnot \\phi \\\\ \\lnot AX \\phi &amp;= EX \\lnot \\phi \\\\ AF \\phi &amp;= A[T \\cup \\phi] \\\\ EF \\phi &amp;= E[T \\cup \\phi] \\end{aligned} \\]"},{"location":"2_Core/Logic_in_CS/03_Temporal_Logic/#adequate-sets","title":"Adequate Sets","text":"\\[ \\begin{aligned} AX \\phi &amp;= \\lnot EX  \\lnot \\phi \\\\ AG &amp;=\\\\ \\end{aligned} \\] <p>there are more</p>"},{"location":"2_Core/Logic_in_CS/04_Program_Verification/","title":"04 Program Verification","text":""},{"location":"2_Core/Logic_in_CS/04_Program_Verification/#hoare-triple-notation","title":"Hoare Triple Notation","text":"<p>\\(\\set{\\phi} P \\set{\\psi}\\)</p> <p>eg: \\(\\set{x \\ge 0} \\text{ fact } \\set{f=x!}\\)</p>"},{"location":"2_Core/Logic_in_CS/04_Program_Verification/#correctness","title":"Correctness","text":"<p>Total Correctness \\(\\implies\\) Partial Correctness</p> Partial Total loop termination not neccessary necessary correctness \\(\\models_\\text{par} \\set{\\phi} P \\set{\\psi}\\) \\(\\models_\\text{tot} \\set{\\phi} P \\set{\\psi}\\) incorrectness \\(\\not \\models_\\text{par} \\set{\\phi} P \\set{\\psi}\\) \\(\\not \\models_\\text{tot} \\set{\\phi} P \\set{\\psi}\\) holds when \\(\\vdash_\\text{par} \\set{\\phi} P \\set{\\psi}\\) is valid \\(\\vdash_\\text{tot} \\set{\\phi} P \\set{\\psi}\\) is valid <p>eg:</p> \\[ \\begin{aligned} \\models_\\text{tot} \\set{x \\ge 0} &amp;\\text{ fact } \\set{f=x!} \\\\ \\not \\models_\\text{tot} \\set{\\top} &amp;\\text{ fact } \\set{f=x!} \\text{(as the loop will not terminate)} \\\\ \\models_\\text{par} \\set{x \\ge 0} &amp;\\text{ fact } \\set{f=x!} \\\\ \\models_\\text{par} \\set{\\top} &amp;\\text{ fact } \\set{f=x!} \\end{aligned} \\]"},{"location":"2_Core/Logic_in_CS/04_Program_Verification/#proof-tableaux","title":"Proof Tableaux","text":"\\[ \\begin{aligned} &amp; \\top \\\\ &amp; \\qquad \\phi_0 &amp; (implied)\\\\ &amp; C_1 \\\\ &amp; \\qquad \\phi_1 &amp; \\text{(assignment)}\\\\ &amp; C_2 \\\\ &amp; \\qquad \\phi_2 &amp; \\text{(assignment)}\\\\ &amp; \\vdots \\\\ &amp; C_{n-1} \\\\ &amp; \\qquad \\phi_{n-1} &amp; \\text{(assignment)}\\\\ &amp; C_n \\\\ &amp; \\qquad \\phi_n &amp; \\text{(assignment)}\\\\ \\end{aligned} \\] <p>justification could be</p> <ol> <li>assigned</li> <li>implied</li> </ol>"},{"location":"2_Core/Logic_in_CS/05_Modal_Logic/","title":"05 Modal Logic","text":""},{"location":"2_Core/Logic_in_CS/05_Modal_Logic/#modal-logic","title":"Modal Logic","text":"<p>it extends propositional and predicate logic</p>"},{"location":"2_Core/Logic_in_CS/05_Modal_Logic/#world","title":"World","text":"<p>is similar to state</p> <p>it\u2019s like a reality in Rick and Morty. We can assume every thing that can/cannot happpens as part of infinite realities.</p>"},{"location":"2_Core/Logic_in_CS/05_Modal_Logic/#symbols","title":"Symbols","text":"Symbol Meaning Interpretation CTL Equivalent \\(\\Box\\) Necessarily All worlds \\(AX\\) \\(\\Diamond\\) Possibly Some world \\(EX\\)"},{"location":"2_Core/Logic_in_CS/05_Modal_Logic/#scenarios","title":"Scenarios","text":"Type Representation Interpretation Possibility \\(\\Diamond \\phi = \\lnot \\Box (\\lnot \\phi)\\) possibly true; not necessarily false Necessity \\(\\Box \\phi = \\lnot \\Diamond (\\lnot \\phi)\\) necessarily true; not possibly false Uncertainity \\(\\lnot(\\Box \\phi) = \\Diamond (\\lnot \\phi)\\) not necessarily true; possibly false Impossibility \\(\\lnot (\\Diamond \\phi) = \\Box (\\lnot \\phi)\\) not possibly true; necessarily false"},{"location":"2_Core/Logic_in_CS/05_Modal_Logic/#notes","title":"Notes","text":"<ol> <li> <p>Necessity requires possibility, impossibility requires uncertainity</p> </li> <li> <p>Necessity \\(\\implies\\) possibility, impossibility \\(\\implies\\) uncertainity</p> </li> <li> <p>Necessity and impossibility are not symbolically contradictory    (look at the position of the \\(\\lnot\\) symbol)</p> </li> </ol> \\[ \\begin{aligned} &amp;\\Box(\\phi) \\\\    \\underbrace{}_\\text{not here} &amp;\\Box ( \\lnot \\phi) \\end{aligned} \\]"},{"location":"2_Core/Math_3/","title":"Math 3","text":"Class Instructor Lecture Dr. Baskaran Tutorial Dr. Baskaran <p>This course is about</p> <ul> <li>Differential Equations</li> <li>Laplace Transformations</li> <li>Fourier Series</li> </ul>"},{"location":"2_Core/Math_3/#note","title":"Note","text":"<p>In this course, I\u2019ve defined my notes in the following manner. This might not be mathematically perfect way to write, but it makes it easier to read and understand.</p> Meaning Key Constant \\(p, q, a, b, A, B\\) Variable \\(x, y\\) Function \\(P, Q\\) <p>I\u2019ve excluded function symbols to make it easier to read. For eg: \\(P(x) \\overset{\\text{written as}}{\\longrightarrow} P\\)</p>"},{"location":"2_Core/Math_3/01_Intro/","title":"01 Intro","text":""},{"location":"2_Core/Math_3/01_Intro/#de","title":"DE","text":"<p>Differential equation is an equation that relates one or more unknown functions and their derivatives.</p>"},{"location":"2_Core/Math_3/01_Intro/#order","title":"Order","text":"<p>The order of a differential equation is defined to be that of the highest order derivative it contains.</p>"},{"location":"2_Core/Math_3/01_Intro/#degree","title":"Degree","text":"<p>The degree of a differential equation is defined as the power to which the highest order derivative is raised.</p>"},{"location":"2_Core/Math_3/01_Intro/#1st-order-de","title":"1<sup>st</sup> Order DE","text":"\\[ \\frac{dy}{dx} = f(x, y) \\] <p>Aim is to find the value of \\(y\\) in terms in \\(x\\). We do this by integrating (anti-derivative).</p>"},{"location":"2_Core/Math_3/01_Intro/#separable-variables","title":"Separable Variables","text":"<p>We can directly solve this by separating the variables</p> \\[ \\begin{aligned} f(x, y) &amp;= g(x) \\cdot h(y) \\\\ \\frac{dy}{dx} &amp;= g(x) \\cdot h(y) \\\\ \\int \\frac{dy}{h(y)}  &amp;= \\int g(x) dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/01_Intro/#homogeneous-equation","title":"Homogeneous Equation","text":"<p>Special type of Homogeneous Expression</p> \\[ M dx + N dy = 0 \\] <p>If both \\(M(x, y)\\) and \\(N(x,y)\\) are homogeneous of the same degree.</p> \\[ \\begin{aligned} \\frac{dy}{dx} &amp;= \\frac{- M(x, y)}{N(x, y)} \\\\ \\text{Let }  v &amp;= \\frac{y}{x} \\implies y = vx \\\\ \\frac{dy}{dx} &amp;= v + x \\frac{dv}{dx} \\end{aligned} \\]"},{"location":"2_Core/Math_3/01_Intro/#homogeneous-expression","title":"Homogeneous Expression","text":"\\[ \\begin{aligned} f(tx, ty) = t^n \\cdot f(x, y) \\end{aligned} \\] Example Degree \\(\\sin(\\frac{x}{y})\\) 0 \\(\\sqrt{x^2 + y^2}\\) 1 \\(x^2 + y^2\\) 2"},{"location":"2_Core/Math_3/01_Intro/#integration-rules","title":"Integration Rules","text":"<p>Grade 12 Integration Rules</p>"},{"location":"2_Core/Math_3/01_Intro/#transposed-differential","title":"Transposed Differential","text":"<p>Be able to identify transposition to simplify</p> \\[ \\begin{aligned} d(\\log x) &amp;= \\left( \\frac{1}{x} \\right) dx \\\\ \\text{because  } \\frac{d(\\log x)}{dx} &amp;= \\frac{1}{x} \\\\ \\end{aligned} \\]"},{"location":"2_Core/Math_3/02_Exact_DE/","title":"02 Exact DE","text":""},{"location":"2_Core/Math_3/02_Exact_DE/#family-of-curves","title":"Family of Curves","text":"\\[ \\begin{aligned} f(x, y) &amp;= c \\\\ d( \\ f(x, y) \\ ) &amp;= d(c) \\\\ f_x dx + f_y dy &amp;= 0 \\end{aligned} \\] <p>This last step</p> <ul> <li>looks like Homogeneous Equation</li> <li>is the exact differential equation of the given curve</li> </ul> <p>The solution is the given equation, and from that we derived the exact differential equation.</p>"},{"location":"2_Core/Math_3/02_Exact_DE/#solution-of-a-de","title":"Solution of a DE","text":"<p>Consider a first-order differential equation of the form</p> \\[ M dx + N dy = 0 \\] <p>if there happens to be a function \\(f(x, y)\\) such that</p> \\[ \\begin{aligned} f_x = M(x, y), \\quad f_y &amp;= N(x, y) \\\\ \\frac{\\partial f}{\\partial x} dx + \\frac{\\partial f}{\\partial y} dy &amp;= 0 \\\\ d( f(x, y) ) &amp;= 0 \\\\ f(x, y) &amp;= c \\end{aligned} \\] <p>The final step is the general solution of the given differential equation.</p>"},{"location":"2_Core/Math_3/02_Exact_DE/#exact-de","title":"Exact DE","text":"<p>is a differential equation where \\(M_y = N_x\\)</p>"},{"location":"2_Core/Math_3/02_Exact_DE/#shortcut-method-for-exact-de","title":"Shortcut Method for Exact DE","text":"<p>This is only for exact DE</p> <p>Consider this DE</p> \\[ (\\ y + y \\cos(xy)  \\ )dx + (\\ x + x \\cos(xy) \\ ) = 0 \\] <ol> <li> <p>Check if the given DE is exact</p> </li> <li> <p>Put integration sign for both sides</p> </li> </ol> \\[ \\int (\\ y + y \\cos(xy)  \\ )  dx + \\int(\\ x + x \\cos(xy) \\ )  dx = \\int 0 \\] <ol> <li>Simplifications</li> <li>Treat \\(y\\) as a constant in the \\(dx\\) integral</li> <li>Drop all terms containing \\(x\\) in the \\(dy\\) integral       think like this: drop your ex       example<ul> <li>\\(y \\cos(x) \\to 0\\)</li> <li>\\(x \\cos(x) \\to 0\\)</li> <li>\\(y + y \\cos(x) \\to y\\)</li> </ul> </li> </ol> \\[ \\int (\\  y + y \\cos(xy) \\ ) dx + \\int (0 + 0) dy = c \\] <ol> <li>Integrate</li> </ol> \\[ \\begin{aligned} yx + y \\left( \\frac{ \\sin xy }{ y } \\right) &amp;= c \\\\ yx + \\sin(xy) &amp;= c \\end{aligned} \\]"},{"location":"2_Core/Math_3/02_Exact_DE/#exact-de-formulae","title":"Exact DE Formulae","text":"\\[ \\begin{aligned} d(xy) &amp;= xdy + y dx \\\\ d(x^2 + y^2) &amp;= 2x dx + 2y dy \\\\ d \\left(\\frac{x^2 + y^2}{2} \\right) &amp;= x dx + y dy \\end{aligned} \\] \\[ \\begin{aligned} d\\left(\\frac{x}{y}\\right) &amp;= \\frac{ydx - xdy}{y^2} \\quad \\left(\\frac{u}{v} \\right)' \\text{ formula}\\\\ &amp;= \\frac{1}{y}dx - \\frac{x}{y^2} dy \\\\ d\\left(\\frac{y}{x}\\right) &amp;= \\frac{xdy - ydx}{x^2} \\\\ &amp;= \\frac{1}{x}dy - \\frac{y}{x^2} dx \\end{aligned} \\] \\[ \\begin{aligned} d\\left(\\log{ |\\frac{x}{y}| }\\right) &amp;= \\frac{1}{\\frac{x}{y}} \\left( \\frac{y dx - x dy}{y^2} \\right) \\\\ &amp;= \\frac{y dx - x dy}{xy} \\\\ \\end{aligned} \\] \\[ \\begin{aligned} d\\left( \\log \\vert  \\frac{y}{x}  \\vert \\right) &amp;= \\frac{x dy - y dx}{xy} \\end{aligned} \\] \\[ \\begin{aligned} d \\left( \\tan^{-1} \\frac{x}{y} \\right) &amp;= \\frac{1}{1 + \\frac{x^2}{y^2} } \\left( \\frac{y dx - x dy}{y^2} \\right) \\\\ &amp;= \\frac{y dx - x dy}{x^2 + y^2} \\\\ d \\left( \\tan^{-1} \\frac{y}{x} \\right) &amp;= \\frac{x dy - ydx}{x^2 + y^2} \\end{aligned} \\]"},{"location":"2_Core/Math_3/02_Exact_DE/#idk","title":"IDK","text":"<p>You cannot integrate \\(\\int f(x,y) \\ dx\\) wrt to \\(dx\\) alone</p> <p>it is only possible for something sir said and double integration (there \\(dy\\) will also be there in outer integral)</p>"},{"location":"2_Core/Math_3/03_Inexact_DE/","title":"03 Inexact DE","text":"<p>Consider a 1<sup>st</sup> order inexact DE</p> \\[ M(x, y) dx + N(x, y) dy = 0, \\quad (M_y \\ne N_x) \\]"},{"location":"2_Core/Math_3/03_Inexact_DE/#steps","title":"Steps","text":"<ol> <li>Find \\(M_y - N_x\\)</li> <li>You will get one of the following cases    the simplification will give in terms of a single variable</li> </ol> Case 1 Case 2 \\(\\dfrac{M_y - N_x}{\\color{orange}-M} = h(y)\\) \\(\\dfrac{M_y - N_x}{\\color{orange}N} = g(x)\\) IF \\(e^{\\int h(y) \\cdot dy}\\) \\(e^{\\int g(x) \\cdot dx}\\) <ol> <li>Multiply both sides of equation:    Inexact DE \\(\\times\\) IF \\(\\to\\) Exact DE</li> <li>Then, use Exact DE method</li> </ol>"},{"location":"2_Core/Math_3/03_Inexact_DE/#shortcut","title":"Shortcut","text":"<ul> <li>Try to get everything in terms of simple integrals like \\(dx, dy, d(xy),d(x+y)\\).</li> <li>Then use exact DE formulae</li> </ul> <p>This way we can avoid the IF step</p>"},{"location":"2_Core/Math_3/04_Linear_DE/","title":"04 Linear DE","text":""},{"location":"2_Core/Math_3/04_Linear_DE/#linear-de-general-form","title":"Linear DE General Form","text":"\\[ y' + P y = Q \\] <p>where \\(y\\) is the dependent variable</p>"},{"location":"2_Core/Math_3/04_Linear_DE/#solution","title":"Solution","text":"<ol> <li> <p>Find IF \\(= e^{\\int P(x) dx}\\)</p> </li> <li> <p>Find general solution</p> </li> </ol> \\[ y \\times IF = \\int \\Big( Q \\times IF \\Big) dx \\quad + c \\]"},{"location":"2_Core/Math_3/04_Linear_DE/#bernoullis-de","title":"Bernoulli\u2019s DE","text":"\\[ y' + P y = Q y^n \\]"},{"location":"2_Core/Math_3/04_Linear_DE/#solution_1","title":"Solution","text":"<ol> <li>Divide both sides by \\(y^n\\)</li> </ol> \\[ y^{-n} y' + P y^{1-n} = Q \\] <ol> <li>Take \\(z = y^{1-n}\\)</li> </ol> \\[ \\begin{aligned} z' &amp;= (1-n) y^{(1-n)-1} y' \\\\ y^{-n} y' &amp;= \\left( \\frac{1}{1-n} \\right) z' \\end{aligned} \\] <ol> <li>Convert into a Linear DE</li> </ol> \\[ \\begin{aligned} \\left( \\frac{1}{1-n} \\right) z' + P z &amp;= Q \\\\ z' + \\underbrace{(1-n) P}_{P\\text{ of linear DE}} \\ z &amp;= (1-n) Q \\end{aligned} \\] <ol> <li>Solving using Linear DE method in terms of \\(z\\)</li> </ol> \\[ \\begin{aligned} \\text{IF} &amp;= (1-n) \\int P dx \\\\    z \\times \\text{IF} &amp;= (1-n) \\int (Q \\times \\text{IF}) dx \\quad + c \\end{aligned} \\] <ol> <li>Put \\(z = y^{1-n}\\) back into this</li> </ol>"},{"location":"2_Core/Math_3/05_Reduction_of_Order/","title":"05 Reduction of Order","text":""},{"location":"2_Core/Math_3/05_Reduction_of_Order/#general-form-of-2nd-order-de","title":"General Form of 2<sup>nd</sup> order DE","text":"\\[ F(x, y, y', y'') = 0 \\] <p>This is for variable coefficients.</p>"},{"location":"2_Core/Math_3/05_Reduction_of_Order/#solving","title":"Solving","text":"<ul> <li>2<sup>nd</sup> order DE is reduced into two 1<sup>st</sup> order DE</li> <li>they are solved one after each other</li> </ul> <p>Reduction of order method is possible under 2 cases</p> Case 1 Case 2 missing terms Dependent variable \\(y\\) Independent variable \\(x\\) Form \\(F(x, y', y'') = 0\\) \\(F(y, y', y'') = 0\\) Let \\(y' = P \\implies y'' = P'\\) $y' = P \\ \\implies y'' = P' = \\frac{dP}{dy} y' \\ y''= P \\left(\\frac{dP}{dy}\\right)$ Solve \\(F(x, P, P') = 0\\) \\(F(y, P, P \\frac{dP}{dy}) = 0\\) Substitute \\(y' = P \\implies y'' = P'\\) \\(y' = P \\implies y'' = P'\\) Solve \\(F(x, y)\\) \\(F(x, y)\\)"},{"location":"2_Core/Math_3/06_2nd_Order_DE/","title":"06 2nd Order DE","text":""},{"location":"2_Core/Math_3/06_2nd_Order_DE/#types","title":"Types","text":""},{"location":"2_Core/Math_3/06_2nd_Order_DE/#complete-equation","title":"Complete Equation","text":"\\[ y'' + P(x) y' + Q(x) y = R(x) \\] <p>Also called non-homogeneous DE Particular Solution of complete equation: \\(y_p(x)\\) If \\(y(x)\\) is the solution, then it is given by</p> \\[ y(x) = y_g + y_p \\]"},{"location":"2_Core/Math_3/06_2nd_Order_DE/#reduced-equation","title":"Reduced Equation","text":"<p>Complete equation with \\(R(x) = 0\\)</p> \\[ y'' + P(x) y' + Q(x) y = 0 \\] <p>Also called as homogeneous DE</p> \\[ y(x) = y_g \\quad (y_p(x) = 0) \\]"},{"location":"2_Core/Math_3/06_2nd_Order_DE/#theorems","title":"Theorems","text":""},{"location":"2_Core/Math_3/06_2nd_Order_DE/#1","title":"1","text":"<p>If \\(y_1(x)\\) and \\(y_2(x)\\) are 2 solutions of reduced DE, then \\(\\set{c_1 y_1(x) + c_2 y_2(x)}\\) is another solution of the reduced DE for any constants \\(c_1, c_2\\)</p>"},{"location":"2_Core/Math_3/06_2nd_Order_DE/#2","title":"2","text":"<p>If \\(y_1(x)\\) and \\(y_2(x)\\) are 2 solutions of reduced DE, then they are linearly-dependent \\(\\iff\\) their wronskian = 0</p> \\[ W(y_1, y_2) =  \\begin{vmatrix} y_1 &amp; y_2 \\\\ {y_1}' &amp; {y_2}' \\end{vmatrix} = 0 \\] <p>Else, they are linearly-independent</p> <p>eg:</p> <ul> <li>\\(y_1 = x^2, y_2 = \\frac{3}{2} x^2\\) - linear dependent</li> <li>\\(y_1 = x, y_2 = x^2\\) - linearly independent</li> </ul>"},{"location":"2_Core/Math_3/06_2nd_Order_DE/#3","title":"3","text":"<p>If \\(y_1(x)\\) and \\(y_2(x)\\) are 2 linearly-independent solutions of reduced DE, then \\(y(x) = c_1 y_1(x) + c_2 y_2(x)\\) is called general solution</p>"},{"location":"2_Core/Math_3/06_2nd_Order_DE/#solving","title":"Solving","text":"<ol> <li>Sub \\(y = y_1(x)\\) and \\(y = y_2(x)\\) in the given equation</li> <li>Show that LHS = RHS</li> </ol>"},{"location":"2_Core/Math_3/06_2nd_Order_DE/#principle-of-superposition","title":"Principle of Superposition","text":"<p>If the given DE is of the form</p> \\[ y'' +  py' + qy = f(x) + g(x) \\] <p>Solution is given by</p> \\[ \\begin{aligned} y'' +  py' + qy &amp;= 0 &amp;\\to y_g \\\\ y'' +  py' + qy &amp;= f(x) &amp;\\to y_{p_1} \\\\ y'' +  py' + qy &amp;= g(x) &amp;\\to y_{p_2} \\\\ \\implies y &amp;= y_g + y_{p_1} + y_{p_2} \\end{aligned} \\] <p>This superposition of the solutions is called as principle of superposition.</p>"},{"location":"2_Core/Math_3/07_Known_Soln/","title":"07 Known Soln","text":"<p>Consider a homogeneous 2<sup>nd</sup> order DE.</p> \\[ y'' + P y' + Q y = 0 \\] <p>Let \\(y_1(x)\\) be the known solution of it.</p> <p>To find another linear-independent solution \\(y_2(x)\\)</p> <ol> <li>Let</li> </ol> \\[ \\begin{aligned} v &amp;= \\int \\frac{1}{ {(y_1)}^2 \\times e^{ \\int P dx} } \\\\ y_2 &amp;= v \\cdot y_1 \\end{aligned} \\] <ol> <li>Now, the general solution \\(y(x) = c_1 y_1(x) + c_2 y_2(x)\\)</li> </ol>"},{"location":"2_Core/Math_3/07_Known_Soln/#special-cases","title":"Special Cases","text":"<p>(not important)</p>"},{"location":"2_Core/Math_3/07_Known_Soln/#legendre-de","title":"Legendre DE","text":"\\[ (1-x^2)y'' - 2xy' + k(k+1) y = 0 \\] <p>where \\(k\\) = const</p>"},{"location":"2_Core/Math_3/07_Known_Soln/#bessels-equation","title":"Bessel\u2019s Equation","text":"\\[ x^2 y'' + xy' + (x^2 - k^2) y = 0 \\] <p>\\(k\\) = const</p>"},{"location":"2_Core/Math_3/08_Constant_Coefficient/","title":"08 Constant Coefficient","text":""},{"location":"2_Core/Math_3/08_Constant_Coefficient/#2nd-order-homogeneous-de-with-constant-coefficients","title":"2<sup>nd</sup> Order Homogeneous DE with constant coefficients","text":"\\[ y'' + py' + qy = 0 \\] <p>where \\(p, q\\) are constants</p> <p>Consider \\(y = e^{mx}\\) as a possible solution, where \\(m\\) = unknown constant. So our goal is to find \\(m\\).</p> <p>Then</p> \\[ y' = m \\cdot e^{mx} \\\\ y' = m^2 \\cdot e^{mx} \\\\ \\implies (m^2 \\cdot e^{mx}) + p(m \\cdot e^{mx}) + qe^{mx} = 0 \\\\ e^{mx} ( m^2 + pm + q ) = 0 \\\\ \\]"},{"location":"2_Core/Math_3/08_Constant_Coefficient/#auxiliary-equation","title":"Auxiliary equation","text":"\\[ e^{mx} \\ne 0 \\\\ \\implies ( m^2 + pm + q ) = 0 \\] <p>Solve this to get the value(s) of unknown \\(m\\)</p> Roots General Solution \\(y\\) real and distinct \\(m_1, m_2\\) \\(c_1 e^{m_1 x} + c_2 e^{m_2 x}\\) equal roots \\(m_1 = m_2 = m\\) \\(e^{mx} (c_1 + c_2 x )\\) Complex roots \\(m_1, m_2 = a \\pm ib\\) \\(e^{ax} (c_1\\cos bx + c_2 \\sin bx )\\)"},{"location":"2_Core/Math_3/08_Constant_Coefficient/#boundary-value-problems","title":"Boundary Value Problems","text":"<p>Using given \u2018initial conditions\u2019, we need to find the values of \\(c_1\\) and \\(c_2\\)</p>"},{"location":"2_Core/Math_3/09_Euler/","title":"09 Euler","text":""},{"location":"2_Core/Math_3/09_Euler/#eulers-equidimensional-de","title":"Euler\u2019s Equidimensional DE","text":"\\[ x^2 y'' + px y' + qy = 0 \\]"},{"location":"2_Core/Math_3/09_Euler/#transformation","title":"Transformation","text":"<ol> <li> <p>Let \\(x = e^z \\quad (z = \\log x)\\)</p> </li> <li> <p>Now, \\(y\\) is a function of \\(z\\), which in turn is a function of \\(x\\)</p> </li> <li> <p>Put the following substitutions; Refer to Custom Operators</p> </li> </ol> \\[ \\begin{aligned} xD &amp;= \\theta \\\\    x^2 D^2 &amp;= \\theta(\\theta - 1) \\end{aligned} \\] <ol> <li>equation becomes</li> </ol> \\[ \\begin{aligned} \\Big( \\theta(\\theta - 1) + p \\theta + q \\Big)y &amp;= 0 \\\\    \\theta(\\theta - 1) + p \\theta + q &amp;= 0 &amp; (y \\ne 0) \\end{aligned} \\] <ol> <li> <p>Put \\(\\theta^2 \\to m^2, \\theta \\to m\\)</p> </li> <li> <p>Find gen solution in terms of \\(z : y(z)\\), using Constant Coefficient</p> <ul> <li>\\(y = c_1 e^{m_1 z} + c_2 e^{m_2 z}\\)</li> <li>\\(y = e^{mz}(c_1 + c_2 z)\\)</li> <li>\\(y = e^{az}(c_1 \\cos bz+ c_2 \\sin bz)\\)</li> </ul> </li> <li> <p>Find gen solution in terms of \\(x\\), by subbing \\(z = \\log x\\)</p> </li> </ol>"},{"location":"2_Core/Math_3/09_Euler/#custom-operators","title":"Custom Operators","text":"\\[ \\begin{aligned} D &amp;= \\frac{d}{dx}  &amp; D^2 &amp;= \\frac{d^2}{dx^2} \\\\ \\theta &amp;= \\frac{d}{dz}  &amp; \\theta^2 &amp;= \\frac{d^2}{dz^2} \\end{aligned} \\]"},{"location":"2_Core/Math_3/09_Euler/#formula","title":"Formula","text":"\\[ x Dy = \\theta y \\implies xD = \\theta \\]"},{"location":"2_Core/Math_3/10_Higher_Order_Constant_Coefficient/","title":"10 Higher Order Constant Coefficient","text":""},{"location":"2_Core/Math_3/10_Higher_Order_Constant_Coefficient/#higher-order-constant-coefficient","title":"Higher Order Constant Coefficient","text":"\\[ y^{(n)} + \\dots + py' + qy = 0 \\] <p>Solve using the same method as Constant Coefficient</p> \\[ m^n + \\dots + pm + q = 0 \\] <p>For 3 equal roots,</p> \\[ y(x) = e^{mx}(c_1 + c_2 x + c_3 x^2) \\]"},{"location":"2_Core/Math_3/11_Undetermined_Coefficients/","title":"11 Undetermined Coefficients","text":"<p>The undetermined coefficient method is possible for a few standards functions such as \\(R(x) = e^{ax}, \\sin(ax), \\cos(ax),\\) polynomials. This method also requires a trial solution to compute the required particular solution.</p> <p>Note If RHS \\(= \\sin(2x) + \\cos(2x)\\), then we can consider it as a single function \\(R(x)\\)</p> <p>Consider</p> <ul> <li>Constants \\(l, k, a, b \\in R\\)</li> <li>Undetermined Coefficients \\(A, B, A_0, A_1, \\dots, A_n\\) (unknown constant)</li> </ul> <p>The exception cases are for preventing duplication of terms, and hence prevent linear dependency of the solutions.</p> \\(R(x)\\) Trial Particular Solution Exception based on root \\(m\\) of auxilary eqn \\(l e^{ax}\\) \\(A e^{ax}\\) \\(A x e^{ax}\\) \\(m_1 = a\\) or \\(m_2 = a\\) \\(A x^2 e^{ax}\\) \\(m_1 = m_2 = a\\) \\(l \\cos(ax)\\)\\(l \\sin(ax)\\)\\(l \\cos(ax) \\pm k \\sin(ax)\\) \\(A \\cos ax + B \\sin ax\\) \\(x (A \\cos ax + B \\sin ax)\\) \\(m= 0 \\pm ai\\) \\(a_0 + a_1 x + \\dots + a_n x^n\\)(\\(n^{\\text{th}}\\) degree polynomial) \\((A_0 + A_1 x + \\dots + A_n x^n)\\) \\(x(A_0 + A_1 x + \\dots + A_n x^n)\\) \\(m = 0\\) \\(e^{ax} \\cos bx\\)\\(e^{ax} \\sin bx\\)\\(e^{ax} ( \\cos bx + \\sin bx )\\) \\(e^{ax} ( A \\cos bx + B \\sin bx )\\) \\(xe^{ax} ( A \\cos bx + B \\sin bx )\\) \\(m = a \\pm bi\\)"},{"location":"2_Core/Math_3/11_Undetermined_Coefficients/#trick-for-product-of-3-functions","title":"Trick for product of 3 functions","text":"<p>If \\(y_g\\) and the trial particular solution are similar</p> <ul> <li>instead of using \\((uvw)' = uvw' + uv'w + u'vw\\)</li> <li>we can take</li> </ul> \\[ x e^x ( A \\cos x + B \\sin x) \\to x \\phi \\]"},{"location":"2_Core/Math_3/11_Undetermined_Coefficients/#example","title":"Example","text":"\\[ \\begin{aligned} y'' - 2y' + 2y &amp;= e^x \\sin x \\\\ x e^x ( A \\cos x + B \\sin x) &amp; \\to x \\phi \\\\ {y_g}'' - 2{y_g}' + 2{y_g} &amp;= 0 \\\\ \\implies \\phi'' - 2\\phi' + 2\\phi &amp;= 0 \\end{aligned} \\]"},{"location":"2_Core/Math_3/12_Variation_of_Parameter/","title":"12 Variation of Parameter","text":""},{"location":"2_Core/Math_3/12_Variation_of_Parameter/#variation-of-parameter","title":"Variation of Parameter","text":"<p>for finding particular solution \\(y_p\\)</p> <p>more suitable if the RHS function is a \\(\\log, \\tan, \\cot, \\sec, \\csc,\\) hyperbolic</p> <ol> <li>Find general solution</li> </ol> \\[ y_g = c_1 \\textcolor{orange}{y_1} + c_2 \\textcolor{orange}{y_2} \\] <ol> <li>Let</li> </ol> \\[ \\begin{aligned} y_p &amp;= v_1 y_1(x) + v_2 y_2(x), \\text{where} \\\\ v_1 &amp;= \\int \\frac{ \\textcolor{orange}{-y_2} \\cdot R(x) }{ W(y_1, y_2) } dx \\\\ v_2 &amp;= \\int \\frac{ \\textcolor{orange}{y_1} \\cdot R(x) }{ W(y_1, y_2) } dx \\end{aligned} \\] <p>where \\(W(y_1, y_2)\\) be the Wronskian, then</p> <ol> <li>Complete solution \\(y = y_g + y_p\\)</li> </ol>"},{"location":"2_Core/Math_3/13_Operator_Method/","title":"13 Operator Method","text":"<p>Operator Method is a more general method, so it is good.</p> <p>Consider a 2<sup>nd</sup> order DE</p> \\[ \\begin{aligned} y'' + py' + qy &amp;= R(x) \\\\ (D^2 + pD + q)y &amp;= R(x) \\end{aligned} \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#definition","title":"Definition","text":"\\[ y_p = \\frac{1}{\\phi(D)} R(x) \\] \\[ \\begin{aligned} \\phi(D) y &amp;= R(x) \\\\ \\phi(D) &amp;= D^2 + pD + q \\\\ &amp;=(D-m_1)(D-m_2) \\end{aligned} \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#integrals","title":"Integrals","text":"\\[ \\begin{aligned} \\frac{1}{D} R(x) &amp;= \\int R(x) dx \\\\ \\frac{1}{D^2} R(x) &amp;= \\iint R(x) dx \\cdot dx \\end{aligned} \\] \\[ \\begin{aligned} \\frac{1}{D-m} R(x) &amp;= \\textcolor{orange}{e^{mx}} \\int R(x) \\cdot \\textcolor{hotpink}{e^{-mx}} \\cdot dx \\\\ \\frac{1}{D+m} R(x) &amp;= \\textcolor{hotpink}{e^{-mx}} \\int R(x) \\cdot \\textcolor{orange}{e^{mx}} \\cdot dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#short-rules-for-standard-functions","title":"Short Rules for standard functions","text":"R(x) \\(y_p\\) Exception \\(e^{\\textcolor{orange}{a}x}\\) \\(e^{\\textcolor{orange}{a}x}\\dfrac{1}{\\phi(\\textcolor{orange}{a})}\\) \\(x e^{\\textcolor{orange}{a}x} \\frac{1}{\\phi'(\\textcolor{orange}{a})}\\) \\(\\phi(a) = 0\\) \\(x^2 e^{\\textcolor{orange}{a}x} \\frac{1}{\\phi''(\\textcolor{orange}{a})}\\) \\(\\phi'(a) = 0\\) \\(\\sin(\\textcolor{orange}{a}x+b), \\cos(\\textcolor{orange}{a}x+b)\\) \\(R(x) \\frac{1}{f(-\\textcolor{orange}{a}^2)}\\) \\(x R(x) \\frac{1}{f'(-\\textcolor{orange}{a}^2)}\\) \\(f(-a^2) = 0\\) \\(x^2 R(x) \\frac{1}{f''(-\\textcolor{orange}{a}^2)}\\) \\(f'(-a^2) = 0\\) \\(x^m\\) \\(\\underbrace{\\Big(\\phi(D) \\Big)^{-1} }_\\text{Binomial Series} x^m\\) \\(e^{\\textcolor{orange}{k}x} h(x)\\)(Exponent Shifting Rule) \\(e^{\\textcolor{orange}{k}x} \\left\\{ \\frac{1}{\\phi(D+\\textcolor{orange}{k})} h(x) \\right\\}\\)Solve using any of the above methods"},{"location":"2_Core/Math_3/13_Operator_Method/#derivatives","title":"Derivatives","text":"\\[ \\begin{aligned} \\phi'(a) &amp;= \\left\\{ \\frac{d \\phi(D)}{dD} \\right\\}_{D \\to a} \\\\ \\phi''(a) &amp;= \\left\\{ \\frac{d^2 \\phi(D)}{d D^2} \\right\\}_{D \\to a} \\\\ f(-a^2) &amp;= \\left\\{ \\frac{d f(D^2)}{dD} \\right\\}_{D^2 \\to -a^2} \\\\ f'(-a^2) &amp;= \\left\\{ \\frac{d^2 f(D^2)}{d D^2} \\right\\}_{D^2 \\to -a^2} \\\\ \\end{aligned} \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#binomial-expansions","title":"Binomial Expansions","text":"\\[ \\begin{aligned} (1+x)^{-1} &amp;= 1 - x + x^2 - x^3 + \\dots \\\\ (1-x)^{-1} &amp;= 1 + x + x^2 + x^3 + \\dots \\end{aligned} \\] \\[ \\begin{aligned} (1+x)^{-2} &amp;= 1 - 2x + 3x^2 - 4x^3 + \\dots \\\\ (1-x)^{-2} &amp;= 1 + 2x + 3x^2 + 4x^3 + \\dots \\end{aligned} \\] \\[ \\begin{aligned} (1+x)^{-n} &amp;= 1 - nx + \\frac{n(n+1) x^2}{2!} -  \\frac{n(n+1)(n+2) x^3}{3!} + \\cdots\\\\ (1-x)^{-n} &amp;= 1 + nx + \\frac{n(n+1) x^2}{2!} + \\frac{n(n+1)(n+2) x^3}{3!} + \\cdots \\end{aligned} \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#cube-formula","title":"Cube Formula","text":"\\[ (a+b)^3 = a^3+b^3+3ab(a+b) \\\\ (a-b)^3 = a^3-b^3-3ab(a-b) \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#long-method","title":"Long Method","text":""},{"location":"2_Core/Math_3/13_Operator_Method/#idk","title":"idk","text":"\\[ \\begin{aligned} y_p &amp;= \\frac{1}{\\phi(D)} R(x) \\\\ &amp;= \\underbrace{     \\left( \\frac{1}{D-m_1} \\right)     \\underbrace{         \\frac{1}{D-m_2} R(x)     }_{R_1(x)} }_{R_2(x)}\\\\ &amp;= \\frac{1}{D-m} R(x) \\end{aligned} \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#if","title":"IF","text":"\\[ \\begin{aligned} Dy - my &amp;= R(x) \\\\ \\frac{dy}{dx} - my &amp;= R(x) \\\\ IF &amp;= e^{\\int P(x) dx} \\\\ &amp;= e^{\\int -m dx} \\\\ &amp;= e^{-mx} \\end{aligned} \\]"},{"location":"2_Core/Math_3/13_Operator_Method/#solution","title":"Solution","text":"\\[ \\begin{aligned} y \\times IF &amp;= \\int R(x) \\cdot IF \\cdot dx \\\\ y e^{-mx} &amp;= \\int R(x) \\cdot e^{-mx} \\cdot dx \\\\ y &amp;= e^{mx} \\int R(x) \\cdot e^{-mx} \\cdot dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/14_Laplace/","title":"14 Laplace","text":""},{"location":"2_Core/Math_3/14_Laplace/#laplace-transformation","title":"Laplace Transformation","text":"<p>Converting differential calculus into algebra</p> <pre><code>flowchart LR\nDE --&gt;\n|LT| ae[Algebraic] --&gt;\n|Solving| sa[Algebraic Solution] --&gt;\n|ILT| sd[DE Solution] -.-&gt;\nDE</code></pre>"},{"location":"2_Core/Math_3/14_Laplace/#lt-function","title":"LT Function","text":"<p>Laplace Transform</p> \\[ \\begin{aligned} L\\{ f(t) \\} &amp;= \\int\\limits_0^\\infty e^{-st} f(t) \\cdot dt  \\quad \\text{ (or a function of } x)\\\\ &amp;= F(s) \\end{aligned} \\] \\(f(t)\\) Time Domain Function \\(s\\) Laplace Variable (real/complex) \\(F(s)\\) Laplace Domain Function"},{"location":"2_Core/Math_3/14_Laplace/#ilt-function","title":"ILT Function","text":"<p>Inverse Laplace Transform</p> \\[ L^{-1} \\{ F(s) \\} = f(t) \\]"},{"location":"2_Core/Math_3/14_Laplace/#basic-rules","title":"Basic Rules","text":"Situation LT ILT Constant Coeffient \\(L\\Big(k f(t) \\Big) = k L(t)\\) \\(L^{-1}(k s) = k L^{-1} \\Big( F(s) \\Big)\\) Sum \\(L \\Big( f(t) \\pm g(t) \\Big) = L \\Big( f(t) \\Big) \\pm L \\Big( g(t) \\Big)\\) \\(L^{-1} \\Big( F(s) \\pm G(s) \\Big) = L^{-1} \\Big( F(s) \\Big) \\pm L^{-1} \\Big( G(s) \\Big)\\)"},{"location":"2_Core/Math_3/14_Laplace/#lt-of-standard-functions","title":"LT of Standard Functions","text":"\\(f(t)\\) \\(L\\Big( f(t) \\Big)\\) \\(1\\) \\(\\frac{1}{s}\\) \\(k\\) \\(\\frac{k}{s}\\) \\(e^{at}\\) \\(\\frac{1}{s\\textcolor{orange}{-}a}\\) \\(\\cos(at)\\) \\(\\frac{s}{s^2 + a^2}\\) \\(\\sin(at)\\) \\(\\frac{a}{s^2 + a^2}\\) \\(\\cosh(at)\\) \\(\\frac{s}{s^2 - a^2}\\) \\(\\sinh(at)\\) \\(\\frac{a}{s^2 - a^2}\\) \\(t^n\\) $\\begin{cases} \\dfrac{n!}{s^{n+1}}, &amp; n \\le 0 \\ \\dfrac{\\Gamma(n+1)}{s^{n+1}}, &amp; \\text{otherwise} \\end{cases}$  where \\(\\Gamma\\) is gamma function \\(e^{at} f(t)\\)(exponent shifting rule) \\(F(s \\textcolor{orange}{-} a) = \\Big\\{ F(s) \\Big\\}_{s \\to s-a}\\) \\(u_a(t)\\) \\(\\frac{e^{-as}}{s}\\) \\(\\delta (t)\\) \\(1\\)"},{"location":"2_Core/Math_3/14_Laplace/#unit-step-function","title":"Unit Step Function","text":"\\[ u_a (t) = \\begin{cases} 0, &amp; t &lt; a \\\\ 1, &amp; t \\ge a \\end{cases} \\]"},{"location":"2_Core/Math_3/14_Laplace/#unit-impulse-function","title":"Unit Impulse Function","text":"\\[ \\delta (t) = \\lim_{\\epsilon \\to 0} f_\\epsilon(t) \\] \\[ f_\\epsilon(t) = \\begin{cases} \\dfrac{1}{\\epsilon}, &amp; 0 \\le t \\le \\epsilon \\\\ 0, &amp; t &gt; \\epsilon \\end{cases} \\] \\[ \\begin{aligned} L\\Big( \\delta(t) \\Big) &amp;= \\lim_{\\epsilon \\to 0} L\\Big( f_\\epsilon (t) \\Big) \\\\ &amp;= \\lim_{\\epsilon \\to 0} \\left[     \\int\\limits_0^\\infty e^{-st}  f_\\epsilon(t) \\cdot dt \\\\ \\right] \\\\ &amp; \\dots \\\\ &amp;= 1 \\end{aligned} \\]"},{"location":"2_Core/Math_3/14_Laplace/#sum-of-gp","title":"Sum of GP","text":"\\[ \\sum GP = \\frac{a}{1-r} \\]"},{"location":"2_Core/Math_3/14_Laplace/#gamma-function","title":"Gamma Function","text":"\\[ \\Gamma(x) = \\int_0^\\infty e^{-x} x^{n-1} dx \\]"},{"location":"2_Core/Math_3/14_Laplace/#properties","title":"Properties","text":"\\[ \\begin{aligned} \\Gamma \\left(\\frac{1}{2} \\right) &amp;= \\sqrt{\\pi} \\\\ \\Gamma(n) &amp;= (n-1)! \\\\ &amp;= (n-1) \\cdot \\Gamma(n-1) \\\\ n! &amp;= \\Gamma (n+1) \\\\ \\end{aligned} \\]"},{"location":"2_Core/Math_3/14_Laplace/#idk","title":"IDK","text":"<p>When doing nested transformations, do it as Part 1 and \\(f(part 1)\\) like how you did it for grade 12 integrals \\(I_1 + I_2\\)</p>"},{"location":"2_Core/Math_3/15_Laplace_Derivatives%2C_Integrals/","title":"15 Laplace Derivatives, Integrals","text":""},{"location":"2_Core/Math_3/15_Laplace_Derivatives%2C_Integrals/#derivatives","title":"Derivatives","text":"\\[ \\begin{aligned} L\\{ f'(t) \\} &amp;= s F(s) - f(0) \\\\ L\\{ f''(t) \\} &amp;= s^2 F(s) - sf(0) - f'(0) \\\\ \\Big( L\\{ f(t) \\} &amp;= F(s) \\Big) \\end{aligned} \\] \\[ \\begin{aligned} f(0) &amp;= \\{ f(t) \\}_{t = 0} \\\\ f'(0) &amp;= \\left\\{ \\frac{d f(t)}{dt} \\right\\}_{t = 0} \\\\ f'(t) &amp;= \\frac{df}{dx}; f''(t) = \\frac{d^2f}{dx^2} \\end{aligned} \\]"},{"location":"2_Core/Math_3/15_Laplace_Derivatives%2C_Integrals/#i-missed-after-this","title":"I missed after this","text":"\\[ \\begin{aligned} L^{-1} \\left[ \\frac{F(s)}{s} \\right] &amp;= \\int\\limits_0^t L^{-1} \\Big( F(s) \\Big)  \\ dt\\\\ L^{-1} \\left[ \\frac{F(s)}{s^2} \\right] &amp;= \\int\\limits_0^t \\int\\limits_0^t L^{-1} \\Big( F(s) \\Big)  \\ dt\\\\ L^{-1} \\left[ \\frac{F(s)}{s^n} \\right] &amp;= \\text{n integrals from } 0 \\to t \\quad L^{-1} \\Big( F(s) \\Big)  \\ dt \\end{aligned} \\]"},{"location":"2_Core/Math_3/16_Convolution/","title":"16 Convolution","text":""},{"location":"2_Core/Math_3/16_Convolution/#definition","title":"Definition","text":"\\[ f(t) \\star g(t) = \\int\\limits_0^\\infty f(t-\\tau) g(\\tau) \\cdot d\\tau \\] \\[ f(t) \\star g(t) = g(t) \\star f(t) \\]"},{"location":"2_Core/Math_3/16_Convolution/#convolution-theorem","title":"Convolution Theorem","text":"<p>It is used for Laplace Transform</p> \\[ L \\{ f(t) \\star g(t) \\} = F(s) \\cdot G(s) \\] \\[ \\begin{aligned} L^{-1} \\{ F(s) \\cdot G(s) \\} &amp;= f(t) \\star g(t) \\\\ &amp;= L^{-1}\\{ F(s) \\} \\star L^{-1}\\{ G(s) \\} \\end{aligned} \\]"},{"location":"2_Core/Math_3/16_Convolution/#trignometric","title":"Trignometric","text":"\\[ \\begin{aligned} \\cos(x) &amp;= \\frac{     e^x \\textcolor{orange}{+} e^{-x} }{2} \\\\ \\sinh(x) &amp;= \\frac{     e^x \\textcolor{orange}{-} e^{-x} }{2} \\\\ \\cos(x) &amp;= \\frac{     e^{\\textcolor{hotpink}{i} x} \\textcolor{orange}{+} e^{-\\textcolor{hotpink}{i} x} }{2i} \\\\ \\sin(x) &amp;= \\frac{     e^{\\textcolor{hotpink}{i} x} \\textcolor{orange}{-} e^{-\\textcolor{hotpink}{i} x} }{2i} \\end{aligned} \\]"},{"location":"2_Core/Math_3/17_Fourier_Series/","title":"Fourier Series","text":"<p>Represent periodic signals in terms of cosines and sines.</p>"},{"location":"2_Core/Math_3/17_Fourier_Series/#periods","title":"Periods","text":"<p>A period signal repeats its pattern at some period \\(T\\).</p> <p>Fourier series of period signal can be used to analyze the signal in another domain.</p> <p>If \\(f(t)\\) is a function with period T, then</p> \\[ f(t+nT) = f(t) \\quad \\forall n \\] Function Period \\(\\cos \\theta, \\sin \\theta\\) \\(2 \\pi\\) \\(\\cos (n\\theta), \\sin (n\\theta)\\) \\(\\dfrac{2\\pi}{n}\\)"},{"location":"2_Core/Math_3/17_Fourier_Series/#fourier-series_1","title":"Fourier Series","text":"<p>of a function \\(f(x)\\) of period \\(2\\pi\\) in the interval \\([-\\pi, +\\pi]\\), is defined as</p> \\[ f(x) = \\frac{a_0}{ \\textcolor{orange}{2} } + \\sum\\limits_{n=1}^\\infty a_n \\cos(nx) + \\sum\\limits_{n=1}^{\\infty} b_n \\sin (nx) \\] <p>It is always continuous.</p> <p>Whenever possible, we have to make it into regular summation, ie from \\(1 \\to \\infty\\).</p>"},{"location":"2_Core/Math_3/17_Fourier_Series/#fourier-constants","title":"Fourier Constants","text":"\\[ \\begin{aligned} a_0 &amp;= \\frac{1}{\\pi} \\int\\limits_{-\\pi}^{\\pi} f(x) \\cdot dx \\\\ a_n &amp;= \\frac{1}{\\pi} \\int\\limits_{-\\pi}^{\\pi} f(x) \\textcolor{orange}{\\cos(nx)} \\cdot dx \\\\ b_n &amp;= \\frac{1}{\\pi} \\int\\limits_{-\\pi}^{\\pi} f(x) \\textcolor{orange}{\\sin(nx)} \\cdot dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/17_Fourier_Series/#sum-of-functions","title":"Sum of Functions","text":"\\[ FS(g_1 \\pm g_2) = FS(g_1) \\pm FS(g_2) \\]"},{"location":"2_Core/Math_3/17_Fourier_Series/#dirchelet-condition","title":"Dirchelet Condition","text":"<p>Even though the function that the FS represents may be discontinuous, the FS itself will be continuous</p> \\[ \\text{FS} \\stackrel{\\text{converges}}{\\longrightarrow} \\begin{cases} f(a) &amp;, a = \\text{Continuous Point} \\\\ \\dfrac{f(a^-) + f(a^+)}{2} &amp;, a = \\text{Discontinuous Point} \\end{cases} \\]"},{"location":"2_Core/Math_3/17_Fourier_Series/#evenodd-functions","title":"Even/Odd Functions","text":"Even Odd \\(f(-x)\\) \\(f(x)\\) \\(-f(x)\\) Fourier Series \\(\\dfrac{a_0}{2} + \\sum\\limits_{n=1}^\\infty a_n \\cos(nx)\\) \\(\\sum\\limits_{n=1}^\\infty b_n \\sin(nx)\\) \\(a_0\\) \\(\\dfrac{2}{\\pi} \\int\\limits_0^\\pi f(x) dx\\) 0 \\(a_n\\) \\(\\dfrac{2}{\\pi} \\int\\limits_0^\\pi f(x) \\cos(nx) dx\\) 0 \\(b_n\\) 0 \\(\\dfrac{2}{\\pi} \\int\\limits_0^\\pi f(x) \\sin(nx) dx\\) <p>This is because \\(\\int f(x) dx = 0\\) when \\(f(x)\\) is even</p>"},{"location":"2_Core/Math_3/17_Fourier_Series/#note","title":"Note","text":"<p>Consider</p> \\[ \\begin{aligned} f(x) &amp;= \\begin{cases}     g_1(x), &amp; (-a, 0) \\\\     g_2(x), &amp; (0, a) \\end{cases}\\\\ \\implies  f(x) &amp;= \\begin{cases} \\text{Even}, &amp; g_1(-x) = +g_2(x) \\\\ \\text{Odd},  &amp; g_1(-x) = -g_2(x) \\end{cases} \\end{aligned} \\]"},{"location":"2_Core/Math_3/17_Fourier_Series/#grahphically","title":"Grahphically","text":"<p>We can also plot the points for \\(x = \\{-\\pi, 0, - \\pi\\}\\). Connect the points.</p> Function Type Symmetric about Even Y axis Odd Origin"},{"location":"2_Core/Math_3/17_Fourier_Series/#sinecosine-series","title":"Sine/Cosine Series","text":"<p>Special types of series, where we represent the fourier series in terms of \\(\\sin\\) alone or \\(\\cos\\) alone in half interval \\((0,\\pi)\\)</p> <p>Sine/Cosine series may be asked for an odd/even function.</p> Cosine Series Sine Series Fourier Series \\(\\dfrac{a_0}{2} + \\sum\\limits_{n=1}^\\infty a_n \\cos(nx)\\) \\(\\sum\\limits_{n=1}^\\infty b_n \\sin(nx)\\) \\(a_0\\) \\(\\dfrac{2}{\\pi} \\int\\limits_0^\\pi f(x) dx\\) 0 \\(a_n\\) \\(\\dfrac{2}{\\pi} \\int\\limits_0^\\pi f(x) \\cos(nx) dx\\) 0 \\(b_n\\) 0 \\(\\dfrac{2}{\\pi} \\int\\limits_0^\\pi f(x) \\sin(nx) dx\\)"},{"location":"2_Core/Math_3/17_Fourier_Series/#arbitrary-interval","title":"Arbitrary Interval","text":"<p>Fourier series of \\(f(x)\\) of period \\(2l\\) defined in the interval \\((-l, l), l \\in R\\) is</p> \\[ f(x) = \\frac{     a_0 }{     \\textcolor{orange}{2} } + \\sum_{n=1}^\\infty a_n \\cos \\left(     \\frac{n \\textcolor{hotpink}{\\pi} x}{\\textcolor{hotpink}{l}} \\right) + \\sum_{n=1}^\\infty b_n \\sin \\left(     \\frac{n \\textcolor{hotpink}{\\pi} x}{\\textcolor{hotpink}{l}} \\right) \\] \\[ \\begin{aligned} a_0 &amp;= \\frac{1}{\\textcolor{hotpink}{l}} \\int\\limits_{-l}^l f(x) dx \\\\ a_n &amp;= \\frac{1}{\\textcolor{hotpink}{l}} \\int\\limits_{-l}^l f(x) \\cos \\left(     \\frac{n \\textcolor{hotpink}{\\pi} x}{\\textcolor{hotpink}{l}} \\right) dx \\\\ b_n &amp;= \\frac{1}{\\textcolor{hotpink}{l}} \\int\\limits_{-l}^l f(x) \\sin \\left(\\frac{n \\textcolor{hotpink}{\\pi} x}{\\textcolor{hotpink}{l}} \\right) dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/17_Fourier_Series/#changes-in-interval","title":"Changes in Interval","text":"From To For \\((-\\pi, \\pi)\\) \\((-l, l)\\) FS \\((0, \\pi)\\) \\((0, l)\\) CS and SS \\(\\cos(nx)\\) \\(\\cos \\left( \\frac{n \\pi x}{l} \\right)\\) FS, CS, SS \\(\\sin(nx)\\) \\(\\sin \\left( \\frac{n \\pi x}{l} \\right)\\) FS, CS, SS \\(\\frac{1}{\\pi} \\int_{-\\pi}^\\pi\\) \\(\\frac{1}{l} \\int_{-l}^l\\) FS, CS, SS \\(\\frac{2}{\\pi} \\int_0^\\pi\\) \\(\\frac{2}{l} \\int_0^l\\) FS, CS, SS"},{"location":"2_Core/Math_3/17_Fourier_Series/#bernoullis-integration-chain-rule","title":"Bernoulli\u2019s Integration Chain Rule","text":"\\[ \\int(uv) dx = u v_1 - u' v_2 - u'' v_3 - \\ldots - u^{(n-1)} v_n \\] Term Meaning \\(u, v\\) Given Functions \\(u', u'', \\dots\\) Derivatives \\(v_1, v_2, v_3, \\dots\\) Integrals"},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/","title":"18 Application of Fourier Series","text":""},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#1d-wave-equation","title":"1D Wave Equation","text":"<p>Assuming that the vibration only happens in one direction.</p> \\[ \\begin{aligned} a^2 &amp;= \\frac{T}{m} &gt; 0 \\\\ \\frac{\\partial^2 y}{\\partial t^2} &amp;= a^2 \\left(     \\frac{\\partial^2 y}{\\partial x^2} \\right) \\end{aligned} \\] <p>\\(a \\ne\\) acceleration</p>"},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#conditions","title":"Conditions","text":"For Initial Vertical Displacement at Left End \\(y(0, t)\\) \\(0\\) \\(\\forall t\\) Initial Vertical Displacement at Right End \\(y(\\pi, t)\\) \\(0\\) \\(\\forall t\\) Vertical Velocity \\(\\frac{\\partial y}{\\partial t}(x, 0)\\) \\(0\\) \\(0 \\le x \\le \\pi\\) The function \\(y(x, 0)\\) \\(f(x)\\) \\(0 \\le x \\le \\pi\\)"},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#solution","title":"Solution","text":"<p>Solution of equation under the initial conditions</p> \\[ \\begin{aligned} y(x, t) &amp;= \\sum_{n = 1}^\\infty b_n \\sin(nx) \\textcolor{hotpink}{\\cos (nat)} \\\\ b_n &amp;= \\frac{2}{\\pi} \\int\\limits_0^\\pi f(x) \\sin(nx) dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#1d-heat-equation","title":"1D Heat Equation","text":""},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#fourier-thermal-law","title":"Fourier Thermal Law","text":"<p>The amount of heat flowing through a heat-producing body \\(H\\)</p> <ul> <li>\\(H \\propto\\) temperature gradient</li> <li>\\(H \\propto\\) area of cross-section</li> <li>\\(H \\frac{1}{\\propto}\\) resistance</li> </ul> <p>Time 0 is the time at which the external temperature is placed</p>"},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#formula","title":"Formula","text":"<p>\\(\\alpha^2\\) is thermal diffusability.</p> \\[ \\begin{aligned} \\alpha^2 &amp;= \\frac{k}{\\rho c} &gt; 0\\\\ \\frac{\\partial u}{\\partial t} &amp;= \\alpha^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} \\right) \\end{aligned} \\]"},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#conditions_1","title":"Conditions","text":"For Initial Heat at Left End \\(u(0, t)\\) 0 \\(\\forall t\\) Initial Heat at Right End \\(u(\\pi, t)\\) 0 \\(\\forall t\\) \\(u(x, 0)\\) \\(f(x)\\) \\(0 \\le x \\le \\pi\\)"},{"location":"2_Core/Math_3/18_Application_of_Fourier_Series/#solution_1","title":"Solution","text":"<p>Solution of equation under the initial conditions</p> \\[ \\begin{aligned} u(x, t) &amp;= \\sum_{n = 1}^\\infty b_n \\sin (nx) \\textcolor{hotpink}{e^{-n^2 \\alpha^2 t}} \\\\ b_n &amp;= \\frac{2}{\\pi} \\int\\limits_0^\\pi f(x) \\sin(nx) dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/19_Power_Series/","title":"19 Power Series","text":""},{"location":"2_Core/Math_3/19_Power_Series/#power-series","title":"Power Series","text":"<p>An infinite series in \\(x\\) of the form</p> \\[ \\sum_{n=0}^\\infty a_n x^n = a_0 + a_1 x + a_2 x^2 + \\dots + a_r x^r + \\dots \\] <p>where \\(\\{ a_0, a_1, a_2, \\dots \\}\\) are constants</p> <p>equation is convergent only when \\(x \\to 0\\)</p>"},{"location":"2_Core/Math_3/19_Power_Series/#non-algebraic-elementary-functions","title":"Non-Algebraic Elementary Functions","text":"<p>Transcendental means non-algebraic</p> Function Power Series Intuition \\(e^x\\) \\(1 + \\frac{x}{1!} + \\frac{x^2}{2!} + \\dots\\) \\(\\cos x\\) \\(1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} + \\dots\\) Even function so even numbers \\(\\sin x\\) \\(x - \\frac{x^3}{3!} + \\frac{x^5}{5!} + \\dots\\) Odd function so odd numbers \\(\\cosh x\\) \\(1 + \\frac{x^2}{2!} + \\frac{x^4}{4!} + \\dots\\) \\(\\sinh x\\) \\(x + \\frac{x^3}{3!} + \\frac{x^5}{5!} + \\dots\\) \\(\\log(1+x)\\) \\(x - \\frac{x^2}{2} + \\frac{x^3}{3} - \\frac{x^4}{4} + \\dots\\) \\((1+x)^{-1}\\) \\(1 - x + x^2 - x^3 + \\dots\\) \\((1-x)^{-1}\\) \\(1 + x + x^2 + x^3 + \\dots\\)"},{"location":"2_Core/Math_3/19_Power_Series/#solving","title":"Solving","text":"\\[ \\begin{aligned} y &amp;= \\sum_{n=0}^\\infty a_n x^n &amp;&amp;= a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\dots \\\\ y' &amp;= \\sum_{n=1}^\\infty a_n n x^{n-1} &amp;&amp;= a_1 + 2a_2 x + 3a_3 x^2 + \\dots \\\\ y'' &amp;= \\sum_{n=2}^\\infty a_n n(n-1) x^{n-2} &amp;&amp;= 2a_2 + (3 \\cdot 2) a_3 x + \\dots \\\\ \\end{aligned} \\]"},{"location":"2_Core/Math_3/19_Power_Series/#comparing-coefficients","title":"Comparing Coefficients","text":"<p>By changing index and re-arranging terms, we have to make the following equal</p> <ol> <li>counter start</li> <li>\\(x\\) power</li> </ol>"},{"location":"2_Core/Math_3/19_Power_Series/#2nd-order","title":"2<sup>nd</sup> Order","text":"<p>Power series solution is only possible if \\(x = 0\\) is an ordinary point of the DE.</p>"},{"location":"2_Core/Math_3/19_Power_Series/#types-of-points","title":"Types of Points","text":"<p>Consider a general 2<sup>nd</sup> order differential equation with polynomials \\(P_1, P_2, P_3\\).</p> \\[ \\begin{aligned} P y'' + Q y' + R y &amp;= 0 \\\\ \\implies y'' + \\frac{Q}{P} y' + \\frac{R}{P} y &amp;= 0 \\end{aligned} \\] Types \\(P(a)\\) Ordinary Point \\(\\ne 0\\) Singular Point \\(= 0\\)"},{"location":"2_Core/Math_3/19_Power_Series/#ordinary-point","title":"Ordinary Point","text":"<p>\\(x=a\\) is an ordinary point of DE equation, if \\(P(a) \\ne 0\\).</p>"},{"location":"2_Core/Math_3/19_Power_Series/#power-series-solution","title":"Power Series Solution","text":"<p>The power series solution of equation is given by</p> \\[ y = \\sum_{n=0}^{\\infty} a_n x^n \\]"},{"location":"2_Core/Math_3/19_Power_Series/#general-solution","title":"General Solution","text":"<p>Solving equation as</p> \\[ y = a(\\text{PS}_1) + b(\\text{PS}_2) \\] <p>where</p> <ul> <li>PS<sub>1</sub> and PS<sub>2</sub> are congruent and linearly-independent power series, for \\(x \\to 0\\)</li> <li>\\(a\\) and \\(b\\) are arbitrary constants</li> </ul>"},{"location":"2_Core/Math_3/19_Power_Series/#singular-points","title":"Singular Points","text":"<p>Consider limits</p> \\[ \\begin{aligned} p&amp;= \\lim_{x \\to a} (x-a) &amp;\\frac{Q(x)}{P(x)}\\\\ q&amp;= \\lim_{x \\to a} (x-a)^{\\textcolor{hotpink}{2}} &amp;\\frac{R(x)}{P(x)} \\end{aligned} \\] Both limits exist Point Type \u2705 Regular \u274c Irregular"},{"location":"2_Core/Math_3/19_Power_Series/#frobenius-series-method","title":"Frobenius Series Method","text":"<p>Differential equations with regular singular points at \\(x=0\\) can be solved using a power series of the form</p> \\[ \\begin{aligned} y &amp;= x^m \\sum_{n=0}^\\infty a_n x^n \\\\ &amp;= \\sum_{n=0}^\\infty a_n x^{m+n} \\end{aligned} \\] <p>where \\(m\\) is constant coefficient called as root/indical/initial value. This is singular points (to be calculated).</p>"},{"location":"2_Core/Math_3/19_Power_Series/#trick-to-find-indical-value","title":"Trick to find indical value","text":"\\[ m(m-1) + p m + q = 0 \\] <p>where \\(p\\) and \\(q\\) are limits from equation</p>"},{"location":"2_Core/Math_3/20_Hyper_Geometric/","title":"20 Hyper Geometric","text":"<p>if \\(a\\) and/or \\(b\\) are negative integers, then it will become a polynomial of degree \\(n\\).</p>"},{"location":"2_Core/Math_3/20_Hyper_Geometric/#general-form","title":"General Form","text":"<p>something</p> \\[ (1-x^2) \\]"},{"location":"2_Core/Math_3/20_Hyper_Geometric/#standard-form","title":"Standard Form","text":"\\[ x(1-x) y'' + \\Big[c - (a+b+1)x \\Big]y' - (ab)y = 0 \\] <p>where \\(a, b, c\\) are real constants</p> <p>\\(x=0, x=1\\) are the regular singular points of equation</p> <p>By Frobenius Series method, at regular singular points, we get 2 initial roots</p> <ul> <li>\\(m=0\\)</li> <li>\\(m=1-c\\)</li> </ul> \\(m=0\\) \\(m=1-c\\) Solution \\(y\\) \\(1 + \\frac{a \\cdot b}{1 \\cdot c}x + \\frac{a(a\\textcolor{hotpink}{+1}) \\cdot b(b\\textcolor{hotpink}{+1})}{1(1\\textcolor{hotpink}{+1}) \\cdot c(c\\textcolor{hotpink}{+1})} x^2 + \\\\ \\frac{a(a\\textcolor{hotpink}{+1})(a\\textcolor{orange}{+2}) \\cdot b(b\\textcolor{hotpink}{+1})(b\\textcolor{orange}{+2})}{1(1\\textcolor{hotpink}{+1})(1\\textcolor{orange}{+2}) \\cdot c(c\\textcolor{hotpink}{+1})(c\\textcolor{orange}{+2})} x^3 + \\dots\\) \\(x^{\\textcolor{hotpink}{1-c}} \\times F(a + \\textcolor{hotpink}{1-c}, b+ \\textcolor{hotpink}{1-c}, 2-c, x)\\) \\(F(a, b, c , x) = F(b, a, c, x)\\)Commutative Constant Outcome \\(a \\le 0\\) or \\(b \\le 0\\) Series breaks off into finite polynomial \\(c\\le 0\\) Solution doesn\u2019t exist"},{"location":"2_Core/Math_3/21_Legendre/","title":"21 Legendre","text":""},{"location":"2_Core/Math_3/21_Legendre/#legendre-de","title":"Legendre DE","text":"\\[ (1-x^2) y'' - 2xy' + n(n+1)y = 0 \\]"},{"location":"2_Core/Math_3/21_Legendre/#solution","title":"Solution","text":"<p>Solution of equation, at the 2 singular points \\(x = \\pm 1\\).</p> <p>We will get</p> \\[ t(t-1)y'' + (1-2t)y' + n(n+1)y = 0 \\] <p>equation is a hyper-geometric function.</p>"},{"location":"2_Core/Math_3/21_Legendre/#solution-of-equation-near-t0","title":"Solution of equation near \\(t=0\\)","text":"\\[ y = F(-n, n+1, 1, t) \\]"},{"location":"2_Core/Math_3/21_Legendre/#solution-of-equation-near-x0","title":"Solution of equation near \\(x=0\\)","text":"\\[ P_n(x) = y = F \\left(-n, n+1, 1, \\frac{1-x}{2} \\right) \\] <p>This is a legendre polynomial of degree \\(n\\).</p>"},{"location":"2_Core/Math_3/21_Legendre/#rodrigues-formula","title":"Rodrigue\u2019s Formula","text":"\\[ P_n(x) = \\frac{1}{2^n \\cdot n!} \\left[     \\frac{d^n}{d x^n} (x^2 - 1)^n \\right] \\] \\[ \\begin{aligned} P_0(x) &amp;= 1 \\\\ P_1(x) &amp;= x \\\\ P_2(x) &amp;= \\frac{1}{2}(3x^2 - 1) \\\\ P_3(x) &amp;= \\frac{1}{2}(5x^3 - 3x) \\end{aligned} \\]"},{"location":"2_Core/Math_3/21_Legendre/#generating-function","title":"Generating Function","text":"\\[ (1-2xt + t^2)^{-1/2} = \\sum\\limits_{n=0}^\\infty P_n (x) t^n \\\\ |t| &lt; 1 \\\\ |x| \\le 1 \\]"},{"location":"2_Core/Math_3/21_Legendre/#binomial-expansion","title":"Binomial Expansion","text":"\\[ (1+t^2)^{-1/2} = \\]"},{"location":"2_Core/Math_3/21_Legendre/#legendre-series","title":"Legendre Series","text":"<p>Similar to Fourier Series, Any function \\(f(x)\\) can be represented as</p> \\[ \\begin{aligned} f(x) &amp;= \\sum_{n=0}^\\infty a_n P_n(x) \\\\ a_n &amp;= \\frac{2n+1}{2} \\int_{-1}^1 f(x) P_n(x) dx \\end{aligned} \\]"},{"location":"2_Core/Math_3/22_Bessel/","title":"22 Bessel","text":""},{"location":"2_Core/Math_3/22_Bessel/#bessels-de","title":"Bessel\u2019s DE","text":"<p>Family of differential equation, with some constant value \\(p\\)</p> \\[ x^2y'' + xy' + (x^2-p^2) y = 0 \\]"},{"location":"2_Core/Math_3/22_Bessel/#bessels-function","title":"Bessel\u2019s Function","text":"<p>is the solution of Bessel\u2019s DE. Denoted by \\(J_p(x)\\)</p> <p>\\(x=0\\) is a regular singular point of equation. Solving using Frobenieus Series method gives 2 initial roots as \\(m = \\pm p\\)</p> \\(+p\\) \\(-p\\) \\(J(x)\\) \\(\\sum\\limits_{n=0}^\\infty \\dfrac{(-1)^n \\left(\\frac{x}{2}\\right)^{2n \\textcolor{hotpink}{+p}}}{n!(n \\textcolor{hotpink}{+p})!}\\) \\(\\sum\\limits_{n=0}^\\infty \\dfrac{(-1)^n \\left(\\frac{x}{2}\\right)^{2n \\textcolor{hotpink}{-p} }}{n!(n \\textcolor{hotpink}{-p} )!}\\) <p>The above 2 formula are not directly possible for negative integers, as \\((n-p)!\\) is not valid when it is negativeUse gamma function</p>"},{"location":"2_Core/Math_3/22_Bessel/#general-solution","title":"General Solution","text":"\\[ y = c_1 J_p(x) + c_2 J_{-p} (x) \\]"},{"location":"2_Core/Math_3/22_Bessel/#properties","title":"Properties","text":""},{"location":"2_Core/Math_3/22_Bessel/#to-remember","title":"To Remember","text":"\\[ \\begin{aligned} J_\\frac{1}{2}(x) &amp;= \\sin x \\sqrt{     \\frac{2}{\\pi x} } \\\\ J_\\frac{-1}{2}(x) &amp;= \\cos x \\sqrt{     \\frac{2}{\\pi x} } \\\\ J_{p-1}(x) + J_{p+1}(x) &amp;= \\frac{2p}{x} J_p(x) \\end{aligned} \\]"},{"location":"2_Core/Math_3/22_Bessel/#other-properties","title":"Other Properties","text":"\\[ \\begin{aligned} \\Big( x^{p} J_p(x) \\Big)' &amp;= x^{p} J_{p-1} (x) \\\\ \\Big( x^{-p} J_p(x) \\Big)' &amp;= - x^{-p} J_{p+1} (x) \\\\ {J_p}'(x) + \\frac{p}{x} J_p(x) &amp;= J_{p-1}(x) \\\\ {J_p}'(x) - \\frac{p}{x} J_p(x) &amp;= - J_{p+1}(x) \\\\ J_{p-1}(x) - J_{p+1}(x) &amp;= 2 {J_p}'(x) \\end{aligned} \\]"},{"location":"2_Core/Math_3/23_Strum-Liouvill/","title":"23 Strum Liouvill","text":"<p>Consider the DE with scalar \\(\\lambda\\) defined in \\([a,b]\\)</p> \\[ \\frac{d}{dx} \\Big[     P(x) y' \\Big] + \\Big[\\lambda Q(x) + R(x) \\Big] y = 0 \\] <p>with the boundary conditions</p> \\[ \\begin{aligned} c_1 y(a) + c_2 y'(a) &amp;= 0 &amp; d_1 y(b) + d_2 y'(b) &amp;= 0 \\\\ c_1 \\text{ or } c_2 &amp;= 0 &amp; d_1 \\text{ or } d_2 &amp;= 0 \\end{aligned} \\]"},{"location":"2_Core/Math_3/23_Strum-Liouvill/#simplest-form","title":"Simplest Form","text":"\\[ \\begin{aligned} y'' + \\lambda y &amp;= 0 \\\\ P(x) &amp;= 1 \\\\ Q(x) &amp;= 1 \\\\ R(x) &amp;= 0 \\end{aligned} \\]"},{"location":"2_Core/Math_3/23_Strum-Liouvill/#legendre-equation","title":"Legendre Equation","text":"<p>Legendre Equation can be represented as Strum-Liouvile Problem.</p> \\[ \\frac{d}{dx} \\Big[     \\underbrace{(1-x^2)}_{P(x)}     y' \\Big] + \\underbrace{n(n+1)}_{\\lambda} \\ y = 0 \\\\ P(x) = 1-x^2 \\\\ Q(x) = 1 \\\\  R(x) = 0 \\\\ \\lambda = n(n+1) \\] <p>Here, \\(\\lambda\\) is the eigen value of equation</p> <p>The corresponding solutions are \\(P_n(x), n = 1, 2, \\dots\\) They are called as eigen functions.</p> <p>\\(n &gt; 0\\) because \\(n \\le 0\\) will give trivial solution.</p>"},{"location":"2_Core/Math_3/23_Strum-Liouvill/#eigen-valuefunction","title":"Eigen Value/Function","text":"\\[ \\begin{aligned} y'' + \\lambda y &amp;= 0 \\\\ y(a) &amp;= 0 \\\\ y(b) &amp;= 0 \\\\ a &amp; \\ne b \\end{aligned} \\]"},{"location":"2_Core/Math_3/24_System_of_DE/","title":"24 System of DE","text":"<p>Consider 2 dependent variables \\(x(t), y(t)\\).</p> \\[ a_1 + something \\\\ a_2 + something \\] <p>These equations are to solved simultaneously.</p>"},{"location":"2_Core/Math_3/25_Chebyshev/","title":"25 Chebyshev","text":""},{"location":"2_Core/Math_3/25_Chebyshev/#chebyshev-de","title":"Chebyshev DE","text":"\\[ (1-x^2)y'' - xy' + n^2 y =0 \\\\ n&gt;0 \\] <p>\\(x = \\pm 1\\) are the regular singular points of equation</p>"},{"location":"2_Core/Math_3/25_Chebyshev/#chebyshev-polynomials","title":"Chebyshev Polynomials","text":"<p>are solutions of Chebyshev DE</p> <p>Using Frobenius method near \\(x=1\\), we get the solution</p> \\[ T_n = F \\left( n, -n, \\frac{1}{2}, \\frac{1-x}{2} \\right) \\] <p>equation is a finite polynomial of degree \\(n\\), as \\(b=-n\\) (-ve integer)</p> <p>Using transformation \\(x=\\cos \\theta\\) in equation, we get another solution</p> \\[ T_n = \\cos(n \\theta), \\quad \\theta = \\cos^{-1}x \\]"},{"location":"2_Core/Math_3/25_Chebyshev/#eulers-theorem","title":"Euler\u2019s Theorem","text":"\\[ \\begin{aligned} e^{i\\theta} &amp;= \\cos \\theta + i \\sin \\theta \\\\ e^{ni\\theta} &amp;= \\cos n\\theta + i \\sin n\\theta \\\\ &amp;= (\\cos \\theta + i \\sin \\theta)^n \\\\ \\end{aligned} \\]"},{"location":"2_Core/MicroProcessors_%26_Interfacing/","title":"Microprocessors and Interfacing","text":"Class Instructor Lecture Dr. MB Srinivas Tutorial Dr. Jagadish Nayak Practical Dr. Shazia Hasan <p>The core of a processing system, that processes logic and data</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/","title":"01 Intro","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#what-happens-when-we-switch-on-computer","title":"What happens when we switch on computer","text":"<ol> <li>BIOS(Basic Input Output System) loaded from the ROM(Read-Only Memory)</li> <li>BIOS loads OS into the RAM    RAM should atleast be the size of the OS</li> <li>OS loads programs from disk to RAM    Program: set of instructions executed by \\(\\mu p\\)</li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#what-is-an-instruction","title":"What is an instruction?","text":"<p>Tells the MP what actions to perform</p> <ul> <li>operations<ul> <li>logic</li> <li>arithmetic</li> </ul> </li> <li>read data from input device</li> <li>write to memory</li> <li>reset</li> <li>stop</li> </ul> <p>Assembly program gives these instructions. Each microprocessor understands these instructions in different ways.</p> <p>High-level program use statements which get compiled/interpreted into machine language. Allows programmer focus on the logic, rather than worrying about how it will understood by the MP.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#microprocessor","title":"Microprocessor","text":"<p>has both sequential and combinational circuits</p> <ul> <li>Control unit has sequential circuits</li> <li>ALU has combinational circuits</li> </ul> <p>Size of the processor = size of ALU</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#instruction-handling","title":"Instruction-Handling","text":"<p>Instructions is a set of command, used by the mp to perform to certain taks</p> <ol> <li>Fetch Instruction    Instruction taken from the memory and stored in instruction register</li> <li>Decode Instruction</li> <li>Fetch Operand(s)</li> <li>Execute Cycle    actions are performed</li> <li>Store result</li> </ol> <p>Make this into block diagram</p> <ul> <li>BIU - Bus Interface Unit</li> <li>ALU - Arithmetic Logic Unit</li> <li>Execution Unit</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#overview","title":"Overview","text":"<p>Microcontrollers like Arduino have the memory also embedded to the processor</p> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#detailed","title":"Detailed","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#architectures","title":"Architectures","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#instruction-set-architecture","title":"Instruction Set Architecture","text":"<p>This is the design/theory</p> <ol> <li>Execution Model</li> <li>Processor Register</li> <li>Address and Data Formats</li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#microarchitecture","title":"Microarchitecture","text":"<p>This is the hardware components</p> <ol> <li>Interconnections between elements</li> <li>ALU</li> <li>Data Path</li> <li>Control Path</li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#mpu-vs-mcu","title":"MPU vs MCU","text":"MPUMicroProcessor Unit MCUMicroController Unit CPU Clock rate &gt; 1 GHz 1 MHz - 0.4 GHz Memory location External Internal Memory capacity &gt; 0.5 GB 2 KB - 512 KB Storage location External Internal Storage capacity &gt; 64 GB 32 KB - 2 MB I/O External Internal Peripherals External Internal No glue logic/software needed \u274c \u2705 Power Consumption Higher&gt; 30W Lower\\(\\rm{150 \\micro W - 23.5 mW}\\) Size Large Small Design flexibility \u2705 \u274c Use Computer system Embedded system Other names SOC (System on a chip)Embedded controllerComputer on a chip"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#types-of-microprocessors","title":"Types of Microprocessors","text":"RISC CISC Full Form Reduced Instruction Set Computing Complex Instruction Set Computing Gives importance to Hardware Software Can access memory directly? \u2705 \u274c(requires registers) Amount of Instructions Small Large Coding Instructions complexity Complex Simple Machine Instructions complexity Simple Complex Decoder Reduced Instruction Decoder Complex Instruction Decoder Architecture Register only Register-Memory Speed Fast Clock cyles for executing an instruction \\(\\ge 1\\) \\(1\\) Usage Real-Time Operations Complexity lies in Microprogram Compiler Application IOT (Internet of Things) Examples ARM x86 processors like 8086"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#x86-family","title":"x86 Family","text":"<ul> <li>CISC</li> <li>Instructions are broken into \\(\\micro\\) operations</li> </ul> <p>8086 has 1MB capacity</p> Bits Address Lines 8086 16 80286 16 80386 80486"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#8086-tut","title":"8086 (Tut)","text":"Lines 20 \\(A_0 \\to A_{19}\\) Data bus 16 \\(A_0 \\to A_{15}\\) memory locations \\(2^{20}\\) Size of each memory location 1 byte 8 bits total memory 2 MB <p>Byte-organised</p> <p>We represent the address of each location in 5bit hex \\(00000H \\to FFFFFH\\)</p> <p>If we need to store 16bits of data</p> <ul> <li>we need 2 bytes</li> <li>so we will require 2 contigious memory locations</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#memory-addressing","title":"Memory Addressing","text":"<p>Each range of addresses is allocated for different **segments **of registers</p> <ul> <li>Code segment</li> <li>Data segment</li> <li>Stack segment</li> <li>Extra segment</li> <li>Instruction pointer</li> </ul> <p>If CS = 10000 and offet = 0002, then DS = 10002</p> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#internal-cache","title":"Internal Cache","text":"<p>a small and fast SRAM memory attached to the processor, for pre-fetching data</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#registers","title":"Registers","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/01_Intro/#idk","title":"IDK","text":"<p>The reason we're left-shifting by 1 digit is because</p> <ul> <li>Address is to be 20 bits (5hex digits)</li> <li>Pointer we want to hold 16bits (4 hex digits)   because the blocks in x86 architecture</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/","title":"02 Addressing","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#types-of-instructuctions","title":"Types of instructuctions","text":"<ul> <li>Data transfer</li> <li>Arithmetic</li> <li>Logical</li> <li>Branch(conditional) and program control</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#little-endian-format","title":"Little Endian Format","text":"<p>In little endian format adopted by Intel and most manufacturers, first the low byte gets stored and then the high byte.</p> <p>Consider a number \\(1234_H\\). It will be stored in memory as follows</p> \\[ \\underset{40000} {\\Large \\fbox{34$\\vphantom{0}$} } \\underset{40001} {\\Large \\fbox{12$\\vphantom{0}$} } \\]"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#addressing-modes","title":"Addressing Modes","text":"Addressing Register MOV AX, BX AX, BX are registers Immediate MOV AX, 1420<sub>H</sub> 1420H = value of data Direct MOV AX, [2340<sub>H</sub>] 2340 = offset address of DS Register Indirect MOV AX, [BX] BX is the pointer Base-Plus-Index MOV AX, [BX+SI] BX, SI are pointers Register relative MOV AX, BX[10] BX is the pointer Base relative-plus-indexed MOV AX, [BX+SI+10] Scaled Indexed MOV AX, [10BX]"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#instruction-format","title":"Instruction Format","text":"<p>The assembler converts assembly code into bytecode</p> <ul> <li>Mnemonics like <code>MOV</code>, <code>ADD</code> get converted into opcode</li> <li>Variable names get converted into addresses</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#register-addressing","title":"Register Addressing","text":"\\[ \\underbrace{ \\fbox{1} \\fbox{0} \\fbox{0} \\fbox{0} \\fbox{1}\\fbox{0} } _{\\text{Opcode}} \\underset{\\text{D}}{ \\fbox{1}} \\underset{\\text{W}}{ \\fbox{1}} \\underbrace{ \\fbox{1} \\fbox{1} } _{\\text{MOD}} \\underbrace{ \\fbox{0} \\fbox{1} \\fbox{1} } _{\\text{Reg}} \\underbrace{ \\fbox{0} \\fbox{1} \\fbox{1} } _{\\text{R/M}} \\]"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#meanings","title":"Meanings","text":"0 1 Opcode Operation Code D **D**irection From Reg To Reg W **W**ord Byte Word MOD Addressing **Mod**e of R/M Reg **Reg**ister R/M **R**egister/**M**emory Address"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#word","title":"Word","text":"W=0 W=1 AL AX CL CX DL DX BL BX AH SP CH BP DH SI DH DI"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#mod","title":"MOD","text":"MOD Addressing Mode 00 01 10 11 Register Addressing"},{"location":"2_Core/MicroProcessors_%26_Interfacing/02_Addressing/#reg","title":"Reg","text":"Register Code EAX, AX, AL 000 EBX, BX, BL 011 EAX, CX, CL <p>No need to learn 32bit encoding</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/","title":"03 Assembly Programs","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#types-of-instructions","title":"Types of Instructions","text":"<ol> <li>Data Transfer</li> <li>Arithmetic</li> <li>Logical</li> <li>Branch and Program Control</li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#steps","title":"Steps","text":"<ol> <li>initialise segment register</li> </ol> <pre><code>mov ax, 2000h\nmov ds, ax\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#mov","title":"<code>MOV</code>","text":"\\[ \\textcolor{orange}{ \\underbrace{\\text{MOV}}_\\text{Opcode} } \\ \\ \\textcolor{hotpink}{ \\underbrace{\\text{dest, src}}_\\text{Operands} } \\] <p>Destination/Source could be register/memory location. This is the data, and the operands of the operation</p> <p>4 bits are required to refer to a register: \\(0000-FFFF\\)</p> <p>MOV, ADD, etc\u2026 are called mnemonics</p> \\[ \\text{MOV dest, src} \\] <ul> <li>copies contents from src to dest</li> <li>no flags affected</li> <li>size of src and dest must be same; however smaller data can be inserted into bigger register</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#possible-options","title":"Possible Options","text":"<ul> <li>source can be register, memory location, immediate date</li> <li>dest can be register/memory location</li> </ul> From To Register Memory Memory Register Register Register Index Memory Index Register <p>You cannot do <code>MOV [1234] [5678]</code></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#inc-dec","title":"<code>INC</code>, <code>DEC</code>","text":"\\[ \\text{INC dest} \\\\ \\text{DEC dest} \\] <p>increments/decrements the content of the affected register by 1.</p> <pre><code>inc ax\n\ninc word ptr[bx]\ninc byte ptr[bx] ; only low byte\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#add","title":"<code>ADD</code>","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#adc","title":"<code>ADC</code>","text":"<p>First you must use <code>CLC</code> to clear the carry flag.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#equ","title":"<code>EQU</code>","text":"<p>used to assign value to a variable. It doesn\u2019t store anything in memory.</p> <pre><code>count equ 08h\nmov cl, count\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#dup","title":"<code>DUP</code>","text":"<p>Duplicate</p> <pre><code>array db 5 dup(12h)\narray db 5 dup('A')\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#flags","title":"Flags","text":"Flag Meaning High when AF Auxiliary internal carry (from lower nibble to higher nibble) CF Carry carry from the entire byte OF Overflow overflow PF Parity even parity (only follows low byte) SF Sign signed number ZF Zero data is 0"},{"location":"2_Core/MicroProcessors_%26_Interfacing/03_Assembly_Programs/#branch-instructions","title":"Branch Instructions","text":"<p>Jump means like <code>go to</code> in C++</p> JZ Jump on Zero JNZ Jump on Non-Zero JE Jump on Equal JNE Jump on Not Equal"},{"location":"2_Core/MicroProcessors_%26_Interfacing/04_String_Instructions/","title":"04 String Instructions","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/04_String_Instructions/#string","title":"String","text":"<p>sequence of data bytes/words that are in consecutive memory locations</p> <p>Everywhere</p> <ul> <li>does not affect flags</li> <li>d = 0 -&gt; SI/DI inc</li> <li>d = 1 -&gt; SI/DI dec</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/04_String_Instructions/#movs","title":"<code>MOVS</code>","text":"<p>Moving Strings</p> <p>copies a byte/word/double word fro a location in the data segment to a location in the extra segment</p> <ul> <li>Source - DS:SI</li> <li>Destination - ES:DI</li> </ul> SI/DI inc/dec by <code>MOVSB</code> 1 <code>MOVSW</code> 2 <code>MOVSD</code> 4"},{"location":"2_Core/MicroProcessors_%26_Interfacing/04_String_Instructions/#lea","title":"<code>LEA</code>","text":"<p>Load effective address</p> <pre><code>lea si, array1\nlea di, array2\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/04_String_Instructions/#lods","title":"LODS","text":"<p>Loads AL/AX/EAX witht the data stored at the data segment</p> <p>offset address indexed by si register</p> Equivalent <code>LODSB</code> AL = <code>LODSW</code> AX = <code>LODSD</code> EAX ="},{"location":"2_Core/MicroProcessors_%26_Interfacing/04_String_Instructions/#stos","title":"STOS","text":"<p>Stores AL/AX/EAX into the extra segment memory at offset address indexed by DI register.</p> Equivalent <code>STOSB</code> <code>STOSW</code> <code>STOSD</code>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/","title":"05 More Instructions","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/#rotate","title":"Rotate","text":"<p>ROL/ROR</p> <p>Data does not get lost</p> <p>also, the value gets stored in carry flag</p> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/#shift","title":"Shift","text":"<p>command is</p> <ul> <li>SAL/SHL</li> <li>SAR/SHR</li> </ul> <p>Shift each bit count times</p> <pre><code>sal dest, count\nshl dest, count\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/#multiplication","title":"Multiplication","text":"<ul> <li>Mul - unsigned</li> <li>Imul - signed</li> </ul> <pre><code>mul src\n\nmul cx ; ax\nmul cl ; al\n</code></pre> <p>Src times</p> <ul> <li>AL</li> <li>AX</li> <li>EAX</li> </ul> <p>Source can be a register or memory location</p> Multiplication Result Storage Byte AX Word DX:AX Dword EDX:EAX <ul> <li>CF and OF are zero if MSB/MSW/MSD zero</li> <li>AF, PF, SF, ZF - undefined</li> <li>CBW/CWD</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/#conversion","title":"Conversion","text":"<ul> <li><code>CBW</code> converts byte to word</li> <li><code>CWD</code> converts word to double word</li> </ul> <p>When MSB is</p> <ul> <li>0, 0s are added</li> <li>1, 1s are added</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/#division","title":"Division","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/#div","title":"<code>div</code>","text":"8bit 16bit dividend AX AX divisor BX BX quotient AL AX remainder AH DX"},{"location":"2_Core/MicroProcessors_%26_Interfacing/05_More_Instructions/#idiv","title":"<code>idiv</code>","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/06_Jumps%2C_Loops/","title":"06 Jumps, Loops","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/06_Jumps%2C_Loops/#jumps","title":"Jumps","text":"Jump Displacement Range Short 8 bits \\(-128 \\iff 127\\) Near 16 bits"},{"location":"2_Core/MicroProcessors_%26_Interfacing/06_Jumps%2C_Loops/#loops","title":"Loops","text":"<pre><code>count db 09h\nmov cx, count           ; initialization\n\nrepeat:\n    ; code\n    loop repeat\n\n; equivalent to\nrepeat:\n    ; code\n    dec cx                      ; updation\n    jnz repeat              ; condition\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/07_Stacks/","title":"07 Stacks","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/07_Stacks/#stack","title":"Stack","text":"<p>it is a temporary scratch memory, for storing variables</p> <p>memory is segmented into different various segments, and one of them is stack segment</p> <p>2/4 bytes involved</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/07_Stacks/#operations","title":"Operations","text":"Push Pop Direction register/memory to stack stack to register/memory lower register \\(\\leftarrow\\) 1<sup>st</sup> bytehigher register \\(\\leftarrow\\) 2<sup>nd</sup> byte Byte SP - 1 SP + 1 Word SP - 2 SP + 2 [SP-1] \\(\\leftarrow\\) MSB[SP-2] \\(\\leftarrow\\) LSB Double Word SP - 4 SP + 4"},{"location":"2_Core/MicroProcessors_%26_Interfacing/08_Subroutines/","title":"08 Subroutines","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/08_Subroutines/#structure","title":"Structure","text":"<pre><code>name proc near\n    ;code\n\n    ret\nname endp\n</code></pre> <pre><code>call procName\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/08_Subroutines/#example","title":"Example","text":"<pre><code>bcd2bin proc near\n    ; code\n    ret\n\nbcd2bin endp\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/","title":"09 Hardware","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#hardware","title":"Hardware","text":"<ul> <li>ALU is a combinational circuit</li> <li>clock is for the frequency</li> <li>Address lines are uni</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#pin-diagram","title":"Pin Diagram","text":"<p>Names</p> <ul> <li>DIP (Dual Inline Package)</li> <li>QFP (Quad Flag Pack)</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#multiplexer","title":"Multiplexer","text":"<p>Intel used multiplexer</p> <ul> <li>minimizes the area required for the chip</li> <li>reduces performance</li> </ul>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#modes","title":"Modes","text":"Minimum Maximum MN/MX\u2019 MN/MX\u2019 Logic 1 0 Size Smaller Larger Processors Single Multiple Cost Cheaper Expensive 8087 (co-Processor)"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#mac-operations","title":"MAC operations","text":"<p>Multiplied and Accumulated</p> <p>\\(AX+B\\)</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#cycle","title":"Cycle","text":"<ol> <li>Clock = T state</li> <li>Machine - memory access</li> <li>Instruction - instruction access + decoding + \u2026</li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#setup-time","title":"Setup Time","text":"<p>the time before the clock high, during which the data must be setup, to avoid data corruption</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/09_Hardware/#hold-time","title":"Hold Time","text":"<p>the time after the clock high, during which the data must be held, to avoid data corruption</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/","title":"10 Pin Out Address","text":"<p>This topic goes over how 8086 creates addresses and how data transfers occurs</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#intro","title":"Intro","text":"<p>8086 can be divided mainly into</p> <ol> <li>Bus Interface Unit</li> <li>Execution Unit</li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#externals","title":"Externals","text":"<p>ROM - Read-Only Memory</p> <p>contains the BIOS (Basic Input/Output System)</p> <p>RAM - Random Access Memory is faster and hence, applications get loaded here during runtime</p> <p>Permanent Memory is non-volatile</p> <p>IO- Input/Output Devices</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#buses","title":"Buses","text":"Address Data Control Direction 1 2 1 <p>All signals depend on the clock. So faster the frequency of the clock, faster the operations.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#address-buses","title":"Address Buses","text":"<p>They are multiplexed with data lines and with selection lines. To reduce area required.</p> <p>Multiplexing happens with inputs that won\u2019t be used simultaneously.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#pin-diagram","title":"Pin Diagram","text":"<p>40 pins</p> <p>Dual Inline Package IC</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#vcc","title":"VCC","text":"<p>\\(5v \\pm 10 \\%\\)</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#gnd","title":"GND","text":"<p>2 grounds</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#clk","title":"Clk","text":"<p>One cycle of this clock is called as T state.</p> <p>The time between 2 rising/falling edges is called as a time period.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#reset","title":"Reset","text":"<p>Used to initialize the processor. The processor will repeat all given instructions. Any data inside registers will be lost, and flags will be reset.</p> <p>CS FFFFh</p> <p>IP 0000h</p> <p>This signal has to high for atleast 4 clk signals.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#mn-overlinemx","title":"\\(MN/ \\overline{MX}\\)","text":"<p>Minimum/Maximum</p> <p>These 2 are different modes of operations.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#ale","title":"ALE","text":"<p>Address Latch Enable</p> <p>Whenever there is address, this is set as high. Else, it is data.</p> <p>This is sent to Gate signal.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#overlinebhes7","title":"\\(\\overline{BHE}/S7\\)","text":"<p>Bus High Enable</p> <p>Enables the most significant data lines (D8 - D15), only when required</p> <p>S7 is always high</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#modes","title":"Modes","text":"Minimum Maximum Logic 1 0 No of processors 1Only 8086 or 8088 Multiplerequires 8087 as its co processor for floating point operation Size Smaller Larger Cost Cheaper Costlier"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#octal-latch","title":"Octal Latch","text":"<p>8 bit latch</p> <p>used for de -multiplexing address and data</p> <p>it is used to ensure that address does not get affected, while operations don\u2019t get affected.</p> <p>we are using LS273</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#g","title":"G","text":"<p>Gate Signal controls whether or not input to the latch get reflected to the output.</p> <p>As soon as the address gets passed through, the signal is turned low.</p> <p>get its value from the ALE</p> <p>When \\(G\\) is high, address is sent out. Else, data is sent out.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#overlineoe","title":"\\(\\overline{OE}\\)","text":"<p>Output Enabled Active Low</p> <p>Grounded by default</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/10_Pin_Out_Address/#dont-know","title":"Don\u2019t know","text":"Signal Address Signal Status Signal \\(A_{16}/S_3\\) \\(A_{16}\\) Segment Address \\(A_{17}/S_4\\) \\(A_{17}\\) Segment Address \\(A_{18}/S_5\\) \\(A_{18}\\) Int Flag Status \\(A_{19}/S_6\\) \\(A_{19}\\) 0 \\(\\overline{BHE}/S_7\\) \\(\\overline{BHE}\\) 1 S4 S3 Function 0 0 Extra Segment 0 1 Stack Segment 1 0 Code or no Segment 1 1 Data Segment"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/","title":"11 Pin Out Control Data","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#data-bus","title":"Data Bus","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#pins","title":"Pins","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#moverlineio","title":"\\(M/\\overline{IO}\\)","text":"<p>Differentiate between memory and IO access.</p> <p>When high, memory reference instructions.</p> <p>When low, IO instructions.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#overlinerd","title":"\\(\\overline{RD}\\)","text":"<p>When it is low, read operation takes place.</p> <p>It is an ouput signal.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#overlinewr","title":"\\(\\overline{WR}\\)","text":"<p>When it is low, write operation takes place.</p> <p>It is an ouput signal.</p> \\(M/\\overline{IO}\\) \\(\\overline{RD}\\) \\(\\overline{WR}\\) Bus Cycle 1 0 1; Memory Read 1 1 0 Memory Write 0 0 1 Input/Output Read 0 1 0 Input/Output Write <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#overlineden","title":"\\(\\overline{DEN}\\)","text":"<p>Data Enable</p> <p>Whenever data is available on \\(AD0- AD15\\), this signal becomes low, to signal that data is coming.</p> <p>Connected to \\(\\bar E\\)</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#dtoverliner","title":"\\(DT/\\overline{R}\\)","text":"<p>Data Transmit/Receive</p> <p>Controls the direction of data transfer from/to data transceivers, such as Bi-Directional Buffer.</p> <p>When high, data transmitted by processor</p> <p>When low, data received by processor</p> <p>Connected to DIR</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#bi-directional-buffer","title":"Bi-Directional Buffer","text":"<p>We are using LS245 as the octal buffer.</p> <p>Bus A = MP, Bus B = Data Bus</p> <p>Data can move from Bus A \\(\\to\\) B, or vice-versa.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#bar-e","title":"\\(\\bar E\\)","text":"<p>Connected to \\(\\overline{DEN}\\)</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/11_Pin_Out_Control_Data/#dir","title":"DIR","text":"<p>Connected to \\(DT/\\overline{R}\\)</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/12_Pin_Out_System/","title":"12 Pin Out System","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/12_Pin_Out_System/#interrupts","title":"Interrupts","text":"<p>8086 has 2 interrupts.</p> Maskable Non-Maskable controlled by the interrupt flag checks interrupt flag \u2705 \u274c works when interrupt flag is high input INTR (Interrupt Request) NMI output \\(\\overline{INTA}\\) (Interrupt Acknowledge)"},{"location":"2_Core/MicroProcessors_%26_Interfacing/12_Pin_Out_System/#hold","title":"Hold","text":"<p>Input Signal to the processor from the bus masters as a request to control the bus.</p> <p>Usually by DMA controller.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/12_Pin_Out_System/#hlda","title":"HLDA","text":"<p>Hold Acknowledge</p> <p>Output Signal from the processor to the bus master requesting control.</p> <p>When high, acknowledged</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/","title":"13 Machine Cycles","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#cycles","title":"Cycles","text":"<p>Instuction cycle is the time taken by the processor to execute one instruction.</p> <p>As 8086 is a CISC processor, each instruction cycle consists of multiple machine cycles.</p> <p>Each machine cycle consists of T states.</p> <p>All operations occur sequentially, controlled by the clock signal.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#machine-cycles","title":"Machine Cycles","text":"<pre><code>flowchart LR\n1[Instruction Fetch] --&gt; 2[Instruction Decode] --&gt; 3[Operand Fetch] --&gt; 4[Instruction Execution] --&gt; 5[Store] --&gt; 1</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#t-state","title":"T State","text":"<p>Time Period = \\(\\frac{1}{\\nu}\\)</p> <p>Getting from/to Register does not require anything</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#timing-diagram","title":"Timing Diagram","text":"<p>Tutorial</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#machine-cycles_1","title":"Machine Cycles","text":"<p>Getting from/to Register does not require anything The number of bits readable in 1 cycle = 16bits 1. opcode      - 16bits requires 2      -  1. Reading from memory = 1 1. Writing to memory = 1</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#time","title":"Time","text":"<p>Total Time = No of T States \\(\\times\\) Duration of each T state  = No of cycles \\(\\times\\) No of T States in each cycle \\(\\times\\) Duration of each T state </p> <p>No of T states in each cycle = 4 Duration of each T state = 1 Time Period = \\(\\frac{1}{\\nu}\\)</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#2-memory-operations","title":"2 memory operations","text":"<ol> <li>Read (Data/Instruction)</li> <li>Write (Data)</li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#timing-diagram_1","title":"Timing Diagram","text":"<p>In write operation, the data is available in the 2<sup>nd</sup> state itself, as there will not be any delay.</p> <p>In read operation, it is available in the 3<sup>rd</sup> state.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#slow-device","title":"Slow Device","text":"<p>Active High signal from slow device/memory, acknowledging that it is ready for data transfer.</p> <p>Else, the processor inserts a wait state, before \\(T_3\\) state.</p> <p>Number of wait states depends on the difference in the speed between the microprocessor and the slow device.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#readwrite","title":"Read/Write","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#write","title":"Write","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/13_Machine_Cycles/#read","title":"Read","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/14_Memory_Banking/","title":"14 Memory Banking","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/14_Memory_Banking/#components","title":"Components","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/14_Memory_Banking/#2704","title":"2704","text":"<p>2704 is ROM chip</p> <p>two has W Inverted W is M It also has o, so ROM</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/14_Memory_Banking/#ls138","title":"LS138","text":"<p>\\(3 \\times 8\\) decoder</p> <p>The other one will be ram chip We don\u2019t need the entire memory, so we instead use in different way.</p> \\(O_0\\) ROM1 \\(O_3\\) RAM1 \\(O_4\\) RAM2"},{"location":"2_Core/MicroProcessors_%26_Interfacing/14_Memory_Banking/#blah","title":"Blah","text":"\\(O_0\\) \\(A_0\\) \\(\\overline{BHE}\\) Even Odd 0 0 0 \u2705 \u2705 0 0 1 \u2705 0 1 0 \u2705 0 1 1 <p>It is active low.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/15_Interrupts/","title":"15 Interrupts","text":"<p>ISR</p> <p>Interrupt Service Routine</p> <p>We need 2 bytes of memory location for pushing the CS contents</p> <p>Total 6 bytes are required for an interrupt to occur</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/15_Interrupts/#interrupt-vectors","title":"Interrupt Vectors","text":"Interrupt Physical Address INT 00H \\({00000}_H\\) \\({IP}_0\\) \\({00002}_H\\) \\({CS}_0\\) INT 01H \\({00004_H}\\) \\({IP}_1\\) \\({00006_H}\\) \\({CS}_1\\) INT FFH \\({003FC_H}\\) \\({IP}_{255}\\) \\({003FE_H}\\) \\({CS}_{255}\\)"},{"location":"2_Core/MicroProcessors_%26_Interfacing/15_Interrupts/#interrupts","title":"Interrupts","text":"<code>INT</code> Interrupt When Explanation 0 Divide by Zero 1 Single Step 2 NMI low-to-high transition on NMI input Type 2 interrupts cannot be disabled(masked) by any instruction 3 BreakPoint 4 into 5 <code>bound</code> 6 Invalid opcode 7 Co-Processor not available 8 Double Fault 9 A B C D E F"},{"location":"2_Core/MicroProcessors_%26_Interfacing/16_IO_Interfacing/","title":"16 IO Interfacing","text":"Input Output Buffer Latch"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/","title":"Intro","text":"<p>We are using \u2018Assembly Language\u2019, which is a lower level language compared to C, C++, Java, Python, etc\u2026</p> <p>It uses an assembler to convert the code into machine language the processor can understand. (high level languages use compiler/interpreter).</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/#installation","title":"Installation","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/#windows","title":"Windows","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/#macos","title":"MacOS","text":"<ol> <li>Install <code>dosbox</code></li> <li>https://www.dosbox.com/download.php?main=1</li> <li>Copy <code>8086</code> files to <code>ahmedthahir/dosbox</code>; basically the root folder (next to Desktop, Documents, etc)</li> <li>https://www.mediafire.com/file/mm7cjztce9efj4w/8086.zip/file</li> <li>open <code>dosbox</code></li> <li><code>mount c ~/dosbox/8086</code></li> <li><code>c:</code></li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/#basics","title":"Basics","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/#skeleton-program","title":"Skeleton Program","text":"<pre><code>.model small\n.stack 20\n\n.data\norg 1000h\nnum1 db 05h\nnum2 db 03h\n\n.code\nstart:\nmov ax, @data\nmov ds, ax\n\nmov al, num1\nadd num2, al\n\nint 3\nend start\ncode ends\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/#steps","title":"Steps","text":"<ol> <li> <p>Open up TurboAssembler</p> </li> <li> <p>Editing</p> <ul> <li>no</li> <li>Dos</li> <li>Type <code>edit fileName.asm</code></li> <li>Type your code</li> <li>Save your code     Click Here to learn how</li> </ul> </li> <li> <p>Assembling    Type <code>tasm fileName.asm</code></p> </li> <li> <p>Linking    Type <code>tlink fileName.obj</code></p> </li> <li> <p>Execution</p> </li> <li>Type <code>td fileName.exe</code></li> <li> <p>Click <code>F7</code> to execute the required lines</p> </li> <li> <p>Viewing results</p> </li> <li>Click <code>Tab</code> key until focus reaches the address-value thing at the bottom</li> <li>Click <code>Ctrl-G</code></li> <li>Enter <code>ds:address</code>       for eg <code>ds:1000</code></li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/#saving","title":"Saving","text":"<p>on your keyboard, click</p> <ol> <li><code>Alt+f</code> </li> <li>then <code>s</code> </li> </ol>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/01/","title":"01","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/01/#program-1","title":"Program 1","text":"<p>Add two 2-digit hexadecimal numbers (method 1)</p> <pre><code>DATA SEGMENT\n\nORG 1000H\nNUM1 DB 89H\nNUM2 DB 7CH\nRES DW ?\n\nDATA ENDS\nCODE SEGMENT\nASSUME CS: CODE, DS: DATA\n\nSTART:\nMOV AX, DATA\nMOV DS, AX\nMOV AH, 0\nMOV AL, NUM1\nADD AL, NUM2\nADC AH, 0\nMOV RES, AX\nINT 3\n\nCODE ENDS\nEND START\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/01/#program-2","title":"Program 2","text":"<p>Add two 2-digit hexadecimal numbers (method 2)</p> <pre><code>.model small\n.stack 20\n\n.data\n\norg 1000H\nnum1 DB 80H\nnum2 DB 86H\nres DW ?\n.code\nstart:\n\nmov ax, @data\nmov ds,ax\nmov ah,0\nmov al,num1\nadd al,num2\nadc ah,0\nmov res,ax\nint 3\n\nend start\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/01/#program-3","title":"Program 3","text":"<p>Write a program to add two 2-digit decimal numbers available in memory and store the result in memory.</p> \\[ 89+78 = 167 \\] <pre><code>DATA SEGMENT\nORG 1000H\nNUM1 DB 89H\nNUM2 DB 78H\nRES DW ?\nDATA ENDS\n\nCODE SEGMENT\nASSUME CS: CODE, DS: DATA\n\nSTART:\n\nMOV AX, DATA\nMOV DS, AX\nMOV AH, 0\nMOV AL, NUM1\nADD AL, NUM2\nDAA\nADC AH, 0\nMOV RES, AX\nINT 3\n\nCODE ENDS\nEND START\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/01/#program-4","title":"Program 4","text":"<p>The above program without H in the input Data</p> <p>This gives wrong answer cuz we do DAA, even though the stored values are decimal</p> <pre><code>DATA SEGMENT\nORG 1000H\nNUM1 DB 89\nNUM2 DB 78\nRES DW ? \nDATA ENDS\nCODE SEGMENT\nASSUME CS: CODE, DS: DATA\n\nSTART:\nMOV AX, DATA\nMOV DS, AX\nMOV AH, 0 \nMOV AL, NUM1\nADD AL, NUM2\nDAA\nADC AH, 0\nMOV RES, AX\nINT 3\n\nCODE ENDS\nEND START\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/01/#daa","title":"<code>DAA</code>","text":"<p>DAA corrects the result of a previous addition of two valid packed decimal operands (note that this result must be in AL). This instruction changes the content of AL so that it will contain a pair of valid packed decimal digits.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/02/","title":"02","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/02/#program-1","title":"Program 1","text":"<p>Write a program to add two multi-byte binary numbers stored in memory and also store the result in memory.</p> <pre><code>.MODEL SMALL ; Type of the model declaration\n.STACK 20 ; size of the stack declaration\n.DATA ; Data segment declaration\norg 1000H ; Memory address initialization. Data start from memory Location\n\n; 1006 (it may vary, depends upon your processor)\n\nNUM1 DB 25H,35H,45H,32H,56H,98H,76H,76H ; These are array of 8 hex numbers\nNUM2 DB 90H,56H,43H,75H,89H,10H,34H,22H ; These are second array of numbers\nANS DB 10 DUP (?) ; Size of the memory to store the results, it reserves 10 duplicate no. with unknown value.\n\nCOUNT DW 8H ; counter to store 8, since 8 times we need to add\n\n.CODE ; code start here\nSTART:\nMOV AX, @DATA\nMOV DS, AX ; Initializing DS: segment register\nMOV CX, COUNT ; Register CX is initializing to COUNT= 8\nMOV SI, 0H ; Initializing Source Index Register SI= 0\nCLC ; Clears the Carry Flag before addition\nREPEAT: ; initializing the loop\n\n; (REPEAT is a loop name, you may change it to any)\n\nMOV AL, NUM1 [SI] ; Loading the 1st array value to AL register\nADC AL, NUM2 [SI] ; Adding the 2nd array value to AL register value\nMOV ANS [SI], AL ; moving the addition value to ANS variable\nINC SI ; incrementing the Source Index for the next position\nLOOP REPEAT ; go back to the location of REPEAT loop\nINT 3 ; Breakpoint interrupt\nEND START ; stopping the program\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/02/#program-2","title":"Program 2","text":"<p>Write a program to subtract two multi-byte binary numbers stored in memory and also store the result in memory.</p> <pre><code>.MODEL SMALL ; Type of the model declaration\n.STACK 20 ; size of the stack declaration\n.DATA ; Data segment declaration\nOrg 1000H ; Memory address initialization. Data start from memory location 1006\n\n; (it may vary, depends upon your processor)\n\nNUM1 DB 89H,35H,45H,32H,56H,98H,76H,76H; These are array of 8 hex numbers\nNUM2 DB 32H,56H,43H,75H,89H,10H,34H,22H; These are second array of numbers\nANS DB 9 DUP(0) ; size of the memory to store the results, it reserves 9 duplicate no. with \u20180\u2019 value.\n\nCOUNT DW 8H ; counter to store 8, since 8 times we need to subtract\n.CODE ; code start here\nSTART:\nMOV AX, @DATA\nMOV DS, AX ; Initializing DS: segment register\nMOV CX, COUNT ; Reg CX is initializing to COUNT=8\nMOV SI, 0H ; Initializing Source Index Register SI=0\nCLC ; Clears the Carry Flag before subtraction\nREPEAT: ; Initializing the loop\nMOV AL, NUM1 [SI] ; Loading the 1st array value to AL register\nSBB AL, NUM2 [SI] ; subtracting the 2nd array value to AL register value\nMOV ANS [SI], AL ; moving the subtracted result to ANS variable\nINC SI ; incrementing the Source Index for the next position\nLOOP REPEAT ; loop repeat\nINT 3 ; Breakpoint interrupt\nEND START ; stopping the program\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/02/#program-3","title":"Program 3","text":"<p>Write a program to multiply two 8-bit binary numbers stored in memory and also store the result in memory (both unsigned and signed operation).</p> <ul> <li>Unsigned numbers stored only positive numbers but not negative numbers</li> <li>Signed numbers contain sign flag</li> </ul> <pre><code>.MODEL SMALL\n.STACK 20\n.DATA\nORG 1000H\nN1 DB 35H ; Input Number one\nN2 DB 82H ; Input Number two\nUn_Sign_PROD DW ? ; This the variable to store Unsigned multiplication\nSign_PROD DW ? ; This the variable to store Signed multiplication\n.CODE ; code segment start here\nSTART:\nMOV AX, @DATA ; Initialize DS\nMOV DS, AX\nMOV AL, N1 ; storing the first value (N1)to AL\nMUL N2 ; Unsigned multiplication, multiplying the N2 with N1\nMOV Un_Sign_PROD, AX ; moving the results of AX to Un_sign_Prod variable\nMOV AL, N1 ; storing the first value (N1) to AL\nIMUL N2 ; Signed multiplication, IMUL multiplies signed numbers\nMOV Sign_PROD, AX ; moving the results from AX to sign_PROD variable memory\nINT 3 ; Breakpoint interrupt\nEND START ; stopping the program\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/02/#assignment","title":"Assignment","text":"<p>Write a program to find factorial of number.</p> <pre><code>.model small\n.stack 20\n.data\norg 1000h\n\nnum dw 6d\nfact dw 1d\n\n.code\nstart:\nmov dx, @data\nmov ds, dx\nmov cx, num\nmov si, 0h\nmov ax, 1d\n\nrepeat:\nmul cx\nloop repeat\n\nmov fact, ax\n\nint 3\nend start\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/03/","title":"03","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/03/#program-1","title":"Program 1","text":"<p>Write a program to add an array of eight 2-digit hexadecimal numbers stored in memory and store the result in memory.</p> <pre><code>.MODEL SMALL\n.STACK 20\n.DATA ; Data segment start here\nORG 1000H ; Memory address initialization\nNUM DB 25H, 35H, 45H, 32H, 56H, 98H, 76H,76H ; eight 2-digit hex numbers input\nSUM DW ? ; Variable to store Sum\nCOUNT DW 0008H ; Count Variable to store count 8\n\n.CODE ; Code start here\nSTART:\nMOV AX, @DATA ; Initializing DS: segment register\nMOV DS, AX\nMOV CX, COUNT ; Reg CX is initializing to COUNT=8\nMOV SI, 0000H ; Initializing Source Index Register SI=0000\nMOV AX, 0000H ; move AX=0000\n\nREPEAT: ; Loop start here\nADD AL, NUM[SI] ; Moving the 1st array value to AL register\nJNC NEXT ; Jump If not Carry, here Next is 16bit address.\nADD AH, 01 ; Add 01 to AH\nNEXT: ; Next address reference\nINC SI ; Increment SI\nLOOP REPEAT ; Repeat loop Reference\nMOV SUM, AX ; Moving the AX value to Sum variable memory\nINT 3 ; Breakpoint interrupt\nEND START ; stopping the program\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/03/#program-2","title":"Program 2","text":"<p>Write a program to count number of occurrences of the byte 25H in the given array of 16-bytes stored starting from 1200H. Also store the result in 1220H memory location.</p> <pre><code>.MODEL SMALL\n.STACK 20\n.DATA ; Data segment start here\nORG 1200H ; Memory address initialization as given in the program\nARRAY DB 25H, 35H, 45H, 32H, 56H, 25H, 76H, 76H, 28H, 56H, 05H, 35H, 25H, 00H, 98H, 21H ; Inputs\nORG 1220H ; Memory address initialization to store results\nRES DB ? ; Variable to store Number of occurrences\nCOUNT DW 0010H ; Count Variable to store length of the array i.e 10\n.CODE ; Code start here\nSTART:\nMOV AX, @DATA ; Initializing DS: segment register\nMOV DS, AX\nMOV CX, COUNT ; Reg CX is initializing to COUNT\nMOV SI, 0000H ; Initializing Source Index Register SI=0000\nMOV AL, 25H ; move AL=25H, We need to find out number of\n\n; occurrences of 25H\nREPEAT: ; Loop start here\nCMP AL, ARRAY[SI] ; The CMP instruction compares two operands.\nJNE NEXT ; Jump if Not Equal, if SI and AL data not equal it jumps\n\n; to INC SI\n\nINC RES ; if SI and AL equal the RES is incremented\nNEXT:\nINC SI ; Increment SI\nLOOP REPEAT ; Loop Repeat\nINT 3 ; Breakpoint interrupt\nEND START ; stopping the program\n</code></pre> <p></p> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/03/#program-3","title":"Program 3","text":"<p>Write a program to exchange two data blocks of length 10-bytes stored in memory starting from 1200H and 1220H respectively.</p> <pre><code>.MODEL SMALL\n.STACK 20\n.DATA ; Data segment start here\nORG 1200H ; Memory address one initialization as given in the program\nARRAY1 DB 05H, 15H, 25H, 35H, 45H, 55H, 65H, 75H, 85H, 95H ; Inputs\nORG 1220H ; Memory address two initialization as given in the program\nARRAY2 DB 0A1H, 0A2H, 0A3H, 0A4H, 0A5H, 0A6H, 0A7H, 0A8H, 0A9H, 0AAH ; Inputs\nCOUNT DW 000AH ; Count Variable to store length of the array i.e 000A\n.CODE ; Code start here\nSTART:\nMOV AX, @DATA ; Initializing DS: segment register\nMOV DS, AX\nMOV CX, COUNT ; Reg CX is initializing to COUNT\nMOV SI, 0000H ; Initializing Source Index Register SI=0000\nREPEAT: ; Loop start here\nMOV AL, ARRAY1 [SI] ; Moving first element of array one to AL Register\nXCHG AL, ARRAY2 [SI] ; Exchange Data. The XCHG exchange the contents of\n\n; two operands.\n\nMOV ARRAY1 [SI], AL ; Move the Content of AL to Array one address\nINC SI ; Increment SI\nLOOP REPEAT ; Loop Repeat\nINT 3 ; Breakpoint interrupt\nEND START ; stopping the program\n</code></pre> <p></p> <p></p> <p></p> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/03/#assignment","title":"Assignment","text":"<p>Write a program to arrange the given array of 8-bit binary numbers stored in the memory in ascending order.</p> <pre><code>.MODEL SMALL\n.STACK 20\n.DATA\nNUM DB 11H, 21H, 31H, 31H, 55H, 45H, 35H, 25H\nCOUNT DW 0008H\n\n.CODE\nSTART:\nMOV AX, @DATA\nMOV DS, AX\nMOV CX, COUNT\n\nDEC CX\n\nNEXT:\n    MOV DX, CX\n    MOV SI, 0000H\n\n  REPEAT:\n    MOV AL, NUM[SI]\n    CMP AL, NUM[SI + 1]\n    JC NOEX\n    XCHG AL, NUM[SI +1]\n    MOV NUM[SI], AL\n\n    NOEX:\n        INC SI\n        DEC DX\n        JNZ REPEAT\n        LOOP NEXT\n\nINT 3\nEND START\n</code></pre> <p></p> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/04/","title":"04","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/04/#program-1","title":"Program 1","text":"<p>Write a program to convert 4-digit BCD number to HEXADECIMAL number and store the result in memory.</p> <pre><code>.MODEL SMALL\n.STACK 20\n\n.DATA ; Data segment start here\nORG 1000H ; Memory address initialization\nBCD DW 1234H ; 4-digit BCD number is 1234H, here BCD is a variable\nHEX DW 0 ; HEX is a variable to store the results\n\n.CODE ; Code start here\nSTART:\nMOV AX, @DATA ; Initializing DS: segment register\nMOV DS, AX\n\nMOV BX, 0001H ; Weight for LSD, storing 0001H into BX register (once position)\nCALL BCD2BIN ; calling BCD2BIN procedure. See the written procedure in the\n\nMOV BX, 000AH ; Weight for 2nd digit, Storing 000AH in to BX register (10th Position)\nCALL BCD2BIN ; calling BCD2BIN procedure. See the written procedure in the last lines\n\nMOV BX, 0064H ; Weight for 3rd digit, Storing 0064H in to BX register (100th Position)\nCALL BCD2BIN ; calling BCD2BIN procedure. See the written procedure in the last lines\n\nMOV BX,03E8H ; Weight for MSD, Storing 03E8H in th BX register (1000th Position)\nCALL BCD2BIN ; calling BCD2BIN procedure. See the written procedure in the last lines\n\nINT 3 ; Breakpoint interrupt\n\nBCD2BIN PROC NEAR ; BCD2BIN is a procedure called 4 times in the main program\nMOV AX, BCD ; Subroutine multiplies digits with respective weights and adds the partial\n; product to get equivalent HEX moving the desired digit LSD position\n\nAND AX, 000FH ; ANDing operation with BCD value i.e 1234\nMUL BX ; multiplies BX with AX\nADD HEX, AX ; add AX value with Hex variable, initially Hex variable have 0\nMOV CL, 04 ; moving 04 to CL\nROR BCD, CL ; Rotate Right\nRET ; RET instruction stands for return, used at the end of the procedures\nBCD2BIN ENDP ; end the procedure\n\nEND START\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/04/#program-2","title":"Program 2","text":"<p>Write a program to convert the given HEXADECIMAL digit to ASCII byte and store the result in memory.</p> <pre><code>.MODEL SMALL\n.STACK 20\n\n.DATA ; Data segment start here\nORG 1000H ; Memory address initialization\nHex_Digit DB 38H ; Given Hex value is 38H, Hex_Digit is a variable\nASCII DB ? ; ASCII is the variable to store the ASCII equivalent Hex of 38H\n\n.CODE ; Code start here\nSTART:\nMOV AX, @DATA ; Initializing DS: segment register\nMOV DS, AX\n\nMOV AL, Hex_Digit ; Moving Hex_Digit value 38H to AL register\nCMP AL, 3AH ; compare 38 with 3A, To see whether it is between 30H to 39H\n\n; or 41H to 46H\n\nJC SUB30 ; if carry generated then jump to location SUB30\nSUB AL, 07H ; if no carry then subtract 07H with AL value\nSUB30: ; User defined location name\nSUB AL,30H ; subtract 30H with AL\nMOV ASCII, AL ; Store the AL value into Hex_Digit variable\n\nINT 3 ; Breakpoint interrupt\nEND START\ncode ends\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/04/#program-3","title":"Program 3","text":"<p>Write a program to display the hexadecimal byte 45H on the screen using DOS interrupts.</p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/04/#easy-version","title":"Easy Version","text":"<pre><code>.model small\n.stack 20\n\n.code\nstart:\n\nmov ah, 02h\n\nmov dl, 34h\nint 21h\n\nmov dl, 35h\nint 21h\nmov ah, 4ch\nint 21h\n\nint 3\nend start\ncode ends\n</code></pre> <pre><code>.MODEL SMALL\n.STACK 20\n\n.CODE\nSTART: ; here no data segment, using DOS interrupts\n\nMOV AL, 45H ; Number to be Display on screen, store the 45H in AL\nMOV BL, AL ; Moving 45H to BL\n\nAND AL, 0F0H ; Get upper digit (nibble), AND operation to 45\nROR AL, 4 ; Rotate to Right\n\nCALL HEXASC ; Convert from hex to ASCII\nMOV DL, AL ; moving AL to DL\nMOV AH, 02 ; Function code to display single character\nINT 21H ; DOS interrupt 21H\n\nMOV AL, BL ; Moving BL to AL\nAND AL, 0FH ; Get lower digit by ANDing AL\nCALL HEXASC ; call HEXASC Procedure\n\nMOV DL, AL ; move AL to DL\nMOV AH, 02 ; 02 to AH to Display second digit\nINT 21H ; DOS interrupt 21H\n\nMOV AH, 4CH ; causes the process to terminate\nINT 21H ; DOS interrupt 21H\n\nHEXASC: ; HEX TO ASCII procedure start\nCMP AL,0AH ; compare 38 with 3A ,To see whether it is between 30H to 39H\n; or 41H to 46H,\nJB NUM ; Jump if Carry\nADD AL,07 ; For A-F, add 37H\nNUM: ; jump address reference\nADD AL,30H ; For 0-9, add 30H\nRET ; RET stands for return, used at the end of the procedures\n\nEND START\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/04/#program-4","title":"Program 4","text":"<p>Write a program to input two single-digit hex numbers from keyboard and display their product on the screen.</p> <pre><code>.MODEL SMALL\n.STACK 20\n.CODE\nSTART:\nCALL READKB ; Read Keyboard Procedure Call\nMOV BL,AL ; move AL to BL\nCALL NXTLINE ; Nextline procedure call\nCALL READKB ; Read Keyboard Procedure Call\nMUL BL ; Multiply BL with AL\nMOV BL, AL ; move AL to BL\nCALL NXTLINE ; Nextline procedure call\nCALL DISP ; Call DISP procedure\nMOV AH, 4CH ; causes the process to terminate\nINT 21H ; DOS interrupt 21H\n\nREADKB PROC NEAR ; Read Keyboard Procedure Start here\nMOV AH,01 ; Accepting number from keyboard\nINT 21H ; DOS interrupt 21H\nCALL ASCHEX ; Procedure to Ascii to Hex\nRET ; RET used at the end of the procedures\nREADKB ENDP ; Read Keyboard Procedure ends here\n\nASCHEX PROC NEAR ; ASCII to Hex procedure start here\nCMP AL, 3AH ; compare AL value with 3AH\nJC SUB30 ; jump if carry, Sub30 is address\nSUB AL, 07H ; no carry the subtract 07H with AL\nSUB30: ; In compare carry generates, SUB30: start executes\nSUB AL,30H ; ASCII to hex conversion\nAND AL,0FH ; AND operation with 0Fh with AL value\nRET ; RET used at the end of the procedures\nASCHEX ENDP ; Ascii to Hex procedure ends here\n\nNXTLINE PROC NEAR ; NEXTLINE procedure start here\nMOV AH, 2 ;\nMOV DL, 0AH ; Line feed\nINT 21H ; DOS interrupt 21H\nMOV DL,0DH ; Carriage return\nINT 21H ; DOS interrupt 21H\nRET ; RET used at the end of the procedures\nNXTLINE ENDP ; NEXTLINE Procedure ends here\n\nDISP PROC NEAR ; DISP procedure start here\nMOV AL, BL ; Moving BL to AL\nAND AL, 0F0H ; AND operation of AL and 0F0h\nROR AL, 4 ; rotate right AL, 4 times\nCALL HEXASC\nMOV DL, AL ; Moving AL contents to DL\nMOV AH, 02 ;\nINT 21H ; DOS interrupt 21H\nMOV AL, BL ; Moving BL contents to AL\nAND AL, 0FH ; AND operation of AL and 0Fh\nCALL HEXASC\nMOV DL, AL ; Moving AL contents to DL\nMOV AH, 02 ;\nINT 21H ; DOS interrupt 21H\nRET ; RET used at the end of the procedures\nDISP ENDP ; DISP procedure ends here\n\nHEXASC PROC NEAR ; HEXASC, Hex to Ascii procedure start here\nCMP AL, 0AH ; compare AL with 0AH\nJB NUM ; i\nADD AL, 07 ; add 07 to AL\nNUM:\nADD AL, 30H ; Add 30h to AL\nRET ; RET instruction used at the end of the procedures\nHEXASC ENDP ; HEXASC procedure ends here\n\nEND START\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/04/#assignment","title":"Assignment","text":"<p>Write a program to accept a character from keyboard and display its ASCII equivalent value on the screen.</p> <pre><code>.model small\n.stack 20\n.code\nstart:\ncall readkb\nmov bl, al\ncall nxtline\ncall disp\nmov ah, 4ch\nint 21h\n\nreadkb proc near\nmov ah, 01\nint 21h\nret\nreadkb endp\n\nnxtline proc near\nmov ah, 2\nmov dl, 0Ah\nint 21h\nmov dl, 0dh\nint 21h\nret\nnxtline endp\n\ndisp proc near\nmov al, bl\nand al, 0F0h\nror al, 4\ncall hexasc\nmov dl, al\nmov ah, 02\nint 21h\nmov al, bl\nand al, 0Fh\ncall hexasc\nmov dl, al\nmov ah, 02\nint 21h\nret\ndisp endp\n\nhexasc proc near\ncmp al, 0Ah\njb num\nadd al, 07\nnum:\nadd al, 30h\nret\nhexasc endp\n\nend start\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/","title":"05","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#dos","title":"DOS","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#display-number","title":"Display Number","text":"<pre><code>mov dl, 34h\nmov ah, 02h\nint 21h\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#display-string","title":"Display String","text":"<pre><code>lea dx, msg\nmov ah, 09h\nint 21h\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#reading","title":"Reading","text":"<pre><code>readkb proc near\n    mov ah, 01h\n    int 21h\n\n    cmp al, 3Ah\n    jc number\n\n    sub al, 07h\n\n    number:\n        sub al, 30\n\n    ret\nreadkb endp\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#program-1","title":"Program 1","text":"<p>Write a program to transfer the given string from source to destination using string instruction and also display the destination string.</p> <pre><code>.MODEL SMALL\n.STACK 20\n.DATA\nSRCSTR DB 'ELECTRONICS' ; Source String 'ELECTRONICS'\nLEN DW $-SRCSTR ; String Length\nMSG DB 'The Transferred String=' ; MSG is variable to store the transferred string\nDSTSTR DB 40 DUP ('$') ; Destination string\n\n.CODE ; code start\nSTART:\nMOV AX, @DATA ; Data segment start here\nMOV DS, AX ; Move AX to DS\nMOV ES, AX ; Move AX to ES\n\nMOV CX, LEN ; Move length of string to CX register\nLEA SI, SRCSTR ; Load Effective Address of source string to SI\nLEA DI, DSTSTR ; Load Effective Address of Destination to DI\nCLD ; for auto increment of SI and DI\nREP MOVSB ; Repeat prefix to MOVSB, Move data as bytes\nLEA DX, MSG\n\nMOV AH, 09 ; Displays a message terminated by $\nINT 21H ; DOS interrupt 21H\n\nMOV AH, 4CH ; program termination\nINT 21H ; DOS interrupt 21H\n\nEND START\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#program-2","title":"Program 2","text":"<p>Write a program to read two digit decimal number using keyboard and search whether the number is present in an array or not. Display suitable message.</p> <pre><code>.MODEL SMALL\n.STACK 20\n.DATA\nARRAY DB 35H, 56H, 82H, 89H, 90H, 23H, 12H, 51H, 88H ; Input array\nLEN DW $-ARRAY ; Length of the array value\nMSG1 DB 0DH, 0AH, ' Enter two digit numbers: $' ; Message one for input\nMSG2 DB 0DH, 0AH, ' The number is present $' ; Message to present output\nMSG3 DB 0DH, 0AH, ' The number is not present $' ; Message to present output\n.CODE\nSTART:\nMOV AX, @DATA ; Data segment start here\nMOV DS, AX\nMOV ES, AX ; MOVE AX, TO Extra Segment\n\nMOV CX, LEN ; load the length of the array to CX\nLEA DX, MSG1 ; Load effective address to DX\nMOV AH, 09 ; To display MSG1\nINT 21H ; DOS interrupt 21H\n\nCALL READKB ; Call to READKB procedure\nROR AL, 4 ; shifting the digit to MSD position, by rotating Right by 4\n; times of AL\nMOV BL, AL ; Move AL value to BL\n\nCALL READKB ; Call the READKB procedure\nADD AL, BL ; To make 2-digit number\nLEA DX, MSG2 ; Load effective address to DX\nLEA DI, ARRAY ; Load the effective address of array to DI\nCLD ; Clear Direction Flag\nREPNE SCASB ; Compares AL with memory pointed by DI\nJE GO ; conditional jump when zero flat equal to 1\nLEA DX, MSG3 ; Load Effective Address of MSG3 to DX\n\nGO:\nMOV AH, 09 ; To display the output\nINT 21H ; DOS interrupt 21H\nMOV AH, 4CH ; To terminate\nINT 21H ; DOS interrupt 21H\n\nREADKB PROC NEAR\nMOV AH,01 ; Accepting number from keyboard\nINT 21H ; DOS interrupt 21H\nCMP AL, 3AH ; compare AL with 3AH\nJC SUB30 ; Jump if carry\nSUB AL, 07H ; subtract 07H with AL\n\nSUB30:\nSUB AL, 30H ; ASCII to hex conversion\nRET ; RET instruction used at the end of the procedures\nREADKB ENDP ; end to READKB procedure\n\nEND START ; end to start\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#program-3","title":"Program 3","text":"<p>Write a program to read a string using DOS interrupts, reverse the entered string and display the same on the screen. Use MACRO for display.</p> <pre><code>.MODEL SMALL\n.STACK 20\n\nDISP MACRO MSG ; Macro Declaration, DISP is the name of the Macro.\nMOV AH, 09H ; To display message\nMOV DX, OFFSET MSG ; Load the MSG offset address to DX\nINT 21H ; DOS interrupt 21H\nENDM ; End Macro\n\n.DATA ; Data segment start here\nMSG1 DB 0DH, 0AH, 'Input a string:$' ; 0DH,0AH are carriage Return &amp; Line Feed\n\n; $ to terminate\nSRC DB 80 ; Maximum size of the string\nDB ? ; Actual size of the string\nDB 30 DUP (?) ; To store actual string\nMSG2 DB 0DH, 0AH, 'The reversed string is:' ; MSG2 to store the reversed string is\nREV DB 30 DUP (?) ; To store the reversed string\n\n.CODE ; code start here\nSTART:\nMOV AX, @DATA ; Data segment start here\nMOV DS, AX\nMOV ES, AX ; moving AX to ES\nDISP MSG1 ; MSG1 is a parameter to MSG of macro DISP, it displays\n; input a string:\nMOV DX, OFFSET SRC ; move Source offset address to DX\nMOV AH, 0AH ; Function code to read a string\nINT 21H ; DOS interrupt 21H\nMOV SI, OFFSET SRC+2 ; increment the source offset by 2 and store the address\n; to SI\nMOV DI, OFFSET REV-1 ; decrement the reverse offset address by 1 and store the\n; results in DI\nMOV CL, SRC+1 ; Length of the string, here SRC is size of the string, it is\n; incremented by 1\nMOV CH, 00 ; make CH=0\nADD DI, CX ; Add cout value to DI\nMOV BYTE PTR [DI+1], '$' ; End character for function 09H\nCLD ; Clear Direction Flag\n\nNEXT:\nMOVSB ; move string of words depending on CLD, SI,DI\n; automatically increase or decrease by 2\n\nSUB DI, 0002 ; subtract 0002 with DI\nLOOP NEXT\n\nDISP MSG2 ; Display message 2\nMOV AH, 4CH ; program termination\nINT 21H ; DOS interrupt 21H\n\nEND START\n</code></pre> <p></p>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/05/#assignment","title":"Assignment","text":"<p>Write a program to compare two arrays. If they are same then display 'IDENTICAL', if not, display \u2018NOT IDENTICAL\u2019. Make use of the string instruction CMPSB.</p> <p>Tried, but did not work correctly</p> <pre><code>.model small\n.stack 20\n\n.data\narray1 db 'Electronic$'\narray2 db 'Electronics$'\n\nequalMsg do 'Identical$'\nunequalMsg do 'Not Identical$'\n\n.code\nstart:\nmov ax, @data\nmvo ds, ax\nmov es, ax\n\nlea si, array1\nlea di, array2\n\ncmpsb\njz equal\njnz unequal\n\nequal:\nmov ah, 09h\nmov dx, offset equalMsg\nint 21h\nmov ah, 4Ch\nint 21h\n\nunequal:\nmov ah, 09h\nmov dx, offset unequalMsg\nint 21h\nmov ah, 4Ch\nint 21h\n\nend start\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/06/","title":"06","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/06/#program-1","title":"Program 1","text":"<p>Write a program to create a file and write text data into it using DOS interrupts.</p> <pre><code>.MODEL SMALL\n.STACK 20\nPRINT MACRO MSG ;Macro Declaration as print\nMOV AH, 09H ;DOS function 09h: display a string of ;characters whose\n\noffset is specified by DX.\n\nLEA DX, MSG ;load effective address of MSG to DX\nINT 21H\nENDM\nREAD MACRO STR ;Macro declaration as read\nLEA DX, STR ;load the effective address of STR to DX\nMOV AH, 0AH ;0AH = Reading a string from keyboard\nINT 21H\nENDM\n.DATA\nMSG1 DB 0DH, 0AH, 'Enter a filename:$'\nMSG2 DB 0DH, 0AH, 'File is created$'\nMSG3 DB 0DH, 0AH, 'Error in File creation$'\nMSG4 DB 0DH, 0AH, 'Enter a text:$'\nMSG5 DB 0DH, 0AH, 'Error in File opening$'\nMSG6 DB 0DH, 0AH, 'Error in writing$'\nMSG7 DB 0DH, 0AH, 'Creating and writing successful$'\nFNAME DB 80\nDB ?\nDB 80 DUP(0)\nTEXT DB 80\nDB ?\nDB 80 DUP(?)\n\n.CODE\nSTART:\nMOV AX,@DATA\nMOV DS, AX\nMOV ES, AX\nPRINT MSG1\nREAD FNAME ;Reading a file name\nLEA SI,FNAME+2 ;FNAME is add of file name,\n;FNAME+1 is add of file length\nMOV CL,FNAME+1 ;Getting the length of file name\nMOV CH,00 ;clear the ch register\nADD SI,CX ;To move SI at next location\nMOV BYTE PTR[SI],00 ;Terminating file name by Zero\nLEA DX,FNAME+2 ;Starting address to write text in file\nMOV AH,3CH ;Function code to create file\nMOV CX,0000H ;File attributes of the new file\nINT 21H\nJNC SUCC1 ;If file creation is success CY=0\nPRINT MSG3 ;Error msg, if file is not created\nJMP EXIT\nSUCC1:\nPRINT MSG2 ;Success msg of file creation\nPRINT MSG4 ;msg to write text in created file\nREAD TEXT ;Reading text to be written to file\nMOV AH,3DH ;Function code to open file\nMOV AL,02H ;To open file in read/write mode\nLEA DX,FNAME+2\nINT 21H\nJNC SUCC2 ;If file open is success CY=0\nPRINT MSG5 ;error msg in opening the file\nJMP EXIT\nSUCC2:\nMOV BX,AX ;File handling returned during open\nMOV AH,40H ;Function code to write text\nMOV CH, 00H ;Number of characters to written into the file\n\nMOV CL,TEXT+1\nLEA DX,TEXT+2\nINT 21H\nJNC SUCC3 ; If file writing is success CY=0\nPRINT MSG6\nMOV AH,3EH ;Function code to close the file.\nINT 21H\nJMP EXIT\nSUCC3:\nPRINT MSG7 ;Disp msg, Creation and writing successful.\nEXIT:\nMOV AH,4CH ;To terminate the program\nINT 21H\nEND START\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/06/#program-2","title":"Program 2","text":"<p>Write a program to read system time and display at the center of the screen</p> <pre><code>.MODEL SMALL\nSTACK 20.DATA\nMS DB \"PRESENT TIME IS: $\"\n.CODE\nSTART:\nMOV AX,@DATA\nMOV DS,AX\nMOV AH,00 ; Function code to clear screen\nMOV AL,03H ; text video mode\nINT 10H ; Calling BIOS interrupts\nMOV AH,02 ; Function code to set Cursor position.\nMOV BH,0 ; video page number\nMOV DH,12 ; Row number\nMOV DL,30 ; Column number\nINT 10H ; Calling BIOS interrupts\nLEA DX,MS ; Display the msg\nMOV AH,09\nINT 21H\n\nMOV AH,2CH ; Function code to read the system time, Hour in CH, ; Minute in\n\nCL, Second in DH\n\nINT 21H\nMOV AL,CH ; To display Hour\nCALL DISP ; Calling DISP procedure for displaying Hour\nMOV DL,':' ; to display \u2018:\u2019 after Hour\nMOV AH,02 ; display the content of DL\nINT 21H\nMOV AL,CL ; To display Minute\nCALL DISP ; Calling DISP procedure for displaying Minute\nMOV DL,':' ; to display \u2018:\u2019 after Minute\nMOV AH,02 ; WRITE CHARACTER TO STANDARD OUTPUT\nINT 21H\nMOV AL,DH ; To display Second\nCALL DISP ; Calling DISP procedure for displaying second\nMOV AH,02 ; WRITE CHARACTER TO STANDARD OUTPUT\nMOV BH,0 ; video page number\nMOV DH,24 ; ROW\nMOV DL,00 ; COLUMN\nINT 10H ; Calling BIOS interrupts\nMOV AH,4CH ; Exit the program to OS\nINT 21H\nDISP PROC NEAR\nAAM ; stands for ASCII adjust for Multiplication or BCD\n\n; Adjust after Multiply\n\nADD AX,3030H\nMOV BX,AX ; move AX to BX\nMOV DL,BH ; move BH to DL\nMOV AH,02 ; WRITE CHARACTER TO STANDARD OUTPUT\nINT 21H\nMOV DL,BL ; move BL to DL\nMOV AH,02 ; WRITE CHARACTER TO STANDARD OUTPUT\nINT 21H\nRET ; Return\nENDP ; end procedure\nEND START\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/06/#program-3","title":"Program 3","text":"<p>Write a program to read system date and display in this format DD-MM-YEAR.</p> <pre><code>.MODEL SMALL\n.STACK 20\nPRINT MACRO MSG\nMOV AH,09H\nMOV DX,OFFSET MSG\nINT 21H\nENDM\n.DATA\nDAY DB ?, ?, '-'\nMONTH DB ?, ?, '-'\nYEAR DB ?, ?, ?, ?, '$'\n.CODE\nSTART:\nMOV AX,@DATA\nMOV DS,AX\nMOV ES,AX\nMOV AH,2AH ; Function code to get Date\nINT 21H ; Call DOS service\nPUSH CX ; Saving year\nPUSH DX ; Saving Day and Month\nMOV AL,DL ; move DL to AL\nLEA SI,DAY ; load effective address of Day to SI\nMOV AH,00H ; Move 00H to AH\nCALL CONV ; To call CONV subroutine\nPOP DX ; Putting ASCII value in memory\nMOV AL,DH ; move DH to AL\nLEA SI,MONTH ; Load the effective address of Month to SI\nMOV AH,00H ; move 00H to AL\nCALL CONV ; To convert month to ASCII\nPOP AX ; Putting ASCII value in memory\nLEA SI,YEAR ; Load effective address of YEAR to SI\nCALL CONV ; To convert year to ASCII\n\nPRINT DAY ; To display Date\nMOV AH,4CH ; Exit program\nINT 21H\nCONV PROC NEAR ; Procedure convert Hexadecimal\nMOV CX,0000H ; Day, Month and Year to BCD\nMOV BX,000AH ; and ASCII for display\nNEXT:\nMOV DX,0000 ; move 0000 to DX\nDIV BX ; Separating the digits\nADD DL,30H ; Converting BCD to ASCII\nPUSH DX\nINC CX ; increment CX\nCMP AX,000AH\nJGE NEXT\nADD AL,30H\nMOV [SI],AL\nUP:\nPOP AX ; Putting ASCII value in memory\nINC SI ; increment SI\nMOV [SI],AL\nLOOP UP\nRET ; return\nCONV ENDP ; end of the procedure conv\nEND START\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/07/","title":"07","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/07/#7-segment-led-interfacing","title":"7-Segment LED Interfacing","text":"<pre><code>DATA SEGMENT \nPORTA EQU 00H\nPORTB EQU 02H\nPORTC EQU 04H\nPORT_CON EQU 06H \nDATA ENDS \n\nCODE SEGMENT \nMOV AX, DATA \nMOV DS, AX \nORG 0000H \nSTART: \nMOV DX, PORT_CON  MOV AL, 10000000B  OUT DX, AL \nMOV SI, 0 \nMOV DI, 0 \nL0: MOV CX, 1FFFH  L1: MOV AL, S1[SI]  MOV DX, PORTA  OUT DX, AL \nLOOP L1 \nINC SI \nCMP SI, 16 \nJL L0 \nMOV DX, PORT_CON  MOV AL, 10000000B  OUT DX, AL \nJMP START \nORG 1000H \nS1 DB 11000000B \nDB 11111001B \nDB 10100100B \nDB 10110000B \nDB 10011001B \nDB 10010010B \nDB 10000010B \nDB 11011000B \nDB 10000000B \nDB 10010000B \nDB 10001000B \nDB 10000011B \nDB 11000110B \nDB 10100001B \nDB 10000110B \nDB 10001110B \nCODE ENDS \nEND\n</code></pre>"},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/08/","title":"08","text":""},{"location":"2_Core/MicroProcessors_%26_Interfacing/Practicals/08/#stepper-motor-interfacing","title":"Stepper Motor Interfacing","text":"<pre><code>DATA SEGMENT\nPORTA EQU 00H\nPORTB EQU 02H\nPORTC EQU 04H\nPORT_CON EQU 06H\nDATA ENDS\nCODE SEGMENT\nMOV AX, DATA\nMOV DS, AX\nORG 0000H\nSTART:\nMOV DX, PORT_CON\nMOV AL, 10000000B\nOUT DX, AL\nMOV SI, 0\nMOV DI, 0\nLL0:MOV CX, 2FFFH\nLL1:MOV AL, S2[DI]\nMOV DX, PORTC\nOUT DX, AL\nLOOP LL1\nINC DI\nCMP DI, 4\nJL LL0\nJMP START\nORG 1000H\nS2 DB 1101B\nDB 1011B\nDB 0111B\nDB 1110B\nCODE ENDS\nEND\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/","title":"Object-Oriented Programming","text":"Class Instructor Lecture Dr. Pranav M. Pawar Tutorial Dr. Pranav M. Pawar Practical Dr. Sujala D. Shetty <p>This course is about Object Oriented Programming concepts using Java.</p>"},{"location":"2_Core/Object_Oriented_Programming/#features-of-oop","title":"Features of OOP","text":"<ol> <li>Data hiding/abstraction</li> <li>function overloading</li> <li>Inheritance</li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/","title":"01 Intro","text":""},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#java-basics","title":"Java Basics","text":"<p>4 bit precision - returns 4 bits for numbers by default</p> <p>hexadecimal is small characters A B a b</p> <p>JDK 16</p> <p><code>.java</code> is the file extension</p> <p>java is case-sensitive</p> <p>file name should be the name of the class containing the main function (TesterClass)</p> <p>main method should always be <code>public static void main(String[] args)</code></p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#stages-of-java-program","title":"Stages of Java Program","text":"<pre><code>flowchart LR\ns[Source Code] --&gt;\n|Compiled,&lt;br/&gt;Interpreted| b[Byte Code] --&gt;\n|Executed| Output</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#compilation","title":"Compilation","text":"<p><code>javac file.java</code></p> <p>Program gets compiled and intrepreted to a .class file bytecode</p> <p>Bytecode offers platform independence</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#execution","title":"Execution","text":"<p><code>java file</code> (no extension)</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#compilation-execution-in-one-go","title":"Compilation-Execution in one-go","text":"<p>If entire program is contained in a single class, then you just have to use <code>java abc.java</code> (just a single command)</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#basic-program","title":"Basic Program","text":"<pre><code>class Tester\n{\n  public static void main(String args[]) // String is a class in java\n    // or (String ... args)\n  {\n    System.out.print(\"hello world\"); // same line\n\n    System.out.println(\"hello world\"); // new line\n  }\n}\n</code></pre> <p><code>print()</code> and <code>println()</code> belong to outstream of System class</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#main","title":"main()","text":"<p>to pass mutiple arguments, we can also use <code>main(String ... args)</code></p> <p>Optional keywords</p> <ul> <li> <p>final = constant in c</p> </li> <li> <p>synchronized = for threading</p> </li> <li> <p>strictfp = strict floating point operations</p> </li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#errors","title":"Errors","text":"<p>Runtime error: <code>NoSuchMethodError:main</code> when there is a problem inside main() Eg: [ ] missing</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#data-types","title":"Data Types","text":"<p>Float ends with f: 34.342f</p> <p>Double ends with d: 34.342d</p> <p>double 0x443 (will print 104, cuz 443 is taken as hex) (no need of d at the end)</p> <pre><code>flowchart TB\nTypes --&gt; primitive &amp; non-primitive\n\nprimitive --&gt; void &amp; boolean &amp; char &amp; int &amp; float &amp; double &amp; String\n\nnon-primitive --&gt; Arrays &amp; Structures &amp; Classes &amp; Lists</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#table-from-slides","title":"Table (from slides)","text":"Data Type Default Value Memory (bytes) boolean false 1 bit char \\u0000 1 int 0 4 float 0.0f 4 double 0.0d 8 String null (without \"\") 0"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#control-statements","title":"Control Statements","text":""},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#if-else","title":"if-else","text":"<p>same as c</p> <pre><code>if (cond)\n  statement;\nelse if (cond)\n  statement;\nelse\n  statement;\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#switch","title":"switch","text":"<pre><code>switch(var)\n{\n  case 1: \n    statement; \n    break;\n  case 2: \n    statement;\n    break;\n  default: \n    statement;\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#loops","title":"Loops","text":"<pre><code>while(cond)\n{\n  statement;\n}\n\ndo {\n  statement;\n} while (cond);\n\nfor(init, cond, upd)\n  statement;\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#input","title":"Input","text":"<pre><code>import java.util.Scanner;\n\npublic class Tester\n{\n  public static void main(String[] args)\n  {\n    Scanner inp = new Scanner(System.in);\n    // variable to access input stream\n\n    int x = inp.nextInt();\n  }\n}\n\n// scanner methods\n\n//check\ninp.hasNextLine();\ninp.hasNextInt();\ninp.hasNextFloat();\ninp.hasNextDouble();\n\n//input\nString line = inp.nextLine();\nString entireThing = inp.next();\nint i = inp.nextInt();\nfloat f = inp.nextFloat();\ndouble d = inp.nextDouble();\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#operators","title":"Operators","text":""},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#arithmetic","title":"Arithmetic","text":"<p>\\(+ - * / \\%\\)</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#unary","title":"Unary","text":"<p>\\(+ \\quad - \\quad ++x \\quad y-- \\quad !\\)</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#conditional","title":"Conditional","text":"<p>&amp;&amp;</p> <p>||</p> <p>?: ternary</p> <pre><code>var = cond?tVal:fVal;\n\nint x = (x&lt;5)?5:0;\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#bitwisebitshift","title":"Bitwise/Bitshift","text":"Operator Name Function Example ~ Bitwise Complement y = ~x &lt;&lt; left shift Multiply by 2<sup>n</sup> x&lt;&lt;2 &gt;&gt; right shift Divide by 2<sup>n</sup> x&gt;&gt;2 &gt;&gt;&gt; unsigned right shift Divide by 2<sup>n</sup> x&gt;&gt;&gt;3 &amp; Bitwise AND perform AND bit-by-bit x&amp;y ^ Bitwise exclusive OR perform OR bit-by-bit x^y \\vert Bitwise inclusive OR perform OR bit-by-bit x \\vert y"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#type-casting","title":"Type Casting","text":"<p>changing the data type of variable during runtime for a momentary purpose</p> <pre><code>Integer.parseInt(); // string to int\nInteger.toString(); // int to string\n\nFloat.parseFloat();\nFloat.toString();\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#method-overloadingoverriding","title":"Method Overloading/Overriding","text":"<p>Method Overloading: Multiple methods having the same name but different functionality Static polymorphism, as compiler knows overloading is happening beforehand</p> <p>Operator overloading: same operator symbol with different functionality Static polymorphism, as compiler knows overloading is happening beforehand eg: - is used for subtraction and also for negative numbers, % is used for mod and for percentages</p> <p>Method Overriding: parent and child class with same function name, but different functionality Dynamic polymorphism, as compiler does not know beforehand, and overriding occurs during run-time</p> <p>For method overloading, the function signature/argument/parameter list of the methods should be differ in atleast one of the following ways</p> <ol> <li>number of parameters</li> <li>data type of parameters</li> <li>order of data type of parameters</li> </ol> <p>Two functions of the same name but different return type is not valid</p> <pre><code>int add(int, int);\nFloat add(int, int);\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#command-line-argument","title":"Command Line Argument","text":"<p>An information that directly follows program's name on the command line when it is executed.</p> <p>Arguments are stored as strings in the String args[] argument of the main().</p> <p>Each argument should be separated by (space)</p> <pre><code>java filename 10 134 3 // command line argument\n\nclass filename\n{\n  public static void main(String args[])\n  {\n    for (int i = 0; i&lt;args.length(); i++)\n    {   \n      int x = Integer.parseInt(args[i]);\n    }\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#keywords","title":"Keywords","text":""},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#static","title":"<code>static</code>","text":"<p>only one instance</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#variable","title":"variable","text":"<p>variable that acts as common property of all objects</p> <p>gets memory only once in the class area at time of class loading</p> <p><code>classname.var</code>, <code>object.var</code></p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#method","title":"method","text":"<p>belongs to class itself, not the object of the class</p> <p>This is why main() is declared as static: to avoid the need for calling it through an object</p> <p>only static methods can change the value of a static variable</p> <p>they cannot change values of non-static variables</p> <p><code>classname.method()</code></p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#block","title":"block","text":"<p>gets executed before main</p> <p>useful to initialize static data members</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#class","title":"class","text":"<p>only a nested class can be static</p> <p>methods inside it will also be static</p> <pre><code>class Student\n{\n  static int x = 5;\n  public static void change()\n  {\n    x = 15;\n  }\n  static class Nested\n  {\n    public void nest() // static because it is inside a static class\n    {\n      x = 2;\n    }\n  }\n\n}\nclass Tester\n{\n  static\n  {\n    System.out.println(\"Static block executed\");\n  }\n  public static void main(String args[])\n  {\n    Student s = new Student();\n        System.out.println(s.x); // 5\n\n    Student.change();\n        System.out.println(s.x); // 10\n\n    Student.Nested n = new Student.Nested();\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#final","title":"<code>final</code>","text":""},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#variable_1","title":"variable","text":"<p>value is fixed</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#method_1","title":"method","text":"<p>cannot override it</p> <p>method overriding is when parent and subclass' methods have the same name</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#class_1","title":"class","text":"<p>cannot extend/inherit it</p> <pre><code>final class Student\n{\n  final int x = 5;\n  public static void change()\n  {\n    x = 15; // compiler error\n  }\n  final void override()\n  {\n    System.out.println(\"hello\"); \n  }\n}\n\nclass Life extends Student // compiler error\n{\n  final void override()\n  {\n    System.out.println(\"hi\"); // compiler error\n  }\n}\n\nclass Tester\n{\n  public static void main(String args[])\n  {\n    Student s = new Student();\n        System.out.println(s.x); // 5\n\n    Student.change();\n        System.out.println(s.x); // 10\n\n    Student.Nested n = new Student.Nested();\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#packages","title":"Packages","text":"<p>is a collection of classes</p> <p>similar to (not same as) header files in C</p> <p><code>java.lang</code> is the default package in java; it is imported by default</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#importing","title":"Importing","text":"<p><code>import packagename.*</code>, <code>import packagename.ClassName</code></p> <p>can contain</p> <ul> <li>classes</li> <li>subpackages</li> <li>interfaces</li> </ul> <p>(Libraries in C/C++ can only contain functions)</p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#uses","title":"Uses","text":"<ol> <li>prevent naming conflicts    allows to use the same class name multiple times in different packages</li> <li>simplify modular usage of classes</li> <li>control access using access specifier</li> <li>data encapsulation/hiding</li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#types","title":"Types","text":"<ol> <li>built-in</li> <li>java.lang       default package, primitive data types, math operations</li> <li>java.io       read/write from files/device</li> <li>java.util       Data structures</li> <li>java.applet</li> <li><code>java.awt</code></li> <li><code>java.swing</code></li> <li>java.net</li> <li>user-defined</li> <li>creating<ol> <li>create a directory with name of package</li> <li>create <code>MyClass.java</code> in directory with the the first statement as <code>package packagename</code></li> </ol> </li> <li>compiling<ol> <li><code>javac MyClass.java</code></li> <li><code>javac -d . MyClass.java</code></li> </ol> </li> <li>using       the main file should be inside the package folder<ol> <li><code>import myPackage1.MyClass</code></li> </ol> </li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#accessor-method","title":"Accessor Method","text":"<p>methods for accessing/getting data</p> <p>should always return data; hence return type shouldn't be void; display() isn't exactly an accessor</p> <p><code>public returnType getData()</code></p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#mutator-method","title":"Mutator Method","text":"<p>Methods for changing/setting data</p> <p>should be void</p> <p><code>public void setData(parameter)</code></p>"},{"location":"2_Core/Object_Oriented_Programming/01_Intro/#math-class","title":"Math Class","text":"<p>it is inbuilt in <code>java.lang</code> itself</p> <pre><code>double y = Math.sqrt(x),\n    t =  Math.pow(x, n);\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/","title":"02 Classes","text":""},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#class","title":"Class","text":"<p>collection of data and related functions into a single entity</p> <p>contains</p> <ul> <li>fields/properties - variables</li> <li>methods - functions<ul> <li>constructor</li> <li>custom</li> </ul> </li> <li>nested classes</li> </ul> <p>Naming convention is TitleCase</p>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#object","title":"Object","text":"<p>Instance of a class</p> <p>declared using <code>new</code> keyword</p> <p>. operator is called object reference operator / relationship operator</p> <pre><code>Classname var = new Constructor();\n</code></pre> <pre><code>class Student\n{\n  String name;\n  int age;\n  Student(String aName, int aAge) // constructor\n  {\n    name = aName;\n    age = aAge;\n  }\n  void display()\n  {\n    System.out.println(name + age); // abc10\n  }\n}\npublic class StudentTester\n{\n  public static void main(String args[])\n  {\n        Student s1 = new Student(\"abc\", 10);\n        s1.display(); \n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#instanceof-operator","title":"<code>instanceof</code> operator","text":"<p>Checks if an object belongs to a particular class</p> <p>returns Boolean true/false</p> <p>Syntax: <code>(object reference var) instanceof (class/interface type)</code></p> <pre><code>boolean result = varName instanceof String;\nboolean result = varName instanceof CustomClass;\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#object-reference","title":"Object reference","text":"<p>Just assigning one object name to another object name just assigns the pointer location; doesn't copy the data over</p> <pre><code>Student s1 = new Student(\"abc\" , 10);\ns1.display(); // abc10\n\nStudent s2 = s1;\n\ns2.setAge(20); \ns1.display(); // abc20\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#constructor","title":"Constructor","text":"<p>function that gets invoked during object creation</p> <p>no return type Not even void, as constructor kinda returns object of class</p> <p>If the formal and actual parameter have the same name, then it will output the default values</p> <ul> <li>null for String</li> <li>0 for int</li> <li>0.0f for float</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#types-of-constructors","title":"Types of constructors","text":"<ul> <li>default constructor (by compiler)</li> <li>Non-parameterized constructor</li> <li>parameterized contructor</li> <li>copy constructor</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#copy-constructor","title":"Copy Constructor","text":"<p>Truly copy data from one object to another</p> <pre><code>class Student\n{\n  private int year;\n  Student(int year)\n  {\n    this.year = year;\n  }\n  Fruit(Student source)\n  {\n    this.year = source.year;\n  }\n}\nclass StudentTester\n{\n  public static void main()\n  {\n    Student s1 = new Student(2020);\n    Student s2 = new Student(s1); // will have the same values of s1\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#constructor-overloading","title":"Constructor Overloading","text":"<p>multiple constructors having the same name but different functionality. They differ in their function signature</p>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#custom-print-message","title":"Custom Print Message","text":"<p>In order to get a custom output for <code>System.out.println(objectName)</code>, we can create a custom <code>public String toString()</code> for the class.</p> <pre><code>class Student\n{\n  int roll;\n  String name;\n\n  public String toString()\n  {\n    String text = \"Name is \" + this.name + \" Roll no is \" + this.roll;\n    return text;\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#this-keyword","title":"this Keyword","text":""},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#refer-to-current-object","title":"refer to current object","text":"<p>useful when the actual and formal parameter have the same name</p> <pre><code>class Student\n{\n  int rno;\n  String name;\n\n    Student(int rno, String name)\n    {\n    this.rno = rno;\n      this.name = name;\n    } \n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#invoke-current-class-method","title":"invoke current class method","text":"<pre><code>this.m();\n//equivalent to\nm(); // compiler adds this.\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#invoke-current-class-constructor","title":"invoke current class constructor","text":"<p>the invoked contructor should have already been defined useful for chaining of constructors to avoid redundancy</p> <p>**Note: ** <code>this()</code> cannot be at the end</p> <pre><code>class Student\n{\n  int rno;\n  String name;\n  boolean student;\n  float fee;\n\n  Student()\n  {\n        student = true;\n  }\n\n  Student(int rno, String name)\n  {\n        this(); // calls Student()\n    this.rno = rno;\n    this.name = name;\n    // this(); here will give error\n    // Thanks Firas\n  }\n\n    Student(int rno, String name, float fee)\n    {\n    this(rno, name); // calls Student(int rno)\n    this.fee = fee;\n    } \n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#pass-current-obj-as-argument-in-method-call","title":"pass current obj as argument in method call","text":"<pre><code>class Student\n{\n    void display(Student s1)\n  {\n    System.out.println(\"blah\");\n  }\n  void m()\n  {\n        display(this);\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#passed-as-argument-in-constructor-call","title":"passed as argument in constructor call","text":"<pre><code>class Student\n{\n  School sch;\n    Student(School sch)\n  {\n    this.obj = obj;\n  }\n  void display()\n  {\n    System.out.println(sch.city);\n  }\n}\nclass School\n{\n  int year = 2000;\n  String city = \"Dubai\";\n  School()\n  {\n    Student s1 = new Student(this);\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#return-current-object","title":"return current object","text":"<pre><code>class Student\n{\n  Student getStudent()\n  {\n    return this;\n  }\n  void msg()\n  {\n    System.out.println(\"hello\");\n  }\n}\nclass main\n{\n  public static void main(String args[])\n  {\n    new Student().getStudent().msg();\n    //equivalent to\n    new Student().msg();\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#access-modifier","title":"Access Modifier","text":"Accessibility <code>private</code> <code>default</code> <code>protected</code> <code>public</code> Same class Y Y Y Y Same package subclass N Y Y Y Same package non-subclass N Y Y Y Diff package subclass N N Y Y Diff package non-subclass N N N Y <p><code>private</code> does not get inherited hence not accessible even in subclass(child class); it is only accessible in the same class/nested class</p>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#other-types","title":"Other Types","text":""},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#nested-classes","title":"Nested Classes","text":"<p>is a class that is inside a function or another class. </p> <p>Nested Inner Class can access any private instance of outer class</p> <pre><code>Outer.Inner obj = new Outer().new Inner();\n\n//or\n\nOuter objo = new Outer();\nOuter.Inner obji = objo.new Inter();\n\n//or\n\n// create a function in the outer class that creates objects of outer class\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/02_Classes/#anonymous-classes","title":"Anonymous Classes","text":"<p>class that does one or more of the following, without even creating the class</p> <ul> <li>implements an interface</li> <li>inherits a class</li> </ul> <pre><code>Student s = new HelloWorld()\n{\n  int x = 5;\n  public void func()\n  {\n    x++;\n  }\n};\n</code></pre> <p>the entire  statement ends with <code>;</code> (just like any other java statement)</p>"},{"location":"2_Core/Object_Oriented_Programming/03_Arrays/","title":"03 Arrays","text":"<p>(write this somewhere else in future)</p> <p>String and Object are different classes directly under <code>java.lang</code> and hence that\u2019s why it is </p> <ul> <li><code>name.length()</code> - String</li> <li><code>a.length</code> without brackets - int</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/03_Arrays/#array","title":"Array","text":"<p>a non-primitive linear data structure that is a collection of elements of the same type</p> <p>starts with index 0</p> <p>in java, arrays are classes</p> <p>arrays are derived from <code>Object</code> class</p> <p>Steps</p> <ol> <li>declaration</li> <li>memory allocation    in java, memory for arrays is dynamically-allocated</li> <li>initialization</li> </ol> <pre><code>System.out.println(inta.getClass() +\n                   bytea.getClass() +\n                   shorta.getClass() + \n\n                   inta.getClass().getSuperClass() // same for bytea, shorta\n\n                   name.getClass() // name = \"hello\"\n                   )\n</code></pre> <pre><code>(Output)\n\nclass [I\nclass [B\nclass [S\nclass java.lang.Object\nclass [Ljava.lang.String //(String is an class under java.lang itself)\n</code></pre> <pre><code>graph TB\njava.lang --&gt; Object &amp; String\nObject --&gt; arrays</code></pre> <pre><code>// declaration, memory allocation, initialization in a single statement\ndouble[] myList = {1.9, 2.4, 34, 34};  \nint[] a = new int[10];\n\n// individually -both are correct\n// declaration\nint[] a;\nint b[];\n// memory allocation\na = new int[10];\n// initialization\na[3] = 100;\n// accessing\nint length = a.length;\nlength = b.length; // for 2d array, it will return no of rows\nlength = b[2].length; // returns the no of columns in 2nd index row\n\nSystem.out.println(a[3]);\n\n// display\nfor(int i = 0; i&lt;a.length; i++)\n  System.out.println(a[i]);\n\n// sum\nint sum = 0;\nfor(int i = 0; i&lt;a.length; i++)\n  sum += a[i];\n\n// largest element\nint max = a[0];\nfor(int i = 0; i&lt;a.length; i++)\n  if(a[i]&gt;max)\n    max = a[i];\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/03_Arrays/#array-of-objects","title":"Array of objects","text":"<p>we have to dynamically</p> <ol> <li>create the array</li> <li>create each location</li> </ol> <pre><code>// creating the array\nStudent[] s = new Student[10];\n\n// creating individual locations\nfor(int i = 0; i&lt; s.length; i++)\n{\n  s[i] = new Student();\n}\n\n// or\nfor(int i = 0; i&lt; s.length; i++)\n{\n  int x = inp.nextInt();\n  s[i] = new Student(x);\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/03_Arrays/#passing-array-to-method","title":"Passing array to method","text":"<p>Pass the name of the array - you're basically passing the pointer</p> <pre><code>display(arr); // without []\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/03_Arrays/#returning-array-from-method","title":"Returning array from method","text":"<pre><code>public static int[] mod()\n{\n  return new int[] {1,2,3};\n  // or\n  int[] a = new int[3]; a[0] = 1; a[1] = 2; a[2] = 3;\n  return a;\n\n    // or \n  int[] a = {1,2,3};\n  return a;\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/03_Arrays/#copying-an-array","title":"Copying an Array","text":"<pre><code>// same array, but new pointer\nint[] b = a; \n\n//independent copied array\nint[] b = new int[a.length];\n// Thanks Firas\n// Firas said just int[] b is not enough. why tho?\n\nSystem.arraycopy(a, 0, b, 0, a.length); // completely copy the array\nSystem.arraycopy(a, 1, b, 0, 2);\n\n// skeleton of arraycopy\npublic static void arraycopy(\n        Object src, int srcPos, \n    Object dest, int destPos,\n    int length\n    )\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/03_Arrays/#multidimensional-array","title":"Multidimensional Array","text":"<p>Array e (below code example) will look like</p> \\[ \\begin{bmatrix} 2 &amp; 3 &amp; 7 \\\\ 3 &amp; 5 &amp; 6 \\end{bmatrix} \\] <pre><code>// declaration\nint[][] a = new int[10][20];\nint[][][] b = new int[10][20][30];\n\nint[][] e = { \n  {2, 3, 7}, // row wise allocation\n  {3, 5, 6}\n};\n\nint[][] a = new int[10][10];\nfor(int i = 0; i &lt; a.length; i++) //row\n  for(int j = 0; j &lt; a[i].length; j++) // column\n    a[i][j] = inp.nextInt();\n\n// or\nint[][] a = new int[m][n];\nfor(int i = 0; i&lt;m; i++)\n  for(int j = 0; j&lt;n; j++)\n    a[i][j] = inp.nextInt();\n\n// addition of 2 arrays\nfor(int i = 0; i&lt;m; i++)\n  for(int j = 0; j&lt;n; j++)\n    add[i][j] = a[i][j] + b[i][j];\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/04_Strings/","title":"04 Strings","text":""},{"location":"2_Core/Object_Oriented_Programming/04_Strings/#strings","title":"Strings","text":"<p>immutable - you cannot change anything directly</p> <p><code>Object</code> and <code>String</code> are interchangeable</p> <pre><code>// both are valid\nObject test1 = \"hello\";\nString test2 = \"hello\"; \n\n// strings\nString s1 = \"hello world\";\nString s = new String(\"hello world\");\n\n// length\ns.length(); // 4\n\n// accessing char\ns.charAt(3);\ns.substring(i); // i to end of the string\ns.substring(i, j); // i to j-1\n\n//concat\ns1 += s2;\n// DONT FORGET s1 = \ns1 = s1.concat(s2); \n// s2 is added to s1 and returns it\n// basicaly s1 is the object in focus, and it is getting modified\n\n// search\n// returns int position of the 1st char of the string\ns1.indexOf(\"HELLO\"); // the string is case-sensitive\ns1.indexOf(s2); // searches for s2 inside s1\ns1.indexOf(s2, 3); // (string, startIndex)\n\n\"Hello\".equals(\"hello\"); // returns false\n\"Hello\".equalsIgnoreCase(\"hello\"); // returns true\n\nchar[] dh = s1.toCharArray();\n\nInteger.parseInt(numberString); // String to int\nFloat.parseFloat(numberString);\n\nInteger.toString(numbervar); // int to String\nFloat.toString(numbervar);\nDouble.toString(numbervar);\nBoolean.toString(numbervar);\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/04_Strings/#comparing-strings","title":"Comparing Strings","text":"<pre><code>s1 = \"hello\";\ns2 = \"hello\";\n\n// equality\nif(s1 == s2) // compares address\nif( s1.equals(\"hello\") ) // compares characters\n\nif( s1.compareTo(\"hello\") ) // compares objects including strings\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/04_Strings/#char-array","title":"Char Array","text":"<pre><code>char ch = 'w';\nchar[] dh = { ch, 'o', 'r', 'd'};\n\nchar dh[] = new char[ buffer.length() ];\n\n//char array\ndh = s1.toCharArray();\nArrays.equals(dh1, dh2); // 2 char arrays\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/04_Strings/#char-array-vs-string","title":"Char array vs String","text":"<p>Char array is the primitive strings we have in C/C++, but it doesn't have the advanced features of the String objects in java</p> <p>Another difference is that String objects have automatically-included <code>\\0</code></p>"},{"location":"2_Core/Object_Oriented_Programming/04_Strings/#stringbuffer","title":"<code>StringBuffer</code>","text":"<p>gives you the best of strings and char array; they are basically mutable Strings</p> <pre><code>StringBuffer sb = new StringBuffer(\"hello there\");\n\nString s = sb.toString();\n</code></pre> <p>you can append, set without creating a new String each time</p> <p>default capacity = 16 (not size) has a minimum allocation of memory for 16 characters; \\(\\ge 16\\) is valid</p> <ul> <li>length = current number of characters</li> <li>capacity = max length</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/04_Strings/#functions","title":"Functions","text":"<ul> <li><code>boolean length()</code> returns length of StringBuffer</li> <li><code>boolean capacity()</code> returns capacity of </li> <li><code>setLength(length)</code></li> <li><code>ensureCapacity()</code></li> <li><code>charAt(index)</code> return the character at index</li> <li><code>setCharAt(index, newchar)</code> change the character at index</li> <li><code>getChars(startIndex, nOfCharacters, arrayName, 0)</code> takes substring and returns as character array</li> <li><code>reverse()</code> reverses string</li> <li><code>append(string, startIndex, endIndex)</code> append data</li> <li><code>String insert(insertPos, arrayName, startIndex, endIndex)</code></li> <li><code>deleteCharAt(index)</code> remove a character</li> <li><code>delete(startIndex, endIndex)</code> remove a substring</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/04_Strings/#stringtokenizer","title":"<code>StringTokenizer</code>","text":"<p>partitions String into individual substring(s)</p> <p>constructor takes 2 parameters</p> <ol> <li>input string</li> <li>delimiter <code>(eg: comma, space, colon)</code></li> </ol> <p><code>import java.util.StringTokenizer</code></p> <pre><code>String s = \"https://ahmedthahir.tk\";\nStringTokenizer st = new StringTokenizer(s, \"://.\"); // order doesn't matter, but the pattern matters\n\nSystem.out.println(st.countTokens());\nwhile(st.hasMoreTokens())\n  System.out.println(st.nextToken());\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/05_Lists/","title":"05 Lists","text":""},{"location":"2_Core/Object_Oriented_Programming/05_Lists/#lists","title":"Lists","text":"<pre><code>flowchart BT\nVector-Class &amp; ArrayList-Class &amp; LinkedList-Class --&gt;\n|implements|List --&gt;\n|extends|Collection</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/05_Lists/#vector","title":"<code>Vector</code>","text":"<p>obsolete/not recommended to use</p> <pre><code>import java.util.Vector;\n\nVector&lt;TypeClass&gt; arrL = new Vector&lt;TypeClass&gt;();\nVector&lt;Integer&gt; arrL = new Vector&lt;Integer&gt;();\n\n//constructors\nVector();\nVector(int initialCapacity);\nVector(int initialCapacity, int capacityIncrement);\n\n// E is element type\nvoid add(int index, E element);\nboolean add(E e);\nvoid addElement(E obj);\nboolean addAll(Collection C);\nboolean addAll(int index, Collection C);\n\nvoid setElementAt(Object element, int index);\nboolean removeElement(Object element);\nboolean removeAll(Collection c);\n\nint capacity();\nvoid clear();\n\nv.get(int index);\n\nboolean contains(Object element);\nboolean containsAll(Collection c);\n\nObject elementAt(int index);\nObject firstElement();\nObject lastElement();\n\nboolean isEmpty();\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/05_Lists/#arraylist","title":"<code>ArrayList</code>","text":"<p>As opposed to arrays, array lists are</p> <ul> <li>mutable</li> <li>size is dynamic</li> <li>only for non-primitive data types</li> <li>you have to access element using <code>arrL.get(index)</code> rather than <code>[]</code></li> </ul> <pre><code>import java.util.ArrayList;\n\nArrayList&lt;TypeClass&gt; arrL = new ArrayList&lt;TypeClass&gt;(); // size is not compulsory\nArrayList&lt;Integer&gt; arrL = new ArrayList&lt;Integer&gt;();\n\nList&lt;Integer&gt; l = new ArrayList&lt;&gt;();\n// this is also allowed\n// List is the parent class of LinkedList\n// no need to specify type for the second &lt;&gt;\n\n// constructors\nArrayList(); // build an empty array list\nArrayList(int capacity); // build an array list with initial capacity\nArrayList(Collection c); // build an array list intialized with the elements from collection c\n// you can pass linkedlist as a parameter (collection class)\n\narrL.add(Object e);\narrL.add(20); // 20\narrL.add(50); // 20 50\n\narrL.add(int index, Object e);\narrL.add(index, 130); // 20 50 130\narrL.add(2, \"hello\");\n\nal.addAll(Collection c);\n\nal.set(int index, Object newData);\n\narrL.remove(int index);\narrL.remove(2); // 20 50\narrL.remove(Object data); // String, Integer, Float\n\narrL.get(index);\narrL.get(1); // 50\n\narrL.size(); // 2\n\nCollections.sort(list); // ascending\n\n// display\nSystem.out.println(arrL); // [20, 50]\n\nfor(int i = 0; i&lt;arrL.size(); i++)\n  System.out.print(arrL.get(i) + \" \"); // 20 50\n\n// enhanced for loop\nfor(String str:arrL)\n  System.out.println(str);\nfor(Integer i:arrL)\n  System.out.println(i);\n\nal.indexOf(Object o);\nal.contains(Object o); // searches for element and returns true/false\nal.clear(); // delete all elements of the arraylist\n\nArrayList&lt;String&gt; newal = (ArrayList&lt;String&gt;) al.clone();\n\nal.ensureCapacity(int minCapacity); // increases the size of the arraylist to the minCapacity\n// it is overriden method as it is available for StringBuffer also\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/05_Lists/#linkedlist","title":"<code>LinkedList</code>","text":"<pre><code>import java.util.LinkedList;\n\nLinkedList&lt;Type&gt; l = new LinkedList&lt;Type&gt;();\nLinkedList&lt;Integer&gt; l = new LinkedList&lt;Integer&gt;();\n\n// constructors\nLinkedList();\nLinkedList(Collection c);\n// you can pass arraylist as a parameter (collection class)\n\nl.size();\n\nl.add(Object e) // returns boolean - true/false - after doing the thingy to indicate if the element was added or not\nl.add(3);\n\nl.add(int index, Object e); // returns void\nl.add(2, 3);\n\nl.addAll(Collection c); // take all elements of arraylist and it to the linked list \n\nl.addFirst(Object e);\nl.addLast(Object e); // most performance-efficient\n\nl.remove(); // removes the first element, ie the default index passed is 0\nl.remove(int index);\nl.revove(Object o);\n\nl.removeFirst();\nl.removeLast();\nl.removeFirstOccurence(Object e);\nl.removeLastOccurence(Object e);\n\nl.get(index);\nl.get(2);\n\nl.set(int index, Object newdata);\nl.set(2, \"hello\");\n\nl.clear(); // delete all elements\nObject obj = l.clone();\nboolean contains(Object item);\n\nl.indexOf(Object item); //returns null if it doesn't find the element\nl.lastIndexOf(Object item);\nObject poll(); // removes and returns the last element\n// more efficent than remove() as there is only instance of it\nObject pollFirst();\nObject pollLast();\n\nCollections.sort(list); // ascending\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/05_Lists/#differences","title":"Differences","text":"<code>Vector</code> <code>ArrayList</code> <code>LinkedList</code> Each location contains data data 1. data2. pointer to previous node3. pointer to next node Type Dynamic Array double linked list setting data in between slowest intermediate fastest reason for performance insertion/deletion involves affecting all succeeding elements only pointers and data of few nodes are affected; other nodes are left unaffected getting data fastest slowest mincapacity 10 10 - Increase in size 2x (if not mentioned)else user increment 1.5x -"},{"location":"2_Core/Object_Oriented_Programming/05_Lists/#iterator","title":"<code>Iterator</code>","text":"<p>can only iterate in the forward direction</p> <pre><code>import java.util.Iterator;\n\nboolean hasNext();\n(Type) itr.next(); // returns the current element and moves the pointer to the next position\n// same like p++ in C++\n\n// the default return type of next() is String, so we have to type cast\n\nvoid remove(); // removes the last element returned by the iterator\n\n// Integer\nIterator&lt;Integer&gt; itr = al.iterator(); // al is the arraylist\n// itr is an indirect pointer/cursor to the location\n// JUST BEFORE THE 0TH INDEX\n\nwhile(itr.hasNext())\n{\n  int i = (Integer) itr.next();\n\n    if(i%2 == 0)\n      itr.remove(); // removes odd\n}\n\n// String\nIterator&lt;String&gt; itr = l.iterator();\nwhile(itr.hasNext())\n{\n  itr.remove();\n  Iterator&lt;String&gt; itr2 = itr.iterator(); // not sure\n  while(itr2.hasNext()) // to go through each element\n  {\n    System.out.println(itr2.next() + \"\");\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/05_Lists/#listiterator","title":"<code>ListIterator</code>","text":"<p>iterate forward and backward</p> <pre><code>import java.util.ListIterator;\n\nListIterator&lt;String&gt; litr = null;\nlitr = al.listIterator();\n\nwhile(litr.hasNext())\n{\n  System.outprintln(litr.next());\n}\n\nwhile(litr.hasPrevious())\n{\n  System.outprintln(litr.previous());\n}\n\nboolean hasNext();\nE next();\nint nextIndex();\n\nboolean hasPrevious();\nE previous(); // returns the current element and moves the pointer to the previous location \n// same like p-- in C++\nint previousIndex();\n\nvoid remove(); // remove the last element which is returned by the next() or previous()\nvoid set(E e); // replace the last element which is returned by the next() or previous()\nvoid add(E e); // insert before next element returned by next() method\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/","title":"06 Inheritance","text":""},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#encapsulation","title":"Encapsulation","text":"<p>put data and related functions in a single capsule, using classes and access specifiers</p> <p>helps in data-hiding</p> <p>default is the default access specifier</p> <ul> <li>trying to call a private member incorrectly will give a run-time error</li> <li>if a class has private constructor, then you cannot create the object of the class from outside that class; this will be a compile-time error</li> </ul> <p>if a class/interface is of private, then you cannot access that class at all; that\u2019s why don\u2019t pick this option</p>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#inheritance","title":"Inheritance","text":"<p>Inheritance creates an is-a relation</p> <p>Constructors are not inherited</p> <p><code>extends</code> keyword is used for inheritance in Java</p> <p>Base class constructor==s== are called before the current class constructor</p> <pre><code>public class Derived extends Base //public inheritance\n{\n\n}\n\nBase obj = new Derived(); // will have characteristic of the Derived class\n// this is like what we did for\n// - String and Object\n// - List and ArrayList/LinkedList\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#types-of-inheritance","title":"Types of Inheritance","text":"<p>java does not support multiple inheritance using classes</p> <p>we need to use interfaces</p> <pre><code>graph TD\n\nsubgraph Single\na --- b\nend\n\nsubgraph Multi-level\nc --- d --- e\nend\n\nsubgraph Hierarchical\nf --- g &amp; h &amp; i\ng --- j &amp; k\nend\n\nsubgraph Multiple\nx &amp; y --- z\nend</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#super-keyword","title":"<code>super</code> keyword","text":"<p>refer to the base class</p> <ol> <li><code>super()</code> base class constructor</li> <li>I guess this is why classes don\u2019t support multiple inheritance</li> <li>cuz Java won\u2019t know which base class to refer to when using <code>super()</code></li> <li><code>super.var</code> base class property</li> <li><code>super.func()</code> base class function</li> </ol> <p>not valid - <code>super.super(), super.super.method(), super.super.var</code></p>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#function-overriding","title":"Function Overriding","text":"<p>Base and derived classes have a function with the same name, but with different functionality</p> <p>private, static and final methods cannot be over-ridden</p> <p>doubt: private methods won\u2019t even be inherited, so it\u2019s not considered as over-riding, right?</p> <pre><code>class Derived extends Base\n{\n  void function1() // run-time binding\n  {\n\n  }\n  @Override\n  void function2() // compile-time binding\n  {\n\n  }\n}\n</code></pre> <p>Compile-time overriding is better for performance and bug prevention</p> <ul> <li>if you keep everything as runtime, execution of program will be slow</li> <li>Therefore, it is better to make everything as compile-time</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#abstract-method","title":"Abstract Method","text":"<p>Method that only has function prototype (declared, but not defined)</p> <pre><code>public abstract void func();\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#abstract-class","title":"Abstract Class","text":"<p>conceptual class which acts a bridge bw class and interface</p> <p>Abstract class is a class containing abstract method</p> <ul> <li>can be inherited</li> <li>can contain constructor<ul> <li>called when creating objects of child classes</li> <li>we cannot create objects of the abstract class itself</li> </ul> </li> <li>can also have final methods</li> </ul> <pre><code>abstract class Vehicle\n{\n  Vehicle()\n  {\n    System.out.println(\"This comes under Vehicle class\"); // gets printed when creating object of any Vehicle subclasses\n  }\n  abstract public void sound();\n\n  String name; // gets inherited for all Vehicle subclasses\n  public String getName() \n  {\n    return name;\n  }\n}\n\nclass Car extends Vehicle\n{ \n  public void sound() // NOT OVERRIDING, as sound was just an abstract method in base class\n  {\n    System.out.println(\"Woof\");\n  }\n}\n\nCar c = new Car();\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#interface","title":"Interface","text":"<p>all types of inheritances are possible using interfaces. Methods from interface cannot use <code>protected</code></p> <p>In new versions, we can have</p> <ul> <li><code>static/default</code> methods in interfaces with their definition also</li> <li><code>private</code> methods</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#automatic","title":"Automatic","text":"<ol> <li>variables are automatically</li> <li>public</li> <li>static</li> <li>final</li> <li>all functions are automatically</li> <li>public</li> <li>abstract</li> <li>functions can only have prototype - declared, but not defined</li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#conditions","title":"Conditions","text":"<ul> <li>A class that <code>implements</code> an interface must have function definition for all the functions of the interface (and extended interfaces)</li> <li>a single interface can extend multiple interfaces (multiple inheritance)</li> <li>can have <code>default</code> methods</li> <li>can have <code>static</code> methods<ul> <li>can be called just by using the interface name</li> </ul> </li> </ul> <p>We use both <code>extends</code> and <code>implements</code> here</p> <pre><code>interface i1\n{\n  void f1();\n}\n\ninterface i2\n{\n  void f2();\n}\n\ninterface Vehicle extends i1, i2\n{\n  void f();\n}\n\nclass Bicycle implements Vehicle\n{\n  void f1(){;}\n  void f2(){;}\n  void f(){;}\n}\n\n// array of instruments of various data types\nInstrument[] orchestra = {\n  new Wind(),\n  new Percussion(),\n  new Brass()\n};\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/06_Inheritance/#abstract-vs-interfaces","title":"Abstract vs Interfaces","text":"Abstract Interface Supported methods abstract, concrete abstract Supported variables all types of variables only static and final multiple inheritance N Y <code>extends</code> only classes only interfaces <code>implements</code> Y N creation of objects N N member access any only public"},{"location":"2_Core/Object_Oriented_Programming/07_Compare/","title":"07 Compare","text":""},{"location":"2_Core/Object_Oriented_Programming/07_Compare/#comparable-and-comparator","title":"Comparable and Comparator","text":"<p>they both are interfaces</p> <p>useful for elements of <code>Collection</code></p> <ul> <li>sorting</li> <li>comparing</li> </ul> <pre><code>Collections.sort(list); // sort() is an abstract function\n\nCollections.sort( list, new NameComparator() );\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/07_Compare/#comparable","title":"Comparable","text":"<pre><code>// Comparable\nclass Student implements Comparable&lt;Student&gt;\n{\n  String name;\n  int age;\n\n  Student(String n, int a)\n  {\n    name = n;\n    a = age\n  }\n\n  public int compareTo(Student s)\n  {\n    if(age &lt; s.age)\n      return -1;\n    else if(age &gt; s.age)\n      return 1;\n    else\n      return 0;\n  }\n}\n\n// ArrayList\n\nCollections.sort(al); // sorting based on age\n//display\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/07_Compare/#comparator","title":"Comparator","text":"<pre><code>// Comparable\nclass Student implements Comparable&lt;Student&gt;\n{\n  String name;\n  int age;\n\n  Student(String n, int a)\n  {\n    name = n;\n    a = age\n  }\n}\n\nclass AgeComparator implements Comparator&lt;Student&gt;\n{\n  public int compare(Student s1, Student s2)\n    {\n    if(s1.age &lt; s2.age)\n      return -1;\n    else if(s1.age &gt; s2.age)\n      return 1;\n    else\n      return 0;\n    }\n}\n\nclass NameComparator implements Comparator&lt;Student&gt;\n{\n  public void compare(Student s1, Student s2)\n  {\n    return s1.name.compareTo(s2.name);\n  }\n}\n\n// ArrayList\n\nCollections.sort(al, new AgeComparator());\n// display\n\nCollections.sort(al, new NameComparator());\n// display\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/07_Compare/#difference","title":"Difference","text":"Comparable Comparator package <code>java.lang</code> <code>java.util</code> method to implement <code>compareTo()</code> <code>compare()</code> Sorting Sequence Single Multiple Affect original class Y N Sorting <code>Collections.sort(list);</code> <code>Collections.sort( list, new NameComparator() );</code>"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/","title":"08 Exceptions","text":""},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#exceptions","title":"Exceptions","text":"<p>warnings, not exactly errors</p> Checked Unchecked handled at compile-time runtime inherited from (class) Exception RuntimeException"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#exception","title":"Exception","text":"<p>For accessing out of bounds array data, JVM throws <code>ArrayIndexOutOfBoundsException</code></p> <ol> <li>JVM will show a warning</li> <li>it will just skip the exception</li> <li>then proceed with the rest of the program</li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#exception-handling","title":"Exception-Handling","text":"<p>use <code>try-catch</code></p> <ul> <li>logic in <code>try</code></li> <li>exception will be caught by <code>catch</code></li> <li><code>finally</code> block contains all statements that must be executed when exception does or does not occurs</li> </ul> <p>IDK</p> <ol> <li>neither can exist independently, but not finally is not compulsory</li> <li>nested try is possible, but nested catch is not</li> <li>nothing can come up after <code>finally</code> - unreachable catch block error</li> </ol> <pre><code>try {\n  // code to test\n\n  try {\n    // something\n  }\n  catch(Exception E)\n  {\n    //something\n  }\n}\ncatch(ArrayIndexOutOfBoundsException e) {\n  //\n}\ncatch(Exception2 e2) {\n  //\n}\ncatch(Exception e) { // all exceptions (checked/unchecked)\n  //\n}\nfinally {\n    //\n}\n\nSystem.out.println(\"Program done\"); // doesn't get executed\n</code></pre> <p>here, statement1 runs, but statement2 doesn\u2019t. this is because, the flow of control goes to the catch after the throw</p> <p>Similarly, the last statement doesn\u2019t get executed because of <code>finally</code> block</p>"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#throw-and-throws","title":"<code>throw</code> and <code>throws</code>","text":"<p>you can explicitly throw any kind of exception</p> <p>can come with/without <code>try-catch</code></p> <code>throw</code> <code>throws</code> no of exceptions at a time only one multiple i\u2019m not sure this, butdoesn\u2019t actually throw - just shows that the function might throw location function definition function prototype can come inside <code>throws</code> cannot come inside <code>throw</code> type of exception unchecked checked/unchecked followed by exception instance exception class example - <code>throw new ArithmeticException(\u201cblah\u201d);</code>- <code>throw e</code> <code>void test() throws IOException{}</code>"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#idk","title":"IDK","text":"<p>error</p> <ul> <li>Compile time - Syntax errors</li> <li>Runtime error - wrong constructor for initialization</li> </ul> <p>exceptions</p> <ul> <li>Runtime exception <ul> <li>unexpected values - divide by 0</li> <li>array index out of bound</li> </ul> </li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#custom-exceptions","title":"Custom Exceptions","text":"<pre><code>class CustomException extends IllegalArgumentException\n{\n  String message = \"Blah\";\n  CustomException(String s)\n  {\n    super(s); // or super(message);\n  }\n  @Override\n  public String toString() \n  {\n    return message;\n  }\n}\n\n// somewhere else\ntry {\n  throw new CustomExcepiton(\"specific message\"); // prints specific message\n} catch(CustomException e) {\n  System.out.println(e); // prints Blah\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#common-exceptions","title":"Common Exceptions","text":"<ol> <li><code>ArithmeticException</code></li> <li><code>ArrayIndexOutOfBoundException</code></li> <li><code>IOException</code></li> <li><code>NullPointerException</code></li> <li><code>StringIndexOutOfBoundsException</code></li> <li><code>FileNotFoundException</code></li> <li><code>NumberFormatException</code></li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/08_Exceptions/#exception-methods","title":"Exception Methods","text":"<pre><code>e.func();\n\npublic String getMessage();\n// inside System.out.println()\n// details of why the exception happened\n// eg: / by zero\n\npublic String toString(); // name + getMessage()\n// eg: java.lang.ArithmeticException / by zero\n\npublic void printStackTrace();\n// outside System.out.println()\n// toString() + location of exception\n// eg: java.lang.ArithmeticException / by zero at Test.main(Testjava:9)\n\npublic Throwable getCause(); // toString()\n// eg: java.lang.ArithmeticException / by zero\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/","title":"09 Thread","text":""},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#threads","title":"Threads","text":"<p>independent subprocess</p> <p>Multi-threading allows for multiple subprocesses to occur for perform a task</p>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#processor","title":"Processor","text":"<p>has 3 stages to perform tasks</p> <p>\\(\\fbox F \\fbox D \\fbox E\\)</p> <ul> <li>Fetch instruction</li> <li>Decode instruction</li> <li>Execute instruction</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#life-cycle-of-thread","title":"Life Cycle of Thread","text":"<pre><code>flowchart LR\nnew &amp; blocked &amp; waiting --&gt; runnable\nrunnable --&gt; blocked &amp; waiting &amp; terminate</code></pre> <ul> <li>new (born) state<ul> <li><code>start</code> is called implicitly(on it\u2019s own)</li> </ul> </li> <li>Blocked state<ul> <li>paused / waiting for I/O or notification</li> <li>short duration</li> </ul> </li> <li>Waiting state<ul> <li>processor is busy</li> <li>when finally going to runnable, <code>notify() / notifyall()</code> method is called</li> </ul> </li> <li>runnable state<ul> <li>highest-priority thread enters</li> </ul> </li> <li>terminate (Dead) state<ul> <li>thread has been processed</li> </ul> </li> <li>sleeping state<ul> <li><code>sleep(t)</code> is called</li> <li>\\(t\\) is in ms</li> <li>long duration</li> <li>exits this state when sleep timer has expired</li> </ul> </li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#priorities","title":"Priorities","text":"<ul> <li><code>Thread.MIN_PRIORITY</code> - 1</li> <li><code>Thread.NORM_PRIORITY</code> - 5 (default)</li> <li><code>Thread.MAX_PRIORITY</code> - 10</li> </ul> <p>New threads inherit the priority of the thread that created it</p>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#timeslicing","title":"Timeslicing","text":"<p>Round robin fashion</p> <p>The initial run takes place based on priority ensuring that each task gets run for 4s. Then, purely based on priority, tasks are run</p> <p>In the following example, let\u2019s say that priority is \\(T_2 &gt; T_4 &gt; T_3 &gt; T_1\\),</p> \\[ \\color{hotpink} \\underbrace{ \\underset{4s}{\\fbox{$T_2$}} \\underset{4s}{\\fbox{$T_4$}} \\underset{4s}{\\fbox{$T_3$}} \\underset{4s}{\\fbox{$T_1$}} }_\\text{initial run} \\color{orange} \\underbrace{ \\underset{4s}{\\fbox{$T_2$}} \\underset{4s}{\\fbox{$T_2$}} \\underset{4s}{\\fbox{$T_2$}} \\underset{4s}{\\fbox{$T_4$}} \\underset{4s}{\\fbox{$T_3$}} \\underset{4s}{\\fbox{$T_3$}} \\underset{4s}{\\fbox{$T_1$}} }_\\text{purely based on priority} \\]"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#implementation","title":"Implementation","text":"<p>Both methods are pretty much identical</p> <ul> <li>implementing <code>Runnable</code> (better)</li> <li>or, extending <code>Thread</code><ul> <li>not recommended</li> <li>cuz then we can\u2019t inherit any other class (java doesn\u2019t support class multiple inheritance)</li> </ul> </li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#implement-runnable","title":"Implement <code>Runnable</code>","text":"<pre><code>class MyThread implements Runnable \n{\n  public void run() {\n      // logic    \n    }\n}\n\npublic class Tester\n{\n    Thread t1 = new Thread(new MyThread() );\n    Thread t2 = new Thread(new MyThread() );\n\n  // or\n    Runnable r = new MyThread();\n  Thread t = new Thread(r);\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#extending-thread","title":"Extending <code>Thread</code>","text":"<pre><code>class MyThread extends Thread\n{\n  public void run()\n  {\n    // logic\n  }\n}\n\nclass Tester\n{\n  public static void main()\n  {\n        MyThread t = new MyThread();\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#inter-thread-communication","title":"Inter Thread Communication","text":"<p>proper coordination/communication between thread helps take care of deadlock situation</p> <pre><code>MyThread t1 = new MyThread();\n\nt1.start();\nt1.sleep(4000); // ms\nt1.join();\nt1.suspend(); // stop it indefinitely, unless resumed\nt1.resume();\n\nt1.wait();\nt1.notify();\nt1.notifyAll();\n</code></pre> <p>synchronized ensures that only thread runs at a time</p> <pre><code>public static class PC\n{\n  public void produce() throws InterruptedException\n  {\n    synchronized(this)\n    {\n\n    }\n  }\n\n  // or\n\n  public synchronized void produce() throws InterruptedException\n  {\n    System.out.println(\"Producer Thread Running\");\n    wait(); //wait tills another does notify()\n    System.out.println(\"\");\n  }\n\n  public synchronized void consume() throws InterruptedException\n  {\n    Thread.sleep(1000);\n    Scanner inp = new Scanner(System.in);\n\n        synchronized(this)\n    {\n      System.out.println(\"Consumer Thread Running\");\n      inp.nextLine();\n      System.out.println(\"Return Key Pressed\");\n\n      notify();\n\n      Thread.sleep(2000);\n    }\n\n  }\n}\n\nclass Tester\n{\n  public static void main()\n  {\n    final PC p = new PC();\n\n    // create a thread object that calls pc.produce()\n    Thread t1 = new Thread(new Runnable())\n    {\n      @Override\n            public void run()\n      {\n        try {\n          pc.produce();\n        } catch(InterruptedException e) {\n          e.printStackTrace();\n        }\n      }\n    }; // anonymous class ends with ;\n\n    Thread t2 = new Thread(new Runnable())\n    {\n      @Override\n            public void run()\n      {\n        try {\n          pc.consume();\n        } catch(InterruptedException e) {\n          e.printStackTrace();\n        }\n      }\n    }; // anonymous class ends with ;\n\n    t1.start();\n    t2.start();\n\n    // when t1 finishes, t2 starts\n    // then t1 finishes, t1 starts\n    t1.join();\n    t2.join();\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#thread-methods","title":"<code>Thread</code> methods","text":"<pre><code>public void start(); \npublic void run(); // contains logic of the thread\n// logic should always be inside try block\n// and there should also be a catch block with InterruptedException\n\njoin();\nwait(); // sends thread to wait state\nresume(); // takes thread out of block state\nsuspend(); // sends thread to block state\nnotify();\nnotifyAll();\n\npublic final boolean isAlive(); // check if alive \npublic static void sleep(long millisec); // send thread to block state for a while\npublic final void setDaemon(boolean on); // set this thread as a daemon thread\npublic void interrupt(); // not sure\npublic static void yield(); // give the runtime to other threads with the same priority\n\npublic final void setName(String name);\npublic final void setPriority(int priority); // 1 &lt;= p &lt;= 10\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/09_Thread/#daemon-thread","title":"Daemon Thread","text":"<p>is a low priority thread that runs in the background, to perform tasks such as garbage collection</p>"},{"location":"2_Core/Object_Oriented_Programming/10_Cloning/","title":"10 Cloning","text":""},{"location":"2_Core/Object_Oriented_Programming/10_Cloning/#cloning","title":"Cloning","text":"<p>creating an exact copy of an existing object in the memory</p> <p><code>clone()</code> from class <code>java.lang.Object</code></p> <p>Only objects of classes which implement <code>Cloneable</code> interface are eligible for cloning</p> <p>By default, shallow copy occurs</p> Shallow Deep definition custom <code>clone()</code> original and clone dependent on each other independent changes affect each other no effect preferred if object has only primitive fields references to other objects as fields performance faster and cheaper slower and costlier"},{"location":"2_Core/Object_Oriented_Programming/10_Cloning/#deep-copy","title":"Deep Copy","text":"<pre><code>class Course implements Cloneable\n{\n  String sub1, sub2, sub3;\n\n    // constructor\n\n  protected Object clone() throws CloneNotSupportedException\n  {\n    return super.clone();\n  }\n}\n\nclass Student implements Cloneable\n{\n  int id;\n  String name;\n   Course c;\n\n    // constructor\n\n  // this is what defines a deep copy\n  // without this, it will just be a shallow copy\n  protected Object clone() throws CloneNotSupportedException\n  {\n    Student s = (Student) super.clone();\n    student.c = (Course) c.clone();\n    return s;\n  }\n}\n\nclass Tester\n{\n  public static void main(String args[])\n  {\n    Course c = new Course(\"Phy\", \"Chem\", \"Bio\");\n\n    Student s1 = new Student(111, \"John\", c);\n    Student s2 = null;\n\n    try {\n      s2 = (Student) s1.clone();\n    } catch (CloneNotSupportedException e) {\n      e.printStackTrace();\n    }\n\n    System.out.println(s1.c.sub3); // Bio\n\n    s2.course.sub3 = \"Math\"; // will not affect s1\n\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/","title":"11 GUI","text":""},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#event","title":"Event","text":"<p>Change in the state of an object</p> <p>generated by user\u2019s interaction with the GUI (graphical user interface), such as</p> <ul> <li>mouse movements</li> <li>mouse clicks</li> <li>pressing keys</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#event-handling","title":"Event Handling","text":"<p>control what happens if an event occurs</p>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#delegation-event-model","title":"Delegation Event Model","text":"<p>UI and event logic are separate</p>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#source","title":"Source","text":"<p>object on which event occurs</p> <p>eg: buttons</p>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#listenerhandler","title":"Listener/Handler","text":"<p>object that</p> <ol> <li>waits for event to occur</li> <li>generates response for the event</li> </ol> <p>eg: mouse click</p> <p>listener should be registered with the source</p>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#important-events-and-listeners","title":"Important events and listeners","text":"<ul> <li><code>java.util</code></li> <li><code>java.awt</code></li> <li><code>java.awt.event</code></li> </ul> Event Classes Interface Generated when <code>ActionEvent</code> <code>ActionListener</code> - button press- menu-item selected- list-item is double clicked <code>MouseEvent</code> <code>MouseListener</code> - mouse dragged, moved, pressed, released- enter/exit a component <code>KeyEvent</code> <code>KeyListener</code> keyboard input <code>ItemEvent</code> <code>ItemListener</code> checkbox/list item is clicked <code>TextEvent</code> <code>TextListener</code> textarea/textfield edited <code>MouseWheelEvent</code> <code>MouseWheelListener</code> mousewheel moved <code>WindowEvent</code> <code>WindowListener</code> window activated, deactivated, opened, closed <code>ComponentEvent</code> <code>ComponentEventListener</code> component hidden <code>ContainerEvent</code> <code>ContainerListener</code> <code>AdjustmentEvent</code> <code>AdjustmentListener</code> <code>FocusEvent</code> <code>FocusListener</code>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#swing","title":"Swing","text":"<p>part of JFC(Java Foundation Classes)</p> <p><code>import javax.swing</code></p> <p>swing classes all start like <code>J...</code></p> <p>We are using Swing Library, cuz</p> <ul> <li>Swing is for cross-platform applications; AWT is only for windows applications</li> <li>Swing is ligher than AWT</li> </ul> <pre><code>graph TB\nObject --&gt; Component --&gt; Container &amp; JComponent\n\nContainer --&gt; Window &amp; Panel\nWindow --&gt; JFrame &amp; Dialog\nPanel --&gt; Applet\n\nJComponent --&gt; JLabel &amp; JButton &amp; x[many more...]</code></pre> \\[ \\color{hotpink} \\fbox{$ \\underset{ \\color{orange} \\fbox{$ \\underset{ \\color{orange} \\fbox{Components} }{Panel} $}} {\\text{Frame}}$} \\]"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#containers","title":"Containers","text":"Top Level Lightweight Weight heavy light Dependence independent requires top level eg <code>JFrame, JDialog, JApplet</code> <code>JPanel</code>"},{"location":"2_Core/Object_Oriented_Programming/11_GUI/#idk","title":"IDK","text":"<p>There are 2 ways</p> <ol> <li>instantiate <code>JFrame</code> class</li> <li>extend <code>JFrame</code> class</li> </ol> <pre><code>import java.awt.*;\nimport java.swing.*;\n\nclass GUI implements ActionListener\n{\n    GUI()\n  {\n    JFrame f = new JFrame();\n\n    JLabel l = new JLabel(\"Blah Blah\");\n\n    JPanel p1 = new JPanel();\n    JPanel p2 = new JPanel();\n\n    JTextField tf = new JTextField();\n    tf.setText(\"Blah\");\n    tf.setEditable(false);\n\n    JButton btn = new JButton(\"Click me\");\n    btn.addActionListener(this);\n\n    JCheckBox jc = new JCheckBox();\n    jc.addActionListener(this);\n\n    ButtonGroup bg = new ButtonGroup();\n    JRadioButton r1 = new JRadioButton(),\n        r2 = new JRadioButton(),\n        r3 = new JRadioButton();\n    bg.add(r1); bg.add(r2); bg.add(r3);\n\n    p1.add(tf); p1.add(btn);\n    p2.add(jc); p2.add(bg);\n\n        f.add(p1); f.add(p1);\n    f.add(l);\n\n    f.setLayout(new FlowLayout() ); //null\n    f.setSize(200, 400);\n    f.setVisible(true);\n  }\n\n  public void actionPerformed(ActionEvent e)\n  {\n    JOptionPane.showMessageDialog(this, \"message\");\n    if( e.getSource() == btn )\n    {\n      if( jc.isSelected() )\n                ;\n      if( r1.isSelected() )\n        ;\n      if( r2.isSelected() )\n                ;\n    }\n  }\n}\n</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/","title":"12 UML","text":""},{"location":"2_Core/Object_Oriented_Programming/12_UML/#phases-of-software-engineering","title":"Phases of Software Engineering","text":"<pre><code>flowchart LR\na[Requirement Gathering] --&gt;\nb[Requirement Analysis] --&gt;\nd[\"Design&lt;br /&gt;(UML Diagrams)\"] --&gt;\nCoding --&gt;\nTesting --&gt;\nDeployment --&gt;\nSupport</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#uml","title":"UML","text":"<p>Unified Modeling Language</p>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#use-case-diagram","title":"Use Case Diagram","text":""},{"location":"2_Core/Object_Oriented_Programming/12_UML/#actors","title":"Actors","text":"<p>classes</p> <p>could be</p> <ol> <li>users of the system</li> <li>external system</li> <li>physical environment</li> </ol> <p>Properties</p> <ol> <li>unique name</li> <li>description (optional)</li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#use-cases","title":"Use Cases","text":"<p>basically like functions</p> <p>properties</p> <ol> <li>unique name</li> <li>participating actors</li> <li>entry conditions</li> <li>exit conditions</li> <li>event flow</li> <li>exceptional cases</li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#extends","title":"<code>&lt;&lt;extends&gt;&gt;</code>","text":"<p>for exceptions/showing use cases that are rarely used</p> <p>The direction of a <code>&lt;&lt;extends&gt;&gt;</code> relationship is to the extended use case</p>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#includes","title":"<code>&lt;&lt;includes&gt;&gt;</code>","text":"<p>for use cases that require/depend on another use case</p> <p>The direction of a <code>&lt;&lt;includes&gt;&gt;</code> relationship is to the using use case (unlike <code>&lt;&lt;extends&gt;&gt;</code> relationships).</p> <p></p>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#class-diagram","title":"Class Diagram","text":""},{"location":"2_Core/Object_Oriented_Programming/12_UML/#access-specifiers","title":"Access Specifiers","text":"<ul> <li>(nothing) default</li> <li><code>-</code> private</li> <li><code>+</code> public</li> <li><code>#</code> protected</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#connections","title":"Connections","text":"<ul> <li> <p>association</p> <ul> <li>can be 1-way or 2-way</li> <li>can be one-one or many-many \\(1-1, \\quad 5\\ldots* - *, \\quad *- 3\\ldots *, \\quad * - *\\)</li> <li>arrow from a towards b, means that a depends on b</li> </ul> </li> <li> <p>aggregation</p> </li> <li>composition (strong aggregation)</li> <li>inheritance<ul> <li>class inheritance</li> <li>interface inheritance</li> </ul> </li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#example","title":"Example","text":"<pre><code>classDiagram\nInterface &lt;|.. Base: implements\nBase &lt;|-- Teacher\nBase &lt;|-- Student\nBase &lt;.. Tester\nClassRoom *-- Teacher\nClassRoom o-- Student\nclass Interface {\n    &lt;&lt;interface&gt;&gt;\n    +func() void\n}\nclass Base {\n    &lt;&lt;abstract&gt;&gt;\n    #var : int\n    +func() void\n}\nclass Tester {\n    +main() void\n}</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#sequence-diagram","title":"Sequence Diagram","text":"<p>Shows the interactions bw the classes/objects</p> <p>calls are solid, returns are dashed</p> <pre><code>sequenceDiagram\nautonumber\n\nactivate d\n\nd -&gt;&gt;+ p: Discharge Advice\n\nactivate r\n\np -&gt;&gt;- r: Discharge Request\n\nr -&gt;&gt; + pd: Check Details\npd --&gt;&gt; - r: Detailed Summary\nr -&gt;&gt; r:  Prepare Bill\nr --&gt;&gt;+ p: Send Bill\np -&gt;&gt;- r: Request Discount\nr -&gt;&gt; d: Check Possibility of discount\nd --&gt;&gt; r: Approve Discount\n\ndeactivate d\n\nr -&gt;&gt; r: Update bill\nr -&gt;&gt;+ p: Send bill\np --&gt;&gt;- r: Pay bill\nr -&gt;&gt; +pd: Update Bill\ndeactivate pd\n\nactivate p\nr -&gt;&gt; p: Discharge note\n\ndeactivate r\n\np -&gt;&gt; + Ward: Show note\nWard --&gt;&gt; - p: Discharge\ndeactivate p\n\n%% participant\nparticipant d as Doctor\nparticipant p as Patient\nparticipant r as Reception\nparticipant pd as Patient Database</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/12_UML/#state-diagrams","title":"State Diagrams","text":"<pre><code>stateDiagram-v2\n[*] --&gt; dr\ndr --&gt; cp: Patient Register\ncp --&gt; er: Resign\ner --&gt; [*]\n\nstate \"Doctor Registration\" as dr\nstate \"Check Patient\" as cp\nstate \"End Service\" as er</code></pre>"},{"location":"2_Core/Object_Oriented_Programming/13_Design_Patterns/","title":"13 Design Patterns","text":"<p>Object Oriented design must be</p> <ul> <li>specific to the problem, and</li> <li>general to adress future problems and requirements</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/13_Design_Patterns/#design-patterns","title":"Design Patterns","text":"<p>Descriptions of communicating objects and classes, that are customized to solve a general design problem, in a particular context.</p> <p>allows</p> <ul> <li>re-usability of design</li> <li>faster production of projects</li> <li>more accessible</li> <li>easier documentation and maintenance</li> </ul>"},{"location":"2_Core/Object_Oriented_Programming/13_Design_Patterns/#parts","title":"Parts","text":"<ol> <li>Pattern Name</li> <li>Problem</li> <li>Solution</li> <li>Context</li> <li>Class Diagram</li> </ol>"},{"location":"2_Core/Object_Oriented_Programming/13_Design_Patterns/#types-of-patterns","title":"Types of Patterns","text":"<ol> <li>Creational Patterns    deal with object creation</li> <li>Singleton       Single object of a class is created, and all other objects can access it globally</li> <li>Structural Patterns    deal with relationship between entities</li> <li>Composite       when you put components inside containers       eg: JPanel</li> <li>Decorator       something that surrounds component       eg: scroll bars</li> <li>Adapter Pattern       a middle interface \u2018adapts\u2019 main interface based on the requirement</li> <li>Proxy Pattern       a class acts a proxy to access another class, to keep that hidden</li> <li>Behavioural Patterns    communication between objects</li> <li>Iterator       access the elements of an aggregate object sequentially without exposing its underlying implementation</li> <li>Observer       eg: ActionListener</li> </ol>"},{"location":"3_Core/Compiler_Contruction/","title":"Compiler Construction","text":"<p>Course taught by Dr. Santhosh Kumar, Dr. Elakkiya and Dr. Vijaykumar</p> <p>Continuation of</p> <ul> <li>Theory of Compution</li> <li>Principles of Programming Languages</li> </ul>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/","title":"01 Introduction","text":""},{"location":"3_Core/Compiler_Contruction/01_Introduction/#language-translators","title":"Language Translators","text":"<p>You should know by this stage :/</p> <p>If you don\u2019t, refer this.</p>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#programming-language-processing","title":"Programming Language Processing","text":"<pre><code>flowchart LR\na(( )) --&gt;\n|Source&lt;br/&gt;Program| Preprocessor --&gt;\n|Modified&lt;br/&gt;Source&lt;br/&gt;Program| Compiler --&gt;\n|Target&lt;br/&gt;Assembly&lt;br/&gt;Code| Assembler --&gt;\n|Relocatable&lt;br/&gt;Machine&lt;br/&gt;Code| Linker/Loader --&gt;\n|Target&lt;br/&gt;Machine&lt;br/&gt;Code| b(( ))</code></pre> <p>Compiler outputs assembly code, as it is easier to</p> <ul> <li>produce as output</li> <li>debug</li> </ul> <p>Linker resolves ext mem addresses, where code in one file may refer to location in another file.</p>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#stages-of-compiler","title":"Stages of Compiler","text":"<pre><code>flowchart LR\n\na[/Input/] --&gt;\n|Char&lt;br/&gt;Stream| la\n\nsubgraph Analysis/Front End\nla[\"Lexical&lt;br/&gt;Analysis&lt;br/&gt;(Scanning)\"] --&gt;\n|Token&lt;br/&gt;Stream| sya[\"Syntax&lt;br/&gt;Analysis&lt;br&gt;(Parsing)\"] --&gt;\n|Syntax&lt;br/&gt;Tree| sea[Semantic&lt;br/&gt;Analysis]\nend\n\nsea --&gt; |Syntax&lt;br/&gt;Tree| icg\n\nsubgraph Synthesis/Back End\nicg[Intermediate&lt;br/&gt;Code&lt;br/&gt;Generation] --&gt;\n|Intermediate&lt;br/&gt;Representation| mico[Machine-Independent&lt;br/&gt;Code Optimization] --&gt;\n|Intermediate&lt;br/&gt;Representation| c[Code&lt;br/&gt;Generator] --&gt;\n|Target&lt;br/&gt;Machine&lt;br/&gt;Code| mdco[Machine-Dependent&lt;br/&gt;Code Optimization]\nend\n\nmdco --&gt; o[/Output/]</code></pre> Stage Input Task LexicalAnalysis/Scanning Source prog - Group characters into lexemes (meaningful sequences)- Generate a token for every lexeme- Access/Update symbol tableSecondary- Stripping comments, whitespaces (blanks, newlines, tokens)- Keep track of line number for errors- Macro expansion SyntaxAnalysis/Parsing Tokens - Check if structure follows [context-free] grammar of lang- Creates tree representationof grammatical structure of token stream SemanticAnalysis Syntax treeSymbol table - Check semantic consistency w/ lang definition- Gathers type information &amp; saves it in syntax tree/symbol table- Type checking: each operator has matching operands- Label Checking- Keywords misuse- Flow Control checking (no <code>break</code> outside loop)- Type conversions called coercions IntermediateCodeGeneration Parse tree from semantic analyzer Generate program in low-level/machine-like intermediate representation CodeOptimization Intermediate code Improve code so that target code uses lesser resources CodeGeneration Intermediate representation - Produces target language (machine/assembly code)- Choose registers &amp; mem locations for vars in prog"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#error-detection-reporting","title":"Error Detection &amp; Reporting","text":"<p>At every phase, if any error is identified, it is reported and handled</p>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#tasks","title":"Tasks","text":"<ul> <li>Report the presence of errors clearly &amp; accurately. One error can mask another &amp; cause correct code to look faulty. </li> <li>Recover from each error quickly enough to detect subsequent errors</li> <li>Add minimal overhead to processing of correct programs</li> </ul>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#types-of-errors","title":"Types of Errors","text":"Types Meaning Example Lexical Misspelled identifier/keyword <code>fi (a == b)</code>(<code>fi</code> could be identifier/misspelled keyword (<code>if</code>)/function nameBut lexical analysis considers it as identifier) Syntax Statement not following lang rules Missing <code>;</code>Arithmetic expression with unbalanced parenthesis Semantic Divide by 0Operation incompatible operand typesWrong number of array index Logical No rules broken, but incorrect logic Using &lt; instead of &lt;=Infinite recursive call"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#symbol-table","title":"Symbol-Table","text":"<p>Data structure (usually hash table - for efficiency) containing a record for each identifier (variables, constants, functions) with fields for the attributes of the identifier</p> <p>It is accessed at every phase of compiler.</p> <ul> <li>Scanner, parser, and semantic analyzer put names of identifiers in symbol table.</li> <li>The semantic analyzer stores more information (e.g. types) in the table.</li> <li>The intermediate code generator, code optimizer and code generator use information in symbol table to generate appropriate code.</li> </ul>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#contains","title":"Contains","text":"<ul> <li>Attributes of variables are name, type, scope, etc.</li> <li>Attributes of procedure names which provide info about</li> <li>no and types of its arguments</li> <li>method of passing each argument (call by value/reference)</li> <li>type returned</li> </ul>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#passes","title":"Passes","text":"<p>Several phases are sometimes combined into a single \u2018pass\u2019</p> <p>A pass reads an input file process it and writes an output file</p>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#normal-passes-in-compilers","title":"Normal Passes in Compilers","text":"<ul> <li>Front-end phases are combined into a pass</li> <li>Code optimization is an optional pass </li> <li>Back-end phase can be made into a pass</li> </ul>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#misc","title":"Misc","text":""},{"location":"3_Core/Compiler_Contruction/01_Introduction/#compilation-examples","title":"Compilation Examples","text":""},{"location":"3_Core/Compiler_Contruction/01_Introduction/#c","title":"C","text":"<pre><code>cc gx.c\nobjdump -d a.out\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#java","title":"Java","text":"<p>This command shows how your class file is treated</p> <pre><code>javac File.java\njavap -c File.class\n</code></pre> <p>It is cross platform, as it executes as a station machine</p>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#python","title":"Python","text":"<pre><code>python file.py\npython decompile file.py\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/01_Introduction/#android-sdk","title":"Android SDK","text":"<p>How does it show how your java program will work on mobile, when mobile is ARM architecture, but your laptop is usually x86 architecture.</p> <p>This is because java program is cross-platform, and the simulator simulates execution of the program as if it is executed on an ARM processor.</p>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/","title":"02 Lexical Analysis","text":"<p>Also called as scanning</p> <p>We specify tokens using Regular Expressions - sequence of characters specifying search pattern in input</p> <p>We use NFA/DFA</p>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#parts","title":"Parts","text":"Meaning Example Tokens Pair containing <code>token_name</code> and <code>attribute</code><code>token_name</code> is a symbol representing a \u2018lexical unit\u2019, which is processed by parser <code>&lt;id, pointer_to_symbol_table_entry&gt;</code> Lexical Units Identifiers, Keywords, Operators, Constants (numeric/string) Pattern Rule describing the format of the lexemes of a token For keywords it\u2019s the sequence of characters itself Lexeme Sequence of characters that matches that pattern for a token Sentinals Special characters that cannot be part of the source program eof character can be used to denote the end of a buffer"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#example","title":"Example","text":"<pre><code>e = m * c ** 2\n</code></pre> <pre><code>&lt;id, pointer_to_symbol_table_entry_for_e&gt;\n&lt;assign_op&gt;\n&lt;id, pointer_to_symbol_table_entry_for_m&gt;\n&lt;mult_op&gt;\n&lt;id, pointer_to_symbol_table_entry_for_c&gt;\n&lt;exp_op&gt;\n&lt;number, 2&gt;\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#input-buffering","title":"Input Buffering","text":"<p>In Fortran, spaces are ignored. So, <code>he l lo</code> is the <code>hello</code>. This is because, there may exist blank instances in the magnetic tape.</p> <p>We can\u2019t tell if the statement <code>do 5 i = 1.25</code> is to be treated as</p> <pre><code>do {i=1}\n// or  \ndo51 = 1.52\n</code></pre> <p>until we reach the <code>.</code></p>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#fortran-loops","title":"Fortran Loops","text":"<pre><code>do index_variable = start, end, step\n    statements\nend do\n\n// or\n\ndo n index_variable = start, end, step\n    statements\nn continue\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#lookahead","title":"Lookahead","text":"<p>Lookahead of atleast one/more characters beyond the next lexeme before we can be sure that we have the right lexeme.</p> <p>Helps speed up reading source program</p> <p>We usually use 2 buffer scheme lookahead, which are alternatively-reloaded; each buffer is of the same size \\(n\\), where \\(n\\) is size of a disk block</p>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#advantages","title":"Advantages","text":"<ul> <li>Using one system read command we can read \\(n\\) characters into a buffer, rather than using one system call per character</li> <li>A special character, represented by eof (character different from any possible character of source code), marks the end of the source file</li> </ul>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#2-buffer-scheme","title":"2 Buffer Scheme","text":"Pointer Purpose <code>lexeme_begin</code> marks the beginning of the current lexeme, whose extent we are attempting to determine <code>forward</code> scans ahead until a pattern match is found <p>When the next lexeme is determined, the following steps are taken:</p> <ul> <li><code>forward</code> is set to the character at its right end</li> <li>Record the lexeme as the attribute of the token</li> <li><code>lexemeBegin</code> is set to the character immediately after the lexeme just found</li> </ul> <p></p> <p>Advancing forward requires checking if end of a buffer is reached. </p> <code>forward</code> is at end of buffer - Reload other buffer from input- Move <code>forward</code> to beginning of newly loaded buffer <code>eof</code> character at the middle of buffer - marks the end of the input- terminate lexical analysis"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#recovery-strategies","title":"Recovery Strategies","text":"<p>Recovery strategies are used when no pattern for tokens matches any prefix of remaining input, preventing lexical analyzer from proceeding</p> <p>Goal: Transform prefix of remaining input into valid lexeme</p> <p>Possible error-recovery actions are:</p> <ul> <li>Panic Mode Recovery: Delete successive characters from the remaining input, until the lexical analyzer can find a well-formed token at the beginning of what input is left</li> <li>Insert a missing character into the remaining input</li> <li>Replace a character by another character</li> <li>Transpose two adjacent characters</li> </ul>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#parts-of-string","title":"Parts of String","text":"Term Meaning Example\\(s =\\) banana Prefix Starting character(s) \\(\\epsilon\\), b, ba, ban, bana, banan, banana Suffix Trailing character(s) \\(\\epsilon\\), a, an, ana, nana, anana, banana Substring Middle character(s) prefix_set \\(\\cup\\) suffix_set Proper Prefix Non-empty prefix \\(\\ne\\) original string b, ba, ban, bana, banan Proper Suffix Non-empty suffix \\(\\ne\\) original string a, an, ana, nana, anana Proper Substring Non-empty substring \\(\\ne\\) original string proper_prefix_set \\(\\cup\\) proper_suffix_set Subsequence Collection of characters of string(not necessarily contiguous, but left \\(\\to\\) right) baaa(too many combinations to list out)"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#operations","title":"Operations","text":"<p>In order of precedence</p> Operation Operator Strings Exponentiation \\(s^i\\) Concatenation \\(s_1 \\cdot s_2\\) Languages Kleene closure \\(L^*\\) Posive closure \\(L^+\\) Concatenation \\(L_1 \\cdot L_2\\) Union \\(L_1\\) \\vert \\(L_2\\)\\(L_1 \\cup L_2\\)"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#regular-definitions","title":"Regular Definitions","text":"<p>Helps to give names to regular expressions and use those names in subsequent expressions</p> <pre><code>d1 -&gt; r1\nd2 -&gt; r2\n...\ndn -&gt; rn\n</code></pre> <p>where </p> <ul> <li>\\(d_i\\) is a new symbol, such that</li> <li>\\(d_i \\not \\in \\epsilon\\)</li> <li>\\(d_i \\ne d_j\\)</li> <li>\\(r_i\\) is a RE over alphabet \\(\\epsilon \\cup \\{d_1, \\dots, d_{i-1} \\}\\)</li> </ul>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#lex","title":"Lex","text":"<p>Language that allows us to create our own lexical analyzer, without having handcode</p> <p>It represents everything in terms of a Finite State Machine, and then generates the code</p>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#lex-symbols","title":"Lex Symbols","text":"Symbol Meaning Example c non-operator character c \\c character \\(c\\) literally \u201cs\u201d string \\(s\\) literally . any character except <code>\\n</code> hello\\(\\implies 5 \\ .\\) ^ beginning of line ^abc $ end of line abc$ [s] any character in \\(s\\) \\([abcde]\\)$a [^s] any character not in \\(s\\) \\([\\wedge abcde]\\)$(a r* 0/more strings matching \\(r\\) (something)* r+ 1/more strings matching \\(r\\) (something)+ r? 0/1 strings matching \\(r\\) (something)? r{m,n} \\(\\text{count} \\in [m, n]\\) strings matching \\(r\\) (something){1, 5} \\(r_1r_2\\) \\(r_1\\) followed by \\(r_2\\)(select \\(r_1\\) and \\(r_2\\)) \\(r_1/r_2\\) \\(r_1\\) followed by \\(r_2\\)(select only \\(r_1\\)) $r_1 r_2$ \\(r_1\\) or \\(r_2\\) \\((r)\\) Same as \\(r\\) $(a"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#transitionstate-diagrams","title":"Transition/State Diagrams","text":"<p>Reg Exprs are translated into transition diagrams (representing Finite State Machines), which are then translated into program code for lexical analyzer</p>"},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#relational-operators","title":"Relational Operators","text":""},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#reserved-wordsidentifiers","title":"Reserved Words/Identifiers","text":""},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#unsigned-numbers","title":"Unsigned Numbers","text":""},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#whitespace","title":"Whitespace","text":""},{"location":"3_Core/Compiler_Contruction/02_Lexical_Analysis/#conflict-resolution","title":"Conflict Resolution","text":"<ul> <li>Longer prefix preferred</li> <li>If there are multiple matches for longest prefix, first pattern in lex program is preffered</li> </ul> <pre><code>a       {printf (\u201c1A\u201d);}\naa  {printf (\u201c2A\u201d);}\n\nInput : aaa\nOutput: 2A1A\n</code></pre> <pre><code>%%\nletter(letter|digit)*   { printf (\u201cID\u201d); }\nif                                      { printf (\u201cIF\u201d); }\n\nInput : if\nOutput: ID\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/","title":"03 Syntax Analysis","text":"<p>Also called as Parsing</p> <p>Regular expressions cannot be used, due to nested structure.</p> <p>Hence, we need a context-free grammar and PDA</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#syntaxparse-tree","title":"Syntax/Parse Tree","text":"<p>Each interior node represents an operation and the children of the node represent the arguments of the operation. It shows the order of operations.</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#yacc","title":"Yacc","text":"<p>Yet another compiler compiler</p> <p>This is covered in practicals</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#cfg","title":"CFG","text":"<p>Context-Free Grammar</p> <ul> <li>Set of terminals \\(T\\)</li> <li>Set of non-terminals \\(N\\)</li> <li>Start symbol \\(S\\) (non-terminal)</li> <li>Set of productions</li> </ul> \\[ X \\to Y_1 Y_2 \\dots Y_n \\] <p>where</p> <ul> <li>\\(X \\in N\\)</li> <li>\\(Y_i \\in T \\cup N \\cup \\{ \\epsilon \\}\\)</li> </ul> <p>LHS of any production/rule can only be a single non-terminal</p> <p>If \\(S\\) is the start symbol and \\(L(G)\\) is the language of \\(G\\), then \\(L(G)\\) is the set of strings that can be derived from \\(S\\)</p> \\[ (a_1 \\dots a_n) | S \\overset{*}{\\implies} a_1 \\dots a_n , \\forall a_i \\in T \\]"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#derivation","title":"Derivation","text":"<p>A derivation defines a parse tree. One parse tree may have multiple derivations.</p> <p>We have 2 different derivation types, which allows for different parser implementations.</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#types","title":"Types","text":"Type Parser Implementation Single-step Derivation Leftmost Top-Down Leftmost non-terminal replaced with corr RHS of non-terminal Rightmost Bottom-Up Rightmost non-terminal replaced with corr RHS of non-terminal"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#example","title":"Example","text":"<pre><code>G: E \u2192 E+E | E\u2217E | (E) | id | num\nInput: (a + 23) * 12\nTokens: LP ID PLUS NUM RP MUL NUM\n</code></pre> <pre><code>Leftmost\n\nE\n\u21d2  E * E\n\u21d2  (E) * E\n\u21d2  (E+E) * E\n\u21d2  (id+E) * E\n\u21d2  (id+num) * E\n\u21d2  (id+num) * num\n\nRightmost\n\nE\n\u21d2  E * E\n\u21d2  E * num\n\u21d2  (E) * num\n\u21d2  (E+E) * num\n\u21d2  (E+num) * num\n\u21d2  (id+num) * num\n</code></pre> <p>Parse tree is same for both</p> <p></p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#grammar","title":"Grammar","text":""},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#types_1","title":"Types","text":"Type Production Form Parser Left-Recursive \\(X \\to Xa\\) Bottom-Up Right-Recursive \\(X \\to aX\\) Bottom-Up/Top-Down <p>where</p> <ul> <li>\\(X\\) is a non-terminal</li> <li>\\(a\\) is a string of terminals, it is called left recursive production</li> </ul> <p>Top-down parser cannot work with Left recursive grammar, but both parsing works with right recursive grammar</p> <pre><code>G1: X \u2192  Xa | a // left recursive\nG2: X \u2192  XA | a // right recursive\n</code></pre> <pre><code>// left recursive\nX()\n{  \n  X();\n  match('a');\n}\n\n// right recursive\nX()\n{  \n  match('a');\n  X();\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#ambiguous-grammar","title":"Ambiguous Grammar","text":"<p>Grammar where the same string has multiple</p> <ul> <li>parse trees</li> <li>leftmost derivations</li> <li>rightmost derivations</li> </ul> <p>It gives incorrect results.</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#example_1","title":"Example","text":"<pre><code>Grammar G: E \u2192 E+E | E*E | (E) | id | num\nInput String s: id+id+id\n</code></pre> <p>In this case, leftmost derivation is incorrect, as <code>+</code> is left-associative, and should be treated as such.</p> <pre><code>// leftmost approach 1\nE\n\u2192 E+E\n\u2192\ufffc id + E\n\u2192 id + E + E\n\u2192 id + id + E\n\u2192 id + id + id\n\n// leftmost approach 2\nE\n\u2192 E + E\n\u2192 E + E + E\n\u2192 id + E + E\n\u2192 id + id + E\n\u2192 id + id + id\n</code></pre> <p></p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#if-statement","title":"<code>if</code> statement","text":"<pre><code>stmt \u2192 if expr then stmt\n     | if expr then stmt else stmt\n     | other\n</code></pre> <p>This has two leftmost derivations for</p> <pre><code>if E1 then if E2 then S1 else S2\n</code></pre> <p></p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#disambiguation","title":"Disambiguation","text":"<p>It is not possible to automatically convert ambiguous grammar into an unambiguous one. Hence, we need to use one of the following to eliminate ambiguity</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#rewrite-grammar","title":"Rewrite Grammar","text":"<pre><code>E \u2192 E + E | E * E | (E) | id\n\ncan be converted to\n\nE \u2192 E + T | T\nT \u2192 T * F | F\nF \u2192 (E) | id\n</code></pre> <pre><code>if grammar previously\n\ncan be converted to\n\nstmt        \u2192 m_stmt\n            | o_stmt\n            | other\nm_stmt  \u2192 if expr then m_stmt else m_stmt\n        | other\no_stmt  \u2192 if expr then stmt\n        | if expr then m_stmt else o_stmt\n</code></pre> <p>where</p> <ul> <li>matched statement: with <code>else</code></li> <li>open statement: without <code>else</code></li> </ul>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#tool-provided-disambiguation","title":"Tool-Provided Disambiguation","text":"<p>Yacc provides disambiguation declarations</p> <pre><code>%left + - * /\n%right = ^\n</code></pre> <p>This is covered in detail in practicals</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#example-grammar-for-prog-lang","title":"Example Grammar for prog lang","text":"<p>Consider a language consisting of semicolon (;) separated list of statements (except the last statement), where</p> <ul> <li>A statement can be</li> <li>id := expr </li> <li>print(expression list)</li> <li>expr can be expr + expr/num/id/ ( statement list, expr)</li> <li>expression list is comma-separated list of expressions</li> </ul> <pre><code>S \u2192 S ; S | id := E | print (L)\nE \u2192 E + E | num | id | ( S , E )\nL \u2192 L,E  | E\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#trees","title":"Trees","text":"Parse Tree Syntax Tree Alternate Name Concrete Syntax Tree Abstract Syntax Tree Grammar symbols? \u2705 \u274c(only terminals) Example"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#parsing","title":"Parsing","text":"<p>Parser decides</p> <ul> <li>which production rule is to be used, when required</li> <li>what is the next token</li> <li>Reserved word <code>if</code>, open paranthesis</li> <li>what is the structure to be built</li> <li><code>if</code> statement, expression</li> <li></li> </ul>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#types-of-parsers","title":"Types of Parsers","text":"Bottom-Up Top-Down Alternate Names LRShift-Reduction LLDerivation Finds rightmost derivation in reverse order Parse treeconstruction leaves \\(\\to\\) root root \\(\\to\\) leaves Start Input string Start symbol End Start symbol Input string Steps Shift &amp; Reduction Replace leftmost nonterminal w/ production rule Automatic Tools Handwritten parsersPredictive parsers Size ofGrammar class Larger Smaller"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#handle","title":"Handle","text":"<p>Substring matching right side of a production rule, which gets reduced in a manner that is reverse of rightmost derivation</p> <p>Not every substring that matches the right side of a production rule is a handle; only the one that gets chosen for reduction</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#sentential-form","title":"Sentential Form","text":"<p>Any string derivable from the start symbol</p> <p>A derivation is a series of rewrite steps</p> \\[ S \\implies \\gamma_0 \\implies \\gamma_1 \\implies \\dots \\implies \\gamma_n \u21d2 \\text{Sentence} \\] Non-terminals in \\(\\gamma_i\\) \\(\\gamma_i\\) is \\(0\\) Sentence in \\(L(G)\\) \\(\\ge 1\\) Sentential Form <p>Right sentential form occurs in rightmost derivation. If the grammar is unambiguous, then every right-sentential form of the grammar has exactly one handle</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#handle-pruning","title":"Handle Pruning","text":"<p>A right-most derivation in reverse can be obtained by handle-pruning.</p> <ol> <li>Start from \\(\\gamma_n\\), find a handle \\(A_n \\to \\beta_n\\) in \\(\\gamma_n\\)</li> <li>Replace \\(\\beta_n\\) by \\(A_n\\) to get \\(\\gamma_{n-1}\\)</li> <li>Repeat the same until we reach \\(S\\)</li> </ol>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#shift-reduce-parsing","title":"Shift-Reduce Parsing","text":"<ul> <li>Initial stack only  contains end-marker <code>$</code></li> <li>End of input string is marked by end-marker <code>$</code></li> </ul> <p>Shift input symbols into stack until reduction can be applied</p> <p>Parser has to find the right handles</p> <p>If a shift-reduce parser cannot be used for a grammar, that grammar is called as non-LR(k) grammar; ambiguous grammar can never be LR grammar.</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#steps","title":"Steps","text":"Step Action Shift New input symbol pushed to stack Reduction Replace handle at top of stack by non-terminal Accept Successful completion of parsing Error Syntax error discoveredParser calls error recovery routine"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#types_2","title":"Types","text":"<ol> <li> <p>Operator-Precedence Parser</p> </li> <li> <p>LR Parser</p> </li> </ol> <p>There are 3 sub-types; only their parsing tables are different</p> <ul> <li>Simple LR</li> <li>LookAhead LR (intermediate)</li> <li>Canonical LR (most general)</li> </ul> <p>Yacc creates LALR</p> <p></p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#conflicts","title":"Conflicts","text":"Type Shift-Reduce - Associativity &amp; precedence not ensured- Default action: prefer shift Reduce-Reduce"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#resolving-conflicts","title":"Resolving conflicts","text":"Easy? Rewrite grammar \u274c Yacc_Directives.md \u2705"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#solving-stack-questions","title":"Solving stack questions","text":"Stack Input Action <code>$</code> somethign"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#lrk-parsing","title":"LR(\\(k\\)) Parsing","text":"<p>Meaning</p> <ul> <li>Left-right scanning</li> <li>Rightmost derivation</li> <li>Lookahead of \\(k\\) i/p symbols at each step; if \\(k\\) not mentioned, \\(k=1\\)</li> </ul> <p>Class of grammars parsable by LR is proper superset of class of grammars parsable with predictive parsers</p> \\[ \\text{LL(1) Grammars} \\subset \\text{LR(1) Grammars} \\] <p>Can detect syntactic error as soon it performs left-to-right scan of input</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#why","title":"Why?","text":"<p>It is the most __ shift-reducing parser</p> <ul> <li>Efficient</li> <li>General</li> <li>Non-backtacking</li> </ul>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#lr-parsing-algorithm","title":"LR Parsing Algorithm","text":"Stack Remaining Input \\(S_0 X_1 S_1 \\dots X_m S_m\\) \\(a_i a_{i+1} \\dots a_n \\$\\) <p>where</p> <ul> <li>\\(X_i\\) is a terminal/non-terminal</li> <li>\\(S_i\\) is a state</li> </ul> <p>The parser action is determined by \\(S_m\\), \\(a_i\\), and parsing action table</p>"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#actions","title":"Actions","text":"action[\\(S_m, a_i\\)] Meaning Shift s Shift new input symbol and next state \\(s_i\\) into stack Reduce\\(A \\to \\beta\\) (or) \\(r_j\\) 1. Reduce by production no \\(j\\)2. Pop 2 \\(\\vert \\beta \\vert\\) items from stack (grammar symbol &amp; state symbol)3. Use goto table4. Push \\(A\\) and \\(s\\) where \\(s=\\text{goto} [s_{m-r}, A]\\)(current input symbol not affected) acc Accept blank Error"},{"location":"3_Core/Compiler_Contruction/03_Syntax_Analysis/#example_2","title":"Example","text":"<p>Parse <code>id*id+id$</code> using</p> <p></p> <p></p>"},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/","title":"04 Top Down Parsing","text":""},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#top-down-parsing","title":"Top-Down Parsing","text":"Recursive Descent Predictive Parsing Method Backtracking Table-Driven Widely-used? \u274c \u2705 Efficient? \u274c \u2705 Grammar General LL(1) Grammar Tries to find Leftmost derivation <ul> <li>Recursive predictive parsing is a type of Recursive Descent, without backtracking</li> <li>Non-recusive predictive parser is also known as LL(1) parser</li> </ul>"},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#recursive-descent-parsing","title":"Recursive Descent Parsing","text":""},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#computations","title":"Computations","text":"<p>I would recommend just drawing the tree, and finding the corresponding set of terminals.</p>"},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#firstx","title":"First(X)","text":"<p>The first symbol accessible;</p> X = \\(\\exist\\) X \\(\\to\\) First(X) \\(\\supset\\) \\(\\epsilon\\) \\(\\{\\epsilon\\}\\) Terminal \\(\\{X\\}\\) Non-Terminal \\(\\epsilon\\) \\(\\{\\epsilon\\}\\) Non-Terminal \\(Y_1 Y_2 Y_n\\) \\(Y_i \\to a; Y_{1, \\dots, i-1} = \\epsilon\\) \\(\\{a\\}\\) Non-Terminal \\(Y_1 Y_2 Y_n\\) \\(Y_i \\to \\epsilon,  \\forall i\\) \\(\\{\\epsilon\\}\\) <p></p>"},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#follownon-terminal","title":"Follow(Non-Terminal)","text":"Non-Terminal Start Symbol \\(S\\) Follow(S) \\(\\supset \\{\\$\\}\\) \\(A \\to \\alpha B \\beta\\) Follow(B) \\(=\\) First(\\(\\beta\\)) - \\(\\{\\epsilon\\}\\) \\(A \\to \\alpha B\\)\\(A \\to \\alpha B \\beta\\), and \\(\\epsilon \\in\\) First(\\(\\beta\\)) Follow(B) \\(\\supset\\) Follow(A)"},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#ll1-grammar","title":"LL(1) Grammar","text":"<p>No multiple-defined entries in parsing table</p> <ul> <li>Left-right scanning</li> <li>Leftmost derivation</li> <li>Lookahead of one i/p symbol at each step</li> </ul>"},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#ll1-parser","title":"LL(1) Parser","text":""},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#components","title":"Components","text":"Input Buffer String to be parsed, ending with <code>$</code> Output Producting rule representing step of leftmost derivation sequence of string in input buffer Stack Contains grammar symbols<code>$</code> signifies bottom of stackInitially, stack contains <code>$S</code>Only <code>$</code> in stack signfies parsing complete Parsing Table 2 dimensional array \\(M[A, a]\\)Each row is a non-terminal symbolEach column is <code>$</code>/terminal symbolEach entry holds production rule"},{"location":"3_Core/Compiler_Contruction/04_Top_Down_Parsing/#construction-of-parser","title":"Construction of Parser","text":"Replace with Elimination of left recursion $A \\to A \\alpha \\beta$ Elimination of left factoring $A \\to \\alpha \\beta_1 \\alpha \\beta_2 Calculate FIRST &amp; FOLLOW Construction of parsing tableFor each \\(A \\to \\alpha\\) For each terminal a in FIRST(\\(\\alpha\\)) Check if input string is accepted/not <p>This part is Incomplete</p>"},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/","title":"05 Symbol Table","text":""},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/#block-structure-languages","title":"Block Structure Languages","text":"<p>Basic units are blocks, which can be nested upto any depth</p>"},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/#scope-of-identifier","title":"Scope of Identifier","text":"<p>Refers to portion of program where the identifier is accessible</p> <p>Related concepts are function overriding, overloading, multiple variable declaration</p> <p>In C and similar languages, <code>{ ... }</code> marks the start and end of scope.</p>"},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/#example-problem","title":"Example Problem","text":"<pre><code>{ int x; char y; { bool y; x; y; } x; y; }\n</code></pre> <pre><code>{ { x:int; y:bool; } x:int; y:char; }\n</code></pre> <p>(Draw stack for this; couldn\u2019t draw cuz no time cuz of exam prep \u2026 sorry junior!)</p>"},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/#scoping-algorithm","title":"Scoping Algorithm","text":"When encountering <code>{</code> Push new stack node\u00a0(with empty symbol table within) Variable declaration/definition Update top\u2019s symbol table Variable invokation Check if element in top\u2019s symbol tableElse, check <code>top-1</code>'s symbol table and so on <code>}</code> Pop top stack node"},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/#push","title":"<code>push</code>","text":"<pre><code>temp = new SymbolTable Node\ntemp.prev = top\ntop = N\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/#pop","title":"<code>pop</code>","text":"<pre><code>temp = top\ntop = temp.prev\ntemp.prev = null\ndelete temp\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/05_Symbol_Table/#symbol-table-tree-representation","title":"Symbol Table Tree Representation","text":""},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/","title":"06 Semantic Analysis","text":""},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#attribute","title":"Attribute","text":"<p>May hold almost any thing: a string, a number, a memory location, a complex record.</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#semantic-rules","title":"Semantic Rules","text":"<p>Semantic rules set up dependencies between attributes which can be represented by a dependency graph. This dependency graph determines the evaluation order of these semantic rules. </p> <p>Evaluation of a semantic rule defines the value of an attribute. But a semantic rule may also have some side effects such as printing a value.</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#sdd","title":"SDD","text":"<p>SDD (Syntax Directed Definition) is a CFG with semantic rules, where each</p> <ul> <li>Grammar symbol is associated with a set of attributes</li> <li>Production rule is associated with a set of semantic rules (will be provided)</li> </ul> <p>If \\(X\\) is a symbol and \\(a\\) is one of its attribute, then \\(X.a\\) denotes value at \\(X\\)</p> <p>This set of attributes for a grammar symbol is partitioned into two subsets called synthesized and inherited attributes of that grammar symbol.</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#properties","title":"Properties","text":"<ul> <li>give high-level specifications for translations</li> <li>hide many implementation details such as order of evaluation of semantic actions.</li> <li>We associate a production rule with a set of semantic actions, and we do not say when they will be evaluated</li> </ul>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#idk","title":"IDK","text":"<p>Each production \\(A \\to \\alpha\\) is associated with a set of semantic rules of the form</p> <p>\\(b=f(c_1,c_2, \\dots ,c_n)\\) where \\(f\\) is a function, and \\(b\\) can be one of the following</p> <ul> <li>\\(b\\) is a synthesized attribute of A and \\(c_1, c_2, ... ,c_n\\) are attributes of the grammar symbols in the production \\(A \\to \\alpha\\)</li> <li>\\(b\\) is an inherited attribute one of the grammar symbols in \\(\\alpha\\), and \\(c_1,c_2, \\dots, c_n\\) are attributes of the grammar symbols in the production \\(A \\to \\alpha\\)</li> </ul>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#types-of-attributes","title":"Types of Attributes","text":"<p>Consider</p> <pre><code>A \u2192 BCD (A is parent; B,C,D are children)\n</code></pre> Synthesized Inherited Meaning Node takes values from children Node takes values from parent/sibling Example <code>A.s = B.s</code><code>A.s = C.s</code><code>A.s = D.s</code> <code>C.i = A.i</code><code>C.i = B.i</code><code>C.i = D.i</code>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#types-of-sdd","title":"Types of SDD","text":"Type S-Attributed Definitions/S-Attributed SDD/S-Attributed Grammar Only synthesis L-Attributed Definitions/L-Attributed SDD/L-Attributed Grammar - Synthesis- Inheritance from parent/left-siblings(from previous example: C.S = A.S, C.S=B.S, not C.S = D.S) <p>Unlike regular SDD, these attribute grammars cannot have side effects (such as printing values); they can only evaluate values of attributes.</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#translation-schemes","title":"Translation Schemes","text":"<p>Indicate the order of evaluation of semantic actions associated with a production rule</p> <p>Compared to SDD, they give some information about implementation details</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#annotated-parse-tree","title":"Annotated Parse Tree","text":"<p>Parse tree showing the values of attributes at each node</p> <p>Process of computing attributes values at nodes is called annotating/decorating</p> <p>Order of these computations depends on the dependency graph induced by the semantic rules</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#example-534","title":"Example: \\(5+3*4\\)","text":""},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#dependency-graph","title":"Dependency Graph","text":"<p>All updward arrows, since this S-Attributed: all parents inherit from child(ren).</p> <p></p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#example-real-p-q","title":"Example: <code>real p, q</code>","text":""},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#example-35","title":"Example: \\(3*5\\)","text":""},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#syntax-dericted-translation","title":"Syntax-Dericted Translation","text":"<p>Combination of CFG, Semantic Rules, and Semantic Actions denoted in <code>{}</code> can be placed anywhere in RHS</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#eg-conversion-of-infix-to-postfix-234","title":"Eg: Conversion of infix to postfix:  \\(2+3*4\\)","text":"<pre><code>E \u2192 E+T {print(\u2018+\u2019);}\nE \u2192 T\nT \u2192 T*F {print(\u2018*\u2019);}\nT \u2192 F\nF \u2192 num {print num.val;}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#eg-conversion-of-infix-to-postfix-12","title":"Eg: Conversion of infix to postfix:  \\(1+2\\)","text":""},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#coercions","title":"Coercions","text":"<p>Binary arithmetic operator may be applied to either a pair of integers or to a pair of floating-point numbers.</p> <p>If an operation involves a float and an integer, the compiler may convert/coerce the integer into a float</p>"},{"location":"3_Core/Compiler_Contruction/06_Semantic_Analysis/#type-checking","title":"Type Checking","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/","title":"07 Intermediate Code Generation","text":"<p>Ideally the details of source language are confined to the front end and the details of target machines to the back end.</p> <p></p>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#why-ic","title":"Why IC?","text":"<p>Rather than creating a compiler for every language to translate code for every machine arch, we create a compiler for every language to translate code to IC; this IC is then translated for the machine arch.</p> <p>This reduces complexity from \\((m \\times n) \\to (m+n)\\), where \\(m\\) and \\(n\\) are number of prog languages and machine arch respectively.</p>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#properties-of-ic","title":"Properties of IC","text":"<ul> <li> <p>easy to produce </p> </li> <li> <p>easy to translate into target machine code</p> </li> <li> <p>Three-address code (TAC)</p> </li> </ul> <p>consisting of sequence of assembly-like three-operand instructions of the form \\(x = y \\text{ op } z\\)</p> <ul> <li>Postfix notation</li> </ul>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#abstract-syntax-tree","title":"Abstract Syntax Tree","text":"<p>Binary tree where</p> <ul> <li>Leaves represent operands</li> <li>Non-terminals represent operators</li> </ul>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#eg-aab-c-b-cd","title":"Eg: \\(a+a*(b-c) +(b-c)*d\\)","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#directed-acyclic-graph-dag","title":"Directed Acyclic Graph (DAG)","text":"<p>AST where all subexpressions of an expression (even repeated subexpressions) occur only once.</p> <p>This helps the compiler generate more efficient code.</p>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#eg-aab-cb-cd","title":"Eg: \\(a+a*(b-c)+(b-c)*d\\)","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#eg-ii10","title":"Eg: \\(i=i+10\\)","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#steps-for-tree-representation","title":"Steps for tree representation","text":"<ol> <li>Check whether an identical node already exists</li> <li>If yes, the existing node is returned</li> <li>If no, create a new node and return it</li> </ol> <pre><code>// for a+a*(b-c)+(b-c)*d\n\np1  = Leaf (id, entry-a)\np2  = Leaf (id, entry-a) = p1\np3  = Leaf (id, entry- b)\np4  = Leaf (id, entry-c)\nP5  = Node ('-', p3, p4)\np6  = Node ('*', p1, p5)\np7  = Node ( '+' p1, p6 )\np8  = Leaf (id, entry-b) = p3\np9  = Leaf (id, entry-c) = p4\np10 = Node ('-', p3, p4) = p5\np11 = Leaf (id, entry-d)\np12 = Node ('*', p5 ,p11)\np13 = Node ('+',p7,p12)\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#steps-for-array-representation","title":"Steps for array representation","text":"<ul> <li>Search the array for a node M with label op, left child l , and right child r.</li> <li>If there is such a node, return the value number of M.</li> <li>If not, create in the array a new node N with label op, left child l, and right child r, and return its value number.</li> </ul> <p>We refer to nodes by giving the integer index/value number of the record for that node within the array.</p>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#three-address-code","title":"Three Address Code","text":"<p>Linearized representation of syntax tree/DAG in which explicit names correspond to internal nodes of the graph</p>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#features","title":"Features","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#arithmetic-expressions","title":"Arithmetic Expressions","text":"<ul> <li>1 operand on LHS</li> <li><code>=</code> if required</li> <li>\\(\\le 1\\) operation on RHS</li> <li>\\(\\le 2\\) operands on RHS</li> </ul>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#jumps","title":"Jumps","text":"<ul> <li><code>goto L</code></li> <li><code>if x goto L</code></li> <li><code>if x &lt;relop&gt; y goto L</code></li> </ul>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#functions","title":"Functions","text":"<ul> <li><code>param x</code></li> <li><code>call p</code></li> <li><code>y = call p</code></li> <li><code>return y</code></li> </ul>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#pointers","title":"Pointers","text":"<ul> <li><code>x = y[i]</code></li> <li><code>x[i] = y</code></li> <li><code>x = &amp;y</code></li> <li><code>x = *y</code></li> <li><code>*x = y</code></li> </ul>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#eg-xyz","title":"eg: \\(x+y*z\\)","text":"<pre><code>t1 = y * z\nt2 = x + t1\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#eg-idk","title":"eg: idk","text":"<pre><code>double a[10];\ndo i = i+1;\nwhile (a[i] &lt; v);\n</code></pre> <pre><code>// using symbolic labels\nL:  t1 = i + 1\n        i = t1\n        t2 = i * 8\n        t3 = a[t2]\n        if t3 &lt; v goto L\n\n// or\n\n// using position numbers\n\n100: t1 = i+1\n101: i  = t1\n102: t2 = i*8\n103: t3 = a[t2]\n104: if t3&lt;v goto 100\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#types-of-three-address-codes","title":"Types of Three Address Codes","text":"Fields Notes Quadruples op, arg1, arg2, result unary operators don\u2019t have arg2for assignment, op is <code>=</code>param does not have args2 and resultJumps put target label in result Triples op, arg1, arg2 We assume that result is stored in the corresponding index Indirect Triples Triples + List of pointers to triples <p>A benefit of quadruples and indirect triples over triples can be seen in an optimizing compiler, where instructions are often moved around.</p>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#ab-cb-c","title":"\\(a=b*-c+b*-c\\)","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#translations-arrays","title":"Translations: Arrays","text":"<p>Let</p> BA Base Address W Size of Element \\(R\\) Total number of rows \\(C\\) Total number of cols \\(L_r\\) Row starting index \\(L_c\\) Col starting index \\(i\\) Row index \\(j\\) Col index 1D \\(\\text{BA} + W*(i-L_r)\\) 2D \\(\\text{BA} + W*[(i-L_r)*C + (j-L_c)]\\) \u2026"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#c-aij-for-int-a43","title":"<code>c + a[i][j]</code> for <code>int a[4][3];</code>","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#a-bi-ci","title":"<code>a = b[i] + c[i]</code>","text":"<p>Correction: Row 6 for triple should be <code>+ (2) (5)</code></p>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#ai-b-c-b-d","title":"<code>a[i] = b * c + b * d</code>","text":""},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#flow-control","title":"Flow Control","text":"<p>The translation of statements such as if-else- statements and while-statements is tied to the translation of boolean expressions</p> <p>Boolean expressions</p> <ul> <li>alter flow of control</li> <li>compute logical values</li> </ul>"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#example","title":"Example","text":"<pre><code>while(a&lt;b) {\n  c=a+b;\n  a=a+1;\n}\n</code></pre> <pre><code>L1:\n    ifFalse a &lt; b L2 t1 = a + b\n    c = t1\n    t2 = a + 1\n    a = t2\n    goto L1\nL2:\n</code></pre> op arg1 arg2 result 0 LABEL L1 1 &lt; a b t1 2 iff(if false) t1 - L2 3 + a b t2 4 = t2 - c 5 + a 1 t3 6 = t3 a 7 goto L1 8 LABEL L2"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#example_1","title":"Example","text":"<pre><code>sum = 0\nfor(i=0; i&lt; n; i++)\n{\n    sum = sum + i;\n}\n</code></pre> <pre><code>sum = 0\ni = 0\nL1:\n  ifFalse i &lt; n L2\n  t1 = sum + i\n  sum = t1\n  i=i+1\ngoto L1 L2:\n</code></pre> op arg1 arg2 Result 0 = 0 sum 1 = 0 i 2 LABEL L1 3 &lt; i n t1 4 iff t1 - L2 5 + sum i t2 6 = t2 sum 7 goto L1 8 LABEL L2"},{"location":"3_Core/Compiler_Contruction/07_Intermediate_Code_Generation/#basic-blows-flow-graphs","title":"Basic Blows &amp; Flow Graphs","text":""},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/","title":"08 Code Generation","text":"<p>The problem is undecidable and most of  those subproblems, intractable (\\(\\not \\exists\\) efficient algorithms to solve them)</p>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#requirements","title":"Requirements","text":"<ul> <li>Maintain semantic meaning</li> <li>Must generate efficient code and makes maximum use of  available resources</li> <li>Code generator itself must be efficient</li> </ul>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#characteristics","title":"Characteristics","text":"<ul> <li>Target Machine has \\(n\\) registers \\(R_0, \\dots, R_{n-1}\\)</li> <li>All operands are integers</li> </ul>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#instruction-format","title":"Instruction Format","text":"load data <code>ld dest, src</code> store data <code>st dest, src</code> Arithmetic <code>add dest, src1, src2</code><code>sub dest, src1, src2</code><code>mul dest, src1, src2</code> Unconditional jump <code>br L</code> Conditional jump <code>bltz r, l</code><code>bgtz r, l</code><code>blez r, l</code><code>bgez r, l</code><code>bz r, l</code><code>bnz r, l</code>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#adressing-modes","title":"Adressing Modes","text":"Mode Example Meaning Indexed1 ld r1, a(r2) <code>r1 = contents(a+contents(r2))</code> Indexed2 ld r1, 100(r2) <code>r1 = contents(100+contents(r2))</code> Indirect ld r1, *100(r2) <code>r1 = contents(contents(100+contents(r2)))</code> Immediate add r1, r2, 100 <code>r1 = contents(r1) + 100</code>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#examples","title":"Examples","text":"<pre><code>x = y - z\n</code></pre> <pre><code>b = a[i]\n</code></pre> <pre><code>a[j] = c\n</code></pre> <pre><code>x = *p\n</code></pre> <pre><code>*p = y\n</code></pre> <pre><code>if x &lt; y goto M\n</code></pre> <pre><code>y = *q\nq = q  + 4\n*p = y\np = p + 4\n</code></pre> <pre><code>LD R1, q     // R1 = q\nLD R2, 0(R1) // R2 = contents(0+con(R1))\nST y, R2     // y = R2\nADD R1, R1, #4 //R1 = R1 + 4\nST q, R1       // q = R1\nLD R3, p       // R3 = p\nST 0(R3), R2   // contents(0+con(R3)) = R2\nADD R3, R3, #4  // R3 = R3 + 4\nST p, R3        // p = R3\n</code></pre> <pre><code>    s = 0\n    i = 0\nL1: if i &gt; n goto L2\n    s = s + i\n    i = i + 1\n    goto L1\nL2:\n</code></pre> <pre><code>    SUB R1, R1, R1\n    ST s, R1\n    ST i, R1\nL1: LD R1, i\n    LD R2, n\n    SUB R1, R1, R2  // R1 =i - n\n    BGTZ R1, L2\n    LD  R1, s\n    LD  R2, i\n    ADD R1, R1, R2\n    ST  s, R1\n    ADD R2, R2, #1\n    ST i, R2\n    BR L1\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#memory-representation","title":"Memory Representation","text":""},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#liveness","title":"Liveness","text":"<p>IC has representation with infinite no of temporaries. This program should be able to run on a machine with limited registers.</p> <p>2 temporaries \\(t_1\\) and \\(t_2\\) can be mapped to the same register, if \\(t_1\\) and \\(t_2\\) are never used at the same time</p> <p>A variable is live if its current value is used in the future, without any intermediary step changing the value</p> <p>Two Data structures</p> <ul> <li>Symbol table</li> <li>metadata associated with current instruction</li> </ul>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#liveness-analysis","title":"Liveness Analysis","text":"<p>Assume the symbol table shows all non-temporary variables as live on exit and \u201cno next use\u201d</p> <p></p> <p>Input: Basic block B of three-address statements</p> <p>Output: At each statement i: <code>x = y op z</code>, we attach to i the liveliness and next-uses of x, y and z, founding using the symbol table</p> <p>We start at the last statement of B and scan backwards</p> <ol> <li>In the symbol table, set x to \u201cnot live\u201d and \u201cno next use\u201d</li> <li>In the symbol table, set y and z to \u201clive\u201d, and next-uses of y and z to i</li> </ol>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#run-time-memory-models","title":"Run Time Memory Models","text":"<p>POPL</p>"},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#registers-allocation-assignment","title":"Registers Allocation &amp; Assignment","text":""},{"location":"3_Core/Compiler_Contruction/08_Code_Generation/#usage-counts","title":"Usage counts","text":"<ul> <li>use(x, B) is 1 if x is used in block B prior to any definition of x</li> <li>use (x, B) is 0 otherwise</li> <li>live(x, B) is 1 if x is live on exit from B and is assigned a value in B</li> <li>live(x, B) is 0 otherwise</li> </ul>"},{"location":"3_Core/Compiler_Contruction/09_Code_Optimization/","title":"09 Code Optimization","text":"<p>Code optimization can be done at the following </p> After IC generation After code generation Code OptimizationType M/C independent M/C dependent Performed on IC Target Code"},{"location":"3_Core/Compiler_Contruction/09_Code_Optimization/#classification","title":"Classification","text":"Classification Type Category Meaning By Scope Local Within a single basic block Peephole On window of instructions (usually local) Loop-Level On 1/more loops or loop nests Global Entire procedure Inter-Procedural Across multiple procedures/entire program By Machine Information used Machine Independent Machine Dependent By effecton program structure Algebraic Transformations Reordering transformation"},{"location":"3_Core/Compiler_Contruction/09_Code_Optimization/#forms-of-optimizations","title":"Forms of Optimizations","text":"Optimizations Before Optim After Optim Algebraic Simplification/Reduction in strength Simplify operations for machine <code>x*2 + x*1024</code> <code>x+x+(x&lt;&lt;10)</code> Common subexpression elimination Subexpression/Duplicate code are repeated expressionsTry to avoid subexpressions, by creating temporaries <code>A[I+10] = B[I+10]</code> <code>t=I+10</code><code>A[t]=B[t]</code> Copy propagation After <code>x=y</code>, try to use <code>y</code> as much as possible <code>t=I*4</code><code>s=t</code><code>a[s] = a[s]+4</code> <code>t=I*4</code><code>s=t</code><code>a[t] = a[t]+4</code> Constant propagation Replace constant variables with constant value <code>a=10</code><code>b=20</code><code>c=a+b</code> <code>a=10</code><code>b=20</code><code>c=10+20</code> Constant folding Evaluate expression with constants, and replace with the result <code>c=64+2</code> <code>c=66</code> Dead-code elimination Remove code that will never be used <code>if (3&gt;7) then { \u2026 }</code> (nothing) Loop Transformations/Loop Unrolling Change <code>for(i=0;i&lt;n;i++)</code> to <code>for(i=0;i&lt;n-s+1;i+=s)</code>replicate the loop body s times (changing also i as needed to i+1, i+2, etc\u2026).Will need an \u2018epilogue\u2019 if s does not divide n.Creates larger basic blocks and facilitates instruction scheduling. <code>for (i=0; i&lt;n; i++){ a[i]=b[i]*c[i]; }</code> <code>for (i=0; i&lt;n-s+1; i+=s) { a[I]=b[i]*c[i]; a[I+1]=b[i+1]*c[i+1]; \u2026 (the loop body repeated s times, from i to i+s-1) }</code><code>for (j=i; j&lt;n; j++) {a[j]=b[j]*c[j];}</code> Code Motion Move loop-invariant calculation outside loop(loop-invariant = expression having same value regardless of how many times loop is run) <code>while (i&lt;=limit-2)</code> <code>t = limit-2</code><code>while (i&lt;=t)</code>"},{"location":"3_Core/Compiler_Contruction/09_Code_Optimization/#automatic-garbage-collection","title":"Automatic Garbage Collection","text":"<ol> <li>Marking: Identify which pieces of memory are in use (very expensive process)</li> <li>Normal deletion: remove unreferenced objects</li> <li>Compacting: Reduce fragmentation by putting allocated memory next to each other</li> </ol>"},{"location":"3_Core/Compiler_Contruction/09_Code_Optimization/#generational-garbage-collection","title":"Generational Garbage Collection","text":"<p>Generations</p> <ul> <li>Young generation</li> <li>When the young generation fills up, this causes a minor garbage collection. Minor collections can be optimized assuming a high object mortality rate. A young generation full of dead objects is collected very quickly. Some surviving objects are aged and eventually move to the old generation</li> <li>All minor garbage collections are \"Stop the World\" events. This means that all application threads are stopped until the operation completes</li> <li>Old Generation</li> <li>Used to store long surviving objects. Typically, a threshold is set for young generation object and when that age is met, the object gets moved to the old generation. Eventually the old generation needs to be collected. This event is called a major garbage collection.</li> <li>Major garbage collection are also Stop the World events. Often a major collection is much slower because it involves all live objects. So for Responsive applications, major garbage collections should be minimized. Also note, that the length of the Stop the World event for a major garbage collection is affected by the kind of garbage collector that is used for the old generation space.</li> <li>Permanent Generation</li> <li>contains metadata required by the JVM to describe the classes and methods used in the application. The permanent generation is populated by the JVM at runtime based on classes in use by the application. In addition, Java SE library classes and methods may be stored here.</li> <li>Classes may get collected (unloaded) if the JVM finds they are no longer needed and space may be needed for other classes.</li> <li>The permanent generation is included in a full garbage collection.</li> </ul>"},{"location":"3_Core/Compiler_Contruction/09_Code_Optimization/#steps","title":"Steps","text":"<ol> <li>New objects are allocated to the eden space. Both survivor spaces start out empty</li> <li>When the eden space fills up, a minor garbage collection is triggered</li> <li>Referenced objects are moved to the first survivor space. Unreferenced objects are deleted when the eden space is cleared</li> <li>At the next minor GC, the same thing happens for the eden space. Unreferenced objects are deleted and referenced objects are moved to a survivor space. However, in this case, they are moved to the second survivor space (S1). In addition, objects from the last minor GC on the first survivor space (S0) have their age incremented and get moved to S1. Once all surviving objects have been moved to S1, both S0 and eden are cleared. Notice we now have differently aged object in the survivor space.</li> <li>At the next minor GC, the same process repeats. However this time the survivor spaces switch. Referenced objects are moved to S0. Surviving objects are aged. Eden and S1 are cleared.</li> <li>After a minor GC, when aged objects reach a certain age threshold, they are promoted from young generation to old generation</li> <li>As minor GCs continue to occure objects will continue to be promoted to the old generation space</li> <li>Eventually, a major GC will be performed on the old generation which cleans up and compacts that space</li> </ol>"},{"location":"3_Core/Compiler_Contruction/Practicals/","title":"CC Lab","text":"<p>All program codes from Anurag\u2019s GitHub</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/01_Lex_Introduction/","title":"01 Lex Introduction","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/01_Lex_Introduction/#lex","title":"Lex","text":"<p>Language translator, which converts</p> <ul> <li>from lex source program having regular expression, to match tokens in input string</li> <li>to a C program which has the function <code>yylex()</code> which is used to scan the input for tokens</li> </ul> <p>This will be the source file for lexical analysis of a C program. It will take a C program as input.</p> <p>We use regular expressions to match lexemes and generate tokens</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/01_Lex_Introduction/#lex-source-code","title":"Lex Source Code","text":"<pre><code>%{\n#include\nC Declarations\n%}\nLex Symbols\n%%\nRule\n%%\nAuxilliary functions (optional)\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/01_Lex_Introduction/#simplest-program","title":"Simplest Program","text":"<p>Default program which copies input to output</p> <pre><code>%%\n%%\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/01_Lex_Introduction/#compilation","title":"Compilation","text":"<pre><code>lex analyzer.l\ncc lex.yy.c -ll\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/01_Lex_Introduction/#execution","title":"Execution","text":"<pre><code>a.out\n\n// Takes user input\n</code></pre> <pre><code>a.out &lt; my_program.c &gt; sample.txt\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/01_Lex_Introduction/#variables","title":"Variables","text":"Data Type Meaning Default Value <code>yytext</code> <code>*char</code> pointer to matched string <code>yyleng</code> <code>int</code> length of matched string <code>yyin</code> <code>*file</code> Input Source STDIN (console) <code>yyout</code> <code>*file</code> Output Destination STDOUT (console)"},{"location":"3_Core/Compiler_Contruction/Practicals/02_Lex_Rules/","title":"02 Lex Rules","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/02_Lex_Rules/#match-real-numbers","title":"Match Real Numbers","text":"<pre><code>digit [0-9]\nsign [+|-]\n%%\n{sign}?{digit}+(\\.{digit}+)? printf(\"Matched real no: %s of length: %d\", yytext, yyleng);\n%%\n</code></pre> <pre><code>300.21\nMatched real no: 300.21 of length: 6\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/02_Lex_Rules/#conflict-resolution","title":"Conflict Resolution","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/02_Lex_Rules/#different-rules","title":"Different Rules","text":"<pre><code>%%\na printf(\"Matched %d a\\n\", yyleng);\naa printf(\"Matched %d a\\n\", yyleng);\n%%\n</code></pre> <pre><code>aaaaaaa\nMatched 2 a\nMatched 2 a\nMatched 2 a\nMatched 1 a\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/02_Lex_Rules/#similar-rules","title":"Similar Rules","text":"<p><code>Warning: Rule not matched</code></p> <pre><code>letter [a-z A-Z]\ndigit [0-9]\n%%\n{letter}({letter}|{digit})* printf(\"Matched id\");\n{letter}+ printf(\"Matched word\");\n%%\n</code></pre> <pre><code>sum\nMatched id\nhello\nMatched id\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/02_Lex_Rules/#match-word-immediately-followed-by-number","title":"Match word immediately followed by number","text":"<pre><code>letter [a-z A-Z]\nword {letter}+\ndigit [0-9]\n%%\n{word}/{digit} printf(\"Found word %s followed by number \", yytext);\n%%\n</code></pre> <pre><code>hello123\nFound word hello followed by number 123\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/","title":"03 Lex Auxilliary Functions","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#file-input-console-output","title":"File Input &amp; Console Output","text":"<pre><code>%%\n[0-9]+ printf(\"Found a number\");\n%%\nvoid main()\n{\n    yyin = fopen(\"in.txt\", \"r\"); // open file in read mode\n    yyout = fopen(\"out.txt\", \"w\"); // open file in read mode\n    yylex(); // invoke scanner\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#file-input-file-output","title":"File Input &amp; File Output","text":"<pre><code>%%\n[0-9]+ fprintf(yyout, \"Found a number\"); // print to file\n%%\nvoid main()\n{\n    yyin = fopen(\"in.txt\", \"r\"); // open file in read mode\n    yyout = fopen(\"out.txt\", \"w\"); // open file in write mode\n    yylex(); // invoke scanner\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#user-defined-vars-functions","title":"User-Defined Vars &amp; Functions","text":"<pre><code>%{\nvoid display();\n%}\ndigit [0-9]\nnumber {digit}+\n%%\nnumber display();\n%%\nvoid display()\n{\nprintf(\"Found a number\");\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#user-defined-vars","title":"User-Defined Vars","text":"<pre><code>%{\nvoid display();\nint a;\n%}\ndigit [0-9]\nnumber {digit}+\n%%\n{number} {\n  a = atoi(yytext);\n  display(a);\n}\n%%\nvoid display()\n{\nprintf(\"Found number %d\", a);\n}\n</code></pre> <p>or</p> <pre><code>%{\nvoid display();\n%}\ndigit [0-9]\nnumber {digit}+\n%%\n{number} display(yytext)\n%%\nvoid display(yytext)\n{\n  int a = atoi(yytext);\n    printf(\"Found number %d\", a);\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#question-1","title":"Question 1","text":"<p>Write a LEX program to recognize the following </p> <ul> <li>Operators: +, -, *, /, |, </li> <li>Numbers</li> <li>newline</li> <li>Any other character apart from the above should be recognized as mystery character</li> </ul> <p>For each of the above mentioned matches (classes of lexeme) in your input, the program should print the following: PLUS, MINUS, MUL, DIV, ABS, NUMBER, NEW LINE, MYSTERY CHAR respectively. Your program should also strip of whitespaces.</p> <pre><code>%%\n\"+\" printf(\"PLUS\");\n\"-\" printf(\"MINUS\");\n\"*\" printf(\"MUL\");\n\"/\" printf(\"DIV\");\n\"|\"\" printf(\"ABS\");\n[0-9]+ printf(\"Number\");\n\\n printf(\"Newline\\n\");\n. printf(\"Wildcard \");\n%%\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#question-2","title":"Question 2","text":"<p>Write a LEX program to print the number of words, characters and lines in a given input.</p> <pre><code>%{\nint cc = 0, wc = 0, lc = 0;\n%}\n%%\n[a-zA-Z]+ {wc++; cc+=strlen(yytext);}\n\\n {lc++; cc++;}\n. {cc++;}\n%%\n\nint yywrap()\n{\n    return 1;\n}\n\nvoid main()\n{\n    yylex();\n    printf(\"%d\\n\", cc);\n    printf(\"%d\\n\", wc);\n    printf(\"%d\\n\", lc);\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#question-3","title":"Question 3","text":"<p>Write a LEX program to print the number of words, characters and lines in a given input, but a word and its characters are counted only if its length is greater than or equal to 6.</p> <pre><code>%{\n  #include &lt;stdio.h&gt;\n  int num_words = 0;\n  int num_chars = 0;\n  int num_lines = 0;\n%}\n%%\n[\\t]+ {\n  // Ignore whitespace\n}\n\n\\n {\n  num_lines++;\n}\n\n[a - zA - Z]{6,} {\n  num_words++;\n  num_chars += yyleng;\n}\n\n. {\n  if (yyleng &gt;= 6)\n    {\n      num_chars += yyleng;\n    }\n}\n\n%%\nint main ()\n{\n  yylex ();\n  printf (\"Number of words: %d\\n\", num_words);\n  printf (\"Number of characters: %d\\n\", num_chars);\n  printf (\"Number of lines: %d\\n\", num_lines);\n  return 0;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/03_Lex_Auxilliary_Functions/#question-4","title":"Question 4","text":"<p>Write a LEX program to print if the input is an odd number or an even number along with its length. Also, the program should check the correctness of the input (i.e. if the input is one even number and one odd number).</p> <pre><code>%{\n#include&lt;stdlib.h&gt;\n#include&lt;stdio.h&gt;\n  int number_1;\n  int number_2;\n%}\nnumber_sequence [0 - 9]*\n%%\n{number_sequence}[0 | 2 | 4 | 6 | 8] {\n  printf (\"Even number [%d]\", yyleng);\n  return atoi (yytext);\n}\n\n{number_sequence}[1 | 3 | 5 | 7 | 9] {\n  printf (\"Odd number [%d]\", yyleng);\n  return atoi (yytext);\n}\n%%\nint main()\n{\n  printf (\"\\nInput an even number and an odd number\\n\");\n  number_1 = yylex ();\n  number_2 = yylex ();\n  int diff = number_1 - number_2;\n  if (diff % 2 != 0)\n    printf\n      (\"\\nYour inputs were checked for correctness, \\nResult : Correct\\n\");\n  else\n    printf\n      (\"\\nYour inputs were checked for correctness,\\nResult : Incorrect\\n\");\n  return 1;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/04_Lex_Something/","title":"04 Lex Something","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/04_Lex_Something/#question-1","title":"Question 1","text":"<p>Write a LEX program to get a binary input and print whether the given input is a power of two or not.</p> <pre><code>%{\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n%}\n%%\n[01]+ {\n    int num = 0, base = 2, exp;\n    int result;\n    int len = strlen(yytext);\n    for (int i = 0; i &lt; len; i++) {\n        if (yytext[i] == '1') {\n        result = 1;\n        exp = len-i-1;\n            while (exp != 0) {\n            result *= base;\n            --exp;\n        }\n        num += result;\n        }\n    }\n    if (num == 0) {\n        printf(\"The input is not a power of two\\n\");\n    } else if ((num &amp; (num-1)) == 0) {\n        printf(\"The input is a power of two\\n\");\n    } else {\n        printf(\"The input is not a power of two\\n\");\n    }\n}\n. {\n    printf(\"Invalid input\\n\");\n}\n%%\nint main() {\n    yylex();\n    return 0;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/04_Lex_Something/#question-2","title":"Question 2","text":"<p>Write a LEX program to insert line numbers to a file. For this copy your favourite C program \u201cinput.c\u201d to your folder which would be the input to your LEX program.</p> <pre><code>%{\n#include &lt;stdio.h&gt;\nint line_number = 1;\n%}\n\n%%\n\n\\n {\n    line_number++;\n    printf(\"\\n%d: \", line_number);\n}\n\n. {\n    printf(\"%c\", yytext[0]);\n}\n\n%%\n\nint main() {\n    FILE *input_file = fopen(\"input.c\", \"r\");\n    if (input_file == NULL) {\n        printf(\"Error: cannot open file.\\n\");\n        return 1;\n    }\n    yyin = input_file;\n    printf(\"1: \");\n    yylex();\n    fclose(input_file);\n    return 0;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/04_Lex_Something/#question-3","title":"Question 3","text":"<p>Write a LEX program to save the contents of an input file excluding comment lines to another file.</p> <pre><code>%{\n#include &lt;stdio.h&gt;\n#include &lt;stdbool.h&gt;\nbool in_block_comment = false;  /* initialize in_block_comment flag to false */\nbool in_line_comment = false;   /* initialize in_line_comment flag to false */\n%}\n\n%%\n\n\"/*\"    { in_block_comment = true; }  /* set in_block_comment flag to true on start of block comment */\n\"*/\"    { in_block_comment = false; }  /* set in_block_comment flag to false on end of block comment */\n\"//\"    { in_line_comment = true; }   /* set in_line_comment flag to true on start of line comment */\n\\n      {\n            if (in_line_comment) { in_line_comment = false; }  /* set in_line_comment flag to false on end of line */\n            if (!in_block_comment) { fputc('\\n', yyout); }     /* write newline character to output file if not in comment */\n         }\n.       { if (!in_block_comment &amp;&amp; !in_line_comment) { fputc(yytext[0], yyout); } }  /* write character to output file if not in comment */\n%%\n\nint main(int argc, char** argv) {\n    if (argc != 3) {\n        printf(\"Usage: %s input_file output_file\\n\", argv[0]);\n        return 1;\n    }\n\n    FILE* input_file = fopen(argv[1], \"r\");\n    if (input_file == NULL) {\n        printf(\"Error: could not open input file %s\\n\", argv[1]);\n        return 1;\n    }\n\n    FILE* output_file = fopen(argv[2], \"w\");\n    if (output_file == NULL) {\n        printf(\"Error: could not open output file %s\\n\", argv[2]);\n        return 1;\n    }\n\n    yyin = input_file;\n    yyout = output_file;\n    yylex();\n\n    fclose(input_file);\n    fclose(output_file);\n    return 0;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/04_Lex_Something/#question-4","title":"Question 4","text":"<p>Write a LEX program that would take a BITS student's roll number as input and prints the details of the student based on that. You are expected to write regular expressions that would synthesize information like, year of joining, specialization, PS/Thesis, Registration index, Campus (U) etc. from the given roll number. If the given input does not abide by the Roll number format, print some error message.</p> <pre><code>%{\n#include &lt;stdio.h&gt;\n%}\n\n%%\n\n^[0-9]{4}[A-Za-z0-9]{2}(PS|TS)[0-9]{4}[HPUG]$  {\n    printf(\"Year of Joining: %c%c%c%c\\n\",yytext[0], yytext[1],yytext[2], yytext[3]);\n    printf(\"Specialization: %c%c\\n\", yytext[4], yytext[5]);\n    printf(\"Thesis/Practice School: %c%c\\n\", yytext[6], yytext[7]);\n    printf(\"Registration Index: %c%c%c%c\\n\", yytext[8], yytext[9], yytext[10], yytext[11]);\n    printf(\"Campus: %c\\n\", yytext[12]);\n}\n.  {\n    printf(\"Invalid roll number format.\\n\");\n}\n\n%%\n\nint main() {\n    yylex();\n    return 0;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/","title":"05 Yacc Introduction","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#yacc","title":"Yacc","text":"<p>yet another compiler compiler</p> <p>Parser Generator: Bottom-up parser</p> <p>Lexical analyzer is a dependency for syntax analyzer. In this case, lex is a dependency for yacc.</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#structure-of-program","title":"Structure of program","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#filenamel","title":"<code>filename.l</code>","text":"<pre><code>%{\n#include \"y.tab.h\"\nextern int yylval;\n%}\n%%\n\n%%\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#filenamey","title":"<code>filename.y</code>","text":"<pre><code>%{\n  int yylex(void);\n  void yyerror(char *);\n\n  #include &lt;stdio.h&gt;\n  #include &lt;stdlib.h&gt;\n\n  C includes\n  C declaration\n%}\n\n%token token_declaration_1 token_declaration_2\n// lex must be able to identify these tokens\n\n%%\n\nLHS : RHS1  {Action1}\n        | RHS2  {Action2}\n        | RHS3  {Action3}\n        ;\n\n%%\n\nvoid yyerror(char *s)\n{\n  printf(\"%s\", s);\n}\n\nvoid main()\n{\n  yyparse();\n}\n\nC functions\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#compilation-execution","title":"Compilation &amp; Execution","text":"<pre><code>yacc -d filename.y\nlex filename.l\ncc lex.yy.c y.tab.c -ll -lm\na.out\n</code></pre> Required? <code>-d</code> Flag that instructs to generate the definitions of the tokens \u2705 <code>-ll</code> Link lex loader \u2705 <code>-lm</code> Link math"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#output-files","title":"Output Files","text":"File Name Purpose <code>y.tab.h</code> Header file containing definitions of tokens(must be included in lex file) <code>y.tab.c</code> Parser C Code"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#value-of-symbols","title":"Value of Symbols","text":"<p>Every yacc grammar symbol has a value associated with it.</p> <ul> <li>LHS = <code>$$</code></li> <li>RHS = <code>$1, $2, ...</code></li> </ul> \\[ \\$\\$ = \\$1 \\text{ Operation } \\$3 \\\\ \\] <p>Example</p> \\[ \\begin{aligned} \\$\\$ &amp;= \\$1 \\text{ + } \\$3 \\\\ \\$\\$ &amp;= \\$1 \\text{ - } \\$3 \\\\ \\$\\$ &amp;= \\$1 \\end{aligned} \\]"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#question-1","title":"Question 1","text":"<p>Write a simple calculator which can gives result for an addition/subtraction expression (ambiguity allowed).</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#05_1l","title":"<code>05_1.l</code>","text":"<pre><code>%{\n#include \"y.tab.h\"\nextern int yylval;\n%}\n%%\n[0-9]+ {\n    yylval = atoi(yytext);\n    return INTEGER;\n}\n\"+\" return PLUS;\n\"-\" return MINUS;\n\"\\n\" return NL;\n[ \\t] ; \n. printf(\"Invalid\");\n%%\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#05_1y","title":"<code>05_1.y</code>","text":"<pre><code>%{\n  int yylex(void);\n  void yyerror(char *);\n\n  #include &lt;stdio.h&gt;\n  #include &lt;stdlib.h&gt;\n%}\n\n%token INTEGER PLUS MINUS NL\n\n%%\nprogram:\nexpr NL {printf(\"%d\\n\", $1); exit(0);}\n;\nexpr:\nINTEGER {$$=$1;}\n| expr PLUS expr    {$$=$1+$3;}\n| expr MINUS expr   {$$=$1-$3;}\n;\n%%\nvoid yyerror(char *s)\n{\n    printf(\"%s\\n\", s);\n}\nint main()\n{\n    yyparse();\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#compilation","title":"Compilation","text":"<pre><code>yacc -d calculator.y\n</code></pre> <pre><code>yacc: 4 shift/reduce conflicts\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#output","title":"Output","text":"<pre><code>1 - 5 + 2\n-6 (should actually be -2)\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/05_Yacc_Introduction/#conversion-from-bnf-to-yacc-rule","title":"Conversion from BNF to YACC Rule","text":"<pre><code>A -&gt; a | \u03b5\n\nA : a\n    | \n    ;\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/","title":"06 Yacc Directives","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#directives","title":"Directives","text":"<p>Along with the tokens</p> <pre><code>%left PLUS MINUS\n%left MUL DIV\n%right POW\n%%\n%%\n</code></pre> <p>The directives written later have higher precedence.</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#question-1","title":"Question 1","text":"<p>Write a simple calculator which can gives result for an addition/subtraction expression (without ambiguity).</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_1l","title":"<code>06_1.l</code>","text":"<p>same as Basic Calculator </p>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_1y","title":"<code>06_1.y</code>","text":"<pre><code>%{\n  int yylex(void);\n  void yyerror(char *);\n\n  #include &lt;stdio.h&gt;\n  #include &lt;stdlib.h&gt;\n%}\n\n%token INTEGER PLUS MINUS NL\n%left PLUS MINUS                                            /* 1 */\n%%\nprogram:\nexpr NL {printf(\"%d\\n\", $1); exit(0);}\n;\nexpr:\nINTEGER {$$=$1;}\n| expr PLUS expr    {$$=$1+$3;}\n| expr MINUS expr   {$$=$1-$3;}\n;\n%%\nvoid yyerror(char *s)\n{\n    printf(\"%s\\n\", s);\n}\nint main()\n{\n    yyparse();\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#output","title":"Output","text":"<pre><code>1-5+2\n-2\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#question-2","title":"Question 2","text":"<p>The program should keep going on until the user exits using <code>Ctrl-D</code></p>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_2l","title":"<code>06_2.l</code>","text":"<p>same as Basic Calculator </p>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_2y","title":"<code>06_2.y</code>","text":"<pre><code>%{\n  int yylex(void);\n  void yyerror(char *);\n\n  #include &lt;stdio.h&gt;\n  #include &lt;stdlib.h&gt;\n  %}\n\n%token INTEGER PLUS MINUS NL\n%left PLUS MINUS                                            /* 1 */\n%%\nprogram:\nprogram expr NL {printf(\"%d\\n\", $2);}   /* 2 */\n| \n;\nexpr:\nINTEGER {$$=$1;}\n| expr PLUS expr    {$$=$1+$3;}\n| expr MINUS expr   {$$=$1-$3;}\n;\n%%\nvoid yyerror(char *s)\n{\n  printf(\"%s\\n\", s);\n}\nint main()\n{\n  yyparse();\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#output_1","title":"Output","text":"<pre><code>1 - 5 + 2\n-2\n1 - 5 + 2\n-2\n1 - 5 + 2\n-2\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#question-3","title":"Question 3","text":"<p>Extend the calculator to incorporate some new functionality. New features include arithmetic operators * and / that can multiply and divide integers respectively. Parentheses may be used to over-ride operator precedence. Note * and / operators have higher precedence over + and \u2013 operators. Also note that * and / are left associative. Ensure this using directive in YACC. </p>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_3l","title":"<code>06_3.l</code>","text":"<pre><code>%{\n#include \"y.tab.h\"\nextern int yylval;\n%}\n%%\n[0-9]+ {\n    yylval = atoi(yytext);\n    return INTEGER;\n}\n\"+\" return PLUS;\n\"-\" return MINUS;\n\"*\" return MUL;     /* 1 */\n\"/\" return DIV;     /* 2 */\n\"^\" return POW;     /* 3 */\n\"\\n\" return NL;     /* 4 */\n[ \\t] ; \n. printf(\"Invalid\");\n%%\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_3y","title":"<code>06_3.y</code>","text":"<pre><code>%{\n  int yylex(void);\n  void yyerror(char *);\n\n  #include &lt;stdio.h&gt;\n  #include &lt;stdlib.h&gt;\n  #include &lt;math.h&gt;\n%}\n\n%token INTEGER PLUS MINUS NL\n%left PLUS MINUS\n%left MUL DIV\n%right POW                                              /* 1 */\n%%\nprogram:\nprogram expr NL {printf(\"%d\\n\", $2);}\n| \n;\nexpr:\nINTEGER {$$=$1;}\n| expr PLUS expr    {$$=$1+$3;}\n| expr MINUS expr   {$$=$1-$3;}\n| expr MUL expr {$$=$1*$3;}             /* 2 */\n| expr DIV expr {$$=$1/$3;}             /* 3 */\n| expr POW expr {$$=pow($1, $3);}   /* 4 */\n;\n%%\nvoid yyerror(char *s)\n{\n  printf(\"%s\\n\", s);\n}\nint main()\n{\n  yyparse();\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#output_2","title":"Output","text":"<pre><code>2 - 2 ^ 2\n-3\n2 - 3 * 3 ^ 6\n-2185\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#question-4","title":"Question 4","text":"<p>Modify the calculator application so that it works for floating point values also.</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#question-5","title":"Question 5","text":"<p>Modify the grammar to allow single-character variables to be specified in assignment statements. The following illustrates sample input and calculator output:</p> <pre><code>user: 3 * (4 + 5)\ncalc: 27\nuser: x = 3 * (4 + 5)\nuser: y = 5\nuser: x\ncalc: 27\nuser: y\ncalc: 5\nuser: x + 2*y\ncalc: 37\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_5l","title":"<code>06_5.l</code>","text":"<pre><code>%{\n  #include \"y.tab.h\"\n  extern int yylval;\n%}\n%%\n\n[a-z] {\n    yylval = *yytext - 'a';\n    return VARIABLE;\n}\n\n[0-9]+ {\n    yylval = atoi(yytext);\n    return INTEGER;\n}\n\n[-+()=*/\\n] { return *yytext; }\n[ \\t] ;\n\n. yyerror(\"invalid character\");\n%%\n\nint yywrap(void) {\n return 1;\n} \n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/06_Yacc_Directives/#06_5y","title":"<code>06_5.y</code>","text":"<pre><code>%{\n    #include&lt;stdio.h&gt;\n    int flag=0;\n    int yylex(void);\n    int sym[26];\n%}\n%token INTEGER VARIABLE\n%left '+' '-'\n%left '*' '/'\n%%\n\nprogram:\n    program statement '\\n'\n    |\n    ;\nstatement:\n    expr { printf(\"%d\\n\", $1); }\n    | VARIABLE '=' expr { sym[$1] = $3; }\n    ;\nexpr:\n    INTEGER\n    | VARIABLE { $$ = sym[$1]; }\n    | expr '+' expr { $$ = $1 + $3; }\n    | expr '-' expr { $$ = $1 - $3; }\n    | expr '*' expr { $$ = $1 * $3; }\n    | expr '/' expr { $$ = $1 / $3; }\n    | '(' expr ')' { $$ = $2; }\n    ;\n%%\nvoid main()\n{\nprintf(\"\\nEnter Any Arithmetic Expression which can have operations Addition, Subtraction, Multiplication, Division, Modulus and Round brackets:\\n\");\n\nyyparse();\nif(flag==0)\nprintf(\"\\nEntered arithmetic expression is Valid\\n\\n\");\n}\n\nvoid yyerror()\n{\nprintf(\"\\nEntered arithmetic expression is Invalid\\n\\n\");\nflag=1;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/","title":"08 09 10 Yacc Mini Compiler","text":"<p>Write the LEX and YACC source to recognize the following:</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#the-template-for-the-c-program-is","title":"The template for the C program is","text":"<pre><code>#include&lt;stdio.h&gt;\nint main( )\n{\n} \nPGM -&gt; HEADER INT MAIN LB RB LCB RCB\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#declaration-statements","title":"Declaration statements:","text":"<p>Allow declaration statements inside the program body. Integer variables separated by comma can be declared inside the program body. A program can have multiple declaration statements. Variables are sequence of lower-case alphabets.Each declaration statement is ended by a semicolon. int a, b;</p> <pre><code>PGM -&gt; HEADER INTMAIN LB RB LCB BODY RCB\nBODY -&gt; DECL_STMTS\nDECL_STMTS -&gt; DECL_STMT DECL_STMTS | DECL_STMT\nDECL_STMT -&gt;INT VAR_LIST SC\nVAR_LIST-&gt;VAR COMA VAR_LIST | VAR\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#operators-program-statements","title":"Operators &amp; Program Statements","text":"<p>Allow declaration statements to be followed by program statements inside the program body. Program statements are ended by a semicolon. Program statements can be arithmetic expressions involving +-*/ operators.</p> <pre><code>PGM -&gt; HEADER INT MAIN LB RB LCB BODY RCB\nBODY -&gt; DECL_STMTS PROG_STMTS\nDECL_STMTS -&gt; DECL_STMT DECL_STMTS | DECL_STMT\nPROG_STMTS -&gt; PROG_STMT PROG_STMTS | PROG_STMT  \nDECL_STMT -&gt; INT VAR_LIST SC\nVAR_LIST -&gt; VAR COMA VAR_LIST | VAR\nPROG_STMT -&gt; VAR EQ A_EXPN SC\nA_EXPN -&gt; A_EXPN OP A_EXPN | LB A_EXPN RB | VAR\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#modify-your-lex-program-to-incorporate-the-following-changes","title":"Modify your LEX program to incorporate the following changes","text":"<p>As per the current set up, the programmer is supposed to use only lower-case alphabets in variable names in their C program. Modify your lex program so as to let the programmer have uppercase letters A to Z together with digits 0 to 9 and underscore character in variable names. Ensure that a variable name always begin with a character.</p> <p>Terminate your program with an error message if in case the programmer uses keywords if, while, do, and for as variable names. Note that it is permitted to have variable names beginning with keywords (ifvar, thenextcount, donut etc.) (hint: rely on conflict resolution rules in LEX).</p> <p>Add provision to declare variables of type float, double and char.</p>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#adding-operators-to-the-language","title":"Adding operators to the language","text":"<ul> <li>Incorporate arithmetic expressions involving binary operators +, -, *, /, ^ (exponent) into your compiler. Note that the exponent operator is a right associative operator and has higher precedence than other arithmetic operators (+, -, *, /).</li> <li>Incorporate unary pre/post increment ++ and pre/post decrement -- operators too (are of highest precedence and left associative).</li> <li>Incorporate the modulo operator (%). It has the same precedence as * and / operators and is left associative. </li> <li>Include numeric integer constants as expressions.</li> <li>Also include parenthesized expressions</li> <li>Variables can be of int/float/char/double type</li> <li>In the given implementation, the input C file is expected to have all declaration statements in the beginning, followed by program statements. Rewrite your grammar to let the user to have declarative and program statements in any arbitrary interleaved order in their input C program.</li> </ul>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#combined-program","title":"Combined Program","text":""},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#filel","title":"<code>file.l</code>","text":"<pre><code>%{\n#include \"y.tab.h\"\nextern int yylval;\n%}\n%%\n\"#include&lt;stdio.h&gt;\"    { return T_HEADER; }\n\"int\"    { return T_INT; }\n\"float\"  { return T_FLOAT; }\n\"double\" { return T_DOUBLE; }\n\"char\"   { return T_CHAR; }\n\"main\"   { return T_MAIN; }\n\"do\"                        { printf(\"ERROR! Reserved keyword do\\n\"); return -1;}\n\"if\"                        { printf(\"ERROR! Reserved keyword if\\n\"); return -1;}\n\"while\"                 { printf(\"ERROR! Reserved keyword while\\n\"); return -1;}\n\"for\"                       { printf(\"ERROR! Reserved keyword for\\n\"); return -1;}\n\\{       { return T_LCB; }\n\\}       { return T_RCB; }\n\\(       { return T_LB; }\n\\)       { return T_RB; }\n\\n       { yylineno++; }\n[ \\t]    ;\n[0-9]+   { return T_NUMBER; }\n[-+*/]   { return T_OP; }\n=        { return T_EQ; }\n[a-zA-Z][a-zA-Z0-9_]*       { return T_VARIABLE; }\n\",\"        { return T_COMMA; }\n\";\"        { return T_SC; }\n.      { return yytext[0]; }\n%%\nint yywrap()\n{\nreturn 1;\n}\n</code></pre>"},{"location":"3_Core/Compiler_Contruction/Practicals/08_09_10_Yacc_Mini_Compiler/#filey","title":"<code>file.y</code>","text":"<pre><code>%{\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\nint yylex(void);\nvoid yyerror(char *);\n%}\n%token T_HEADER T_INT T_CHAR T_FLOAT T_DOUBLE T_MAIN T_LB T_RB T_LCB T_RCB\n%token T_NUMBER T_VARIABLE T_COMMA T_SC T_OP T_EQ\n%left T_OP\n%%\nprogram: HEADER INT MAIN LB RB LCB BODY RCB\n{\n    printf(\"Valid\\n\");\n}\n;\nBODY: DECL_STMTS PROG_STMTS\n{\n    printf(\"Token: Body\\n\");\n}\n;\nHEADER: T_HEADER\n{\n    printf(\"Token: Header\\n\");\n}\n;\nINT: T_INT\n{\n    printf(\"Token: Int\\n\");\n};\nMAIN: T_MAIN\n{\n    printf(\"Token: Main\\n\");\n}\n;\nLB: T_LB\n{\n    printf(\"Token: Left_Bracket\\n\");\n}\n;\nRB: T_RB\n{\n    printf(\"Token: Right_Bracket\\n\");\n}\n;\nLCB: T_LCB\n{\n    printf(\"Token: Left_Curly_Bracket\\n\");\n}\n;\nRCB: T_RCB\n{\nprintf(\"Token: Right_Curly_Bracket\\n\");\n}\n;\nDECL_STMTS: DECL_STMT DECL_STMTS\n                    |   DECL_STMT\n{\n    printf(\"Token: Statement\\n\");\n}\n;\n\nPROG_STMTS: PROG_STMT PROG_STMTS\n                    | PROG_STMT\n;\nDECL_STMT:  T_INT VAR_LIST T_SC\n                    | T_FLOAT VAR_LIST T_SC\n                    | T_DOUBLE VAR_LIST T_SC\n                    | T_CHAR VAR_LIST T_SC\n                    ;\n\nVAR_LIST: T_VARIABLE T_COMMA VAR_LIST\n                    |   T_VARIABLE\n                    ;\n\nPROG_STMT: T_VARIABLE T_EQ A_EXPN T_SC\n                     ;\n\nA_EXPN: A_EXPN T_OP A_EXPN\n            | T_LB A_EXPN T_RB\n            | T_VARIABLE\n            | T_NUMBER\n            ;\n%%\nvoid main() \n{\n    printf(\"Enter a C program:\\n\");\n    yyparse();\n}\n\nvoid yyerror(char *s) \n{\n    printf(\"The provided code is invalid\\n\", s);\n    exit(1);\n}\n</code></pre>"},{"location":"3_Core/Computer_Architecture/","title":"Computer Architecture","text":"<p>Taught by Dr. Tamizharasan Periyasami</p> <p>This is one of the most important core courses of Computer Engineering</p> <ul> <li>Operating Systems</li> <li>Computer Architecture</li> <li>Compiler Constuction</li> </ul>"},{"location":"3_Core/Computer_Architecture/#overview","title":"Overview","text":"<ul> <li> <p>Components of computer</p> </li> <li> <p>Performance and how to measure it</p> </li> <li> <p>MIPS ISA</p> <ul> <li>Microprocessor without Interlocked Pipeline Stages</li> <li>Instruction Set Architecture</li> </ul> </li> <li> <p>Computer Arithmetic</p> </li> <li> <p>CPU and control design</p> </li> <li> <p>Pipelining &amp; hazards</p> </li> <li> <p>Memory organization</p> </li> <li> <p>Storage and I/O organization</p> </li> <li> <p>Introduction to some advanced concepts</p> </li> </ul>"},{"location":"3_Core/Computer_Architecture/01_Intro/","title":"01 Intro","text":""},{"location":"3_Core/Computer_Architecture/01_Intro/#overall-view-of-computer-engineering","title":"Overall View of Computer Engineering","text":"<pre><code>flowchart TB\napp --&gt;\nalgo[Algorithm] --&gt;\npl[Programming Language] --&gt;\nosvm[Operating System/&lt;br /&gt;Virtual Machine] --&gt;\nisa[\"ISA&lt;br /&gt;(Instruction Set Architeture)\"] --&gt;\nma[Microarchitecture] --&gt;\nrtl[Register-Transfer Level] --&gt;\ng[Gates] --&gt;\nc[Circuits] --&gt;\nd[Devices] --&gt;\np[Physics]\nsubgraph app[Application]\n    direction TB\n    sd[Software Development]\n    AI\n    ml[Machine Learning]\nend\n\nsubgraph Computer Science\n    algo\n    pl\nend\n\nsubgraph Computer Architecture\n    isa\n    ma\n    rtl\nend\n\nsubgraph Digital Design\n    g\n    c\n    d\n    p\nend</code></pre>"},{"location":"3_Core/Computer_Architecture/01_Intro/#mips","title":"MIPS","text":"<p>Microprocessors without Interlocked Pipelined Stages</p> Architecture Organization Describes ___ computer does what how Role Interface b/w hardware &amp; software Way comuper components are connected in a system Programmer\u2019s View InstructionsAddressing ModesRegisters Realization of architecture(Circuit Design, signals, peripherals)"},{"location":"3_Core/Computer_Architecture/01_Intro/#microprogram","title":"Microprogram","text":"<p>It is a microinstruction program that controls the functions of a central processing unit or peripheral controller of a computer</p> <p>Microcode is low-level code that defines how a microprocessor should function when it executes machine-language instructions. </p> <p>Typically, one machine-language instruction translates into several microcode instructions</p>"},{"location":"3_Core/Computer_Architecture/01_Intro/#class-of-computers","title":"Class of Computers","text":"Computer Class Purpose Characteristic Size Personal General Cost/Performance Tradeoff Small Server Network Based High CapacityHigh PerformanceHigh Reliability Small-Building Size Super Scientific calculations(weather forecasting, oil exploration) Highest capacity Embedded Embedded within systems(Digital TVs, cameras)Specific application Stringent power/performance/cost constraints Small Datacenters Storage and retrieval of data High performance"},{"location":"3_Core/Computer_Architecture/01_Intro/#levels-of-computing-system","title":"Levels of Computing System","text":"Level Application Software Written in High Level Language System Software CompilerOS Hardware ProcessorMemoryI/O Controllers"},{"location":"3_Core/Computer_Architecture/01_Intro/#levels-of-program-code","title":"Levels of Program Code","text":"<ul> <li>Machine Language</li> <li>Assembly</li> <li>High-Level</li> </ul>"},{"location":"3_Core/Computer_Architecture/01_Intro/#components-of-computer","title":"Components of Computer","text":"Component Input Write data to memory(from user) Output Read data from memory(to user) Registers Cache Small fast SRAM Datapath Performs data operations Control sends signals that determine operations of datapath, memory, I/O"},{"location":"3_Core/Computer_Architecture/01_Intro/#isa","title":"ISA","text":"<p>Instruction Set Architecture</p> <p>Interface between hardware and lowest level of software</p> <p>Includes information necessary (instructions, registers, memory access, I/O, and so on) to write a machine language program that will run correctly</p>"},{"location":"3_Core/Computer_Architecture/01_Intro/#abi","title":"ABI","text":"<p>Application Binary Interface</p> <p>Combination of the basic instruction set and the operating system interface</p>"},{"location":"3_Core/Computer_Architecture/02_Performance/","title":"02 Performance","text":""},{"location":"3_Core/Computer_Architecture/02_Performance/#performance-measures","title":"Performance Measures","text":"Measure Definition Goal Concerns Execution Time Time between start and completion of a task \\(\\downarrow\\) individual users Throughput/Bandwidth Total work done per unit time \\(\\uparrow\\) Datacenter managers"},{"location":"3_Core/Computer_Architecture/02_Performance/#performance-and-execution-time","title":"Performance and Execution Time","text":"\\[ \\text{Performance} = \\frac{1}{\\text{Execution Time}} \\] \\[ \\begin{aligned} P_x &amp;\\textcolor{orange}{&gt;} P_y \\\\ \\implies T_x &amp; \\textcolor{orange} &lt; T_y \\quad \\left( \\frac{1}{T_x} &gt; \\frac{1}{T_y} \\right) \\end{aligned} \\] \\[ \\begin{aligned} &amp; X \\text{ is } n \\text{ times as fast as } Y \\\\ \\implies &amp; n  = \\frac{P_{\\textcolor{orange}{x}}}{P_{\\textcolor{hotpink}{y}}} = \\frac{T_{\\textcolor{hotpink}{y}}}{T_{\\textcolor{orange}{x}}} \\end{aligned} \\]"},{"location":"3_Core/Computer_Architecture/02_Performance/#execution-time","title":"Execution Time","text":""},{"location":"3_Core/Computer_Architecture/02_Performance/#components","title":"Components","text":""},{"location":"3_Core/Computer_Architecture/02_Performance/#responseelapsed-time","title":"Response/Elapsed Time","text":"<p>Time to complete a task</p> <ul> <li>Processing</li> <li>I/O activity</li> <li>Memory access</li> <li>OS overhead</li> </ul>"},{"location":"3_Core/Computer_Architecture/02_Performance/#cpu-time","title":"CPU Time","text":"<ul> <li>Time spent by processor to execute a job   Discounts I/O time, other jobs\u2019 shares</li> <li>User CPU time/CPU performance   CPU time spent in user program</li> <li>System CPU Time   CPU time spent in operating system performing tasks on behalf of the program</li> </ul>"},{"location":"3_Core/Computer_Architecture/02_Performance/#formula","title":"Formula","text":"\\[ \\text{Clock Cycle Time} = \\frac{1}{\\text{Clock Frequency Rate}} \\] \\[ \\begin{aligned} &amp; \\text{No of clock cycles} \\\\ &amp;= \\text{No of instructions} \\times \\text{CPI} \\\\ &amp; \\qquad \\qquad \\text{CPI}\\to \\text{(Cycles per Instruction)} \\\\ &amp;= \\sum_{i=1} \\text{(No of instructions)}_i \\times \\text{(CPI)}_i \\\\ &amp; \\qquad\\qquad (\\exists \\text{ different classes of instructions)} \\end{aligned} \\] \\[ \\begin{aligned} &amp;\\text{CPU Execution time for a program} \\\\ =&amp; \\text{No of clock cycles} \\times \\text{Clock cycle time} \\end{aligned} \\] <p>Be careful when calculating avg CPI for a code sequence (simple, but avoid careless mistake)</p> <p>We can improve performance by</p> <ul> <li>Reducing number of clock cycles</li> <li>Increasing clock rate   However, this is not ideal, as this will increase<ul> <li>Power consumption</li> <li>Heat produced</li> </ul> </li> </ul>"},{"location":"3_Core/Computer_Architecture/02_Performance/#cpu-clocking","title":"CPU Clocking","text":"<p>Constant-rate clock that governs operation of digital hardware</p>"},{"location":"3_Core/Computer_Architecture/02_Performance/#performance-factors","title":"Performance Factors","text":"Factor Determines AffectsInstruction Count Affects CPI<sub>avg</sub> Affects T<sub>C</sub> Algorithm No of source-level statementsI/O operations executed \u2705 \u2705 \u274c Programming Language No of machine instructions executed per source-level statement \u2705 \u2705 \u274c Compiler No of machine instructions executed per source-level statement \u2705 \u2705 \u274c ISA No of machine instructions executed per source-level statement \u2705 \u2705 \u2705 ProcessorMemory Speed of instruction execution I/O SystemOS Speed of I/O operations execution"},{"location":"3_Core/Computer_Architecture/02_Performance/#speedup","title":"Speedup","text":"\\[ \\begin{aligned} S &amp;= \\frac{P_\\text{new}}{P_\\text{old}} \\\\ &amp;= \\frac{T_\\text{old}}{T_\\text{new}} \\end{aligned} \\]"},{"location":"3_Core/Computer_Architecture/02_Performance/#amdahls-law","title":"Amdahl's Law","text":"<p>\u2026 gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved.</p> <p>If</p> <ul> <li>\\(s\\) is the fraction that is sequential</li> <li>\\(p\\) is the fraction that can be parallelized</li> <li>\\(n\\) is the new parallel processing ability</li> </ul> \\[ \\begin{aligned} n &amp;= \\text{factor of increase in number of processors} \\\\ &amp; \\qquad \\times \\text{factor of increase in processor performance} \\end{aligned} \\] <p>\\((s = 1-p; \\quad p = 1-s)\\)</p> <p>Then, the maximum speed up \\(S\\) is</p> \\[ \\begin{aligned} S &amp;=  \\frac{\\text{Speed with parallelization}}{\\text{Speed without parallelization}} \\\\ &amp;= \\frac{1}{ s + \\frac{p}{n} } \\end{aligned} \\]"},{"location":"3_Core/Computer_Architecture/02_Performance/#design-principles","title":"Design Principles","text":"<ul> <li>Simplicity is favored over regularity</li> <li>Smaller is faster</li> <li>Something</li> <li>Something</li> </ul>"},{"location":"3_Core/Computer_Architecture/02_Performance/#isa","title":"ISA","text":"<p>Instruction Set Architecture</p> <p>The sheet will be given</p> <p>Note</p> <ul> <li>All core instructions have 3 operands</li> <li>All pseudo-instructions have 2 operands</li> </ul>"},{"location":"3_Core/Computer_Architecture/02_Performance/#branching","title":"Branching","text":"<p>Doing the branching opposite of the pseudocode helps eliminate a jump instruction.</p> <p>It may seem small, but if you use a loop, the savings will add up to a lot of cycles.</p>"},{"location":"3_Core/Computer_Architecture/02_Performance/#idk","title":"IDK","text":"P Multiplicand Mr Step 0000000 00001100 1100 00000110 110 Right-Shift multiplierLeft-Shift multiplier Right-Shift multiplierLeft-Shift multiplier"},{"location":"3_Core/Computer_Architecture/03_ISA/","title":"03 ISA","text":"<ul> <li>MIPS_Instruction_Set.pdf</li> <li>MIPS_Instruction_Format.pdf </li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#starter-program","title":"Starter Program","text":"<pre><code>.data\na: .byte 10\nb: .word 10\n\narray .word 10, 20\n\nchar .ascii 'H'\nstring .asciiz \"Hello world\"\n\n.text\nmain:\n    ## your code\nend main\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#design-principles","title":"Design Principles","text":""},{"location":"3_Core/Computer_Architecture/03_ISA/#simplicity-favours-regularity","title":"Simplicity favours regularity","text":"<ul> <li>keeping all instructions a single size</li> <li>always requiring three register operands in arithmetic instructions</li> <li>keeping the register fields in the same place in each instruction format</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#advantages","title":"Advantages","text":"<ul> <li>Regularity makes implementation simpler</li> <li>Simplicity enables higher performance at lower cost</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#smaller-is-faster","title":"Smaller is Faster","text":""},{"location":"3_Core/Computer_Architecture/03_ISA/#make-the-common-case-fast","title":"Make the common case fast","text":"<p>Small constants are common</p> <p>Immediate operand avoids a load instruction</p>"},{"location":"3_Core/Computer_Architecture/03_ISA/#operands","title":"Operands","text":""},{"location":"3_Core/Computer_Architecture/03_ISA/#register","title":"Register","text":"<ul> <li>MIPS has a \\(32 \\times 32\\)-bit register file</li> <li>Used for frequently accessed data</li> <li>Numbered 0 to 31</li> </ul> <p>32-bit data is called a \u2018word\u2019</p>"},{"location":"3_Core/Computer_Architecture/03_ISA/#assembler-names","title":"Assembler Names","text":"<ul> <li><code>$t0, $t1, \u2026, $t9</code> for temporary values</li> <li><code>$s0, $s1, \u2026, $s7</code> for saved variables</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#preserved-on-call","title":"Preserved on Call","text":"<ul> <li><code>$s0-$s7</code></li> <li><code>$sp</code></li> <li><code>$fp</code></li> <li><code>$ra</code></li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#memory","title":"Memory","text":"<p>Main memory used for composite data (arrays, structures, dynamic data)</p> <p>To apply arithmetic operations</p> <ul> <li>Load values from memory into registers</li> <li>Store result from register to memory</li> </ul> <p>Memory is byte-addressed</p> <ul> <li>Each address identifies 8-bits</li> <li>Words are aligned in memory<ul> <li>Address must be a multiple of 4</li> </ul> </li> <li>MIPS is Big/Little Endian<ul> <li>In our course, we are taking little endian</li> </ul> </li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#loadstore","title":"Load/Store","text":"<code>lw rt, offset(rs)</code><code>lh rt, offset(rs)</code><code>lb rt, offset(rs)</code> Load wordLoad half-wordLoad byte <code>sw rt, offset(rs)</code><code>sh rt, offset(rs)</code><code>sb rt, offset(rs)</code> Store wordStore half-wordStore byte <code>li $t0, immediate_value</code> load immediate <code>la $t0, variable_name</code> load address <pre><code>a[12] = h + a[8];\n</code></pre> <p>\\(8 \\text{ word locations} \\implies 8 \\times 4\\)</p> <ul> <li>each word occupies 4 memory locations</li> </ul> <pre><code>la $s0, a\nlw $t0, 32($s0)\nadd $s2, $s1, $t0\nsw $s2, 48($s0)\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#immediate","title":"Immediate","text":"<pre><code>addi $t0, $t0, 1\naddi $t0, $t0, -1\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#zero","title":"Zero","text":"<pre><code>## Initialize variable as 0\nadd $t0, $zero, $zero\n\n## Copy value\nadd $t1, $t0, $zero\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#registers-vs-memory","title":"Registers vs Memory","text":"<p>Registers are faster to access than memory</p> <p>Operating on memory data requires loads and stores \\(\\to\\) More instructions to be executed</p> <p>Compiler must use registers for variables as much as possible. Only spill to memory for less frequently-used variables</p>"},{"location":"3_Core/Computer_Architecture/03_ISA/#instructions","title":"Instructions","text":"<p>Encoded as 32-bit instruction words</p> <p>Register numbers</p> <ul> <li><code>$t0 \u2013 $t7</code> are reg\u2019s 8 \u2013 15</li> <li><code>$t8 \u2013 $t9</code> are reg\u2019s 24 \u2013 25</li> <li><code>$s0 \u2013 $s7</code> are reg\u2019s 16 \u2013 23</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#r-format","title":"R-Format","text":"op operation code (opcode) rs first source register number rt second source register number rd destination register number shamt shift amount (00000 for now) funct function code (extends opcode)"},{"location":"3_Core/Computer_Architecture/03_ISA/#number-formats","title":"Number Formats","text":"<ul> <li>Unsigned</li> <li>2\u2019s complement</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#sign-extension","title":"Sign Extension","text":"<p>Representing a number using more bits, while preserving numeric value</p> <ul> <li><code>addi</code>: extend immediate value</li> <li><code>lb</code>, <code>lh</code>: extend loaded byte/halfword</li> <li><code>beq</code>, <code>bne</code>: extend the displacement</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#bitwise-operations","title":"Bitwise Operations","text":"<p>Useful for inserting/extracting groups of bits from a word</p> Operation Shift Left Logical <code>sll</code> <code>sll</code> by \\(i\\) bits multiplies by \\(2^i\\) <code>sll $t0, $t0, 2</code> Shift Right Logical <code>srl</code> <code>srl</code> by \\(i\\) bits divides by \\(2^i\\)(unsigned only) <code>srl $t0, $t0, 2</code> Bitwise and <code>and</code><code>andi</code> Useful to mask bits in a wordSelect some bits, clear others to 0 <code>and $t0, $t1, $t2</code><code>andi $t0, $t1, 0</code> Bitwise or <code>or</code><code>ori</code> Useful to include bits in a wordSet some bits to 1, leave others unchanged <code>or $t0, $t1, $t2</code><code>ori $t0, $t1, 1</code> Bitwise not <code>nor</code> Useful to invert bits in a wordChange 0 to 1, and 1 to 0 <code>nor $t0, $t1, $zero</code>"},{"location":"3_Core/Computer_Architecture/03_ISA/#jump-statements","title":"Jump Statements","text":"<pre><code>## unconditional\nj exit\n\n## Conditional\nbeq $t0, $t1, exit\nbne $t0, $t1, exit\n\nbgt $t0, $t1, exit\nbge $t0, $t1, exit\n\nblt $t0, $t1, exit\nble $t0, $t1, exit\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#alternate-approach","title":"Alternate Approach","text":"<p>Using</p> <ul> <li>Set less than</li> <li>Set greater than</li> </ul> <p>Faster than <code>bgt</code>, <code>bge</code>, <code>blt</code>, <code>ble</code></p> <ul> <li><code>bgt</code>, <code>bge</code>, <code>blt</code>, <code>ble</code> require combining logical operation with branch involves more work per instruction, requiring a slower clock</li> </ul> <pre><code>## signed\nslt $t0, $s1, $s2 ## if ($s1 &lt; $s2)\nsgt $t0, $s1, $s2 ## if ($s1 &gt; $s2)\n\n## signed immediate\nslti $t0, $s1, 9 ## if ($s1 &lt; 9)\nsgti $t0, $s1, 9 ## if ($s1 &lt; 9)\n\n## unsigned\nsltu $t0, $s1, $s2 ## if ($s1 &lt; $s2)\nsgtu $t0, $s1, $s2 ## if ($s1 &lt; $s2)\n\n## unsigned immediate\nsltui $t0, $s1, 9 ## if ($s1 &lt; 9)\nsgtui $t0, $s1, 9 ## if ($s1 &lt; 9)\n## use with\nbeq $t0, $zero, exit\nbne $t0, $zero, exit\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#loop","title":"Loop","text":"<p>Tip: Doing the opposite conditional statement saves a clock cycle every time the loop runs</p>"},{"location":"3_Core/Computer_Architecture/03_ISA/#for-while","title":"<code>for</code>, <code>while</code>","text":"<pre><code>## initialization\n\nloop:\n    bne $s0, $s1, exit ## condition\n\n    ## statements\n\n    addi $t0, $t1 ## updation\n    j loop\n\nexit:\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#dowhile","title":"<code>do...while</code>","text":"<pre><code>## initialization\n\nloop:\n    ## statements\n\n    addi $t0, $t1 ## updation\n\n    bne $s0, $s1, exit ## condition\n\n    j loop\n\nexit:\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#registers","title":"Registers","text":"\\(a_0 \\iff a_3\\) Argument \\(s_0 \\iff s_7\\) Saved Need to be pushed/popped to/from stack \\(t_0 \\iff t_9\\) Temporary \\(v_0, v_1\\) Return variables"},{"location":"3_Core/Computer_Architecture/03_ISA/#procedure-calling","title":"Procedure Calling","text":""},{"location":"3_Core/Computer_Architecture/03_ISA/#steps","title":"Steps","text":"<ol> <li>Place parameters in registers</li> <li>Transfer control to procedure</li> <li>Acquire storage for procedure</li> <li>Perform procedure\u2019s operations</li> <li>Place result in register for caller</li> <li>Return to place of call</li> </ol>"},{"location":"3_Core/Computer_Architecture/03_ISA/#registers_1","title":"Registers","text":"<ul> <li><code>$a0 \u2013 $a3</code>: arguments (reg\u2019s 4 \u2013 7)</li> <li><code>$v0, $v1</code>: result values (reg\u2019s 2 and 3)</li> <li><code>$t0 \u2013 $t9</code>: temporaries<ul> <li>Can be overwritten by callee</li> </ul> </li> <li><code>$s0 \u2013 $s7</code>: saved<ul> <li>Must be saved/restored by callee</li> </ul> </li> <li><code>$gp</code>: global pointer for static data (reg 28)</li> <li><code>$sp</code>: stack pointer (reg 29)</li> <li><code>$fp</code>: frame pointer (reg 30)</li> <li><code>$ra</code>: return address (reg 31)</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#instructions_1","title":"Instructions","text":"<pre><code>jal function_name\n</code></pre> <p>Procedure call: jump and link</p> <ul> <li>Address of following instruction put in <code>$ra</code></li> <li>Jumps to target address</li> </ul> <pre><code>jr $ra\n</code></pre> <p>Procedure return: jump register</p> <ul> <li>Copies $ra to program counter</li> <li>Can also be used for computed jumps<ul> <li>e.g., for case/switch statements</li> </ul> </li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#example","title":"Example","text":"<ul> <li>Arguments \\(g, \\dots, j\\) in <code>$a0</code> \\(,\\dots,\\) <code>$a3</code></li> <li>\\(f\\) in <code>$s0</code> (hence, need to save <code>$s0</code> on stack)</li> <li>Result in <code>$v0</code></li> </ul> <pre><code>int leaf(int g, int h, int i, int j)\n{\n  int f = (g + h) - (i + j);\n    return f;\n}\n\nvoid main()\n{\n  leaf();\n}\n</code></pre> <p>For solving this question, we don\u2019t need to use stack. However, we are using because it is asked to do so in the question</p> <pre><code>.data\n\n.text\nmain:\n    addi $a0, $zero, 10\n    addi $a1, $zero, 20\n    addi $a2, $zero, 30\n    addi $a3, $zero, 40\n\n    jal leaf\nend main\n\nleaf:\n  ## save $s0 on stack\n\n  addi $sp, $sp, -4\n  sw $s0, 0($sp)\n\n  ## procedure body\n  add $t0, $a0, $a1\n  add $t1, $a2, $a3\n  sub $s0, $t0, $t1\n\n  ## result\n  add $v0, $s0, $zero\n\n  ## restore $s0\n  lw $s0, 0($sp)\n  addi $sp, $sp, 4\n\n  ## return\n  jr $ra\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#non-leaf-procedures","title":"Non-Leaf Procedures","text":"<p>Procedures that call other procedures</p> <p>For nested call, caller needs to save on the stack</p> <ul> <li>its return address</li> <li>any arguments and temporaries needed after the call</li> </ul> <p>Restore from the stack after the call</p> <pre><code>int fact (int n)\n{\n    if (n &lt; 1)\n    return (1);\n    else\n    return n * fact(n - 1);\n}\n</code></pre> <pre><code>fact:\n  addi $sp, $sp, -8 ## adjust stack for 2 items\n  sw $ra, 4($sp) ## save return address\n  sw $a0, 0($sp) ## save argument\n\n  slti $t0, $a0, 1 ## test for n &lt; 1\n  beq $t0, $zero, L1\n\n  addi $v0, $zero, 1 ## if so, result is 1\n  addi $sp, $sp, 8 ## pop 2 items from stack\n  jr $ra ## and return\n\nL1:\n    addi $a0, $a0, -1 ## else decrement n\n  jal fact ## recursive call\n\n  lw $a0, 0($sp) ## restore original n\n  lw $ra, 4($sp) ## and return address\n  addi $sp, $sp, 8 ## pop 2 items from stack\n\n  mul $v0, $a0, $v0 ## multiply to get result\n\n  jr $ra ## and return\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#character-data","title":"Character Data","text":"Encoding Bits Characters ASCII 8 128 95 graphic, 33 control Latin-1 8 256 ASCII + 96 more graphic characters Unicode 32 Most of the world\u2019s alphabets, symbolsUsed in Java, C++ wide characters UTF-8 8 variable-length encodings UTF-16 16 variable-length encodings"},{"location":"3_Core/Computer_Architecture/03_ISA/#bytehalfword-operations","title":"Byte/Halfword Operations","text":"<pre><code>## Sign extend to 32 bits in rt\nlb rt, offset(rs)\nlh rt, offset(rs)\n\n## Zero extend to 32 bits in rt\nlbu rt, offset(rs)\nlhu rt, offset(rs)\n\n## Store just rightmost byte/halfword\nsb rt, offset(rs)\nsh rt, offset(rs)\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#string-copy","title":"String Copy","text":"<pre><code>void strcpy (char x[], char y[])\n{\n  int i = 0;\n\n    while ( (x[i]=y[i])!='\\0' )\n        i += 1;\n}\n</code></pre> <pre><code>strcpy:\n  addi $sp, $sp, -4 ## adjust stack for 1 item\n  sw $s0, 0($sp) ## save $s0\n\n  add $s0, $zero, $zero ## i = 0\n\nloop:\n  add $t1, $s0, $a1 ## addr of y[i] in $t1\n  lbu $t2, 0($t1) ## $t2 = y[i]\n\n  add $t3, $s0, $a0 ## addr of x[i] in $t3\n  sb $t2, 0($t3) ## x[i] = y[i]\n\n    beq $t2, $zero, exit ## exit loop if y[i] == 0\n\n  addi $s0, $s0, 1 ## i = i + 1\n  j loop ## next iteration of loop\n\nexit:\n  lw $s0, 0($sp) ## restore saved $s0\n  addi $sp, $sp, 4 ## pop 1 item from stack\n\n  jr $ra ## and return\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#32-bit-constants","title":"32-bit Constants","text":"<p>16-bit immediate is the default in instructions</p> <p>However, if we need to store 32-bit constant, use load upper immediate</p> <pre><code>lui $s0, upper_16_bits\nori $s0, $s0, lower_16_bits\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#lui","title":"<code>lui</code>","text":"<ul> <li>Copies 16-bit constant to left 16 bits of <code>rt</code></li> <li>Clears right 16 bits of <code>rt</code> to 0</li> </ul> <p>Then we use <code>ori</code> to store the lower 16bits</p>"},{"location":"3_Core/Computer_Architecture/03_ISA/#branch-addressing","title":"Branch Addressing","text":"<p>Branch instructions specify</p> <ul> <li>Opcode</li> <li>two registers</li> <li>target address</li> </ul> <p>Most branch targets are near-branch (forward/backward)</p> <p></p> <p>PC-relative addressing</p> \\[ \\text{Target address} = \\text{PC}_\\text{new} + (\\text{Offset} \u00d7 4) \\] <p>PC already incremented by 4 by this time</p>"},{"location":"3_Core/Computer_Architecture/03_ISA/#jump-addressing","title":"Jump Addressing","text":"<p>Jump (<code>j</code> and <code>jal</code>) targets could be anywhere in text segment</p> <p>Encode full address in instruction</p> <p></p> <p>(Pseudo) Direct jump addressing</p> \\[ \\text{Target address} = (\\text{address} \u00d7 4) \\] <p>Why do we have 00 at the end of immediate when we calculate new instruction for branch/jump instructions? This is because</p> <ul> <li>Instructions are word-aligned, so their addresses always end with 00</li> <li>We aplways jump by a full instruction, which is 4 bytes, so we multiply the jump offset by 4, by shifting it left by 2 places</li> <li>We can jump further, if the offset is in multiple of 4 bytes instead of 1</li> </ul>"},{"location":"3_Core/Computer_Architecture/03_ISA/#branching-far-away","title":"Branching Far Away","text":"<p>If branch target is too far to encode with 16-bit offset, assembler rewrites the code, using unconditional jump (as it has larger range)</p> <p>Example</p> <pre><code>beq $s0, $s1, L1\n\n\u2193\n\nbne $s0, $s1, L2\nj L1\nL2:\n    \u2026\n</code></pre>"},{"location":"3_Core/Computer_Architecture/03_ISA/#addressing-summary","title":"Addressing Summary","text":""},{"location":"3_Core/Computer_Architecture/03_ISA/#assembler-pseudoinstructions","title":"Assembler Pseudoinstructions","text":"<p>Most assembler instructions represent machine instructions one-to-one</p> <p>Pseudoinstructions: figments of the assembler\u2019s imagination</p> <pre><code>move $t0, $t1\n\n\u2193\n\nadd $t0, $zero, $t1\n</code></pre> <pre><code>blt $t0, $t1, L\n\n\u2193\n\nslt $at, $t0, $t1\nbne $at, $zero, L\n</code></pre> <p><code>$at</code> (register 1): assembler temporary</p>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/","title":"04 Arithmetic","text":""},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#signed-integer-addition","title":"Signed Integer Addition","text":"<p>Overflow if result out of range</p> Operands Overflow? +ve \\(+\\) +ve \u2705 if result sign is 1 +ve \\(+\\) \u2013ve \u274c -ve \\(+\\) -ve \u2705 if result sign is 0"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#signed-integer-subtraction","title":"Signed Integer Subtraction","text":"<p>Take the twos complement (negation) of the subtrahend and add it to the minuend.</p> <p>Overflow if result out of range</p> Operands Overflow? +ve \\(-\\) +ve \u274c +ve \\(-\\) -ve \u2705 if result sign is 1 -ve \\(-\\) +ve \u2705 if result sign is 0 -ve \\(-\\) -ve \u274c"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#dealing-with-overflow","title":"Dealing with Overflow","text":"<p>Some languages (e.g., C) ignore overflow</p> <ul> <li>Use MIPS <code>addu</code>, <code>addui</code>, <code>subu</code> instructions</li> </ul> <p>Other languages (e.g., Ada, Fortran) require raising an exception</p> <ul> <li>Use MIPS <code>add</code>, <code>addi</code>, <code>sub</code> instructions</li> <li>On overflow, invoke exception handler<ul> <li>Save PC in exception program counter (EPC) register</li> </ul> </li> <li>Jump to predefined handler address</li> <li><code>mfc0</code> (move from coprocessor 0 reg) instruction can retrieve EPC value, to return after corrective action</li> </ul>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#multiplication-hardware","title":"Multiplication Hardware","text":""},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#regular-unsigned-multiplication","title":"Regular Unsigned Multiplication","text":"<p>Length of product is sum of operand lengths</p>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#observations","title":"Observations","text":"<ul> <li> <p>Multiplication involves the generation of partial products, one for each digit in the multiplier   | Multiplier bit | Partial Product |   | -------------- | --------------- |   | 0              | 0               |   | 1              | Multiplicand    |</p> </li> <li> <p>Each successive partial product is shifted one position to the left relative to the preceding partial product   (Effectively shifting multiplicand left one position for every   bit of multiplier)</p> </li> <li> <p>The final product is produced by summing the partial products.</p> </li> </ul>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#possible-improvements","title":"Possible Improvements","text":"<p>Can be done more efficiently</p> <ul> <li>A running sum of partial products is maintained rather   than waiting until the end to sum all partial products<ul> <li>Saves storage</li> </ul> </li> <li>Shift multiplier right each step<ul> <li>Allows to look at a constant position (i.e) examine the least significant bit only</li> </ul> </li> <li>For each 1 on the LSB of the multiplier<ul> <li>Add (add running sum of partial product with the multiplicand)</li> <li>Shift (shift-left the multiplicand)</li> </ul> </li> <li>For each 0 on the LSB of multiplier<ul> <li>Shift left the multiplicand</li> </ul> </li> </ul> <p></p>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#example","title":"Example","text":""},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#booths-multiplication","title":"Booth\u2019s Multiplication","text":"<ul> <li>Multiplier and multiplicand are placed in the \\(Q\\) and \\(M\\) registers</li> <li>1-bit register \\(Q_{-1}\\) placed logically to the right of the least-significant bit of the \\(Q\\) register</li> <li>The results of the multiplication will appear in the \\(A\\) and \\(Q\\) registers</li> <li>\\(A\\) and \\(Q_{-1}\\) are initialized to \\(0\\)</li> </ul> <p>Control logic scans the bits of the multiplier Each bit is examined along with the bit to its right</p> \\(Q_0\\) \\(Q_{-1}\\) Action 0 0 Shift-Right \\(A,Q, Q_{-1}\\) 1 1 Shift-Right \\(A,Q, Q_{-1}\\) 0 1 \\(A = A + M\\)Shift-Right \\(A,Q, Q_{-1}\\) 1 0 \\(A = A \u2013 M\\)Shift-Right \\(A,Q, Q_{-1}\\) <p>In order to preserve sign bit arithmetic shift right is performed. The leftmost bit of \\(A\\), \\(A_{n-1}\\) is not only shifted into \\(A_{n-2}\\) but also remains in \\(A_{n-1}\\)</p> <p></p>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#example_1","title":"Example","text":""},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#advantage","title":"Advantage","text":"<ul> <li>Speeds up the multiplication process</li> <li>Blocks of 1s or 0s are skipped over, with an average of only one addition/subtraction per block</li> </ul>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#mips-multiplication","title":"MIPS Multiplication","text":"<p>Two 32-bit registers for product</p> <ul> <li><code>HI</code>: most-significant 32 bits</li> <li><code>LO</code>: least-significant 32-bits</li> </ul>"},{"location":"3_Core/Computer_Architecture/04_Arithmetic/#instructions","title":"Instructions","text":"<pre><code>## 64-bit product in HI/LO\nmult rs, rt\nmultu rs, rt\n\n## Move from HI/LO to rd\nmfhi rd\nmflo rd\n\n## Least-significant 32 bits of product \u2013&gt; rd\nmul rd, rs, rt ## (pseudoinstruction!)\n</code></pre>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/","title":"05 Floating Point Arithmetic","text":""},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#floating-point","title":"Floating Point","text":"\\[ x = (-1)^s \\times (1.\\text{Fraction}) \\times 2^{\\text{Exponent - Bias}} \\]"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#s","title":"S","text":"<ul> <li>Sign bit</li> <li>0: non-negative</li> <li>1: negative</li> </ul>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#exponent","title":"Exponent","text":"<ul> <li>Excess representation: actual exponent + Bias</li> <li>Ensures exponent is unsigned</li> <li>Single: Bias = 127; Double: Bias = 1023</li> </ul>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#normalized-significand","title":"Normalized Significand","text":"<ul> <li>Significand is Fraction with the <code>1.</code> restored</li> <li>\\(1.0 \\le |\\text{significand}| &lt; 2.0\\)</li> <li>Always has a leading pre-binary-point 1 bit, so no need to represent it explicitly (hidden bit)</li> </ul>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#single-precision-32-bit","title":"Single Precision (32-bit)","text":"<p>Exponents \\(00000000\\) and \\(11111111\\) reserved</p> Smallest value Largest value Exponent 00000001 11111110 actual exponent \u2013126 +127 Fraction 000\u202600 111\u202611 significand 1.0 2.0 Value \\(\u00b11.0 \u00d7 2^{\u2013126} \u2248 \u00b11.2 \u00d7 10^{\u201338}\\) \\(\u00b12.0 \u00d7 2^{+127} \u2248 \u00b13.4 \u00d7 10^{+38}\\)"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#double-precision-64-bit","title":"Double Precision (64-bit)","text":"<p>Exponents \\(0000\u202600\\) and \\(1111\u202611\\) reserved</p> Smallest value Largest value Exponent 00000000001 11111111110 actual exponent \u20131022 +1023 Fraction 000\u202600 111\u202611 significand 1.0 2.0 Value \\(\u00b11.0 \u00d7 2^{\u20131022} \u2248 \u00b12.2 \u00d7 10^{\u2013308}\\) \\(\u00b12.0 \u00d7 2^{+1023} \u2248 \u00b11.8 \u00d7 10^{+308}\\)"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#floating-point-examples","title":"Floating Point Examples","text":""},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#denormal-numbers","title":"Denormal Numbers","text":"<p>Exponent = 000...0 \u21d2 hidden bit is 0</p> \\[ x = (-1)^s \\times (0+\\text{Fraction}) \\times 2^{-\\text{Bias}} \\] <ul> <li>Smaller than normal numbers</li> <li>Allow for gradual underflow, with diminishing precision</li> </ul> <p>Denormal with fraction = 000...0 is \\(\\pm 0.0\\) (2 representations of \\(0.0\\))</p>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#infinities-and-nans","title":"Infinities and <code>NaN</code>s","text":"\\(\\pm \\infty\\) <code>NaN</code> Infinity Not-A-Number Exponent \\(111 \\dots 1\\) \\(111 \\dots 1\\) Fraction \\(000 \\dots 0\\) \\(\\ne 000 \\dots 0\\) Can be used in subsequent calculations \u2705 \u2705 Avoids need for overflow check Indicates illegal or undefined resultFor eg: \\(0/0\\)"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#floating-point-addition","title":"Floating-Point Addition","text":"<ol> <li>Align binary points    Shift number with smaller exponent</li> <li>Add significands (in binary)</li> <li>Normalize result &amp; check for over/underflow</li> <li>Round and renormalize, if necessary</li> </ol>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-adder-hardware","title":"FP Adder Hardware","text":"<p>Much more complex than integer adder</p> <p>Doing it in one clock cycle would take too long</p> <ul> <li>Much longer than integer operations</li> <li>Slower clock would penalize all instructions</li> </ul> <p>FP adder usually takes several cycles</p> <ul> <li>Can be pipelined</li> </ul>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#mips-floating-point-instructions","title":"MIPS Floating Point Instructions","text":"<p>FPU co-processor is an adjunct processor that extends the ISA</p> <p>Separate FP registers</p> <ul> <li>32 single-precision: <code>$f0, $f1, \u2026 $f31</code></li> <li>Paired for double-precision: <code>$f0/$f1, $f2/$f3,</code></li> </ul> <p>FP instructions operate only on FP registers</p> <ul> <li>Programs generally don\u2019t do integer ops on FP data, or vice versa</li> <li>More registers with minimal code-size impact</li> </ul> <p>Separate FP instructions for single/double precision</p> Precision Bits Instruction Extension Example Single 32 <code>.s</code> <code>add.s $f0, $f1, $f2</code> Double 64 <code>.d</code> <code>add.d $f0, $f2, $f4</code>(equivalent to<code>add.d $f0/$f1, $f2/f3, $f4/$f5</code>)"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-arithmetic-operations","title":"FP Arithmetic Operations","text":""},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-loadstore","title":"FP Load/Store","text":"<code>lwc1</code> load word coprocessor 1 <code>ldc1</code> load double coprocessor 1 <code>swc1</code> store word coprocessor 1 <code>sdc1</code> store double coprocessor 1"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-loadstore-pseudo-instructions","title":"FP Load/Store pseudo Instructions","text":"<code>l.s</code> lwc1 load FP single <code>s.s</code> swc1 store FP single <code>l.d</code> ldc1 load FP double <code>s.d</code> sdc1 store FP double"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-loading-immediate-value","title":"FP Loading immediate value","text":"<p>(pseudoinstruction)</p> <pre><code>li.s $f1, 1.0\n\nli.s $f10, 1.0e-5 ## $f10 = 0.00001\n</code></pre>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-data-movement-instructions","title":"FP Data Movement Instructions","text":"<p>Moving data between general purpose and FP registers</p> Moving data between general purpose andFP registers <code>mfc1</code> move from coprocessor 1 (to general purpose register) <code>mtc1</code> move to coprocessor 1 (from general purpose register) Moving data between FP registers <code>mov.s</code> move single precision float <code>mov.d</code> move double precision float = even/odd pair of registers <p></p>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-convert-instructions","title":"FP Convert Instructions","text":"<p><code>m.x.y</code></p> <p>Convert</p> <ul> <li>to destination format \\(x\\)</li> <li>from source format \\(y\\)</li> </ul>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#supported-formats","title":"Supported Formats","text":"<ul> <li>Single precision float = <code>.s</code> (single precision float in FP register)</li> <li>Double precision float = <code>.d</code> (double float in even-odd FP register)</li> <li>Signed integer word = <code>.w</code> (signed integer in FP register)</li> </ul>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#fp-compare-and-branch-instructions","title":"FP Compare and Branch Instructions","text":"<p>FP unit (co-processor 1) has a condition flag</p> <ul> <li>Set to 0 (false) or 1 (true) by any comparison instruction</li> </ul> <p>Three comparisons</p> <ul> <li>equal, less than, less than or equal</li> </ul> <p>Two branch instructions based on the condition flag</p> <p></p>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#reading-and-printing-single-and-double-values","title":"Reading and printing single and double values","text":""},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#floating-point-data-declarations","title":"Floating-Point Data Declarations","text":"<pre><code>.data\npi: .float 3.14\ntao: .double 6.28\n\n.text\nmain:\n\nend main\n</code></pre>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#mips-floating-point-examples","title":"MIPS Floating Point Examples","text":""},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#area-of-circle","title":"Area of Circle","text":"<pre><code>.data\npi: .double 3.14\n\n.text\nmain:\n    #f2,f3 = pi\n    ldc1 $f2, pi\n\n    ## read double (radius)\n    addi $v0, $zero, 7\n    syscall ## f0, f1 = r\n\n    mul.d $f12, $f0, $f0 ## r^2\n    mul.d $f12, $f2, $f12 ## area = pi * r^2\n\n  ## print value\n  addi $v0, $zero, 3\n  syscall\n</code></pre>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#f-to-c","title":"\u00b0F \\(\\to\\) \u00b0C","text":"<pre><code>.data\nconst5: .float 5.0\nconst9: .float 9.0\nconst32: .float 32.0\nconstf: .float 50.0\n\n.text\nmain:\nl.s $f16, const5\nl.s $f18, const9\ndiv.s $f16, $f16, $f18\nl.s $f12, constf\nl.s $f18, const32\nsub.s $f18, $f12, $f18\nmul.s $f12, $f16, $f18\nli $v0, 2\nsyscall\nli $v0, 10\nsyscall\n</code></pre>"},{"location":"3_Core/Computer_Architecture/05_Floating_Point_Arithmetic/#ax2-bx-c-for-user-inputted-x","title":"\\(ax^2 + bx + c\\) for user-inputted \\(x\\)","text":"<pre><code>.data\na: .float 1.0\nbb: .float 2.0\nc: .float 3.0\nmsg: .asciiz \"Enter x: \"\nblank: .asciiz \" \"\nnewl: .asciiz \"\\n\"\n\n.text\nmain: ## read input\nla $a0,msg ## prompt user for x\nli $v0,4 ## print string\nsyscall\nli $v0,6 ## read single\nsyscall ## $f0 &lt;-- x\n\n## evaluate the quadratic\nl.s $f2,a ## sum = a\nmul.s $f2,$f2,$f0 ## sum = ax\nl.s $f4,bb ## get b\nadd.s $f2,$f2,$f4 ## sum = ax + b\nmul.s $f2,$f2,$f0 ## sum = (ax+b)x = ax^2 +bx\nl.s $f4,c ## get c\nadd.s $f2,$f2,$f4 ## sum = ax^2 + bx + c\n\n## print the result\nmov.s $f12, $f2 ## $f12 = argument\nli $v0,2 ## print single\nsyscall\nla $a0,newl ## new line\nli $v0,4 ## print string\nsyscall\nli $v0,10 ## code 10 == exit\nsyscall ## Return to OS.\n</code></pre>"},{"location":"3_Core/Computer_Architecture/06_Datapath/","title":"06 Datapath","text":""},{"location":"3_Core/Computer_Architecture/06_Datapath/#mips-datapath","title":"MIPS Datapath","text":""},{"location":"3_Core/Computer_Architecture/06_Datapath/#goal-of-datapath","title":"Goal of Datapath","text":"<p>Build an architecture to support the following instructions</p> <ul> <li>Arithmetic: <code>add</code>, <code>sub</code>, <code>addi</code>, <code>slt</code></li> <li>Memory references: <code>lw</code>, <code>sw</code></li> <li>Branches: <code>j</code>, <code>beq</code></li> </ul>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#process","title":"Process","text":"<ol> <li>Design basic framework that is needed by all instructions</li> <li>Build a computer for each operation individually</li> <li>Add MUXs to choose between different operations</li> <li>Add control signals to control the MUXs</li> </ol>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#mips-steps","title":"MIPS Steps","text":"<pre><code>flowchart LR\nif[\"Instruction Fetch&lt;br/&gt;(using Program Counter)\"] --&gt;\n|PC += 4| r[\"Instruction Decode&lt;br /&gt;&amp;&lt;br /&gt;Register Read\"] --&gt;\nalu[\"Execute&lt;br /&gt;(ALU)\"] --&gt;\nm[\"Memory&lt;br /&gt;(Read/Write)\"] --&gt;\nR[\"WriteBack&lt;br /&gt;(Register Write)\"]</code></pre> <p>Register Read may be</p> <ul> <li>One register: <code>addi</code>, <code>lw</code></li> <li>Two registers: <code>add</code>, <code>sub</code>, <code>slt</code>, <code>sw</code>, <code>beq</code></li> </ul> <p>Quick operations may loop twice through machine, getting incorrect result, as clock is dependent on longest path (<code>lw</code>). </p>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#sign-extension","title":"Sign Extension","text":"<p>Important for immediate data operations</p> <p>Take the top bit and copy it to all the other bits</p> <p>example</p> \\[ \\begin{aligned} 7 &amp;\\to 0111 \\to 0000 \\ 0000 \\ 0000 \\ 0111 \\\\ -2 &amp;\\to 1110 \\to 1111 \\ 1111 \\ 1111 \\ 1110 \\end{aligned} \\]"},{"location":"3_Core/Computer_Architecture/06_Datapath/#mips-instruction-available-datapath","title":"MIPS Instruction Available Datapath","text":""},{"location":"3_Core/Computer_Architecture/06_Datapath/#add-instruction","title":"<code>add</code> instruction","text":""},{"location":"3_Core/Computer_Architecture/06_Datapath/#addi-instruction","title":"<code>addi</code> Instruction","text":""},{"location":"3_Core/Computer_Architecture/06_Datapath/#load-instruction","title":"<code>load</code> Instruction","text":""},{"location":"3_Core/Computer_Architecture/06_Datapath/#store-instruction","title":"Store Instruction","text":""},{"location":"3_Core/Computer_Architecture/06_Datapath/#beq-instruction","title":"<code>beq</code> Instruction","text":"<p>Choose between</p> <ul> <li>\\(\\text{PC = (PC + 4)}\\)</li> <li>\\(\\text{PC = (PC + 4) + \\ \\ Imm&lt;&lt;2}\\)</li> </ul> <p></p>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#j-instruction","title":"<code>j</code> Instruction","text":"<p><code>imm</code> is 26 bits, but PC is 32 bits</p> <ul> <li><code>imm &lt;&lt;</code> (shift left)</li> <li>Concatenate PC\u2019s upper bits</li> </ul> <p></p>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#control-unit","title":"Control Unit","text":"<p>Set of control line values that cause appropriate actions to be taken at each step</p> <p>Finite state machine determines what needs to be done at each step</p> <ul> <li>Fetch</li> <li>Decode</li> <li>Action depends on opcode<ul> <li>Execute</li> <li>Memory</li> <li>Writeback</li> </ul> </li> </ul>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#single-cycle-implementation","title":"Single Cycle implementation","text":"<p>An implementation in which an instruction is executed in one clock cycle</p> <p>Also called single clock cycle implementation</p>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#advantage","title":"Advantage","text":"<p>Easy to understand</p>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#disadvantage","title":"Disadvantage","text":"<p>Too slow</p> <p>The clock cycle must have the same length for every instruction. Hence, the longest possible path in the processor determines the clock cycle</p> <ul> <li>usually it is the <code>load</code> instruction, which uses five functional units in series<ul> <li>instruction memory</li> <li>register file</li> <li>ALU</li> <li>data memory</li> <li>register file</li> </ul> </li> </ul> <p>Single long clock cycle makes <code>add</code> take as long as <code>load</code></p>"},{"location":"3_Core/Computer_Architecture/06_Datapath/#solution","title":"Solution","text":"<ul> <li>Break single instruction execution into small execution steps</li> <li>Improve performance by pipelining</li> </ul>"},{"location":"3_Core/Computer_Architecture/07_Pipelining/","title":"07 Pipelining","text":""},{"location":"3_Core/Computer_Architecture/07_Pipelining/#pipelining","title":"Pipelining","text":"<p>Pipelining improves efficiency by executing multiple instructions simultaneously (through overlapped execution)</p> <p>Pipelining produces speedup, while maintaining similar datapath</p> <p>Assume time for stages is</p> <ul> <li>100ps for register read or write</li> <li>200ps for other stages</li> </ul>"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#mips-pipeline","title":"MIPS Pipeline","text":"<p>Each of the 5 stages have their own step</p> <p></p>"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#diagram","title":"Diagram","text":""},{"location":"3_Core/Computer_Architecture/07_Pipelining/#resource-usage-form","title":"Resource Usage Form","text":""},{"location":"3_Core/Computer_Architecture/07_Pipelining/#traditional-form","title":"Traditional Form","text":""},{"location":"3_Core/Computer_Architecture/07_Pipelining/#time","title":"Time","text":"\\[ \\begin{aligned} \\text{Time with pipeline} &amp;= \\frac{\\text{Time without pipeline}}{\\text{No of stages}} \\\\ &amp;= \\frac{800}{5} \\\\ &amp;= \\cancel{160} \\\\ &amp;= 200 \\end{aligned} \\] <p>Why 200ps? The longest stage determines the clock cycle time of the pipeline</p> <p></p> <p>Let \\(n\\) be the no of instructions</p> Without With Total Time \\(800 n\\) \\(800 + 200(n-1)\\)"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#speedup","title":"Speedup","text":"<p>Speedup is due to increased throughput (number of instructions per unit time), not reduced latency (time for each instruction remains same)</p> <p>Assuming all stages are balanced/even (all stages take same time)</p> \\[ \\begin{aligned} S_\\text{ideal} &amp;= \\text{No of Stages} \\\\ &amp;= 5 \\end{aligned} \\] <p>If stages are unbalanced, speedup is less. Hence \\(\\downarrow\\)</p> \\[ \\begin{aligned} S_\\text{actual} &amp;= \\frac{\\text{Time without Pipeline}}{\\text{Time with Pipeline}} \\\\ &amp;= \\frac{800}{200} \\\\ &amp;= 4 \\end{aligned} \\] <p>Maximum speed up is achieved only when the no of instructions is very large.</p>"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#convention-of-reg-readwrite","title":"Convention of Reg Read/Write","text":"<p>It only takes half of a cycle to read or write to register file</p> <p>Hence, whenever we are working with registers</p> <ul> <li>Write first half-cycle</li> <li>Read second half-cycle</li> </ul> <p>This is to ensure that we always read the latest value</p>"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#hazards","title":"Hazards","text":"<p>Situations that prevent executing the next instruction in the following (next) clock cycle</p>"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#types","title":"Types","text":"HazardType Meaning Example Structure Instruction cannot execute because a required resource (hardware) is busy In a single-memory system, memory-read of instruction and fetch of instruction 2 happening simultaneously Data Instruction cannot execute because data required to execute instruction is not availableNeed to wait for data <code>add $s0, $t0, $t1</code><code>sub $t2, $s0, $t3</code> Load-Use Specific form of Data HazardData being loaded by a load instruction is not available, which is needed by another instruction <code>lw $s0, 20($t1)</code><code>sub $t2, $s0, $t3</code> Control/Branching Instruction cannot execute because the instruction that was fetched is not the one that is needed."},{"location":"3_Core/Computer_Architecture/07_Pipelining/#solutions","title":"Solutions","text":"Solution Working Advantage Disadvantage 2 Memories Separate instruction/data memories Avoid structure hazard BubblingStalling Delaying using dummy instructionsWaste Avoids hazard Wastes time ForwardingBypassing Using internal buffer/latchForwarding path valid only if destination stage is after source stage We can save clock cycles (depends on the instruction)Reduces time taken Not that useful when using <code>lw</code>; we have to introduce one bubble anyway Code-Rescheduling Reorder serializable code to avoid use of load result in the next instruction, while ensuring there is no dependencySimilar to transactions like in DBMSTry to transfer all <code>lw()</code> to the top Overhead for the compiler/assembler Branch Prediction Make prediction and flush if incorrectStatic means assume branch not takenDynamic can 1 bit/2bit Delayed Branching Code Rescheduling for branching- From before- From below- From fall-through"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#i-missed-some-parts","title":"I missed some parts","text":"<p>Check slides</p> <p>Branch Prediction and all</p>"},{"location":"3_Core/Computer_Architecture/07_Pipelining/#gpu","title":"GPU","text":"<p>(not for exam)</p> <p>Works on SIMD(Single Instruction Multiple Data) architecture</p> <p>Works on matrix operations</p> <p>The same operation is performed over multiple rows/columns</p> <p>You have explicitly select GPU, hence this is explicit parallelism</p>"},{"location":"3_Core/Computer_Architecture/08_Memory/","title":"08 Memory","text":""},{"location":"3_Core/Computer_Architecture/08_Memory/#principle-of-locality","title":"Principle of Locality","text":"<p>Programs access a small proportion of its address space at any time. This exhibits locality.</p> Spatial locality Temporal locality Meaning Load clusters of related data into cache Recently-used data Example - Multiple elements in a loop- Sequential instruction access - Global variables from global region of memory- Instructions of a loop <p>Data can only move between 2 adjacent levels</p> <p>Register is highest level; Tertiary memory is lowest memory</p> <pre><code>flowchart LR\n\nCPU &lt;--&gt;\nRegister &lt;--&gt;\nL1 &lt;--&gt;\nL2 &lt;--&gt;\nL3 &lt;--&gt;\nPM[Primary&lt;br /&gt;Memory] &lt;--&gt;\nSM[Secondary&lt;br /&gt;Memory] &lt;--&gt;\nTM[Tertiary&lt;br /&gt;Memory]\n\nsubgraph Cache\n\n    L1\n    L2\n    L3\nend</code></pre>"},{"location":"3_Core/Computer_Architecture/08_Memory/#memory-performance","title":"Memory Performance","text":"Block(Cache Line) Unit of copyingConsists multiple words Hit Event of data requested by processor being present in upper level Miss Not a hit Hit Rate/Ratio Fraction of memory found in upper level\\(\\frac{\\text{Hits}}{\\text{Access}}\\) Miss Rate/Ratio \\(1 - \\text{Hit Ratio}\\) Hit Time Time to access the upper level + time to determine if access is hit or miss Miss Penalty Time to replace a block in upper level with the corresponding block from lover level AMAT Average Memory Access Time\\(T_\\text{avg} = T_\\text{cache} + (m*\\text{Miss Penalty}) + (m*T_\\text{memory})\\)"},{"location":"3_Core/Computer_Architecture/08_Memory/#cache-memory","title":"Cache Memory","text":"<p>L1 cache can be located on CPU Chip</p>"},{"location":"3_Core/Computer_Architecture/08_Memory/#cache-operation","title":"Cache Operation","text":"<pre><code>flowchart LR\n\nstart((Start)) --&gt;\n1[Retries RA from CPU] --&gt;\n2[Is block containing RA in cache] --&gt;\nsomething</code></pre>"},{"location":"3_Core/Computer_Architecture/08_Memory/#types-of-access","title":"Types of Access","text":"<ul> <li>Regular access</li> <li>Irregular access</li> </ul>"},{"location":"3_Core/Computer_Architecture/08_Memory/#direct-mapped-cache","title":"Direct Mapped Cache","text":"\\[ \\begin{aligned} \\text{Total no of bits} &amp;= 2^n \\times \\Big( \\text{Block size + Tag Size + Valid Field Size} \\Big) \\\\ \\text{where } n &amp;= \\text{No of bits to represent cache lines} \\end{aligned} \\]"},{"location":"3_Core/Computer_Architecture/08_Memory/#cache-line-table","title":"Cache Line Table","text":"<p>Let \\(s\\) be address bus size (number of bits to represent main memory address)</p> Cache Line Main memory blocks held \\(0\\) \\(0, m, 2m, \\dots, 2s-m\\) \\(1\\) \\(1, m+1, 2m+1, \\dots, 2s-m+1\\) \\(\\dots\\) \\(m-1\\) \\(m-1, \\dots,\\)"},{"location":"3_Core/Computer_Architecture/08_Memory/#memory-addressing","title":"Memory Addressing","text":"Tag Line number/Index Line/Byte offset Purpose Distinguish block from other blocks that can fit into a cache line Specify one of the \\(m=2r\\) blocks of main memory Identify unique word/byte within line of cache memory Bits Most significant \\(s-r-w\\) bits Next most significant \\(r\\) bits Least significant \\(w\\) bits <p>No of cache blocks \\(= 2^something\\)</p> \\[ \\begin{aligned} &amp;\\text{No of index bits} \\\\ &amp;= \\text{No of bits for Total Cache Size} -  \\text{No of bits for Offset} \\end{aligned} \\] \\[ \\begin{aligned} &amp;\\text{No of tag bits} \\\\ &amp;= \\text{No of bits for Total Memory Size} \\\\ &amp; \\ -\\Big( \\text{No of bits for Index} + \\text{No of bits for Offset} \\Big) \\end{aligned} \\]"},{"location":"3_Core/Computer_Architecture/08_Memory/#tags-valid-bits","title":"Tags &amp; Valid Bits","text":"<p>Initially valid bit = 0, when you boot up the computer</p>"},{"location":"3_Core/Computer_Architecture/08_Memory/#address-subdivision-diagram","title":"Address Subdivision Diagram","text":"<p>Take from slides</p>"},{"location":"3_Core/Computer_Architecture/08_Memory/#reading-from-cache","title":"Reading from Cache","text":"<ol> <li>Search the index</li> <li>Check validity<ul> <li>If valid, check the tag</li> <li>If equal tag, mark as hit</li> <li>If invalid, mark as miss</li> </ul> </li> </ol>"},{"location":"3_Core/Computer_Architecture/08_Memory/#fully-associative-cache","title":"Fully-Associative Cache","text":""},{"location":"3_Core/Computer_Architecture/08_Memory/#writing-to-cache","title":"Writing to Cache","text":"<p>LRU Replacement</p> <p>\u2705 No calculation happens, so it is efficient and faster</p>"},{"location":"3_Core/Computer_Architecture/08_Memory/#reading-from-cache_1","title":"Reading from Cache","text":"<p>\u274c Comparison of all bits happens, so it is inefficient and slower</p> <ol> <li>Check validity for all valid lines</li> <li>If valid, check the tag</li> <li>If invalid, add new element in first-come-first-serve order</li> </ol>"},{"location":"3_Core/Computer_Architecture/08_Memory/#set-associative-cache","title":"Set Associative Cache","text":"<p>Combination of Direct Mapped Cache and Fully-Associative Cache</p> <p>Particular block address is mapped to a particular set</p> <p>'\\(n\\)-way associated cache' means each set has \\(n\\) blocks, where \\(n \\in \\{2, 4, 8, \\dots \\}\\)</p> \\[ \\begin{aligned} \\text{No of sets } N &amp;= \\frac{\\text{Total no of blocks}}{n} \\\\ &amp;= \\frac{1}{n} \\times \\frac{\\text{Cache Size in bytes}}{\\text{Size of each block in bytes}} \\end{aligned} \\] <p>No of bits for set index = \\(2^N\\)</p> \\[ \\text{Mapped Set} = \\text{Address } \\% \\ N \\] <p>LRU Replacement</p> <p>Note</p> <ul> <li>Direct Mapped Cache is basically one-way associative caching</li> <li>Fully-Associative Cache is basically associative caching with no of sets = total no of blocks</li> </ul>"},{"location":"3_Core/Computer_Architecture/08_Memory/#write","title":"Write","text":""},{"location":"3_Core/Computer_Architecture/08_Memory/#write-through","title":"Write-Through","text":""},{"location":"3_Core/Computer_Architecture/08_Memory/#write-back","title":"Write-Back","text":"<p>Dirty block something</p>"},{"location":"3_Core/Computer_Architecture/08_Memory/#write-buffer","title":"Write-Buffer","text":"<p>If the same data is accessed again, there is overhead of checking queue also, just in case</p>"},{"location":"3_Core/Computer_Architecture/08_Memory/#lru-replacement","title":"LRU Replacement","text":"<p>Least Recently-Used</p> <p>We have to implement a data structure to keep track</p> <ul> <li>doubly linked list</li> <li>hash map</li> </ul>"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/","title":"09 Cache Optimization","text":""},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#goal-of-cache-optimization","title":"Goal of Cache Optimization","text":"<p>Reduce average memory access time by improving the following aspects</p> Aspect Solution Advantage Disadvantage Reduce Miss Rate(Increase Hit Rate) Larger block size (but not too high) Fewer capacity miss Longer hit time (due to longer search)Costlier Larger cache size Higher Associativity Fewer conflict miss Complicated circuitLonger clock cycle time (increased hit time) Reduce Miss Penalty Multilevel Caches Reduced turnaround time Increased overhead of write-back/write-through/write-buffer Write-through with buffer to serve reads before writes (to give priority to read misses over writes) Write-Back Reduce Hit Time Use virtually-indexed, physically-tagged, to avoid address translation during indexing of cache Small and Simple caches Pipelined cache access Trace caches <p>RAW = Read After Write</p>"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#cache-research-results","title":"Cache Research Results","text":""},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#21-cache-rule","title":"2:1 cache rule","text":"<p>Miss rate of Direct </p>"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#8-way-set-associate","title":"8 way Set associate","text":"<p>is as effective as fully associative </p>"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#cache-segment","title":"Cache Segment","text":"<p>Each cache divided into 2 segments</p> <ul> <li>Instruction Segment</li> <li>Data Segment</li> </ul>"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#types-of-miss-rate","title":"Types of Miss Rate","text":""},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#local-miss-rate","title":"Local miss rate","text":"\\[ \\frac{\\text{Misses in this cache}}{\\text{Number of accesses of this cache}} \\]"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#global-miss-rate","title":"Global miss rate","text":"\\[ \\frac{\\text{Misses in this cache}}{\\text{Total number of accesses}} \\]"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#multiple-cache-amat","title":"Multiple Cache AMAT","text":"\\[ \\begin{aligned} \\text{AMAT}_\\text{Overall} &amp;= \\Big( \\text{Hit Rate}_{L_1} \\times \\text{Hit Penalty}_{L_1} \\Big) + \\Big( \\text{Miss Rate}_{L_1} \\times \\textcolor{hotpink}{\\text{Miss Penalty}_{L_1}} \\Big) \\\\ \\textcolor{hotpink}{\\text{Miss Penalty}_{L_1}} &amp;=  \\Big( \\text{Hit Rate}_{L_2} \\times \\text{Hit Penalty}_{L_2} \\Big)  + \\Big( \\text{Miss Rate}_{L_2} \\times \\textcolor{orange}{\\text{Miss Penalty}_{L_3}} \\Big) \\\\ &amp;\\dots \\end{aligned} \\]"},{"location":"3_Core/Computer_Architecture/09_Cache_Optimization/#cache-miss-types","title":"Cache Miss Types","text":"Miss Type When Compulsory MissCold Miss Initially caches are empty(Valid bits are all 0) Capacity Miss Not enough space in cache to store Conflict Miss Already there is some data in the same cache location"},{"location":"3_Core/Computer_Architecture/Lab/00_Setup/","title":"00 Setup","text":"<ol> <li>Write your program in a text program</li> <li>Open <code>QtSpim</code></li> <li><code>File</code> &gt; <code>Reinitialize and Load File</code></li> <li>Load your file</li> <li>Run the program</li> <li>View the output on the <code>Console</code></li> </ol>"},{"location":"3_Core/Computer_Architecture/Lab/01/","title":"01","text":""},{"location":"3_Core/Computer_Architecture/Lab/01/#print-hello-world","title":"Print <code>Hello World</code>","text":"<pre><code>.data\nmsg: .asciiz \"Hello World\"\n\n.text\nmain:\n\nli $v0, 4\nla $a0, msg\nsyscall\n\nli $v0, 10\nsyscall\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/01/#add-2-numbers","title":"Add 2 Numbers","text":"<p>I used <code>add</code> to assign values, as <code>li</code> is a pseudo-instruction, which will take 2 cycles</p> <pre><code>.text\n\nmain:\nadd $v0, $zero, 1\n\nadd $11, 10, $zero\nadd $12, 10, $zero\nadd $a0, $11, $12\nsyscall\n\nadd $v0, $zero, 10\nsyscall\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/02/","title":"02","text":"<p>We cannot store an immediate value into memory.</p>"},{"location":"3_Core/Computer_Architecture/Lab/02/#sum-of-first-n-numbers","title":"Sum of first \\(n\\) numbers","text":"<pre><code>.text\nmain:\n\naddi $t0, $zero, 5 ## n\nadd $t1, $zero, 0 ## sum\nadd $t2, $zero, 1 ## i\n\nrepeat:\nbgt $t2, $t0, display\nadd $t1, $t1, $t2\naddi $t2, $t2, 1\nj repeat\n\ndisplay:\nadd $v0, $zero, 1\nadd $a0, $zero, $t1\nsyscall\n\n#exit\nadd $v0, $zero, 10\nsyscall\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/02/#array-memory","title":"Array Memory","text":"<pre><code>.data\narray .word 10, 20, 30\n\n.text\nla $t0, array ## array \n\naddi $t1, $zero, 3 ## n = 3\naddi $t2, $zero, 0 ## i = 0\n\nloop: ## for (i = 0; i &lt; n; i++)\n## i &gt;= n (exit if i = n)\n    beq $t2, $t1, exit\n\n    ## code for displaying 1 element\n    addi $a0, $zero, 3\n    addi $v0, $zero, 4\n    syscall\n\nexit:\n</code></pre> <ol> <li>Initialize array</li> <li>Get address of array</li> <li></li> </ol>"},{"location":"3_Core/Computer_Architecture/Lab/07_Procedures/","title":"07 Procedures","text":""},{"location":"3_Core/Computer_Architecture/Lab/07_Procedures/#question-1","title":"Question 1","text":"<p>Procedures to find __ of 2 inputted numbers</p> <ul> <li>Sum</li> <li>Difference</li> <li>Product</li> <li>Quotient</li> </ul> <p>Arguments</p> <ul> <li>\\(x\\)</li> <li>\\(y\\)</li> </ul> <pre><code>.data\nnewline: .asciiz \"\\n\"\n\n.text\nmain:\n    addi $a0, $zero, 1\n    addi $a1, $zero, 5\n\n    jal sum\n    add $a0, $zero, $v0\n    addi $v0, $zero, 1\n  syscall   \n  la $a0, newline\n    addi $v0, $zero, 4\n    syscall\n\n    addi $a0, $zero, 1\n    addi $a1, $zero, 5\n\n  jal dif\n    add $a0, $zero, $v0\n    addi $v0, $zero, 1\n  syscall\n    la $a0, newline\n    addi $v0, $zero, 4\n    syscall\n\n    addi $a0, $zero, 1\n    addi $a1, $zero, 5\n\n  jal pro\n    add $a0, $zero, $v0\n    addi $v0, $zero, 1\n  syscall\n    la $a0, newline\n    addi $v0, $zero, 4\n    syscall\n    addi $a0, $zero, 1\n    addi $a1, $zero, 5\n\n  jal quo\n    add $a0, $zero, $v0\n    addi $v0, $zero, 1\n  syscall\n    la $a0, newline\n    addi $v0, $zero, 4\n    syscall\n\n    #exit\n    addi $v0, $zero, 10\n    syscall\n.end main\n\nsum:\n    add $v0, $a0, $a1\n\n    jr $ra\n\ndif:\n    sub $v0, $a0, $a1\n\n    jr $ra\n\npro:\n    mult $a0, $a1\n    mflo $v0\n\n    jr $ra\n\nquo:\n    div $a0, $a1\n    mflo $v0\n\n    jr $ra\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/07_Procedures/#question-2","title":"Question 2","text":"<p>Procedure for linear search</p> <p>Arguments</p> <ul> <li>Array address</li> <li>Array length</li> <li>Search Element</li> </ul> <p>Return</p> <ul> <li>Found flag</li> <li>Index, if found</li> </ul> <pre><code>.data\narray: .word 10, 20, 30, 40, 50\nfound_msg: .asciiz \"Found at index \"\nnot_found_msg: .asciiz \"Not Found\"\n\n.text\nmain:\n    la $a0, array\n    addi $a1, $zero, 5\n    addi $a2, $zero, 30\n\n    jal linear_search\n    beq $v0, $zero, print_not_found\n\n    print_found:\n        la $a0, found_msg\n        addi $v0, $zero, 4\n        syscall\n\n        add $a0, $zero, $v1\n        addi $v0, $zero, 1\n        syscall\n\n        j exit\n\n    print_not_found:\n        la $a0, not_found_msg\n        addi $v0, $zero, 4\n        syscall\n\n    exit:\n        addi $v0, $zero, 10\n        syscall\n\nlinear_search:\n    add $t0, $zero, $zero ## i = 0  \n    add $t4, $zero, 4\n    add $v0, $zero, $zero ## status\n\n    loop:\n        beq $t0, $a1, return\n\n        mult $t0, $t4 ## i*4\n        mflo $t1 ## offset = i*4\n        add $t1, $t1, $a0 ## adress = array_base_address + offset\n\n        lw $t2, 0($t1)\n        beq $t2, $a2, found\n\n        addi $t0, $t0, 1\n        j loop\n\n    j return\n\n    found:\n        addi $v0, $zero, 1\n        add $v1, $zero, $t0\n        j return\n\n    return:\n        jr $ra\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/08_Procedures_2/","title":"08 Procedures 2","text":""},{"location":"3_Core/Computer_Architecture/Lab/08_Procedures_2/#question-1","title":"Question 1","text":"<p>Implement a function to find exponent of a number</p> <pre><code>.data\n\n.text\nmain:\naddi $a0, $zero, 2\naddi $a1, $zero, 0\n\njal power\n\ndisplay:\nadd $a0, $zero, $v0\naddi $v0, $zero, 1\nsyscall\n\nexit:\naddi $v0, $zero, 10\nsyscall\n\npower:\n    beq $a1, 0, zero_case\n\n  addi $sp, $sp, -8\n    sw $ra, 4($sp)\n    sw $a0, 0($sp)\n\n    beq $a1, 1, one_case\n\n    mult $v0, $a0\n    mflo $v0\n    jr $ra\n\n    addi $a1, $a1, -1\n    jal power\n\n    zero_case:\n        addi $v0, $zero, 1\n        jr $ra\n\n    one_case:\n        lw $ra, 4($sp)\n        lw $v0, 0($sp)\n        addi $sp, $sp, 8\n\n        add $v0, $zero, $a0\n        jr $ra\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/08_Procedures_2/#question-2","title":"Question 2","text":""},{"location":"3_Core/Computer_Architecture/Lab/09_Floating_Point/","title":"09 Floating Point","text":""},{"location":"3_Core/Computer_Architecture/Lab/09_Floating_Point/#1-area-of-circle","title":"1: Area of circle","text":"<pre><code>.data\npi: .double 3.1415926535897924 \nr: .float 2.2\n\n.text\nmain:\nldc1 $f2, pi\nlwc1 $f4, r\ncvt.d.s $f4, $f4\n\nmul.d $f12, $f4, $f4    ## r^2\nmul.d $f12, $f2, $f12   ## pi r^2\n\naddi $v0, $zero, 3\nsyscall\n\n## exit\naddi $v0, $zero, 10\nsyscall\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/09_Floating_Point/#2-convert-from-f-to-c","title":"2: Convert from F to C","text":"<pre><code>.data \nf: .float 98.6\n\n.text\nmain:\nli.s $f2, 5.0\nli.s $f3, 9.0\n\nlwc1 $f4, f\nli.s $f5, 32.0\n\ndiv.s $f6, $f2, $f3 ## 5/9\nsub.s $f7, $f4, $f5 ## f - 32\n\nmul.s $f12, $f6, $f7    ## (5/9)*(f-32)\n\naddi $v0, $zero, 2\nsyscall\n\n## exit\naddi $v0, $zero, 10\nsyscall\n</code></pre>"},{"location":"3_Core/Computer_Architecture/Lab/09_Floating_Point/#3-value-of-ax2-bx-c-for-inputted-x","title":"3: Value of \\(ax^2 + bx + c\\) for inputted \\(x\\)","text":"<pre><code>.data \n\n.text\nmain:\n\n## read x\naddi $v0, $zero, 6\nsyscall\n\nmov.s $f2, $f0 ## x\nmul.s $f3, $f0, $f0 ## x^2\n\nli.s $f4, 1.0 ## a\nli.s $f4, 1.0 ## b \nli.s $f5, 1.0 ## c\n\nmul.s $f6, $f4, $f3 ## ax^2\nmul.s $f7, $f5, $f2 ## bx\n\nadd.s $f12, $f6, $f7 ## ax^2 + bx\nadd.s $f12, $f12, $f5 ## ax^2 + bx + c\n\n## Print\naddi $v0, $zero, 2\nsyscall\n\n## exit\naddi $v0, $zero, 10\nsyscall\n</code></pre>"},{"location":"3_Core/Computer_Networks/","title":"Computer Networks","text":"<p>Unfortunately, the notes could\u2019ve been better. Need help improving this.</p>"},{"location":"3_Core/Computer_Networks/01_Introduction/","title":"Introduction","text":""},{"location":"3_Core/Computer_Networks/01_Introduction/#data-communication","title":"Data Communication","text":"<p>Exchange of data b/w devices via transmission medium, where data is information presented in form agreed by involved parties. Termed from \u2018telecommunication\u2019 - communication at a distance</p>"},{"location":"3_Core/Computer_Networks/01_Introduction/#components-of-data-communication","title":"Components of Data Communication","text":"<ul> <li>Message</li> <li>Sender</li> <li>Sending protocol</li> <li>Medium</li> <li>Receiver</li> <li>Receiving protocol</li> </ul>"},{"location":"3_Core/Computer_Networks/01_Introduction/#node","title":"Node","text":"<p>Device capable of sending/receiving data to/from other notes on network</p>"},{"location":"3_Core/Computer_Networks/01_Introduction/#network","title":"Network","text":"<p>Set of devices connected by communication links</p>"},{"location":"3_Core/Computer_Networks/01_Introduction/#purpose","title":"Purpose","text":"<p>Share resourcces</p> <ul> <li>File sharing</li> <li>Hardware sharing</li> <li>Application sharing: Client/server apps</li> <li>Network graming</li> <li>User Commuication</li> <li>Voice over IP (VoIP): allows calls over traditional IP rather than by traditional PTSN</li> </ul>"},{"location":"3_Core/Computer_Networks/01_Introduction/#distance-based-classification","title":"Distance-Based Classification","text":"Range Example LAN Short Wifi MAN Specific area (city, campus) Cable TV WAN Long The Internet"},{"location":"3_Core/Computer_Networks/01_Introduction/#parts-of-network","title":"Parts of Network","text":"Part Role \u2018The Internet\u2019 Router Connect internet to \u2018The Internet\u2019has intelligence(represented using \\(\\otimes\\)) Firewall Rules to adhere on which messages to be allowed Switch Helps form a LAN (Local Area Network)No of ports will always be \\(2^n\\) File Server Database Server File Server WiFi Access Point kinda like a wireless switchconnected to wired swetch <p>Links between one/more routers should be a \u2018dedicated link\u2019</p>"},{"location":"3_Core/Computer_Networks/01_Introduction/#transmission-modes-media","title":"Transmission Modes &amp; Media","text":"Type Medium Range Requires Example Wired Twisted Pair Cables Short Landline, Ethernet cable Coaxial Cables Long Fibreoptic Cables Very Long Wireless(Frequency bands) Radio Waves Long Omni-directional antenna Car radio Micro Waves Long Uni-directional Microwave antennaLon Etisalat connection tower Infrared Waves Short Bluetooth <p>Wireless can - Infrastructure-Based: Mobile Network - Infrastructure-less: Bluetooth</p>"},{"location":"3_Core/Computer_Networks/01_Introduction/#idk","title":"IDK","text":""},{"location":"3_Core/Computer_Networks/01_Introduction/#transmission-modes","title":"Transmission Modes","text":"Direction Order Example Simplex Uni Car Radio Half-Duplex Bi Sequential(one direction after the other) Walkie-Talkie Full-Duplex Bi Simultaneous(both directions at the same time) Telephone"},{"location":"3_Core/Computer_Networks/01_Introduction/#line-configurations","title":"Line Configurations","text":"Example Point-to-Point Connection from ISP to home router Multi-Point Multiple devices connected to a single home router"},{"location":"3_Core/Computer_Networks/01_Introduction/#topology","title":"Topology","text":"<p>Arrangement of nodes in a network</p> Bus Ring Star Mesh Hybrid Arrangement Sequential Each node connected to 2 adjacent nodes Nodes directly connected to a central \u2018controller\u2019 Every device connected to every other devicein point-point manner Combination of star and bus Working Devices collectively help transfer data b/w pointsTerminators stop signals after reaching end of wire,to prevent signal bounce Token-Passing(Token: Message which gives priority to a station to use ring)- Data hops from one device to another until it reaches its destination- Each device communicates its routing info to every other connected device- Each device then determines either passes/keep received data Device Used TapDrop line Repeater Hub/Switch/Router Advantage SimpleCheapEasy installationNode failure does not affect others Easier to manageEasier to locate defective node/cable problemGreat for transmitting signals over long distances on a LANHandles high-volume network trafficEnables reliable communication - Good for modern networks- Low startup costs- Easy to manage- Easy to expand- Great availability of equipment- Scalable- High security Highest redundancyLow failure chanceLow trafficEasy fault identificationRobust Disadvantage Not fault-tolerantProne to congestionNo security ExpensiveSingle point of failureRequires more cable &amp; network equipment at startFewer equipment optionsFewer options for high-speed upgradesOnly one station can send messageRequires tokensRequires multiple repeatersNo security Single point of failure - If hub fails, everything failsPossible congestion at hubRequires more cables than bus Expensive(Many cables, I/O port, connections) Same as star Method Half-Duplex Simplex Duplex? Example Ethernet Between ISP routers Duplex/Half-Duplex links 1 0 \\(n\\) \\(\\frac{n(n-1)}{2}\\) Simplex links 0 1 \\(2n\\) \\(n(n-1)\\) Diagram"},{"location":"3_Core/Computer_Networks/01_Introduction/#network-devices","title":"Network Devices","text":"End Points PCs, Servers, Printers, etc Interconnections Media, ConnectorsNIC(Network Interface Card)/LAN Card/Ethernet Card) Bridge (not used anymore) Switches Connects endpoints to LANMulti-Port Bridge Router Connect multiple LANs to form internetworksChooses best path between LAN &amp; WAN Repeater Repeats Token in a round-robin fashionHelps overcome signal attenuation Hub Device without any intelligenceMulti-port repeaterNot used much anymoreIt will just broadcast every packet, as it cannot select devices."},{"location":"3_Core/Computer_Networks/01_Introduction/#network-rules","title":"Network Rules","text":""},{"location":"3_Core/Computer_Networks/01_Introduction/#protocol","title":"Protocol","text":"<p>Consists rules for the following aspects</p> Aspect Meaning Syntax Format of data Semantics Meaning of each section of bits Timing Timing and speed of data transfer"},{"location":"3_Core/Computer_Networks/01_Introduction/#the-internet","title":"The Internet","text":"<p>Network of networks, consisting of</p> <ul> <li>Connected computing devices</li> <li>communication links</li> <li>Routers</li> <li>Protoctols</li> <li>Communication infrasture for distributed applications</li> <li>Communication services</li> </ul>"},{"location":"3_Core/Computer_Networks/01_Introduction/#standard","title":"Standard","text":"<p>Collection of protocols agreed by organizations, such as ITU, IEEE</p> De Facto Standards De Jure Standards Approved by organizations Adopted through widespread use <p>For eg</p> <ul> <li>Wired LAN uses standard <code>IEEE 802.3</code></li> <li>WiFi (WirelessFidelity) uses standard <code>802.11</code></li> </ul>"},{"location":"3_Core/Computer_Networks/01_Introduction/#internet-standards","title":"Internet Standards","text":"<ul> <li>Internet draft</li> <li>RFC (Request for Comment)</li> </ul>"},{"location":"3_Core/Computer_Networks/01_Introduction/#models","title":"Models","text":"Model Example Client-Server 1 Client1 Server WWWEmail Peer-to-Peer End devices use each other\u2019s resources TorrentingTeleconferencing"},{"location":"3_Core/Computer_Networks/01_Introduction/#types-of-services","title":"Types of Services","text":"Connection-Oriented Connection-Less Stages 1. Set up connection2. Receive acknoledgement3. Send data4. Receive acknowlegment5. Repeat steps 3-4 Send data Reliable \u2705 \u274c Flow Control \u2705 \u274c Congestion Control \u2705 \u274c Speed Slower Faster Example Protocol TCP(Transmission Control Protocol) UDP(User Datagram Protocol) Example Applications HTTP (WWW)FTP (File Transfer Protocol)Telnet (Remote LoginSMTP (Simple Mail Transfer Protocol) Streaming mediaTeleconferencingInternet telephony"},{"location":"3_Core/Computer_Networks/01_Introduction/#switchingrouting-mechanism","title":"Switching/Routing Mechanism","text":"Circuit Switching Packet Switching Type Physical Logical Dedicated circuit per call: telephone net Data sent in discrete \u2018chunks\u2019Each packet uses full link bandwidth Steps - Establish physical connection- Network resources divided into pieces- Pieces allocated to calls- Data Transmission- Teardown - Split data into packets- Transmit packets one hope at a time- Packet reaches receiver Resource reservation \u2705 \u274c Resources allocated Fixed On-Demand (Dynamic) Advantages Line efficiency (Single link can be shared by multiple packets)Data rate conversionPackets are accepted even when network is busy (delayed, but still accepted)Priorities can be set Disadvantage Resource piece idle if not used by owning call (no sharing)Call setup required Connection Type Connection-oriented Connection-less (Virtual Circuit Approach)Connection-oriented (Datagram Approach) Total resource demandcan exceed  available? \u274c \u2705 CongestionControl? \u274c \u2705 Performanceguaranteed? \u2705 \u274c"},{"location":"3_Core/Computer_Networks/01_Introduction/#resource-division","title":"Resource Division","text":"<ol> <li>Frequency division</li> <li>Time division</li> <li>Code division</li> </ol>"},{"location":"3_Core/Computer_Networks/01_Introduction/#tdm","title":"TDM","text":"<p>Time Division Multiplexing</p> <p></p>"},{"location":"3_Core/Computer_Networks/01_Introduction/#subnet-mask","title":"Subnet Mask","text":"<p>This is the value to perform <code>and</code> operation</p> <p>To get the value, just make the network bits of the IP address as 1s and host bits as 0s</p>"},{"location":"3_Core/Computer_Networks/02_Layers/","title":"02 Layers","text":"<p>Task of moving information b/w computers over the network is divided into smaller and more manageable problems.</p> <p>Each problem is considered as a different layer in the network, which reduces complexity.</p> <p>Each layer</p> <ul> <li>provides service to layer above &amp; belo</li> <li>communicates with the same layer\u2019s software or hardware on other computer</li> </ul> <p>There are 2 network standards</p>"},{"location":"3_Core/Computer_Networks/02_Layers/#iso-osi-standard","title":"ISO OSI Standard","text":"<p>International Organization of Standardization-Open System Interconnection</p> <p>The upper 3 layers of the OSI model (application, presentation and session\u2014Layers 7, 6 and 5) are orientated more toward services to the applications</p> <p>Lower 4 layers (transport, network, data link and physical \u2014Layers 4, 3, 2, and 1) are concerned with the flow of data from end to end through the network.</p> <p></p> Type Layer Description PDU Device/Example Address Delivery Protocols TransmissionMode LineConfiguration ServiceType Logical Application Provides  network-access services to user Data/Page WhatsappBrowserMail client HTTPFTPSMTPSNMPDNSNFSTelnetDHCP Presentation Data/File formatData TranslationProtocol conversionSyntax &amp; SemanticsCompression/DecompressionEncryption/Decryption Data/Page SSLTLS Session Session creation, maintainence, terminationDialogue control &amp; synchronization b/w 2 end systemsToken ManagementPassword ValidationLogical connection requestSynchronization &amp; checkpointing of pages Data/Page PPTPSIPSAPNetBIOS Half-duplexFull-duplex Transport Ensuring reliable data exchange mechanismError control (only end-systems: source-dest)Flow controlConnection controlService point addressingSegmentation/Re-assembly into/from a packet Segment Port(identifies process/service) Process-to-Process TCPUDP Multiplex ConnectionlessConnection-oriented Hardware Network Inter-NetworkingRouting algoIP addressingCongestion handlingPacketizingFragmenting Packet/Datagram Router IP Host-to-Host IPv4, IPv6IPSecICMPIGPEGPOGHPRARPARP Data Link Ensuring reliable communication over physical layer\u2018Framing\u2019/ReassemblingError control (router &amp; end-system: source-dest + each hop)Error correction/handlingCorruption detection/correctionFlow control (pacing b/w adjacent sending &amp; receiving nodes)Access controlLAN formationPhysical addressing &amp; matching Frame BridgesSwitches MAC Hop-to-Hop Delivery ATMSLIPFrameRelayPPP SimplexHalf-DuplexFull-Duplex Point-to-PointBroadcast Physical Convert signal b/w digital &amp; analogEncryption &amp; decryptionRepresentation of bitsData rateSynchronization of bitsEncodingModulationLine ConfigurationTransmission mediumTransmission modeTopology Bitstream/Raw Data HubRepeater USBBluetooth Connection-Oriented(most reliable layer)"},{"location":"3_Core/Computer_Networks/02_Layers/#pdu","title":"PDU","text":"<p>Protocol data unit</p> <p>PDU\u2019s are used for peer-to-peer contact between corresponding layers</p>"},{"location":"3_Core/Computer_Networks/02_Layers/#packet","title":"Packet","text":"H3(Header) Data Source IP addressDestination IP address"},{"location":"3_Core/Computer_Networks/02_Layers/#frame","title":"Frame","text":"H2(Header of layer 2) Data T2(Trailer of layer 2) Source MAC AddressDestination MAC Address(found through Hop-to-Hop Delivery) Usually a parity"},{"location":"3_Core/Computer_Networks/02_Layers/#analogy","title":"Analogy","text":"<p>12 kids in Ann\u2019s house sending letters to 12 kids in Bill\u2019s house:</p> <ul> <li>hosts = houses</li> <li>processes = kids</li> <li>app messages = letters in envelopes</li> </ul> <p>transport protocol = Ann\u2019 multiplexing and Bill\u2019 demultiplexing to in-house siblings</p> <p>network-layer protocol = postal service</p>"},{"location":"3_Core/Computer_Networks/02_Layers/#tcpip","title":"TCP/IP","text":"<p>Transmission Control Protocol with inter-networking protocol</p> <ul> <li>Application</li> <li>Transport</li> <li>Network</li> <li>Data Link</li> <li>Physical</li> </ul>"},{"location":"3_Core/Computer_Networks/02_Layers/#osi-vs-tcpip","title":"OSI vs TCP/IP","text":"OSI TCP/IP No of Layers 7 5 Transport Layer Connection-oriented/Connection-less Connection-oriented/Connection-less Network layer Connection-oriented Connection-less Delivery model \u2018Best\u2019 \u2018Best-effort\u2019"},{"location":"3_Core/Computer_Networks/02_Layers/#addresses","title":"Addresses","text":"Address Size (in Bits) Denotion Example Separator Connect devicein ___ network Set during Fixed Administered by Portable Specific Port 16 Decimal 753(0-1024 are reserved) (none; it is a single no) IP/Logical/Host 32 Decimal 192.168.22.5 Dot different Connectionto network \u274c \u274c(address depends on connected IP subnet) MAC(Medium Access Control)/Ethernet/LAN/Physical/Link 4824 Vendor Code,24 Serial No) Hexadecimal AA.F0.C1.E2.77.51 Colon (Linux)Hyphen (Windows) same Devicemanufacture \u2705(usually burnt into NIC ROM;sometimes software-configurable) IEEE(Manufacturer buys portion of MAC address space for uniqueness) \u2705(LAN card can be moved) <ul> <li>MAC address is like Social Security Number</li> <li>IP address is like postal address</li> </ul>"},{"location":"3_Core/Computer_Networks/02_Layers/#idk","title":"idk","text":"<p>The physical addresses will change from hop to hop, but the logical and port addresses usually remain the same. Huh???</p>"},{"location":"3_Core/Computer_Networks/02_Layers/#ipv4","title":"IPv4","text":"Class Byte 1 (Decimal) Byte 1 (Binary) A 0-127 0\u2026 B 128-191 10\u2026 C 192-223 110\u2026 D 224-299 1110\u2026 E 240-255 1111\u2026 <p>Network ID is the first IP address, for eg: <code>10.0.0.0, 20.0.0.0</code>. This is used to refer to all devices in a network.</p> <p>Only end-devices and routers require IP address, as they belong to network layer.</p>"},{"location":"3_Core/Computer_Networks/02_Layers/#protocols","title":"Protocols","text":"Layer Protocol Full Form Details Network IP Internet Protocol Network ICMP Internet Control Message Protocol <code>ping</code> command uses this Network IGMP Internet Group Message Protocol Network +Data Link(Hybrid) ARP Address resolution protocol Convert ip address to mac address Network +Data Link(Hybrid) RARP Reversed Address resolution protocol Convert mac address to ip address(Only required when connecting to a network for the first time)"},{"location":"3_Core/Computer_Networks/03_Performance/","title":"03 Performance","text":""},{"location":"3_Core/Computer_Networks/03_Performance/#network-criteria","title":"Network Criteria","text":"<ul> <li>Fault Tolerance</li> <li>Scalability</li> <li>QoS (Quality of Service)</li> <li>High Throughput</li> <li>High Bandwidth</li> <li>Low Latency</li> <li>Security</li> </ul>"},{"location":"3_Core/Computer_Networks/03_Performance/#performance-criteria","title":"Performance Criteria","text":"Bandwidth Max number of bits transferrable per unit time(In analog world, it is the range of accepted frequencies) Throughput Actual number of bits transferred per unit time Latency/Delay Duration to send info &amp; its earliest possible reception End-to-EndDelay Duration to transmit packet along its entire path- Created by application- Handed over to OS- Passed to NIC- Encoded, transmitted over a physical medium- Received by intermediate device (switch, router)- Analyzed, retransmitted over another medium, etc. Round-Trip-Time Duration to send and receive acknowledge"},{"location":"3_Core/Computer_Networks/03_Performance/#types-of-delays","title":"Types of Delays","text":"Delay Duration of Formula Transmission Placing bits onto transmission mediaum \\(\\frac{\\text{Size}}{\\text{Bandwidth}}\\) Propagation Travel for a bit from one end of medium to other \\(\\frac{\\text{Distance}}{\\text{Speed}}\\) Processing Error verificationRouting decision, ie- analyze packet header- decide where to send packet No of entries inrouting tableImplementatio of data structuresHardware specs Buffer/Queuing Packet to wait until it is transmitted Traffic intensityType of traffic <p>Latency = \\(\\sum\\) all the above delays</p>"},{"location":"3_Core/Computer_Networks/03_Performance/#mediums","title":"Mediums","text":"Medium Speed\u00a0(m/s) Vacuum \\(3 \\times 10^8\\) Cable \\(2.3 \\times 10^8\\) Fiber \\(2 \\times 10^8\\)"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/","title":"04 Data Link Layer","text":"<p>It is a combination of hardware, software, and firmware (software for hardware)</p> <p>It is implemented in NIC and attaches into host\u2019s system buses</p>"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#sublayers","title":"Sublayers","text":"<p>The data link may be further divided into sublayers, which is explained in detail in Ethernet</p>"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#flow-control","title":"Flow Control","text":"<p>Handles mismatch b/w sender\u2019s and receiver\u2019s speed</p> Control Method Type Meaning Feedback-Based(More common) Explicit Permission required from receiver Rate-Based Implicit Limit sending rate"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#error-types","title":"Error Types","text":"Type No of Bits Consecutive Bits? Single-Bit 1 Multiple-Bit &gt;1 \u274c Burst &gt;1 \u2705"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#error-control","title":"Error Control","text":"Error detection codes Detect error Error/Forwardcorrection codes(FEC) Detect &amp; correct errorUse in wireless networks Retransmission/Automatic Repeat Request(ARQ) Used along with error detection/correctionBlock of data with error discardedTransmitter retransmits that block of data"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#redundancy","title":"Redundancy","text":"<p>Redundant bits added to data to detect &amp; correct errors</p> <pre><code>flowchart LR\n\nsubgraph s[Sender's Encoder]\nm1[Message] --&gt;\nGenerator --&gt;\na[Message &amp;&lt;br/&gt;Redundancy]\nend\n\nsubgraph r[Receiver's Decoder]\nd[Received&lt;br/&gt;Data] --&gt;\nc[Checker] --&gt;\n|Accept| m2[Message]\nend\n\na --&gt;\n|Unreliable&lt;br/&gt;Transmission| d\n\nc --&gt; |Discard| Lost</code></pre>"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#coding","title":"Coding","text":"<p>Process of adding redundancy for error detection/correction</p> <p>Error-detecting code can detect \u2028only types of errors for which it is designed; other types of errors may remain undetected. There is no way to detect every possible error</p> Code Steps Redundant bits Total bits\\(n\\) Memoryless? Block Divide data into set of \\(k\\)-bit blocks (called datawords) Extra info attached to each blockCombined blocks called codewords \\(r\\) \\(k+r\\) \u2705 Convolutional Treats data a series of bitsComputes code over continuous series \u274c(Code depends on current &amp; previous i/p) <p></p> <pre><code>flowchart TB\n\nd1[\"Dataword&lt;br/&gt;a3 a2 a1 a0&lt;br/&gt;&lt;br/&gt;(k bits)\"] --&gt;\nc1 &amp; g[\"Generator&lt;br/&gt;(r bits)\"]\n\ng --&gt;\nc1[\"Codeword&lt;br/&gt;a3 a2 a1 a0 &lt;span style='color:red'&gt;p0&lt;/span&gt;&lt;br/&gt;&lt;br/&gt;(n bits)\"]</code></pre>"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#code-rate","title":"Code Rate","text":"\\[ = \\frac{k}{n} \\] Code Rate \\(\\implies\\) Error Correcting Capability Bandwidth Efficiency \\(\\uparrow\\) \\(\\downarrow\\) \\(\\uparrow\\) \\(\\downarrow\\) \\(\\uparrow\\) \\(\\downarrow\\)"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#error-detection-methods","title":"Error Detection Methods","text":"<p>If syndrome = 0 at the receiver, there is no error</p> Simple parity check Horizontal &amp; VerticalParity check CRC(Cyclic Redundancy Check) Checksum Use an odd/even parity bit Use parity bit vertically and horizontally Add \\(r\\) zeros to right of dividend, where \\(r=\\)no of redundant bits = length of divisor - 1Long division using XOR (used in network layer)Find sum of digitsIf overflow, perform paddingTake 1s complement Errors detectable \\(\\{1, 3, \\dots, 2n+1 \\}\\)(odd no of errors) \\(\\{1, 2, 3, 5, 6, 7, \\dots \\} \\implies R - \\{4n\\}\\) All All Can correct error? \u274c(error can be in any positionincluding parity bit itself)"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#simple-parity","title":"Simple Parity","text":"Parity Parity bit = 0 means dataword has Odd Odd number of ones Even Even number of ones"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#mac-layer-throughput","title":"Mac Layer Throughput","text":"<p>Number of bits sent by MAC (Data Link) layer in given period of time</p> \\[ \\begin{aligned} \\text{Throughput} = \\frac{\\text{Payload}}{\\text{Total Time}} \\end{aligned} \\]"},{"location":"3_Core/Computer_Networks/04_Data_Link_Layer/#control-frame","title":"Control Frame","text":"<p>Frames that only contain headers/trailers, and no payload</p>"},{"location":"3_Core/Computer_Networks/05_Multiple_Access/","title":"05 Multiple Access","text":""},{"location":"3_Core/Computer_Networks/05_Multiple_Access/#access-protocols","title":"Access Protocols","text":"Random-Access/Contention Controlled-Access Channelization No station is superior to anotherNo station permits another station to send at the same timeNode with packet transmits at full channel data rateAll transmission on shared channel Collisions Moderate Little-to-none Throughput for smaller networks Low High Throughput for larger networks High Low Easy to maintain? \u2705 \u274c Commonly-used? \u2705 \u274c(Hard to control large networks) Example ALOHACSMACSMA/CDCSMA/CA ReservationPollingToken-Passing FDMATDMACDMA"},{"location":"3_Core/Computer_Networks/05_Multiple_Access/#collision","title":"Collision","text":"<p>When 2 nodes transmit concurrently</p>"},{"location":"3_Core/Computer_Networks/05_Multiple_Access/#carrier-sensing","title":"Carrier-Sensing","text":"<p>When the energy level is higher than usual, that means that there is a collision</p> <p></p> <p>However, this method may not suitable for wireless transmission, due to energy loss.</p>"},{"location":"3_Core/Computer_Networks/05_Multiple_Access/#persistence-methods","title":"Persistence Methods","text":"1-persistent Non-persistent \\(p\\) - persistent Default persistent method Probabilistic mixture of 1-persistent &amp; non-persistentAssume channels are slottedOne slot = contention period (one RTT)Used when time slot duration \\(\\ge\\) max \\(T_P\\) Steps 1. Sense channel2. if idle, transmit immediately3. If busy, keep listening 1. Sense channel2. If idle, transmit immediately3. If busy, wait random amount of time and sense channel - When station ready to send, it senses the channel- If channel is idle, transmits with probability \\(pp\\)- If channel is busy, station waits until next slot.- With probability \\(q=l-p\\), the station then waits for beginning of next slot - If next slot also idle, either transmit/wait again with probabilities \\(pp\\) &amp; \\(q\\) - Process repeated till either frame transmitted/another station starts transmitting- If another station  transmits, station waits random amount of time &amp; starts again If collision occurs Wait ranom amount of time &amp; start over Wait random amount of time &amp; start over Diagram"},{"location":"3_Core/Computer_Networks/06_Random_Access/","title":"06 Random Access","text":"<p>Let</p> Symbol Meaning \\(T_\\text{fr}\\) Time to transmit a frame \\(T_p\\) Propagation Delay \\(G\\) Average no of frames requested per frame-time \\(S\\) Throughput(Number of packets successfully transmitted per packet time) \\(V\\) Vulnerable TimeTime bracket for potential collision"},{"location":"3_Core/Computer_Networks/06_Random_Access/#protocols","title":"Protocols","text":"Pure ALOHA Slotted ALOHA CSMA CSMA/CD CSMA/CA IDK Carrier Sense Multiple AccessListen before transmissionNode does not send if another node already sendingUses persistence methods Collision DetectionListen to channel while packet being sentNode stops sending if \\(\\exists\\) interference Assumptions Stations trying to transmit follow Poisson Distribution All frames are of same sizeTime divided into equal slots (time to transmit a frame)Nodes start transmission only at start of slotIf 2/more nodes transmit, all nodes detect collision Constant length packetsNo errors, except ones caused by collisionsEach host can sense transmissions of all other hostsPropagation delay is small compared to transmission delay 1. Check line is quiet2. Detect collision ASAP3. If collision detected, stop transmission; wait random time and start over Preferred for Wired Networks Wired Networks (not used; always used with CD or CA) Slow Wired Networks(since efficiency reduces for faster networks; as bandwidth increases, collisions increase) Wireless Networks (WLAN)(since all signals are broadcasted and collisions cannot be detected) MinimumFrameLength Frame length such that \\(T_t &gt; 2 \\times T_P\\) \\(V\\) \\(2 \\times T_\\text{fr}\\) \\(T_\\text{fr}\\) \\(T_P\\) \\(S\\) \\(G \\times e^{-2G}\\) \\(G \\times e^{-G}\\) \\(G_\\text{max}\\) \u00bd 1 \\(S_\\text{max}\\) 0.184 0.368 Flowchart"},{"location":"3_Core/Computer_Networks/06_Random_Access/#csmacd","title":"CSMA/CD","text":"\\[ \\begin{aligned} B &amp;= \\frac{\\text{PD}}{\\text{TD}} \\\\ &amp;= \\frac{ \\frac{\\text{Distance}}{\\text{Speed}} }{ \\frac{\\text{Data Size}}{\\text{Bandwidth}} }\\\\ &amp;= \\frac{\\text{Distance} \\times \\text{Bandwidth}}{\\text{Speed} \\times \\text{Data Size}} \\end{aligned} \\] \\[ \\begin{aligned} \\text{Throughput } E &amp;= \\frac{1}{1+kB} &amp; (k \\in [1, 10]) \\\\ &amp;= \\frac{1}{1+k \\left(  \\frac{\\text{Distance} \\times \\text{Bandwidth}}{\\text{Speed} \\times \\text{Data Size}} \\right)} \\\\ \\implies E &amp;\\propto \\frac{1}{\\text{Bandwidth}} \\end{aligned} \\]"},{"location":"3_Core/Computer_Networks/06_Random_Access/#csmaca","title":"CSMA/CA","text":"\\[ \\begin{aligned} \\text{Maximize Size of contention window} &amp;= 15 \\times \\text{RTT} \\\\ &amp;= 30 \\times T_P \\end{aligned} \\]"},{"location":"3_Core/Computer_Networks/06_Random_Access/#dcf","title":"DCF","text":"<p>Distributed Coordination Function</p> <p>DCF sublayer uses CSMA </p> <ul> <li> <p>if station has frame to send, it listens to medium</p> </li> <li> <p>if medium idle, station may transmit</p> </li> <li>else waits until current transmission complete </li> </ul> <p>No collision detection possible due to wireless network</p> <p>DCF includes delays that act as a priority scheme</p> <p>Combination of</p> Full Form Contains CSMA/CA RTS Request/Ready to Send Duration required for channel CTS Clear to Send MAC address NAV Network Allocation Vector DIFS Domething InterFrame Space SIFS Something InterFrame Space"},{"location":"3_Core/Computer_Networks/06_Random_Access/#steps","title":"Steps","text":"<p>When a station wants to transmit data</p> <ul> <li> <p>It sends an RTS packet to the intended receiver</p> </li> <li> <p>The RTS packet contains the length of the data that needs to be transmitted</p> </li> <li> <p>Any station other than the intended recipient hearing RTS defers transmission for a time duration equal to the end of the corresponding CTS reception</p> </li> <li>The receiver sends back CTS packet back to sender if it is available to receive</li> <li> <p>The CTS packet contains the length of the data that original sender wants to transmit </p> </li> <li> <p>Any station other than the original RTS sender, hearing CTS defers transmission until the data is sent. </p> </li> <li>The original sender upon reception of the CTS, starts transmitting. </li> </ul>"},{"location":"3_Core/Computer_Networks/06_Random_Access/#flowchart","title":"Flowchart","text":""},{"location":"3_Core/Computer_Networks/06_Random_Access/#timeline-diagram","title":"Timeline Diagram","text":"Vertical Format Horizontal Format"},{"location":"3_Core/Computer_Networks/06_Random_Access/#wireless-channel-problems","title":"Wireless Channel Problems","text":"Hidden Terminal Problem Exposed Terminal Problem Description Two nodes hidden from each other transmit complete frames to base station Disadvantage Wasted bandwidth for long duration Solution Small reservation packets: RTS+CTSNodes track reservation interval with internal NAV Diagram"},{"location":"3_Core/Computer_Networks/07_Controlled_Access/","title":"07 Controlled Access","text":"<p>(please complete from slides)</p>"},{"location":"3_Core/Computer_Networks/07_Controlled_Access/#reservation-method","title":"Reservation Method","text":"<p>Priority is given to each station</p> <p>Reservation frames are used by stations to \u2018reserve access\u2019. Size of reservation frame (in bits) will be equal to number of stations in the network.</p> <ul> <li>Stations take turns transmitting a single frame at a full rate \\(R\\) bps</li> <li>Transmissions are organized into variable length cycles</li> <li>Each cycle begins with a reservation interval that consists of \\(N\\) minislots. One minislot for each of the \\(N\\) stations.</li> <li>When a station needs to send a data frame, it makes a reservation in its own minislot.</li> <li>By listening to the reservation interval, every station knows which stations will transfer frames, and in which order.</li> <li>The stations that made reservations can send their data frames after the reservation frame</li> </ul> <p></p>"},{"location":"3_Core/Computer_Networks/07_Controlled_Access/#polling","title":"Polling","text":"Primary Station Secondary Station Example Servers Clients Permission to select \u2705 \u274c <p>Polling by primary station keeps switching between secondary stations at a certain polling rate.</p> <p>Stations take turns accessing the medium</p>"},{"location":"3_Core/Computer_Networks/07_Controlled_Access/#types","title":"Types","text":"Centralized Polling Distributed Polling - One device is assigned as primary station and the others as secondary stations- All data exchanges are done through the primary- When the primary has a frame to send it sends a select frame that includes the address of the intended secondary- When the primary is ready to receive data it send a Poll frame for each device to ask if it has data to send or not. If yes, data will be transmitted otherwise NAK (Negative AcKnowledgement)\u00a0is sent.- Polling can be done in order (Round-Robin) or based on predetermined order - No primary and secondary- Stations have a known polling order list which is made based on some protocol- station with the highest priority will have the access right first, then it passes the access right to the next station (it will send a pulling message to the next station in the pulling list), which will passes the access right to the following next station, \u2026"},{"location":"3_Core/Computer_Networks/07_Controlled_Access/#token-passing","title":"Token-Passing","text":"<p>Requires ring topology</p> <pre><code>flowchart TB\nstart([Start]) --&gt;\ntoken[\"Wait for&lt;br/&gt;Token\"] --&gt;\nct[/\"Capture&lt;br/&gt;Token\"/] --&gt;\ndfts{\"Data frame&lt;br/&gt;to send?\"}\n\ndfts --&gt;\n|Yes| send[/\"Send&lt;br/&gt;Frame\"/] --&gt;\nate{\"Allocated Time&lt;br/&gt;Expired\"} --&gt;\n|No| dfts\n\ndfts --&gt; |No| e\nate --&gt; |Yes| e\n\n\ne((\" \")) --&gt;\nrt[\"Release Token&lt;br/&gt;(Next station takes token)\"] --&gt;\nstop([Stop])</code></pre>"},{"location":"3_Core/Computer_Networks/08_Ethernet/","title":"08 Ethernet","text":"<p>Protocol for connecting multiple computer systems to form a LAN, with protocols to</p> <ul> <li>control passing of information</li> <li>avoid simultaneous transmission by multiple systems</li> </ul>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#ieee-8023-data-link-layer-sublayers","title":"IEEE 802.3 Data Link Layer Sublayers","text":"Datalink Sublayer Tasks Name of frame Implementation Protocol LLC(Logical Link Control) Error ControlFlow ControlInterconnectivity b/w data link layer of different LANsMultiplex multiple network layer protocols in frame IEEE 802.3 Software CRC (error-correction)ARQ MAC(Medium Access Control) FramingMAC AddressingMedium Access Control IEEE 802.2 Hardware Token-Passing (Wired Token Ring)CSMA/CD (Wired other)CSMA/CA with NAV (Wireless)"},{"location":"3_Core/Computer_Networks/08_Ethernet/#diagram","title":"Diagram","text":""},{"location":"3_Core/Computer_Networks/08_Ethernet/#domains","title":"Domains","text":"Domain Associated with Number Broadcast Router Connection No of switches connected to router Collision Switch Connection No of half-duplex links connected to switch Collision occurs as switches are not as intelligent as routers"},{"location":"3_Core/Computer_Networks/08_Ethernet/#topology","title":"Topology","text":"Bus Star Active switch in center Collision domain All nodes in same collision domain Each spoke runs separate Ethernet protocol Collisions Prevented? \u274c \u2705"},{"location":"3_Core/Computer_Networks/08_Ethernet/#normal-ethernet-operation","title":"Normal Ethernet Operation","text":"Receiver receives frame with Matching destination address Data sent to network layer Broadcast address (e.g. ARP packet) Data sent to network layer Neither of the above Discard frame"},{"location":"3_Core/Computer_Networks/08_Ethernet/#types","title":"Types","text":"Type Speed Connection Reliable? Chance ofdropping frames AccessProtocol Standard 10 Mbps Connectionless \u274c High CSMA/CD Fast 100 Mbps Gigabit 1 Gbps Ten-Gigabit 10 Gbps"},{"location":"3_Core/Computer_Networks/08_Ethernet/#standard-ethernet-implementations","title":"Standard Ethernet Implementations","text":"Implementation Topology Transmission Medium 10Base5 Bus Thick coaxial 10Base2 Bus Thin coaxial 10Base-T Star UTP(Unshielded-Twisted-Pair) 10Base-F Star Fiber"},{"location":"3_Core/Computer_Networks/08_Ethernet/#steps-of-routing-to-another-lan","title":"Steps of Routing to another LAN","text":"<p>Assuming A has all the required addresses already, and wants to send a message to B via R.</p> <ol> <li>Create packet in Network Layer with</li> <li>Source address = A\u2019s IP address</li> <li>Destination address = B\u2019s IP address</li> <li>Create frame in Datalink Layer with </li> <li>Source address = A\u2019s MAC address</li> <li>Destination address = R\u2019s receiving terminal MAC address</li> <li>A sends message to R</li> <li>R receives message</li> <li>R processes and removes frame in Datalink Layer</li> <li>R processes packet in Network Layer</li> <li>R forwards packet with the same source and destination as before in the Network layer</li> <li>R creates frame in the Network layer with</li> <li>Source address = R\u2019s sending terminal MAC address</li> <li>Destination address = B\u2019s MAC address</li> </ol>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#ethernet-switch","title":"Ethernet Switch","text":"<ul> <li>Examines incoming frame\u2019s MAC address</li> <li>Selectively forwards frame to one/more outgoing links when frame is to be forwarded on segment</li> <li>Uses CSMA/CD to access segment</li> <li>Buffers packets</li> </ul> <p>Every host has dedicated &amp; direction connection to switch</p> <p>Each link connected to switch is its own collision domain; hosts transmitting simultaneously does not affect other transmissions if they are on different link.</p>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#characteristics","title":"Characteristics","text":"<ul> <li>Transparent: Hosts are unaware of presence of switches</li> <li>Plug-and-Play device: No configuration required by network admin</li> <li>Self-Learning mechanism</li> </ul>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#types_1","title":"Types","text":"Cut-through Store-and-forward switch Begins forwarding dataafter examining only first part of header entire data Retransmission Time \\(&lt; T_t\\) \\(= T_t\\)"},{"location":"3_Core/Computer_Networks/08_Ethernet/#switch-table","title":"Switch Table","text":"<p>Helps switch data from source to destination</p> Host MAC Address Interface to reach host TTL"},{"location":"3_Core/Computer_Networks/08_Ethernet/#self-learning","title":"Self-Learning","text":"<ol> <li> <p>Check if receiver exists in switch table</p> </li> <li> <p>If yes, go to step 5</p> </li> <li> <p>\u2018Flood\u2019 (broadcast) message to all stations</p> </li> <li> <p>Update switch table with receiver\u2019s entry</p> </li> <li>Send to receiver</li> </ol>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#interconnected-switches","title":"Interconnected Switches","text":"<p>Works using the same self-learning process</p> <p></p>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#switches-vs-router","title":"Switches vs Router","text":"Switch Router Store &amp; Forward? \u2705 \u2705 Layer Data Link Network Examine Data link layer headers Network layer headers Understand addresses MAC IP Forwarding Table? \u2705 \u2705 Learning Method Flooding learning Routing algorithms"},{"location":"3_Core/Computer_Networks/08_Ethernet/#vlan","title":"VLAN","text":"<p>Virtual Local Area Network</p> <p>Allows us to divide a LAN without any additional switches</p> <p>VLAN can be defined using one of the following techniques</p> <ul> <li>Switch port</li> <li>MAC addresses of endpoints</li> </ul>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#advantages","title":"Advantages","text":"<p>VLAN helps overcome the following</p> <ul> <li>Improve traffic isolation: frames by default can only travel within their own VLAN</li> <li>Dynamic membership: ports can be dynamically assigned among VLANs</li> <li>Efficient use of switches</li> <li>Management of users</li> <li>Forwarding between VLANS</li> <li>Address Security, privacy and efficiency issues. Data link layer broadcast traffic (ARP, DHCP, unknown location of destination MAC address) need not cross entire LAN.</li> </ul>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#port-based-vlan","title":"Port-Based VLAN","text":"Details Trunk Port connected to routerTraffic isolationsomething else No of usable ports \\(n-1\\)(Trunk port unusable) Actual connections Behaves as"},{"location":"3_Core/Computer_Networks/08_Ethernet/#trunk-port","title":"Trunk Port","text":"<p>Carries frames between VLANS defined over multiple physical switches. Frames forwarded over multiple switches must carry VLAN ID info as well, and hence uses IEEE 802.1Q Frame.</p> <p></p>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#ethernetieee-8021-frame","title":"Ethernet/IEEE 802.1 Frame","text":"<p>All sizes shown in Bytes</p> Size Minimum 64 Bytes Maximum 1518 Bytes Preamble SFD(Start Frame Delimiter) Dest MACAddress Source MACAddress Type Payload(Data &amp; Padding) CRC 7 Bytes 1 byte 6 Bytes 6 Bytes 2 Bytes \\([46, 1500]\\) Bytes 4 Bytes Alternating 1/01010\u20261010 10101010**11** Type of Data Cyclic Redundancy Check Part of physical layer header(Processed at physical layer) Part of physical layer header(Processed at physical layer) 0800 \u2013&gt; IPv40806 \u2013&gt; ARP Frame8100 \u2013&gt; IEEE 802.1Q Frame86DD \u2013&gt; IPv6 Error -&gt; Frame dropped Synchronizes sender &amp; receiver clock rates Signals the beginning of frame"},{"location":"3_Core/Computer_Networks/08_Ethernet/#example-of-multiple-frames","title":"Example of multiple frames","text":""},{"location":"3_Core/Computer_Networks/08_Ethernet/#receiver-address-type","title":"Receiver Address Type","text":"Type Receiver Address Value Unicast LSB of first byte = 0 Multicast LSB of first byte = 1 Broadcast All bits are 1 <p>LSB = Least Significant Bit</p>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#ieee-8021q-frame","title":"IEEE 802.1Q Frame","text":"<p>Adds/removes additional header fields for frames forwarded between trunk ports</p> <p>(Empty cells of the following table means that they are the same as regular Ethernet frame)</p> Preamble SFD(Start Frame Delimiter) DestAddress SourceAdd Tag Protocol Identifier Tag Control Info Type Data &amp; Padding CRC 2B 12bits VLAN ID field3bits field like IP TOS Recomputed CRC 81-100 <p></p>"},{"location":"3_Core/Computer_Networks/08_Ethernet/#vlan-frame","title":"VLAN Frame","text":"Preamble SFD(Start Frame Delimiter) Dest MACAddress Source MACAddress Tag Type Payload(Data &amp; Padding) CRC <p>Tag is </p>"},{"location":"3_Core/Computer_Networks/09_ARP/","title":"09 ARP","text":"<p>Address Resolution Protocol</p> <p>Obtain MAC Address from IP address</p> <p>It is \u2018plug-and-play\u2019, as nodes create their ARP tables w/o intervention from network admin</p>"},{"location":"3_Core/Computer_Networks/09_ARP/#arp-procedure","title":"ARP Procedure","text":"<p>Let\u2019s say node A wants to send message to node B</p> <ol> <li>Check ARP Table for B\u2019s MAC address using IP address.</li> <li>If B found, A sends message to B. Stop</li> <li>Else, A broadcasts ARP query packet, containing B's IP address</li> <li>dest MAC address = \\(FF \\ FF \\ FF \\ FF \\ FF \\ FF\\)</li> <li>all nodes on LAN receive ARP query</li> <li>B receives ARP packet, replies to A with its (B's) MAC address    frame sent to A\u2019s MAC address (unicast)</li> <li>A adds B\u2019s mac address to its ARP table</li> <li>Go to step 1</li> </ol> ARP Message Type Type ARP Request Broadcast ARP Reply Unicast"},{"location":"3_Core/Computer_Networks/09_ARP/#arp-table","title":"ARP Table","text":"<p>Each IP node on LAN has ARP table, which contains</p> IP Address MAC Address TTL Time To LiveTime after which address mapping will be forgottenUsually 20min"},{"location":"3_Core/Computer_Networks/09_ARP/#arp-packet","title":"ARP Packet","text":"<p>Destination address of the frame will be all 1s, as this will be broadcast</p> <p></p> <p></p> Meaning Value Size Hardware Type Type of network on which ARP is running Ethernet -&gt; 1 16 bits Hardware Length Length of physical address in bytes Ethernet -&gt; 6 8 bits Protocol Length Length of logical address in bytes 8 bits Protocol Type Type of IP used IPv4 -&gt; \\(0800_H\\) 16 bits Operation Type of ARP Packet Request -&gt; 1Reply -&gt; 2 16 bits Sender MAC address 6 bytes for ethernet Sender IP address 4 bytes for IP Target MAC address Request (all 0s as MAC address unknown)Reply (returned MAC address) 6 bytes for ethernet Target IP address 4 bytes for IP"},{"location":"3_Core/Computer_Networks/09_ARP/#target-ip-address","title":"Target IP address","text":"Sender Receiver Network Value of Target IP address Host Host Same Same as destination IP address in IP packet Host Host Different IP address of router Router Host Same Same as destination IP address in IP packet Router Host Different IP address of router"},{"location":"3_Core/Computer_Networks/10_Network_Layer/","title":"10 Network Layer","text":""},{"location":"3_Core/Computer_Networks/10_Network_Layer/#summary","title":"Summary","text":""},{"location":"3_Core/Computer_Networks/10_Network_Layer/#network-layer-source","title":"Network Layer @ Source","text":""},{"location":"3_Core/Computer_Networks/10_Network_Layer/#network-layer-router","title":"Network Layer @ Router","text":""},{"location":"3_Core/Computer_Networks/10_Network_Layer/#network-layer-destination","title":"Network Layer @ Destination","text":""},{"location":"3_Core/Computer_Networks/10_Network_Layer/#packetization","title":"Packetization","text":"<p>Each packet contains a portion of user data plus some control info (routing info, etc)</p> <p>Size of packet determined by network and its governing protocol</p> <p>Packets are received, buffered (stored briefly), then and past on to the next node. This is called as \u2018Store-and-forward\u2019</p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#packet-switching-methods","title":"Packet-Switching Methods","text":"<p>Context already given in Introduction</p> Datagram Approach Virtual-Circuit Approach Connection Type Connection-less Connection-oriented Each packet contains Destination address Virtual-circuit ID(implemented in Data Link Layer) Efficiency Better than circuit switched network(channel is always occupied) Delay &gt; Circuit Switching &amp; Virtual-Circuit Switch keeps info about connection state \u274c Each packet is treated independently dependently Path Each node chooses the next node Same path as previous packet of same packet stream(Node does not make any routing decision) Packets can take any possible route based on the link availability \u2705 \u274c Capacity Guaranteed \u2705 \u274c Packets always arrive in order \u274c \u2705(packets  may arrive with different delays  if resource allocation is on demand) Packets not lost \u274c(due to lack of resources; upper layers ask for retransmission) Re-order packets and recover from missing packets Receiver Example The Internet X.25, Frame Relay, ATM Routing Table Single Channel Multiple Channels Delays \\(3 T + 3 \\tau + w_1 + w_2\\) \\(\\text{delay}_\\text{tot} = \\text{delay}_\\text{trans} + \\text{delay}_\\text{prop} + \\text{setup delay} + \\text{teardown delay}\\)"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#ip-addressing","title":"IP Addressing","text":"<p>Each IP address is unique and only defines 1 connection to the Internet. Two devices on the internet can never have the same address at the same time. (referring to IP Public addresses)</p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#types-of-addresses","title":"Types of Addresses","text":"Network Address Host Address"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#types-of-addressing","title":"Types of Addressing","text":"Classful Classless Entire range of IP addresses is classified into different classesEach class is divided into a fixed number of blocks with fixed size Variable length blocks No of blocks must be power of 2 Beginning address must be divisible by no of addresses(If block has less than 256 addresses, we need to check only the rightmost byte)(If block has less than 65,536 addresses, we need to check only the two rightmost bytes, and so on.) Inflexible Inefficient(wasted IP addresses)"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#classful-addressing","title":"Classful Addressing","text":""},{"location":"3_Core/Computer_Networks/10_Network_Layer/#classes","title":"Classes","text":"A B C D E Network &amp; Host Part N.H.H.H N.N.H.H N.N.N.H -(Not for commercial use) -(Not for commercial use; only for experimentation) Starting bit(s) \\(0\\) \\(10\\) \\(110\\) \\(1110\\) \\(1111\\) Range Start \\(1.0.0.0\\) \\(128.0.0.0\\) \\(192.0.0.0\\) \\(224.0.0.0\\) \\(240.0.0.0\\) Range End \\(127.255.255.255\\) \\(191.255.255.255\\) \\(223.255.255.255\\) \\(239.255.255.255\\) \\(255.255.255.255\\) Casting Uni-Cast Uni-Cast Uni-Cast Multi-Cast Default Mask(number to AND IP address with to get netid) \\(255.0.0.0\\) \\(255.255.0.0\\) \\(255.255.255.0\\) No of Network Blocks \\(2^{8-1} - 1\\)(1 bit for class)(1 block for private address) \\(2^{16-2}-16\\)(2 bits for class)(16 blocks for private address) \\(2^{24-3}-256\\)(3 bits for class)(256 blocks for private address) 1 No of Hosts \\(2^{24} \\textcolor{hotpink}{-2}\\) \\(2^{16} \\textcolor{hotpink}{-2}\\) \\(2^{8} \\textcolor{hotpink}{-2}\\) Subnetting Possible? \u2705 \u2705 \u274c Supernetting Possible? \u274c \u274c \u2705 <ul> <li> <p>\\(\\textcolor{hotpink}{-2}\\) is because</p> </li> <li> <p>Network address: all host fields = 0</p> </li> <li>Network broadcast address: all host fields = 1</li> <li>\\(0.0.0.0 \\iff 0.255.255.255\\) is a special block not belonging to any class</li> <li>\\(127.0.0.0 \\iff 127.255.255.255\\) is a special block belonging to class A, but it is reserved for loopback(<code>localhost</code>): the computer to refer to itself</li> </ul> <p>The outside world recognizes the network via network address, not the individual host-IPs</p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#categories-of-addresses","title":"Categories of Addresses","text":"<p>Packet with loopback address does not leave the device (will not reach the network)</p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#private-addresses","title":"Private Addresses","text":"<p>Assigned for private use and not recognized globally, used in</p> <ul> <li>Isolation</li> <li>Connection with network address translation</li> </ul> <p></p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#modified-networks","title":"Modified Networks","text":"Subnetting Supernetting Split large network into smaller networks Combine smaller network into 1 larger network Subnet Address borrows bits from hostid netid Rules No of modified nets must be power of 2 No of modified nets must be power of 2 Blocks must be contiguous in address  space 3<sup>rd</sup> byte of first address in supernet must be evenly divisible by number of blocks of supernet"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#subnetting","title":"Subnetting","text":"<p>Network is divided into several smaller groups, with their own subnet address depending on the hierarchy of subnetting, but still appearing as a single network to the rest of the Internet</p> <p>Hierarchy changes from <code>netid:hostid</code> to <code>netid:subnetid:hostid</code></p> <p>Only the network administrator knows about the network address and subnet address but router does not</p> <p>2 routers</p> <ul> <li>External router has routing table based on network addresses</li> <li>Internal router has routing table based on subnetwork addresses.</li> </ul>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#classless-addressing","title":"Classless Addressing","text":""},{"location":"3_Core/Computer_Networks/10_Network_Layer/#slash-notation","title":"Slash Notation","text":"<p>Also called as CIDR (classless inter-domain routing) Notation</p> <p></p> <p>Where \\(n=\\) no of 1s in mask (starting from the left side)</p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#routing","title":"Routing","text":"<p>Determine the most optimal path for packet to take from source to destination</p> <p>Only possible to pick most optimality with global knowledge about network</p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#objective","title":"Objective","text":"<ul> <li>Minimize number of hops</li> <li>Minimize end-to-end delay</li> <li>Maximize available bandwidth</li> </ul>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#criteria-for-routing-algo","title":"Criteria for Routing Algo","text":"<ol> <li>Correctness: correct route and accurate delivery</li> <li>Robustness: adaptive to changes of network topology, in case of node/link failure &amp; varying traffic load</li> <li>Cleverness: ability to detour congestion links &amp; determine connectivity of network</li> <li>Efficiency: rapid finding of route &amp; minimization of control messages</li> </ol>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#classification-of-routing-algo","title":"Classification of Routing Algo","text":"Static Dynamic Compute route Manually Automatic When Prior During Based on TopologyLink Capacity Life of routing table entry Long Variable Change of routing table entry Fixed Variable Advantage Simple Adaptive Disadvantage Not scalableNot dynamicCannot react to n/w failures, traffic load changes, n/w size increase Complex Suitable for Small &amp; fixed topology networks"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#routing-table","title":"Routing Table","text":"<p>Store path information, so that each node knows how to forward packets</p> <p>Datagram approach &amp; Virtual Circuit method have different types. Refer Packet-Switching Methods for the diagram</p>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#routing-graph","title":"Routing Graph","text":"<p>Graphical representation of network with</p> <ul> <li>vertices: router nodes</li> <li>edges: links</li> <li>Cost: time delay, monetary cost, congestion level</li> </ul>"},{"location":"3_Core/Computer_Networks/10_Network_Layer/#routing-algorithms","title":"Routing Algorithms","text":"Flooding Shortest Path Routing Link State Routing(OSPF: Open Shortest Path First) Distance Vector Routing(RIP: Routing Information Protocol) Type Static Static Dynamic Dynamic Steps Packet sent by node to every neighborIncoming packets retransmitted on every link (except incoming link)Eventually \\(\\ge 1\\) copies arrive at destinatinEach packet is uniquely number, so duplicates are discardedNodes can remember packets already forwarded to keep network load in boundsCan include hop count in packets Solve single-source shortest path problem using Dijkstra\u2019s AlgoProduces \u201ctree\u201d of routes from source to all pointsConstruct forwarding table containing next hop Each router reliably floods information about its neighbors to every other routerEach router independently calculates the shortest path from itself to every other router, using Dijkstra\u2019s Algo Each router only knows links to neighbors; does not flood entire networkEach router has provisional shortest path (reach B with cost 11 via next hop router D)Routers exchange this information only with neighborsUpdate best path using info from neighborsBellman-Ford Algo Advantages No network info requiredRobust: All possible routes are triedCan be used for virtual circuit: At least one packet will have taken minimum hop count routeAll nodes are visited: Useful to distribute information Diagram Works well for Large networks Smaller networksMax hop limit of 15"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/","title":"11 IP Protocol","text":"<p>Inter-Networking Protocol</p> <p>Responsible for node-to-node transmission</p> <p>Unreliable: Packets might be lost, corrupted, duplicated, or delivered out of order</p>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#ipv4-packet-format","title":"IPv4 Packet Format","text":"Meaning Size (bits) Value Vers Version of IP protocol 4 Hlen Header length w/o options 4 Hlen=5 : 20bytesHlen=15: 60bytes TOS Type Of Service(Used for QoS priority) 8 Total Length Length of packet in bytes, including header &amp; payload 16 TTL Time To LiveSpecified how long packet is allowed to remain on InternetPrevents infinite loopsRouters decrement by 1When TTL=0, router discards datagram 8 Protocol Specifies format of payloadIdentify Transport Layer protocol used (TCP/UDP) 8 TCP=6UDP=17ICMP=1IGMP=2(administered by central authority to guarantee agreement) Source IP address 32 Dest IP address 32 Options Mainly used to record a router, timestamps, or specify routing Variable Header Checksum Error control Identification Copied into fragment, allows dest to know which fragments belong to which packet 16 Fragmentation Offset Specifies offset in original packet of data being carried in current fragment 13 Multiple of 8 bytes Flags Control fragmentation 3 - Reserved: 0<sup>th</sup> bit- Don\u2019t fragment: (1<sup>st</sup> bit)   - D=1 Don\u2019t fragment   - D=0 Can fragment- More fragments (LSB)   - M=1: More fragments incoming  - M=0: This is last fragment of packet"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#ip-fragmentation","title":"IP Fragmentation","text":"<p>Every network has its own MTU (Maximum Transmission Unit). This is the largest size of packet that can be put on the network.</p> <p>For eg, Ethernet is 1500 Bytes</p> <p>What makes fragmentation tricky is that we don\u2019t know the MTU of all networks in advance</p>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#reassembly","title":"Reassembly","text":"End Nodes Better Avoids unnecessary workIf any fragment is missing, discard entire packet Intermediate Nodes Dangerous Hard to determine how much buffer space required by routersUnreliable when routes in network changes <p>Final destination host reusables original packet from fragments (if none of them are lost) with the following steps</p> <ol> <li>Check if first fragment has offset field = 0</li> <li>Divide length of first fragment by 8; this value should be equal to offset of 2<sup>nd</sup> fragment</li> <li>Divide the total length of the first and second fragment by 8; this value should be equal to offset of 3<sup>rd</sup> fragment</li> <li>Continue process, until fragment with more bit value = 0 is reached</li> </ol> <p></p> <p></p>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#fragmentation-types","title":"Fragmentation Types","text":"<p>IP protocol uses non-transparent fragmentation</p> Transparent Fragmentation Non-Transparent Fragmentation Steps - Router breaks large packet into fragments- All fragments sent to same exit router- Reassemble fragments before forwarding to next network - Router breaks large packet into fragments- Packet fragments not reassembled at intermediate routers- Each fragment is treated as independent packet by routers- Fragments reassembled at final destination host Advantages Multiple exit routers can be usedHigher throughput Disadvantages All packets must be routed via same exit routerExit router must know when all pieces have been receivedEither \u2018count\u2019 field or \u2018end of packet\u2019 field must be stored in each packetLarge overhead: Large packet may fragmented &amp; reassembled repeatedly When a large packet is fragmented, overhead increasesEach fragment must have a header (min 20 bytes)"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#ipv6","title":"IPv6","text":"<p>(Version 5 was allocated to experimental Internet Stream Protocol)</p> <p>IPv6 has 128 bits, represented as 8 groups of 4 hex digits each</p> <p>Eg: \\(FEDC:BA98:7654:3210:FEDC:BA98:7664:3210\\)</p>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#goals","title":"Goals","text":"<ul> <li>Providing improved security. </li> <li>Authentication Header</li> <li>Encrypted Security Payload Header.</li> <li>Reduction in size of Routing Tables</li> <li>Providing for a single, unique address assignment to mobile hosts.</li> <li>Providing support for new as well as older versions of the IP</li> </ul>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#benefits","title":"Benefits","text":"<ul> <li>Increases address space</li> <li>Efficient addressing &amp; routing topology</li> <li>Network address is not required (restores end-to-end IP addressing)</li> </ul>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#packet","title":"Packet","text":""},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#base-header","title":"Base Header","text":""},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#mobile-ip","title":"Mobile IP","text":"<p>Addressing is the main problem in mobile communication</p> <p>Regular IP addressing is based on the assumption that a host is stationary</p> <ul> <li>Routers use hierarchical structure of IP address to route packet</li> <li>Address is valid only when devices attached to network; if network changes, address is no longer valid</li> </ul> <p>When a host moves from one network to another, IP addressing structure needs to be modified</p> <p></p> <p></p> <p>There are 3 options to deal with device changing networks</p>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#change-the-address","title":"Change the address","text":"<ul> <li>DHCP Protocol</li> <li>Limitations</li> <li>Configuration files need to be changed</li> <li>Each time computer moves from one network to another, it must be rebooted</li> <li>DNS tables need to be revised so that every other host in the Internet is aware of change</li> <li>If host roams from one network to another during transmission, data exchange will be interruted<ul> <li>Since port &amp; IP address of client &amp; server must remain constant for duration of connection</li> </ul> </li> </ul>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#combination-of-2-addresses-to-identify-device","title":"Combination of 2 addresses to identify device","text":"<p>Host has</p> <ul> <li>Home address: original address</li> <li>Care-of-address: temporary address   (Associate host with foreign network)</li> <li>When host moves from one network to another, care-of-address changes</li> <li>Mobile host receives its care-of-address during agent-discovery &amp; registration</li> </ul> <p></p>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#agent-discovery","title":"Agent Discovery","text":"<ol> <li>Home Agent\u2019s and Foreign Agent\u2019s broadcast their presence on each network to which they are attached; Beacon messages via ICMP Router Discovery Protocol (IRDP)</li> <li>Mobile Node\u2019s listen for advertisement and then initiate registration</li> </ol> <p>Thus,</p> <ul> <li>Foreign Agent is now aware of mobile</li> <li>Home Agent knows location of mobile</li> </ul>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#registration","title":"Registration","text":"<ol> <li>When Mobile Node is away, it registers its COA with its Home Agent, usually through Foreign Agent with strongest signal</li> <li>Registration control messages are sent via UDP to well-known port</li> </ol>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#tables-maintained","title":"Tables Maintained","text":""},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#mobility-binding-table","title":"Mobility Binding Table","text":"<p>Maintained on Home Agent</p> <p>Maps Mobile Node\u2019s home address with its current care-of-address</p> Home Address Care-Of-Address Lifetime (sec)"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#visitor-list","title":"Visitor List","text":"<p>Maintained on Foreign Agent serving the Mobile Node</p> <p>Maps Mobile Nodes\u2019s home address to its MAC address &amp; Home Address</p> Home Address Home Agent Address Media Address Lifetime (sec)"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#indirect-triangle-routing","title":"Indirect (Triangle) Routing","text":"<p>Mobile Node uses 2 addresses</p> <ul> <li>Home address, used by correspondent (mobile location is transparent to correspondent)</li> <li>Care of Address, used by Home Agent to forward packets to mobile</li> </ul> <p>Foreign agent functions may be done by mobile itself</p> <p></p>"},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#data-transfer-tunnelling","title":"Data Transfer Tunnelling","text":""},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#problems-with-mobile-ip","title":"Problems with Mobile IP","text":""},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#double-crossing","title":"Double Crossing","text":""},{"location":"3_Core/Computer_Networks/11_IP_Protocol/#triangle-routing","title":"Triangle routing","text":"<p>Packet travel as two sides of triangle</p> <p></p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/","title":"12 Transport Layer","text":"<p>Transport Protocols run on end-devices</p> TCP UDP Connection setupCongestion ControlFlow Control No-frills extension of best-effort IPDelay guaranteesBandwidth guarantees"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#port-addressing","title":"Port Addressing","text":"<p>\\([0, 65535]\\)</p> <ul> <li> <p>Ephemeral (short-lived) port number</p> <ul> <li>\\(\\ge 1,023\\)</li> <li>used for client</li> </ul> </li> <li> <p>Well-known port number</p> <ul> <li>Universal port numbers</li> <li>used for servers</li> </ul> </li> </ul> <p></p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#icann","title":"ICANN","text":"<p>Internet Corporation for Assigned Names and Numbers (ICANN) Ranges</p> <p></p> <ul> <li>Well-known ports : 0 ~ 1,023<ul> <li>Assigned and controlled by ICANN</li> </ul> </li> <li>Registered ports : 1,024 ~ 49,151<ul> <li>Not assigned and controlled by ICANN</li> </ul> </li> <li>Can be registered with ICANN to prevent duplication</li> <li>Dynamic ports : 49,152 ~ 65,535<ul> <li>Can be used as temporary or private port number</li> </ul> </li> </ul>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#socket-address","title":"Socket Address","text":"<p>Combination of IP &amp; Port address</p> <p>Eg: \\(200.23.56.8:69\\)</p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#mux-demux","title":"Mux &amp; Demux","text":"Multiplexing Demultiplexing Entity accepts items from  more than one source Entity deliver items to more  than one source"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#delivery","title":"Delivery","text":"<p>Delivery of items from a producer to a consumer</p> <pre><code>- Pushing : sender delivers items whenever they produced\n- Pulling : producer delivers the items after the consumer has requested\n</code></pre> <p></p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#flow-control","title":"Flow Control","text":"<p>Balance between production and consumption rates</p> <p>A buffer is a set of memory locations that can hold packets at the sender and receiver</p> <p>Normally we use two buffers for flow control</p> <ol> <li>at sending transport layer</li> <li>at receiving transport layer</li> </ol> <p></p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#error-control","title":"Error Control","text":"<ol> <li>Detect and discard corrupted segments</li> <li>Keep track of lost and discarded segments and resend them</li> <li>Recognize duplicate segments and discard them</li> <li>Buffer out-of-order segments until the missing segments arrive</li> </ol>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#sequence-number","title":"Sequence Number","text":"<p>Each segment to holds a sequence number</p> <p>Sequence Number helps decide </p> <ul> <li>Which packet is to be resent</li> <li>Which packet is a duplicate</li> <li>Which packet has arrived out of order</li> </ul> <p>Sequence numbers can be repeated</p> <ul> <li>\\(0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, \\dots\\)</li> </ul>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#sequence-number-limit","title":"Sequence Number Limit","text":"<p>If the header of the frame allows \\(m\\) bits for sequence number, the sequence numbers range from \\(0 \\iff 2m \u2013 1\\)</p> <p>The values are modulo \\(2^m\\)</p> \\[ \\text{Final seq no} = \\text{Actual Seq Number } \\% \\ 2^m \\] <p>For m = 3, sequence numbers are: 0, 1, 2, 3, 4, 5, 6, 7.</p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#acknowledgement","title":"Acknowledgement","text":"<p>The receiver side can send an acknowledgement for each or a collection of segments that have been received correctly</p> <p>There can be +ve and -ve ack</p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#combination-of-flow-error-control","title":"Combination of Flow &amp; Error Control","text":"<p>Flow control requires the use of two buffers, one at the sender site and the other at the receiver site. </p> <p>The error control requires the use of sequence and acknowledgment numbers by both sides. </p> <p>These two requirements can be combined by using two numbered buffers, one at the sender, one at the receiver</p>"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#sliding-window","title":"Sliding Window","text":"Linear Format Circular Format"},{"location":"3_Core/Computer_Networks/12_Transport_Layer/#incomplete","title":"Incomplete","text":"<p>Some contributor, please complete using the ppt below</p>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/","title":"13 Application Layer","text":"<p>Applications are the entities that communicate with each other to exchange services</p> <p>To make any use of the Internet, application programs should run on the two endpoints of a network connection</p> <ul> <li>\u201cClient\u201d applications request service</li> <li>\u201cServer\u201d applications provide service</li> </ul> <p>A socket is one end of an inter-process communication channel.</p>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#client-server-model","title":"Client Server Model","text":"<p>Many-to-One</p> <p></p> Server Client Run all the time (i.e. infinite)Provide service to any clientUsually specialize in providing certain type of service, e.g. MailListen to a well-known port and passively open connection. Run when needed, then terminate (i.e. finite)Actively open TCP or UDP connection with Server\u2019s socket <ul> <li>Client needs to know existence &amp; address of server </li> <li>However, the server does not need to know the existence or address of the client prior to the connection</li> <li>Once a connection is established, both sides can send and receive information</li> </ul>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#connection-establishment","title":"Connection Establishment","text":"<ul> <li>Both client and server will construct a socket</li> <li>The process to establish a socket on the client side is different from the process to establish a socket on the server side</li> </ul>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#p2p-peer-to-peer-model","title":"P2P (Peer-to-Peer) Model","text":"<p>Every node in the network acts alike</p> <p></p>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#advantages","title":"Advantages","text":"<ul> <li>No central point of failure</li> <li> <p>Scalability</p> </li> <li> <p>Since every peer is alike, it is possible to add more peers to the system and scale to larger networks</p> </li> </ul>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#disadvantages","title":"Disadvantages","text":"<ul> <li>Decentralized coordination; How to keep global state consistent?</li> <li> <p>All nodes may not be equal</p> </li> <li> <p>Computing power</p> </li> <li>Bandwidth</li> </ul>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#http","title":"HTTP","text":"<p>HyperText Transfer Protocol</p> <ul> <li>HTTP 1.0: RFC 1945</li> <li>HTTP 1.1: RFC 2068 (persistent TCP)</li> </ul> <p>Used for Client-Server model</p> <ul> <li>Client: Browser request &amp; receive Web objects</li> <li>Server: Web server sends objects in response to requests</li> </ul>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#properties","title":"Properties","text":"<ul> <li>Uses TCP</li> <li></li> <li>\u201cStateless\u201d</li> <li>A \u2018state\u2019 is information kept in memory     of a host, server or router to reflect     past events: such as routing tables,     data structures or database entries</li> <li>HTTP server maintains no information about past client requests</li> <li>Protocols that maintain \u201cstate\u201d are complex!<ul> <li>history (state) is maintained</li> <li>if server/client crashes, views of \u201cstate\u201d may be inconsistent, must be reconciled</li> <li>state is added via \u2018cookies\u2019</li> </ul> </li> </ul>"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#steps","title":"Steps","text":""},{"location":"3_Core/Computer_Networks/13_Application_Layer/#types","title":"Types","text":"Non-Persistent HTTP Persistent HTTP without Pipelining Persistent HTTP with Pipelining Max no of objects sent over TCP connection 1 Multiple Multiple Used in HTTP Version HTTP/1.0 HTTP/1.1 Categories Steps Server leaves connection open after sending responseSubsequent HTTP messages  between same client/server sent over open connectionClient issues new request only when previous response has been receivedOne RTT for each referenced object Server leaves connection open after sending responseSubsequent HTTP messages  between same client/server sent over open connectionClient sends requests as soon as it encounters a referenced object1 RTT for all referenced objects Total Response Time(\\(n =\\) no of objects) \\(n (2 \\ \\text{RTT} + \\text{Transmit Time})\\)- one RTT to initiate TCP connection- one RTT for HTTP request &amp; first few bytes of HTTP response to return- file transmission time \\(n (1 \\ \\text{RTT} + \\text{Transmit Time})\\) \\(1 \\ \\text{RTT} + n(\\text{Transmit Time})\\) Disadvantages - requires 2 RTTs per object- OS overhead for each TCP connection- browsers often open parallel TCP connections to fetch referenced object Non-Persistent &amp; Non-Parallel Non-Persistent &amp; Parallel"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#http-messages","title":"HTTP Messages","text":"HTTP Request HTTP Response Format Example"},{"location":"3_Core/Computer_Networks/13_Application_Layer/#headers","title":"Headers","text":""},{"location":"3_Core/Computer_Networks/13_Application_Layer/#responses","title":"Responses","text":""},{"location":"3_Core/Computer_Networks/13_Application_Layer/#http-methods","title":"HTTP Methods","text":""},{"location":"3_Core/Computer_Networks/14_WiFi/","title":"WiFi Bands","text":"2.4GHz 5GHz Slower Faster Term Meaning SSID Service Set IDentifier RSSI Received Signal Strength Indicator Less negative, the better"},{"location":"3_Core/Computer_Networks/Practicals/","title":"Index","text":""},{"location":"3_Core/Computer_Networks/Practicals/#tools","title":"Tools","text":"<ul> <li>Java</li> <li>Wireshark</li> <li></li> </ul>"},{"location":"3_Core/Computer_Networks/Practicals/01_Network_Commands/","title":"01 Network Commands","text":"Command Usage Displays Full Form UnixAlternative <code>getmac</code> <code>getmac</code> Get mac address of current machine <code>ipconfig</code> <code>ipconfig</code> <code>ipconfig</code> computer\u2019s IP details <code>ping</code> <code>ping www.google.ae</code> Check validity of connection between 2 machinesSends 4 packets to the other machine and checks how many of those packets reachedRount-trip timeTime to live <code>netstat</code> <code>netstat</code><code>netstat -r</code> Connection informationRouting table Network Statistics <code>route</code> <code>route</code> Routing table <code>netstat -nr</code> <code>arp</code> <code>arp -a</code> ARP cache of current machine Address Resolution Protocol <code>hostname</code> <code>hostname</code> Gives the machine name <code>nslookup</code> <code>nslookup</code><code>nslookup www.google.ae</code> Look and diagnose the DNS of a location Name System <code>tracert</code> <code>tracert www.google.ae</code> Shows the RTT from source and destination node, and also all the intermediary nodes Trace Root <code>traceroute</code> <code>pathping</code> <code>pathping www.google.ae</code> Combination of <code>ping</code> and <code>tracert</code>"},{"location":"3_Core/Computer_Networks/Practicals/02_03_CISCO_Packet_Tracer/","title":"02 03 CISCO Packet Tracer","text":"<p>This is pretty simple, actually</p> <ol> <li>Add end devices</li> <li>Add network devices</li> <li>Add connecting wires</li> <li>Configure IP address</li> <li>Configure Routing</li> <li>Static</li> <li>Dynamic</li> </ol>"},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/","title":"04 05 UniThreaded TCP","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#simple-example","title":"Simple Example","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#serverjava","title":"<code>Server.java</code>","text":"<pre><code>import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Server extends Thread {\n  private ServerSocket server_socket;\n\n  public Server(int port_no) throws IOException {\n    while (true) {\n      try {\n        server_socket = new ServerSocket(port_no);\n\n        System.out.println(\"Waiting for client to connect\");\n\n        Socket server = server_socket.accept();\n        System.out.println(\"Connected to client\");\n\n        DataOutputStream out = new DataOutputStream(server.getOutputStream());\n        String server_message = \"Hi there! Enter something\";\n        out.writeUTF(server_message);\n\n        DataInputStream in = new DataInputStream(server.getInputStream());\n        String client_reply = in.readUTF();\n        System.out.println(\"User replied with: \" + client_reply);\n        server.close();\n      } catch (Exception e) {\n        e.printStackTrace();\n      }\n    }\n  }\n\n  public static void main(String[] args) throws IOException {\n    Thread t1 = new Server(5000);\n    t1.start();\n  }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#clientjava","title":"<code>Client.java</code>","text":"<pre><code>import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Client\n{\n  public Client(String host, int port) throws IOException\n  {\n    try\n    {\n      Socket client = new Socket(host, port);\n\n      System.out.println(\"Connected to server\");\n\n      DataInputStream in = new DataInputStream(client.getInputStream());\n\n      String server_message = in.readUTF();\n      System.out.println(server_message);\n\n      DataOutputStream out = new DataOutputStream(client.getOutputStream());\n\n      Scanner user_in = new Scanner(System.in);\n      String client_reply = user_in.next();\n      out.writeUTF(client_reply);\n\n      user_in.close();\n      client.close();\n    } catch (Exception e)\n    {\n      e.printStackTrace();\n    }\n  }\n  public static void main(String[] args) throws IOException\n  {\n    new Client(\"localhost\", 5000);\n  }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#execution-commands","title":"Execution Commands","text":"<pre><code>javac Server.java\njava Server\n\njavac Client.java\njava Client\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#output","title":"Output","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#server","title":"Server","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#client","title":"Client","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#calculator","title":"Calculator","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#serverjava_1","title":"<code>Server.java</code>","text":"<pre><code>import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Server extends Thread {\n    private ServerSocket server_socket;\n\n    public Server(int port_no) throws IOException {\n        while (true) {\n            try {\n                server_socket = new ServerSocket(port_no);\n\n                System.out.println(\"Waiting for client to connect\");\n\n                Socket server = server_socket.accept();\n                System.out.println(\"Connected to client\");\n\n                DataOutputStream out = new DataOutputStream(server.getOutputStream());\n                String server_message = \"Hi there! Enter something\";\n                out.writeUTF(server_message);\n\n                DataInputStream in = new DataInputStream(server.getInputStream());\n\n                int num1 = Integer.parseInt(in.readUTF());\n                String op = in.readUTF();\n                int num2 = Integer.parseInt(in.readUTF());\n\n                String client_reply = \"Received: \" + num1 + op + num2;\n                System.out.println(client_reply);\n\n                int result = 0;\n\n                switch(op)\n                {\n                    case \"+\": {result = num1 + num2; break;}\n                    case \"-\": {result = num1 - num2; break;}\n                    case \"*\": {result = num1 * num2; break;}\n                    case \"/\": {result = num1 / num2; break;}\n                    case \"^\": {result = num1 ^ num2; break;}\n                    default: {System.out.println(\"Invalid Operator\");}\n                }\n\n                out.writeUTF(Integer.toString(result));\n\n                server.close();\n            } catch (Exception e) {\n        e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) throws IOException {\n        Thread t1 = new Server(args[0]);\n        t1.start();\n    }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#clientjava_1","title":"<code>Client.java</code>","text":"<pre><code>import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Client {\n    public Client(String host, int port) throws IOException\n  {\n    try\n    {\n      Socket client = new Socket(host, port);\n\n      System.out.println(\"Connected to server\");\n\n      DataInputStream in = new DataInputStream(client.getInputStream());\n\n      String server_message = in.readUTF();\n      System.out.println(server_message);\n\n      DataOutputStream out = new DataOutputStream(client.getOutputStream());\n\n      Scanner user_in = new Scanner(System.in);\n\n      int num1 = user_in.nextInt();\n      String op = user_in.next();\n      int num2 = user_in.nextInt();\n\n      out.writeUTF(Integer.toString(num1));\n      out.writeUTF(op);\n      out.writeUTF(Integer.toString(num2));\n\n\n      String result = in.readUTF();\n      System.out.println(result);\n\n      user_in.close();\n      client.close();\n    } catch (Exception e)\n    {\n      e.printStackTrace();\n    }\n  }\n\n    public static void main(String[] args) throws IOException {\n        new Client(args[0], args[1]);\n    }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#execution-commands_1","title":"Execution Commands","text":"<pre><code>javac Server.java\njava Server 5000\n\njavac Client.java\njava Client localhost 5000\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#output_1","title":"Output","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#server_1","title":"Server","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#client_1","title":"Client","text":""},{"location":"3_Core/Computer_Networks/Practicals/04_05_UniThreaded_TCP/#working-with-telnet","title":"Working with Telnet","text":"<ol> <li>no need to implement your own client</li> <li>change server\u2019s parameters as command-line arguments (using <code>args[0], ...</code>)</li> <li>Need to use <code>BufferedReader</code> and <code>PrintWriter</code> as the encoding used Telnet is different</li> </ol> <pre><code>import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Server extends Thread {\n  private ServerSocket server_socket;\n\n  public Server(int port_no) throws IOException {\n    while (true) {\n      try {\n        server_socket = new ServerSocket(port_no);\n\n        System.out.println(\"Waiting for client to connect\");\n\n        Socket server = server_socket.accept();\n        System.out.println(\"Connected to client\");\n\n        PrintWriter out = new PrintWriter(server.getOutputStream());\n        String server_message = \"Hi there! Enter something\";\n        out.print(server_message);\n\n        BufferedReader in = new BufferedReader(new InputStreamReader(\n            server.getInputStream()\n        ));\n        String client_reply = in.readLine();\n\n        System.out.println(\"User replied with: \" + client_reply);\n        server.close();\n      } catch (Exception e) {\n        e.printStackTrace();\n      }\n    }\n  }\n\n  public static void main(String[] args) throws IOException {\n    Thread t1 = new Server(5000);\n    t1.start();\n  }\n}\n</code></pre> <pre><code>javac Server.java\njava Server 5000\ntelnet localhost 5000\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/06_Multithreaded_TCP/","title":"06 Multithreaded TCP","text":""},{"location":"3_Core/Computer_Networks/Practicals/06_Multithreaded_TCP/#serverjava","title":"<code>Server.java</code>","text":"<pre><code>// import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Server {\n    private ServerSocket server_socket;\n\n    public Server(int port_no) throws IOException {\n        server_socket = new ServerSocket(port_no);\n\n        System.out.println(\"Waiting for client to connect\");\n\n        while (true) {\n            try {\n                Socket connection = server_socket.accept();\n                System.out.println(\"Connected to client\");\n\n                ClientHandler client_handler = new ClientHandler(connection);\n                client_handler.start();\n            } catch (Exception e) {\n        e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) throws IOException {\n        new Server(5000);\n    }\n}\n\nclass ClientHandler extends Thread {\n\n    public ClientHandler(Socket connection) throws IOException {\n        try {\n            DataOutputStream out = new DataOutputStream(connection.getOutputStream());\n            String server_message = \"Hi there! Enter something\";\n            out.writeUTF(server_message);\n\n            DataInputStream in = new DataInputStream(connection.getInputStream());\n\n            int num1 = Integer.parseInt(in.readUTF());\n            String op = in.readUTF();\n            int num2 = Integer.parseInt(in.readUTF());\n\n            String client_reply = \"Received: \" + num1 + op + num2;\n            System.out.println(client_reply);\n\n            int result = 0;\n\n            switch (op) {\n                case \"+\": {\n                    result = num1 + num2;\n                    break;\n                }\n                case \"-\": {\n                    result = num1 - num2;\n                    break;\n                }\n                case \"*\": {\n                    result = num1 * num2;\n                    break;\n                }\n                case \"/\": {\n                    result = num1 / num2;\n                    break;\n                }\n                case \"^\": {\n                    result = num1 ^ num2;\n                    break;\n                }\n                default: {\n                    System.out.println(\"Invalid Operator\");\n                }\n            }\n\n            out.writeUTF(Integer.toString(result));\n\n            in.close();\n            out.close();\n            connection.close();\n\n        } catch (Exception e) {\n      e.printStackTrace();\n        }\n    }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/06_Multithreaded_TCP/#clientjava","title":"<code>Client.java</code>","text":"<pre><code>import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Client {\n    public Client(String host, int port) throws IOException\n  {\n    try\n    {\n      Socket client = new Socket(host, port);\n\n      System.out.println(\"Connected to server\");\n\n      DataInputStream in = new DataInputStream(client.getInputStream());\n\n      String server_message = in.readUTF();\n      System.out.println(server_message);\n\n      DataOutputStream out = new DataOutputStream(client.getOutputStream());\n\n      Scanner user_in = new Scanner(System.in);\n\n      int num1 = user_in.nextInt();\n      String op = user_in.next();\n      int num2 = user_in.nextInt();\n\n      out.writeUTF(Integer.toString(num1));\n      out.writeUTF(op);\n      out.writeUTF(Integer.toString(num2));\n\n\n      String result = in.readUTF();\n      System.out.println(result);\n\n      user_in.close();\n      client.close();\n    } catch (Exception e)\n    {\n      e.printStackTrace();\n    }\n  }\n\n    public static void main(String[] args) throws IOException {\n        new Client(\"localhost\", 5000);\n    }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/07_HTTP/","title":"07 HTTP","text":""},{"location":"3_Core/Computer_Networks/Practicals/07_HTTP/#initial-steps","title":"Initial Steps","text":"<ol> <li>Go to Windows Features</li> <li>Turn on <code>Internet Information Services</code></li> <li>Host the web page</li> <li>Go to <code>Windows (C:)&gt;inetpub&gt;wwwroot</code></li> <li>Add a file called <code>index.html</code></li> <li> <p>Type your html code</p> </li> <li> <p>Perform Execution</p> </li> </ol>"},{"location":"3_Core/Computer_Networks/Practicals/07_HTTP/#clientjava","title":"<code>Client.java</code>","text":"<pre><code>import java.util.*;\nimport java.io.*;\nimport java.net.*;\n\npublic class Client\n{\n    public static void main(String[] args) throws IOException\n    {\n        String server = args[0];\n        int port = Integer.parseInt(args[1]);\n\n        try\n        {\n            Socket socket = new Socket(server, port);\n\n            DataOutputStream request = new DataOutputStream(socket.getOutputStream());\n            request.writeUTF(\"\\n\");\n\n            DataInputStream response = new DataInputStream(socket.getInputStream());\n\n            String response_text = response.readUTF();\n            while(response_text != null)\n            {\n                System.out.println(response_text);\n                response_text = response.readUTF();\n            }\n\n            request.close();\n            response.close();\n            socket.close();\n        } catch (Exception e)\n        {\n            e.printStackTrace();\n        }\n    }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/07_HTTP/#execution","title":"Execution","text":"<pre><code>javac Client.java\njava Client localhost /\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/08_UDP/","title":"08 UDP","text":"<p>This is not required for evaluation.</p>"},{"location":"3_Core/Computer_Networks/Practicals/08_UDP/#baseserverjava","title":"<code>BaseServer.java</code>","text":"<pre><code>import java.io.*;\nimport java.net.*;\n\npublic class udpBaseServer\n{\n  public static void main(String[] args) throws IOException\n  {\n    // Step 1 : Create a socket to listen at port 1234\n    DatagramSocket ds = new DatagramSocket(1234);\n    byte[] receive = new byte[65535];\n\n    DatagramPacket DpReceive = null;\n    while (true)\n    {\n\n      // Step 2 : create a DatgramPacket to receive the data.\n      DpReceive = new DatagramPacket(receive, receive.length);\n\n      // Step 3 : revieve the data in byte buffer.\n      ds.receive(DpReceive);\n\n      System.out.println(\"Client:-\" + data(receive));\n\n      // Exit the server if the client sends \"bye\"\n      if (data(receive).toString().equals(\"bye\"))\n      {\n        System.out.println(\"Client sent bye.....EXITING\");\n        break;\n      }\n\n      // Clear the buffer after every message.\n      receive = new byte[65535];\n    }\n  }\n\n  // A utility method to convert the byte array data into a string representation.\n  public static StringBuilder data(byte[] a)\n  {\n    if (a == null)\n      return null;\n    StringBuilder ret = new StringBuilder();\n    int i = 0;\n    while (a[i] != 0)\n    {\n      ret.append((char) a[i]);\n      i++;\n    }\n    return ret;\n  }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/08_UDP/#baseclientjava","title":"<code>BaseClient.java</code>","text":"<pre><code>import java.io.*;\nimport java.net.*;\nimport java.util.*;\n\npublic class BaseClient\n{\n  public static void main(String args[]) throws IOException\n  {\n    Scanner sc = new Scanner(System.in);\n\n    // Step 1:Create the socket object for carrying the data.\n    DatagramSocket ds = new DatagramSocket();\n\n    InetAddress ip = InetAddress.getLocalHost();\n    byte buf[] = null;\n\n    // loop while user not enters \"bye\"\n    while (true)\n    {\n      String inp = sc.nextLine();\n\n      // convert the String input into the byte array.\n      buf = inp.getBytes();\n\n      // Step 2 : Create the datagramPacket for sending the data.\n      DatagramPacket DpSend = new DatagramPacket(buf, buf.length, ip, 1234);\n\n      // Step 3 : invoke the send call to actually send the data.\n      ds.send(DpSend);\n\n      // break the loop if user enters \"bye\"\n      if (inp.equals(\"bye\"))\n        break;\n    }\n  }\n}\n</code></pre>"},{"location":"3_Core/Computer_Networks/Practicals/09_Wireshark/","title":"09 Wireshark","text":"<p>Packet Analyzer</p>"},{"location":"3_Core/Computer_Networks/Practicals/09_Wireshark/#steps","title":"Steps","text":"<ol> <li>Select the network</li> <li>Click capture packets</li> <li>Make a request on your browser</li> <li>Stop capture</li> <li>Filter by <code>http</code></li> <li>Analyze each packet\u2019s 5 layers\u2019</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/","title":"Design &amp; Analysis of Algorithms","text":"<p>Taught by Dr. Siddhaling</p> <p>Make sure to first read Introduction to Algorithms</p> <p>Whatever code/algorithm/complexity is missing, refer DSA Notes</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/","title":"01 Divide & Conquer","text":"<ol> <li>Divide problem into 2/more smaller sub-problems (Divide)</li> <li>Solve sub-problems recursively</li> <li>Obtain sol to original problem by combining sub-solutions (Conquer)</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/#general-form","title":"General Form","text":"<pre><code>Algorithm divide_and_conquer(a, p, r)\n{\n    if(p&lt;r)\n    {\n        part1 = divide_and_conquer(a, p, q_1)\n        part2 = divide_and_conquer(a, q1 + 1, q2)\n        ...\n        partn = divide_and_conquer(a, qn + 1, r)\n\n        return combine(part1, part2, ..., partn)\n    }\n    else\n    {\n        return solution\n    }\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/#algorithms","title":"Algorithms","text":"\\(T(n)\\) \\(O()\\) Binary Search \\(1 \\cdot T(n/2) + 1\\) \\(O(\\log n)\\) Min-Max Algorithm \\(2 \\cdot T(n/2) + 1\\) \\(O(n)\\) Merge Sort \\(2 \\cdot T(n/2) + n\\) \\(O(n \\log n)\\) Quick Select Quick Sort \\(2 \\cdot T(n/2) + n\\)\\(T(n-1) + n\\) \\(O(n \\log n)\\)Worst-Case \\(O(n^2)\\) \\(n!\\) \\(T(n-1) + 1\\) Tower of Hanoi \\(2 T(n-1) + 1\\) Example \\(3T(n/4) + n^2\\) <p>Derive the complexity for the above using</p> <ul> <li>Substitution method</li> <li>Recursion tree</li> <li>Master\u2019s Theorem</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/#min-max","title":"Min-Max","text":"<pre><code>Algorithm min(a, p, r)\n{\n  if (p&lt;r)\n  {\n    q = (p+r)/2;\n\n    min1 = min(a, p, q);\n    min2 = min(a, q+1, r);\n\n    return argin(min1, min2);\n  }\n  else\n  {\n      return a[p];\n  }\n}\n\n// We could use brute-force method. It is O(n) as well, but it worse.\n\nAlgorithm min_max(a)\n{\n  min = max = a[0];\n\n  for i=1 to n\n    if a[i] &lt; min\n        min = a[i]\n    else if a[i] &gt; max\n        max = a[i]\n\n  return min\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/#quick-select","title":"Quick Select","text":"<p>The algorithm is quick select algorithm, based on the Quick-Sort algorithm.</p> <p>It returns \\(k^\\text{th}\\) smallest element in S</p> <pre><code>Select (k, S)\n{\n  pick pivot in S\n\n  partition S into L, E, Q such that:\n    max(L) &lt; pivot // L contains all elements smaller than pivot\n    E = {pivot}\n    pivot &lt; min(G) // G contains all elements greater than pivot\n\n  if k \u2264 length(L) // Searching for item \u2264 pivot.\n    return Select(k, L)\n  else if k \u2264 length(L) + length(E) // Found\n    return pivot\n  else  // Searching for item \u2265 pivot.\n    return Select(k - length(L) - length(E), G)\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/#time-complexity","title":"Time Complexity","text":"<ul> <li>Worst-Case \\(O(n^2)\\)</li> <li>Average-Case \\(O(n)\\)</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/#others","title":"Others","text":"<p>Refer DSA</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/01_Divide_%26_Conquer/#masters-theorem","title":"Master\u2019s Theorem","text":"<p>Consider a recurrence relation</p> \\[ T(n) = a T \\left( \\frac{n}{b} \\right) + n^d \\] \\(d \\ \\_\\_\\_ \\ \\log_b a\\) \\(T(n)\\) \\(&gt;\\) \\(n^d\\) \\(=\\) \\(n^d \\log n\\) \\(&lt;\\) \\(n^{\\log_b a}\\)"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/","title":"02 Greedy","text":"<p>A greedy algorithm solves problems by making the choice that appear to be the best at that particular moment.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#prims-algorithm","title":"Prim\u2019s Algorithm","text":"<p>Refer Discrete Structures</p> <ul> <li>With cost matrix \\(O(n^2)\\)</li> <li>With heaps \\(O\\Bigg( (n + |E|) \\log n \\Bigg)\\)</li> </ul> <p>I didn\u2019t understand the code implementation</p> <p></p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#knapsack-problem","title":"Knapsack Problem","text":"<p>There exists items, with each having</p> <ul> <li>profit \\(p_i\\)</li> <li>weight \\(w_i\\)</li> </ul> <p>There also exists a limit \\(m\\) which is the max weight you can pick</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#goal","title":"Goal","text":"<p>maximize profit \\(P\\), while adhering to the limit.</p> \\[ \\begin{aligned} \\text{max } P = &amp; \\sum p_i x_i \\\\ \\text{such that} &amp; \\sum w_i x_i \\le m \\end{aligned} \\]"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#steps","title":"Steps","text":"<ol> <li>Convert list of \\(p_i\\) and \\(w_i\\) into a new list of \\(p_i/w_i\\)</li> <li>Sort in descending order</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#algorithm","title":"Algorithm","text":"<pre><code>// this is for x_i = 0 or 1 (binary)\n\nAlgorithm GreedyKnapsack(p, w, m, n)\n{\n    Input\n        - Profit array (sorted)\n        - Weights array (sorted)\n        - max capacity (knapsack size)\n        - no of objects\n\n    for i=1 to n\n        x[i] = 0\n\n    remaining_cap = m\n\n    for i=1 to n\n        if(w[i] &lt; remaining_cap)\n            x[i] = 1\n            remaining_cap -= w[i]\n        else\n            break\n\n    if (i&lt;=n)\n        x[i] = remaining_cap/w[i]\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#types","title":"Types","text":"Type Example 0/1(Discrete) An item can be- not taken- completely taken Phone Fractional(Continous) An item is can be- not taken- partially taken- completely taken Juice"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#tree-vertex-splitting","title":"Tree Vertex Splitting","text":"<p>Directed and weighted binary tree</p> <p>Nice video</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#steps_1","title":"Steps","text":"<ol> <li>Traverse from bottom</li> <li>Split a node from the tree if \\(d(u) &gt; \\delta\\)</li> <li>\\(d(u) = 0\\) for leaves</li> <li>\\(d(u) = \\underset{v \\in c(u)}{\\max} \\{ d(v) + w(u, v) \\}\\)</li> <li>Traverse upward</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#example-with-delta5","title":"Example with \\(\\delta=5\\)","text":"<pre><code>flowchart TB\n\nsubgraph After\ndirection TB\na1((1)) --&gt; a2((2i)) &amp; a3((3))\na2o((2o)) --&gt; a4i((4i))\na4o((4o)) --&gt; a7((7)) &amp; a8((8))\n\na3 --&gt; a5((5)) &amp; a6i((6i))\na6o((6o)) --&gt; a9((9)) &amp; a10((10))\nend\n\nsubgraph Before\ndirection TB\n1((1))\n2((2))\n3((3))\n4((4))\n5((5))\n6((6))\n7((7))\n8((8))\n9((9))\n10((10))\n\n1 --&gt;|4| 2\n2 --&gt; 0(( ))\n2 --&gt;|2| 4\n4 --&gt;|1| 7\n4 --&gt;|4| 8\n\n1 --&gt;|2| 3\n3 --&gt;|1| 5\n3 --&gt;|3| 6\n6 --&gt;|2| 9\n6 --&gt;|3| 10\nend</code></pre> <pre><code>Algorithm TVS(T, w, delta)\n{\n    if(T != 0)\n    {\n        d[T] = 0\n\n        for each child v of T\n        {\n            TVS(v, w, delta)\n            d[T] = argmax{d[T], d[v] + w(T, v)}\n        }\n\n        if(\n            T is not root\n            and\n            d[T] + w(parent(T), T) &gt; delta\n        )\n        {\n            write(T)\n            d[T] = 0\n        }\n    }\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#job-scheduling","title":"Job Scheduling","text":"<p>Similar to Knapsack problem</p> <p>There exists jobs, with each having</p> <ul> <li>profit \\(p_i\\)</li> <li>deadline \\(w_i\\)</li> </ul> <p>To complete each job, it only takes 1 unit of time</p> <p>Also</p> <ul> <li>it is not necessary to complete all jobs</li> <li>a job can only be taken once</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#goal_1","title":"Goal","text":"<p>maximize profit \\(P\\), while adhering to the limit. $$ \\begin{aligned} \\text{max } P = &amp;\\sum p_i x_i \\ \\text{such that } &amp; d_i \\text{ is not violated} \\end{aligned} $$</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#step","title":"Step","text":"<ol> <li>Sort the jobs in descending order based on profit</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/02_Greedy/#algorithm_1","title":"Algorithm","text":"<pre><code>Algo JS(arr, t):\n\n    // length of array\n    n = len(arr)\n\n        sort_desc(arr)\n\n    // To keep track of free time slots\n    result = [False] * t\n\n    // To store result (Sequence of jobs)\n    job = ['-1'] * t\n\n    // Iterate through all given jobs\n    for i in range(len(arr)):\n\n        // Find a free slot for this job\n        // (Note that we start from last possible slot)\n        for j in range(min(t-1, arr[i][1] - 1), -1, -1):\n            // Free slot found\n            if result[j] is False:\n                result[j] = True\n                job[j] = arr[i][0]\n                break\n\n    // print the sequence\n    print(job)\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/03_Dynamic_Programming/","title":"03 Dynamic Programming","text":"<p>Difference b/w divide &amp; conquer and dynamic programming is  - divide &amp; conquer combines the solutions of the subproblems to find solution of main problem - dynamic programming uses the result of the subproblems to find optimum solution of main problem</p> <p>Difference b/w greedy method and dynamic programming is</p> <ul> <li>greedy method first makes a choise that appears best at the time, and then solves a resulting subproblem</li> <li>dynamic programming solves all subproblems, and then selects one that helps to find the optimum solution</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/03_Dynamic_Programming/#principle-of-optimality","title":"Principle of Optimality","text":"<p>Optimal sequence of decisions has the property that whatever the initial state and decision are, the remaining decisions must constitute an optimal decision sequence with regard to the state resulting from the first decision.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/03_Dynamic_Programming/#all-pair-shortest-path","title":"All Pair Shortest Path","text":"\\[ \\begin{aligned} A^k(i, j) = \\text{argmin} &amp; \\{ \\\\ &amp; A^{k-1} (i, j), \\\\ &amp; A^{k-1} (i, k) + A^{k-1} (k, j) \\\\ &amp;\\} \\end{aligned} \\] <p>Try to find the path between pairs of points either directly/through another intermediate point.</p> <p>Time complexity \\(= O(n^3)\\)</p> <pre><code>Algorithm AllPaths(cost, n)\n{\n    for k=1 to n // taking every node as intermediary\n        for i=1 to n\n            for j=1 to n\n                a[i][j] = argmin(\n                    cost[i][j],\n                    cost[i][k] + cost[k][j]\n                )\n\n    return a\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/03_Dynamic_Programming/#single-source-shortest-path","title":"Single Source Shortest Path","text":"<p>Also called as Bellman Ford algorithm</p> <p>Similar to All Pair Shortest Path, but only from a single source to every other point.</p> <pre><code>Algorithm BellmanFord(v, cost)\n{\n    for i=1 to n\n        dist[i] = cost[v][i]\n\n    for k=1 to n\n        for i=1 to n\n            for j=1 to n\n                a[i] = argmin(\n                    a[i],\n                    cost[i][k] + cost[k][j]\n                )\n\n    return a\n}\n</code></pre> <p>Time complexity \\(= O(n^3)\\)</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/","title":"04 Backtracking","text":"<p>A general algorithm that</p> <ul> <li>incrementally builds candidates to the solutions</li> <li>backtracks/abandons candidate \\(c\\) once it is found that \\(c\\) cannot help attain valid solution</li> </ul> <p>It is an important tool for solving constraint satisfaction problems, such as crosswords, verbal arithmetic, Sudoku, and many other puzzles.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#types","title":"Types","text":"<ul> <li>Find a path to success</li> <li>Find all paths to success</li> <li>Find the best path to success</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#pseudocode","title":"Pseudocode","text":"<pre><code>Backtrack(x)\n    if x is not a solution\n        return false\n    if x is a new solution\n        add to list of solutions\n\n    backtrack(expand x)\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#terminology","title":"Terminology","text":"Term Meaning Problem State Node in Depth-First Search Tree State Space Set of all paths from root \\(\\to\\) other nodes Solution States Problem states for which path from root node defines a tuple in solution spaceIn variable tuple size formulation tree, all nodes are solution statesIn fixed tuple size formulation tree, only leaf nodes are solution states Answer states Solution states for which path from root defines a tuple that is a member of set of solutionsThese states implicit constraints State Space Tree Tree organization of solution space Static trees/Fixed-Size Independent of problem instance being solved Dynamic trees/Variable-Sized Dependent of problem instance being solved Live node Generated node whose all children have not been generated yet E-Node Live nodes whose children are currently being generated/explored Dead node Generated node that is not to be expanded any further Promising Node Node can lead to feasible solution Non-Promising Node Node cannot lead to feasible solution Pruned state space tree State space tree consisting of expanded nodes"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#backtracking-tree-structure","title":"Backtracking Tree Structure","text":"<pre><code>flowchart TB\nstart(( )) --&gt;\n1(( )) &amp; 2(( )) &amp; 3(( ))\n\n1 --&gt; 4(( )) &amp; 5\n5(( )) --&gt; 6(( )) &amp; 7(( ))\n\n2 --&gt; 8(( )) &amp; 9(( )) &amp; 12(( ))\n3 --&gt; 10(( )) &amp; 11(( ))\n\nclassDef red fill:red,stroke:red\nclassDef green fill:green,stroke:green\n\nclass 4,6,7 red\nclass 8 green</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#sudoku","title":"Sudoku","text":"<p>Obviously, the brute force approach would be randomly try all combinations of solutions, but the probability of getting the answer right in just a few attempts is very low, and hence, it is very computationally expensive.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#n-queens-problem","title":"N Queens Problem","text":"<p>Place \\(n\\) queen pieces on a chess board such that</p> <ul> <li>none of them can attack eachother</li> <li>no two queens in same row, same column or diagonal</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#steps","title":"Steps","text":"<ol> <li>Each recursive call attempts to place a queen in a specific column.</li> <li>For a given call, the state of the board from previous placements is known (i.e. where are the other queens?)</li> <li>Current step backtracking: If a placement within the column does not lead to a solution, the queen is moved \"down\" the column (to the next row)</li> <li>Previous step backtracking: When all rows in a column have been tried, the call terminates and backtracks to the previous call (in the previous column)</li> <li>If a queen cannot be placed into column \\(i\\), do not try to place one in column \\((i+1)\\), rather, backtrack to column \\((i-1)\\) and move the queen that had been placed there. Using this approach we can reduce the number of potential solutions even more</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#algorithm","title":"Algorithm","text":"Clash Possible if Row Won\u2019t happen cuz every iteration goes to next row implicitly Column If a queen is placed in column i, no other queen is placed in the same column Diagonal If two queens are placed at positions \\((i,j)\\) and \\((k,l)\\), then they are on the same diagonal only if\\(\\vert j \u2013 l\\vert  = \\vert i \u2013 k \\vert\\) <pre><code>Algorithm NQueens(k, n)\n{\n    for i=1 to n\n    {\n        if Place(k, i)\n        {\n            x[k] = i\n            if(k=n)\n                write(x[1:n])\n            else\n                NQueens(k+1, n)\n        }\n    }\n}\n\nAlgorithm Place(k, i)\n{\n    for j=1 to k-1\n    {\n        if (\n            x[j] == i // same col\n            or\n            abs(x[j]-i) == abs(j-k) // diagonal\n    )\n        return false\n    }\n\n    return true\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#time-complexity","title":"Time Complexity","text":"Approach Complexity Brute Force \\(n^n\\) Refactored Brute Force(modify to prevent from checking queens occupying same rows) \\(n!\\) Backtracking \\(2^n\\)"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#4x4-example","title":"4x4 Example","text":"<p>Only has 2 solutions</p> <ul> <li>\\((2, 4, 1, 3)\\)</li> <li>\\((3, 1, 4, 2)\\)</li> </ul> <p></p> <p></p> <p>where</p> <ul> <li>level 1, 2, 3, 4 correspond to queen 1, 2, 3, 4 respectively</li> <li>value at each node represents the position of the corresponding queen</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#sum-of-subsets","title":"Sum of Subsets","text":"<p>From a given set, find subset of numbers whose sum adds up to a given number</p> <p>Given n positive integers \\(\\{w_1, \\dots, w_n\\}\\) and a positive integer \\(S\\). Find all subsets of \\(w1, \\dots wn\\) that sum to \\(S\\). Let \\(\\{x_1, x_2, x_3, \\dots, x_n\\}\\) takes value either 0 or 1.</p> <ul> <li>If \\(x_i = 1\\) then \\(w_i\\) is chosen</li> <li>If \\(x_i=0\\) then \\(wi\\) is not chosen</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#using-bfs","title":"Using BFS","text":"<p>Edges from level \\(i\\) nodes to level \\(i+1\\) nodes are labeled with the value of \\(x_i\\) which is either zero or one. </p> <p>All paths from the root to a leaf node define the solution space. </p> <p>The left subtree of the root defines all subsets containing \\(w_1\\) while the right subtree defines all subsets not containing \\(w_1\\) etc. </p> <p>Variable-Sized tree with 24 leaf nodes which represent 16 possible tuples.</p> <p></p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#using-dfs","title":"Using DFS","text":"<p>Solution states are the leaf nodes </p> <p>The state space tree organization described here will be called static/Fixed sized tees. </p> <p>The tree organizations are independent of the problem instance being solved. Either fixed sized or variable sized tree can be opted. </p> <p>For some problems it is advantageous to use different tree organizations for different problem instances</p> <p></p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#algorithm_1","title":"Algorithm","text":"<pre><code>Algorithm SumOfSub(s, k, r)\n{\n    // generate left child\n    x[k] = 1\n\n    if s+w[k] == m\n        write(x[1:k])\n\n    else if s+w[k]+w[k+1] &lt;= m\n        SumOfSub(s+w[k], k+1, r-w[k])\n\n    // generate right child\n    if (\n        s+r-w[k] &gt;= m\n        and\n        s+w[k+1] &lt;= m\n    )\n    {\n        x[k] = 0\n        SumOfSub(s, k+1, r-w[k])\n    }\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/04_Backtracking/#complexity","title":"Complexity","text":"Brute Force \\(2^n\\) Backtracking \\(2^n\\), but faster"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/","title":"05 Branch & Bound","text":"<p>Algorithm that is used for solving combinatorial optimization problems, which usually have exponential time complexity.</p> <p>Algorithm that is used for solving combinatorial optimization problems, which usually have exponential time complexity.</p> <p>All children of the E-node are generated before any other live node can become the E-node</p> <p>Bounding functions are used to help avoid the generation of sub trees that do not contain an answer node</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#types","title":"Types","text":"<ol> <li>DFS (Stack/FIFO)</li> <li>BFS (Queue/LIFO)</li> <li>Least cost branch and bound</li> </ol> <p>In both LIFO and FIFO types, the selection rule for the next E-node is rigid, resulting in exploring maximum of all the E-nodes consuming more time.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#least-cost-branch-bound","title":"Least Cost Branch &amp; Bound","text":"<p>Selection of E-node is based on a cost function</p> <p>Not all the children of a node is generated; only nodes with least cost are expanded</p> <p>If we are close to the solution, first explore that path completely, instead of partially exploring other paths.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#cost-function","title":"Cost Function","text":"<p>If Cost measure is used</p> <ul> <li>search would always generate the minimum number of nodes </li> <li>only nodes to become E-nodes are the nodes on the path from the root to the nearest answer node</li> </ul> <p>The difficulty with using the \"ideal\" cost functions is that computing the cost of a node will usually involve a search of the subtree X for an answer node.</p> <p>Hence, by the time the cost of a node is determined, that subtree has been searched and there is no need to explore X again. </p> <p>For this reason, search algorithms usually rank nodes based only on an estimated value, \u011d(), of their cost.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#formula","title":"Formula","text":"\\[ \\hat c(x) = f\\Big(h(x)\\Big) + \\hat g(x) \\] <p>where</p> <ul> <li>\\(f(x)\\) is a non-decreasing function</li> <li>\\(h(x)\\) is cost reaching \\(x\\) from root</li> <li>\\(\\hat g(x)\\) is estimated additonal effort  to reach answer node from \\(x\\)</li> <li>\\(\\hat g(y) \\le \\hat g(x)\\), if \\(y\\) is a child of \\(x\\)</li> </ul> <pre><code>flowchart TB\nr((Root)) --&gt;\n|\"h(x)\"| x((x)) --&gt;\n|\"\u011d(x)\"| a((Answer&lt;br/&gt;Node ))</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#cases-of-formula","title":"Cases of Formula","text":"Case \\(f\\Big(h(x)\\Big) =0\\) DFS \\(f\\Big(h(x)\\Big) \\ne 0\\) Favor node close to the root over a node which is many levels below, thus reducing possibility of unproductive deep searches into tree \\(f\\Big(h(x)\\Big) =\\) level of node \\(x\\) \\(\\hat g (x) = 0\\) BFS"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#cases-of-cost","title":"Cases of Cost","text":"\\(x\\) is answer node Subtree \\(x\\) has answer node \\(\\implies\\) \\(c(x)\\) \u2705 N/A Cost of reaching \\(x\\) from root \u274c \u2705 Cost of mininum cost answer node in subtree \\(x\\) \u274c \u274c \\(\\infty\\)"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#optimization-vs-decision-problem","title":"Optimization vs Decision Problem","text":"Optimization Decision Problem Value Type Continuous Binary Example Finding the value of shortest path Finding whether the shortest path in a graph is of length 20"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#backtracking-vs-branch-bound","title":"Backtracking vs Branch &amp; Bound","text":"Parameter Backtracking Branch and Bound Approach Find all possible solutions available to a problem.When a wrong choice is made, perform backtracking Once a better optimal solution is obtained than a pre-solution leads to, it abandons that pre-solution Traversal DFS DFSBFS Function Feasibility function Bounding function Problems Decision Problem Optimization Problem Searching Until solution is obtained Tree need to be searched completely Efficiency better worse"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#4-queens","title":"4 Queens","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#fifo","title":"FIFO","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#lifo","title":"LIFO","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/05_Branch_%26_Bound/#least-cost","title":"Least Cost","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/","title":"06 Approximation Algorithms","text":"<p>Algorithm that generates a feasible solution with value close to the optimal solution.</p> <p>To reduce an time complexity of solving an optimization problem</p> <ol> <li>We remove the requirement that the algorithm must always generate an optimal solution</li> <li>We use an \u2018Probabilistically Good Algorithm\u2019, that almost always generates optimal solution</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#np-problem","title":"NP Problem","text":"<p>A problem is an NP (nondeterministic polynomial time) problem if it is solvable in polynomial time by a nondeterministic Turing machine</p> <p>A P-problem whose solution time is bounded by a polynomial is always also NP</p> <p>eg: 0/1 knapsack, traveling salesperson</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#terminology","title":"Terminology","text":"Symbol Meaning \\(p\\) NP problem \\(I\\) Instance of \\(P\\) \\(\\overset{\\star} F (I)\\) Opitmal solution to \\(I\\) \\(\\hat F(I)\\) Approximate solution to \\(I\\) \\(A\\) Algorithm that generates feasible solution to every \\(I\\) of \\(P\\) \\(\\hat F(I) &lt; \\overset{\\star} F (I)\\) Maximization problem \\(\\hat F(I) &gt; \\overset{\\star} F (I)\\) Minimization problem"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#types-of-approximation-algorithms","title":"Types of Approximation Algorithms","text":"Type Meaning Application Absolute \\(\\vert \\hat F(I) - \\overset{\\star} F (I) \\vert \\le k\\), for some constant \\(k\\)for every \\(I\\) of \\(P\\) Planar Graph ColoringMaximum Programs Stored Problem \\(f(n)\\) \\(\\frac{\\vert \\hat F(I) - \\overset{\\star} F (I)  \\vert}{\\overset{\\star} F (I)} \\le f(n)\\), for \\(\\overset{\\star} F (I) &gt; 0\\)for every \\(I\\) of \\(P\\) \\(\\epsilon\\) \\(f(n)\\) approximation algo for which \\(f(n) \\le \\epsilon\\), where \\(\\epsilon\\) is some constant"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#planar-graph-coloring","title":"Planar Graph Coloring","text":"<p>Coloring vertices of a graph, such that no two adjacent vertices have the same color</p> <p>Goal: Minimize no of colors used</p> <p>A graph is planar if it can be represented by a drawing in the plane such that no edges cross.</p> <p>The maximum no of colors required for a planar graph is 4</p> <pre><code>Algorithm Acolor(V, E)\n{\n  if V = null\n    return 0\n  else if E = null\n    return 1\n  else if (G is bipartite)\n    return 2\n  else\n    return 4\n}\n</code></pre> <p>Time Complexity: \\(O(|V|+|E|)\\), which is the time taken to check if graph is bipartite</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#maximum-program-stored-problem","title":"Maximum Program Stored Problem","text":"<p>Consider</p> <ul> <li>\\(n\\) programs</li> <li>two disks with storage capacity of \\(L\\) each. </li> <li>list \\(l\\) where \\(l_i\\) is the storage required to store program \\(i\\)</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#goal","title":"Goal","text":"<p>Determine max no of programs that can be stored on the disks, without splitting a program over the disks.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#solution","title":"Solution","text":"<ol> <li>Sort \\(l\\) in ascending order (to maximize count; in knapsack, we don\u2019t maximize count, we maximize profit)</li> <li>Keep placing elements</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#algorithm","title":"Algorithm","text":"<pre><code>Algorithm Pstore(l, n, L) \n{ \n    // sort l in ascending order\n\n    i = 1\n    for j=1 to 2\n    {\n        sum = 0; // amount (part) of disk j already assigned \n    while (sum + l[i]) &lt;= L\n    { \n        write (\"store program\", i, \"on disk\", j)\n        sum = sum + l[i]\n        i = i + 1\n        if i &gt; n\n        return\n    }\n  }\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/06_Approximation_Algorithms/#time-complexity","title":"Time Complexity","text":"<p>\\(O(n) + \\underbrace{O(n \\log n)}_{\\text{Sorting}} = O(n \\log n)\\)</p> <p>The most optimal algorithm will have exponential time.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/07_Network_Flow/","title":"07 Network Flow","text":"<p>blah</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/07_Network_Flow/#properties","title":"Properties","text":"Condition Meaning Mathematical representation Capacity \\(0 \\le \\text{flow}_e \\le \\text{capacity}_e\\) \\(0 \\le f(e) \\le c_e, \\ \\forall e \\in E\\) Conservation Inflow = Outflow @ every node \\(\\sum\\limits_\\text{Inflow} f(e) = \\sum\\limits_\\text{Outflow} f(e), \\ \\forall e \\in E\\)"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/07_Network_Flow/#algorithm","title":"Algorithm","text":"<ol> <li>Find all paths from source to destination</li> <li>The maximum flow is limited by the bottleneck, which is the lowest value in a path, ie \\(\\text{argmin} (c_e), \\ e \\in P\\)</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/07_Network_Flow/#residual-graph","title":"Residual Graph","text":"<p>Indicates how much more flow is allowed in each edge in the network graph</p> Path Direction of flow in residual graph Unused Same Partially used Used will be reversedUnused will be same Completely used Reversed"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/","title":"08 Parallelization","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#multi-threading","title":"Multi-Threading","text":"<p>Ability of a single core of a CPU to have concurrent threads of execution, supported by the OS</p> <p>The threads share the resources of the single/multiple cores, including computing units, cache, and TLB (translation look-aside buffer)</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#real-life-examples","title":"Real-Life Examples","text":"<ul> <li>Web Browsers</li> <li>Download multiple files at the same time</li> <li>One website blocking downloads will not affect other downloads</li> <li>Web Servers</li> <li>A thread web server handles each request with a new thread</li> <li>There is a thread pool and each time a new request comes in, it is assigned to a thread from the thread pool</li> </ul>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#parallelization","title":"Parallelization","text":"<p>Multi-threading a single algorithm so that some of its instructions can be executed simultaneously</p> <p>This can be applied to scheduling &amp; managing multiple algorithms, each running concurrently on their own threads and possibly sharing resources.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#types-of-multi-threading","title":"Types of Multi-Threading","text":"Static Dynamic Type of Control Explicit Implicit Real Control Programmer Concurrency Platform(maps concurrency opportunities specified by programmer to actual static threads) Flexible \u274c \u2705"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#dynamic-multi-threading","title":"Dynamic Multi-Threading","text":"Keyword Meaning <code>parallel</code> Add to loop construct such as <code>for</code>Indicates each iteration can be executed in parallel <code>spawn</code> Create a parallel subprocess, then keep executing current process <code>sync</code> Wait here until all active parallel threads created by this instance of the program finish <p><code>parallel</code> and <code>spawn</code> are not compulsory to be followed; they do not force parallelism, they just say that this is permissible. A scheduler will make the decision concerning allocation to processors.</p> <p>However, if parallelism is used, sync must be respected. For safety, there is an explicit sync at the end of every procedure.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#example-fibonacci","title":"Example: Fibonacci","text":"<pre><code>F(0)\u00a0= 0\nF(1)\u00a0= 1\nF(i)\u00a0= F(i-1)\u00a0+ F(i-2), for\u00a0i\u00a0\u2265 2\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#non-parallel","title":"Non-Parallel","text":"<pre><code>fib(n):\n    if n &lt;= 1\n        return n\n    else\n        x = fib(n-1)\n        y = fib(n-2)\n        return x + y\n</code></pre> \\[ \\begin{aligned} T(n) &amp;= T(n\u00a0\u2212 1) + T(n\u00a0\u2212 2) + \\theta(1) \\\\ &amp;= \\theta(F_n) \\end{aligned} \\] <p>This grows exponentially, this is not very efficient.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#parallel","title":"Parallel","text":"<pre><code>fib(n):\n    if n &lt;= 1\n        return n\n    else\n        x = spawn fib(n-1)\n        y = fib(n-2)\n        sync\n        return x + y\n</code></pre> <p><code>sync</code> is required to avoid <code>x</code> and <code>y</code> getting summed before <code>x</code> is computed. Even if there wasn\u2019t an explicitly-mentioned <code>sync</code>, every function does an implicit <code>sync</code> and then only terminates</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/08_Parallelization/#modelling-dynamic-multi-threading","title":"Modelling Dynamic Multi-Threading","text":"<p>Consider a computation DAG (Directed Acyclic Graph) \\(G=(V, E)\\)</p> <ul> <li>Vertices represent instructions/strand</li> <li>A strand is a sequence of non-parallel instructions</li> <li>A strand with multiple successors means that all but one of them must have spawned.</li> <li>A strand with multiple predecessors means that they join at a sync statement.</li> <li>Edges represent dependencies between edges</li> <li>\\((u, v) \\in E\\) means \\(u\\) must execute before \\(v\\)<ul> <li>This means that \\(u\\) and \\(v\\) are in series</li> </ul> </li> <li>All \\((u, v) \\not \\in E\\) means that they are \\(u\\) and \\(v\\) are logically parallel</li> </ul> <p>We assume an ideal parallel computer with sequentially-consistent memory: it behaves as if instructions are executed sequentially in some full ordering consistent with orderings within each thread (consistent with partial-ordering of computation DAG)</p> <p></p> <p>Rounded rectangles are not part of the formal model, but they help organize the visualization by collecting together all strands for a given call</p> <p>The colors are specific to this example and indicate the corresponding code: black indicates that the strand is for lines 1-3; grey for line 4; and white for lines 5-6</p> <p></p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/","title":"09 NP","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#problems","title":"Problems","text":"P NP NP Complete NP Hard Can be solved using __ algorithm Deterministic Non-Deterministic Non-Deterministic Non-Deterministic Time Complexity (Solving) Polynomial Exponential Exponential Exponential Time Complexity (Verification) Polynomial Polynomial Exponential Type of problem Any Any Decision Problem Any IDK Problem L \u00a0is NP Complete if- L is in NP- Every problem in NP is reducible to L in polynomial time Example Determination of hamiltonian cycleDetermination of satisfaction level of boolean formula Circuit SatisfactoryVertex CoverHalting problems"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#problem-properties","title":"Problem Properties","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#reducible","title":"Reducible","text":"<p>\\(L_1 \\underset{\\text{reduces to}}{\\propto} L_2 \\iff\\) there is a way to solve \\(L_1\\) using a deterministic algorithm that solves \\(L_2\\) in polynomial time</p> <p>This is transitive, ie, \\(L_1 \\propto L_2, L_2 \\propto L_3 \\implies L_1 \\propto L_3\\)</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#polynomially-equivalent","title":"Polynomially-Equivalent","text":"<p>\\(L_1\\) and \\(L_2\\) are polynomially-equivalent \\(\\iff (L_1 \\propto L_2) \\land (L_2 \\propto L_1)\\)</p> <p>To show that a problem \\(L_2\\) is NP-Hard, it is sufficient to show that \\(L_1 \\propto L_2\\), where \\(L_1\\) is a problem already known to be NP-Hard.</p> <p>Due to transitivity, if satisfiability \\(\\propto L_1\\) and \\(L_1 \\propto L_2 \\implies\\) Satisfiability \\(\\propto L_2\\)</p> <p>To show that an NP-Hard decision problem is NP-Complete, we just need to find a polynomial time non-deterministic algorithm for it.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#p-np-algorithms","title":"P &amp; NP Algorithms","text":"P Algorithm NP Algorithm Deterministic Non-Deterministic Polynomial Polynomial Used to solve exponential problems"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#non-deterministic-algorithms","title":"Non-Deterministic Algorithms","text":"<code>choice(S)</code> Arbitrarily choose one of the elements in set \\(S\\) <code>failure()</code> Signals unsuccessful completion <code>success()</code> Signals successful completion"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#non-deterministic-search-algorithm","title":"Non-Deterministic Search Algorithm","text":"<pre><code>Algo Nsearch(a, n, key)\n{\n    c = Choice([1, n]);\n\n    if (a[c] == key)\n    success()\n    else\n    failure();\n}\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#non-deterministic-sort-of-ve-integers","title":"Non-Deterministic Sort of +ve integers","text":"<pre><code>Algo Nsort(a, n)\n\n    for i=1 to n\n        b[i] = 0\n\n    // randomly place elements\n    for i=1 to n\n        c = choice([1, n])\n        if b[c] != 0 // element already not there\n            b[c] = a[i]\n        else // element exists at same position\n            failure()\n\n    // verify order\n    for i=1 to n\n        if b[i] &gt; b[i+1]\n            failure()\n\n    sucess()\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#non-deterministic-binary-knapsack","title":"Non-Deterministic Binary Knapsack","text":"<pre><code>Algo NDBK(profits, weights, min_profit, max_weight)\n    taken_profit = 0\n    taken_weight = 0\n\n    for i=1 to n do\n        c = choice(0, 1)\n\n        if c == 1 then\n      taken_profit += profits[i]\n      taken_weight += weights[i]\n\n  if (\n    (taken_profit &gt;= min_profit) &amp;&amp;\n    (taken_weight &lt;= max_weight)\n  )\n    success()\n  else\n    failure()\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#clique-problem","title":"Clique Problem","text":"<p>A clique is complete subgraph of a given graph, ie, every node of the subgraph is connected to each other.</p> <pre><code>Algo clique(a) // adjacency matrix\n    s = [] // subgraph\n\n    // randomly add elements\n    for i=1 to a.length\n        c = choice(0, 1)\n\n        if c==1\n            s.add(\n                (i, j)\n            )\n\n    // verify subgraph\n    for i=1 to a.length\n        for j=1 to a.length\n            i not connected to j then\n                failure()\n\n    success()\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#satisfiability","title":"Satisfiability","text":"<pre><code>Algo sat(E, n)\n    for i=1 to n do\n        x[i] = choice(false, true)\n\n    if E(x[1], ..., x[n]) then\n        success()\n    else\n        failure()\n</code></pre>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#np-hard-graph-problems","title":"NP-Hard Graph Problems","text":"<p>To prove that a problem \\(L_2\\) is NP-hard</p> <ol> <li>Pick a problem \\(L_1\\) already known to be NP-hard</li> <li>Show how to obtain (in polynomial deterministic time) an instance \\(I'\\) of \\(L_2\\) from any instance \\(I\\) of \\(L_1\\) such that from the solution of \\(I'\\), we can determine (in polynomial deterministic time) the solution to instance \\(I\\) of \\(L_1\\)</li> <li>Conclude from 2. that \\(L_1 \\propto L_2\\)</li> <li>Conclude from 1 &amp; 3 and transitivity that \\(L_2\\) is NP-hard</li> </ol>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#clique-decision-problem","title":"Clique Decision Problem","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#node-cover-decision-problem","title":"Node Cover Decision Problem","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/09_NP/#chromatic-number-decision-problem","title":"Chromatic Number Decision Problem","text":""},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/10_Linear_Programming/","title":"10 Linear Programming","text":"<p>If we can specify the objective as a linear function of variables, and if we can specify the constraints on resources as equalities/inequalities, we have a linear programming problem</p> <p>I already did optimization course, so I\u2019ve skipped a lot.</p>"},{"location":"3_Core/Design_%26_Analysis_of_Algorithms/10_Linear_Programming/#conversions","title":"Conversions","text":"<ul> <li>Convert from min problem to max problem</li> <li>Negate the coefficients in objective function</li> <li>If some of the variables do not have \\(\\ge 0\\) constraints</li> <li>Add \\(\\ge 0\\) constraints \\(x'_j &gt; 0, x''_j &gt; 0\\)</li> <li>Replace \\(x_j \\to x'_j - x''_j\\)</li> <li>Replace \\(c_j x_j \\to c_j x'_j - c_j x''_j\\)</li> <li>Replace \\(a_{ij} x_j \\to a_{ij} x'_j - a_{ij} x''_j\\)</li> <li>Any feasible solution obtained corresponds to<ul> <li>\\(\\bar x_j = \\hat x'_j - \\hat x''_j\\)</li> <li>\\(\\hat x'_j = \\bar x_j, \\hat x''_j = 0, \\text{ if }\\bar x_j \\ge 0\\)</li> <li>\\(\\hat x''_j = \\bar x_j, \\hat x'_j = 0, \\text{ if }\\bar x_j \\le 0\\)</li> </ul> </li> <li>Convert constraint \\(\\ge k \\implies \\le -k\\)</li> <li>Convert constraint \\(= k \\implies \\le k \\ \\&amp; \\ge k\\)</li> <li>Add slack</li> </ul>"},{"location":"3_Core/Immunology/","title":"Immunology","text":"<p>Taught by Dr. Mainak Dutta</p> <p>(add description)</p>"},{"location":"3_Core/Operating_Systems/","title":"Operating Systems","text":"<p>Taught by Dr. Angel Arul Jothi</p> <p>This course covers foundational concepts relevant to operating systems.</p>"},{"location":"3_Core/Operating_Systems/01_Intro/","title":"01 Intro","text":""},{"location":"3_Core/Operating_Systems/01_Intro/#software","title":"Software","text":"<p>a set of programs</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#types-of-softwares","title":"Types of Softwares","text":"Application Softwares System Softwares Purpose Helps users with specific applications - Provides environment for application software- Manage hardware resources Example Word, Paint - Operating System- Emulator- Language Translators (Compiler, Interpreters, Assemblers)- Linker, Loader"},{"location":"3_Core/Operating_Systems/01_Intro/#operating-system","title":"Operating System","text":"<p>System software that acts as an interface between users and the hardware resources of a computing system.</p> <ul> <li>Resource allocator<ul> <li>Keeps track of occupied/empty portions of the primary and secondary memory</li> <li>Status of I/O Devices</li> </ul> </li> <li>control program</li> <li>Kernel of a computing system   Kernel is the most important part of any computing system/programming environment<ul> <li>Kernel is system software which is part of operating system</li> <li>Kernel provides interface between hardware and software components</li> </ul> </li> </ul> \\[ \\fbox{System, Application Software $\\fbox{ Operating System $\\fbox{Kernel $\\fbox{H/W Resources}$}$}$} \\]"},{"location":"3_Core/Operating_Systems/01_Intro/#types-of-operating-system","title":"Types of Operating System","text":"<ul> <li>Mobile</li> <li>Personal Computer</li> <li>Real Time</li> <li>Distributed</li> </ul>"},{"location":"3_Core/Operating_Systems/01_Intro/#hardware-resources","title":"Hardware Resources","text":"<ul> <li>Memory<ul> <li>Primary is volatile</li> <li>Secondary is non-volatile</li> </ul> </li> <li>Processor</li> <li>I/O Devices</li> </ul>"},{"location":"3_Core/Operating_Systems/01_Intro/#example","title":"Example","text":"<pre><code>flowchart LR\n\ngc[Google Chrome] --&gt;\nCPU((CPU)) --&gt;\nScreen[Output Screen]\n\nHD[(Hard Disk)] --&gt;\n|Operating System &lt;br/&gt; loads| pm[[Primary Memory]]</code></pre>"},{"location":"3_Core/Operating_Systems/01_Intro/#device","title":"Device","text":"<pre><code>flowchart LR\nOS &lt;--&gt;\ndd[Device Driver] &lt;--&gt;\ndc[Device Controller] &lt;--&gt;\nDevice</code></pre>"},{"location":"3_Core/Operating_Systems/01_Intro/#controller","title":"Controller","text":"<ul> <li>Data Register/Local buffer</li> <li>Command Register</li> </ul>"},{"location":"3_Core/Operating_Systems/01_Intro/#driver","title":"Driver","text":"<ul> <li>Interface between OS &amp; Device</li> <li>Understands the device controller &amp; device</li> </ul>"},{"location":"3_Core/Operating_Systems/01_Intro/#daemons","title":"Daemons","text":"<p>Background system processes, that are not in direct control of user</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#interrupts","title":"Interrupts","text":"<p>Asynchoronous request to the CPU, handled by the OS using the ISR (Interrupt Service Routine).</p> <p>They can be initiated anytime without reference to the system clock.</p> <p>Could be hardware-generated or software-generated.</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#isr-ivt","title":"ISR &amp; IVT","text":"<p>ISR and IVT(Interrupt Vector Table) are stored in fixed location in memory.</p> <p>ISR is accessed using IVT, which contains the starting address of the ISRs.</p> \\[ \\begin{aligned} &amp;\\text{Starting address of ISR in IVT}\\\\ &amp; = \\text{Starting address of IVT in memory } \\\\ &amp; \\quad + ( \\text{type} \\times \\text{no. of loc to store address of 1 ISR} ) \\end{aligned} \\] <p>8086 has 256 vectored interrupts</p> <p>Each ISR requires 4 bytes</p> <ul> <li>2 bytes of IP   followed by</li> <li>2 bytes of CS</li> </ul> <p>If the starting address of IVT is \\(\\text{00000_H}\\), then the ending address is \\(\\text{003FF_H}\\)</p> <p></p>"},{"location":"3_Core/Operating_Systems/01_Intro/#graph","title":"Graph","text":"<p>(take from slides)</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#interrupt-latency","title":"Interrupt latency","text":"<p>Time taken to service an interrupt</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#advantages","title":"Advantages","text":"<ul> <li>Save processor time<ul> <li>Processor resources are very valuable, as it can be used for some other task</li> </ul> </li> <li>Avoid polling<ul> <li>Going around asking I/O devices; wasting processor time</li> </ul> </li> </ul> <pre><code>flowchart LR\n\nsubgraph Write Operation\ndirection LR\nup2[User Program] --&gt;\nOS2[OS] --&gt;\ndd2[Device Driver] --&gt;\ndc2[Device Controller] &lt;--&gt;\nod2[Output Device]\n\ndc2 --&gt;|Status| dd2\nend\n\nsubgraph Read Operation\ndirection LR\nup[User Program] --&gt;\nOS --&gt;\ndd[Device Driver] --&gt;\ndc[Device Controller] &lt;--&gt;\nid[Input Device]\n\ndc --&gt;|Interrupt| dd\nend</code></pre>"},{"location":"3_Core/Operating_Systems/01_Intro/#program-counter","title":"Program Counter","text":"<p>Similar to instruction pointer of x86</p> <ul> <li>Initially points to 1<sup>st</sup> instruction</li> <li>Subsequently, points to the address of the next instruction to be executed</li> </ul>"},{"location":"3_Core/Operating_Systems/01_Intro/#interrupt-handling","title":"Interrupt Handling","text":"<ol> <li>An interrupt that occurs in between an instruction can only happen after fetch, decode, execute, write-back of that instruction is first complete.</li> <li> <p>When interrupt occurs, we need to push the following values into stack</p> <ul> <li> <p>PC so that we can return to the same point after finishing the interrupt</p> </li> <li> <p>CPU state  Contents of all CPU and flag registers</p> </li> <li>Service the interrupt using ISR</li> <li>Restore processor state</li> <li>Load the saved return address into the program counter</li> <li>Resume interrupted computation</li> </ul> </li> </ol>"},{"location":"3_Core/Operating_Systems/01_Intro/#storage-of-multi-byte-data","title":"Storage of Multi-Byte data","text":"<p>Little Endian = Lower Byte is stored first then Higher Byte.  This is what 8086 uses</p> <p>Big Endian = Higher Byte is stored first then Lower Byte</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#storage-structure","title":"Storage Structure","text":"<ul> <li>Bit (0/1) [most basic unit]</li> <li>Byte = 8 bits</li> <li>Word = Group of bytes</li> </ul> Bytes KB \\(2^{10}\\) MB \\(2^{20}\\) GB \\(2^{30}\\) TB \\(2^{40}\\) PB \\(2^{50}\\)"},{"location":"3_Core/Operating_Systems/01_Intro/#types-of-storage-devices","title":"Types Of Storage Devices","text":"<pre><code>flowchart TB\nMemory --&gt;\ncpu[CPU Registers] &amp; Cache &amp; Primary &amp; Secondary &amp; Tertiary\n\nPrimary[\"Primary&lt;br/&gt;(Volatile)\"] --&gt; RAM\nSecondary[\"Secondary&lt;br/&gt;(Non-Volatile)\"] --&gt; HDD &amp; SSD\nTertiary[\"Tertiary&lt;br/&gt;(Non-Volatile Backup)\"] --&gt; CD &amp; DVD &amp; Backup</code></pre> Feature Order Speed Reg &gt; Cache &gt; PM &gt; SM &gt; TM Cost Reg &gt; Cache &gt; PM &gt; SM &gt; TM Access Time Reg &lt; Cache &lt; PM &lt; SM &lt; TM Size Reg &lt; Cache &lt; PM &lt; SM &lt; TM <pre><code>flowchart TB\n\nsubgraph While Using\nCPU2[CPU] --&gt;|1| PM2[PM] --&gt;|2| CPU2\nend\n\nsubgraph First Time\ndirection LR\n\nCPU1[CPU]\nCPU1 --&gt;\n|1| PM1[PM] --&gt;\n|2| SM1[(SM)]\n\nSM1 --&gt;|3|PM1\n\nPM1 --&gt;|4| CPU1\nend</code></pre>"},{"location":"3_Core/Operating_Systems/01_Intro/#booting","title":"Booting","text":"<p>Process of loading OS Kernel into the primary memory</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#steps","title":"Steps","text":"<ul> <li>Starting address of Bootstrap program is stored into the Program Counter</li> <li>Bootstrap loader loads the OS using Boostrap program</li> </ul>"},{"location":"3_Core/Operating_Systems/01_Intro/#bootstrap-program","title":"Bootstrap Program","text":"<ul> <li>In Intel architecture, it\u2019s called as BIOS(Basic Input Output System)</li> <li>In Unix architecture, it\u2019s called as GRUB(GRand Unified Bootloader)</li> <li>In Android, LK(Little Kernel)</li> </ul>"},{"location":"3_Core/Operating_Systems/01_Intro/#tasks","title":"Tasks","text":"<ol> <li>Run POST(Power-On Self Test) diagnostics</li> <li>Initialize and check peripheral devices</li> <li>Initializes other aspects of the system, such as the registers</li> <li>Locates and loads the kernel</li> </ol>"},{"location":"3_Core/Operating_Systems/01_Intro/#rom","title":"ROM","text":"<p>Read-Only Memory</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#eeprom","title":"EEPROM","text":"<p>Electrically Erasable Programmable Read-Only Memory</p> <p>It is firmware (combination of hardware and software that can hold code)</p> <p>Bootstrap program is burnt into EEPROM</p> <p>System Programs loaded to PM, System process, Deamons, Program in its execution, Printer network, Background Process</p> <p>In linux, the first program is <code>systemd</code></p>"},{"location":"3_Core/Operating_Systems/01_Intro/#software-interrupt","title":"Software Interrupt","text":"<p>Trap/exception</p> Source/Cause Example Errors - Divide by zero- Access to illegal parts of memory System call When user actions requires something like input/output <pre><code>flowchart LR\n\nUP[User Program]\nOS\nTasks\n\nsubgraph Tasks\n    direction LR\n    io[I/O Management]\n    Memory\nend\n\nUP --&gt;|Request| OS --&gt; Tasks</code></pre>"},{"location":"3_Core/Operating_Systems/01_Intro/#programming-types","title":"Programming Types","text":"<p>Uni was before.</p> Uni Multi Primary memory parts - OS area- User area can be used by only 1 program - OS area- User area contains multiple programs Advantage When one program is waiting for I/O, the OS sends off another program to the CPU. Disadvantage This has improper utilization of system resources, especially when I/O devices are being used. Malicious programs can affect the other program\u2019s segments; before it was even possible for them to affect the OS"},{"location":"3_Core/Operating_Systems/01_Intro/#modes-of-operations","title":"Modes of Operations","text":"<p>This mode bit will change continuously.</p> Mode Bit Mode Computer is executing 0 Kernel/Supervisor/Priveledged OS code/System call 1 User User code"},{"location":"3_Core/Operating_Systems/01_Intro/#privileged-execution-of-instruction","title":"Privileged Execution of Instruction","text":"<p>Privilege signifies the access level of a program</p> <p>I/O, memory, timer, CPU, and Interrupts are privileged</p> <p>Privilege level varies from</p> <ul> <li>0 (high privilege)</li> <li>3 (low privilege)</li> </ul> <p>If a program trying to access memory is privileged, then it is checked if it is in Kernel mode or User mode.</p> <p>If it is in user mode, a trap is generated.</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#lab-code","title":"Lab code","text":"<p>Lab</p>"},{"location":"3_Core/Operating_Systems/01_Intro/#i-missed-something-sep-14-1st-hour","title":"I missed something (Sep 14 1<sup>st</sup> Hour)","text":""},{"location":"3_Core/Operating_Systems/02_Functions_of_OS/","title":"02 Functions of OS","text":""},{"location":"3_Core/Operating_Systems/02_Functions_of_OS/#functions-of-os","title":"Functions of OS","text":""},{"location":"3_Core/Operating_Systems/02_Functions_of_OS/#process-management","title":"Process Management","text":"<ul> <li>Job scheduling<ul> <li>Picks processes from job pool to be placed in PM</li> <li>Process = Program in its execution</li> </ul> </li> <li>CPU Scheduling<ul> <li>Pick a process from PM and allocate to CPU</li> </ul> </li> <li>Process Synchronization</li> <li>Deadlock Handling</li> </ul>"},{"location":"3_Core/Operating_Systems/02_Functions_of_OS/#memory-management","title":"Memory Management","text":"<ul> <li>Allocate/Deallocate PM to processes</li> <li>Keep track of allocated and unallocated parts of PM</li> </ul>"},{"location":"3_Core/Operating_Systems/02_Functions_of_OS/#storage-management","title":"Storage Management","text":"<ul> <li>File System Management</li> <li>Mass Storage/Disk Management</li> <li>I/O Management</li> </ul>"},{"location":"3_Core/Operating_Systems/02_Functions_of_OS/#protection-and-security","title":"Protection and Security","text":""},{"location":"3_Core/Operating_Systems/03_Evolution/","title":"03 Evolution","text":""},{"location":"3_Core/Operating_Systems/03_Evolution/#early-computers","title":"Early Computers","text":"<p>Something compiler</p> <p>Aim was to optimize CPU time</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#batch-processing-systems","title":"Batch Processing Systems","text":"<p>Shared computer systems</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#steps","title":"Steps","text":"<ul> <li>Operator hired</li> <li>Jobs with similar needs were batched together and run though computer, to reduce setup time</li> </ul>"},{"location":"3_Core/Operating_Systems/03_Evolution/#problems","title":"Problems","text":"<ul> <li>Stopped jobs (normal/abnormal)</li> <li>Dump (Log file)   Status of the memory is stored into a text file</li> <li>Load device with next job</li> <li>Restart computer</li> </ul>"},{"location":"3_Core/Operating_Systems/03_Evolution/#issues","title":"Issues","text":"<p>(i missed this)</p> <p>CPU Burst</p> <p>I/O Burst</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#solution","title":"Solution","text":"<ul> <li>Perform CPU execution and I/O concurrently</li> <li>Multi-programming and Time Sharing<ul> <li>Multi-programming \\(\\ne\\) Multi-Processing</li> <li>Multi-Programming means using 1 CPU and performing multiple programs concurrently</li> <li>Multi-Processing means using multiple CPUs</li> </ul> </li> </ul>"},{"location":"3_Core/Operating_Systems/03_Evolution/#time-sharingmulti-tasking-systems","title":"Time Sharing/Multi-Tasking Systems","text":"<p>Extension of Multiprogramming</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#time-multiplexing","title":"Time Multiplexing","text":"<p>CPU switch between the programs kept in PM</p> <p>This is done by dividing CPU time into Time Quanta(fixed intervals)</p> <p>Involves timer = counters + clock</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#space-multiplexing","title":"Space Multiplexing","text":"<p>After partitioning primary memory into OS and User area, the User Area is then further partitioned for multiple users</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#advantages","title":"Advantages","text":"<ul> <li>Supported user interaction</li> <li>Improved response time</li> </ul>"},{"location":"3_Core/Operating_Systems/03_Evolution/#difference-from-multi-programming","title":"Difference from Multi-Programming","text":"<p>A single CPU switches between multiple users, in a way that every user feels as if they are using the CPU.</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#steps_1","title":"Steps","text":"<ol> <li>P1 runs to completion</li> <li>P1 requests I/O</li> <li>P1 has not completed the execution, but the time quanta expired</li> <li>Timer interrupt occurs (as the down-counting timer is over), the CPU switches to another user</li> </ol>"},{"location":"3_Core/Operating_Systems/03_Evolution/#time-delay","title":"Time Delay","text":"<p>Time between switching between 2 users</p> <p>= Count value * Time Period</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#features","title":"Features","text":"<ul> <li>Job, CPU Scheduling</li> <li>Memory Management</li> <li>Resonable response time<ul> <li>Using Virtual memory</li> <li>Swap/Roll</li> </ul> </li> <li>File system and disk management</li> <li>job sync and communication</li> <li>Deadlocks handling</li> <li>protection and security</li> </ul>"},{"location":"3_Core/Operating_Systems/03_Evolution/#swaproll","title":"Swap/Roll","text":"Swap-in/Roll-In Swap-out/Roll-out Moving partially executed program from ___ memory secondary \\(\\to\\) primary primary \\(\\to\\) secondary Basically like loading in"},{"location":"3_Core/Operating_Systems/03_Evolution/#multi-tasking","title":"Multi-Tasking","text":"<p>Each program of the same user is a \u2018task\u2019. The processor switches between each task.</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#computer-system","title":"Computer System","text":"Single-Processor System Multi-Processor System Total No of chips 1 Multiple Total No of cores 1 Multiple <p>Core = CPU, Register, Local Cache</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#multi-processor-system","title":"Multi-Processor System","text":"Traditional Modern(Multi-Core) Each processor has ___ core 1 Multiple Processors connected to shared memory unit, shared I/O, shared clock, and other shared system resources All shared resources for the cores are within the CPU, thereby improving performance <ul> <li>i3 has dual-core</li> <li>i5, i7 have quad-core</li> </ul>"},{"location":"3_Core/Operating_Systems/03_Evolution/#multi-processing","title":"Multi-Processing","text":"<p>Concurrent execution using multiple processors</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#increased-throughput","title":"Increased Throughput","text":"<p>Execution of programs is distributed to multiple processors, hence more output</p> <p>Expected increase is the number of additional processors, but this is not real. Check Amdahl's law in CA</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#improved-reliability","title":"Improved Reliability","text":"<p>Even if one processor fails, complete failure is avoided. However there will be obvious delay.</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#useful-for-testing-fault-tolerance","title":"Useful for testing fault Tolerance","text":"<p>2 systems perform the same task and the results will be checked.</p> <p>However, increased redundancy and consumption of resources.</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#desktop-os","title":"Desktop OS","text":"<p>WindowsOS, MacOS, Linux</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#mobile-os","title":"Mobile OS","text":"<p>Android, iOS</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#embedded-systems","title":"Embedded Systems","text":"<p>Washing machine, dishwasher</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#realtime-os","title":"Realtime OS","text":"<p>More complex, Dynamic and have time constraints                  </p> <p>eg: Industrial control systems, Weapon systems</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#distributed-systems","title":"Distributed Systems","text":"<p>Multiple hardware devices are networked together.</p> <p>Each device runs a subset of the \u2018distributed OS\u2019</p> <p>When a process executes, the process is split into subprocesses which is sent to different nodes.</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#advantages_1","title":"Advantages","text":"<p>Some more points are there</p> <ul> <li>Data access</li> <li>Special h/w requirements</li> <li>Load balancing</li> </ul>"},{"location":"3_Core/Operating_Systems/03_Evolution/#definitions","title":"Definitions","text":""},{"location":"3_Core/Operating_Systems/03_Evolution/#throughput","title":"Throughput","text":"<p>No of tasks completed</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#turn-around-time","title":"Turn around time","text":"<p>Time between starting of execution of a program and its completion</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#questions","title":"Questions","text":"<ol> <li>Steps when a user double clicks MS Powerpoint icon in a Windows Desktop<ul> <li>CPU recognizes user click (Hardware Interrupt), after execution of current instruction</li> <li>Mode changes to kernel mode</li> <li>Identifies <code>.exe</code> file in secondary memory</li> <li>OS loads program into primary memory</li> <li>Allocate the CPU</li> <li>Hardware interrupt to display on screen</li> </ul> </li> <li>Important activities/functions done by OS<ul> <li>Functions of OS</li> </ul> </li> <li>Suppose a computer system has 10000 bytes of memory available. Out of this, the OS occupies 5000bytes. Now it is required to run a program whose size is 7000bytes. Is this possible?<ul> <li>No, it is not possible in basic computers</li> <li>Every program has to be loaded into primary memory for its execution</li> <li>The memory is split into 2 parts</li> <li>OS segment</li> <li>Program segment (for loading the program)</li> <li>As only 5000bytes is available for the program segment, we cannot load this program, and hence we cannot run it</li> <li>However, we can sort this issue using virtual memory</li> </ul> </li> <li>What is meant by dual mode of operation in intel CPUs<ul> <li>To ensure better security and stricter access priveleges, the CPU has 2 modes of operations</li> <li>Instructions by the user are done in user mode, with lower priveleges</li> <li>Instructions by the user are done in kernel mode, with higher priveleges</li> </ul> </li> <li>Can you guess in what mode OS program is run and in what mode user program is run?<ul> <li>Kernel mode</li> <li>User mode</li> </ul> </li> <li>What is the difference between hardware and software interrupt in a computer system? Can you give examples of each type.<ul> <li>Hardware interrupt are interrupts involving I/O devices. eg: keyboard input</li> <li>Software interrupts do not include I/O devices. eg: Mathematical errors, rejected priviledged instructions, Exceptions</li> </ul> </li> <li>Why do you require a bootstrap loader?<ul> <li>POST Diagnostics</li> <li>Detect and initialize devices</li> <li>Initialize registers and primary memory</li> <li>Load the kernel into primary memory</li> </ul> </li> <li>Using the Interrupt Vector Table (of an 8086 processor operating in real mode) shown below, determine the address of the ISR of a device with interrupt vector 42H. </li> </ol> <p>Answer \\(= \\text{4D6EA_H}\\) 9. Differentiate between multi-programming &amp; multi-processing      - Multi-programming means running multiple programs, using only 1 processor      - Multi-processing means running one or more programs, using multiple processors</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#system-call","title":"System Call","text":"<p>It is the way for user instructions to perform priviledged instructions.</p>"},{"location":"3_Core/Operating_Systems/03_Evolution/#virtual-memory","title":"Virtual Memory","text":"<p>Combines primary and secondary memory into a single \u2018logical memory\u2019</p> <p>Load only the required part of a program into primary memory.</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/","title":"04 Process Management","text":""},{"location":"3_Core/Operating_Systems/04_Process_Management/#process","title":"Process","text":"<p>Program in execution</p> <p>Smallest unit of work</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#types","title":"Types","text":"<ul> <li>User processes</li> <li>System processes</li> </ul>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#example","title":"Example","text":"<pre><code>flowchart TB\nP1 --&gt; P2 &amp; P3\n\nP3 --&gt; P4</code></pre>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#interpretations","title":"Interpretations","text":"<ul> <li>\\(P_1\\) spawns \\(P_2\\) and \\(P_3\\), and is their parent</li> <li>\\(P_2\\) and \\(P_3\\) are children of \\(P_1\\)</li> </ul>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#program-vs-process","title":"Program vs Process","text":"Program Process Active? \u274c (Passive) \u2705 Requires resources? \u274c \u2705 Segments required Text (Code) Text (Code)DataStackHeap Type of memory required Secondary Primary"},{"location":"3_Core/Operating_Systems/04_Process_Management/#registers","title":"Registers","text":"Register Pointer? Stores Base register \u2705 Starting address of process in Primary Memory Limit register Length of the process Flag register GPRsGeneral purpose Registers PCProgram Counter \u2705 Address of next instruction to be executed Index pointer \u2705"},{"location":"3_Core/Operating_Systems/04_Process_Management/#memory-layout-of-a-process","title":"Memory Layout of a Process","text":"Segment Stores Text Code Data Global variables Stack - Function Calls- Return address arguments- Local variables Heap - Dynamic data- Data structures in memory"},{"location":"3_Core/Operating_Systems/04_Process_Management/#process-state-transition-diagram","title":"Process State Transition Diagram","text":""},{"location":"3_Core/Operating_Systems/04_Process_Management/#5-state","title":"5-State","text":"<p>In very early systems that didn\u2019t have virtual memory</p> <pre><code>flowchart LR\nNew --&gt;\n|Admit| Ready --&gt;\n|Dispatch| Run --&gt;\n|Exit| Terminate\n\nRun ----&gt; |1. Timer Interrupt&lt;br /&gt;2. Higher-Priority Process pre-empts| Ready\n\nRun --&gt;\n|I/O&lt;br/&gt;Request| b[Blocked/&lt;br/&gt;Wait] --&gt;\n|I/O&lt;br/&gt;Complete| Ready</code></pre> <p>Jobs are picked by job scheduler and CPU scheduler</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#new-to-ready","title":"New \\(\\to\\) Ready","text":"<p>Promoting a program into a process has some work associated with it for the OS</p> <ul> <li>Creates PCB</li> <li>Address space</li> </ul> <p>(I missed some points)</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#7-state-virtual-memory","title":"7-State (Virtual Memory)","text":"<p>Further explanation has been uploaded on LMS</p> <p>Similar to 5-State, but has 2 more states</p> <ul> <li>Blocked suspended: Wait for I/O or event; kept in secondary memory</li> <li>Ready Suspended: Wait for CPU but kept in secondary memory</li> </ul>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#equivalent-names","title":"Equivalent Names","text":"<ul> <li>Activate = Swap-in</li> <li>Suspend = Swap-out</li> </ul> <pre><code>flowchart LR\nws[Wait&lt;br/&gt;Suspended]\nrs[Ready&lt;br/&gt;Suspended]\n\nNew -----&gt;\n|Admit| Ready --&gt;\n|Dispatch| Run --&gt;\n|Exit| Terminate\n\nRun ---&gt; |1. Timer Interrupt&lt;br /&gt;2. Higher-Priority Process pre-empts| Ready\n\nRun --&gt;\n|I/O&lt;br/&gt;Request| b[Blocked/&lt;br/&gt;Wait] --&gt;\n|I/O&lt;br/&gt;Complete| Ready\n\nrs --&gt;|Activate| Ready --&gt;|Suspend| rs\n\nws --&gt;|I/O&lt;br/&gt;Complete| rs\n\nws --&gt; |Activate| b --&gt; |Suspend| ws\n\nNew --&gt;|Preloading| rs</code></pre>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#wait-to-wait-suspended-state","title":"Wait \\(\\to\\) Wait Suspended State","text":"<ol> <li>In case all processes are in wait state (let\u2019s say all are waiting for I/O)</li> <li>OS shifts some waiting processes into wait suspended queue (in secondary memory)</li> <li>Then, the OS brings in programs from the Job Queue (in secondary memory), and loads them into primary memory.</li> <li>There is ready and wait processes, but there isn\u2019t enough primary memory available</li> <li>So the OS shifts some waiting processes into wait suspended queue (in secondary memory) to free up some primary memory</li> </ol>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#run-to-ready-suspended","title":"Run \\(\\to\\) Ready Suspended","text":"<ul> <li>Processes in the ready or running state but are swapped out of main memory and placed in the disk </li> <li>The process will transition back to ready state whenever the process is again brought onto the main memory</li> </ul>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#new-to-ready_1","title":"New \\(\\to\\) Ready","text":"<p>PCB address space</p> <p>Just-in Time process</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#new-to-ready-suspended","title":"New \\(\\to\\) Ready Suspended","text":"<p>Pre-emptive computations are performed</p> <p>PCB, address space are generated before-hand</p> <p>Some designers think it is necessary, others argue otherwise</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#pcbtcb","title":"PCB/TCB","text":"<p>Process/Task Control Block</p> <p>It stores the Context of a Process</p> <p>Whenever CPU requires details on any process, it will refer to PCB</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#context-of-a-process","title":"Context of a Process","text":"<ul> <li>State</li> <li>Process id \\(\\to\\) unique number</li> <li>PC</li> <li>Register Contents<ul> <li>Flag</li> <li>Index Pointer</li> <li>GPRs (General Purpose Registers)</li> </ul> </li> <li>CPU Scheduling info<ul> <li>Priority no</li> <li>Scheduling info</li> <li>Pointer to scheduling queues</li> </ul> </li> <li>Memory management info<ul> <li>Base register</li> <li>Limit register</li> <li>Virtual memory</li> <li>Page Table, Segment Table</li> </ul> </li> <li>Accounting info<ul> <li>Amt of CPU Time used</li> </ul> </li> <li>I/O Info<ul> <li>I/O devices alloted</li> <li>List of open file(s)</li> </ul> </li> </ul>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#context-switching","title":"Context Switching","text":"<p>Whenever there is a switch from one process to another, the OS</p> <ol> <li>saves/stores the context of the previous process</li> <li>loads/restores the context of the current process</li> </ol> <p>The \u2018process\u2019 can be a program/interrupt service routine; this interrupt can be Maskable/Non-Maskable Interrupt</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#context-switch-time","title":"Context-Switch Time","text":"<p>This is an overhead, as it is not \u2018useful work\u2019 and is just \u2018book-keeping\u2019.</p> <p>Depends on</p> <ul> <li>architecture of the system</li> <li>amount of \u2018context\u2019 information that is required to be stored/loaded</li> </ul>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#process-scheduler","title":"Process Scheduler","text":"Job Scheduler CPU Scheduler Mid-Term Type Long-Term Short-Term Medium-Term Executing Frequency \\(\\downarrow\\) \\(\\uparrow\\)(CPU Burst is faster) Task Selects processes to be loaded into Ready Queue Allocates process from ready queue \\(\\to\\) CPU Swap-InSwap-Out Goal Ensure good mix of CPU-Bound and I/O-Bound operationsControls degree of multi-programming Ensure max CPU-utilization Modify degree of multiprogramming"},{"location":"3_Core/Operating_Systems/04_Process_Management/#medium-term-scheduler-flowchart","title":"Medium Term Scheduler Flowchart","text":""},{"location":"3_Core/Operating_Systems/04_Process_Management/#degree-of-multi-programming","title":"Degree of multi-programming","text":"<p>No of programs kept in primary memory</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#cpu-io-bound","title":"CPU-I/O Bound","text":"CPU-Bound I/O-Bound Process spends most of its time with CPU Process spends most of its time in I/O operations Short burst time Long burst time"},{"location":"3_Core/Operating_Systems/04_Process_Management/#overhead","title":"Overhead %","text":"<p>% time spent on scheduling decision</p> \\[ \\begin{aligned} &amp;\\text{Overhead} \\% \\\\ &amp;= \\frac{\\text{Scheduling Decision Time}}{\\text{Process Execution Time} + \\text{Scheduling Decision Time}} \\times 100 \\% \\end{aligned} \\] <p>We want to minimize this.</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#queues","title":"Queues","text":"<p>Each queue has queue header containing pointers to the first and last PCBs of list</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#job-queue","title":"Job Queue","text":"<p>set of all processes in system</p> <p>stored in secondary memory</p> <p></p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#ready-queue","title":"Ready Queue","text":"<p>Processes that are ready to execute</p> <p>Stored in primary memory</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#device-queue","title":"Device Queue","text":"<p>Set of processes waiting for I/O device</p>"},{"location":"3_Core/Operating_Systems/04_Process_Management/#queuing-diagram","title":"Queuing Diagram","text":"<p>Represents queues, resources and the corresponding flows</p> <p>Very similar to state transition diagram, but the focus is on the queues</p> <pre><code>flowchart LR\njq[[Job Queue]] --&gt;\n|Admit| rq[[Ready Queue]] --&gt;\n|Dispatch| p[(CPU)] --&gt;\n|Release| r(( ))\n\np --&gt; |Time-Out| rq\n\np --&gt;\n|I/O| bq[[Device Queue]] --&gt;\nrq</code></pre>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/","title":"05 CPU Scheduling","text":""},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#cpu-scheduling","title":"CPU Scheduling","text":"<p>Note that in this course, we are neglecting the effect of context switch. In reality, context switch time is around \\(5 \\micro s\\)</p> <ul> <li>Wait \\(\\to\\) Ready<ul> <li>Higher priority process enters Ready Queue</li> </ul> </li> <li>Current Process in the CPU goes to wait state</li> <li>Current process terminates</li> <li>Current process is timed-out</li> </ul> <pre><code>flowchart LR\nNew --&gt;\nReady --&gt;\nRunning --&gt;\nTerminates\n\nRunning --&gt;\nWaiting --&gt;\nReady</code></pre>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#pre-emptive-scheduling","title":"Pre-Emptive Scheduling","text":"<p>Re-evaluate the schedule every time a new process enters the ready queue.</p> <p>Usually you evaluate the schedule every time a process completes its quanta(will be explained below)/or completely executes</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#dispatcher","title":"Dispatcher","text":"<p>Gives control of CPU to the process selected by CPU-Scheduler</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#functions","title":"Functions","text":"<ul> <li>Context Switch</li> <li>Switch to the user mode</li> <li>Jumping to correct location of user program\u2019s for restarting it</li> </ul>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#dispatch-latency","title":"Dispatch Latency","text":"<p>Time between stopping one process and starting another process, including context switch time</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#sheduling-criteria","title":"Sheduling Criteria","text":"Criteria Goal is to max/min? CPU UtilizationAmount of time CPU is used \\(\\uparrow\\) Throughput \\(\\uparrow\\) Response Time \\(\\downarrow\\)"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#times","title":"Times","text":"Time Meaning Formula Arrival Time Time at which process arrived (duh) Burst Time Duration of CPU execution required for a process End Time/Completion Time Time at which process has completed entire execution (not duration)\ud83d\udca1 Tip for questions- Find the latest instance of the process in the Gantt chart- That end time is the end time of the process Turnaround Time Duration to complete execution, ie time between job submitted and final result obtained- Waiting time to enter memory- Waiting time in ready queue- Time to execute- Time to perform I/O operations EndTime - ArrivalTime Wait Time(to be minized) Duration spent waiting for complete execution TurnAroundTime - BurstTime Average Wait Time Avg of wait times of all processesWe can reduce this by shifting the more time-consuming processes to later"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#cpu-scheduling-algorithms","title":"CPU Scheduling Algorithms","text":""},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#fcfs","title":"FCFS","text":"<p>First-Come-First-Serve</p> <p>Simple</p> <p>Ready Queue = FIFO Queue</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#properties","title":"Properties","text":"<ul> <li>Non-interactive<ul> <li>Not applicable for time-sharing systems</li> </ul> </li> <li>Non-Preemptive Scheduling</li> <li>High average waiting time</li> <li>Convey effect?   Many times resources are idle<ul> <li>CPU</li> <li>I/O devices</li> </ul> </li> </ul>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#sjf","title":"SJF","text":"<p>Shortest Job First</p> <p>Pick the process with the lowest CPU remaining burst time (at the moment of scheduling)</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#types","title":"Types","text":"<ul> <li> <p>**Preemptive **(SRTF)   Shortest remaining time first (makes sense for partially-executed programs)</p> <ul> <li>Reschedule every time a new task enters ready queue</li> </ul> </li> <li> <p>Non-Preemptive</p> <ul> <li>Only prioritize once a process is completed</li> </ul> </li> </ul>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#priority-scheduling","title":"Priority Scheduling","text":"<p>Processes are scheduled based on a priority number alone (Burst time not involved in the scheduling calculation)</p> <p>Priority number is assigned to every process, which is an integer value within a fixed range</p> <ul> <li>Some implementations take \\(0\\) as highest priority</li> <li>Some implementations take \\(0\\) as low priority</li> </ul> <p>In this course, smallest number \\(=\\) highest priority, unless specified otherwise.</p> <p>Equal priority processes are scheduled in FCFS order</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#types_1","title":"Types","text":"<ul> <li>Preemptive</li> <li>Non-Preemptive</li> </ul>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#priority","title":"Priority","text":"<p>In our questions, it will be given.</p> <p>However, in real world, it is based on</p> <pre><code>flowchart TB\ns((Start)) --&gt;\nInternal &amp; External\n\nInternal --&gt;\nResources --&gt;\nc[CPU Time] &amp; o[Open File] &amp; Memory\n\nExternal --&gt;\nImportance &amp; f[\"Funds&lt;br&gt;(Payment for Cloud-Computing)\"]</code></pre>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#starvation","title":"\u274c Starvation","text":"<p>Low priority processes may never execute</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#solution-aging","title":"Solution: Aging","text":"<p>Increase the priority of processes, as time progresses</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#round-robin","title":"Round Robin","text":"<p>Basically pre-emptive FCFS</p> <p>Used in Time Sharing systems</p> <p>Also called as \u2018Fair-Share Scheduling\u2019</p> <p>CPU Time is divided into small units, called as time slice/quanta</p> <p>Ready Queue is actually a circular queue</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#working","title":"Working","text":"<ol> <li>Scheduler runs</li> <li>Picks process at the <code>Head</code> of the queue</li> <li>Dispatcher runs</li> <li>Timer is set (equal to time quanta)</li> <li>Timer interrupt (time-out/time quanta expires)</li> <li>Process moves to the <code>Tail</code> of the queue</li> <li><code>Head</code> pointer now points to the next process</li> </ol> <p>If there are \\(n\\) processes in the ready queue and the time quantum is \\(q\\), the each process gets \\(\\frac{1}{n}\\) of the CPU time in chunks of atmost \\(q\\) time units at once.</p> <p>No process waits more than \\((n-1) q\\) time units</p> <ul> <li>\u274c Higher average waiting time than SJF</li> <li>\u2705 Lower response time than SJF</li> </ul>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#value-of-q","title":"Value of \\(q\\)","text":"<p>We need to choose \\(q\\) in a reasonable way</p> \\(q\\) Behaves like Solution Too large FCFS Dec \\(q\\) Too small too many context switches Inc \\(q\\)\\(q\\) must be large with respect to context switch timeotherwise overhead is too high; more time will be spent on context switching rather than actual execution"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#example","title":"Example","text":"<p>Assume time quantum is 20ms, and all the processes arrive at time 0.</p> Process Burst Time Turn-Around Time WT \\(P_1\\) \\(53\\) 134 81 \\(P_2\\) \\(17\\) 37 20 \\(P_3\\) \\(68\\) 162 94 \\(P_4\\) \\(24\\) 121 97 Avg \\(\\to\\) 113.5 73 <pre><code>gantt\ndateFormat x\naxisFormat %L\ntitle CPU\n\nP1: 0, 20\nP2: 20, 37\nP3: 37, 57\nP4: 57, 77\n\nP1: 77, 97\nP3: 97, 117\nP4: 117, 121\n\nP1: 121, 134\nP3: 134, 162</code></pre>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#multi-level-queuing","title":"Multi-Level Queuing","text":"<ol> <li>Maintain one ready queue for each type of process</li> <li> <p>Process are usually classified into different types, using one of the following methods</p> <ul> <li> <p>Method 1</p> </li> <li> <p>foreground process</p> </li> <li>interactive</li> <li> <p>require quick response time</p> </li> <li> <p>background process</p> </li> <li> <p>batch process</p> </li> <li> <p>Method 2</p> </li> <li> <p>Real-Time Process</p> </li> <li> <p>System Process</p> </li> <li> <p>Interactive Process</p> </li> <li> <p>Batch Process</p> </li> <li>Assign fixed priorities to each queue</li> <li>Apply an appropriate within-queue scheduling algo</li> <li>Apply an appropriate between-queue scheduling algo</li> <li>Fixed-priority pre-emptive scheduling</li> <li>Entry of a new process into a higher priority queue will cause pre-emption</li> <li>The higher priority ones have short burst time, so no need to worry about user delay</li> <li>Low-priority queues do not execute unless higher priority queues are empty</li> <li> <p>Hence, there is possibility of starvation of batch processes</p> </li> <li> <p>Time Slice Scheduling</p> </li> <li>Round Robin between queues</li> <li>Each group is given a certain amount of CPU Time</li> <li>For eg</li> <li>Real-Time = 40% of CPU Time</li> <li>System = 30% of CPU Time</li> <li>Interactive = 20% of CPU Time</li> <li>Batch = 10% of CPU Time</li> </ul> </li> </ol>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#multilevel-feedback-queue","title":"Multilevel Feedback Queue","text":"<p>Move between queues</p> <p>Kind of pre-emptive scheduling, as process from low priority queue is pre-empted when a process enters any of the high priority queues</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#aim","title":"Aim","text":"<p>Separate processes based on CPU Burst Time</p>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#working_1","title":"Working","text":"<p>Favors (gives high priority to) I/O-bound and interactive processes</p> <ul> <li>Small CPU burst time \\(\\to\\) High priority</li> <li>Long CPU burst time \\(\\to\\) Low priority</li> </ul> <p>In case of starvaton, process from low priority queue moves to a high priority queue (Aging)</p> <p>In case of any pre-emption, the round robin timer won\u2019t reset</p> <ul> <li>For eg, if a process in \\(Q_1\\) has executed for 4ms out of 8ms time quanta, and it gets pre-empted by a process in \\(Q_0\\)</li> <li>When we get back to \\(Q_1\\), we continue from 4ms (not reset to 0)</li> </ul>"},{"location":"3_Core/Operating_Systems/05_CPU_Scheduling/#components","title":"Components","text":"<p>3 Queues</p> <pre><code>flowchart LR\n\nStart((Start))\nFinish((Finish))\n\nStart --&gt;\nq0[[\"Q0&lt;br&gt;(q = 8ms)\"]] --&gt;\n|\"Incomplete&lt;br /&gt;\u274c\"| q1[[\"Q1&lt;br /&gt;(q = 16 ms)\"]] --&gt;\n|\"Incomplete&lt;br /&gt;\u274c\"| q2[[\"Q2&lt;br /&gt;FCFS\"]]\n\nq0 &amp; q1 &amp; q2 --&gt;|\"Complete&lt;br /&gt;\u2705\"| Finish\n\nclassDef queue fill: teal, color: orange, font-weight: bold\nclass q0,q1,q2 queue</code></pre>"},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/","title":"06 Realtime CPU Scheduling","text":""},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/#realtime-systems","title":"Realtime Systems","text":"<p>Realtime processes exist along normal processes, and their tasks are of higher priority \\(\\implies\\) Latency should be minimized</p> <p>In this course, we are assuming that all realtime tasks are periodic, ie task repeats itself at regular intervals of time</p>"},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/#types-of-realtime-systems","title":"Types of Realtime Systems","text":"Soft Realtime System Hard Realtime System Strict deadline constraints? \u274c \u2705 Deadline miss leads to Degradation in performance failure/destruction Bounded Latency? \u274c \u2705 Example Streaming Video Robots in medical treatmentAutomated chemical plantAuto-missile system"},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/#types-of-latency","title":"Types of Latency","text":"<ul> <li>Interrupt latency</li> <li>Dispatch latency</li> <li>Event latency</li> </ul>"},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/#terms","title":"Terms","text":"Term Symbol Meaning Execution Time \\(t\\) Time taken for a process to complete execution Time Period \\(p\\) The interval at which the process has to repeat itself(not like time quanta in Round Robin) Deadline \\(d\\) Time constraint for execution time \\(:d \\le p\\)In this course, we are assuming that \\(d = p\\) Processor Utilization \\(U\\) Fraction of utilization of available processor resources\\(U = \\sum\\limits_{i=1}^n \\frac{t}{p}\\), where \\(n=\\) number of tasks"},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/#scheduling-algorithms","title":"Scheduling Algorithms","text":"<p>Algorithms to complete a set of \\(n\\) tasks, using a single processor, such that</p> <ul> <li>\\(d=p\\)</li> <li>\\(t =\\) constant</li> </ul> <p>CPU utilization is not always 100%. It is bounded to a limit, based on number of tasks in system</p> RMS/RMA EDF Full Form Rate-Monotic Scheduling Algorithm Earliest Deadline First Priority-Based \u2705 \u2705 Priority Type Static Dynamic High Priority for task with __ Shortest Period Earliest Deadline Schedulability Condition(s) - Test of Schedulability- Test of Maximum CPU Utilization Bound - Test of Schedulability (Necessary &amp; Sufficient Condition) Requirement Tasks must announce their deadlines to scheduler, when it becomes runnable"},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/#3-cases","title":"3 Cases","text":"\\(U_\\text{tot}\\) RMS Schedulable? EDF Schedulable? \\(&gt; 1\\) \u274c \u274c \\(\\le U_\\text{max}\\) \u2705 \u2705 \\(U_\\max &lt; U_\\text{tot} &lt; 1\\) Inconclusive(Draw Realtime Scheduling Gantt Chart) \u2705"},{"location":"3_Core/Operating_Systems/06_Realtime_CPU_Scheduling/#testing-methods","title":"Testing Methods","text":"Test Check Test of Schedulability \\(U_\\text{tot} \\le 1\\) Test of Maximum CPU Utilization Bound(aka upper bound of schedulability test) \\(U_\\text{tot} \\le n(2^\\frac{1}{n} - 1)\\) Realtime Scheduling Gantt Chart Scheduling the task set using a Gantt chart(If the total time to plot is not given, plot till the LCM of the periods of the processes.)"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/","title":"07 Process Synchronization","text":""},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#types-of-processes","title":"Types of Processes","text":"Independent process Co-operating process Affect other processes \u274c \u2705 Affected by other processes \u274c \u2705 Share code/data with other processes \u274c \u2705"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#process-synchronization","title":"Process Synchronization","text":"<p>is used for orderly execution of cooperating processes that share a logical address space, in concurrent or parallel execution</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#types-of-execution","title":"Types of Execution","text":"Execution Type Meaning Sequential One after another Asynchronous (Not in the course) Concurrent Multiple tasks start, run, and complete in overlapping time periods, in no specific order Parallel Multiple tasks or subtasks of the same task that literally run at the same time on a hardware with multiple computing resources like multi-core processor"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#producer-consumer-bounded-buffer-problem","title":"Producer-Consumer / Bounded-Buffer Problem","text":"Parts Role Producer Process Produce an item Consumer Process Consume an item Bounded-Buffer Contains produced items (values, records)Implemented as Circular Array of fixed size"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#bounded-buffer-variables","title":"Bounded-Buffer Variables","text":"Variable Stores Initial Value in location of next item to be written by producer 0 out location of next item to be read by consumer 0 counter number of elements in buffer 0"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#counter-updation","title":"<code>counter</code> Updation","text":"Occurance Counter value Production counter++ Consumption counter--"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#counter-cases","title":"<code>counter</code> Cases","text":"<code>counter</code> Value __ is Blocked because buffer is Problem \\(= 0\\) Consumer empty Busy Waiting Buffer_Size Producer full(buffer content has not yet been consumed)"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#interlockedinterleaved-schedule","title":"Interlocked/Interleaved Schedule","text":""},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#busy-waiting","title":"Busy Waiting","text":"<p>consumes CPU cycles but no work is done</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#race-condition","title":"Race Condition","text":"<p>Situtation when several processes access and manipulate shared data concurrently.</p> <p>Final value of shared data depends on the final write operation</p> <p>To prevent race condition, concurrent processes must be synchronized</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#critical-section-problem","title":"Critical-Section problem","text":"<p>\\(n\\) cooperating processes all competing to use some shared data</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#critical-section","title":"Critical-Section","text":"<p>Section where shared data is accessed/modified.</p> <p>For producer-consumer problem, <code>counter++</code> and <code>counter--</code> are the critical section</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#requirement","title":"Requirement","text":"<p>Avoid data inconsistency</p> <p>When one process is ints critical section, another process should not be alowed to enter its critical section</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#task","title":"Task","text":"<p>Design protocol/algorithms which cooperating processes can use to cooperate, ensuring that the requirement is satisfied</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#structure","title":"Structure","text":"<p>Assume a process \\(P\\) is executing indefinitely</p> <pre><code>do\n{\n  entry_section\n    critical_section\n  exit_section\n    remainder_section\n} while (1);\n</code></pre> Section Role Entry Gain access to criticial section/resourceEnsures that only a selected number of processes are in its critical section Critical Code that affects common memory location Exit Relinquish access to criticial section/resourceAllows other process to enter their critical section Remainder"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#solution","title":"Solution","text":"Solution Mutual Exclusion If process \\(P_i\\) is executing in its critical section, no other processes can be executing in their critical sections Progress If no process is executing in its critical section, and \\(\\exists\\) some processes that wish to enter their critical section, then the selection of the processes that will enter the critical section next cannot be postponed indefinitely Bounded waiting Bound must exist on the number of times that other processes are allowed to enter their critical sections after a process has made a request to enter its critical section before that request is granted"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#semaphores","title":"Semaphores","text":"<p>Synchronization Tool/Construct</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#purpose","title":"Purpose","text":"<ul> <li>Solve critical section problem</li> <li>Guard access to shared resource</li> </ul>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#parts","title":"Parts","text":"<ul> <li> <p>Value</p> </li> <li> <p>Queue of process that are waiting on it</p> </li> <li> <p>2 operations/methods associated with it   atomic/indivisible - These operations cannot be interrupted</p> </li> </ul> Operation <code>wait(s)</code> <code>signal(s)</code> Alternate Name P(s) V(s) Purpose used by process to gain access to critical section/access to shared resource used by process to inform that it has completed access of critical region/using the shared resource Steps - dec value of semaphore- check safety for process to enter critical section - inc value of semaphore- check if semaphore value \\(\\le 0\\), or if any process is waiting WhenOutput  = Yes Process enters critical region WhenOutput  = No Process added to queue of process waiting for this semaphore <p>The number of process that are waiting in the semaphore queue</p> \\[ = |\\text{Semaphore Value}| \\\\ \\Big(\\text{Value} \\iff &lt; 0 \\Big) \\]"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#implementation-of-counting-semaphore","title":"Implementation of Counting Semaphore","text":"<pre><code>typedef struct\n{\n  int value;\n  Queue of processes;\n} Sephamore;\n</code></pre> <p>Assume 2 operations</p> <ul> <li><code>block()</code> suspends the process that invokes it<ul> <li>Moves the process from run state \\(\\to\\) blocked/wait state</li> <li>Control is transferred to CPU scheduler, which then schedules another process instead</li> </ul> </li> <li><code>wakeup(P)</code> resumes the execution of a blocked process \\(P\\)<ul> <li>Moves the process from blocked/wait state \\(\\to\\) ready state</li> </ul> </li> </ul> <pre><code>P1\n{\n  wait(s);\n  access printer;\n  signal(s);\n}\n\nP2\n{\n  wait(s);\n  access printer;\n  signal(s);\n}\n</code></pre>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#wait-operation","title":"<code>wait()</code> Operation","text":"<pre><code>void wait(Semaphore s)\n{\n  s.value--;\n\n  if(s.value &lt; 0)\n  {\n    // Semaphore is unavailable\n    // process cannot access critical region\n\n    add this process to s.queue;\n    block();\n  }\n\n  // Semaphore available\n  // Process gains access to critical region\n}\n</code></pre>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#for-binary-semaphore","title":"For binary semaphore","text":"<pre><code>void wait(Semaphore s)\n{ \n  if(s.value == 1)\n  {\n        // Semaphore available\n        // Process gains access to critical region\n\n\n    s.value = 0;\n  }\n  else\n  {\n    // Semaphore is unavailable\n    // process cannot access critical region\n\n    add this process to s.queue;\n    block();\n  }\n}\n</code></pre>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#signal-operation","title":"<code>signal()</code> Operation","text":"<pre><code>void signal(Semaphore s)\n{\n  s.value++;\n  if(s.value &lt;= 0)\n  {\n    // processes are waiting\n    // pick up a process\n\n    remove process from s.queue;\n    wakeup(P);\n  }\n\n  // no processes are waiting for this semaphore\n\n}\n</code></pre> <pre><code>void signal(Semaphore s)\n{\n  if( s.queue.isempty()  )\n  {\n    // no processes are waiting for this semaphore\n      s.value = 1;\n  }\n  else\n  {\n    // processes are waiting\n    // pick up a process\n\n    remove process from s.queue;\n    wakeup(P);      \n  }\n\n}\n</code></pre>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#solution-for-bounded-buffer-problem-using-semaphores","title":"Solution for bounded buffer problem using semaphores","text":"<p>Use 3 semaphores</p> Semaphore Initial value Producer produces a process 0 means 1 means \\(n\\) means Empty Keep track of free buffers \\(n\\) <code>wait()</code> Buffer full Buffer empty Full Keep track of full buffers 0 <code>signal()</code> Buffer empty Buffer full Mutex**Mut**ual-**ex**clusion Ensures exclusive access to buffer pool (binary) Access to buffer pool not possible Access to buffer pool possible N/A <p>This solution prevents Busy Waiting</p>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#producer-process","title":"Producer process","text":"<pre><code>do\n{\n  // produce an item in next_produced\n\n  wait(empty);\n  // check if buffer pool has empty buffer. if yes, then proceed else it waits.\n  // avoids busy waiting\n\n  wait(mutex); // gain access to buffer pool\n\n  // add next_produced to buffer\n\n  signal(mutex); // gives control to buffer pool\n  signal(full); // increment value of full\n\n} while (1);\n</code></pre>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#consumer-process","title":"Consumer Process","text":"<pre><code>do\n{\n  // item next_consumed;\n\n  wait(full);\n  // check if buffer is empty. if true, process blocks\n  // avoids busy waiting\n\n  wait(mutex); // exclusive access buffer pool\n\n  // remove item from buffer to nextconsumed\n\n  signal(mutex);\n  signal(empty); // increment value of empty\n\n  // consume item in next_consumed\n\n} while(1);\n</code></pre>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#readers-writers-problem","title":"Readers-Writers Problem","text":"Meaning Reader Process Reads from shared resource Writer Process Reads and/or writes from shared resource"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#problem-statement","title":"Problem Statement","text":"<p>Multiple readers can access shared resource</p> <p>Only 1 writer can have exclusive access to shared resource</p> Process 1 Process 2 Read \u2705 Read Read \u2705 Read Write \u274c Write \u2705 Write Read \u274c Write Write \u274c"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#variables","title":"Variables","text":"<code>readcount</code> <code>mutex</code> <code>rw_mutex</code> data type integer binary semaphore binary semaphore Purpose Keep track of number of readers accessing shared resource @ a timeGive access to first readerRelinquish access after last reader Control access to <code>readcount</code> Control access to shared resource Used by N/A Readers 1<sup>st</sup> reader - gain exclusive access <code>wait(rw_mutex)</code>Last reader - relinquish access <code>signal(rw_mutex)</code>All writers <code>wait(rw_mutex)</code>, <code>signal(rw_mutex)</code> initial value 0 1 1 when a reader/writer accesses the shared resource inc 0 0 when a reader/writer finishes reading dec 1 1"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#writer-process","title":"Writer Process","text":"<pre><code>do\n{\n  // entry section\n  wait(rw_mutex);   // gain exlclusive access by this writer process to shared resource\n\n  // critical section\n  // perform read and/or write operation\n\n\n  // exit section\n  signal(rw_mutex); // relinquish access by this writer process to shared resource\n\n} while(1);\n</code></pre>"},{"location":"3_Core/Operating_Systems/07_Process_Synchronization/#reader-process","title":"Reader Process","text":"<pre><code>do\n{\n  wait(mutex); // exclusive access to readcount\n\n  readcount++;\n  if(readcount == 1) // 1st reader\n    wait(rw_mutex); // gain exclusive access by all readers to shared resource\n\n    signal(mutex); // relinquish access to readcount\n\n  // read from shared resource\n\n  wait(mutex); // exclusive access to readcount\n\n  readcount--; \n  if(readcount == 0) // last reader\n    signal(rw_mutex); // relinquish access by all readers to shared resource\n  signal(mutex); // relinquish access to readcount\n\n} while(1);\n</code></pre>"},{"location":"3_Core/Operating_Systems/08_Deadlock/","title":"08 Deadlock","text":""},{"location":"3_Core/Operating_Systems/08_Deadlock/#types-of-resources","title":"Types of Resources","text":"Preemptable Resource Non-Preemptable Resource Can be removed from process without causing computation fail Once allotted to a process, it cannot be removed from a process unless the process relinquishes the resource by itself Example Primary Memory can be swapped out Printers"},{"location":"3_Core/Operating_Systems/08_Deadlock/#necessary-conditions-for-deadlocks","title":"Necessary conditions for Deadlocks","text":"Condition Meaning Mutual-exclusion Only one process can use a resource at a time Hold &amp; Wait A process holding at least one resource is waiting to acquire additional resources held by other processes (hence causing a wait) Non-Preemptive resources A resource can be released only voluntarily by the process holding it, after that process has completed its task. Circular Wait There exists a set {P0, P1, \u2026, Pn} of waiting processes such that P0 is waiting for a resource that is held by P1, P1 is waiting for a resource that is held by P2, \u2026, Pn\u20131 is waiting for a resource that is held by Pn, and Pn is waiting for a resource that is held by P0."},{"location":"3_Core/Operating_Systems/08_Deadlock/#rag","title":"RAG","text":"<p>Resource Allocation Graph</p> <p>Directed graph that how processes and resources are related</p> Symbol Meaning Circle Process Rectangle with circles Resource Type with instances Edges Request Edge (process \\(P_i\\) requests resource \\(R_j\\)) \\(P_i \\to R_j\\) Assignment Edge (resource \\(R_j\\) is alloted to \\(P_i\\)) \\(R_j \\to P_i\\)"},{"location":"3_Core/Operating_Systems/08_Deadlock/#checking-deadlock","title":"Checking deadlock","text":"Cycle exists? Instances of each resource type \\(\\implies\\) Deadlock exists? \u274c N/A \u274c \u2705 1 \u2705 \u2705 Multiple Inconclusive"},{"location":"3_Core/Operating_Systems/08_Deadlock/#disadvantage","title":"Disadvantage","text":"<p>Inconclusive for the 3<sup>rd</sup> case</p>"},{"location":"3_Core/Operating_Systems/08_Deadlock/#bankers-algo-for-deadlock-detection","title":"Banker\u2019s Algo for Deadlock Detection","text":"<p>It is an algorithm which is implemented as a system process in the OS</p> <p>In this section, processes are referring to user processes</p> <p>Let</p> <ul> <li>\\(n =\\) No of processes</li> <li>\\(m =\\) No of resources</li> </ul> Dimension Meaning Initial value MaxMatrix \\(n \\times m\\) Maximum resource requirement of each type by every process AllocationMatrix \\(n \\times m\\) Total number of resources of each type that is currently allocated to each process NeedMatrix \\(n \\times m\\) Denotes the number of resources of each resource type that are yet to be allocated to a process AvailableVector \\(m\\) Total no of instances of each resource type that is available WorkVector \\(m\\) No of instances of each resource type that is currently available Work = Available FinishVector \\(n\\) Denotes the completion status of each process False RequestVector for process \\(i\\) \\(m\\) No of instances of each type of resource that process \\(i\\) requests \\[ \\text{Need}[i][j] = \\text{Max}[i][j] - \\text{Allocation}[i][j] \\\\ i \\in [1, n],\\\\ j \\in [1, m] \\]"},{"location":"3_Core/Operating_Systems/08_Deadlock/#vector-comparison","title":"Vector Comparison","text":"<p>Let \\(X, Y\\) be 2 vectors</p> \\[ X \\le Y \\iff X[i] \\le Y[i], \\\\ \\forall i \\in \\text{len}(X) = \\text{len}(Y) \\\\ (0, 0, 0) \\le (0, 0, 1) \\\\(0, 1, 0) \\not \\le (0, 0, 1) \\] <p>Every element of \\(X\\) should be smaller than/equal to every corresponding element of \\(Y\\)</p>"},{"location":"3_Core/Operating_Systems/08_Deadlock/#algorithm","title":"Algorithm","text":"<ol> <li> <p>Initialize all vectors</p> </li> <li> <p>Find process \\(i\\) with</p> </li> <li> <p>Finish[i] = <code>False</code></p> </li> <li>Need[i] \\(\\le\\) Work</li> </ol> <p>If we can\u2019t find, go to step 4</p> <ol> <li> <ul> <li>Work = Work + Allocation[i]</li> <li>Finish[i] = True</li> <li>Go to step 2</li> </ul> </li> <li> <p>If finish[i]==True \\(\\forall i\\), the system is in a safe state</p> </li> </ol>"},{"location":"3_Core/Operating_Systems/08_Deadlock/#safe-sequence","title":"Safe Sequence","text":"<p>You may get multiple valid safe sequences for the same list of process</p>"},{"location":"3_Core/Operating_Systems/08_Deadlock/#resource-request-algorithm","title":"Resource-Request Algorithm","text":"<p>Consider a Request[i] vector for process \\(P_i\\)</p> <ol> <li> <p>Check if Request[i] \\(\\le\\) Need[i]</p> <ul> <li>if true, got to step 2</li> <li>else, raise error condition that \\(P_i\\) has requested more than it needs</li> </ul> </li> <li> <p>Check if Request[i] \\(\\le\\) Available[i]</p> </li> <li> <p>if true, go to step 3</p> </li> <li> <p>else, \\(P_i\\) must wait, as resources are not available</p> </li> <li> <p>Pretend to allocate requested resources to \\(P_i\\), by modifying the states as follows</p> </li> </ol> <pre><code>Available -= Request[i]\nAllocation[i] += Request[i]\nNeed[i] -= Request[i]\n</code></pre> <ol> <li> <p>Run the safety algo to check if the system is in a safe state</p> <ul> <li>If safe, resources are allocated to \\(P_i\\)</li> <li>else, \\(P_i\\) must wait and the old resource-allocated state is restored</li> </ul> </li> </ol>"},{"location":"3_Core/Operating_Systems/08_Deadlock/#deadlock-handling","title":"Deadlock Handling","text":"Deadlock Avoidance Deadlock Prevention Deadlock Detection &amp; Recovery"},{"location":"3_Core/Operating_Systems/08_Deadlock/#deadlock-detection","title":"Deadlock Detection","text":"<p>Almost exactly the same as Banker\u2019s; just that this has request instead of need.</p> <ol> <li> <p>Initialization</p> </li> <li> <p>Let <code>work = available</code></p> </li> <li> <p>Check if \\(\\text{allocation}[i] \\ne 0\\)</p> <ol> <li>true \\(\\implies\\) set finish[i] = false</li> <li>false \\(\\implies\\) set finish[i] = true</li> </ol> </li> <li> <p>Find \\(i\\) such that</p> </li> <li> <p>Finish[i] = false</p> </li> <li>request[i] \\(\\le\\) work</li> </ol> <p>If not found, go to step 4</p> <ol> <li> <p>Work = Work + Allocation    Finish[i] = true    Go to step 2</p> </li> <li> <p>If finish[i] == false, for some \\(i \\implies\\) system is in deadlock state    or, in other words, there is no deadlock if</p> <ul> <li>all the finish[i] = false \\(\\forall i\\)</li> <li>we are able to derive a safe sequence with all the processes, then there is no deadlock</li> </ul> </li> </ol>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/","title":"09 Memory Management","text":""},{"location":"3_Core/Operating_Systems/09_Memory_Management/#address","title":"Address","text":"Address Logical (Virtual) Address generated by CPU Physical Address seen by memory unit(one loaded into memory address register)"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#address-space","title":"Address Space","text":"Address Space Logical Set of all logical address Physical Set of all physical address"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#types-of-memory-allocation","title":"Types of Memory Allocation","text":"Type 1 chunk of consecutive locations are required? Contiguous \u2705 Non-contiguous \u274c <pre><code>flowchart TB\n\nma[Memory Allocation] --&gt;\nc &amp; nc[Non-Contiguous]\nc[Contiguous] --&gt;\nspa[Single Partion Allocation] &amp; mpa[Multiple partition allocation]\n\nmpa --&gt;\nfsp &amp; dp[Dynamic Partioning]\n\nfsp[Fixed Size Partioning] --&gt;\nes[Equal Sized] &amp; us[Unequal Sized]</code></pre>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#multiple-partition-allocation","title":"Multiple Partition Allocation","text":"<p>When a partition is free, a process is selected from input queue and is loaded to the free partition</p>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#fixed-size-partitions","title":"Fixed Size Partitions","text":"<p>Internal fragmentation = unused memory within a partition</p> <p></p>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#equal-fixed-size-partitions","title":"Equal Fixed Size Partitions","text":"<p>\u274c Program may be much smaller or larger than the size of the partitions</p> <p>\u274c Internal fragmentation = large</p>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#unequal-fixed-size-partitions","title":"Unequal Fixed Size Partitions","text":"<p>\u274c Program may be much smaller or larger than the size of the partitions</p> <p>\u2705 Internal fragmentation is lower than equal partitioning</p>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#dynamic-partitions","title":"Dynamic Partitions","text":"<p>Partitions are created dynamically as process enter and leave main memory</p> <p>Hole is the block of available memory</p> <p>\u274c Causes external fragmentation (multiple holes generated within the memory)</p> <p></p> <p></p>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#allocation-algorithms","title":"Allocation Algorithms","text":"Meaning First-fit Allocate the first hole that is big enough to accomodate Next-fit Allocate the hole immediately after the previously alloted location(Subtype of first-fit) Best-fit Allocate the smallest hole that is big enough to accomodate Worst-fit Allocate the largest hole available"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#compactiondefragmentation","title":"Compaction/Defragmentation","text":"<p>Computationally-expensive, but allows us to reduce external fragmentation</p> <p>Move</p> <ul> <li>allotted partitions beside each other</li> <li>holes beside each other</li> </ul>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#paging","title":"Paging","text":"<p>non-contiguous memory allocation technique</p> <p>To run a program of size \\(n\\) pages, we need to find \\(n\\) free frames and load the pages of the program into the frames</p> <p>used to map/translate logical to physical address</p> <p>Every process has a page table</p> <p>frame size = page size \\(\\in 2^n, n \\in Z\\)</p>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#page-table","title":"Page Table","text":"<p>Indexed by page number</p> <p>Stores the frame number/base address of each page in physical memory</p> <p>No of entries = no of pages</p> Page number(acts as index) Frame no/base address 0 0 1 4 2 2 3 7"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#formulae","title":"Formulae","text":"\\[ \\begin{aligned} &amp; \\text{Total no of logical address (space size) of the paging} \\\\ &amp;= \\text{No of pages } \\times \\text{ Page Size} \\\\ &amp; \\text{Total Physical memory size} \\\\ &amp;= \\text{No of frames} \\times \\text{Frame Size} \\end{aligned} \\] \\[ \\begin{aligned} \\text{Logical memory size} &amp;= 2^\\text{Size of logical address bus} \\\\ \\implies \\text{Size of logical address bus} &amp;= \\log_2 (\\text{Logical memory size}) \\\\ \\text{Physical memory size} &amp;= 2^\\text{Size of physical address bus} \\\\ \\implies \\text{Size of physical address bus} &amp;= \\log_2 (\\text{Physical memory size}) \\end{aligned} \\]"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#address-translation","title":"Address Translation","text":"<p>(Diagram from slides)</p> <ol> <li>Given logical address</li> <li>Get page no and page offset</li> </ol> Page No Page Offset Bits to locate base address of each page in physical memory Bits to combine with base address to define the physical address <ol> <li> <p>Get frame no (stored in the page we just accessed)</p> </li> <li> \\[    \\text{Base address} = \\text{Frame no} \\times \\text{Frame size}    \\] </li> <li> <p>Frame Offset = page offset</p> </li> </ol> Frame No Frame Offset Bits to locate base address of each frame in physical memory Bits to combine with base address to define the physical address <ol> <li> \\[    \\text{Physical address} = \\text{Base Address} + \\text{Frame Offset}    \\] </li> </ol>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#i-missed-something","title":"I Missed Something","text":""},{"location":"3_Core/Operating_Systems/09_Memory_Management/#tlb","title":"TLB","text":"<p>Small, fast-lookup hardware cache called associative memory or translation look-aside buffers (TLBs) are used for implementing Page Table.</p> <p>64 or 128 locations/entries</p> <p>Each entry has 2 parts</p> <ul> <li>key(tag)</li> <li>value</li> </ul> <p>When presented with an item, it is compared with all keys simulatneously for a match</p> <p>If a key is matched, corresponding value is returned</p> <p>Costly but faster</p> <p>TLB Hit, TLB Miss</p>"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#effective-memory-access-time","title":"Effective Memory Access Time","text":"\\[ \\text{EMET } = (\\text{ TLB Hit Ratio } \\times \\text{ Hit Time }) + (\\text{ TLB Miss Ratio } \\times \\text{ Miss Time})} \\] \\[ \\begin{aligned} \\text{Hit Time} &amp;= \\text{Time to search TLB } + &amp; \\text{Time to access memory} \\\\ \\text{Miss Time} &amp;= \\text{Time to search TLB } + &amp; \\textcolor{hotpink}{2 \\times} \\text{Time to access memory} \\\\ \\end{aligned} \\]"},{"location":"3_Core/Operating_Systems/09_Memory_Management/#memory-protection","title":"Memory Protection","text":"<p>We achieve this using memory protection bit in the page table (not TLB)</p> Memory Protection Bit Read-only 0 Read-write 1 <p>Implementation of page table will now be</p> Frame No Memory Protection Bit 0 2 0 1 4 1 2 3 0 3 5 1 <p>Whenever we have a write operation, the OS checks the memory protection bit in the page table</p> <p>If we try to write into a read-only page of the process, we receive a trap (software interrupt) by the OS</p>"},{"location":"3_Core/Operating_Systems/10_Virtual_Memory/","title":"10 Virtual Memory","text":"<p>Only the required page of a process is required to be brought to physical memory; when a page is not required for execution, it is not brought in</p>"},{"location":"3_Core/Operating_Systems/10_Virtual_Memory/#main-usecases","title":"Main usecases","text":"<p>Rarely used features/functions and data structures</p>"},{"location":"3_Core/Operating_Systems/10_Virtual_Memory/#advantages","title":"Advantages","text":"<ul> <li>Size of process is not limited by the size of physical memory (primary)</li> <li>Increased degree of multiprogramming (no of programs that can exist in the primary memory at the same time)</li> <li>Increased CPU utilization</li> <li>Reduced I/O wrt a process, by eliminating unnecessary \u2018swapping-in\u2019</li> </ul>"},{"location":"3_Core/Operating_Systems/10_Virtual_Memory/#page-fault","title":"Page Fault","text":"<p>When a process tries to access a page that exists in memory, execution continues as normal</p> <p>Otherwise, if the process tries to access a page that is marked invalid, this means that the corresponding page is missing</p> <ul> <li>software interrupt (trap) is created</li> <li>bring in required page from secondary memory</li> <li>Store into free frame/Page Replacement</li> <li>Reset page table</li> <li>Restart execution</li> </ul>"},{"location":"3_Core/Operating_Systems/10_Virtual_Memory/#page-replacement","title":"Page Replacement","text":"<p>If there are no free frames, we need to replace the frame in a manner that would reduce future page faults.</p> <p></p>"},{"location":"3_Core/Operating_Systems/10_Virtual_Memory/#algorithms","title":"Algorithms","text":"Algo Replace frame that is Avoids B\u00e9l\u00e1dy's Anomaly FIFO (First in First out) oldest \u274c Optimal least likely to be used in the future \u2705 LRU Least Recently-Used \u2705"},{"location":"3_Core/Operating_Systems/10_Virtual_Memory/#beladys-anomaly","title":"B\u00e9l\u00e1dy's Anomaly","text":"<p>In computer storage, the phenomenon in which having more page frames can cause more page faults for first-in first-out page replacement algorithm</p>"},{"location":"3_Core/Operating_Systems/Lab/01_Reading_Files/","title":"01 Reading Files","text":""},{"location":"3_Core/Operating_Systems/Lab/01_Reading_Files/#return-value","title":"Return Value","text":"Return Value Read Successful? Return Value \\(&gt;= 0\\) \u2705 no of bytes read \\(&lt; 0\\) \u274c <pre><code>#include&lt;stdio.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;sys/stat.h&gt;\n#include &lt;fcntl.h&gt;\n#include &lt;string.h&gt;\n#include &lt;errno.h&gt;\n#include &lt;unistd.h&gt;\n\nint main(int argc, char *argv[])\n{\n  int fd;\n  char content[100]=\"\\0\";\n  fd = open(argv[1], O_RDONLY);\n  if(fd &lt; 0)\n  {\n    printf(\"File could not be opened.\\n\");\n    return 1;\n  }\n  else\n  {\n    read(fd, content, sizeof(content)-1);\n    write(1, content, sizeof(content)-1);\n  }\n  return 0;\n}\n</code></pre> <ul> <li><code>argc</code> stands for argument count and argv stands for argument values</li> <li><code>open</code>: Used to Open the file for reading, writing or both.<ul> <li><code>int open (const char* Path, int flags [, int mode ]);</code></li> </ul> </li> <li>Flags<ul> <li><code>O_RDONLY</code>: read only</li> <li><code>O_WRONLY</code>: write only</li> <li><code>O_RDWR</code>: read and write,  </li> <li><code>O_CREAT</code>: create file if it doesn\u2019t exist</li> <li><code>O_EXCL</code>: prevent creation if it already exists</li> </ul> </li> </ul>"},{"location":"3_Core/Operating_Systems/Lab/02_Processes_1/","title":"02 Processes 1","text":""},{"location":"3_Core/Operating_Systems/Lab/02_Processes_1/#unix-process-creation","title":"UNIX Process Creation","text":"<p>If \\(P_1\\) spawns \\(P_2\\)</p> <ul> <li>\\(P_1\\) is parent</li> <li>\\(P_2\\) is child</li> </ul>"},{"location":"3_Core/Operating_Systems/Lab/02_Processes_1/#fork","title":"<code>fork()</code>","text":"<p>function using which new processes become child processes of the caller</p> <ul> <li>No parameters</li> <li>returns 0 to child process</li> <li>returns process ID of the child to the parent</li> </ul> <p>Both parent and child will immediately execute after the <code>fork()</code></p> <p>UNIX makes an exact copy of the parent\u2019s Stack, Heap, Data, and Code in another sequence of memory locations.</p> <p>Any change of variables by parent process won\u2019t affect the child process\u2019 values, and vice-versa</p> <p>If there are \\(n\\) <code>fork()</code> one after each other,</p> <pre><code>void main()\n{\n  fork(); // 1\n  fork(); // 2\n  ...;\n  fork(); // n\n}\n</code></pre> <ul> <li>Total number of processes \\(= 2^n\\)</li> <li>Total number of child processes \\(= 2^n - 1\\)</li> </ul>"},{"location":"3_Core/Operating_Systems/Lab/02_Processes_1/#code-1","title":"Code 1","text":"<p>The output after <code>fork()</code></p> <pre><code>#include &lt;unistd.h&gt;\n#include &lt;stdio.h&gt;\n\nvoid main()\n{\n  int pid;\n  pid = fork();\n\n  print(\"Hello\\n\");\n}\n</code></pre> <pre><code>Hello\nHello\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/02_Processes_1/#concept-2","title":"Concept 2","text":"<p>The order of execution may be</p> <ul> <li>Parent then child</li> <li>or, Child then parent</li> </ul> <p>This depends on the system</p> <p>Value of <code>pid</code></p> <ul> <li>Child (=0)</li> <li>Parent (&gt;0)</li> <li>Unsuccessful (&lt;0)</li> </ul> <pre><code>#include &lt;unistd.h&gt;\n#include &lt;stdio.h&gt;\n\nvoid main()\n{\n  int pid;\n  pid = fork();\n\n  if(pid == 0)\n    printf(\"Child\\n\");\n  else if(pid &gt; 0)\n    printf(\"Parent\\n\");\n  else\n    printf(\"Unsuccessful Fork\");\n}\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/02_Processes_1/#concept-3","title":"Concept 3","text":"<p>Let\u2019s say both the parent and child get the same variable, then</p> <ul> <li>Changes in parent process will only affect the value in the parent process</li> <li>Changes in child process will only affect the value in the child process</li> </ul> <p>This is because each process has its own address space; any modifications will be independent of each other</p> <pre><code>#include &lt;unistd.h&gt;\n#include &lt;stdio.h&gt;\n\nvoid main()\n{\n  int a = 0;\n\n  int pid;\n  pid = fork();\n\n  if(pid == 0)\n  {\n    a = a+10;\n    printf(\"Child %d\\n\", a);\n  } else if(pid &gt; 0)\n  {\n    a = a+5;\n    printf(\"Parent\\n\");\n  } else\n    printf(\"Unsuccessful Fork\");\n}\n</code></pre> <pre><code>Parent 5\nChild 10\n(or)\nChild 10\nParent 5\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/","title":"03 Processes 2","text":""},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/#getpid","title":"<code>getpid()</code>","text":"<p>Used to display the id of the process that invokes it</p>"},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/#getppid","title":"<code>getppid()</code>","text":"<p>Get parent\u2019s process ID</p>"},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/#waitnull","title":"<code>wait(NULL)</code>","text":"<p>parent process waits for completion of any one of its children</p> <p>Parent initially moves to wait state, then comes to ready queue</p>"},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/#dependencies","title":"Dependencies","text":"<ul> <li><code>#include &lt;sys/types.h&gt;</code></li> <li><code>#include &lt;sys/wait.h&gt;</code></li> </ul>"},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/#return-value","title":"return value","text":"<p>pid of the terminated child</p>"},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/#exit-status-of-child","title":"exit status of child","text":"<p>integer value</p> <ul> <li>+ve: sucessful termination</li> <li>-ve : unsuccessful termination</li> </ul> <pre><code>pid_t wait(int *status);\n\nint status;\npid = wait(&amp;status);\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/03_Processes_2/#code-1","title":"Code 1","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n\n#include &lt;sys/types.h&gt;\n#include &lt;sys/wait.h&gt;\nvoid main()\n{\n  int rv, a;\n  rv = fork();\n\n  if(rv == 0)\n  {\n        printf(\"Hello\\n\");\n    printf(\"Child PID is %d\\n\", getpid());\n    printf(\"My parent's PID is %d\\n\", getppid());\n  }\n  else if(rv &gt; 0)\n  {\n    a = wait(NULL);\n    printf(\"Parent PID is %d\\n\", getpid());\n    printf(\"Parent: The child that terminated is %d\\n\", a);\n  }\n  else\n  {\n    printf(\"Unsuccessful\");\n  }\n}\n</code></pre> <pre><code>Hello\nChild PID is 1676\nMy parent's PID is 1672\nParent PID is 1672\nParent: The child that terminated is 1676\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/04_Processes_3/","title":"04 Processes 3","text":""},{"location":"3_Core/Operating_Systems/Lab/04_Processes_3/#execlp","title":"<code>execlp()</code>","text":"<p>replaces the data &amp; text region of the calling process with the new data of program</p> <pre><code>execlp(program path, exec_name, arg_1, arg_2, ... , NULL);\n</code></pre> <p><code>NULL</code> is always the last parameter of <code>execlp()</code></p> <p><code>execlp()</code> will return to the child process only in case of error. It will go back to the parent process regardless. </p> <p>Hence, in the following example, \u201cblah blah\u201d will not execute.</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;sys/wait.h&gt;\n\nvoid main()\n{\n  int rv;\n  rv = fork();\n\n  if(rv == 0)\n  {\n    printf(\"I am a child process\\n\");\n    execlp(\"ls\", \"ls\", NULL);\n    printf(\"blah blah\"); \n  }\n  else if(rv &gt; 0)\n  {\n    wait(NULL);\n    printf(\"Hi. I am the parent\\n\");\n  }\n  else\n  {\n    printf(\"Unsuccessful\");\n  }\n}\n</code></pre> <pre><code>I am a child process\na.out  main.c\nHi. I am the parent\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/04_Processes_3/#code-2-long-listing","title":"Code 2: Long Listing","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;sys/wait.h&gt;\n\nvoid main()\n{\n  int rv;\n  rv = fork();\n\n  if(rv == 0)\n  {\n    printf(\"I am a child process\\n\");\n    execlp(\"ls\", \"ls\", \"-l\", NULL);\n    printf(\"blah blah\");\n  }\n  else if(rv &gt; 0)\n  {\n    wait(NULL);\n    printf(\"Hi. I am the parent\\n\");\n  }\n  else\n  {\n    printf(\"Unsuccessful\");\n  }\n}\n</code></pre> <pre><code>I am a child process\ntotal 24\n-rwxr-xr-x 1 runner3 runner3 16864 Oct 20 05:55 a.out\n-rwxrwxrwx 1 root    root      371 Oct 20 05:55 main.c\nHi. I am the parent\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/04_Processes_3/#code-3-without-null","title":"Code 3: Without <code>NULL</code>","text":"<p>Gives error: missing sentinel in functional call</p> <p>This causes blah blah to be displayed</p> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/types.h&gt;\n#include &lt;sys/wait.h&gt;\n\nvoid main()\n{\n  int rv;\n  rv = fork();\n\n  if(rv == 0)\n  {\n    printf(\"I am a child process\\n\");\n    execlp(\"ls\", \"ls\", \"-l\");\n    printf(\"blah blah\");\n  }\n  else if(rv &gt; 0)\n  {\n    wait(NULL);\n    printf(\"Hi. I am the parent\\n\");\n  }\n  else\n  {\n    printf(\"Unsuccessful\");\n  }\n}\n</code></pre> <pre><code>main.c: In function \u2018main\u2019:\nmain.c:14:5: warning: missing sentinel in function call [-Wformat=]\n   14 |     execlp(\"ls\", \"ls\", \"-l\");\n      |     ^~~~~~\nI am a child process\nblah blahHi. I am the parent\n</code></pre>"},{"location":"3_Core/Operating_Systems/Lab/04_Processes_3/#code-4-executing-another-program","title":"Code 4: Executing another program","text":""},{"location":"3_Core/Operating_Systems/Lab/04_Processes_3/#samplec","title":"<code>sample.c</code>","text":"<pre><code>#include &lt;stdio.h&gt;\nvoid main()\n{\n  printf(\"Hi there!\");\n  something\n}\n</code></pre> <pre><code>cc sample.c a.out\ncc sample.c -o sample.o\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/","title":"Principles of Programming Languages","text":"<p>Taught by Dr. B. Vijayakumar</p> <p>This course covers</p> <ul> <li>Features of a good programming language</li> <li>Efficiency and Optimization of computations</li> </ul> <p>The programming languages in this course are</p> <ul> <li>C</li> <li>C++</li> <li>Python</li> <li>Prolog</li> <li>LISP</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/","title":"01 Intro","text":""},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#programming-lanugage","title":"Programming Lanugage","text":"<p>Tool for humans to communicate with a computer system</p> <p>We should try to generalize a programming language, to ensure compatibility.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#properties","title":"Properties","text":"<ul> <li>Turing Complete   Must be able to express anything computable </li> <li>Must be able to implement on existing hardware platforms</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#what-makes-a-good-language","title":"What makes a good language?","text":"<ul> <li>Syntax close to what we are used to</li> <li>Readability</li> <li>Expressibility   For eg, <code>while</code> loop instead of <code>if</code> and <code>goto</code></li> <li>Reliability: Error Checking<ul> <li>Detect use of initialized variables</li> <li>Type checking</li> <li>Array Bounds (C vs Java)</li> <li>Testing Support</li> </ul> </li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#paradigms","title":"Paradigms","text":"Imperative Declarative Programmer tells __ to do how what Focus of programming language Do exactly what is told Do what is meant Classifications - Procedural: Fortran, C- Object-Oriented: C++, Java- Scripting: Python, Javascript, Bash(Shell) - Functional: LISP/Scheme/Haskel, symbolic data processing- Logic: Prolog, Logic Reasoning- SQL: mySQL, PostgreSQL, Cassandra, NoSQL - Sequential- Concurrent"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#why-do-we-usually-use-imperative-languages","title":"Why do we usually use imperative languages?","text":"<p>As we mainly use von Neumann machines, which is the class of stored program digital computer.</p> <p>Imperative languages give control over moving data and program instructions between registers in CPU and Memory location</p>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#von-neumann-architecture","title":"von Neumann Architecture","text":"<p>There is no distinction between code and data, as they are stored in the same memory</p>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#structured-programming","title":"Structured Programming","text":"<p>Dijkstra</p> <p>Also referred to as \u2018goto-less\u2019 programming</p> <ul> <li>Single entry, Single exit sequence</li> <li>Selection</li> <li>Repetition</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#generations","title":"Generations","text":"LanguageGeneration Description LanguageTranslatorrequired Example Performance Machine This is what your machine understands None \ud83d\udd25 Assembly Mnemonics (names and symbols) Assembler x86MIPS \ud83d\udd25 High-Level - Machine independence- Semantics not limited to machine architecture- Human-Friendly- Data/Control Flow abstractions- Availability of libraries- Consistency check (data types) CompilerInterpreter CC++FortranPascal \ud83d\udd25 4<sup>th</sup> Gen Interpreter Python \ud83d\udc0c 5<sup>th</sup> Gen Just-in-Time Compiler Julia \ud83d\udd25 <p>In the present-day, compiler-generated code is faster than human-written assembly code; it was not the case before</p>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#bugs","title":"Bugs","text":"<p>Programming testing can be used to show the presence of bugs, but never their absence!</p> <p>~ Dijkstra</p>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#solution","title":"Solution","text":"<ul> <li>Organize code modularly, such that each part can be understood</li> <li>Alpha Testing by company testers</li> <li>Beta Testing by end-users</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#early-programming-languages","title":"Early Programming Languages","text":"Year Language Full Form Creator Purpose Focus Still Used? 1954 Fortran Formula Translator J Backus (IBM) Numerical Computing Efficiency \u2705 1958 ALGOL Algorithmic Language J Backus (IBM)F Bauer (TU) Algo \\(\\to\\) Programs ClarityElegance \u274c 1958 LISP List Processor J McCarthy (MIT) Symbolic Computing Abstractions \u2705 1959 COBOL Common Business Oriented Language G Hopper (US Navy) Data Processing (Payroll) \u2018English-like\u2019 \u2705"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#scripting-language-vs-programming-language","title":"Scripting Language vs Programming Language","text":"<p>Programming languages</p> <ul> <li>follow EBNF(Extended Bacus Normal Form)</li> <li>have CFG(Context-Free Grammar)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#language-translators","title":"Language Translators","text":"Compiler Interpreter Virtual Machine Speed Faster Slower Error Detection Harder Easier Code Processing Method One-Go Line-by-Line Translation Once Every execution Distributes Executable Executable not possible Development time Slower Faster Typing Static/Dynamic Dynamic Target Program Machine CodePortable Machine Code (Java Byte Code)C Code \u274cDoes not generate target programexecutes instructions directly Example CC++Java JavascriptPython JavaPython"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#compiled-code","title":"Compiled Code","text":"<pre><code>flowchart LR\n\nsubgraph \"Once\"\n  sp2[Source Program] --&gt; Compiler\nend\n\nCompiler --&gt;  tp2\n\nsubgraph \"Every Execution\"\n    tp2[Target Program]\n    i2[/Input/] --&gt; tp2 --&gt; o2[/Output/]\nend</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#interpreted-code","title":"Interpreted Code","text":"<pre><code>flowchart LR\n\nsubgraph \"Every Execution\"\n    direction LR\n  sp2[Source Program] --&gt; Interpreter\n  i1[/Input/] --&gt; Interpreter --&gt; o2[/Output/]\nend</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#virtual-machines","title":"Virtual Machines","text":"<pre><code>flowchart LR\n\nsubgraph \"Once\"\n  sp2[Source Program] --&gt; Compiler --&gt; ip[\"Byte Code&lt;br /&gt;(Intermediate Program)\"]\nend\n\nip --&gt; vm[Virtual Machine]\n\nsubgraph \"Every Execution\"\n    i2[/Input/] --&gt; vm --&gt; o2[/Output/]\nend</code></pre> <p>combine the plus points of compiler/interpreter</p> <p>Interpreting high level code is slow</p>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#java","title":"Java","text":"<pre><code>javac Prog.java\njava Prog\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#python","title":"Python","text":"<pre><code>python prog.py\n</code></pre> <ul> <li>First time the program is run, it is interpreted</li> <li>In subsequent runs, the cached byte code <code>.pyc</code> is executed</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#ram","title":"RAM","text":"<p>Random Access Memory</p> <p>Stores program instructions, addresses, and immediate values</p>"},{"location":"3_Core/Principles_of_Programming_Languages/01_Intro/#shell-scripts","title":"Shell Scripts","text":"<pre><code>ls | sort | more\n</code></pre> <p>View resources consumption by various users</p> <pre><code>ipcs\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/","title":"02 Language Evaluation","text":""},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#qualities-of-a-language","title":"Qualities of a Language","text":"Quality Meaning Readability Ease with humans can read and understand programs Writability Ease with humans can write programs Reliability Program performs to its specifications under all conditions Cost-efficiency - Efficiency of Training programmers- Efficiency of writing, compiling, executing, reading programs- Efficiency of computation and development- Monetary cost of compilers, license- Maintenance cost, due to reliability- Portability (standardization of the language)- Generality (applicability to a wide range of use-cases/applications)"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#features","title":"Features","text":"Characteristic AffectsReadability? AffectsWritability? AffectsReliability? Simplicity \u2705 \u2705 \u2705 Orthogonality \u2705 \u2705 \u2705 Data Types &amp; Structures \u2705 \u2705 \u2705 Syntax Design \u2705 \u2705 \u2705 Abstraction \u2705 \u2705 Expressivity \u2705 \u2705 Type Checking \u2705 Exception Handling \u2705 Restricted Aliasing \u2705"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#simplicity","title":"Simplicity","text":""},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#fewer-features-and-basic-constructs","title":"Fewer features and basic constructs","text":"<p>The main cause of readability issues is because program author uses a subset different from what the reader is familiar with</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#fewer-feature-multiplicity","title":"Fewer Feature Multiplicity","text":"<p>Feature Multiplicity = Ability to do the same operation in different ways</p> <pre><code>count = count + 1;\ncount += 1;\ncount++;\n++count;\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#fewer-operator-overloading","title":"Fewer Operator Overloading","text":"<p>Ambiguity arises due to ability of operator to perform multiple operations</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#orthogonality","title":"Orthogonality","text":"<p>Constructs in programming languages should be independent of each other; should not be redundant. Every combination of features should be meaningful.</p> <p>Any operation has minimal undesired side effects.</p> <p>Orthogonality is the property that means \"Changing A does not change B\".</p> <p>An example of an orthogonal system would be a radio, where changing the station does not change the volume and vice-versa.</p> <p>A non-orthogonal system would be like a helicopter where changing the speed can change the direction.</p> <p>In programming languages this means that when you execute an instruction, nothing but that instruction happens (which is very important for debugging).</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#data-types-structures","title":"Data Types &amp; Structures","text":"<p>For eg, the existence of <code>boolean</code> data type in a programming language is important, as otherwise we have to use integers (which make the program less clear)</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#syntax-design","title":"Syntax Design","text":""},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#identifiers","title":"Identifiers","text":"<p>Names for variables, functions, arrays, structures, etc</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#rules","title":"Rules","text":"<ul> <li>Starting character must be alphabet/underscore</li> <li>Other characters can be<ul> <li>Alphabet</li> <li>Underscore</li> <li>Digits</li> </ul> </li> <li>Max Length = 31 characters</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#key-words","title":"Key Words","text":"<p><code>while</code>, <code>for</code>, <code>class</code></p> <p>Most programming languages use braces for pairing control structers</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#semantics-should-follow-syntax","title":"Semantics should follow Syntax","text":"<p>Semantics = meaning of your code; basically the logic</p> <p>For eg, use of <code>static</code>, <code>extern</code> in C</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#form-and-meaning","title":"Form and Meaning","text":"<p>Self-descriptive constructs and meaningful keywords</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#abstraction","title":"Abstraction","text":"<p>Ability to define and use complex structures/operations in ways that allow details to be ignored</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#process-abstraction","title":"Process Abstraction","text":"<p>Functions/Sub-routines for codes that will be required multiple times</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#data-abstraction","title":"Data Abstraction","text":"<p>Ability to create own data structures, such as binary tree using pointers/integers</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#expressivity","title":"Expressivity","text":"<p>Set of relatively convenient ways of specifying operations</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#examples","title":"Examples","text":"<ul> <li><code>count++</code> instead of <code>count = count + 1</code></li> <li><code>for</code> instead of <code>while</code></li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#type-checking","title":"Type Checking","text":"<p>Testing for type errors - ensuring that operands of an operator are of compatible type</p> <p>Run-Time type checking is expensive, hence compile-time type checking is preferred</p> Statically-Typed Languages Dynamically-Typed Languages CC++C#JavaFortran Objective-CGroovyJavascriptLISPLuaPHPPrologPythonRubySmalltalkTCL"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#exception-handling","title":"Exception Handling","text":"<p>Intercept run-time errors and take corrective measures</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#restricted-aliasing","title":"Restricted Aliasing","text":"<p>Aliasing = Presence of multiple names for the same memory location</p> <p>Changing value pointed by one pointer changes the value pointed by another pointer to the same location.</p> <p>\u274c In C, union members and pointers may be set to point to the same variable.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/02_Language_Evaluation/#grep","title":"Grep","text":"<p>**G**et **re**gular **e**x**p**ression</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/","title":"03 Language Description","text":""},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#syntax-vs-semantics","title":"Syntax vs Semantics","text":"Syntax Semantics Structure of expressions, statements, program units Meaning of expressions, statements, program units - Lexical layer- Grammar layer"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#grammar","title":"Grammar","text":"<p>Means of</p> <ul> <li>describing a language: all possible legally-correct programs</li> <li>analyzing a sentence: check if program is valid</li> <li>derive a sentence: program</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#notations","title":"Notations","text":"Example Easy to decode during left-right scan Parenthesis-free Operands of each operator can be found unambiguously Can be evaluated with Prefix \\(+ ab\\) \u2705 \u2705 \u2705 - Tree- Stack Postfix \\(ab +\\) \u274c \u2705 \u2705 - Tree- Queue Infix \\(a+b\\) \u274c \u274c \u274c - Tree Mixfix If \\(a&gt;b\\) then \\(a\\) else \\(b\\)- <code>if</code>, <code>then</code>, <code>else</code> are keywords- \\(a, b\\) are components of expression \u274c \u274c \u274c"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#infix-notation","title":"Infix Notation","text":""},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#associativity","title":"Associativity","text":"<ul> <li>Left: \\(+, -, *, /\\)</li> <li>Right: \\(=,\\) ^</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#precedence","title":"Precedence","text":"<p>BODMAS</p> <ol> <li>Brackets</li> <li>Orders (Powers, Indices, Roots)</li> <li>Division</li> <li>Multiplication</li> <li>Addition</li> <li>Subtraction</li> </ol>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#abstact-syntax-tree","title":"Abstact Syntax Tree","text":"<p>identifies meaningful components of each construct in the language</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#ab-ab-ab","title":"\\(+ab, \\ a+b, \\ ab+\\)","text":"<p>all have the same abstract syntax tree</p> <pre><code>flowchart TB\n+ --&gt; a &amp; b</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#if-a-b-then-a-else-b","title":"if \\(a &gt; b\\), then \\(a\\), else \\(b\\)","text":"<pre><code>flowchart TB\nstmt --&gt; if &amp; e1 &amp; then &amp; stmt1 &amp; else &amp; stmt2\n\ne1 --&gt; x[\"a&gt;b\"]\nstmt1 --&gt; a\nstmt2 --&gt; b</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#lexical-syntax","title":"Lexical Syntax","text":"<p>group characters of source program into meaningful sequence (omitting blank spaces and comments) and generate tokens/terminals</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#syntax-of-token","title":"Syntax of token","text":"<p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#token-classes","title":"Token Classes","text":"Class Example Keyword <code>if</code>, <code>else</code>, <code>while</code> Operator \\(+ - * /\\) Identifier(Variables) max, a, total Constant(Numeric/String constant) pi Punctuation Marks \\(, ; () [] \\{ \\}\\) Number \\(1 \\ 2 \\ 3 \\ \\dots\\)"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#example","title":"Example","text":"<p>\\(a*b-4\\) has the following tokens"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#cfg","title":"CFG","text":"<p>Context-Free Grammar</p> <p>Used to specify grammar of non-regular expressions (refer Theory of Computation)</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#parts","title":"Parts","text":"<ul> <li>Set of tokens/terminals</li> <li>Set of non-terminals</li> <li>Set of rules/productions   Each production has a<ul> <li>non-terminal on its left hand-side</li> <li>\\(::=\\) or \\(\\rightarrow\\) on right-hand side</li> <li>String of terminals/non-terminals on right-hand side</li> </ul> </li> <li>A Non terminal is chosen as the starting non-terminal   Unique starting terminal is called starting symbol</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#bnf","title":"BNF","text":"<p>Bacus Naur Form</p> <p>used to specify grammar</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#parts_1","title":"Parts","text":"<ul> <li>Terminal appear as keyword, opeator, identifiers, constant, punctuation mark</li> <li>Non-terminals are enclosed between \\(&lt; &gt;\\)   Eg: &lt; fraction &gt;</li> <li>Productions<ul> <li>Read \\(::=\\) as \u2018can be\u2019</li> <li>Read \\(|\\) or</li> </ul> </li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#example_1","title":"Example","text":"<ul> <li>&lt; fraction &gt; \\(::=\\) &lt; digit &gt; | &lt; digit &gt;&lt; fraction &gt;   Fraction can be digit or a digit followed by fraction</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#cfg-for-real-number-bnf","title":"CFG for real number BNF","text":"<ul> <li>&lt; real-number &gt; \\(::=\\)  . &lt; fraction &gt; <li>&lt; integer_part &gt; \\(::=\\) &lt; digit &gt; |  &lt; digit &gt; <li>&lt; fraction &gt; \\(::=\\) &lt; digit &gt; | &lt; digit &gt;&lt; fraction &gt;</li> <li>&lt; digit &gt; \\(::=\\) 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 9</li>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#parse-tree","title":"Parse Tree","text":"<p>Also called as Concrete Syntax Tree</p> <p>Tree built using starting non-terminal and productions</p> <p>Construction of a parse tree is called parsing</p> <p>Generates the string formed by reading terminals at its leaves from left to right</p> <p>A string is only in a language if it is generated by some parse tree</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#rules","title":"Rules","text":"<ul> <li>Root is labeled with the starting non terminal</li> <li>Each non-leaf is labeled with a non terminal</li> <li>Each leaf is labeled with a terminal</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#example_2","title":"Example","text":"<p>\\(123.789\\)</p> <pre><code>flowchart TB\nrn[Real Number]\n\nrn --&gt; i1[Integer-Part] &amp; . &amp; f1[Fraction]\ni1 --&gt; d1[Digit] &amp; i2[Integer-Part]\ni2 --&gt; d2[Digit] &amp; i3[Integer-Part]\ni3 --&gt; d3[Digit]\n\nf1 --&gt; d7[Digit] &amp; f2[Fraction]\nf2 --&gt; d8[Digit] &amp; f3[Fraction]\nf3 --&gt; d9[Digit]\n\nd1 --&gt; 1\nd2 --&gt; 2\nd3 --&gt; 3\nd7 --&gt; 7\nd8 --&gt; 8\nd9 --&gt; 9</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#ambiguous-grammar","title":"Ambiguous Grammar","text":"<p>A grammar for a language is syntactically ambiguous, if some string in its language has more than one parse tree.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#dangling-else","title":"Dangling Else","text":"<p><code>if E1 then if E2 then S1 else S2</code> has 2 parse trees with the following grammar</p> <ul> <li>S \\(::=\\) if E then S</li> <li>S \\(::=\\) if E then S else S</li> </ul> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#math","title":"Math","text":"<p>\\(2+3*5\\) has 2 parse trees with the following grammar</p> <ul> <li>&lt; expr &gt; \\(::=\\) &lt; expr &gt; &lt; op &gt; &lt; expr&gt; | &lt; digit &gt;</li> <li>&lt; op &gt; \\(::=\\) + | - | * | /</li> <li>&lt; digit &gt; \\(::= 0 | 1 | 2 | \u2026. | 9\\)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#derivations","title":"Derivations","text":"<p>Text version of Parse Tree</p> Top-Down Derivation Bottom-Up Derivation Start from Starting symbol and derive the sentence. Start from the sentence and reach the start symbol. Replace the LHS of a production by RHS Replace the RHS of a production by the LHS Leftmost Derivation Rightmost Derivation Leftmost nonterminal is replaced repeatedly Rightmost nonterminal is replaced repeatedly"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#example_3","title":"Example","text":"<p>Real Number</p> <p>real-number \\(\\implies\\) integer-part . fraction \\(\\implies\\) integer-part digit.fraction</p>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#grammar-for-expressions","title":"Grammar for Expressions","text":"<ul> <li>Left-Recursive Grammars handle </li> <li>Right-Recursive Grammars handle right-associativity</li> </ul> Left-Recursive Right-Recursive Handles Left-associativity Right-associativity Example \\(L ::= L + \\text{num} \\ L \u2013 \\text{num} \\vert  \\text{num}\\) \\(R ::= \\text{num} + R \\vert  \\text{num} \u2013 R  \\vert \\text{num}\\)"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#operator-precedence","title":"Operator Precedence","text":"<p>(Low to High)</p> Operator Meaning \\(=\\) Assignment \\(\\vert  \\vert\\) Logical or \\(\\&amp;\\&amp;\\) Logical and \\(\\vert\\) inclusive or ^ exclusive or \\(\\&amp;\\) and \\(== \\ \\ \\ne\\) equality \\(&lt; \\ \\le \\ \\ge \\ &gt;\\) relational \\(&lt;&lt; \\ \\ &gt;&gt;\\) shift \\(+ -\\) additive \\(* / \\%\\) multiplicative \\(\\uparrow\\) exponentiation"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#operator-association","title":"Operator Association","text":"Association Left \\(+ - */\\) Right \\(= \\ \\uparrow\\)"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#extended-bnf","title":"Extended BNF","text":"<ul> <li>Braces \\(\\{ \\}\\) represent zero/more repetitions</li> <li>Brackets \\([]\\) represent optional contruct</li> <li>Vertical bar \\(|\\) represents a choice</li> <li>Parentheses \\(()\\) are used for grouping</li> </ul> \\[ \\begin{aligned} E &amp;::= T \\Big\\{ (+ | -) \\ T \\Big\\} \\\\ T &amp;::= F \\Big\\{ (* | /) \\ F \\Big\\} \\\\ F &amp;::= ( E ) | \\text{Name} | \\text{Number} \\end{aligned} \\] <ul> <li>\\(E =\\) Expression</li> <li>\\(T =\\) Term</li> <li>\\(F =\\) Factor</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/03_Language_Description/#syntax-chart","title":"Syntax Chart","text":"<p>The above can be represented as \u2b07</p> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/","title":"04 Structured Programming","text":""},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#structured-programming-context","title":"Structured Programming Context","text":"<p>CA sequential computation consists of sequence of actions. These computations are dynamic occur during program execution</p> <p>Program text is static</p> <p>It is essential that the program text represents the computation that occurs when the program runs</p>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#design-principles-of-imperative-languages","title":"Design Principles of Imperative Languages","text":"<ol> <li>Structure of program text should help understand what program does. Reliability of structured programs make them easier to modify for efficiency</li> <li>Language must allow underlying machine to be used efficiently</li> </ol>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#structured-control-flow","title":"Structured Control Flow","text":"<p>A program is structured if the flow of control through the program is evident from the syntactic structure of the program text.</p> <p>This is done by making structured statements single-entry, single-exit</p>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#sequential-statements","title":"Sequential Statements","text":"<p>sequence of statements</p> <p>A compound statement is a block of code, which is a grouped statement enclosed in some manner, such as <code>{...}</code>, <code>begin ... end</code></p>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#selectionconditional-statements","title":"Selection/Conditional Statements","text":""},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#if-else","title":"<code>if ... else</code>","text":"<ul> <li><code>if &lt;exp1&gt; then &lt;stmt1&gt;</code></li> <li><code>if &lt;exp1&gt; then &lt;stmt1&gt; else &lt;stmt2&gt;</code></li> <li>Nested conditionals</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#switchcase","title":"<code>switch...case</code>","text":"<pre><code>switch(exp)\n{\n  case const1:\n    ; // stmt1\n    break;\n  case const2:\n    ; // stmt2\n    break;\n  default:\n    ; // default stmt\n}\n</code></pre> <p>Properties</p> <ul> <li>Case constants can appear in any order</li> <li>Case constants need not be consecutive</li> <li>Several case constants can select the same sub-statement</li> <li>Case constants must be distinct to avoid ambiguity</li> </ul> <p>Notes</p> <ul> <li>Pascal gives error if none of the cases are selected</li> <li>Pascal uses <code>else</code> case instead of <code>default</code> case</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#if-else-vs-switch-case","title":"<code>if ... else</code> vs <code>switch ... case</code>","text":"<p>Case statements are preferred over <code>if ... else</code> when we have adjacent conditionals. Otherwise, use <code>if \u2026 else</code></p> <pre><code>// \u2705\nswitch(s)\n{\n  case 1:\n  case 2:\n  case 3:\n}\n\n// \u274c\nswitch(s)\n{\n  case 1:\n  case 2000:\n  case 30000:\n}\n\n// \u2705\nif (s == 1)\nelse if (s == 2000)\nelse if (s == 30000)\n</code></pre> <p>When using cases, a jump table is created, which contains entry \\(i\\) that is machine instruction to jump to code for case \\(i\\). The no of entries in the jump table \\(= \\max - \\min + 1\\). However, only the cases that are in the our code are actually used.</p> <p>Compiler uses jump table if atleast half of the entries are used. Else, the compiler uses a hash table instead.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#iterativeloops-statements","title":"Iterative/Loops Statements","text":"<ul> <li>Definite Loop   Known number of iterations</li> <li>Indefinite Loop   Number of iterations is only known at run time</li> <li>Infinite loop   Loop keeps iterating</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#while","title":"While","text":"<p><code>while &lt;exp&gt; do &lt;stmt</code></p> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#do-while","title":"Do-While","text":"<p><code>repeat &lt;stmt&gt; until &lt;exp&gt;</code></p>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#for","title":"For","text":"<p><code>for &lt;id&gt; = &lt;exp&gt; to &lt;exp&gt; do &lt;stmt&gt;</code></p> <p>Components</p> <ul> <li>index/iterative variable</li> <li>Step</li> <li>Limit</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#handling-special-cases","title":"Handling Special Cases","text":"<ul> <li><code>break</code></li> <li><code>continue</code></li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#return-statements","title":"Return Statements","text":"<p><code>return &lt;exp&gt;</code></p> <p>Sends control from a procedure back to a caller carrying the value of the expression. If return is not inside a procedure the program halts.</p> <p>Break vs Return</p> <ul> <li>Break : control goes out of a loop</li> <li>Return : control goes out of a procedure</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/04_Structured_Programming/#goto-statements","title":"Goto Statements","text":"<p>Basically unconditional jump</p> <pre><code>goto L\n  ...\nL: &lt;stmt&gt;\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/","title":"05 Types Data Representation","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#data-type-definition","title":"Data Type Definition","text":"<p>Collection of dat objects, having a set of predefined operations</p> <ul> <li>Descriptor: Collection of attributes for a variable</li> <li>Object: Instance of a user-defined/abstract data type</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#primitive-data-types","title":"Primitive Data Types","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#void","title":"<code>void</code>","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#boolean","title":"<code>boolean</code>","text":"<p>true/false</p> <p>represented as a byte</p> <ul> <li>Could be represented as bit</li> <li>but accessing a single bit is not as efficient as accessing a byte (as it is the smallest addressable unit of memory)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#char","title":"<code>char</code>","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#int","title":"<code>int</code>","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#float","title":"<code>float</code>","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#double","title":"<code>double</code>","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#table","title":"Table","text":"<p>No need to study this; just for reference</p> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#derived-data-types","title":"Derived Data Types","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#array","title":"Array","text":"<ul> <li>Collection of elements of the same data type</li> <li>Linear data structure</li> </ul> <p>Implementing arrays require high compile-time effort. Code to allow accessing of array elements must be generated during compilation. At run time, this code must be executed to produce element addresses.</p> <p>Dynamic allocation of arrays allows to choose an array length at runtime. Java has built-in dynamic arrays.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#alternative-names","title":"Alternative Names","text":"Dimension of array Alternative Name 1 Vector 2 Matrix"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#rowcolumn-major","title":"Row/Column Major","text":"<p>Most programming languages use row major</p> Major Address of \\((i, j)\\)th element Row \\(B + W[C(i \u2013 L_r) + (j \u2013 L_c)]\\) Column \\(B + W[(i \u2013 L_r) + R(j \u2013 L_c)]\\) Variable Meaning \\(B\\) Base address \\(W\\) Width of every blockSize of every element(bytes) \\(L_r\\) index of 1<sup>st</sup> row, if in-between(assume 0 if not specified) \\(L_c\\) index of 1<sup>st</sup> col(assume 0 if not specified) \\(R\\) total number of rows \\(C\\) total number of columns"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#structures","title":"Structures","text":"<ul> <li>Collection of elements of one/more data types</li> <li>Non-linear data structure</li> <li>Another way to think of it: Represent a record of different attributes</li> </ul> <pre><code>struct Book\n{\n  char title[50];\n  int year;\n};\n\nvoid main()\n{\n    struct Book b1;\n\n  strcpy(b1.title, \"Blah Blah\");\n  b1.year = 2020;\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#union","title":"union","text":"<p>Data type in C that allows to store different data types in the same memory location</p> <pre><code>union Book\n{\n  char title[50];\n  int year;\n}\n</code></pre> <p>Union is very similar to structure, but the memory implementation is different; both <code>title</code> and <code>year</code> will be stored together in one block, rather than different blocks.</p> <p>The size of the block will be the size of the largest data type. So, the value of the block will be the latest value we stored. So we won\u2019t get the correct expected output like structure.</p> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#enum","title":"Enum","text":"<p>Assign names to integral constants</p> <pre><code>enum week {\n  Mon, // 0\n  Tue, // 1\n  Wed, // 2\n  Thu, // 3\n  Fri, // 4\n  Sat, // 5\n  Sun  // 6\n}\n\nvoid main()\n{\n  enum week d1;\n  d1 = Wed;\n  printf(\"%d\", day);\n}\n\n// Output\n// 2\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#pointer","title":"Pointer","text":"<p>Variable containing address to memory location</p> <pre><code>char *p;\nint *p;\nfloat *p;\ndouble *p;\n</code></pre> <pre><code>void main()\n{\n  int var = 20;\n\n  int *ip;\n  ip = &amp;var;\n\n  printf(\n    \"Address of var variable: %x\\n\",\n    &amp;var\n  ); \n  printf(\n    \"Address stored in ip variable: %x\\n\",\n    ip\n  ); \n\n  printf(\n    \"Value of *ip variable: %d\\n\",\n    *ip\n  );\n}\n\n// Output\n// Address of var variable: bffd8b3c \n// Address stored in ip variable: bffd8b3c \n// Value of *ip variable: 20 \n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#null-pointer","title":"Null Pointer","text":"<p>Pointer pointing to \u2018nothing\u2019 (empty location in memory)</p> <p>Value of pointer is 0</p> <pre><code>int *p = NULL;\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#issues-with-pointers-and-dynamic-allocation","title":"Issues with Pointers and Dynamic Allocation","text":"Dangling Pointer Memory Leak Meaning Pointer is pointing to- invalid memory- memory not owned by program Allocated memory is not de-allocated, after utilization Occurs when Referencing object is deleted/de-allocated, without changing the value of pointers Programmer does not de-allocate memory, if the PL doesn\u2019t have automatic garbage collection. Solution Set the pointer as null pointer when not required anymore. Have a counter variable to track no of- Dynamic allocations- De-allocationsAt the end, both counters should be equal <pre><code>void main()\n{\n    int *p = NULL;\n  p = malloc( // or calloc\n    sizeof(int) * 5\n  ); // dynamic array that can contain 5 integers\n\n  free(p); // Without This =&gt; Memory Leak\n  *p = NULL; // without this =&gt; Dangling Pointer\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#subrange-type","title":"Subrange Type","text":"<p>Limits the range of values a variable can take, by defining a subset of the values of a particular type. Code is inserted by compiler to restrict assingments to subrange values</p> <p>Example</p> <pre><code>type\ndigit = 0..9;\nletter = 'A'..'Z';\n\nvar\nnum: digit;\nalpha: letter;\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#types-error-checking","title":"Types &amp; Error Checking","text":""},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#purpose","title":"Purpose","text":"<ul> <li>Avoid errors in programs</li> <li>Analyze safety of program (eg bufferoverflow)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#variable-bindings","title":"Variable Bindings","text":"<p>Associate a property with a variable</p> <p>Binding can be</p> <ul> <li>static (early)</li> <li>dynamic (late)</li> </ul> Language Variables Values Compiled Fixed Dynamic Interpreted Changeable Dynamic"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#types-systems","title":"Types Systems","text":"<ul> <li>Set of rules for associating a type with expressions</li> <li>Used for detecting invalid operations on incompatible types   For eg<ul> <li>pointer + int = \u2705</li> <li>pointer + pointer = \u274c</li> </ul> </li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#type-checking","title":"Type Checking","text":"<ul> <li>Uses property of function</li> <li>Function maps element of one set to another set</li> <li> <p>For eg: Arithmetic operations are functions</p> <ul> <li>If \\(E, F\\) are <code>int</code>, then \\(E+F\\) will also be <code>int</code></li> </ul> </li> <li> <p>Strongly-typed language is one that allows only safe expressions.</p> </li> <li> <p>Type-Safe Program is one that executes without any type errors</p> </li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#static-vs-dynamic-typing","title":"Static vs Dynamic Typing","text":"Type-Checking When? Execution Time Example Static Compile-Type \\(\\downarrow\\) C, C++ Dynamic Run-Time \\(\\uparrow\\) Python"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#type-conversion","title":"Type Conversion","text":"Conversion By Automatic? Alternate Name Example Implicit Language Translator \u2705 Coercion <code>double x = 3;</code> Explicit User \u274c Casting <code>double x = (double) 5;</code>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#type-name-equivalence","title":"Type Name &amp; Equivalence","text":"EquivalenceType Meaning Example Structural SE1 Type is structurally-equivalent to itself \\(\\text{char} \\equiv \\text{char}\\) SE2 2 types are structurally-equivalent, if they are formed using the same construtor to structurally-equivalent types \\(\\text{char} \\equiv \\text{char} \\implies \\text{char}[10] \\equiv  \\text{char}[10]\\) SE3 One data type is declared using <code>typedef</code> with the other <code>typedef X Y</code> \\(\\implies X \\equiv Y\\) RestrictedType Pure Name Type name is equivalent to itself \\(\\text{char} \\equiv \\text{char}\\) Transitive Name <code>typedef X int; typedef Y X</code> \\(\\implies X \\equiv Y \\equiv \\text{int}\\) TypeExpression Type name is equivalent only to itselfApply same constructor to equivalent expressions <p>Notes</p> <ul> <li>C uses SE for all types, except structures</li> <li>(Somethign about circular types - I didn\u2019t understand)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#type-error","title":"Type Error","text":"<p>If a function/operation expects an argument of type \\(T\\), but is supplied with argument of type \\(S\\), such that \\(S \\not \\equiv T\\)</p>"},{"location":"3_Core/Principles_of_Programming_Languages/05_Types_Data_Representation/#polymorphism","title":"Polymorphism","text":"<p>assuming different forms</p> Binding Type When Example Static Compilation - Operator Overloading- Function Overloading Dynamic Execution Function Overriding"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/","title":"06 Procedures","text":"<p>Named block of code. When the name is called, the body is executed.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#types-of-procedures","title":"Types of Procedures","text":"FunctionProcedures ProperProcedures Extend built-in__ of language Operators Actions/statements Return single value - Set variables/perform output Placement Within-Expression Atomic Statements <code>r * sin(angle)</code> <code>read(ch)</code> Called byfunction \u2705 \u274c Called byprocedure \u2705 \u2705 PL C/C++ Pascal"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#procedure-definition","title":"Procedure Definition","text":"<ul> <li>Procedure Name</li> <li>Code body</li> <li>Formal Parameters</li> <li>Return type</li> </ul> <pre><code>function square(x:integer):integer\nbegin\n    square := x*x\nend\n</code></pre> <pre><code>int square(int x)\n{\n  return x*x;\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#note","title":"Note","text":"<p>C does not allows procedure bodies to be nested, so uses control links only. So calling a procedure means that procedure will be</p> <ul> <li>Within same procedure   (or)</li> <li>Outside all procedures</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#procedure-calls","title":"Procedure Calls","text":"<pre><code>procedure_name(parameters)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#procedure-activation","title":"Procedure Activation","text":"<p>Execution of procedure body</p> <p>Layout of activation is known at run-time</p> <p>Frame is put on the stack and storage within is accessed relative to the frame pointer.</p> <p>The values of variables in an activation are accessed as</p> <ul> <li>Frame Pointer + Displacement (or offset)</li> <li>Displacement is calculated at run-time</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#benefits-of-procedures","title":"Benefits of Procedures","text":"<ul> <li>Procedure Abstraction</li> <li>Hides implementation details</li> <li>Program Legibility</li> <li>Better maintainence</li> <li>Better modularity</li> <li>Code re-usability (user-defined and from libraries)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#parameter-passing-methods","title":"Parameter Passing Methods","text":"Call by value Call by reference Passed Absolute valueVariable AddressPointer Changes to formal parameter in the function affects the actual parameter? \u274c \u2705 Same memory location for Formal and actual parameter \u274c \u2705 Default in PL C Pascal"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#scope","title":"Scope","text":""},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#scope-of-variable","title":"Scope of Variable","text":"<p>Part of program where use of variable refers to its declaration</p> Static/Lexical Dynamic Binding occurs during Compilation Execution ProgrammerComprehensibility Easy Difficult Example CPascalJavaPearl (<code>my</code>) PythonLISPPearl (<code>local</code>) Rules A variable always refers to its top-level environment Variable declared within a block are not in the scope outside the block Global identifier refers to the identifier associated with the most recent environment Variables outside the block are visible unless overridden The occurrence of a identifier is searched in the most recent binding Binding of variable can be determined by program text, independent of run-time function call stack Each time a new function is executed, a new scope is pushed onto the stack. Compiler first searches in the current block, then in global variables The compiler first searches the current block and then successively all the calling functions. ### Scope Rules <p>Visibility rules for names in a PL; names could denote procedures, types, constants, variables</p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#macros","title":"Macros","text":"<ul> <li>Procedure body is substituted at every point of call</li> <li>Actual parameters are substituted for the formals   Different from call by value/reference</li> </ul> <p>Dynamic scoping</p> <pre><code>#define pi 3.14\n</code></pre> <p>Every occurance of <code>pi</code> is replace with \\(3.14\\) by the compiler.</p> <pre><code>#define product(x, y) x*y\n</code></pre> <p>Every call of <code>product(x, y)</code> is replaced with <code>x*y</code></p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#runtime-memory-model","title":"Runtime Memory Model","text":"<p>Layout of executable file</p> Segment Stores Code Machine code of program Static Data live throughout program execution- Global vars- Constants Stack Local variables of procedureProcedure activation records (C, Pascal) Space reclaimed when procedure terminatesRelative Address of variable are same Heap Dynamic memory allocationProcedure activation records Activation records stay here as long as they are needed <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#procedure-activations","title":"Procedure Activations","text":"<p>I didn't understand this</p> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#activation-record","title":"Activation Record","text":"<p>Activation records on stack are called as stack frame</p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#sections","title":"Sections","text":"Link Type Represents ___ environment of procedure Access Static Points to activation record for run-time caller defining Control Dynamic implement statically-scope languages calling"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#special-registers","title":"Special Registers","text":"Register Full-Form Pointer to PC Program Counter Next instruction to be executed SP Stack Pointer Last location allocated on call stack FP Frame Pointer Current activation record to allow access to local variable AP Argument Pointer Current argument/parameter"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#variables","title":"Variables","text":"<p>Storage is allocated at compile time</p> <p>Languages without recursive procedure treat all variables as static.</p> Static Local Lifetime Entire program Within procedure activation Retain values between activations? \u2705 \u274c(Bound to distinct storage in each activation) <p>Example for Static variable declaration in C <pre><code>static int count = 0;\nint count = 0; // variables declared outside main() are static by default\n</code></pre></p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#activation-tree","title":"Activation Tree","text":"<p>Tree representing procedure activations of program</p> <p>For eg: Trees for merge sort, quicksort in DSA</p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#garbage-collection","title":"Garbage Collection","text":"<p>Technique to reclaim storage that is no longer needed</p>"},{"location":"3_Core/Principles_of_Programming_Languages/06_Procedures/#recursion","title":"Recursion","text":"<p>Also called as multiple activation</p> <p>Recursive procedure is one that can be activated by its own body.</p> Traditional Recursion Tailed Recursion Nothing to do after the function returns, except return its value Compiler replaces caller with callee Last statement in the body of procedure is recursive call \u274c \u2705 Steps - Perform recursive calls first- Take the return value of the recursive call- Calculate the result - Perform your calculations first- Execute the recursive call- Passing results of current step to next Result of calculation obtained only after returning from every recursive call Re-useStack Frame \u274c(Nested Stack Frames) \u2705 Efficient \u274c \u2705 <pre><code>// Traditional\nfactorial(n) {\n    if (n == 0)\n    return 1;\n\n  return n * factorial(n - 1);\n}\n\n// Tailed\nfactorial1(n, accumulator)\n{\n  if (n == 0)\n    return accumulator;\n\n  return factorial1(n - 1, n * accumulator);\n}\n\nfactorial(n)\n{\n  return factorial1(n, 1);\n}\n</code></pre> <p>Converting a tailed-recursion logic into an equivalent control-flow logic is called as Tail-recursion elimination. This can be done using <code>goto</code></p>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/","title":"07 OOP","text":"<p>We did an entire course on this, so not much details have been written here. If any doubts, refer to <code>Sem 3 &gt; OOP</code> notes</p>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#oop","title":"OOP","text":"<p>Object-Oriented Programming</p> <ul> <li>Classes are collection of properties/functions</li> <li>Objects are instances of that class</li> <li>Subclass, Superclass</li> <li>Method: Procedure body implementing operation</li> <li>Message: Procedure call; request to execute method</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#purpose-of-oop","title":"Purpose of OOP","text":"<ul> <li>Data abstraction</li> <li>Data encapsulation</li> <li>Data hiding</li> <li>Polymorphism</li> <li>Inheritance   <code>is-a</code> relationships</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#classes","title":"Classes","text":"<ul> <li>Class declaration and definition</li> <li>Access specifiers</li> <li>Constructors</li> <li>Destructors (<code>~Class()</code>)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#binary-scope-resolution-operator","title":"Binary scope resolution operator","text":"<p>used for defining member function outside class</p> <pre><code>return_type ClassName::function_name()\n{\n\n}\n\n// constructor\nLine::Line() {\n   ;\n}\n\n// destructor\nLine::~Line() {\n   ;\n}\n\n// regular functions\nvoid Line::setLength() {\n   ;\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#inheritance","title":"Inheritance","text":"<ul> <li>Base/Parent/Super class</li> <li>Derived/Child/Sub class</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#purpose","title":"Purpose","text":"<p>It allows a class to __ properties/functions of another class</p> <ul> <li>Re-use</li> <li>Extend</li> <li>Modify</li> </ul> <pre><code>class derived_class:access_specifier base_class {\n\n};\n\nclass Rectangle: public Shape {\n   public:\n      int func() { \n        ;\n      }\n};\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#access-specifiers","title":"Access Specifiers","text":"<ul> <li>Public</li> <li>Protected</li> <li>Private</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#types","title":"Types","text":"<ul> <li>Single</li> <li>Multiple</li> <li>Multi-Level</li> <li>Hierarchical</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#polymorphism","title":"Polymorphism","text":""},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#function-overloading","title":"Function Overloading","text":"<p>based on different argument list</p>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#function-overriding","title":"Function overriding","text":"<p>Derived class function definition overrides parent class definition</p>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#operator-overloading","title":"Operator Overloading","text":"<p>Overloaded operators are functions with special names.</p> <pre><code>class className {\n  public:\n    returnType operator symbol (arguments) {\n        ;\n    } \n};\n</code></pre> <pre><code>class Person {\n  int age;\n  Person()\n  {\n    age = 0;\n  }\n  void operator ++ () {\n    ++age;\n  }\n};\n\nvoid main() {\n  Person p;\n\n  ++p;\n  // Calls ++ ()\" that I defined\n}\n</code></pre> <p>Following operators cannot be overloaded</p> <ul> <li>\\(::\\)</li> <li>\\(.*\\)</li> <li>\\(?:\\)</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#virtual-function","title":"Virtual Function","text":"<p>Declared using <code>virtual</code> in base class</p> <p>Member function of base class that is overriden by derived class</p> <p>When you refer to a derived class object using a pointer or a reference to the base class, you can call a virtual function for that object and execute the derived class\u2019s version of the function.</p> <p>Used to achieve runtime polymorphism</p> <p>Useful when you want a function to exist in the base class, but have no meaningful definition in the base class.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#mutable","title":"<code>mutable</code>","text":"<p>\u2026 is used for making data member of a object that is declared as a constant, to be changeable</p>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#explanation","title":"Explanation","text":"<p>If we have an object that is declared as a constant, then by default, all the data members of this object now become constant. However, if you want one/more specific data members to be changeable, use <code>mutable</code> next to the data member in the class defintion.</p> <pre><code>class Student\n{\n  public:\n    x = 0;\n    mutable y = 0;\n};\n\nvoid main()\n{\n  const Student s;\n\n  s.x = 10; // not possible\n  s.y = 10; // possible due to mutable keyword\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/07_OOP/#order-of-invokation-of-nested-objects","title":"Order of invokation of nested objects","text":"<ol> <li>Nested object constructor</li> <li>Outer object constructor</li> <li>Outer object destructor</li> <li>Nested object destructor</li> </ol>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/","title":"08 Python","text":""},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#characteristics-of-scripting-languages","title":"Characteristics of Scripting Languages","text":"<ul> <li>Both Batch and Interactive use</li> <li>Economy of Expression</li> <li>Lack of declarations; simple scoping rules</li> <li>Flexible dynamic typing</li> <li>Easy access to other programs</li> <li>Sophisticated Pattern matching</li> <li>High-level data types</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#python","title":"Python","text":"<p>is a general-purpose interpreted, interactive, object-oriented, and high-level programming language.</p> <p>It was created by Guido van Rossum during 1985-1990.</p> <p>Philosophy: Easy-to-read, easy-to-learn</p>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#variables","title":"Variables","text":"<p>No explicit declaration; declaration happens the first time you initialize variable</p>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#data-types","title":"Data Types","text":"<pre><code>x = True\nx = 5 ## int\nx = 5.4 ## float\nx = 'a' #string\nx = 1+10j ## complex number\nx = \"Ahmed Thahir\" ## string\nx = (\"a\", \"b\", \"c\") ## tuple \nx = [\"a\", \"b\", \"c\"] ## list\nrange(5) ## range from 0-4\nx = { ## dict\n  \"a\": \"x\",\n  \"b\": \"y\"\n}\nx = {\"a\", \"b\", \"c\"}\nx = frozenset({\"a\", \"b\", \"c\"}) ## frozenset\nx = b\"Hello\" ## bytes\nx = bytearray(5) ## bytearray\nx = memoryview(bytes(5)) ## memoryview\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#idk","title":"Idk","text":"<pre><code>x = str(3)\nx = int(3)\nx = float(3)\n\nprint(x)\nprint(type(x))\n\nfruits = [\"apple\", \"banana\", \"cherry\"]\nx, y, z = fruits\nprint(x, y, z)\n## apple banana cherry\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#conditional-statements","title":"Conditional Statements","text":"<pre><code>if x &lt; 10 or y &lt; 20:\n  print(1)\nelif x &gt; 20 and y &lt; 20:\n  print(2)\nelse\n    print(3)\n\nprint(1) if x &gt; 10 else print(2) if x&gt;20 else print(3)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#loops","title":"Loops","text":"<pre><code>i = 0\nwhile i &lt; 10:\n  if(i==3):\n    continue\n\n  if(i==5):\n    break\n\n  print(i)\n  i += 1\n</code></pre> <pre><code>for i in range(5):\n  print(i)\n\nfor i in range(1, 5, 3): ## starting, ending, updation\n  print(i)\n\nfor i in [3, 5, 7]:\n  print(i)\n\nfor ch in \"Hello\":\n  print(ch)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#pass-vs-comments","title":"Pass vs Comments","text":"<code>pass</code> <code>#comment</code> No operation CPU instruction(NOP) Skipped over <pre><code>def func(test):\n    ## comment\n  pass\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#list","title":"List","text":"<pre><code>a = [10, 20, 30, 40, 50]\n\nprint(a)\nprint(a[0])\nprint(a[-1])\n\nprint(a[3:5])\n## prints list with elements of index 3 and 4\n## tip to remember: no of elements = 5-3 = 2\n\nif 10 in a:\n  print(\"Yes\")\nif \"hi\" in a:\n  print(\"Yes\")\n</code></pre> <pre><code>a.append(\"hi\")\na.clear()\nb = a.copy()\na.count(\"hi\")\na.extend(another_list)\na.index(\"hi\")\n\na.insert(\"hi\", 3)\na.pop(3) ## index\na.remove(\"hi\") ## element\na.reverse()\na.sort()\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#list-comprehension","title":"List Comprehension","text":"<pre><code>new_list = [x for x in fruits if x &gt; 10]\nnew_list = [x for x in fruits if \"h\" in x]\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#tuple","title":"Tuple","text":"<p>is non-mutable</p> <pre><code>a = [10, 20, 30, 40, 50]\n\nprint(a)\nprint(a[0])\nprint(a[-1])\n\nprint(a[3:5])\n## prints tuple with elements of index 3 and 4\n## tip to remember: no of elements = 5-3 = 2\n\nif 10 in a:\n  print(\"Yes\")\nif \"hi\" in a:\n  print(\"Yes\")\n</code></pre> <pre><code>a.count(\"hi\")\na.index(\"hi\")\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#modifying-a-tuple","title":"Modifying a tuple","text":""},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#add-a-tuple","title":"Add a tuple","text":"<pre><code>x = (10, 20, 30, 40, 50)\nx += (60)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#you-have-to-convert-it-to-a-list-and-then-revert-it-to-a-tuple","title":"You have to convert it to a list and then revert it to a tuple","text":"<pre><code>x = (10, 20, 30, 40, 50)\nx = list(x)\n\nx.append(40)\nx[1] = 100\nx.remove(10)\nx += 50\n\nx = tuple(x)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#advantages","title":"Advantages","text":"<ul> <li>Better performance than list, as they are immutable</li> <li>Tuple ensures write-protection of elements</li> <li>General convention<ul> <li>Tuples for different data types</li> <li>Lists for similar data types</li> </ul> </li> <li>Tuples that contain immutable elements can be used as key for dictionary</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#dictionaries","title":"Dictionaries","text":"<p>key-value pairs</p> <p>keys have to be unique</p> <pre><code>student_marks = {\n  \"thahir\": 10,\n  \"ahmed\": 20\n}\n\nstudent_marks = dict(\n  thahir = 10,\n  ahmed = 20\n)\n\nprint(student_marks[\"thahir\"])\nprint(student_marks[\"ahmed\"])\n\nprint(students_marks.get(\"thahir\"))\n\nfor key in students_marks.keys():\n  print(students_marks[key])\n\nfor key, value in student_marks:\n  print(key, value)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#functions","title":"Functions","text":"<pre><code>student_marks.clear()\ns = student_marks.copy()\n\nnew_dict = dict.fromkeys((\"key1\", \"key2\"), 0)\n## gives a dictionary with the specified keys and specified value\n## {'key1': 0, 'key2': 0, 'key3': 0}\nnew_dict = dict.fromkeys((\"key1\", \"key2\"))\n## {'key1': None, 'key2': None, 'key3': None}\n\nstudent_marks.get(\"thahir\")\nstudent_marks.items() ## list of tuples\nstudent_marks.keys() ## list\nstudent_marks.values() ## list\n\nstudent_marks.pop(\"thahir\")\nstudent_marks.popitem() #remove last inserted key-value pair\n\nx = thisdict.setdefault(\"azhar\", 10)\n## Returns the value of the specified key. If the key does not exist: insert the key, with the specified value\n\nstudent_marks.update({\n  \"thahir\": 100\n})\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#nested","title":"Nested","text":"<pre><code>student_marks = {\n  \"thahir\": {\n    \"math\": 10,\n    \"science\": 20\n  },\n  \"ahmed\": {\n    \"math\": 10,\n    \"science\": 20\n  }\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#set","title":"Set","text":"<p>unordered and mutable collection of elements, which are unique and immutable</p> <pre><code>my_set = {\"thahir\", \"ahmed\", 10}\n\nfor x in my_set:\n  print(x)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#strings","title":"Strings","text":"<pre><code>a = 'hello world'\na = \"hello world\"\na = \"\"\"\nhello world\n\"\"\"\n\nprint(a)\nprint(a[0])\nprint(a[1:3])\n\nprint(a[-3:-1])\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#functions_1","title":"Functions","text":"<p>Values are passed by value, just like C++. However, pandas dataframes behave like pointers, and hence are passed by reference.</p> <pre><code>def func(name, age):\n  print(name, age)\n\n  return name\n\nname = func(\"ahmed\", 20)\nname = func(age=20, name=\"ahmed\")\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#arbitrary-arguments","title":"Arbitrary Arguments","text":"<p>When you are unsure how many parameters will be passed</p> <pre><code>def func(*args):\n  print(args) ## tuple\n  print(args[0], args[1])\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#default-argument","title":"Default Argument","text":"<pre><code>def func(name, age=20):\n  print(name, age)\n\nfunc(\"ahmed\")\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#keyword-arguments","title":"Keyword Arguments","text":"<pre><code>def func(**kwargs):\n  print(kwargs) ## dictionary\n  print(args[\"name\"], args[\"age\"])\n\nfunc(name = \"thahir\", age = 20)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#recursion","title":"Recursion","text":"<pre><code>def fact(n):\n  if(n==0):\n    return 1\n  else:\n    return n * fact(n-1)\n\nf = fact(10)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#classes","title":"Classes","text":"<p>The first argument to any function/constructor in a class is the class object itself</p> <pre><code>class Student:\n  def __init__(self): ## self can be anything (blah, bruh)\n    self.age = 20\n\nclass Student:\n  def __init__(bruh, name, age):\n    bruh.name = name\n    bruh.age = age\n  def print_name(bruh):\n    print(bruh.name)\n\n## object creation\ns = Student(\"thahir\", 20)\n\n## printing\nprint(s.age)\nprint(s.print_name())\n\n## modification\ns.age += 10\n\n## deletion\ndel s.age\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/08_Python/#inheritance","title":"Inheritance","text":"<pre><code>class Student:\n  def __init__(self, name): ## self can be anything (blah, bruh)\n    self.name = name\n    self.age = 20\n\nclass Math_Student(Student):\n  pass\n\nclass Sci_Student(Student):\n  def __init__(self, name):\n    Student.__init__(self, name)\n\nclass Eng_Student(Student):\n  def __init__(self, name):\n    super().__init__(name) ## no need of self\n\n## Multiple inheritance\nclass CS_Student(Sci_Student, Math_Student):\n  def __init__(self, name):\n    Sci_Student.__init__(self, name)\n    Math_Student.__init__(self, name)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/","title":"09 LISP","text":""},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#lisp","title":"LISP","text":"<p>LISt Processing</p> <p>In this course, we will use PICO LISP</p>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#functional-programming","title":"Functional Programming","text":"<p>is a subset of declarative programming</p> <p>is not tied to von Neumman machine</p> <p>Functional programs do not concern themselves with state and memory locations. They work exclusively with values, expressions and functions that compute values.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#characteristics","title":"Characteristics","text":"<ul> <li>Simple and concise syntax and semantics</li> <li>Repetition is done through recursion instead of iteration</li> <li>Functions are manipulated easily like any data type</li> <li>Data as functions   We can build a function on-the-fly and execute it</li> <li>Higher order functions   Arguments and results of a function can be functions</li> <li>Lazy evaluation   Expressions are evaluated only when necessary</li> <li>Garbage collection   Dynamic memory that is no longer required is automatically reclaimed by the system</li> <li>Polymorphic types   Functions can work on data of different types</li> <li>Easier mathematical manipulation compared to procedural programming</li> <li>Global assignments are not permitted (side effects are avoided)</li> <li>Easier parallelization   Possibility of performing function evaluation in parallel is inherent in the function definition. Hence, no new language construct is required to express parallelism.</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#symbolic-expressions","title":"Symbolic Expressions","text":"Examples Atom happybirthdayyouare20 (numeric atom) Lists Group of atoms(not comma-separated) (happy birthday)(you are 20)"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#lisp-procedures","title":"LISP Procedures","text":"<p>Defined in pre-fix format</p> <p>Invokation consists of </p> <ul> <li>pair of enclosing parentheses <code>(...)</code></li> <li>procedure</li> <li>arguments</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#primitives","title":"Primitives","text":"<p>A primitive is an inbuilt procedure such as <code>+, -, *, /</code></p> <pre><code>(+ 3.14 3) ; 6 (rounded-off)\n(- 3.14 3) ; 0 (rounded-off)\n(* 3.14 3) ; 9 (rounded-off)\n(/ 3.14 3) ; 1 (rounded-off)\n(% 3.14 3) ; 0 (rounded-off)\n\n(* (+ 3.14 3) 5) ; 30.0 (inner and outer calculations are rounded-off)\n\n(- -8) ; 8\n\n(max 3 5)   ; 5\n(min 3 5)   ; 3\n(sqrt 4)    ; 2\n(abs -5)    ; 5\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#procedure-abstraction","title":"Procedure Abstraction","text":"<p>constructing new user-defined procedures by combining existing ones</p> <p>A program is a collection of procedures</p> <p>Defined using <code>de</code> keyword</p> <pre><code>(\n de simple(x)\n x\n)\n\n(simple 2) ; 2\n\n(\n de pow(x n)\n (\n  if(= n 0)\n  1\n  ( ; else\n   *\n   x\n   (pow x (- n 1))\n  )\n )\n)\n\n(pow 2 3) ; 8\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#side-effect","title":"Side Effect","text":"<p>Anything done by a procedure that persists after it returns its value</p> <p><code>setq</code> function has a side effect that value of a variable changes</p>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#advanced-primitives","title":"Advanced Primitives","text":""},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#quote","title":"<code>quote</code>","text":"<p>Takes 1 argument</p> <p>returns the argument</p> <p>Used for characters; basically for the programming language to know if we are passing a string or a character</p> <p><code>\u201c...\u201d</code> is for strings</p> <pre><code>(quote (A))\n(quote (A B C))\n\n'A\n'(A B C)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#setq","title":"<code>setq</code>","text":"<p>Sets a value to a variable</p> <p>2 arguments</p> <pre><code>(setq &lt;variable&gt; &lt;value&gt;)\n\n(setq my_list (1 2 3))\n(setq my_list '(A B C))\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#car","title":"<code>car</code>","text":"<p>First element of a non-empyt list</p> <p>1 argument</p> <pre><code>(car my_list) ; A\n(car '(A B C)) ; A\n\n(car 'L) ; error, as this is not a list\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#cdr","title":"<code>cdr</code>","text":"<p>All elements except the first elemnt</p> <p>1 argument</p> <pre><code>(car my_list) ; (B C)\n(car '(A B C)) ; (B C)\n\n(car 'L) ; error, as this is not a list\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#cons","title":"<code>cons</code>","text":"<p>Create record structure</p> <p>2 arguments</p> <p>Returns a list such that</p> <ul> <li>arg1 is car</li> <li>arg2 is cdr</li> </ul> <pre><code>; dotted pair\n(cons 1 2) ; (1.2)\n(cons 'a 'b); (a.b)\n(cons 1 'b); (1.b)\n\n; regular list\n(cons 'a '(b c d)) ; (a b c d)\n(cons '(a b) '(c d)) ; ((a b) c d)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#append","title":"<code>append</code>","text":"<p>2 Arguments</p> <pre><code>(append (1 2) (3 4)) ; (1 2 3 4)\n\n(append '(A B) (3 4)) ; (A B 3 4)\n\n(append (1) (2) (3) 4) ; (1 2 3.4)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#list","title":"<code>list</code>","text":"<p>infinite arguments</p> <p>converts a list of arguments to a list</p> <pre><code>(list 1 2 3 4) ; (1 2 3 4)\n(list 'a 'b 'c 'd) ; (a b c d)\n\n(list 'a \"hello world\" (2 3) 'd) ; (a \"hello world\" (2 3) d)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#cond","title":"<code>cond</code>","text":"<p>conditional branching</p> <pre><code>(\n cond\n (test_1 action_1)\n (test_2 action_2)\n ...\n (test_n action_n)\n)\n\n; with t\n; t is like else\n; t\u00a0in a clause ensures that the last action is performed if none other would.\n(t(\n cond\n (test_1 action_1)\n (test_2 action_2)\n ...\n (testn action_n)\n (action_default)\n))\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/09_LISP/#dotted-pair","title":"Dotted Pair","text":"<p>created using <code>cons</code></p> <p>neither atoms nor lists</p>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/","title":"10 Prolog","text":""},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#logic-programming","title":"Logic Programming","text":"<p>Logic program is expressed as a set of atomic sentences(facts) and Horn clauses (rules)</p> <p>We can ask questions in the form of conjectures (like facts, but with variables) to find out what values will make the conjecture true</p> Statement Type of Statement Ramu is a boy Fact Ramu\u2019s father is Kicha Relationship Ramu eats chocolate if chocolates are available and chocolates have nuts Horn Clause(Rule) <p>LIPS: Logical Inferences per second</p>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#prolog","title":"Prolog","text":"<p>Consists of a database of predicates composed of facts and rules, involving constants and variables</p>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#properties","title":"Properties","text":"<ul> <li>There is no structure imposed on a Prolog program, there is no main procedure, and there is no nesting of definitions. </li> <li>Terminator is <code>.</code></li> <li>Assignment is performed using <code>is</code></li> <li>Program is executed by asking a question using <code>?-</code>, called a query</li> <li>All facts and rules are global in scope and the scope of a variable is the fact or rule in which it appears</li> <li>Facts, rules, and queries are called clauses. </li> </ul> Naming Rule Example Constant(Atoms) NumberString starting with lowercase letter tombilla1x217-33.74 Variable String starting with uppercase letterString starting with <code>_</code> Thahir_thahirX Fact True about some constant Predicate Function result, which can be true/false"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#relationship","title":"Relationship","text":"<pre><code>father(bukhari, thahir)\nmother(habeeb_fathima, bukhari)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#rules","title":"Rules","text":"Symbol Meaning <code>:-</code> <code>if</code> <code>,</code> <code>and</code> <code>;</code> <code>or</code> <pre><code>grandmother(x, z) :- mother(x, y), parent(y, z)\n\ngrandmother(x, z) :- mother(x, y), ( father(y, z); mother(y, z) )\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#query","title":"Query","text":"<p>Queries in Prolog are entered by the user following the  ?- prompt</p> <pre><code>?- grandmother(habeeb_fathima, thahir) % will give Yes\n?- grandmother(What, thahir) % will give habeeb_fathima\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#datatypes","title":"Datatypes","text":""},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#complex-term","title":"Complex term","text":"<p>No of arguments in a complex term is called arity</p> <pre><code>position(20, 10)\nemployee(1234, 'Jones', 'James', 1000)\nhide(X, father(father(father(butch))))\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#other","title":"Other","text":"<pre><code>% list\n[dog, cat, mouse]\n\n% records/tuples are represented as patterns; elements are accessed by pattern matching\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#example-of-a-knowledge-base","title":"Example of a Knowledge Base","text":"<pre><code>loves(vincent, mia).\nloves(marcellus, mia).\nloves(pumpkin, honey_bunny).\nloves(honey_bunny, pumpkin).\n\njealous(X, Y) :- loves(X, Z), loves(Y, Z).\n\n?- loves(X, mia) % gives us who loves mia\n?- jealous(X, Y) % gives us which pairs are jealous\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#database","title":"Database","text":"<pre><code>part(p001,nut).\npart(p002,bolt).\n\nsupplier(s001,abc).\nsupplier(s002,def).\n\npart_supplier_cost(p001,s001,0.10).\npart_supplier_cost(p002,s001,0.15).\n\nlist(Pkey):-\n  part(Pkey,Pname),\n  part_supplier_cost(Pkey,Skey,Cost),\n  supplier(Skey,Sname),\n\n  write(Pkey),write(' '),\n  write(Pname),write(' '),\n  write(Skey),write(' '),\n  write(Sname),write(' '),\n  write(Cost),nl.\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#type-predicates","title":"Type Predicates","text":"<p><code>=..</code> is used to compose and decompose terms</p>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#arithmetic-expression","title":"Arithmetic Expression","text":"<pre><code>?- X is 3*4.\n    X = 12\nyes\n</code></pre> <pre><code>plus(X, Y, Z) :- Z is X + Y.\n\n?- plus(2,3,Z)\nZ=5\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#unification","title":"Unification","text":"<p>Two terms unify,</p> <ul> <li>if they are the same term   or</li> <li>if they contain variables that can be uniformly instantiated with terms in such a way that the resulting terms are equal.</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#example","title":"Example","text":"Unify? mia and mia \u2705 42 and 42 \u2705 woman(mia) and woman(mia) \u2705 vincent and mia \u274c woman(mia) and woman(jody) \u274c <pre><code>?- mia = mia.\nyes\n\n?- mia = vincent.\nno \n\n?- mia = X.\nX=mia\nno\n\n?- X=mia, X=vincent.\nno\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#comparison-operators","title":"Comparison Operators","text":"Symbol Operation <code>A =:= B</code> A==B(value) <code>A =\\+= B</code> A!=B(value) <code>A &lt; B</code> numeric <code>A @&lt; B</code> String comparison <code>A =&lt; B</code> numeric <code>A @=&lt; B</code> String comparison <code>A &gt; B</code> numeric <code>A @&gt; B</code> String comparison <code>A &gt;= B</code> numeric <code>A @&gt;= B</code> String comparison <pre><code>3 @&lt; 4 % yes\n3 @&lt; a % yes\na @&lt; abc6 % yes\nab\u00a0@&lt; abc % yes\nabcd\u00a0@&lt; ab % no\n\n?- 3&gt;0 % yes\n</code></pre> <p>Value of functor with argument (term) is always more than any numeric and character (or string)</p>"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#logical-operators","title":"Logical Operators","text":"<pre><code>a :- b.                 % a if b\na :- b,c.               % a if b and c.\na :- b;c.               % a if b or c.\na :- not b.         % a if b fails\na :- b -&gt; c;d.  % a if (if b then c else d)\n</code></pre> Meaning <code>a :- b.</code> a if b <code>a :- b,c.</code> a if b and c <code>a :- b;c.</code> a if b or c <code>a :- not b.</code> a if b fails <code>a :- b -&gt; c;d.</code> a if (if b then c else d)"},{"location":"3_Core/Principles_of_Programming_Languages/10_Prolog/#functions","title":"Functions","text":"<p>Functions are implemented using relations</p> <pre><code>fac(0,1).\nfac(N,F) :- N &gt; 0, M is N - 1, fac(M,Fm), F is N * Fm.\n\n?- fac(5,F).\n120\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/","title":"11 Concurrent Programming","text":""},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#concurrent-programming","title":"Concurrent Programming","text":"<p>Making programs having cooperating processes that are set to achieve a common goal</p>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#ipc","title":"IPC","text":"<p>Inter-Process Communication</p> <p>Transfer data/info between address space, while ensuring protection and isolation</p> IPC Meaning Diagram \u2705Advantage \u274cDisadvantage Pipes(Shared buffer) - Exchange of messages- Named pipes allow processes on different computers to communicate over the network OS in control Overhead Shared Memory One process creates a portion of memory that another process accesses No overhead May require re-writing code Message Queue Ordered list of memory segments where processes store and retrieve data Process Synchronization mutex locksemaphoremonitors Files - Parent process creates 2 files before forking child process- Child inherits file descriptors from parent, and they share the file pointers- Can use one for parent to write and child to read, other for child to write and parent to read <pre><code>ipcs -a ## (linux only)\n</code></pre> <p>Lists all IPC facilities which has read access for the current process. It provides details abou message queue, semaphore, and shared memory.</p> <p>Every IPC facility has unique key and identifier, which is used to identify an IPC facility.</p> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#thread","title":"Thread","text":"<p>Basic unit of CPU utilization</p>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#components","title":"Components","text":"<ul> <li>thread ID</li> <li>program counter</li> <li>stack</li> <li>set of registers</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#advantages-of-multi-threading","title":"Advantages of Multi-Threading","text":"Advantage Description Responsiveness One thread can provide response, while other threads are blocked/slowed down due to intensive operations Resource-sharing Multiple tasks can be performed in a single address space Economy Creating, managing, context-switching between multiple threads is faster than that of multiple processes Scalability Utilization of multiprocessor architecture"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#types-of-threads","title":"Types of Threads","text":"Thread Type Description User Thread Threads that application programmers put in programsWithout kernel support Kernel Thread Supported within kernel of OS <p>In a specific implementation, user threads must be mapped to kernel threads</p> User Thread \\(\\to\\) Kernel Thread Mapping Example One \\(\\to\\) One Windows 95 \\(\\leftrightarrow\\) Windows XPDOS Many \\(\\to\\) One Word Processor Application Many \\(\\to\\) Many LinuxSolaris"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#thread-libraries","title":"Thread Libraries","text":"<p>Provide API for programmers to create and manage threads</p> <p>May be implemented in</p> <ul> <li>user space: no kernel support</li> <li>kernel space: involves system calls, requires kernel with thread library support</li> </ul> <p>3 present-day thread libraries</p> <ul> <li>POSIX Pthreads</li> <li>Win32 Threads</li> <li>Java Threads   Implementation of threads depends on which OS and hardware the JVM (Java Virtual Machine) is running on, ie, Pthreads/Win32</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#critical-section-problem","title":"Critical Section Problem","text":"Mutual Exclusion Only one process can execute at a time in their critical section Progress If no process is currently executing in their critical section, and one or more processes want to execute their critical section, then only the processes not in their remainder sections can participate in the decision, and the decision cannot be postponed indefinitely.( i.e. processes cannot be blocked forever waiting to get into their critical sections. ) Bounded Waiting Process requesting entry into their critical section will get a turn eventually, and there is a limit on how many other processes go first"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#mutex-lock","title":"Mutex Lock","text":"<pre><code>do {\n    acquire_lock() // returns when it is safe for process to enter critical section\n\n    critical section\n\n    release_lock() // allow another process to acquire lock\n\n    remainder section\n} while(True);\n</code></pre> <pre><code>acquire_lock(){\n    while(! available){\n        // if not available, then keep waiting until available\n        ; // causes busy waiting to keep checking if available\n    }\n\n    // if available\n    available = False;\n}\n\nrelease_lock(){\n    available = True;\n}\n</code></pre> <p>\u274c Busy loop is used to block processes in the acquire phase. These types of locks are referred to as spinlocks, because the CPU just spins while blocking the process, thus wasting CPU cycles. This is especially bad on single-CPU single-threaded machines, as this blocks the entire computer, and does not allow any process to release the lock.</p> <p>\u2705 Spinlocks do not have overhead of a context switch, so they are effectively used on multi-threaded machines, when it is expected that the lock will be released after a short time.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#semaphores","title":"Semaphores","text":"<p>Counters to control access to shared resources, used as a locking mechanism to prevent processes from accessing a particular resource while another process is performing operations on it.</p> <p>Actually implemented as sets.</p> <p>Semaphore is actually an old railroad term, referring to the crossroad \u2018arms\u2019 that prevent cars from crossing the tracks at intersections.</p> <ul> <li>If the semaphore is on (the arms are up), then a resource is available (cars may cross the tracks)</li> <li>else (the arms are down), then resources are not available (the cars must wait) </li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#dining-philosophers-problem","title":"Dining-Philosophers Problem","text":"<p>Consider five philosophers sitting around a table, in which there are five chopsticks evenly distributed and an endless bowl of rice in the center, as shown in the diagram below. ( There is exactly one chopstick between each pair of dining philosophers. )These philosophers spend their lives alternating between two activities: eating and thinking.</p> <ul> <li>When it is time for a philosopher to eat, it must first acquire two chopsticks - one from their left and one from their right.</li> <li>When a philosopher thinks, it puts down both chopsticks in their original locations.</li> </ul> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#solution","title":"Solution","text":"<p>Array of semaphores <code>chopsticks[0 ... (n-1)]</code></p> <p>Here, \\(n=5\\)</p> <pre><code>do {\n    wait(chopstick[i]);\n    wait(chopstick[(i+1)%n]);\n\n    // eat\n\n    signal(chopstick[i]);\n    signal(chopstick[(i+1)%n]);\n\n    // think\n\n} while(true);\n\nvoid wait(s)\n{\n  s--;\n}\n\nvoid signal(s)\n{\n  s++;\n}\n</code></pre> <p>\u274c But suppose that all five philosophers get hungry at the same time, and each starts by picking up their left chopstick. They then look for their right chopstick, but because it is unavailable, they wait for it, forever, and eventually all the philosophers starve due to the resulting deadlock.</p>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#monitor","title":"Monitor","text":"<p>Monitor is a class in which</p> <ul> <li>all data is private</li> <li>only one method within any given monitor object may be active at a time.</li> <li>methods may only access the shared data within the monitor and any data passed to them as parameters, ie, they cannot access any data external to the monitor</li> </ul> <pre><code>monitor Monitor_Name\n{\n  // shared variable declarations\n\n  procedure P1(){;}\n  procedure P2(){;}\n  ...\n  procedure Pn(){;}\n\n  initialization_code(){;}\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#data-type-condition","title":"Data Type <code>condition</code>","text":"<p>Variable <code>X</code> of type <code>condition</code> has only two legal operations</p> <ul> <li><code>X.wait()</code><ul> <li>Blocks a process until some other process calls <code>signal()</code></li> <li>adds the blocked process onto a list associated with that condition</li> </ul> </li> <li><code>X.signal()</code><ul> <li>does nothing if there are no processes waiting on that condition</li> <li>Otherwise, it wakes up exactly one process from the condition's list of waiting processes</li> </ul> </li> </ul> <p></p>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#disadvantage","title":"Disadvantage","text":"<p>If a process P within the monitor issues a <code>signal()</code> that would wake up process Q also within the monitor, then there would be two processes running simultaneously within the monitor, violating the exclusion requirement.</p> <p>Solutions for this</p> <ul> <li>Signal and wait   When process P issues the <code>signal()</code> to wake up process Q, P then <code>waits()</code>, either for Q to leave the monitor or on some other condition</li> <li>Signal and continue   When P issues the <code>signal()</code>, Q <code>waits()</code>, either for P to exit the monitor or for some other condition.</li> </ul>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#dining-philosophers-solution-using-monitors","title":"Dining Philosophers Solution using Monitors","text":"<p>Philosopher \\(i\\) can set variable <code>state[i] = EATING</code> only if two neighbours are not eating</p> <pre><code>cond = (\n  (state[(i+4) % 5] != EATING) and\n  (state[(i+1) % 5] != EATING)\n)\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/11_Concurrent_Programming/#full-implementation","title":"Full Implementation","text":"<pre><code>monitor DP\n{ \n\u00a0\u00a0\u00a0\u00a0status state[5]; \n\u00a0\u00a0\u00a0\u00a0condition self[5]; \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0// Pickup chopsticks \n\u00a0\u00a0\u00a0\u00a0Pickup(int i) \n\u00a0\u00a0\u00a0\u00a0{ \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// indicate that I\u2019m hungry \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0state[i] = hungry; \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// set state to eating in test() \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// only if my left and right neighbors\u00a0 \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// are not eating \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0test(i); \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// if unable to eat, wait to be signaled \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (state[i] != eating) \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0self[i].wait; \n\u00a0\u00a0\u00a0\u00a0} \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0// Put down chopsticks \n\u00a0\u00a0\u00a0\u00a0Putdown(int i) \n\u00a0\u00a0\u00a0\u00a0{ \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// indicate that I\u2019m thinking \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0state[i] = thinking; \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// if right neighbor R=(i+1)%5 is hungry and \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// both of R\u2019s neighbors are not eating, \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// set R\u2019s state to eating and wake it up by\u00a0 \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// signaling R\u2019s CV \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0test((i + 1) % 5); \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0test((i + 4) % 5); \n\u00a0\u00a0\u00a0\u00a0} \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0test(int i) \n\u00a0\u00a0\u00a0\u00a0{ \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0if (state[(i + 1) % 5] != eating \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&amp;&amp; state[(i + 4) % 5] != eating \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0&amp;&amp; state[i] == hungry) { \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// indicate that I\u2019m eating \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0state[i] = eating; \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// signal() has no effect during Pickup(), \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// but is important to wake up waiting \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0// hungry philosophers during Putdown() \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0self[i].signal(); \n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0} \n\u00a0\u00a0\u00a0\u00a0} \n\u00a0\u00a0\n\u00a0\u00a0\u00a0\u00a0init() \n\u00a0\u00a0\u00a0\u00a0{ \n      // Execution of Pickup(), Putdown() and test() \n      // are all mutually exclusive, \n      // i.e. only one at a time can be executing \n      for i = 0 to 4 \n      {\u00a0\n        // Verify that this monitor-based solution is \n        // deadlock free and mutually exclusive in that \n        // no 2 neighbors can eat simultaneously \n        state[i] = thinking; \n      }\n\u00a0\u00a0\u00a0\u00a0} \n} // end of monitor \n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/12_Non_Local_Jump/","title":"12 Non Local Jump","text":"<p>C mechanism to transfer control to any program point higher in the current stack, ie, to go to a function that called the current function.</p> <p>It is a form of \u2018non-local goto\u2019</p> <p>For eg, if we have 3 functions <code>f1(), f2(), f3()</code>, such that <code>f1()</code> invokes <code>f2()</code> and <code>f3()</code>. The calling diagram will be represented as follows</p> <pre><code>flowchart TB\nf1 --&gt; f2 &amp; f3</code></pre> Direction of jump Long jump possible? Higher \\(\\to\\) lower \u274c Lower \\(\\to\\) Higher \u2705 Adjacent \u274c"},{"location":"3_Core/Principles_of_Programming_Languages/12_Non_Local_Jump/#requirements","title":"Requirements","text":"Description Returns <code>setjmp.h</code> Header file N/A <code>jmp_buf jb</code> Store \u2018environment\u2019 of return point.It is a pointer to a structure.Stores- current register content- stack pointer- Program counter N/A <code>int setjmp(jb)</code> Set return point, by saving current state of program execution in <code>jb</code> 0 <code>void longjmp(jb, val)</code> Restores register context from jump buffer envSets function\u2019s return value register to <code>val</code>Jumps to the old PC value stored in jump buffer <code>jb</code> It itself does not return anything, butcauses <code>setjmp()</code> to return \\[ \\text{longjmp}(jb, \\textcolor{hotpink}{k})  \\text{ causes setjmp to return} \\\\ \\text{return val} = \\begin{cases} 1, \\textcolor{hotpink}{k} = 0 \\\\ k, \\textcolor{hotpink}{k} \\ne 0 \\end{cases} \\]"},{"location":"3_Core/Principles_of_Programming_Languages/12_Non_Local_Jump/#example","title":"Example","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;longjmp.h&gt;\n\njmp_buf jb;\n\nvoid f1()\n{\n  printf(\"Entering f1()\");\n\n  f2();\n\n  printf(\"Exiting f1()\");\n}\n\nvoid f2()\n{\n  printf(\"Entering f2()\");\n\n  f3();\n\n  printf(\"Exiting f2()\");\n}\n\nvoid f3()\n{\n  printf(\"Entering f3()\");\n\n  longjmp(buf);\n\n  printf(\"Exiting f3()\");\n}\n\nvoid main()\n{\n  printf(\"Entering main() function\");\n\n  setjmp(jb);\n  f1();\n\n  printf(\"Exiting main() function\");\n}\n</code></pre>"},{"location":"3_Core/Principles_of_Programming_Languages/12_Non_Local_Jump/#output","title":"Output","text":"<pre><code>Entering main() Function\nEntering f1()\nEntering f2()\nEntering f3()\nExiting main() Function\n</code></pre> <p>Notice how the exiting and return statements of <code>f1(), f2(), f3()</code> are skipped.</p>"},{"location":"3_Core/Theory_of_Computation/","title":"Theory Of Computation","text":"<p>Taught by Dr. Santhosh Kumar</p> <p>The course goes over various methods to represent 'machines' to solve problems. The focus is on the algorithm of the 'machine', rather than the implementation.</p>"},{"location":"3_Core/Theory_of_Computation/01_Alpha%2C_Strings%2C_Lang/","title":"01 Alpha, Strings, Lang","text":""},{"location":"3_Core/Theory_of_Computation/01_Alpha%2C_Strings%2C_Lang/#model-of-computation","title":"Model of Computation","text":"<ol> <li>FSM(Finite State Machine)    Has Memory/State</li> <li>FSM with Stack</li> <li>Turing Machine    Read/Write capability</li> </ol> <p>A problem that cannot be solved by a Turing Machine is not computable.</p>"},{"location":"3_Core/Theory_of_Computation/01_Alpha%2C_Strings%2C_Lang/#symbols","title":"Symbols","text":"Symbol Meaning Description \\(\\Sigma\\) Set of Alphabet Non-empty finite set of symbolseg: \\(\\{0, 1 \\}\\) String Finite sequence of zero/symbols \\(\\vert  s  \\vert\\) Length of string s \\(\\Sigma^k\\) Set of strings of length \\(k\\) \\(\\Sigma^1\\) Set of strings of length 1 eg: \\(\\{0, 1 \\}\\) \\(\\epsilon\\) Empty String \u201c\u201d \\(\\phi, \\{ \\}\\) Null set(Empty) \\(\\phi \\ne \\epsilon \\ne \\{\\epsilon\\}\\) \\(L\\) Language Finite/countably-infinite set of strings over a finite alphabet"},{"location":"3_Core/Theory_of_Computation/01_Alpha%2C_Strings%2C_Lang/#operations","title":"Operations","text":""},{"location":"3_Core/Theory_of_Computation/01_Alpha%2C_Strings%2C_Lang/#on-strings","title":"On Strings","text":"Operation Representation Description Concatenation \\(S_1 \\cdot S_2\\) \\(S_1\\) followed by \\(S_2\\) Power \\(S^n\\) Concatenation with itself for \\(n\\) times Closure $\\begin{aligned} \\Sigma^+ &amp;= \\Sigma^1 \\cup \\Sigma^2 \\cup \\dots \\ \\Sigma^* &amp;= \\Sigma^0 \\cup \\Sigma^1 \\cup \\Sigma^2 \\cup \\dots \\ &amp;=  { \\epsilon } \\cup \\Sigma^+ \\end{aligned}$ Union of infinite concatenation with itselfAlso called as Kleene Closure/Star"},{"location":"3_Core/Theory_of_Computation/01_Alpha%2C_Strings%2C_Lang/#on-languages","title":"On Languages","text":"Operation Representation Description Union \\(L_1 \\cup L_2\\) Union of both sets Intersection \\(L_1 \\cap L_2\\) Intersection of both sets Concatenation \\(L_1 \\cdot L_2\\) Complement $\\begin{aligned} &amp;L'\\ = &amp;\\Sigma^* - L \\end{aligned}$ Opposite of defined languageSwap all accepting and rejecting states Closure of languages \\(L^*\\) Similar to that of string Power Set of \\(\\Sigma^*\\) $\\begin{aligned} P(S) &amp;= 2<sup>{\\Sigma</sup>*} \\ \\vert  P(S) \\vert  &amp;= 2^{\\vert S \\vert} \\end{aligned}$ Set of all subsets of \\(\\Sigma^*\\) \\[ \\begin{aligned} L = \\phi \\implies L^* &amp;= \\{ \\epsilon \\} \\\\ \\text{How?} \\implies L^* &amp;= L^0 \\cup L^1 \\cup \\dots \\\\ &amp;= \\{ \\epsilon \\} \\cup \\phi \\cup \\dots \\\\ &amp;= \\{ \\epsilon \\} \\end{aligned} \\]"},{"location":"3_Core/Theory_of_Computation/02_DFA/","title":"02 DFA","text":""},{"location":"3_Core/Theory_of_Computation/02_DFA/#automator","title":"Automator","text":"Symbol Meaning Description A Automator State Machine(same as DD) FA Finite Automator Automator with finite no of states DFA Deterministic Finite Automator FA where \\(\\exists\\) next state \\(\\forall\\) states <p>States are the only mechanism for a FA to \u201cremember\u201d what it has seen of input string so far</p>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#dfa","title":"DFA","text":"<ul> <li>Can have more than one accept state</li> <li>Start state can also be an accept state</li> <li>DFA accepts \\(\\epsilon \\iff\\) start state is accepting state</li> </ul> Notation Meaning \\(\\enclose{circle}{q_0}\\) State \\(\\overset{1}{\\longrightarrow}\\) Transition \\(\\delta\\) \\(\\enclose{circle}{q_0} \\overset{1}{\\longrightarrow} \\enclose{circle}{q_1}\\) \\(\\delta(q_0, 1) = q_1\\) \\(\\enclose{circle}{\\enclose{circle}{\\ q_5 \\ }}\\) Accepting State Symbol Meaning \\(Q\\) Set of States \\(q_0\\) Starting State \\(F\\) Set of Final States \\(\\Sigma\\) Alphabet $\\begin{aligned} &amp;\\delta: Q \\times \\Sigma \\to Q \\ &amp; \\delta(\\text{Current State}, \\text{Input}) \\end{aligned}$ State Transition Function $\\begin{aligned} &amp;\\delta^: Q \\times \\Sigma^ \\to Q \\ &amp; \\delta(\\text{Current State}, \\text{Input}) \\end{aligned}$ Extended State Transition Function(Recursive traversal including \\(\\epsilon\\)) \\[ \\begin{aligned} \\delta (q, \\epsilon) &amp;= q \\\\ \\delta^* (q, \\epsilon) &amp;= \\{q, \\ \\dots\\} \\end{aligned} \\] <p>DFA seen as 5-Tuple</p> \\[ \\text{DFA} = D(Q, \\Sigma, \\delta, q_0, F) \\]"},{"location":"3_Core/Theory_of_Computation/02_DFA/#language-of-a-machine","title":"Language of a Machine","text":"<p>If \\(L\\) is the set of all strings that machine \\(M\\) accepts, then we say</p> <ul> <li>\\(M\\) recognizes \\(L\\)</li> <li>\\(L\\) is the language of machine \\(M\\)</li> </ul>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#notes","title":"Notes","text":"<ul> <li>Machine may accept several strings, but recognizes only one language</li> <li>If a machine accepts no strings, it still recognizes one language: empty language \\(\\phi\\)</li> </ul>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#regular-language","title":"Regular Language","text":"<p>A language \\(L\\) is regular if it is recognized by some DFA \\(M\\) \\(\\implies L(M)= L\\)</p> <p>Operations on a regular language gives another regular language(s)</p>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#closure-properties","title":"Closure Properties","text":"<p>Regular languages are closed under these operations</p> <ul> <li>\\(L1 \\cup L2\\)</li> <li>\\(L1 \\cap L2\\)</li> <li>\\(L1 - L2\\)</li> </ul>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#combination-of-machines","title":"Combination of Machines","text":"<p>Rather than deriving machines for everything, we can use the above operations to combine machines.</p> <p>If</p> <ul> <li>\\(Q_1, Q_2\\) are states of \\(M_1, M_2\\)</li> <li>\\(M_3\\) is combined machine and \\(Q_3\\) is the pair of states in \\(M_3\\)</li> </ul> <p>Then</p> <ul> <li>For \\(L1 \\cup L2 \\to F_3 = [F_1 \\times Q_2] \\cup [F_2 \\times Q_1]\\)</li> <li>For \\(L1 \\cap L2 \\to F_3 = F_1 \\times F_2\\)   Cross-Product of 2 DFA</li> <li>Max no of states in \\(Q_3\\) is given by \\(|Q_3|_\\max = |Q_1| \\times |Q_2|\\)</li> </ul>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#dfa-decidable-decision-problem","title":"DFA-Decidable Decision Problem","text":"<p>A decision problem that is solveable by algorithm that</p> <ul> <li>takes input of string of length \\(n\\)</li> <li>uses constant amount of memory</li> <li>runs in exactly \\(n\\) steps</li> </ul>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#regular-expression","title":"Regular Expression","text":"<p>Expression for which a FA exists, which can be used by a regular language.</p>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#dead-state","title":"Dead State","text":"<p>Also called as Sink/Trap state</p> <ul> <li>Once a machine enters a dead state, there is no way out</li> <li>Remaining input are ignored</li> <li>Only has self loop</li> <li>The input string is rejected</li> </ul> <p>In the following diagram, <code>b</code> is the deadstate</p> <pre><code>flowchart LR\na --&gt;|0| b\na --&gt;|1| c\n\nb --&gt;|0/1| b\n\nc --&gt;|0| b\nc --&gt;|1| a\n\nclassDef dead fill:darkred, color: #EEE\nclass b dead</code></pre>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#complement-of-dfa","title":"Complement of DFA","text":"<ul> <li>Accepting states \\(\\to\\) Non-Accepting states</li> <li>Non-Accepting states \\(\\to\\) Accepting states</li> </ul> \\[ \\begin{aligned} L&amp; \\implies M = ( Q, \u03a3, \u03b4, q_0, F ) \\\\ L'&amp; \\implies M' = ( Q, \u03a3, \u03b4, q_0, Q-F ) \\end{aligned} \\]"},{"location":"3_Core/Theory_of_Computation/02_DFA/#reversing-a-regular-expression","title":"Reversing a regular expression","text":"<p>Given a DFA</p> <ol> <li>Reverse all arrows of transitions of the DFA</li> <li>Swap the start state and accepting state    If there are 2 start states, use \\(\\epsilon\\) transition</li> <li>Convert NFA \\(\\to\\) DFA</li> </ol>"},{"location":"3_Core/Theory_of_Computation/02_DFA/#grep","title":"Grep","text":"<p>**G**et **re**gular ex**p**ression</p> <p>utility for identifying regular expressions</p>"},{"location":"3_Core/Theory_of_Computation/03_NFA/","title":"03 NFA","text":"<p>Non-deterministic Finite Automator</p> <p>Finite automator that only shows the transitions required for the pattern to be recognized.</p> <p>For a state \\(q\\) and symbol \\(a \\in \\Sigma\\), NFA can have</p> <ul> <li>no edge leaving \\(q\\) labelled with symbol \\(a\\)   or   multiple edges leaving \\(q\\) labelled with the same symbol \\(a\\)</li> <li>edges leaving \\(q\\) labelled with \\(\\epsilon\\)</li> <li>can take \\(\\epsilon\\)-edge without reading any symbol from input string.</li> </ul>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#advantage-of-nfa","title":"Advantage of NFA \u2705","text":"<ul> <li>Easier to construct than DFAs</li> <li>Easier to combine than DFAs for operations like union, concatenation etc. on regular languages</li> </ul>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#evaluation-of-nfa","title":"Evaluation of NFA","text":""},{"location":"3_Core/Theory_of_Computation/03_NFA/#tracing-steps","title":"Tracing Steps","text":"<ul> <li>NFA splits into multiple copies of itself (threads)<ul> <li>Each copy performs independent and parallel computation</li> </ul> </li> <li>At any instant, NFA will be in a set of states (one/more states)</li> <li>If a copy is in a state and there is no outgoing transition, then the copy dies/crashes<ul> <li>We discard this copy from our evaluation</li> </ul> </li> </ul>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#conclusion","title":"Conclusion","text":"<ul> <li>Accept, if atleast one copy ends in an accept state after reading entire input string</li> <li>Reject, if no copy ends in an accept state after reading entire input string</li> </ul>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#dfa-vs-nfa","title":"DFA vs NFA","text":"DFA NFA \\(\\Sigma\\) consist of only symbolsexcluding \\(\\epsilon\\) \\(\\Sigma_\\epsilon = \\Sigma \\cup \\epsilon\\) \\(\\delta\\) \\(Q \\times \\Sigma \\to Q\\) \\(Q \\times \\Sigma^* \\to P(Q)\\)(Power set of \\(Q\\)) No of states \\(\\uparrow\\) \\(\\downarrow\\) Easy to construct \u274c \u2705 Efficient Execution \u2705 \u274c(due to backtracking) Time Complexity \\(T\\) \\(O(k)\\) \\(O\\Big(k*f(m, n)\\Big)\\) <p>\\(k =\\) length of input string</p>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#notes","title":"Notes","text":"<ul> <li>Both DFA and NFA accept the same class of languages called Regular Languages</li> <li>Every NFA has an equivalent DFA</li> <li>NFAs have the same power as DFAs</li> <li>Parallel (or non deterministic execution) does not add any computation power to NFAs</li> <li>Power of a machine is defined based on the class of languages recognized by the machine.</li> </ul>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#epsilon-closure-of-a-set-of-states","title":"\\(\\epsilon\\)-Closure (of a set of states)","text":"<p>Set of states that can be reached transitively from a state by travelling using 0 or more \\(\\epsilon\\) transitions</p>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#nfa-to-dfa","title":"NFA \\(\\to\\) DFA","text":"<p>For every transition, we will have a set of states</p> <p>These combination of states will be renamed as a single new state.</p>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#nfa-for-operations","title":"NFA for Operations","text":""},{"location":"3_Core/Theory_of_Computation/03_NFA/#union","title":"Union","text":"<p>Let\u2019s say you have 2 NFAs</p> <ul> <li>Take both the NFAs</li> <li>Introduce an extra starting state<ul> <li>Introduce a \\(\\epsilon\\) transition to each of the starting states of the NFAs</li> </ul> </li> <li>Introduce an extra ending state<ul> <li>Introduce a \\(\\epsilon\\) transition from each of the ending states of the NFAs</li> </ul> </li> </ul> <pre><code>flowchart LR\nq0((q0)) --&gt;|\u03b5| NFA1 &amp; NFA2 --&gt;|\u03b5| qf</code></pre>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#intersection","title":"Intersection","text":"<p>No simple method; you have to do cross product</p>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#concatenation","title":"Concatenation","text":"<ul> <li>Draw both the NFAs</li> <li>Connect end state of one NFA to start state of other NFA</li> </ul> <pre><code>flowchart LR\nNFA1 --&gt;|\u03b5| NFA2</code></pre>"},{"location":"3_Core/Theory_of_Computation/03_NFA/#wr","title":"\\(W^R\\)","text":"<p>Reversed word</p> <p>(similar to DFA only; however, here we are given an NFA and are asked for an NFA)</p> <ol> <li>Swap the direction of every transition</li> <li>Swap starting and accepting states</li> </ol>"},{"location":"3_Core/Theory_of_Computation/04_Reg_Ex/","title":"04 Reg Ex","text":""},{"location":"3_Core/Theory_of_Computation/04_Reg_Ex/#regular-language-types","title":"Regular Language Types","text":"RL Description Method Difficulty forHuman Difficulty forComputer Verbal Textual Easy Difficult(Natural Language Processing required) Reg Ex Algebraic Slightly difficult Difficult NFA Diagrammatic Medium Medium DFA Diagrammatic Difficult Easy"},{"location":"3_Core/Theory_of_Computation/04_Reg_Ex/#regular-expression","title":"Regular Expression","text":"<p>are algebraic expression to describe the same class of strings (which can be recognized with finite memory)</p> <p>Denoted as \\(R\\)</p>"},{"location":"3_Core/Theory_of_Computation/04_Reg_Ex/#atomic","title":"Atomic","text":"<ul> <li>\\(R = 0\\) means \\(\\{0 \\}\\)</li> </ul>"},{"location":"3_Core/Theory_of_Computation/04_Reg_Ex/#composite","title":"Composite","text":"<p>Atomic regex with operations (in order of precedence)</p> <ul> <li>Kleene star \\({}^*\\)</li> <li>concatenation \\(\\cdot\\)</li> <li>union: represented with \\(\\cup\\) or \\(|\\) or \\(+\\)</li> </ul> <p>Think similar to BODMAS: ^\\(,\\times , +\\)</p> <p>Other operators</p> <ul> <li>\\(R^+ = RR^*\\)</li> <li>\\(R^k\\) for k -fold concatenation</li> </ul>"},{"location":"3_Core/Theory_of_Computation/05_CFG/","title":"05 CFG","text":"<p>Refer to POPL notes, as this is kinda repeated</p>"},{"location":"3_Core/Theory_of_Computation/05_CFG/#grammar","title":"Grammar","text":"<p>Set of substitution/production rules to derive a string, applied \\(k\\) times</p> <p>Grammar is way to</p> <ul> <li>Describe a language   Represent all possible legal strings</li> <li>Derive a sentence   Generate a legal string of the language</li> <li>Analyze a sentence   Check if given string is valid (opposite of derivation)</li> </ul>"},{"location":"3_Core/Theory_of_Computation/05_CFG/#parse-tree","title":"Parse Tree","text":"<p>Visual representation of derivation of a string, using a grammar</p>"},{"location":"3_Core/Theory_of_Computation/05_CFG/#cfg","title":"CFG","text":"<p>Context-Free Grammar</p> <p>Context-free grammar</p> \\[ \\text{CFG} = G(V, \\Sigma, R, S) \\] \\(V\\) Finite set of variables/non-terminals \\(\\Sigma\\) Finite set of terminals \\(R\\) Finite set of substitution rules \\(S\\) Start symbol <p>\\(V \\cap \\Sigma = \\phi\\)</p>"},{"location":"3_Core/Theory_of_Computation/05_CFG/#cfg-vs-csg","title":"CFG vs CSG","text":"CFG CSG \\(X\\) Single non-terminal \\(\\in (V \\cup \\Sigma)^+\\) Substitution independent of context \\(X\\) appears in \u2705 \u274c"},{"location":"3_Core/Theory_of_Computation/05_CFG/#derivations","title":"Derivations","text":"<p>\\(u \\overset{*}{\\implies} v\\) means \\(u\\) derives \\(v\\)</p> <ul> <li>\\(u = v\\)</li> <li>or   \\(\\exists \\ u_1, u_2, \\dots u_k\\) such that \\(u \\implies u_1 \\implies u_2 \\implies \\dots \\implies v\\)</li> </ul> <p>\\(\\overset{*}{\\implies}\\) denotes a sequence of zero/more single step-derivations</p> <p>Note</p> <p>\\(\\to\\) and \\(\\implies\\) are di\ufb00erent</p> <ul> <li>\\(\\to\\) used in de\ufb01ning rules (productions)</li> <li>\\(\\implies\\) used in derivation</li> </ul>"},{"location":"3_Core/Theory_of_Computation/05_CFG/#cfl","title":"CFL","text":"<p>Context-Free Language</p> <p>Lang which can be generated by a CFG</p> \\[ L(G) = \\{ w \\in \\Sigma^* | S \\overset{*}{\\implies} w \\} \\] \\[ L(G) \\subseteq \\Sigma^* \\] <pre><code>flowchart LR\n\nsubgraph Languages\n  subgraph CFL\n    RL\n  end\nend\n\nclassDef bg2 fill:#222, color:white\nclass Languages bg2</code></pre>"},{"location":"3_Core/Theory_of_Computation/05_CFG/#ambiguous-grammar","title":"Ambiguous Grammar","text":"<p>Multiple parse tree for a single string</p> <p>\\(\\exists\\) multiple interpretations for the string</p> <p>Examples</p> <ul> <li>Arithmetic expressions evaluation without BODMAS</li> <li>Balenced parenthesis evaluation</li> </ul>"},{"location":"3_Core/Theory_of_Computation/06_PDA/","title":"06 PDA","text":""},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda","title":"PDA","text":"<p>Pushdown Automaton</p> <p>NFA + Stack</p> <p>Also represented as NPDA (non-deterministic)</p> \\[ \\text{PDA} \\implies M(Q, \\Sigma, \\Gamma, \\delta, q_0, F) \\] Symbol Meaning \\(Q\\) Set of States \\(\\Sigma\\) Set of input alphabet \\(\\Sigma_\\epsilon = \\Sigma \\cup \\epsilon\\) \\(\\Gamma\\) Set of stack alphabet \\(\\Gamma_\\epsilon = \\Gamma \\cup \\epsilon\\) \\(\\delta\\) Transition Function \\(\\delta: Q \\times \\Sigma_\\epsilon \\times \\Gamma_\\epsilon \\to P(Q \\times \\Gamma_\\epsilon)\\) \\(q_0\\) Start state \\(F\\) Set of accepting states <ul> <li>States \\(Q\\)</li> <li>Input Alphabet \\(\\Sigma\\)</li> <li>Stack Alphabet \\(\\Gamma\\)<ul> <li>$ marks the bottom of stack</li> <li>Symbols are pushed/popped to/from stack</li> </ul> </li> <li>Transitions<ul> <li>If PDA is current in state \\(q_i\\)</li> <li>it reads \\(a \\in \\Sigma_\\epsilon\\) off the stack</li> <li>it pops \\(b \\in \\Gamma_\\epsilon\\) off the stack</li> </ul> </li> </ul>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#conclusion","title":"Conclusion","text":"<p>Same as NFA Conclusion</p>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#note","title":"Note","text":"<p>DPDA means DFA + Stack</p> <ul> <li>Every DPDA has an equivalent PDA</li> <li>Not every PDA has an equivalent DPDA</li> </ul>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#stack-operations","title":"Stack Operations","text":"Operation Representation Pop 0 and Push 1 \\(0 \\to 1\\) Push 0(Pop \\(\\epsilon\\), Push 0) \\(\\epsilon \\to 0\\) Pop 0(Pop 0, Push \\(\\epsilon\\)) \\(0 \\to \\epsilon\\) <pre><code>flowchart LR\nq0((q0)) --&gt;|\"input, push &amp;rarr; pop\"| q1((q1))</code></pre>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#cfl","title":"CFL","text":"<p>Context-Free Language</p> <p>Language that is recognized by a PDA</p> <p>The intersection of 2 context-free languages does not result in another CFL</p> Deterministic CFL Non-Deterministic CFL \\(\\exists\\) DPDA? \u2705 \u274c Example Programming Languages - \\(w w^R\\)- \\(0^n 1^n\\)"},{"location":"3_Core/Theory_of_Computation/06_PDA/#closed-operations","title":"Closed Operations","text":"<p>Let \\(L_1, L_2\\) have grammar \\(G_1 = \\{S_1 \\to A\\}, G_2 = \\{S_2 \\to B\\}\\)</p> Operation New Grammar \\(G_\\text{new}\\) \\(L^*\\) \\(\\{SS \\vert  \\epsilon \\}\\) \\(L_1 \\cdot L_2\\)(concatenation) \\(\\{S_1 \\cdot S_2 \\}\\) \\(L_1 \\cup L_2\\) \\(\\{S_1 \\vert  S_2\\}\\)"},{"location":"3_Core/Theory_of_Computation/06_PDA/#note_1","title":"Note","text":"<p>Using properties, we can say that \\(L=\\{a^n b^n | n \\ge 0, n \\ne 50 \\}\\) is CFL</p> <p>This is because</p> \\[ \\begin{aligned} L =&amp; \\{a^n b^n \\} - \\{a^{50} b^{50} \\} \\\\ =&amp; \\{a^n b^n \\} \\cap \\{a^{50} b^{50} \\}' &amp; &amp; \\Big( A-B = A \\cap B' \\Big) \\\\ =&amp; \\text{CFL} \\cap \\text{RL} &amp;&amp; {\\Big( (RL)' \\to RL \\Big)} \\\\ \\implies &amp; \\text{CFL} \\end{aligned} \\]"},{"location":"3_Core/Theory_of_Computation/06_PDA/#non-closed-operations","title":"Non-Closed Operations","text":"<ul> <li>Intersection is not closed \\(\\implies L_1 \\cap L_2\\) is not always CFL</li> <li>Complement is not closed \\({L_1}'\\) is not always CFL</li> </ul>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-cfg","title":"PDA for CFG","text":"<p>Initialize stack as $</p>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#leftmost-derivation","title":"Leftmost Derivation","text":"Top of Stack Input Non-Terminal Pop itPush RHS of rule Terminal Terminal Pop it $ Pop itAccept string <p>As pushing strings instead of a symbol into stack is not possible, we can use another approach, as both are equivalent.</p> <pre><code>flowchart LR\nsubgraph B\n    direction LR\n    p0((q0)) --&gt;\n    |\"a, b &amp;rarr; x\"| p1((q1)) --&gt;\n    |\"&amp;epsilon;, &amp;epsilon; &amp;rarr; y\"| p2((q2)) --&gt;\n    |\"&amp;epsilon;, &amp;epsilon; &amp;rarr; z\"| p3((q3))\nend\n\nsubgraph A\n    direction LR\n    q0((q0)) --&gt;|\"a, b &amp;rarr; xyz\"| q1((q1))\nend</code></pre>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#classic-questions","title":"Classic Questions","text":""},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-0n-1n","title":"PDA for \\(0^n 1^n\\)","text":"<pre><code>flowchart LR\nq0(((q0))) --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; $\"| q1((q1)) --&gt;\n|\"\n0, &amp;epsilon; &amp;rarr; 0\n(Push)\n\"| q1 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q2((q2)) --&gt;\n|\"\n1, 0 &amp;rarr; &amp;epsilon;\n(Pop)\n\"|q2 --&gt;\n|\"&amp;epsilon;,  $ &amp;rarr; &amp;epsilon;\"| q3(((q3)))</code></pre> <p>The reason why \\(1, 0 \\to \\epsilon\\) for \\(q_2\\to q_3\\) can be replaced by \\(\\epsilon, \\textcolor{hotpink}{\\epsilon} \\to \\epsilon\\) is because the top of stack should be \\(\\textcolor{hotpink}{\\epsilon}\\). The top of stack can be thought as the actual top of stack or an empty string \u201c\u201d \\((\\epsilon)\\)</p> Input \\(\\rightarrow\\) \\(0\\) \\(1\\) \\(\\epsilon\\) Stack Top \\(\\rightarrow\\) \\(0\\) $ \\(\\epsilon\\) \\(0\\) $ \\(\\epsilon\\) \\(0\\) $ \\(\\epsilon\\) \\(q_0\\) {(q_1, $)} \\(q_1\\) \\(\\{(q_1, 0)\\}\\) \\(\\{(q_2, \\epsilon)\\}\\) \\(q_2\\) \\(\\{(q_2, \\epsilon)\\}\\) \\(\\{(q_3, \\epsilon)\\}\\) \\(q_3\\) <p>(Blank entries are \\(\\phi\\))</p>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-wwr","title":"PDA for \\(ww^R\\)","text":"<pre><code>flowchart LR\nq0((q0)) --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; $\"| q1 --&gt;\n|\"\n0, $ &amp;rarr; 0$\n1, $ &amp;rarr; 1$\n0, 0 &amp;rarr; 00\n0, 1 &amp;rarr; 01\n1, 0 &amp;rarr; 10\n1, 1 &amp;rarr; 11\n(Push)\n\"| q1((q1)) --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q2 --&gt;\n|\"\n0, 0 &amp;rarr; &amp;epsilon;\n1, 1 &amp;rarr; &amp;epsilon;\n(Pop)\n\"|q2((q2)) --&gt;\n|\"&amp;epsilon;, $ &amp;rarr; &amp;epsilon;\"| q3(((q3)))</code></pre>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-ai-bj-ck-i-j-k-ge-0-land-bigij-lor-ik-big","title":"PDA for \\(a^i b^j c^k: (i, j, k \\ge 0) \\land \\Big((i=j) \\lor (i=k) \\Big)\\)","text":"<p>We can simplify the regex: our PDA will accept the following strings</p> <ul> <li>\\(a^i b^i c^*\\)</li> <li>\\(a^i b^* c^i\\)</li> </ul> <pre><code>flowchart LR\nq0(((q0)))\nq1((q1))\nq2((q2))\nq3((q3))\nq4((q4))\nq5((q5))\nq6((q6))\n\nq0 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; $\"| q1 --&gt;\n|\"a, &amp;epsilon; &amp;rarr; a\"| q1 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q2 &amp; q4\n\nq2 --&gt;\n|\"b, a &amp;rarr; &amp;epsilon;\"| q2 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q3 --&gt;\n|\"c, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q3\n\nq4 --&gt;\n|\"b, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q4 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q5 --&gt;\n|\"c, a &amp;rarr; &amp;epsilon;\"| q5 --&gt;\n|\"&amp;epsilon;, $ &amp;rarr; &amp;epsilon;\"| q6</code></pre>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-an-b2n","title":"PDA for \\(a^n b^{2n}\\)","text":"<pre><code>flowchart LR\nq0(((q0)))\nq1((q1))\nq2((q2))\nq3((q3))\nq4(((q4)))\n\nq0 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; $\"| q1 --&gt;\n|\"a, &amp;epsilon; &amp;rarr; a\"| q1 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q2 --&gt;\n|\"b, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q3 --&gt;\n|\"b, a &amp;rarr; &amp;epsilon;\"| q2\n\nq2 --&gt; |\"&amp;epsilon;, $ &amp;rarr; &amp;epsilon;\"| q4</code></pre>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-a2n-b3n","title":"PDA for \\(a^{2n} b^{3n}\\)","text":"<pre><code>flowchart LR\nq0(((q0)))\nq1((q1))\nq2((q2))\nq3((q3))\nq4((q4))\nq5((q5))\nq6(((q6)))\n\nq0 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; $\"| q1 --&gt;\n|\"a, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q2 --&gt;\n|\"a, &amp;epsilon; &amp;rarr; a\"| q1 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q3 --&gt;\n|\"b, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q4 --&gt;\n|\"b, &amp;epsilon; &amp;rarr; &amp;epsilon;\"| q5 --&gt;\n|\"b, a &amp;rarr; &amp;epsilon;\"|q3\n\nq3 ---&gt;\n|\"&amp;epsilon;, $ &amp;rarr; &amp;epsilon;\"| q6</code></pre>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-g-s-to-text0ts1-1t0-t-to-1","title":"PDA for \\(G = \\{S \\to \\text{0TS1} | 1T0 , T \\to 1 \\}\\)","text":"<pre><code>flowchart LR\nq0((q0))\nq1((q1))\nq2(((q2)))\n\nq0 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; &lt;span style=background:yellow;color:black;font-weight:bold&gt;S$&lt;/span&gt;\"| q1 --&gt;\n|\"\n&amp;epsilon;, S &amp;rarr; 0TS1\n&amp;epsilon;, S &amp;rarr; 1T0\n&amp;epsilon;, T &amp;rarr; 1\n0, 0 &amp;rarr; &amp;epsilon;\n1, 1 &amp;rarr; &amp;epsilon;\n\"| q1 --&gt;\n|\"&amp;epsilon;, $ &amp;rarr; &amp;epsilon;\"| q2</code></pre>"},{"location":"3_Core/Theory_of_Computation/06_PDA/#pda-for-g-s-to-0s1-quad-0n-1n","title":"PDA for \\(G = \\{S \\to 0S1\\} \\quad (0^n 1^n)\\)","text":"<pre><code>flowchart LR\nq0((q0))\nq1((q1))\nq2((q2))\n\nq0 --&gt;\n|\"&amp;epsilon;, &amp;epsilon; &amp;rarr; S$\"| q1 --&gt;\n|\"\n&amp;epsilon;,  S &amp;rarr; 1S1\n0, 0 &amp;rarr; &amp;epsilon;\n1, 1 &amp;rarr; &amp;epsilon;\n\"| q1 --&gt;\n|\"&amp;epsilon;, $ &amp;rarr; &amp;epsilon;\"| q2</code></pre>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/","title":"07 Turing Machine","text":""},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#cromsky-hierarchy","title":"Cromsky Hierarchy","text":""},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#turing-machine","title":"Turing Machine","text":"<p>NFA + Read/Write Capability</p> <ul> <li>Read/write happens from/to an \u2018infinite tape\u2019</li> <li>Read-write head can move left and right</li> <li> <p>Initially, all cells of the tape have special blank symbol \\(\\square\\), except where the input string exists</p> </li> <li> <p>FSMs always halt after \\(n\\) steps, where \\(n\\) is the length of the input. At that point, they either accept or reject.</p> </li> <li>PDAs don't always halt, but there is an algorithm to convert any PDA into one that does halt.</li> <li>Turing machines can do one of the following</li> <li>Halt and accept</li> <li>Halt and reject</li> <li>Not halt       If a turing machine loops forever \\(\\implies \\not \\exists\\) algorithm to solve the problem</li> </ul> Symbol Meaning \\(Q\\) Finite set of states \\(\\Sigma\\) Finite set of input alphabet \\(\\Gamma\\) Finite set of tape alphabet, such that\\(\\square \\in \\Gamma\\)\\(\\Sigma \\in \\Gamma\\) \\(q_0\\) Start state \\(q_\\text{acc}\\) Accepting state \\(q_\\text{rej}\\) Rejecting state \\(\\delta\\) Transition function\\(Q \\times \\Gamma \\to Q \\times \\Gamma \\times \\text{\\{L, R\\}}\\)"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#transition-in-expression-form","title":"Transition in Expression form","text":"<p>\\(\\delta(q_0, a) = (q_1, b, L)\\) represents a transition with</p> <ul> <li>Current state \\(q_0\\)</li> <li>\\(a\\) is current tape input character</li> <li>New state \\(q_1\\)</li> <li>\\(b\\) is new tape input character</li> <li>\\(L\\) is the direction that read-write head moves</li> </ul>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#transition-in-diagram-form","title":"Transition in Diagram Form","text":"<p><code>&lt;tape_input&gt;/&lt;tape_write&gt;, &lt;direction&gt;</code></p> <pre><code>flowchart LR\nq0((q0)) --&gt;|1/X, R| q1((q1))</code></pre>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#uses","title":"Uses","text":"<ul> <li>Language decider/recognizer<ul> <li>Yes/No output</li> <li>Halts for correct input</li> <li>May not halt for wrong inputs</li> </ul> </li> <li>Compute functions<ul> <li>Reverse string</li> <li>Computing systems</li> </ul> </li> </ul>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#hailstone-sequence","title":"Hailstone Sequence","text":"<p>For example, for a starting number of 7, the sequence is 7, 22, 11, 34, 17, 52, 26, 13, 40, 20, 10, 5, 16, 8, 4, 2, 1, 4, 2, 1, .... Such sequences are called hailstone sequences because the values typically rise and fall, somewhat analogously to a hailstone inside a cloud.</p> <p>Suppose we have</p> <p>(Code not required to be studied)</p> <pre><code>#include &lt;stdio.h&gt;\nint main()\n{\n  unsigned int n;        \n  printf(\"Pl. enter no :\");    \n  scanf(\"%d\", &amp;n);    \n\n  while ( n &gt; 0 )\n  {\n    printf( \"%d \", n);\n    if (n == 1)\n      break;\n    if (!(n &amp; 1))\n      n /= 2;\n    else\n      n = 3*n + 1;\n  }    \n\n  printf(\"Done \\n\");\n  return 0;\n}\n</code></pre> <p>Is there any n for which the program does not terminate, ie does not converge to 1? It is inconclusive, as we do not know.</p> <p>Hence, the turing machine may not halt for this problem.</p>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#questions","title":"Questions","text":""},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#0n-1n-n-ge-1","title":"\\(0^n 1^n, n \\ge 1\\)","text":"<pre><code>flowchart LR\n\nsubgraph Only X\ndirection LR\n\nq0((q0))\nq1((q1))\nq2((q2))\nq3((q3))\nq4((q4))\nq5(((q5)))\n\nq0 --&gt;\n|0/X, R| q1 --&gt;\n|\"\n0/0, R\nX/X, R\n\"| q1 --&gt;\n|1/X, L| q2 --&gt;\n|X/X, L| q2 --&gt;\n|\"0/0, L\"| q3 --&gt;\n|\"0/0, L\"| q3 --&gt;\n|\"X/X, R\"| q0\n\nq2 --&gt;\n|\"&amp;square;/&amp;square;, R\"| q0\n\nq0 ---&gt;\n|\"X/X, R\"| q4 --&gt;\n|\"X/X, R\"| q4 --&gt;\n|\"&amp;square;/&amp;square;, R\"| q5\n\nend\n\nsubgraph Using X &amp; Y\ndirection LR\np0((q0))\np1((q1))\np2((q2))\np3((q3))\np4(((q4)))\n\np0 --&gt;\n|0/X, R| p1 --&gt;\n|\"\n0/0, R\nY/Y, R\n\"| p1 --&gt;\n|1/Y, L| p2 --&gt;\n|\"\n0/0, L\nY/Y, L\n\"| p2 --&gt;\n|X/X, R| p0 --&gt;\n|Y/Y, R| p3 --&gt;\n|Y/Y, R| p3 --&gt;\n|\"&amp;square;/&amp;square;, R\"| p4\nend</code></pre>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#w-w","title":"\\(w w\\)","text":"<p>Kinda complicated</p>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#w-wr","title":"\\(w w^r\\)","text":"<p>Kinda complicated</p>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#balanced-parantheses","title":"Balanced Parantheses","text":"<p>We first look for closing bracket; The opening bracket for a given closed bracket is always the first one on its left; converse statement is not true.</p> <pre><code>flowchart LR\nq0((q0))\nq1((q1))\nq2((q2))\nq3((q3))\nq4(((q4)))\n\nq0 --&gt;\n|\"\n(/(, R\nX/X, R\n\"| q0 --&gt;\n|\")/X, R\"| q1 --&gt;\n|\"X/X, L\"| q1 --&gt;\n|\"(/X, R\"| q0 --&gt;\n|\"&amp;square;/&amp;square;, L\"| q3 --&gt;\n|\"X/X, L\"| q3 --&gt;\n|\"&amp;square;/&amp;square;, R\"| q4\n\nq3 --&gt;|\"(/(, R\"| q2\n\nq1 --&gt;\n|\"&amp;square;/&amp;square;, R\"| q2</code></pre>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#ww-011011","title":"\\(w\\#w: 011\\#011\\)","text":""},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#add-b-to-match-a-such-that-an-bn","title":"Add \\(b\\) to match \\(a\\), such that \\(a^n b^n\\)","text":""},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#convert-w-to-w-wr","title":"Convert \\(w \\to w w^r\\)","text":"<p>Pretty complicated</p>"},{"location":"3_Core/Theory_of_Computation/07_Turing_Machine/#multiplication","title":"Multiplication","text":"<p>Pretty complicated</p>"},{"location":"CS_Electives/3D_Printing/","title":"3D Printing","text":""},{"location":"CS_Electives/3D_Printing/#references","title":"References","text":"<ul> <li> https://www.youtube.com/playlist?list=PLGs0VKk2DiYwxUjGRWEgotTY8ipVvFsIp</li> </ul>"},{"location":"CS_Electives/AI/","title":"Artificial Intelligence","text":"<p>This course offers an overview of the fundamental ideas and concepts in artificial intelligence. It sets the foundation for more advanced subjects like Machine Learning and Deep Learning.</p> <p>Taking DAA (Design &amp; Analysis of Algorithms) course really helps</p>"},{"location":"CS_Electives/AI/#references","title":"References","text":"<ul> <li> Artificial Intelligence | Dr. Sujala Shetty</li> <li> Artificial Intelligence | John Levine</li> <li> AI for Everyone | Andrew Ng | Coursera</li> <li> Data-Centric AI | MIT<ul> <li> 2024</li> <li> 2023</li> </ul> </li> <li> MIT 6.034 Artificial Intelligence, Fall 2010</li> <li> Stanford CS221: Artificial Intelligence: Principles and Techniques | Autumn 2021</li> <li> How to build a career in AI | Andrew Ng</li> <li> Deep Multi-Task and Meta Learning</li> <li> Beyond Fairness: A Sociotechnical view of Machine Learning | T\u00fcbingen Machine Learning</li> </ul>"},{"location":"CS_Electives/AI/01_Intro/","title":"Artificial Intelligence","text":"<p>Branch of computer science which designs \u2018intelligent\u2019 machines capable of behaving, thinking and making decisions like a human.</p> <p></p>"},{"location":"CS_Electives/AI/01_Intro/#rapid-rise","title":"Rapid Rise","text":"<p>Due to data availability from digitalization</p> <p></p>"},{"location":"CS_Electives/AI/01_Intro/#key-areas","title":"Key Areas","text":"<ol> <li>Machine Learning</li> <li>Natural Language Processing</li> <li>Robotics</li> <li>Object Detection</li> <li>Speech Recognition</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#applications","title":"Applications","text":"<ol> <li>Fashion and Art</li> <li>Science</li> <li>Games</li> <li>Music and Sounds</li> <li>Videos and Images  </li> <li>Business and Finance</li> <li>Security and Safety and the list goes on...</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#why-ai","title":"Why AI?","text":"<ul> <li>Replicate human intelligence to provide precise decisions and outcomes</li> <li>Solve knowledge-intensive tasks to reduce human workload</li> <li>Establish an intelligent connection of perception and action</li> </ul>"},{"location":"CS_Electives/AI/01_Intro/#types","title":"Types","text":"<p>There are 2 types of artificial intelligence</p> ANI AGI Full form Artificial Narrow Intelligence Artificial General Intelligence Concept Specific Task Do anything a human can do Advancements Rapid Slow Examples Self-driving car, web search Learning to drive a car through ~20hrs of practiceCompleting a PhD thesis after ~5 yrs of work"},{"location":"CS_Electives/AI/01_Intro/#limitations","title":"Limitations","text":"<p>Don\u2019t be too optimistic or pessimistic about AI</p> <ol> <li>Performance</li> <li> <p>Explainability: AI finds it hard to justify its decisions</p> </li> <li> <p>Biases due to biased data</p> </li> <li>Attacks on AI</li> <li>Adverse use of AI</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#responsible-ai","title":"Responsible AI","text":"<ol> <li>Fairness: Ensure AI does not perpetuate/amplify biases</li> <li>Transparency: Making AI systems and their decisions understandable to stakeholders impacted</li> <li>Privacy: Protecting user data and ensure confidentiality</li> <li>Security: Safeguard AI systems from malicious attacks</li> <li>Ethical use: Ensuring AI is used for beneficial purposes</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#ai-company","title":"AI Company","text":"<p>This section is not relevant from the AI courses as such, but is important to know.</p> <p>Company + Deep learning \\(\\ne\\) AI company</p>"},{"location":"CS_Electives/AI/01_Intro/#features","title":"Features","text":"<ol> <li>Strategic data acquisition: some companies release non-monetised products just for data collection</li> <li>Unified data warehouse: makes it easier to connect and link</li> <li>Task Automation</li> <li>New roles (ML engineer) and division of labor</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#roles","title":"Roles","text":"<p>Roles aren\u2019t concrete</p> <ol> <li>Software engineer - program/task execution</li> <li>ML engineer - Trains the neural network</li> <li>ML researcher - extend state-of-the-art in ML</li> <li>Applied ML scientist - does roles of ML engineer and researcher</li> <li>Data scientist</li> <li>examine data</li> <li>provide insights</li> <li>presentations</li> <li>Data engineer</li> <li>organize data</li> <li>ensure data security, accessibility and cost-efficiency</li> <li>AI product manager</li> <li>decide what to build</li> <li>feasibility and value</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#transformation","title":"Transformation","text":"<p>Steps for a company to transform into an AI company</p> <ol> <li> <p>Execute pilot projects</p> </li> <li> <p>focus on success rather than value of pilot projects</p> </li> <li>some sort of progress in 6-12 months</li> <li>In-housed/outsourced</li> <li>Build in-house AI team</li> <li>Provide AI training to all employees</li> </ol> <p>Curate (online courses, books, etc) instead of create training 4. AI strategy    1. use AI to create an advantage specific to the required sector    2. strategic data acquisition</p> <ol> <li> <p>unified data warehouse</p> </li> <li> <p>network effects and platform advantages</p> <p>Eg: social media - more users join, more lucrative for prospective users</p> </li> <li> <p>aligned with \u2018Virtuous Cycle of AI\u2019</p> </li> </ol> <pre><code>flowchart LR\n\na[More&lt;br/&gt;Data] --&gt;\nb[Better&lt;br/&gt;Product] --&gt;\nc[More&lt;br/&gt;Users] --&gt;\na</code></pre> <ol> <li>Communications:    everyone should be aligned with how company is \u2018navigating' with AI</li> <li>internal</li> <li>external<ol> <li>investors</li> <li>governments</li> <li>customers</li> <li>talent</li> </ol> </li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#projects","title":"Projects","text":"<p>Outsource whatever does not require specialisation/customisation - especially industry-standards</p>"},{"location":"CS_Electives/AI/01_Intro/#choosing-a-project","title":"Choosing a project","text":""},{"location":"CS_Electives/AI/01_Intro/#brainstorming","title":"Brainstorming","text":"<ol> <li>Automate tasks instead of automating jobs</li> <li>what are the main drivers of business value</li> <li>what are the main recurring weak points in your business</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#proofing","title":"Proofing","text":"<ul> <li>Techincal Diligence - AI experts</li> <li>AI must be able to perform</li> <li>how much data is required</li> <li>resources required</li> <li>Business diligence - domain experts</li> <li>valuable</li> <li>does it<ul> <li>lower costs</li> <li>increase revenue</li> <li>allow to launch new product/business</li> </ul> </li> <li>Ethical diligence</li> <li>does it benefit/harm society</li> </ul>"},{"location":"CS_Electives/AI/01_Intro/#implementing","title":"Implementing","text":"<ol> <li>Specify acceptance criteria</li> <li>do not expect 100% accuracy<ol> <li>limitations of ML</li> <li>Insufficient data</li> <li>mislabelled data</li> <li>ambiguous labels</li> </ol> </li> <li>provide AI team with <ol> <li>training set</li> <li>test set</li> </ol> </li> <li>to measure performance</li> <li>Eg: 95% accuracy</li> </ol>"},{"location":"CS_Electives/AI/01_Intro/#implementation","title":"Implementation","text":"<p>IDk</p> <ul> <li>Augmentation: Help humans with a task</li> <li>Automation: Perform task without human</li> </ul> <p>Potential</p> <ul> <li>Business Value: Does this significantly fasters, cheaper, more consistently create substantial value</li> <li>Technical Feasibility: Can AI do it?</li> </ul>"},{"location":"CS_Electives/AI/02_Search/","title":"Search","text":""},{"location":"CS_Electives/AI/02_Search/#steps","title":"Steps","text":"<ol> <li>Formulate goal</li> <li>Formulate problem</li> <li>Find solution</li> </ol>"},{"location":"CS_Electives/AI/02_Search/#types-of-search","title":"Types of Search","text":"Type Examples Single-Agent Traveling Salesperson8-Puzzle (Sudoku)Wiring of VLSI circuitsFinding faults in vehicle Two-Agent ChessTic-Tac-ToeCheckersGoTzaar Constraint-Satisfication Scheduling8-QueensF-Block"},{"location":"CS_Electives/AI/02_Search/#parts-of-search","title":"Parts of Search","text":""},{"location":"CS_Electives/AI/02_Search/#agents","title":"Agents","text":"Type of Agents Intelligent/Problem Solving/Rational Agents has goals and tries to perform a series of actions that yield the best outcome/achieve a goal Reflex Agents Don\u2019t think about consequences of its actions, and selects an action based on current state of the world."},{"location":"CS_Electives/AI/02_Search/#keywords","title":"Keywords","text":"Keyword Meaning State Description of possible state of the worldIncludes all features relevant to problem Initial/Start State State from where agent begins the search Goal State State where success is attained, which we want to reachMultiple goal states can exist Goal Test Function that observes current state and returns whether goal state is achieved/not Action Function that maps transitions from one state to another Problem Definition of general problem as search problem Solution Sequence of actions that help go from initial state to goal state Solution cost Cost associated to perform solution Search Process of looking for solution State Space Set of all states that are possible and can be reached in an environment/system. State space size Total number of states. Counted using fundamental counting principle. Search Tree Tree representation of search problem."},{"location":"CS_Electives/AI/02_Search/#search-type","title":"Search Type","text":""},{"location":"CS_Electives/AI/02_Search/#idk","title":"IDK","text":"Type Path is relevant? Direction Planning Sequence of actions \u2705 Backward chaining Diagonosis \u2705 Forward chaining Identification Assignment to variables \u274c"},{"location":"CS_Electives/AI/02_Search/#information","title":"Information","text":"Information Other names Comment Uninformed BlindBrute-ForceUndirected Informed Tends to be faster"},{"location":"CS_Electives/AI/02_Search/#search-property","title":"Search Property","text":"Property Meaning Completeness Algo guaranteed to find soln in a finite duration \\(\\iff \\exists\\) a soln Optimality Algo guaranteed to find least cost path to goal state"},{"location":"CS_Electives/AI/02_Search/#heuristic","title":"Heuristic","text":"<p>A heuristic function \\(h(x)\\) is an estimated cost from one node to another</p> <ul> <li>Heuristics are problem-specific</li> <li>Over-estimating heuristic is better than under-estimating</li> <li>As heuristics get closer to the true cost, you will expand fewer nodes but usually do more work per node to compute the heuristic itself</li> </ul> <p>Eg: Manhattan distance, Euclidean distance</p>"},{"location":"CS_Electives/AI/02_Search/#characteristics","title":"Characteristics","text":"<p>Consider</p> <ul> <li>\\(h(a, b)\\) is heuristic from \\(a\\) to \\(b\\)</li> <li>\\(c(a, b)\\) is true cost from \\(a\\) to \\(b\\)</li> </ul> Characteristic Definition Comment Implication Admissible \\(h(x, G) \\le c(x, G) \\quad \\forall x\\) Heuristic never overestimates true cost Admissible slows down bad plans, but never outweigh true costsInadmissible/pessimistic compromises optimality but with lower (better) search time Consistent \\(\\vert h(x_1, G) - h(x_2, G) \\vert \\le c(x_1, x_2)\\)where \\(x_2\\) is an intermediate node b/w \\(x_1\\) and \\(G\\) Every consistent heuristic is also admissible \\(f\\) value along path never decreasesYou can skip checking for shortest path when a node is encountered 2<sup>nd</sup> time. Informedness/Domination \\(h_1(x, G) \\ge h_2(x, G) \\quad \\forall x\\) where\\(h_1, h_2\\) are admissible \\(h_1\\) is more informed than \\(h_2\\)\\(h_1\\) dominates \\(h_2\\) Semi-lattice of heuristics \\(\\max(h_1, h_2)\\) is admissible Trivial heuristic Bottom of lattice is zero heuristic \\(\\implies\\) top of lattice is exact heuristic <p></p>"},{"location":"CS_Electives/AI/02_Search/#search-algorithms","title":"Search Algorithms","text":"Search Type Algo Comment Complete Optimal Time Complexity Space Complexity Disadvantage Advantage Hyperparameter Uninformed DFS Keep picking left-most node possible Explore deepest node from start node(Stack - LIFO) \u274c\u2705 (if no cycles) \u274c \\(O(b^m)\\) \\(O(bm)\\) May get \u201clost\u201d deep in graph, missing the shortest path Avoids searching \u201cshallow states\u201d for long solution BFS Traverse left to right, level by level Explore shallowest node from start node(Queue - FIFO) \u2705 \u2705 \\(O(b^{m_s} + 1)\\) \\(O(b^{m_s}+1)\\) High memory usage if states have high avg no of children Always finds shortest path Iterative-Deepening Combination of DFS and BFS) Perform DFS for every levelDFS with depth bound Not necessarily \\(O(b^d)\\) \\(O(bd)\\) Repeated work (negligible though: \\(O(1/b)\\)) Prevents DFS from getting lost in infinite path Depth threshold UCS (Uniform Cost)/Branch &amp; Bound Orders by path/backward cost \\(c(i, x)\\) Explore least cost node from start node \u2705(\\(\\iff\\) all costs are non-negative) \u2705 \\(O(b^m)\\) \\(O(b^m)\\) Explores options in \u201cevery direction\u201d Keeps cost low Bi-Directional Performed on search graph Two simultaneous search - forward search from start vertex toward goal vertex and backward search from goal vertex toward start vertex \u2705 \u2705\\(\\iff\\) we use BFS in both searches \\(O(b^{d/2})\\) \\(O(b^{d/2})\\) Can prune many options - Which goal state(s) to use- Handling search overlap- Which search to use in each direction- 2 BFS searches Informed Greedy/Best-First Explore the node with lowest heuristic value which takes closer to goalOrders by goal proximity/forward cost \\(h(x, G)\\) Similar to UCS, but with a priority queue \u274c \u274c \\(O(b^m)\\) \\(O(b^m)\\) TentativeMay directly go to wrong end stateMay behave like a poorly-guided DFS Helps find solution quickly A* Explore the node with lowest total cost value\\(f = C(i, x) + h(x, G)\\) Uses priority queueCombination of UCS &amp; Greedy \u2705 \u2705(\\(\\iff\\) heuristic is admissible) \\(O(b^m)\\) \\(O(b^m)\\) Hill-Climbing Basically gradient-descent \u274c \u274c \\(O(bm)\\) \\(O(b)\\) IrreversibleIf bad heuristic, may prune away goalsStuck at local minima/maximaSkips ridgesPlateaus FastLow memory Beam Compromise b/w hill-climbing &amp; greedy \\(n=1:\\) Hill-Climbing\\(n=\\infty:\\) Best-First\\(n \\in (1, \\infty) :\\) Beam width (no of children to search) \u274c \u274c \\(O(nm)\\) \\(O(bn)\\) IDA*(Iterative Deepening A *) Similar to Iterative Deepening, but uses A* cost threshold Increase always includes at least one new node \u2705 \u2705 \\(O(b^m)\\) \\(O(m)\\) Some redundant search, but negligibleDangerous if continuous \\(h\\) values or if \\(h\\) values very close to threshold Ensures search never looks beyond optimal cost soln - Threshold- \\(h\\)(root)- \\(f\\)(min_child)min_child is the cut off child with min \\(f\\) RBFS(Recursive Best-First/Greedy) Linear space variant of \\(A^*\\) Backtrack if current node is worse than next best alternativePerform \\(A^*\\) but discard subtrees when performing recursionKeep track of alternative (next best) subtreeExpand subtree until \\(f&gt;\\) boundUpdate \\(f\\) before (from parent) and after (from child) recursive call \\(O(2^m)\\) \\(O(bm)\\) Stores more info than IDA* More efficient than IDA* SMA* Simplified Memory-Bounded A* Perform A*, but when memory is full, discard worst leaf (highest \\(f\\))Back value of discarded node to parent Hill-Climbing Random restart helps overcome local maxima/minimaRandom sideways moves help escape from- shoulders- loop on flat maxima \u274cTrivially complete with random restart \u274c Irreversible stepsSkips ridges FastLow memory requirement Local Beam \\(k\\) hill climbs Choose \\(k\\) random successorsSimilar to natural selection \u274c \u274c InefficientAll \\(k\\) states end up on same local hill \\(k\\) Simulated Annealing Trade-off b/w hill-climbing &amp; random search Randomness at high \u201ctemperature\u201dWhen temperature cools, reduce prob of random moves Can find global optima when temperature chosen correctly Temperature Genetic Algorithm <p>where</p> <ul> <li>\\(b =\\) max branching factor (nodes at each level)</li> <li>\\(m=\\) depth</li> <li>\\(m_s =\\) depth of shallowest solution</li> <li>\\(C^*\\) is optimal path cost</li> <li>\\(\\epsilon\\) is minimal cost between 2 nodes</li> </ul> <p>Fringe is a priority queue</p>"},{"location":"CS_Electives/AI/02_Search/#iterative-improvement-search","title":"Iterative Improvement Search","text":"<p>Local search</p> <p>Hill-climbing, local beam, simulated annealing, genetic</p> <p>Appropriate when only reaching goal state is required; solution path is irrelevant</p>"},{"location":"CS_Electives/AI/02_Search/#idk_1","title":"IDK","text":""},{"location":"CS_Electives/AI/02_Search/#graph-search","title":"Graph Search","text":"<p>Helps avoid repeated states - Do not return to parent/grand-parent states - Do not create solution paths with cycles - Do not generate repeated states as options (need to store &amp; check more states)</p>"},{"location":"CS_Electives/AI/02_Search/#implementation","title":"Implementation","text":"<ul> <li>Data structures</li> <li>Tree (as usual)</li> <li>Set of expanded (visited/closed) nodes</li> <li>Traversal</li> <li>Visit node from open set</li> <li>Check if visited previously</li> <li>If visited, skip node and go to step 1</li> <li>Else<ol> <li>expand node</li> <li>add node to closed set</li> <li>add children to open set</li> </ol> </li> </ul>"},{"location":"CS_Electives/AI/02_Search/#implications","title":"Implications","text":"<ul> <li>Completeness maintained</li> <li>Optimality is not guaranteed</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/","title":"Genetic Algorithm","text":"<p>Nature-inspired search technique to find true/approximate solutions to optimization and search problems</p> <p>Categorized as global search heuristics</p> <p>Neither complete nor optimal</p>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#terminology","title":"Terminology","text":"Term Meaning Individual Any possible solution Population Collection of all individuals Gene Single bit that represents an attribute Trait Possible features of an individual Chromosome String of genes that represent the trait of an individual Genome Collection of all chromosome (traits) for an individual Fitness Target function that we are optimizing(each individual has a fitness)"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#algorithm","title":"Algorithm","text":"<ol> <li>Initialize random population of solution guesses</li> <li>Repeat for each generation</li> <li>Evaluate each chromosome in population using a fitness function</li> <li>Apply GA operators to create a new population</li> <li>Repeat until desired fitness/stopping criterion is met</li> </ol>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#ga-operators","title":"GA Operators","text":""},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#representation","title":"Representation","text":"<ul> <li>Binary strings</li> <li>Arrays of integers (usually bound)</li> <li>Array of letters</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#selection","title":"Selection","text":"<p>Selecting a subset of individuals \\(x\\) according to fitness function \\(f(x)\\) like beam search</p> Selection Technique Logic Roulette-wheel/Fitness-proportionate Each individual gets slice of wheel proportional to fitness\\(p_i = \\dfrac{f_i}{\\sum_j^n f_j}\\) Elitist Select only \\(n\\) most fit members of each generation Cutoff selection Select only members with fitness &gt; threshold Scaling Rank-Space Fitness ignores diversity, hence populations tend to become uniform1. Sort population by sum of fitness rank and diversity rank2. Diversity rank is the result of sorting by the function \\((1/d^2)\\)"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#crossoverrecombination","title":"Crossover/Recombination","text":"<ul> <li>Parents are randomly (with prob) recombined to form new offsprings</li> <li>Chromosome of other parents copied onto next generation as is</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#simple","title":"Simple","text":"<ol> <li>For each couple, using a pre-determined prob, decide if crossover to be performed</li> <li>Select 2 parents</li> <li>Select cross site</li> <li>Cut &amp; substitute substring of one parent with another</li> </ol> \\[ \\begin{aligned} &amp; \\textcolor{hotpink}{101} 110 \\quad \\textcolor{orange}{110} 001 \\\\ \\\\ \\implies &amp; \\textcolor{orange}{110} 110 \\quad \\textcolor{hotpink}{101} 001 \\end{aligned} \\]"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#2-point","title":"2 Point","text":"<p>Helps avoid cases when genes at the beginning and end of chromosome are always split $$ \\begin{aligned} &amp; 1 \\textcolor{hotpink}{01} 110 \\quad 1 \\textcolor{orange}{10} 001 \\ \\ \\implies &amp; 1 \\textcolor{orange}{10} 110 \\quad 1 \\textcolor{hotpink}{01} 001 \\end{aligned} $$</p>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#k-pointmulti-point","title":"k-point/Multi-point","text":"<ol> <li>Pick \\(k\\) random splice points</li> <li>Splice for \\(k-1\\) substrings</li> </ol>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#uniform-crossover","title":"Uniform crossover","text":"<ul> <li>Random subset is chosen for both parents</li> <li>Subset of parent 1 is substituted with subset of parent 2</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#mutation","title":"Mutation","text":"<p>Random alteration of mutating offsprings with small probability</p> <ul> <li>An insurance policy against lost bits</li> <li>Pushes out of local minima</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#inversion","title":"Inversion","text":"<p>Reverse selected subsequence</p> <p>1011011 -&gt; 10 | 110 | 11 -&gt; 10 | 011 | 11 -&gt; 1001111</p> <ul> <li>Preserves adjacency information</li> <li>Discards order information</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#elitism","title":"Elitism","text":"<p>Best chromosomes from prev generation replace few of the worst chromosomes in current generation</p>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#idk","title":"IDK","text":"<ul> <li>Order1 crossover: inversion and recombination</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#applications","title":"Applications","text":"Domain Application Control Gas PipelinesMissile evasion Design Aircraft designKeyboard configurationCommunication networks Game playing PokerCheckers Security EncryptionDecryption Robotics Trajectory Planning"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#advantages","title":"Advantages","text":"<ul> <li>Concept is easy</li> <li>Modular, separate from application</li> <li>Supports multi-objective optimization</li> <li>Easily exploits previous/alternate solutions</li> <li>Flexible building blocks for hybrid applications</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#issues","title":"Issues","text":"<ul> <li>How to select original population</li> <li>How to handle non-binary solution types</li> <li>What should be size of population</li> <li>What is the optimal mutation rate</li> <li>How are mates picked for crossover</li> <li>Can any chromosome appear more than once in a population</li> <li>Stopping criteria: When should GA halt</li> <li>How to deal with local minima</li> <li>How to parallelize</li> </ul>"},{"location":"CS_Electives/AI/03_Genetic_Algorithms/#classifier-systems","title":"Classifier Systems","text":"<ul> <li>GAs &amp; load balancing</li> <li>SAMUEL</li> </ul>"},{"location":"CS_Electives/AI/04_Game_Playing/","title":"Adversarial Search","text":"<p>Also called as Game Playing</p>"},{"location":"CS_Electives/AI/04_Game_Playing/#game","title":"Game","text":"<p>A game can be defined as a type of search in AI which can be formalized of the following elements</p> <ol> <li>Initial state</li> <li>Terminal state</li> <li>Player\\((s)\\)</li> <li>Action\\((s)\\)</li> <li>Result\\((s, a)\\) - It is the transition model, which specifies the result of moves in the state space.</li> <li>Terminal-Test\\((s)\\) - Terminal test is true if the game is over, else it is false at any case. </li> <li>Utility\\((s, p)\\) - A utility function gives the final numeric value for a game that ends in terminal states \\(s\\) for player \\(p\\).</li> </ol> <p>A game tree is a tree where nodes of the tree are the game states and Edges of the tree are the moves by players. Game tree involves initial state, actions function, and result Function.</p>"},{"location":"CS_Electives/AI/04_Game_Playing/#types-of-games","title":"Types of Games","text":"Deterministic Non-Deterministic(Chance/Randomness) Fully Observable Chess Monopoly Partially Observable Battleship Card games"},{"location":"CS_Electives/AI/04_Game_Playing/#zero-sum-game","title":"Zero Sum game","text":"<ul> <li>In Zero-sum game each agent's gain or loss of utility is exactly balanced by the losses or gains of utility of another agent.</li> <li>One player of the game tries to maximize one single value, while other player tries to minimize it.</li> <li>Examples are tic tac toe and chess.</li> </ul>"},{"location":"CS_Electives/AI/04_Game_Playing/#mini-max-algorithm","title":"Mini-Max Algorithm","text":"<p>Algo to determine optimal moves for utility maximizing agent in fully-observable, deterministic games</p> <p>Min-max is complete and optimal</p>"},{"location":"CS_Electives/AI/04_Game_Playing/#assumption","title":"Assumption","text":"<p>Opponent behaves optimally, ie always perform the move that is worst for us</p>"},{"location":"CS_Electives/AI/04_Game_Playing/#logic","title":"Logic","text":"<ul> <li>Utility of each node is computed bottom up from leaves toward root. </li> <li>At each MAX node, pick move w/ max utility</li> <li>At each MIN node, pick move w/ min utility</li> </ul>"},{"location":"CS_Electives/AI/04_Game_Playing/#limitations","title":"Limitations","text":"<p>Really expensive for trees with large branding factor (complex games such as Chess, Go)</p> <p>Complexity = \\(O(b^m)\\)</p> <p>Can be overcome with \\(\\alpha \\beta\\) Pruning</p>"},{"location":"CS_Electives/AI/04_Game_Playing/#alpha-beta-pruning","title":"\\(\\alpha \\beta\\) Pruning","text":"<p>Alpha Beta Pruning</p> <ul> <li>Optimized mini-max</li> <li>Form of meta-reasoning</li> <li>Used to reduce branching factor, hence handles complex games as well </li> <li>Maintain two parameters in depth-first search</li> <li> <p>\\(\\alpha =\\) highest value found yet for MAX along any path</p> <ul> <li>\\(\\alpha_\\text{root} = - \\infty\\)</li> </ul> </li> <li> <p>\\(\\beta =\\) lowest value found yet for MIN along any path</p> <ul> <li>\\(\\beta_\\text{root} = + \\infty\\)</li> </ul> </li> <li> <p>Prune (skip) a subtree once it is known to be worse than current \\(\\alpha\\) or \\(\\beta\\)</p> </li> <li>If \\(\\alpha &gt; \\beta\\), stop evaluating children</li> </ul> <p></p>"},{"location":"CS_Electives/AI/04_Game_Playing/#implications","title":"Implications","text":"<ul> <li>Solution does not change</li> <li>Complexity = \\(O(b^{m/2})\\)</li> </ul>"},{"location":"CS_Electives/AI/04_Game_Playing/#cut-off-search","title":"Cut-off Search","text":"<ul> <li>Cutoff search tree before terminal state reached</li> <li>Use heuristic of minimax value at leaves, instead of utility</li> </ul>"},{"location":"CS_Electives/AI/04_Game_Playing/#deep-blue","title":"Deep Blue","text":"<ul> <li>Minimax</li> <li>\\(\\alpha\\beta\\) pruning</li> <li>Progressive deepening</li> <li>Parallel computing</li> <li>uneven tree development</li> </ul> <p>14-16 levels deep</p>"},{"location":"CS_Electives/AI/05_CSP/","title":"Constraint Satisfaction Problem","text":"<p>Identification problem: These are problems in which we must simply identify whether a state is a goal state or not</p> <ul> <li>State is defined by</li> <li>Variables \\(X_i\\)</li> <li> <p>with values from Domain \\(D\\)</p> </li> <li> <p>Goal test is a set of constraints</p> </li> </ul> <p>CSPs are represented as constraint graphs, where nodes represent variables and edges represent constraints between them.</p>"},{"location":"CS_Electives/AI/05_CSP/#constraints","title":"Constraints","text":"Type Example Implicit A \\(\\ne\\) B Explicit (A, B) \\(\\in\\)"},{"location":"CS_Electives/AI/05_CSP/#graph-coloring","title":"Graph Coloring","text":"Problem Contraint Graph Variables WA, NT, Q, NSW, SA, V, T Domain {Red, Green, Blue} Constraints WA \\(\\ne\\) NT\u2026"},{"location":"CS_Electives/AI/05_CSP/#n-queens","title":"N-Queens","text":"Formulation 1 Formulation 2 Variables \\(X_{ij}\\) \\(Q_k\\) Domain \\(\\{ 0, 1 \\}\\) \\(\\{ 1, 2, \\dots, N \\}\\) Constraints \\(\\sum_{i, j} X_{ij} = N\\) Implicit: \\(\\forall i, j\\): non threatening \\((Q_i, Q_j)\\)Explicit: \\((Q, _1, Q_2) \\in \\{ (1, 3), (1, 4), \\dots \\}\\)"},{"location":"CS_Electives/AI/05_CSP/#idk","title":"IDK","text":"<ul> <li>Binary CSP: Each constraint relates at most 2 variables</li> <li>Binary constraint graph: nodes are variables, arcs show constraints</li> </ul>"},{"location":"CS_Electives/AI/05_CSP/#cryptarithmetic","title":"Cryptarithmetic","text":"Variables Domain \\([0, 9]\\) Constraints alldiff(variables)"},{"location":"CS_Electives/AI/05_CSP/#sudoku","title":"Sudoku","text":"Variables \\(X_{ij}\\) Domain \\([1, 9]\\) Constraints 9-way all diff for each column9-way all diff for each row9-way all diff for each sub-grid"},{"location":"CS_Electives/AI/05_CSP/#types","title":"Types","text":"Variable Type Domain Examples Discrete Finite Size \\(d\\) means \\(O(d^n)\\) complete assignments Boolean satisfiability (np-complete) Infinite(integers, strings) Job Scheduling (Vars are start/end times for each job)Linear constraints solvableNon-linear undecidable Continuous Linear constraints solvable in polynomial time by LP methods Start/end times for Hubble telescope observations"},{"location":"CS_Electives/AI/05_CSP/#constraints_1","title":"Constraints","text":"Variety Example Unary Single variable SA \\(\\ne\\) Green Binary Pairs SA \\(\\ne\\) WA Higher-Order Cryptarithmetic column constraints Enforcement Example Soft (Preferences) Represented by cost for each var assignmentGives constrained optimization problems Red better than green Hard"},{"location":"CS_Electives/AI/05_CSP/#standard-search-formulation","title":"Standard Search Formulation","text":"<p>States are defined by the values assigned so far (partial assignments)</p> <ul> <li>Initial state: Empty assignment</li> <li>Successor function: assign value to unassigned variable</li> <li>Goal test: current assignment is complete and satisfies all constraints</li> </ul>"},{"location":"CS_Electives/AI/05_CSP/#idk_1","title":"IDK","text":""},{"location":"CS_Electives/AI/05_CSP/#backtracking-search","title":"Backtracking Search","text":"<p>Backtracking = DFS + variable-ordering + fail-on-violation</p> <p>Assumption: assignments are commutative (order of assignment doesn\u2019t matter)</p> <ol> <li>Fix an ordering for variables, and select values for variables in this order</li> <li>Consider assignments to a single var at each step</li> <li>Check constraints on the go</li> <li>When selecting values for a variable, only select values that don\u2019t conflict with any previously assigned values</li> <li>If no such values exist, backtrack and return to the previous variable, changing its value</li> </ol> <p>Can solve n-queens for \\(n \\le 25\\)</p> <p></p> <p></p>"},{"location":"CS_Electives/AI/05_CSP/#filteringpruning","title":"Filtering/Pruning","text":"<p>To improve performance, we consider filtering which checks if we can prune the domain of unassigned variables ahead of time. </p> <p>To improve performance, we can prune subtrees that will inevitably lead to failure</p>"},{"location":"CS_Electives/AI/05_CSP/#forward-checking","title":"Forward Checking","text":"<ul> <li>Whenever a new variable is assigned, we can run forward checking and prune the domains of unassigned variables adjacent to the newly assigned variable in the constraint graph.</li> <li>Basically we eliminate all the values from the domain of the adjacent variables which could cause violation of any constraint.</li> </ul> <p>This propagates info from assigned to unassigned vars, but doesn\u2019t provide early detection for all failures</p> <p>Time Complexity: \\(O(n^2 d^3)\\)</p> <p></p>"},{"location":"CS_Electives/AI/05_CSP/#arc-consistency","title":"Arc Consistency","text":"<p>An arc \\(X \\to Y\\) is consistent \\(\\iff \\forall x\\) in the tail, \\(\\exists y\\) in the head which could be assigned without violating a constraint</p> <ul> <li>Forward checking only enforces consistency of arcs pointing to each new assignment</li> <li>More advanced: If \\(X\\) loses a value, neighbors of \\(X\\) need to be rechecked</li> <li>Arc consistency detects failure earlier than forward checking</li> <li>Can be run as a pre/post-processing step for each assignment</li> </ul> <p>Note: delete from tail</p> <p>Time Complexity: \\(O(n^2 d^2)\\)</p> <p>But detecting all possible future problems is np-hard</p>"},{"location":"CS_Electives/AI/05_CSP/#limitations","title":"Limitations","text":"<ul> <li>After enforcing arc consistency</li> <li>Can have one solution left</li> <li>Can have multiple solutions left</li> <li>Can have no solutions left (and not know about it)</li> <li>Arc consistency still runs inside a backtracking search</li> </ul>"},{"location":"CS_Electives/AI/05_CSP/#ac3-algorithm","title":"AC3 Algorithm","text":"<ol> <li>Turn each binary constraint represented as undirected edge into 2 directed arcs</li> </ol> <p>Eg</p> <ul> <li>\\(A \\ne B \\implies A \\ne B, B \\ne A\\)</li> <li> <p>\\(A &lt; B \\implies A &lt; B, B &gt; A\\)</p> </li> <li> <p>Add all arcs to agenda \\(Q\\)</p> </li> <li> <p>Repeat until \\(Q\\) empty</p> </li> <li> <p>Take an arc \\((X_i, X_j)\\) off \\(Q\\) and check it</p> </li> <li>\\(\\forall X_i , \\exists X_j\\): For every element of \\(X_i\\) there should be at least one element of \\(X_j\\) that satisfies condition </li> <li>Remove any inconsistent values from \\(X_i\\)</li> <li>if \\(X_i\\) has changed, add all arcs of the form \\((X_k, X_i)\\) to agenda<ol> <li>If arc \\(X_k \\rightarrow X_i\\) is already in \\(Q\\), don't add it again</li> </ol> </li> </ul>"},{"location":"CS_Electives/AI/05_CSP/#ordering","title":"Ordering","text":"Ordering Disadvantage MRV: Minimum Remaining Values/\u201cFail-Fast\u201d Choose \u201cmost constrained var\u201d, ie the var with the fewest legal left values in domain LCV: Least Constraining Value Choose least constraining valueIe, var that rules out the fewest values in the remaining vars Extra computation for re-running filtering Degree Choose node with highest degreeChoose var involved in most no of constraints on other unassigned vars Min-Conflicts chooses randomly any conflicting variable, i.e., the variable that is involved in any unsatisfied constraint, and then picks a value which minimizes the number of violated constraints (break ties randomly)"},{"location":"CS_Electives/AI/06_Planning/","title":"Planning","text":"<p>Planning is a particular type of problem solving in which actions and goals are declaratively specified in logic and generally concerns performing actions in the real world.</p> <p>Generally languages of planning problems consist mainly of  </p> <ol> <li> <p>States - conjunction of positive literals  </p> </li> <li> <p>Goals - conjunction of positive ground literals  </p> </li> <li> <p>Actions - represented in terms of precondition and effect of the action  </p> </li> </ol> <p>STRIPS and ADL are two languages used to express planning problems</p> STRIPS Language ADL Language Only positive literals in states: \\(Poor \u2227 Unknown\\) Positive and negative literals in states:  \\(\u00acRich \u2227 \u00acFamous\\) Unmentioned literals are false Unmentioned literals are unknown Effect \\(P \u2227 \u00acQ\\) means add P and delete Q Effect \\(P \u2227 \u00acQ\\) means add P and \u00acQ and delete \u00acP and Q. Only ground literals in goals: \\(Rich \u2227 Famous\\) Quantified variables in goals:  \\(\u2203xAt(P1,x) \u2227 At(P2, x)\\) Goals are conjunctions Goals allow conjunction and disjunction Effects are conjunctions Conditional effects allowed No support for equality Equality predicate (x = y) is built in No support for types Variables can have types Example : \\(Action(Fly(p, from,to),\\)\\(PRECOND:At(p, from) \u2227 Plane(p) \u2227 Airport(from) \u2227 Airport(to)\\)\\(EFFECT:\u00acAt(p, from) \u2227 At(p,to))\\) Example : \\(Action(Fly(p : Plane, from : Airport,to : Airport),\\)\\(PRECOND:At(p, from) \u2227 (from = to)\\)\\(EFFECT:\u00acAt(p, from) \u2227 At(p, to))\\)"},{"location":"CS_Electives/AI/06_Planning/#partial-order-planning-pop","title":"Partial Order Planning (POP)","text":"<p>Any planning algorithm that can place two actions into a plan without specifying which comes first is called a partial-order planner.</p> <ul> <li>Ordering constraints - of the form \\(A \u227a B\\) (A before B) which means that action A must be executed sometime before action B</li> <li>Causal link - between two actions A and B in the plan is written as \\(A\\xrightarrow{\\text{p}}B\\)  (A achieves p for B). </li> <li>Conflict - An action C conflicts with \\(A\\xrightarrow{\\text{p}}B\\) if C has the effect \u00acp and if C could come after A and before B.</li> <li>Open precondition - A precondition is open if it is not achieved by some action in the plan.</li> </ul> <p>Consider the following description of planning problem :  </p> <p>\\(Goal(RightShoeOn \u2227 LeftShoeOn)\\) \\(Init()\\) \\(Action(RightShoe, PRECOND:RightSockOn, EFFECT:RightShoeOn)\\) \\(Action(RightSock, EFFECT:RightSockOn)\\) \\(Action(LeftShoe, PRECOND:LeftSockOn, EFFECT:LeftShoeOn)\\) \\(Action(LeftSock, EFFECT:LeftSockOn)\\)</p> <p></p> <p>Actions - \\({RightSock, RightShoe, LeftSock, LeftShoe, Start, Finish}\\) Orderings - \\({RightSock \u227a RightShoe, LeftSock \u227a LeftShoe}\\) Links - {\\({RightSock\\xrightarrow{\\text{RightSockOn}}RightShoe, LeftSock\\xrightarrow{\\text{LeftSockOn}}LeftShoe,RightShoe\\xrightarrow{\\text{RightShoeOn}}Finish, LeftShoe\\xrightarrow{\\text{RightShoeOn}}Finish}\\)} Open Preconditions - { }</p>"},{"location":"CS_Electives/AI/06_Planning/#planning-graphs","title":"Planning Graphs","text":"<p>A planning graph consists of a sequence of levels that correspond to time steps in the plan, where level 0 is the initial state. Each level contains a set of literals and a set of actions.</p> <p>NOTE : persistence actions are actions that remain true from one situation to the next if no action alters it.</p> <p>Before forming a planning graph we need to understand mutex links A mutex relation holds between two actions if  </p> <ol> <li> <p>Inconsistent effects - one action negates an effect of the other  </p> </li> <li> <p>Interference - one of the effects of one action is the negation of a precondition of the other  </p> </li> <li> <p>Competing needs - one of the preconditions of one action is mutually exclusive with a precondition of the other.  </p> </li> </ol> <p>Consider this problem : </p> <p>\\(Init(Have(Cake))\\) \\(Goal(Have(Cake) \u2227 Eaten(Cake))\\) \\(Action(Eat(Cake)\\) \\(\\quad\\) \\(PRECOND: Have(Cake)\\) \\(\\quad\\) \\(EFFECT: \u00ac Have(Cake) \u2227 Eaten(Cake))\\) \\(Action(Bake(Cake)\\) \\(\\quad\\) \\(PRECOND: \u00ac Have(Cake)\\) \\(\\quad\\) \\(EFFECT: Have(Cake))\\) </p> <p></p> <p>In the above graph rectangles indicate actions, small squares indicate persistence actions and straight lines indicate preconditions and effects. Mutex links are shown as curved gray lines.</p> <p>These notes can be refined</p>"},{"location":"CS_Electives/AI/07_Bayesian/","title":"Bayesian Network","text":"<p>Technique for describing complex joint distributions using simple, local distributions (conditional probabilities)</p> <p>Also known as probabilistic graph model</p> <p>Bayes net = Graph + Local conditional probabilities</p> <p>Local interactions chain together to give global, indirect interactions</p> <p>Note: Kindly go through Bayes' Theorem in Probability and Statistics</p>"},{"location":"CS_Electives/AI/07_Bayesian/#semantics","title":"Semantics","text":"<p>DAG that represents the dependence b/w vars</p> <ul> <li>Nodes - represents variables</li> <li>Links - X points to Y, implies X has direct influence over Y or X is a parent of Y</li> <li>Conditional Probability Table - each node has a conditional probability distribution which determines the effect of the parent on that node</li> </ul>"},{"location":"CS_Electives/AI/07_Bayesian/#why-needed","title":"Why needed?","text":"<p>Inefficient to use full joint distribution table as probabilistic model</p> <ul> <li>Joint is way too big to represent explicitly</li> <li>Hard to learn/estimate anything empirically about more than few variables at a time</li> </ul>"},{"location":"CS_Electives/AI/07_Bayesian/#aspects","title":"Aspects","text":"Definition \\(P(X=x)\\) Representation Given a BN graph, what kinds of distributions can it encode? Modelling What BN is most appropriate for a given domain Inference Given a fixed BN, what is \\(P(X \\vert e)\\) Learning Given data, what is best BN encoding Diagnosis Infer P(problem type | symptoms) Prediction Infer prob dist for values that are expensive/impossible to measure Anomaly detection Detect unlikely obs Active learning Choose most informative diagnostic test to perform given obs"},{"location":"CS_Electives/AI/07_Bayesian/#joint-probability-distribution","title":"Joint Probability Distribution","text":"\\[ \\begin{aligned} P(x_i|x_{i \\ne j}) &amp;= P(x_i |\\text{Pa}(x_i)) \\\\ P(x_1, \\dots, x_m) &amp;= \\prod_{i=1}^m P(x_i |\\text{pa}(x_i)) \\end{aligned} \\]"},{"location":"CS_Electives/AI/07_Bayesian/#independence-in-bn","title":"Independence in BN","text":"<p>\\(x {\\perp \\!\\!\\! \\perp} y | z\\) is read as \\(X\\) is conditionally independent of \\(Y\\) given \\(Z\\)</p> <p>$$ X {\\perp !!! \\perp} Y | Z \\iff P(x, y \\vert z) = P(x \\vert z) \\cdot P(y \\vert z) $$ Are 2 nodes independent given evidence?</p> <ul> <li>If yes: prove using algebra (tedious)</li> <li>If no: prove with counter example</li> </ul>"},{"location":"CS_Electives/AI/07_Bayesian/#d-separation","title":"D-Separation","text":"<p>Condition that explains the independence of subgraphs</p> <p>Query: $$ x_i {\\perp !!! \\perp} x_j \\vert { x_{k_1}, \\dots, x_{k_n} } $$ Check all (undirected) paths between \\(x_i\\) and \\(x_j\\)</p> Independence guaranteed If one/more paths active \u274c All paths inactive \u2705"},{"location":"CS_Electives/AI/07_Bayesian/#casual-chains","title":"Casual chains","text":"<pre><code>graph LR\nx((x))--&gt;y((y))\ny((y))--&gt;z((z))</code></pre> <p>\\(x {\\perp \\!\\!\\! \\perp} y | z\\) guaranteed</p>"},{"location":"CS_Electives/AI/07_Bayesian/#common-cause","title":"Common Cause","text":"<pre><code>  graph TD;\n    y((y))--&gt;x((x));\n    y((y))--&gt;z((z));</code></pre> <p>\\(x {\\perp \\!\\!\\! \\perp} y | z\\) guaranteed</p>"},{"location":"CS_Electives/AI/07_Bayesian/#common-effect","title":"Common effect","text":"<pre><code>graph TD;\nx((x))--&gt;z((z));\ny((y))--&gt;z((z));</code></pre> <ul> <li>\\(x {\\perp \\!\\!\\! \\perp} y\\) guaranteed</li> <li>\\(x \\centernot{\\perp \\!\\!\\! \\perp} y | z\\) guaranteed</li> </ul>"},{"location":"CS_Electives/AI/07_Bayesian/#active","title":"Active","text":"<p>A path is active if every triple in path is active</p> <p>NOTE : All possible configurations for active and inactive triples are below</p> <pre><code>graph TB\n\nsubgraph Inactive\n\ndirection LR\nsubgraph i1\ndirection LR;\nAi1((\"x\")) --&gt; Bi1[\"z\"] --&gt;Ci1((\"y\"));\nstyle Bi1 fill : #808080\nend\n\nsubgraph i2\ndirection TB\nBi2[\"z\"]--&gt;Ai2((\"x\")) &amp; Ci2((\"y\"));\nstyle Bi2 fill : #808080\nend\n\nsubgraph i3\n    direction TB\n    Ai3((\"x\")) &amp; Bi3((\"y\")) --&gt; Ci3((\"z\"))\nend\n\n\nsubgraph i4\n    direction TB\n    Ai4((\"x\")) &amp; Bi4((\"y\")) --&gt; Ci4((\"z\")) --&gt; Di4((\" \"))\nend\n\nend\n\nsubgraph Active\ndirection LR\nsubgraph 4\n    direction TB\n  x4((\"x\"))--&gt;C4((\"z\"));\n  y4((\"y\"))--&gt;C4((\"z\"));\n  C4((\"z\"))-.-&gt;D4[\" \"]\n  style D4 fill : #808080\nend\n\nsubgraph 3\n  direction TB\n  A3((\"x\"))--&gt;C3[\"z\"];\n  B3((\"y\"))--&gt;C3[\"z\"];\n  style C3 fill : #808080\nend\n\nsubgraph 2\n  direction TB\n  B2((\"z\"))--&gt;A2((\"x\")) &amp; C2((\"y\"));\nend\n\nsubgraph 1\ndirection LR\nA1((\"x\"))--&gt;B1((\"z\"));\nB1((\"z\"))--&gt;C1((\"y\"));\nend\nend</code></pre>"},{"location":"CS_Electives/AI/07_Bayesian/#topology-limits-distributions","title":"Topology Limits Distributions","text":"<p>Given some graph topology \\(G\\), only certain joint distributions can be encoded</p> <p>The graph structure guarantees certain (conditional) independencies</p> <p>Bayes net\u2019s joint distribution may have further (conditional) independencies that is not detectable until inspection of specific distribution</p> <p>Adding arcs increases set of distributions but has several costs</p> <p>Full conditioning can encode any distribution</p> <p></p>"},{"location":"CS_Electives/AI/07_Bayesian/#building-a-bayes-net","title":"Building a Bayes Net","text":"<ol> <li>Choose set of relevant vars</li> <li>Represent each var by a node</li> <li>Choose ordering for vars \\(x_1, \\dots, x_m\\) such that if \\(x_i\\) influences \\(x_j\\), then \\(i &lt; j\\)</li> <li>Add links: Link structure must be acyclic</li> <li>Add conditional probability table for each node</li> </ol>"},{"location":"CS_Electives/AI/07_Bayesian/#interpreting","title":"Interpreting","text":"<ol> <li>Given parents, each node is conditionally independent of all non-descendents in the tree</li> <li>2 unconnected vars may still be correlated</li> <li>Whether 2 vars are conditionally-independent can be deduced using \u201cd-separation\u201d</li> </ol>"},{"location":"CS_Electives/AI/07_Bayesian/#inference","title":"Inference","text":"<ul> <li>Doing exact inference is computationally hard</li> <li>Tractable in some cases: trees</li> <li>We can instead perform approximate inference</li> <li> <p>Likelihood-weighted sampling</p> </li> <li> <p>Marginal probability</p> </li> <li>Rewrite in terms of joint distribution<ol> <li>Fix query vars</li> <li>Sum over unknown vars</li> </ol> </li> <li>Conditional probability</li> <li>Fix query vars</li> <li>Fix evidence vars</li> <li>Sum over unknown vars</li> <li>Add normalization constant \\(\\alpha\\) such that</li> <li>Rewrite joint probability using Bayes Net factors</li> <li>Choose variable order; take summations inside</li> </ul>"},{"location":"CS_Electives/AI/07_Bayesian/#learning","title":"Learning","text":"<ul> <li>Structure learning</li> <li>Parameter learning</li> </ul>"},{"location":"CS_Electives/AI/07_Bayesian/#variable-elimination","title":"Variable Elimination","text":"<p>Eliminating all vars in turn until there is a factor (function from set of vars) with only query var</p> <p>To eliminate a var</p> <ol> <li>Join all factors containing that var</li> <li>Sum out influence of var on a new factor</li> <li>Exploits product form of joint distribution</li> </ol>"},{"location":"CS_Electives/AI/08_Generative_AI/","title":"Generative AI","text":""},{"location":"CS_Electives/AI/08_Generative_AI/#llm","title":"LLM","text":"<p>Large Language Models</p>"},{"location":"CS_Electives/AI/08_Generative_AI/#limitations","title":"Limitations","text":"<ul> <li>Bias</li> <li>Hallucinations</li> <li>Expensive to build &amp; run</li> </ul>"},{"location":"CS_Electives/AI/08_Generative_AI/#chatgpt","title":"ChatGPT","text":"<ol> <li>Train supervised policy</li> <li>Provide prompt</li> <li>Labeler demonstrates desired output behavior</li> <li>Fine-tune model</li> <li>Collect comparaison data &amp; train reward model</li> <li>Prompt and several model outputs are samples</li> <li>Labeler ranks outputs from best to worst</li> <li>Data used to train reward model</li> <li>Policy optimization</li> </ol>"},{"location":"CS_Electives/AI/08_Generative_AI/#fine-tuning","title":"Fine-Tuning","text":"<p>Process of training model using specific data, usually with a significantly smaller learning rate</p>"},{"location":"CS_Electives/AI/08_Generative_AI/#disadvantages","title":"Disadvantages","text":"<ul> <li>requires copy of the model</li> <li>associated costs of hosting it</li> <li>Risk of \u201ccatastrophic forgetting\u201d: model forgets previously learnt information</li> </ul>"},{"location":"CS_Electives/AI/08_Generative_AI/#rag","title":"RAG","text":"<p>Retrieval Augmented Generation</p> <p>Makes use of a source of knowledge, usually vector store of embeddings and associated texts</p> <p>By comparing predicted embeddings of query to embeddings in the vector store, we can form a prompt for the LLM that fits inside its context and contains the information needed to answer the question</p>"},{"location":"CS_Electives/AI/08_Generative_AI/#advantages","title":"Advantages","text":"<ul> <li>Does not require re-training</li> <li>No need to deal with internal workings of model</li> <li>Just adjust the data that the model \u201ccheats\u201d off</li> <li>Reduces the amount a model \u201challucinates\u201d</li> </ul>"},{"location":"CS_Electives/AI/08_Generative_AI/#difficulties","title":"Difficulties","text":"<ul> <li>Finding relevant data to give the model</li> </ul>"},{"location":"CS_Electives/AI/08_Generative_AI/#keywords","title":"Keywords","text":"<ul> <li>Data organization: </li> <li>Vector creation: Unique index that points right to a chunk of information</li> <li>Querying: Prompting</li> <li>Retrieval</li> <li>Prompt goes through embedding model and transforms into a vector</li> <li>Systems uses this to get the chunks most relevant to the question</li> <li>Prepending the context: Most relevant chunks are served up as context</li> <li>Answer generation</li> </ul>"},{"location":"CS_Electives/AI/08_Generative_AI/#types-of-questions","title":"Types of Questions","text":"No special skills required to answerJust need right reference material What is the capital of France? Write a poem in GermanWrite a computer program to calculate the first n natural numbers"},{"location":"CS_Electives/AI/09_Issues/","title":"Issues","text":""},{"location":"CS_Electives/AI/09_Issues/#environmental-issues","title":"Environmental Issues","text":"<p>Sources of carbon footprint</p> <ul> <li>train models</li> <li>data collection</li> <li>inference</li> <li>creating new chips</li> </ul>"},{"location":"CS_Electives/AI/09_Issues/#types","title":"Types","text":"<ul> <li>Embodied carbon</li> <li>Operational carbon</li> </ul> <p>Not just the energy cost of running computers, but also energy required to build them</p> <p></p>"},{"location":"CS_Electives/AI/09_Issues/#solutions","title":"Solutions","text":"<ul> <li>Efficiency of models</li> <li>Software infra to promote development of efficiency</li> <li>AutoML instead of grid search</li> <li>Easy-to-use APIs for efficient models</li> <li>Efficient computer chips</li> <li>Efficient datacenters</li> <li>Microsoft: underwater servers<ul> <li>8 x more reliable, using Nitrogen, etc</li> <li>No need for fresh water for cooling</li> </ul> </li> <li>Use renewable energy</li> <li>Transitioning to 100% renewables will not eliminate the carbon footprint of chips</li> <li></li> <li>Stop planned obscelence</li> </ul>"},{"location":"CS_Electives/AI/09_Issues/#4-ms-of-ai-efficiency","title":"4 M\u2019s of AI Efficiency","text":"<ol> <li>Model</li> <li>Machine</li> <li>Mechanism</li> <li>Map: Location</li> </ol>"},{"location":"CS_Electives/AI/09_Issues/#jevons-paradoxeffect","title":"Jevon\u2019s Paradox/Effect","text":"<p>Improved efficiency in resource utilization increases the total consumption of resources, due to increased rate of consumption from increased demand</p> <p>Hence, definition of \u201cefficiency\u201d is important</p>"},{"location":"CS_Electives/AI/09_Issues/#pue","title":"PUE","text":"<p>Power Usage Effectiveness</p> <p>Lower is better</p> <p>Typically \\(\\in [1.1, 1.6]\\)</p> <p>How the power input is being used for compute &amp; for other supporting consumption such as cooling, lighting, etc. $$ \\begin{aligned} \\text{PUE} &amp;= \\dfrac{\\text{Total Energy}}{\\text{Productive Energy}} \\ &amp;= 1 + \\dfrac{\\text{Overhead}}{\\text{Productive Energy}} \\end{aligned} $$</p>"},{"location":"CS_Electives/AI/09_Issues/#ethical-issues","title":"Ethical Issues","text":"<p>New technologies are disruptive, not neutral</p> <p>AI can - change current practices - influence human decisions - regulate human behavior</p>"},{"location":"CS_Electives/AI/09_Issues/#responsible-ai","title":"Responsible AI","text":"<ul> <li>Researchers and engineers should<ul> <li>be proactive - not reactive - about ethics</li> <li>anticipate how their work will impact society</li> <li>incorporate human values throughout all stages of product's lifecycle</li> </ul> </li> <li>Increased public trust means<ul> <li>Improved marketability</li> <li>Higher product adoption</li> </ul> </li> </ul>"},{"location":"CS_Electives/AI/09_Issues/#abstraction","title":"Abstraction","text":"<p>Researchers/Engineers often abstracted away from application they\u2019re working on, hence not aware of bad things that can be used for</p>"},{"location":"CS_Electives/AI/09_Issues/#data-ownership","title":"Data Ownership","text":"<p>Data governance</p> <p>Trade-off: Privacy vs Progress</p> <p>Model monetization trained on consumer data, eg: GitHub Copilot</p>"},{"location":"CS_Electives/AI/09_Issues/#data-bias","title":"Data Bias","text":"<p>Dataset curation</p> <p>Federated learning</p>"},{"location":"CS_Electives/AI/09_Issues/#research-inequality","title":"Research Inequality","text":"<ul> <li>Inequitable access to computing resources</li> <li>Inequitable access to datasets</li> </ul>"},{"location":"CS_Electives/AI/09_Issues/#bias","title":"Bias","text":"<p>Solution</p> Solution Meaning Pro Con Group unawareness Sensitive attributes not included as features Avoids disparate treatment Possibility of highly correlated features that are proxies of the sensitive attributeIncompatible with group threshold Group threshold Counteract historical biases in data by adjusting confidence thresholds independently for each group Incompatible with group unawareness Demographic Parity TP + FP equal for all groups Introduces false negatives Equal opportunity TP + FN equal for all groups Introduces false positivesIncompatible with equal accuracy Equal accuracy TP + TN equal for all groups Higher FN for one groupHigher FP for one groupIncompatible with equal opportunity"},{"location":"CS_Electives/AI_in_Robotics/","title":"AI in Robotics","text":"<p>Unlike AI courses by CS department which focus on the algorithms, this course looks at the application of those concepts specifically for Robotics</p>"},{"location":"CS_Electives/AI_in_Robotics/#concepts","title":"Concepts","text":"<ul> <li>Probability Distributions</li> <li>Robot Kinematics</li> <li>Tracking/Navigation</li> <li>Filters</li> <li>Localization</li> <li>Mapping</li> <li>SLAM</li> <li> <p>Programming Languages</p> </li> <li> <p>Python</p> </li> <li> <p>ROS: Robotics Operating System</p> </li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/#references","title":"References","text":"<ul> <li> AI in Robotics | Dr. R. Karthikeyan | BITS Pilani Dubai Campus</li> <li> Self-Driving Cars | Andreas Geiger | T\u00fcbingen Machine Learning</li> <li> Principles of Sensing for Autonomy | Stanford</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/01_Introduction/","title":"Introduction","text":""},{"location":"CS_Electives/AI_in_Robotics/01_Introduction/#applications","title":"Applications","text":"<ul> <li>Path Planning</li> <li>Motion Control</li> <li>Computer Vision</li> <li>Machine Learning</li> <li>Optimization</li> <li>NLP</li> <li>Manipulator &amp; Mobile Robot Hardware</li> <li>Computer Vision, Pathfinding and other tasks</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/01_Introduction/#agent","title":"Agent","text":"<p>Anything that can be viewed as</p> <ul> <li>perceiving its environment through sensors</li> <li>acting upon that environment through effectors</li> </ul> Sensors Effectors Humans EyesNoseSkinTongue HandsLegs Robots CamerasInfrared Range FindersThermal Scanners Motors"},{"location":"CS_Electives/AI_in_Robotics/01_Introduction/#robot","title":"Robot","text":"<p>Software-controllable device using sensors to guide effectors through programmed motion in a workspace to manipulate physical objects</p>"},{"location":"CS_Electives/AI_in_Robotics/01_Introduction/#types-of-robots","title":"Types of Robots","text":"<ul> <li>Mobile</li> <li>Stationary</li> <li>Autonomous</li> <li>Remote-Controlled</li> <li>Virtual</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/01_Introduction/#robot-control-system","title":"Robot Control System","text":"<pre><code>flowchart LR\n\ne[/Environment/] --&gt;\nSensors --&gt;\n|Send&lt;br/&gt;Telemetery| r[Radio] --&gt;\n|Decision| c[Controllers] --&gt; Actuators\n\nOperator &lt;--&gt; cs[Control&lt;br/&gt;Station] &lt;-.-&gt;\n|Data&lt;br/&gt;Link| r\n\nsubgraph Actuators\n    direction LR\n    Motors\n    Servos\nend</code></pre>"},{"location":"CS_Electives/AI_in_Robotics/02_Probabilistic/","title":"Probabilistic Modelling","text":"<ul> <li>Every robot action is uncertain</li> <li>Every sensor measurement is uncertain</li> </ul> <p>Probabilistic approach acknowledges these uncertainties and uses models to abstract useful information from data</p> <p>Goal is an incrementally-updated probabilistic estimate of position of robot relative to map</p>"},{"location":"CS_Electives/AI_in_Robotics/02_Probabilistic/#associated-concepts","title":"Associated Concepts","text":"<ul> <li>Mean</li> <li>Variance</li> <li>Discrete &amp; Continuous Random Variables</li> <li>Total Probability</li> <li>Gaussian Distribution</li> <li>Bayes Rule</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/02_State_Space_Modelling/","title":"State Space Modelling","text":"<p>Representation of a system that replaces an \\(n\\)th order differential equation with a single first order matrix differential equation.</p> <p>The state space representation is given through 2 equations</p> State \\(\\dot q(t) = Aq(t) + Bx(t)\\) Output \\(y(t) = Cq(t) + Dx(t)\\) <p>where</p> Dimension \\(q\\) State Vector \\(n \\times 1\\) Constant \\(A\\) State Matrix \\(n \\times n\\) Constant \\(B\\) Input Matrix \\(n \\times r\\) Constant \\(x\\) Input \\(r \\times 1\\) Function of time \\(C\\) Output matrix \\(m \\times n\\) Constant \\(D\\) Direct transition matrix \\(m \\times r\\) Constant \\(y\\) Output \\(m \\times 1\\) Function of time"},{"location":"CS_Electives/AI_in_Robotics/02_State_Space_Modelling/#advantages","title":"Advantages","text":"<ul> <li>Concise notation: Even large systems can be represented using 2 simple equations</li> <li>Easy to develop general techniques to solve systems, as all systems are represented by the same notation</li> <li>Computers easily simulate first-order equations</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/02_State_Space_Modelling/#example","title":"Example","text":"\\[ 2 \\dfrac{d^3 y}{dt^3} + 4 \\dfrac{d^2 y}{dt^2} + 6 \\dfrac{dy}{dt} + 8y = 10 u(t) \\\\ \\implies 2 y''' + 4 y'' + 6 y' + 8y = 10 u(t) \\] <p>Since DE is of 3<sup>rd</sup> order, there are 3 state variables $$ x_1 = y, x_2 = \\dot y, x_3 = \\ddot y \\ \\implies 2 \\dot x_3 + 2 x_3 + 6 x_2 + 8x_1 = 10u(t) $$</p>"},{"location":"CS_Electives/AI_in_Robotics/02_State_Space_Modelling/#equation-representation","title":"Equation Representation","text":"\\[ \\begin{aligned} \\dot x_1 &amp;= x_2 \\\\ \\dot x_2 &amp;= x_3 \\\\ \\dot x_3 &amp;= -4x_1 - 3x_2 - 2x_3 + 5u(t) \\end{aligned} \\]"},{"location":"CS_Electives/AI_in_Robotics/02_State_Space_Modelling/#matrix-representation","title":"Matrix Representation","text":"\\[ \\begin{aligned} \\begin{bmatrix} \\dot x_1 \\\\ \\dot x_2 \\\\ \\dot x_3 \\end{bmatrix} &amp;= \\begin{bmatrix} 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ -4 &amp; -3 &amp; -2 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} + \\begin{bmatrix} 0 \\\\ 0 \\\\ 5 \\end{bmatrix} u(t) \\\\ y &amp;= \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} \\end{aligned} \\]"},{"location":"CS_Electives/AI_in_Robotics/02_State_Space_Modelling/#representation-of-kalman-filter","title":"Representation of Kalman Filter","text":"\\[ x_k = A x_{k-1} + B u_{k-1} + w_{k-1} \\] \\[ z_k = H x_k + v_k \\]"},{"location":"CS_Electives/AI_in_Robotics/03_Kinematics/","title":"Kinematics","text":"<ul> <li>Displacement</li> <li>Velocity</li> <li>Acceleration</li> <li>Mobile Robots</li> <li>Robotic Manipulator</li> <li>Mobile Manipulator</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/03_Kinematics/#system-state","title":"System State","text":"<p>Future target position can be easily calculated using Newton\u2019s motion equations. $$ \\begin{aligned} x &amp;= x_0 + v_{x0} \\Delta t + \\dfrac{1}{2} a_x \\Delta t^2 \\ y &amp;= \\cdots \\ z &amp;= \\cdots \\end{aligned} $$ The target parameters \\((x, y, z, v_x, v_y, v_z, a_x, a_y, a_z)\\) are called System State.</p>"},{"location":"CS_Electives/AI_in_Robotics/04_Navigation_and_Tracking/","title":"Navigation &amp; Tracking","text":"<ul> <li>Global coordinate systems &amp; local coordinate systems</li> <li>Robot navigation means robot\u2019s ability to position itself in its frame of reference &amp; then to plan a Plath towards some goal location</li> <li>Tracking is the problem of extraction, detection, identification, and tracking of the mobile robot from its environment to obtain motion parameters such as position, trajectory, velocity, and acceleration of the mobile robot</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/","title":"Localization","text":"<p>Navigation is one of the most challenging competencies required of a mobile robot.</p>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#building-blocks-of-navigation","title":"Building blocks of navigation","text":"<ol> <li>Perception: Robot must interpret its sensors to extract meaningful data</li> <li>Localization: Robot must determine its position in its environment</li> <li>Cognition: Robot must decide how to act to achieve its goals</li> <li>Motion Control: Robot must modulate its motor outputs to achieve the desired trajectory</li> </ol> <p>Devices relying on localization include IMU, encoders, LiDARs, Ultrasonic sensors, onboard cameras</p> <p>Methodologies include Markov, Monte Carlo, Kalman Filters</p>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#particle-filter","title":"Particle Filter","text":"<p>For localization in a known map</p> <p>Estimate posterior density of state variables given the observation variables</p> <p>Generic particle filter estimates the posterior distribution of hidden states using observation measurement process</p> <p>Working principle: Bayes\u2019 Rule</p> <p></p>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#requirements","title":"Requirements","text":"<ul> <li>Uniformly-distributed particles</li> <li>Landmarks</li> <li>Object</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#concept","title":"Concept","text":"<ul> <li>Object senses landmarks and generates measurements vector for each landmark</li> <li>These measurements are bearing angles, ie angle between object and landmark location</li> <li>Since sensors are noisy, bearing noise of gaussian mean 0 is added to the measurements</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#steps","title":"Steps","text":"<ol> <li> <p>Randomly generate set of particles \\(p_i =\u00a0(x_i, y_i, \\theta_i)\\)</p> </li> <li> <p>Predict next state of particles: Move particles based prediction of how the real system is behaving</p> </li> <li> <p>Update weighting of particles proportional to closeness to object</p> </li> <li> <p>Particles that closely match the measurements are weighted higher</p> </li> <li> <p>Represented with larger area</p> </li> <li> <p>Resample, by replacing highly improbable particles with copies of more probable particles</p> </li> <li> <p>Compute estimate</p> </li> </ol> <p>Optionally, compute weighted means and covariance of set of particles to get a state estimate</p> <p></p> <p></p>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#convolution","title":"Convolution","text":"<p>Shifting &amp; flattening of probability distribution of the beliefs</p> <p></p> \\[ P(\\hat x_i \\vert x_i) = \\dfrac{P(x_i \\vert \\hat x_i) \\cdot P(x_i)}{P(\\hat x_i)} \\\\ P(\\hat x_i) = \\sum_j P(x_j \\vert \\hat x_j) \\cdot P(\\hat x_j) \\]"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#inexact-motion","title":"Inexact Motion","text":"<p>Incorporate probability of undershooting/overshooting</p>"},{"location":"CS_Electives/AI_in_Robotics/06_Localization/#multiple-measurements","title":"Multiple Measurements","text":""},{"location":"CS_Electives/AI_in_Robotics/07_Mapping_and_SLAM/","title":"Mapping &amp; SLAM","text":""},{"location":"CS_Electives/AI_in_Robotics/07_Mapping_and_SLAM/#mapping","title":"Mapping","text":"<p>Computer vision and cartography</p> <p>Goal for an autonomous robot is to be able to construct (and/or use) a map/floor plan and to localize itself and its recharging bases.</p>"},{"location":"CS_Electives/AI_in_Robotics/07_Mapping_and_SLAM/#slam","title":"SLAM","text":"<p>Simultaneous Localization and Mapping</p> <p>Method for autonomous vehicles that enables building a map and localization of vehicle in that map at the same time.</p> <p>Allow vehicle to map out unknown environments</p> <pre><code>flowchart LR\nsd[/Sensor&lt;br/&gt;Data/] --&gt; fe --&gt; be --&gt; pose[Pose Graph &lt;br/&gt;&amp; Map Information]\n\nsubgraph fe[\"Frontend&lt;br/&gt;(Sensor-Dependent)\"]\n    direction LR\n    me[\"Motion&lt;br/&gt;Estimation\"] \n    ole[\"Obstacle&lt;br/&gt;Location&lt;br/&gt;Estimation\"]\nend\n\nsubgraph be[\"Backend&lt;br/&gt;(Sensor-Independent)\"]\n    direction LR\n    rpg[\"Register&lt;br/&gt;Pose Graphs\"]\n    go[Graph&lt;br/&gt;Optimization]\nend</code></pre> Localization Mapping SLAM given Map object\u2019s trajectory (position at each time) Use sensor data to estimate current position of object map Build map and estimate trajectory"},{"location":"CS_Electives/AI_in_Robotics/07_Mapping_and_SLAM/#need-for-map","title":"Need for Map","text":"<ul> <li>Path planning</li> <li>Limiting error in state estimates, by providing opportunity to \u2018reset\u2019</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/07_Mapping_and_SLAM/#2d-graph-slam","title":"2D Graph SLAM","text":"<p>Considering uncertainty in \\(x\\) and \\(y\\), gaussian functions are applied to maximize probability of product $$ \\mu = \\Omega^{-1} \\epsilon $$ where</p> <ul> <li>\\(\\mu =\\) locations of landmarks and robot positions</li> <li>\\(\\Omega=\\)  matrix of \\(X\\) and landmarks</li> <li>\\(\\epsilon=\\)\u00a0vector of constraints</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/07_Mapping_and_SLAM/#constraints","title":"Constraints","text":"<ul> <li>Initial constraint</li> <li>Relative motion constraint</li> <li>Relative measurement constraint</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/","title":"Path Planning","text":"<p>Goal is to plan a collision-free route from a starting point to a target point</p> <p>Find a path between 2 locations in an environment, regardless of the level of knowledge about it.</p> <p>Computational problem to find a sequence of valid configurations that move object from source to destination</p>"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#algorithms","title":"Algorithms","text":"<ul> <li>A*</li> <li>Dijkstra</li> <li>GVD (Generalized Moroni Diagrams)</li> <li>RRT (Rapidly Exploring Random Tree)</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#local-global-frame","title":"Local &lt;-&gt; Global Frame","text":"<p>If robot position in a plane is defined by its state vector (location and orientation) is defined by $$ q(t) = \\begin{bmatrix} x(t) \\ y(t) \\ \\theta(t) \\end{bmatrix} $$ Transformation between local frame \\(m\\) and global frame \\(g\\) $$ R(\\theta) = \\begin{bmatrix} \\cos \\theta &amp; \\sin \\theta &amp; 0 \\ - \\sin \\theta &amp; \\cos \\theta &amp; 0 \\ 0 &amp; 0 &amp; 1 \\end{bmatrix} $$</p>"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#directforward-kinematics","title":"Direct/Forward Kinematics","text":"<p>Determination of robot position for given control variables</p>"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#odometrydead-reckoning","title":"Odometry/Dead Reckoning","text":"<p>Obtaining through integration of kinematic model $$ \\begin{aligned} x(t) &amp;= \\int_0^t v(t) \\cdot \\cos \\theta(t) \\cdot dt \\ y(t) &amp;= \\int_0^t v(t) \\cdot \\sin \\theta(t) \\cdot dt \\ \\theta(t) &amp;= \\int_0^t w(t) \\cdot dt \\end{aligned} $$</p> <p>### Euler Method</p> \\[ \\begin{aligned} x(t+1) &amp;= x(t) + v(t) T_s \\cos \\theta(t) \\\\ y(t+1) &amp;= y(t) + v(t) T_s \\sin \\theta(t) \\\\ \\theta(t+1) &amp;= \\theta(t) + w(t) T_s \\end{aligned} \\]"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#control","title":"Control","text":"<p> $$ u(t) = k_p e(t) + k_i \\int_0^t e(\\tau) d \\tau + k_d \\dfrac{d}{dt} e(t) $$ where \\(e=\\) error</p>"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#path-planning-algorithms","title":"Path Planning Algorithms","text":""},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#single-course-shortest-path-problem","title":"Single-Course Shortest Path problem","text":"<p>Finding shortest path from a source to all other vertices in the graph</p> <p>Dijkstra\u2019s algorithm</p>"},{"location":"CS_Electives/AI_in_Robotics/08_Path_Planning/#a-algorithm","title":"A* algorithm","text":""},{"location":"CS_Electives/AI_in_Robotics/09_Motion_Control/","title":"Motion Control","text":"<p>PID (Proportional Integral Derivative) controllers are used to control movement of mobile robot.</p> <p>Linear velocity loop controls the robot wheels speeds using motor speed feedback signal from the encoder</p> <p>Angular velocity control loop keeps robot always in the accepted angle boundary using a 6 degree-of-freedom gyroscope and accelerometer as a feedback signal</p> <pre><code>flowchart LR\nstart(( )) --&gt;\n|\"Desired Path&lt;br/&gt;x_d, y_d, &amp;theta;_d\"| ec[Error&lt;br/&gt;Calculation] \n\nec --&gt;|ex| cta\nec --&gt;|ey| cta\nec --&gt;|\"e&amp;theta;\"| cta\ncta[Conversion to Angular]\n\ncta --&gt;\n|ed| fpidc[1st PID Controller] --&gt;\n|u_right| mrs\n\ncta --&gt;\n|\"e&amp;theta;\"| spidc[2nd PID Controller] --&gt;\n|u_left| mrs\n\nmrs[Mobile Robot System] --&gt;\n|\"Actual Path&lt;br/&gt;x_a, y_a, &amp;theta;_a\"| ec</code></pre>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/","title":"Computer Vision","text":"<p>Extraction, analysis and comprehension of useful information from image(s)</p> <p>Used for Navigation &amp; Mapping</p> <p>An image may be defined as a 2D function \\(f(x, y)\\) where</p> <ul> <li>\\(x, y\\) are spatial coordinates</li> <li>value of \\(f\\) gives the intensity at a point</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#channels","title":"Channels","text":"<ul> <li>For a gray-range image, intensity is given by just one \u2018channel\u2019</li> <li>For color images, intensity is given by 3d vector (3 channels): RGB</li> </ul> <p>Conversion from analog to a \u201cdigital image\u201d requires both coordinates and intensity to be digitized</p> <ul> <li>Sampling: Digitizing the coordinates</li> <li>Quantization: Digitizing the intensity</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#types-of-images","title":"Types of images","text":"Binary Image Intensity Image Color Image Black and white Data matrix whose values have been scaled to represent intensities Intensity image with 3 channels (RGB) Values 0/1 Usually scaled to [0, 255] or [0, 1]"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#image-quantization","title":"Image Quantization","text":"<p>Transforming a real valued sampled image into one with a finite number of distinct values</p> <p>Eg: rounding the digits, setting a max/min range</p>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#convolution-filters","title":"Convolution Filters","text":"<ul> <li>Low-pass: noise removal, blur</li> <li>High-pass: edge detection, sharpening</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#averaging","title":"Averaging","text":""},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#gaussian","title":"Gaussian","text":"<p>Nearest neighboring pixels have the most influence</p> <p>Center of the filter matrix will be larger than the edges and the corners</p> <p>Variance of the filter determines the smoothing</p>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#median","title":"Median","text":"<p>Salt and pepper noise reduction</p>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#bilateral","title":"Bilateral","text":"<p>Blur while maintaining sharp edges</p> <p>Slower</p>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#edge-detection","title":"Edge Detection","text":"<p>Look for a neighborhood with strong signs of change</p> <ul> <li>Surface normal discontinuity</li> <li>Surface color discontinuity</li> <li>Illumination discontinuity</li> <li>Depth discontinuity</li> </ul> <p>Kernel</p> <ul> <li>Kernel should be symmetric</li> <li>Normalization required to make the sum of elements in the filter as 1</li> </ul> <p>Derivative will be non-zero at edges</p> \\[ \\begin{aligned} \\nabla f &amp;= ( f_x, f_y ) \\\\ \\theta &amp;= \\tan^{-1} \\left( \\dfrac{ f_y }{ f_x} \\right) \\\\ \\vert \\vert \\nabla f \\vert \\vert &amp;= \\sqrt{     {f_x}^2 + {f_y}^2 } \\end{aligned} \\]"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#discrete-gradient","title":"Discrete gradient","text":"\\[ \\begin{aligned} \\dfrac{\\partial f}{\\partial x} &amp;\\approx \\dfrac{f(x+1, y) - f(x, y)}{1} \\\\ &amp;\\approx f(x+1, y) - f(x, y) \\end{aligned} \\]"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#sobel-operator","title":"Sobel Operator","text":"<ul> <li>Sobel</li> <li>Prewitt</li> <li>Roberts</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#difficulties","title":"Difficulties","text":"<ul> <li>Neighborhood size</li> <li>Change detection</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#canny-edge-detection","title":"Canny Edge Detection","text":"<p>Robust and flexible</p> <ol> <li>Noise reduction</li> <li>Calculating intensity gradient</li> <li>Suppression of false edges</li> <li>Hysteresis thresholding</li> </ol> <p>Thresholding: \\(\\vert \\vert \\nabla f \\vert \\vert\\) are compared with 2 threshold values</p> <ul> <li>If \\(\\vert \\vert \\nabla f \\vert \\vert &gt; T_h\\), those pixels are associated with solid edges and included in the final edge map</li> <li>If \\(\\vert \\vert \\nabla f \\vert \\vert &lt; T_l\\), those pixels are suppressed and excluded from final edge map</li> <li>All other pixels are marked as \u201cweak\u201d edges, and become candidates for final edge map</li> <li>If weak pixels are connected to solid pixels, they are also included in final edge map</li> </ul> <p></p>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#camera-calibration","title":"Camera Calibration","text":"<p>Estimates parameters of lens and image sensor, to be used for</p> <ul> <li>Correction of lens distortion</li> <li>Object measurement</li> <li>Determine location of camera in scene</li> <li>Estimate depth using stereo camera</li> <li>Estimate 3D structure from camera motion</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#camera","title":"Camera","text":"<p>Converts 3D world into 2D image $$ \\begin{aligned} x &amp;= PX \\ \\begin{bmatrix} X \\ Y \\ Z \\end{bmatrix} &amp;=  \\begin{bmatrix} p_1 &amp; p_2 &amp; p_3 &amp; p_4 \\ p_5 &amp; p_6 &amp; p_7 &amp; p_8 \\ p_9 &amp; p_{10} &amp; p_{11} &amp; p_{12} \\end{bmatrix} \\begin{bmatrix} X \\ Y \\ Z \\ 1 \\end{bmatrix} \\end{aligned} $$ where</p> <ul> <li>\\(x =\\)  homogeneous image</li> <li>\\(P =\\)  camera matrix</li> <li>\\(X =\\)  homogeneous world point</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#parameters","title":"Parameters","text":"Intrinsic/Internal Extrinsic/External Allows mapping between pixel coordinates and camera coordinates in the image frame Describe orientation and location of camera Example Optical centerFocal lengthRadial distortion of coefficients of lens Rotation of cameraTranslation of camerawrt world coordinate system"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#pinhole-camera-model","title":"Pinhole Camera Model","text":"<p>Basic camera model without a lens. Light passes through aperture and projects an inverted image on the opposite side of the camera.</p> <p></p> <p>Visualize the virtual image plane in front of the camera and assume that it is containing the upright image of the scene $$ \\begin{aligned} w \\begin{bmatrix} x &amp; y &amp; 1 \\end{bmatrix} &amp;= \\begin{bmatrix} X &amp; Y &amp; Z &amp; 1 \\end{bmatrix} P \\ P &amp;= \\begin{bmatrix} R \\ T \\end{bmatrix} k \\ k &amp;= \\begin{bmatrix} f_x &amp; s &amp; c_x \\ 0 &amp; f_y &amp; c_y \\ 0 &amp; 0 &amp; 1 \\end{bmatrix} \\end{aligned} $$ where</p> <ul> <li>\\(w=\\) scale factor</li> <li>\\(P=\\) camera matrix represents the camera specifications</li> <li>\\(R=\\) Rotation</li> <li>\\(T=\\) Translation</li> <li>\\(k=\\) Intrinsic matrix</li> <li>\\(F =\\) focal length in world units, usually in mm</li> <li>\\((p_x, p_y) =\\) size of pixel in world units</li> <li>\\(f_x, f_y = \\dfrac{F}{p_x}, \\dfrac{F}{p_y} =\\) focal length in pixels</li> <li>\\(\\begin{bmatrix}c_x &amp; c_y \\end{bmatrix}=\\) optical center (principal point) in pixels</li> <li>\\(s = f_x \\tan \\alpha\\) skew coefficient</li> <li>non-zero if image axes are not perpendicular</li> <li>1 pixel \\(\\approx 1/96 \\text{inch}\\)</li> </ul> <p></p>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#distortion","title":"Distortion","text":"Barrel(Radial) Pincushion(Radial) Tangential/Decentering Meaning Straight lines of actual world appear curved outward Straight lines of actual world appear curved inward Image appears to slanted &amp; stretched -ve radial displacement +ve radial displacement Cause Unequal light bending(rays bent more at lens\u2019 border than at center)Before hitting the image sensor, the light ray is shifted radial inward/outward from its optimal point Unequal light bending(rays bent more at lens\u2019 border than at center)Before hitting the image sensor, the light ray is shifted radial inward/outward from its optimal point Picture screen/sensor is at an angle wrt lens Example"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#radial-distortion-coefficients-model","title":"Radial distortion coefficients model","text":"\\[ \\begin{aligned} x_\\text{distorted} &amp;= x (1 + k_1 r^2 + k_2 r^4 + k_3 * r^6) \\\\ y_\\text{distorted} &amp;= y (1 + k_1 r^2 + k_2 r^4 + k_3 * r^6) \\end{aligned} \\] <p>where</p> <ul> <li>\\(x_\\text{distorted}, y_\\text{distorted}\\) are distorted points</li> <li>\\(x, y\\) are undistorted and dimensionless pixel location in normalized image coordinates format, calculated from pixel coordinates by translating to optical center and dividing by focal length in pixels</li> <li>\\(k_1, k_2, k_3\\) are radial distortion coefficients of the lens</li> <li>\\(r^2 = x^2 + y^2\\)</li> </ul>"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#tangential-distortion-coefficients-model","title":"Tangential distortion coefficients model","text":"\\[ \\begin{aligned} x_\\text{distorted} &amp;= x + [2 p_1 x y + p_2(r^2 + 2x^2)] \\\\ y_\\text{distorted} &amp;= y + [2 p_1 (r^2 + 2y^2) + 2 p_2 x y] \\end{aligned} \\]"},{"location":"CS_Electives/AI_in_Robotics/10_Computer_Vision/#distortion-removal","title":"Distortion Removal","text":"<ol> <li>Calibrate camera and obtain intrinsic camera parameters</li> <li>Control percentage of undersized pixels in undistorted image by fine-tuning camera matrix</li> <li>Use revised camera matrix to remove distortion from image</li> </ol>"},{"location":"CS_Electives/API/","title":"Index","text":""},{"location":"CS_Electives/API/#apis","title":"APIs","text":"<p>Application Programming Interface</p>"},{"location":"CS_Electives/API/#architecture-style","title":"Architecture Style","text":"Best Usage Communication Protocol Data Format Analogy Security RPCRemote Procedure Calls SOAP Legacy systemsEnterprise integrations LetterSend, stamp High REST Simple PublicWeb-ServicesSimple JSON XML Postcard Low GraphQL Schema Controllable Complex dataPersonalized UXFlexible data access Own querying language gRPC PerformanceLanguage-Agnostic RealtimeAppsStreaming dataMicro-servicesHigh performance <p>Previously, SOAP was the most secure. However, now all types can be encrypted using API tools.</p>"},{"location":"CS_Electives/Audio/","title":"Audio","text":""},{"location":"CS_Electives/Audio/#references","title":"References","text":""},{"location":"CS_Electives/Audio/01_Introduction/","title":"Introduction","text":""},{"location":"CS_Electives/Audio/01_Introduction/#human-perception-of-sound","title":"Human Perception of Sound","text":""},{"location":"CS_Electives/Audio/01_Introduction/#dataset","title":"Dataset","text":""},{"location":"CS_Electives/Audio/01_Introduction/#building","title":"Building","text":"<ul> <li>Who are the users</li> <li>What do they need</li> <li>What task are they trying to solve</li> <li>How do they interact with the system<ul> <li>Distance</li> <li>Environment<ul> <li>Background Noise</li> <li>Reverb</li> </ul> </li> </ul> </li> <li>Quality Control<ul> <li>Only keep whatever a human can understand</li> </ul> </li> </ul>"},{"location":"CS_Electives/Audio/01_Introduction/#industry-standard","title":"Industry-Standard","text":"<ul> <li>Google Speed Commands dataset<ul> <li>Recorded as individual words, not sentences</li> <li>1000-4000 examples of each word</li> </ul> </li> </ul>"},{"location":"CS_Electives/Audio/01_Introduction/#good-characteristics-of-model","title":"Good Characteristics of Model","text":"Volume Invariance"},{"location":"CS_Electives/Audio/01_Introduction/#pre-processing","title":"Pre-Processing","text":"<p>What aspects of the signal should you sent to the neural network</p> <ol> <li>Align on start point</li> <li>Normalization of amplitude</li> <li>Denoise</li> <li>Convert to frequencies, using Fast Fourier transform<ol> <li>Extract features</li> <li>Sliding window</li> </ol> </li> <li>Cut on end point</li> </ol> Word Volume Waveform Spectrogram MFCC Yes Loud Quiet No Loud Quiet"},{"location":"CS_Electives/Audio/01_Introduction/#mel-filterbanks","title":"Mel Filterbanks","text":""},{"location":"CS_Electives/Audio/02_Keyword_Spotting/","title":"Keyword Spotting","text":""},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#keyword-spotting-vs-speed-recognition","title":"Keyword Spotting vs Speed Recognition","text":"Keyword Spotting Speed Recognition Power-Usage Low High Type Continuous Location On-Device On-Device/Online"},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#types","title":"Types","text":"Single Shot Streaming Only keyword spoken Keyword within a sentence"},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#challenges","title":"Challenges","text":"Aspect Constraint Comment Metrics System performance Latency Listening animation Bandwidth Preserving Security Safeguarding data being sent to cloud Privacy Model Accuracy Listen continuously, but only trigger at the right timePick operating point accordingly Personalization Trigger only for user, not for other users or for background noise Resource constraints Battery Memory"},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#model","title":"Model","text":"<p>Spectrogram is just an image</p> <p></p>"},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#tinyconv","title":"TinyConv","text":"<p>Since we only we are only focused on recognizing a few keywords, we can just use One Conv2D followed by single dense layer</p> <pre><code>flowchart LR\n\nInput --&gt; Conv --&gt; FC --&gt; Softmax --&gt; Output</code></pre>"},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#limitations","title":"Limitations","text":"<ul> <li>Limited vocabulary</li> <li>Lower accuracy</li> <li>Limited UX</li> </ul>"},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#cascading","title":"Cascading","text":""},{"location":"CS_Electives/Audio/02_Keyword_Spotting/#multiple-inferences","title":"Multiple Inferences","text":"<ul> <li>Average inferences across multiple time slices</li> </ul> <p>This is to avoid False Positives for group of words. For eg: - No     - No good     - Notion     - Notice     - Notable</p>"},{"location":"CS_Electives/Blockchain/","title":"Blockchain","text":""},{"location":"CS_Electives/Blockchain/#referencs","title":"Referencs","text":"<ul> <li> Blockchain and Cryptocurrency | Stanford</li> <li> Cryptocurrency Engineering and Design | MIT</li> <li> Blockchains and Crypto Assets | Prof Carol Alexander</li> </ul>"},{"location":"CS_Electives/CSE/","title":"Computational Science &amp; Engineering","text":""},{"location":"CS_Electives/CSE/#references","title":"References","text":"<ul> <li> Physics-Informed Neural Networks (PINNs)</li> <li> Physics Informed Machine Learning | Steve Brunton</li> <li> MIT OCW | Parallel Computing and Scientific Machine Learning</li> <li> Deep Learning in Scientific Computing | ETH Zurich</li> <li> AI in the Sciences and Engineering | ETH Zurich</li> </ul>"},{"location":"CS_Electives/CSE/01/","title":"01","text":""},{"location":"CS_Electives/CSE/01/#typical-scientific-tasks","title":"Typical Scientific Tasks","text":""},{"location":"CS_Electives/CSE/01/#pinn","title":"PINN","text":"<p>Physics-Informed Neural Networks</p> <p></p>"},{"location":"CS_Electives/CSE/01/#digital-twin","title":"Digital Twin","text":""},{"location":"CS_Electives/CSE/01/#physics-properties-preferred-in-machine-learning","title":"Physics\u2019 Properties Preferred in Machine Learning","text":"<ul> <li> <p>Interpretability</p> </li> <li> <p>Generalizability</p> </li> <li> <p>Parsimony/Simplicity</p> </li> <li> <p>Symmetries/Conservations</p> </li> <li> <p>Invariance: \\((f \\circ g)(x) = f(x)\\)</p> </li> <li>Equivariance: \\((f \\circ g)(x) = (g \\circ f)(x)\\)</li> </ul> <p>where</p> <ul> <li>\\(f\\)\u00a0is deep learning model</li> <li>\\(g\\) is a transformation such as rotation</li> </ul>"},{"location":"CS_Electives/Cloud_Computing/","title":"Cloud Computing","text":""},{"location":"CS_Electives/Cloud_Computing/#references","title":"References","text":"<ul> <li> Cloud Computing | IIT</li> </ul>"},{"location":"CS_Electives/Computer_Vision/","title":"Computer Vision","text":"<p>Visual recognition using computers</p>"},{"location":"CS_Electives/Computer_Vision/#tasks","title":"Tasks","text":""},{"location":"CS_Electives/Computer_Vision/#references","title":"References","text":"<ul> <li> Deep Learning for Computer Vision | Andrej Karpathy | Stanford</li> <li> Deep Learning for Computer Vision | IITM</li> <li> Introduction to Computer Vision | UC Berkeley</li> <li> Computer Vision | UC Berkeley</li> <li> Photo Forensics: Physics-Based Techniques | UC Berkeley</li> <li> Introduction| First Principles of Computer Vision</li> </ul>"},{"location":"CS_Electives/Computer_Vision/#current-video","title":"Current Video","text":""},{"location":"CS_Electives/Computer_Vision/01_Introduction/","title":"Introduction","text":""},{"location":"CS_Electives/Computer_Vision/01_Introduction/#computer-vision","title":"Computer Vision","text":""},{"location":"CS_Electives/Computer_Vision/01_Introduction/#insights","title":"Insights","text":"<ol> <li>Vision in animals starts by cells recognizing simple patterns such as edges, not the whole object</li> <li>Vision is hierarchical</li> </ol> <ol> <li>Perception grouping</li> <li>Identifying features is more important than identifying the entire object</li> </ol>"},{"location":"CS_Electives/Computer_Vision/02_Image_Classification/","title":"Image Classification","text":"<p>Image \u2192 Class</p>"},{"location":"CS_Electives/Computer_Vision/02_Image_Classification/#why-is-it-hard","title":"Why is it hard?","text":"<ul> <li>Semantic gap between input and output</li> <li>Viewpoint variation</li> <li>Translational</li> <li>Rotational</li> <li>Illumination variation</li> <li>Deformation of object</li> <li>Occlusion: object partially hidden</li> <li>Background clutter</li> <li>Intraclass variation</li> <li>Textural variation</li> </ul>"},{"location":"CS_Electives/Computer_Vision/02_Image_Classification/#models","title":"Models","text":"Disadvantage Robust to variance \\(k\\) Nearest neighbor L1 L2 distance of pixels Inference speed proportional to train size \u274c Linear \u274c FNN \u274c CNNs \u2705"},{"location":"CS_Electives/Computer_Vision/02_Image_Classification/#pre-processing","title":"Pre-Processing","text":"<ul> <li>Resize images to the same size</li> <li>Does Greyscale work better???</li> <li>Greyscale worsens linear classifier because it can no longer extract colors; linear classifier cannot extract textures well regardless anyways</li> <li>Normalize<ul> <li>Subtract mean image   or</li> <li>Subtract per channel mean</li> </ul> </li> </ul>"},{"location":"CS_Electives/Computer_Vision/03_Localization/","title":"Localization","text":"<p>Image \u2192 Bounding box</p> <p></p> <ol> <li>Train classification model</li> <li>Attach new fully-connected \"regression head\"</li> <li>Train regression head with regression loss</li> <li>At inference, use both heads</li> </ol>"},{"location":"CS_Electives/Computer_Vision/03_Localization/#regression-head-approaches","title":"Regression Head Approaches","text":"<ul> <li>Class agnostic: one box in total</li> <li>Class specific: one box per class<ul> <li>more intuitive</li> <li>works for multiple object localization; For eg: represent human pose with \\(k\\) joints</li> </ul> </li> </ul>"},{"location":"CS_Electives/Computer_Vision/03_Localization/#regression-head-position","title":"Regression Head Position","text":""},{"location":"CS_Electives/Computer_Vision/03_Localization/#sliding-window","title":"Sliding Window","text":""},{"location":"CS_Electives/Computer_Vision/03_Localization/#naive","title":"Naive","text":"<ul> <li>Run classification + regression head at multiple location on high resolution network</li> <li>Combine classifier and regressor predictions across all scales for final prediction</li> </ul>"},{"location":"CS_Electives/Computer_Vision/03_Localization/#efficient","title":"Efficient","text":"<p>Convert FC layers into conv layers</p> <p></p> Train Inference(larger image) <p>Advantage: Extra compute only for extra pixels</p>"},{"location":"CS_Electives/Computer_Vision/04_Detection/","title":"Detection","text":"<p>Perform classification and localization for multiple (unspecified) instances</p> <p>Hard to solve with techniques used for localization, as we need variable sized outputs</p> <p></p> <p></p>"},{"location":"CS_Electives/Computer_Vision/04_Detection/#approaches","title":"Approaches","text":"<ul> <li>Brute-force Classification: Keep running classification for sliding window at different positions; computationally-expensive</li> <li>Histogram of oriented gradients</li> <li>Deformable parts model</li> <li>Region proposals<ul> <li>Class -agnostic object detector</li> <li>Look for \"blob-like\" regions that are likely to be foreground containing objects</li> <li>Search techniques<ul> <li>Selective search</li> <li>EdgeBoxes</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Computer_Vision/04_Detection/#datasets","title":"Datasets","text":"<ul> <li>Pascal</li> <li>ImageNet Detection</li> <li>Microsoft Coco</li> </ul>"},{"location":"CS_Electives/Computer_Vision/05_Image_Captioning/","title":"Image Captioning","text":"<p>Rather than instructing the RNN to sample text at random, we are conditioning that sampling by the output of the CNN</p>"},{"location":"CS_Electives/Computer_Vision/05_Image_Captioning/#forward-pass","title":"Forward Pass","text":""},{"location":"CS_Electives/Computer_Vision/05_Image_Captioning/#backward-pass","title":"Backward pass","text":"<ul> <li>If you start with pre-trained CNN, only backprop for the RNN</li> <li>Else, backprop through the RNN and CNN</li> </ul>"},{"location":"CS_Electives/Computer_Vision/06_Segmentation/","title":"Segmentation","text":""},{"location":"CS_Electives/Computer_Vision/06_Segmentation/#types","title":"Types","text":"Semantic Instance/Simultaneous detection &amp; segmentation Label every pixel Differentiate instances \u274c \u2705 Working Method 1Method 2Method 3: Multi-ScaleMethod 4: Iterative refinementMethod 5: Upsampling R-CNNFast R-CNN Example"},{"location":"CS_Electives/Computer_Vision/06_Segmentation/#region-refinement","title":"Region Refinement","text":""},{"location":"CS_Electives/Computer_Vision/07_Video/","title":"Video","text":"<p>Continuous stream of images</p>"},{"location":"CS_Electives/Computer_Vision/07_Video/#before-deep-learning","title":"Before deep learning","text":"<p>they used 'tracklets'</p> <p></p> <p></p>"},{"location":"CS_Electives/Computer_Vision/07_Video/#generalizing-cnns","title":"Generalizing CNNs","text":"<p>Intuitively a recurrent CNNs to share weights across time</p> <p>Extend convolutional filters in time, performing spatio-temporal convolutions,</p> <p>so filters will be \\(w \\times h \\times T; T \\in [2, 15]\\), where \\(T =\\) temporal width</p> <p>However, single frame is a very strong baseline and motion detection does not add much value</p>"},{"location":"CS_Electives/Computer_Vision/10_Visual_Wake/","title":"Visual Wake","text":""},{"location":"CS_Electives/CyberSecurity/","title":"Computer Systems Security","text":"<p>What are issues with Computer Systems security and How to improve them</p> <p>There isn\u2019t exactly a textbook on this topic</p>"},{"location":"CS_Electives/CyberSecurity/#pre-requisites","title":"Pre-Requisites","text":"<ul> <li> Computer Networks</li> </ul>"},{"location":"CS_Electives/CyberSecurity/#references","title":"References","text":"<ul> <li> Introduction to Cybersecurity | Harvard</li> <li> Computer Systems Security | MIT 6.858</li> <li> Spring 2022</li> <li> Fall 2014</li> <li> Cyber Security Fundamentals | Level Effect </li> <li> Google Cybersecurity Certificate</li> <li> Machine Learning for Cyber Security | University of Purdue</li> <li>Lectures</li> <li>Labs</li> <li> Machine Learning for Cyber Security | Cathal Smyth</li> <li> Cyber Security | IIT Bombay</li> <li> Digital Forensics</li> <li> Cybersecurity and Privacy | IIT Madras</li> <li> Ethical Hacking | FreeCodeCamp</li> <li> Introduction to Digital Forensics | DFIR Science</li> <li> Securing Autonomous Systems | Abhishek Gupta</li> <li> Network Security | IITB</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/","title":"Cyber-Security","text":"<p>Security: Achieving a goal against an adversary</p>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#cyber-security_1","title":"Cyber-Security","text":"<ul> <li>Protection of important information and related systems</li> <li>All fields require cyber-security, especially financial and govt institutions</li> <li>Highly influenced by military</li> <li>There is always tradeoff between usability and security</li> </ul> <p>Note: Never hack into a system you\u2019re not authorized to do so, not even a scan.</p> Entity Every entity has an identification Resource Authentication Process of proving an entity's identification Authorization Whether or not an entity can have access to a resource, after authentication"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#privileges","title":"Privileges","text":"<p>Whenever you\u2019re designing a system, everyone should have the least amount of privileges as possible.</p>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#aspects","title":"Aspects","text":""},{"location":"CS_Electives/CyberSecurity/01_Introduction/#policy","title":"Policy","text":"<p>CIA</p> <ul> <li>Confidentiality</li> <li>Protection of data</li> <li>Integrity</li> <li>Maintaining the data as it is</li> <li>Availabiltiy (Capacity Planning)</li> <li>Making information available when required</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#thread-model","title":"Thread Model","text":"<p>Assumptions about adversary</p> <p>Better to be over-cautious about adversary than casual</p>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#mechanism","title":"Mechanism","text":"<p>Hardware, Software, Algorithms to enforce policy against the threat model</p> <p>This process is iterative, as you are trying to achieve a negative goal, so you need to keep updating the system.</p> <p>A good mechanism is one that enforces the policy using as few components as possible. The more endpoints you have, the more vulnerabilities</p>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#cyber-security-awareness","title":"Cyber Security Awareness","text":"<p>Not a science</p> <p>It is an evolving list of best practices</p> <p>Instilling knowledge to people about these practices</p>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#cyber-security-threats","title":"Cyber Security Threats","text":"<p>These are very easy for hackers</p> <ul> <li>Web Application</li> <li>Software Vulnerability</li> <li>Credentials Theft</li> <li>\u2018Strategic Web Compromise\u2019</li> <li>DDOS (Distributed Denial of Service)</li> <li>Malware/Ransomware</li> <li>Phishing</li> <li>Social Engineering</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#threat-creators","title":"Threat Creators","text":"Skill Goal Example Script Kddies Low Hacktivism Varied Public show against unethical organizations \u2018Anonymous\u2019 Crime ORganizations Medium \\(\\iff\\) High Nation State Actors Very High Insider Threat Low Edward Snowden"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#fields-of-cyber-security","title":"Fields of Cyber-Security","text":""},{"location":"CS_Electives/CyberSecurity/01_Introduction/#risk-management","title":"Risk-Management","text":"<ul> <li>Security Strategies</li> <li>Risk Assessments</li> <li>List out the possible outcomes</li> <li>Security Architecture</li> <li>Compliance Reviews</li> <li>Risk &amp; Governance</li> <li>Policy</li> <li>Awareness</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#offensive","title":"Offensive","text":"<ul> <li>Vulerability Assessment</li> <li>Penetration Testing</li> <li>Bug Bounty</li> <li>Netowrk Instrusion</li> <li>Hacking</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#defensive","title":"Defensive","text":"<p>Mostly white hat hackers do this</p> <ul> <li>Data Protection</li> <li>Log Monitoring</li> <li>Incident Response</li> <li>Threat Intelligence &amp; Detection</li> <li>Using indicators, like fraud detection in data mining</li> <li>Cyber Forensics</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#types-of-hackers","title":"Types of Hackers","text":"<ul> <li>White Hat = Ethical Hacking</li> <li>Black Hat =  Cracking/Unethical Hacking</li> <li>Grey Hat = Mix of both</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#parts-of-cyber-security","title":"Parts of Cyber-Security","text":""},{"location":"CS_Electives/CyberSecurity/01_Introduction/#vulnerability","title":"Vulnerability","text":"<p>Weakness in the system</p> <ul> <li>Bugs</li> <li>Misconfiguration</li> <li>Poor process or control</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#threat","title":"Threat","text":"<p>Circumstance/event with potential harm</p> <ul> <li>Cyber criminals</li> <li>Nation State Actors</li> <li>Internal Threats</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#cyber-controls","title":"Cyber Controls","text":""},{"location":"CS_Electives/CyberSecurity/01_Introduction/#types","title":"Types","text":"<p>Defence-in-depth is followed, using a collection of these types</p> <ul> <li>Administrative   You cannot proceed to the other types without first addressing this</li> <li>Compliance to regulators</li> <li>Standarsds</li> <li>Policies</li> <li>Precedures</li> <li>Legal contracts</li> <li>Service level agreements</li> <li>Preventative</li> <li>Firewalls</li> <li>Web Proxy<ul> <li>Internet Content Inspection</li> </ul> </li> <li>Email Gateways</li> <li>Anti-Virus</li> <li>Patch Management</li> <li>Detective</li> <li>Vulnerability Scanning</li> <li>Log Monitoring</li> <li>Security Reviews</li> <li>Honey Bot<ul> <li>Enticement of hackers, to detect how they would attack your main system</li> <li>Not lure/entrap (that is illegal)</li> </ul> </li> <li>Corrective</li> <li>Incident Response</li> <li>Cyber Forensics</li> <li>Business Continuity &amp; Disaster Recovery</li> <li>Deterrent Control</li> <li>Just to deter any possible hackers; Doesn\u2019t provide security</li> <li>Such as a \u2018Beware of Dog\u2019, without actually having a dog</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#examples","title":"Examples","text":"<ul> <li>Firewall is like Locks</li> <li>Log Monitoring is like CCTV</li> </ul>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#risk","title":"Risk","text":"<p>Materialized threat exploiting a vulnerability $$ \\text{Inherent Risk} + \\underset{\\approx \\text{ Brakes}}{\\text{Cyber Controls}} = \\text{Residual Risk} $$ The organization should decide the residual risk it can tolerate.</p>"},{"location":"CS_Electives/CyberSecurity/01_Introduction/#4-ways-to-handle-risk","title":"4 ways to handle risk","text":"<ul> <li>Risk assessment</li> <li>Risk transfer</li> <li>Risk mitigation</li> <li>(one more thing)</li> </ul>"},{"location":"CS_Electives/CyberSecurity/02_Securing_Accounts/","title":"Securing Accounts","text":"Attack Description Problem Solution Dictionary Hacker attempts different combination of the dictionary to find credential Do not use words from dictionary Brute-Force Hacker attempts all possible combination of credentials Even if the credential is random, if it is too short, hacker will be able to get it NIST recommendations for credentialsMFASSOPassword Manager Keylogging Malicious software recording everything user types Adversary will get access to username, credential, OTP - Avoid using public computers- Avoid connecting to public networks Credential Stuffing Using list of known credentials Adversary will try these to get access Use different credentials for different services Social Engineering Phishing Be careful of clicking linksBe careful of entering information online Machine-in-the-Middle Compromise of any machines in between Be careful what online services you use Deepfakes AudioVideo Voice can be used by adversary to gain access Disable authentication using voiceDo not speak out any special key phrases into services"},{"location":"CS_Electives/CyberSecurity/02_Securing_Accounts/#solutions","title":"Solutions","text":"Solution Good password Check out NIST credential  requirements MFAMulti-Factor Authentication SSOSingle Sign-On Password-Manager Catch: protect the master password Passkeys Login to online services with biometrics via device's hardware"},{"location":"CS_Electives/CyberSecurity/02_Securing_Accounts/#nist-credentials-requirements","title":"NIST credentials requirements","text":"<p>National Institute of Standards and Technology</p> <ul> <li>Should contain letters, numbers, punctuations, and unicode characters</li> <li>Should at least be 8 characters</li> <li>Should not contain<ul> <li>credentials from previously-breached corpuses</li> <li>Dictionary words</li> <li>Repetitive or sequential characters</li> <li>Context-specific words<ul> <li>username</li> <li>name of service</li> </ul> </li> </ul> </li> <li>Do not allow hint, that is accessible to unauthenticated entity</li> <li>Verifiers should not require memorized secrets to be changed arbitrarily/periodically<ul> <li>Keeping on changing will irritate people and they will end up making a less-secure credential</li> </ul> </li> <li>Verifiers should enforce a rate-limiting mechanism</li> </ul>"},{"location":"CS_Electives/CyberSecurity/02_Securing_Accounts/#mfa","title":"MFA","text":"<p>Multi-Factor Authentication</p> Factor Meaning Example Knowledge Something you know Childhood best friendcredential Possession Something you have OTP (One-Time credential) Inherence Something you are Biometrics Sending OTP over SMS is not safe - SMS is unencrypted - SIM Swapping"},{"location":"CS_Electives/CyberSecurity/03_Securing_Data/","title":"Securing Data","text":"<p>According NIST requirements, secrets must be salted and hashed</p> Meaning Reversible Limitation One-way Hashing Converting credential into fixed-length hash value \u274c - multiple credentials can have the same hash value; which is also good because adversary cannot easily get the credential even with hashes- multiple people can have the same credential and hence, the same hash    - adversary will use this information to find patterns between the people and crack the credentials Salting Private key perturbs the hash value N/A Encryption \u2705 <p>The hashing algorithm need not be private; reputed hashing functions are nearly impossible to reverse-engineer</p>"},{"location":"CS_Electives/CyberSecurity/03_Securing_Data/#problems","title":"Problems","text":"Rainbow Table Adversaries may have already hashed all the words in the dictionaryBut very unlikely for reputed hashing functions <p>If an online service directly emails your password - that means they know your password, and hence it is stored unencrypted - do not use that service anymore</p>"},{"location":"CS_Electives/CyberSecurity/03_Securing_Data/#encryption","title":"Encryption","text":"Type Encryption Decryption Application Algorithms Secret-Key/Symmetric Private key Private key AESTriple DES AssymetricPublic-Key Public key Private key Messaging data transfer and storage Diffie-HellmanMQVRSA AssymetricPrivate-Key Private key Public key Digital signaturesMessage source verification End-to-End ## Deleting Data <p>Deleting from storage device does not actually physically delete the files; it just frees up the pointer</p> <ul> <li>Secure deletion: just turn all the bits to 0s/1s/random</li> <li>Full-disk encryption/Encryption at rest<ul> <li>Data only decrypted when the device is on</li> <li>Important to enable this at the start of using storage device<ul> <li>Over time, device may wear out and encryption may not happen</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/CyberSecurity/03_Securing_Data/#ransomeware","title":"Ransomeware","text":"<p>Adversary encrypts the victim's storage for payment</p>"},{"location":"CS_Electives/CyberSecurity/03_Securing_Data/#quantum-computing","title":"Quantum Computing","text":"<p>If adversaries get more computing power, all systems will become insecure</p>"},{"location":"CS_Electives/CyberSecurity/04_Securing_Systems/","title":"Securing Systems","text":""},{"location":"CS_Electives/CyberSecurity/04_Securing_Systems/#network-layer","title":"Network Layer","text":"Layer Protocol Attacks Solution Application HTTP Machine-in-the-Middle attacks:1. Script injection2. Session hijacking using cookies3. SSL/TLS Stripping: Redirecting to fake website 1. HSTS: Hint from server to browser to always use TLS2. VPN3. URL redirecting of suspicious links HTTPS(<sub>~SSL</sub>~TLS) SSH Transport Port Scanning Penetration testing Network Unsecured Packet sniffing: Adversary can be on the same network, or using an antenna FirewallDeep Packet InspectionProxy SecuredWPA: Wi-Fi Protected Access"},{"location":"CS_Electives/CyberSecurity/04_Securing_Systems/#attacks","title":"Attacks","text":"<ul> <li>Malware</li> <li>Virus</li> <li>Worm: virus that can transfer through port-scanning</li> <li>Botnet</li> <li>DDOS: Distributed Denial of Service<ul> <li>Attempt to disrupt normal services by flooding machines/networks with superfluous requests, typically at high volume and frequency</li> <li>Can be directed at occupying bandwidth, drive space, or CPU</li> <li>Source: one or distributed (botnet)</li> <li>Features of Log<ul> <li>Duration</li> <li>No of packets sent</li> <li>No of received packets</li> <li>Interval of sending packets</li> <li>Interval of receiving packets</li> <li>Upload speed by source</li> <li>Download speed by destination</li> <li>Label: Normal (0)/DDOS (1)</li> </ul> </li> <li>Challenges in Data<ul> <li>Labelling<ul> <li>They don't label themselves</li> <li>Not definite if DDOS is happening</li> <li>Labelling is expensive and time-consuming</li> </ul> </li> <li>Benign network traffic is variant across different infrastructures<ul> <li>University: students streaming videos</li> <li>Enterprise: High SMTP load</li> </ul> </li> </ul> </li> </ul> </li> <li>Zero-day attacks</li> </ul>"},{"location":"CS_Electives/CyberSecurity/04_Securing_Systems/#solutions","title":"Solutions","text":"<ul> <li>Antivirus (with auto-updates)<ul> <li>Cannot handle zero-day attacks</li> </ul> </li> </ul>"},{"location":"CS_Electives/CyberSecurity/05_Securing_Software/","title":"Securing Software","text":"<ul> <li>OWASP: Open Worldwide Application Security Project<ul> <li>has documentation all kinds of attacks</li> </ul> </li> <li>CVE: Common Vulnerabilities and Exposures</li> <li>CVSS: Common Vulnerability Scoring System</li> <li>EPSS: Exploit Prediction Scoring System</li> <li>KEV: Known Exploited Vulnerabilities Catalog</li> </ul>"},{"location":"CS_Electives/CyberSecurity/05_Securing_Software/#attacks","title":"Attacks","text":"Type of Attack Attack What could go wrong Solution Web Phishing <code>&lt;a href=\"https://g00gle.com\"&gt;https://google.com&lt;/a&gt;</code> Fake website 1. Always hover and verify destination before clicking links2. Check if website has <code>https</code> (minimum requirement; not sufficient for safety) JS Injection XSS: Cross-Site Scripting Trick website to execute malicious code via js/css Character escapeHTTP Header Reflected attack Phishing + XSS<code>&lt;a href=\"https://g00gle.com/search?q=script_here\"&gt;https://google.com&lt;/a&gt;</code> Cookie Hijacking Character escapeHTTP Header Stored Attack Email Character escapeHTTP Header SQL Injection Extract details/credentials of other users Prepared statements Command injection Command-line<code>os.system()</code>, <code>eval()</code> Access file system Developer Tools Tweaks Bypass client-side validation Always do server-side validation CSRFCross-Site Request Forgery GET Using GET request for changing stateEg: Buying amazon item Request can be made via other websites using <code>&lt;img src&gt;</code> GET Request should never be used for changing state POST Even POST form has issues Javascript can be used to automatically submit form across websites, when user visits a website with an embedded form<code>document.forms[0].submit()</code> Use POST with a random CSRF token for a particular user Native Code ExecutionR/ACERemote/Arbitrary Code Execution Buffer Overflow Digital SignaturesPackage managers Cracking Reverse Engineering"},{"location":"CS_Electives/CyberSecurity/05_Securing_Software/#solutions","title":"Solutions","text":"<p>Always preprocess inputs from user; do not trust any input</p>"},{"location":"CS_Electives/CyberSecurity/05_Securing_Software/#character-escape","title":"Character Escape","text":"<p>At least escape these</p> replace with <code>&lt;</code> <code>&amp;lt;</code> <code>&gt;</code> <code>&amp;gt;</code> <code>&amp;</code> <code>&amp;amp;</code> <code>\"</code> <code>&amp;quot;</code> <code>'</code> <code>&amp;apos;</code>"},{"location":"CS_Electives/CyberSecurity/05_Securing_Software/#http-header","title":"HTTP Header","text":"<p>Instruct browsers to only allow execution of styles/scripts - in files (not inline css/js) - from the specified domain</p> <pre><code>Content-Security-Policy: script-src https://example.com\nContent-Security-Policy: style-src https://example.com\n</code></pre>"},{"location":"CS_Electives/CyberSecurity/05_Securing_Software/#prepared-statements","title":"Prepared Statements","text":"<p>Let programming language/DB engine handle escaping</p> <pre><code>query = f\"\"\"\nselect *\nfrom users\nwhere username = ? AND password = ?;\n\"\"\"\n</code></pre>"},{"location":"CS_Electives/CyberSecurity/05_Securing_Software/#bug-bounties","title":"Bug Bounties","text":""},{"location":"CS_Electives/CyberSecurity/06_Preserving_Privacy/","title":"Preserving Privacy","text":"<ul> <li>Web browsing history</li> <li>Server-side logs</li> <li>Referer<ul> <li>Browser tells webpage from which webpage you came</li> <li><code>&lt;meta name=\"referrer\" content=\"none\" /&gt;</code></li> <li><code>Referrer-Policy: no-referrer</code></li> </ul> </li> <li>Fingerprinting<ul> <li>Profiling user using request characteristics</li> <li>User-Agent<ul> <li>Browser</li> <li>Operating System</li> </ul> </li> <li>Display resolution</li> <li>Timezone</li> </ul> </li> <li>IDK<ul> <li>Cookies<ul> <li>Session Cookies: usually harmless, but not safe from physical snooping</li> <li>Tracking Cookies: disable</li> <li>Third-Party Cookies: disable</li> <li>Supercookies: no solution</li> </ul> </li> <li>Tracking Query Parameters: remove them</li> <li>LocalStorage is preferred</li> </ul> </li> <li>DNS: Domain Name System<ul> <li>ISP (Internet Service Provider) can see what domain you are looking for</li> <li>DoH: DNS over HTTPS</li> <li>DoT: DNS over TLS</li> </ul> </li> </ul>"},{"location":"CS_Electives/CyberSecurity/06_Preserving_Privacy/#solutions","title":"Solutions","text":"<ul> <li>Incognito: Private Browsing</li> <li>Strict privacy permissions</li> <li>VPN</li> <li>Tor</li> </ul>"},{"location":"CS_Electives/CyberSecurity/06_Preserving_Privacy/#data-protection","title":"Data Protection","text":"<p>GDPR: General Data Protection Regulation</p> Aspect Meaning Solution Identifiability Reduce and safeguard identifiable data components as much as possible De-Identification Techniques- Anonymization- Pseudonymization Safeguarding practices- Data Encryption- Secure servers- Storage Location Data Minimization Limit data collection and duration of storage to only what is required to fulfill specific purpose Right to be Forgotten Notice and Consent Prepare clear notice and consent communication to data subjects Consent- Voluntary- Informed- Competent ## Class of Data Sensitive GeneticBiometricHealthRaceEthnicityPolitical affiliationReligious affiliation Personal NameHome addressLocationEmailIP address Non-Personal Generalized dataAggregated dataData collected by govt bodies"},{"location":"CS_Electives/CyberSecurity/08_Emerging_Technologies/","title":"Emerging Technologies","text":""},{"location":"CS_Electives/CyberSecurity/08_Emerging_Technologies/#growing-threat-space","title":"Growing Threat Space","text":"<ul> <li>IoT devices</li> <li>Social media</li> <li>Generative AI</li> <li>Cloud</li> <li>New attacks<ul> <li>Ransomeware</li> <li>Adversarial attacks to AI</li> <li>Cryptojacking: computer is controlled by a cryptocurrency miner and used to generate cryptocurrency. It works by installing a script on your device that controls it, using its processing power to mine crypto.</li> </ul> </li> </ul>"},{"location":"CS_Electives/CyberSecurity/09_ML_in_Cybersecurity/","title":"ML in Cybersecurity","text":""},{"location":"CS_Electives/CyberSecurity/09_ML_in_Cybersecurity/#applications","title":"Applications","text":"<ul> <li>Detection<ul> <li>Malware</li> <li>Intrusion events</li> <li>Phishing</li> <li>Botnets</li> </ul> </li> <li>Authentication<ul> <li>Biometrics</li> </ul> </li> <li>Forensics<ul> <li>Threat Actor fingerprinting</li> </ul> </li> <li>Pen-testing</li> </ul>"},{"location":"CS_Electives/CyberSecurity/09_ML_in_Cybersecurity/#challenges","title":"Challenges","text":"<ul> <li>Labelling<ul> <li>Few datasets</li> <li>Unbalanced</li> <li>Unlabelled</li> </ul> </li> <li>Heterogeneity<ul> <li>Tabular data</li> <li>Network graphs</li> <li>Concept drift</li> </ul> </li> <li>Volume<ul> <li>Tera-Petabytes</li> <li>Streaming</li> </ul> </li> <li>Obfuscation<ul> <li>Discrimination</li> </ul> </li> </ul>"},{"location":"CS_Electives/CyberSecurity/09_ML_in_Cybersecurity/#solution","title":"Solution","text":""},{"location":"CS_Electives/CyberSecurity/09_ML_in_Cybersecurity/#-transfer-learning-for-adversarial-discriminative-domain-adaptation","title":"- Transfer learning for Adversarial discriminative domain adaptation","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/","title":"999 cybersecurity workshop","text":"<p>Take these points and plug them into other pages</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#why-does-cyber-security-awareness-fails","title":"Why does Cyber Security Awareness Fails","text":"<ul> <li>Complicated/Boring training content</li> <li>Poor Enforcement</li> <li>Lack of monitoring</li> <li>Unfocused awareness</li> <li>Point-in-Time Compliance</li> <li>Culture Misalignment</li> <li>Shared responsibility</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#solution","title":"Solution","text":"<ul> <li>Conventional vs UNconventional Thinking</li> <li>Policy vs Story telling</li> <li>Point-in-Time Assessment vs Continuous monitoring</li> <li>Compliance vs Culture</li> <li>Single-Unit vs Cross-Functional Team</li> </ul> <p>Awareness has to fun and exciting, not like work.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#using-virtual-machine","title":"Using Virtual Machine","text":"<p>If you isolate your virtual machine from your OS, you may get away even in the case of an attack.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#zero-day-vulnerability","title":"Zero Day Vulnerability","text":"<p>Zero day vulnerability is something that was not known before.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#phases-of-cyber-kill-chain","title":"Phases of Cyber Kill Chain","text":"<p>The earlier you detect, the better</p> <ul> <li> <p>Reconnaisance</p> </li> <li> <p>Observation</p> </li> <li> <p>Attacker identifies a target and explores vulnerabilities</p> </li> <li> <p>The one who knows their enemy more than themselves wins the war.</p> <pre><code>&gt; If you don\u2019t know how someone will attack you, then you can\u2019t protect yourself.\n</code></pre> </li> <li> <p>Learn to attack so you can defend yourself</p> </li> <li> <p>Weaponization</p> </li> <li> <p>Develop \u2018ammunition\u2019</p> </li> <li> <p>Create a payload/malware</p> </li> <li> <p>This is the only thing the defender has no control over, as it is in the attacker\u2019s hands</p> </li> <li> <p>Delivery</p> </li> <li> <p>Send the payload to the intended target</p> </li> <li> <p>Social Engineering</p> </li> <li> <p>Web Proxy helps protect users</p> </li> <li> <p>Exploitation</p> </li> <li> <p>Malicious explotaition is executed within the victim\u2019s system</p> </li> <li> <p>Reverse shell is a response to a shell</p> </li> <li> <p>Installation</p> </li> <li> <p>C&amp;C</p> </li> <li> <p>Command and Control of system resources</p> </li> <li> <p>Action &amp; Objectives</p> </li> </ul> <p>1 attacker and many victims leads to a bot(something)</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#cyber-threat-intelligence","title":"Cyber Threat Intelligence","text":"<p>The first phrase people say when something happens is \u2018failure of intelligence\u2019</p> <ul> <li>Strategy is long-term</li> <li>Tactics is short-term</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#fundamentals","title":"Fundamentals","text":"<ol> <li>Intel Planning/Strategy</li> <li>Data Collection &amp; Aggegration</li> <li>Threat Analytics</li> <li>Intel Uage &amp; Dissemination</li> </ol>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#dark-web","title":"Dark Web","text":"<ul> <li>Gives illusion of anonymity</li> <li>Gives you access to information</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#onion-network","title":"Onion Network","text":"<p>Be careful when using Tor</p> <p>Most Tor networks are actually the host of the network, so they are infact monitored.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#types-of-malware","title":"Types of Malware","text":"Type Meaning Backdoor Botnet Downloader Information-Stealing Scareware"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#dark-web-economy","title":"Dark Web Economy","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#incident-response","title":"Incident Response","text":"<pre><code>flowchart LR\np[Preparation] --&gt;\nIdentification --&gt;\nContainment --&gt;\nEradication --&gt;\nRecovery --&gt; \nl[Lessons Learnt] --&gt; p</code></pre>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#compliance-management","title":"Compliance Management","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#compliance-montoring","title":"Compliance Montoring","text":"<p>You need to know what to comply to.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#unified-compliance-framework","title":"Unified Compliance Framework","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#service-level-agreements","title":"Service Level Agreements","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#shell","title":"Shell","text":"<p>Communication tunnel between 2 computers?</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#types-of-ip","title":"Types of IP","text":"<p>The class of IP depends on the size of the organization</p> <ul> <li>Class A</li> <li>Class B</li> <li>Class C</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#skilled","title":"Skilled","text":"<p>Really skilled hackers won\u2019t even be known.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#miscelaneous","title":"Miscelaneous","text":"<p>Any field you are in, you should learn the terminologies.</p> <p>Never believe you know everything; keep learning</p> <p>Keep an open-mind always; don\u2019t go with a bank mindset to another field.</p> <p>Always see if you get importance in your organizations. But then again, if you do get importance, never let it get to your head.</p> <p>You may not certificates/acknowledgment, but don\u2019t let it get to your head.</p> <p>Success will won\u2019t teach much; only failure will teach</p> <p>The only time you can stop learning is \u201cwhen you\u2019re 6ft under\u201d</p> <p>You should be able to adapt to any situation.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#book-on-kingpin","title":"Book on Kingpin","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#impact","title":"Impact","text":"<p>The extent to which a risk event might affect the enterprise.</p> Asset Vulnerability Threat Security Controls Risk Possibilty that a threat will exploit a vulnerability, affecting asset"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#nist-cybersecurity-framework","title":"NIST Cybersecurity Framework","text":"<ul> <li>Identify</li> <li>Protect</li> <li>Detect</li> <li>Respond</li> <li>Recover</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#gdpr","title":"GDPR","text":"<p>General Data Protection Regulation</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#control","title":"Control","text":"<p>All risks should be evaluated, and a corresponding control measure should be used.</p> <p>We need effectiveness</p> <p>We cannot use 7 factor authentication </p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#control-designmeasure","title":"Control Design/Measure","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#control-operation","title":"Control Operation","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#risk-management","title":"Risk Management","text":"<ul> <li>Risk Tolerance</li> <li></li> <li>Risk Transfer</li> <li>Getting insurance after doing whatever you can do yourself</li> <li>Risk Mitigation</li> <li>Something</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#business-continuity","title":"Business Continuity","text":"<p>Ensures bare minimum services are provided in case of a business</p> <pre><code>flowchart LR\n\nsubgraph BCM Lifecycle\n    direction LR\n  pp[Policy &amp; Program] --&gt;\n  Analysis --&gt;\n  Design --&gt;\n  Implementation --&gt;\n  Validation --&gt;\n  e[Embedding Business Continuity] --&gt; pp\nend</code></pre>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#bia","title":"BIA","text":"<p>Business Impact Analysis</p> <p>Analyze what are your critical processes</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#idk","title":"IDK","text":"<ul> <li>It is not safe to swipe your credit card, as the magnetic stripe is not encrypted</li> <li>It is safer to either</li> <li>insert your card, and use the encrypted Electro-Magnetic chip</li> <li>or, tap it and use NFC</li> </ul> <p>Be careful about scams. A bank would never ask you for your credit card details.</p> <p>Keep updated with the latest news related to cyber-security</p> <p>There is high demand for cyber-security, but not enough supply to meet the demand.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#supply-chain-attack","title":"Supply-Chain Attack","text":"<p>Attack on backdoor (3<sup>rd</sup> Party Software dependency compromise)</p> <p>Solar Winds</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#log4j-jndi-attack","title":"log4j JNDI Attack","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#security-assessment","title":"Security Assessment","text":"<p>We need to test our tools before attackers do.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#ddos","title":"DDOS","text":"<p>A Denial-of-Service (DoS) attack is an attack meant to shut down a machine or network, making it inaccessible to its intended users. DoS attacks accomplish this by flooding the target with traffic, or sending it information that triggers a crash.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#half-flood-attack","title":"Half-Flood Attack","text":"<p>Uses TCP</p> <p>Evolution and </p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#evolution-app-infrastructrue","title":"Evolution App Infrastructrue","text":"<p>Mainframe</p> <p>Shared Responsibility</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#monilithic-vs-microservice-architecture","title":"Monilithic vs Microservice Architecture","text":"<p>Microservice is basically modular distributed computing, for each service/page of the product</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#watch-list","title":"Watch List","text":"<p>History repeats itself.</p> <p>Learn about history, and learn about what thought processes they used</p> <ul> <li> Pirates of the Silicon Valley</li> <li> Steve Jobs Autobiography</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#types-of-assessment","title":"Types of Assessment","text":"<ul> <li>Vulernaribility Assessment</li> <li>Penetration Testing</li> <li>Red Teaming</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#tools","title":"Tools","text":"<ul> <li>SATAN (Security Admin Tool for Analyzing Networks)</li> <li>NMAP</li> <li>Nessus Project</li> <li>Appscan</li> <li>Burp Suite</li> <li>Used for bug bounties</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#cve","title":"CVE","text":"<p>Maintained in the National Vulnerability Database</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#vulnerabilities-scanner-operation-models","title":"Vulnerabilities Scanner - Operation Models","text":"Scan Direction"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#types-of-vulnerability-scanner","title":"Types of Vulnerability Scanner","text":"<ul> <li>Signtature-Based</li> <li>Behavioural</li> </ul> <p>Something</p> <ul> <li>Static</li> <li>Dynamic</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#security-assessment-lifecycle","title":"Security Assessment Lifecycle","text":"<pre><code>flowchart LR\ni[Identify Scope] --&gt;\nf[Finalize&lt;br/&gt;Assesment Methology&lt;br/&gt;Tools Required] --&gt;\nr[Reporting]</code></pre>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#risk-rating-and-prioritization","title":"Risk Rating and Prioritization","text":"<p>NVD rates vulnerabilities</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#where-to-start","title":"Where to Start","text":"<p>NICE (National Initiative for Cybersecurity Education) Framework</p> <ul> <li>Employers</li> <li>Learners</li> <li>Something</li> </ul> <p>There are lists of required skills and knowledge</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#something","title":"Something","text":"<p>Data protection is needed to protect only for outgoing confidential data.</p> <ul> <li>It is not feasible to protect all data</li> </ul> <p>Importance/Confidentiality of data varies over time</p> <ul> <li>Exam questions are important for uni before exam</li> <li>After exam, it is not important</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#biggest-risks","title":"Biggest Risks","text":"<ul> <li>Human Errors</li> <li>Insider threats</li> <li>BYOD (Bring Your Own Device)</li> <li>Public Networks</li> <li>Especially in airports, where they harvest user data</li> <li>Even your user-id and password will go through the public access point</li> <li>Even https is not free from this risk</li> <li>Charging Ports</li> <li>Using a \u2018dumb intermediary\u2019 (such as power bank) prevents this</li> </ul> <p>Data Residency Law</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#data-protection-model","title":"Data Protection Model","text":"<pre><code>flowchart LR\ndd[Data&lt;br/&gt;Discovery] --&gt;\ndc[Data&lt;br/&gt;Classification] --&gt;\ndlp[Data&lt;br/&gt;Loss&lt;br/&gt;Prevention] --&gt;\ndp[Data&lt;br/&gt;Protection]</code></pre>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#dlp-architecture","title":"DLP Architecture","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#training-techniques","title":"Training Techniques","text":"<ul> <li>Provide data</li> <li>Exact data Matching</li> <li>Exact match data identifier</li> <li>Indexed document matching</li> <li>OCR</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#cloud-data-protection","title":"Cloud Data Protection","text":"<ul> <li>Intune</li> <li>O365 DLP</li> <li>Cloud Access Security Broker</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#aip-azure-information-protection","title":"AIP (Azure Information Protection)","text":"<p>Encryption travels with the file</p> <p>Used in Netflix Offline Saved</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#digital-rights-management","title":"Digital Rights Management","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#credit-card-pattern","title":"Credit Card Pattern","text":"<ul> <li>1: Credit Service Provider</li> <li>4 = Visa</li> <li>5 = Mastercard</li> <li>2-5: Bin Number</li> </ul> <p>IBAN number?</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#idk_1","title":"IDK","text":"<p>Never share your secrets with anyone; it will destroy you.</p> <p>Trust anyone; never trust the devil inside.</p> <p>\u201cIf you can't measure it, you can't manage it.\u201d If you don't measure, then how do you know how you are doing?</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#siem","title":"SIEM","text":"<p>Used for log monitoring</p> <p>Cannot simulate attacks</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#log","title":"Log","text":"<p>Historical record of an event</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#log-management","title":"Log Management","text":"<p>Approach to deal with large volumnes of computer-generated log messages.</p> <p>Open-source something Wazoo</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#why","title":"Why?","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#challenges","title":"Challenges","text":"<ul> <li>Variety of formats</li> <li>Large volume of data</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#load-balancing","title":"Load Balancing","text":"<p>Load Balancer manages the load that each collector receives</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#steps","title":"Steps","text":"<ol> <li>Log </li> <li>Incident</li> </ol>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#incident-response_1","title":"Incident Response","text":"<pre><code>flowchart LR\np[Preparation] --&gt;\nda[Detection &amp;&lt;br/&gt;Analysis] --&gt;\ncer[Containment,&lt;br/&gt;Eradication &amp;&lt;br/&gt;Recovery] --&gt;\npia[Post-Incident&lt;br/&gt;Activity] --&gt;\np\n\ncer --&gt; da</code></pre>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#database-activity-monitoring","title":"Database Activity Monitoring","text":"<p>Monitor the activities of database admins.</p> <p>For eg, if someone suddenly performs a <code>select</code> query of all tables</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#iam","title":"IAM","text":"<p>Identity Access &amp; Management</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#aaa-principles","title":"AAA Principles","text":"<ul> <li>Authentication</li> <li>Authorization</li> <li>Accountability/Auditing</li> <li>Authorized person has access to authorized resources only at authorized times</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#access-control-models","title":"Access Control Models","text":"<ul> <li>Discretionary Access Control</li> <li>Mandatory Access Control</li> <li>Rule-Based Access Control</li> <li>Attribute-Based Access Control</li> <li>Role-Based Control</li> <li>Most common in companies</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#identity-life-cycle-management","title":"Identity Life Cycle Management","text":""},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#segregation-of-duties","title":"Segregation of Duties","text":"<p>If both maker and checker are the same person,</p> <ul> <li>Possibility of frauds</li> <li>Possibility of human error</li> </ul>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#ui-path-rpa","title":"UI Path RPA","text":"<p>You\u2019ll get job tomorrow at First Abu Dhabi bank if you are RPA-certified</p> <p>CASSP, CSSP, CEH</p> <p>~ Senthilkumar</p> <p>Most important thing is surveillance and find out weaknesses.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#bridge-mode","title":"Bridge Mode","text":"<p>You can run a </p> <p>VM is paired to machine</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#nat-mode","title":"NAT Mode","text":"<p>VM is subset of machine</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#idk_2","title":"IDK","text":"<p>Go watch Chinese movies</p> <p>Snake in the Monkey\u2019s Shadow</p> <p>The world throws questions for which there are no answers. No point in memorizing stuffe</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#vuca","title":"VUCA","text":"<p>Volatile Uncertain Complex Ambiguous</p> <p>US Military Strategy</p> <ol> <li>nsetn</li> <li>Preachers preach change, but they never do</li> <li>Most people do not realize their prejudices when taking decisions</li> </ol> <p>When making a decision, first try to see if any problem is similar to past experience, or is it a new problem</p> <p>God, give me the courage to do what i can change, the something to , and the wisdom know the difference between both</p> <p>Insult is the better way to force someone to learn. Getting stones helps you build a castle.</p> <p>Fear is the greatest thing in life.</p> <p>Fear and Confidence, Pain and Pleasure are the 4 driving forces of life.</p> <p>You may treat people nicely, but doesn\u2019t mean they will treat you the same. Life isn\u2019t fair. You don\u2019t eat the lion doesn\u2019t mean that it won\u2019t eat you.</p> <p>Nowadays, students coming out of university are Unskilled Unemployable Something Resource. Industry wants Deployable Something Resource.</p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#supply-chain-risk","title":"Supply Chain Risk","text":"<p><code>node.js</code>, <code>faker.js</code></p>"},{"location":"CS_Electives/CyberSecurity/999_cybersecurity_workshop/#macos-is-not-fully-safe","title":"MacOS is not fully safe","text":"<p>It is based on Linux FreeBSD/BSD</p>"},{"location":"CS_Electives/CyberSecurity/Lab/","title":"Lab","text":""},{"location":"CS_Electives/CyberSecurity/Lab/#kali","title":"Kali","text":"<pre><code>ifconfig\n</code></pre> <pre><code>cat /etc/hosts\n</code></pre> <pre><code>ping kali\n</code></pre> <pre><code>ping google\nping www.google.ae\n</code></pre> <pre><code>64 bytes from any.in\n</code></pre> <pre><code>netstat -ano\n</code></pre> <pre><code>nmap 172.16.22.5\n</code></pre> <p>We can see what ports are open</p>"},{"location":"CS_Electives/CyberSecurity/Lab/#telnet-vs-sshsecure-shell","title":"Telnet vs SSH(Secure SHell)","text":"<p>Telnet(Port 23) is unencrypted and insecure, as all traffic occurs in cleartext.</p> <p>Block any service on Port 23 of the server.</p> <p>If you see that port 23 is being used</p> <pre><code>telnet 172.16.22.5\n</code></pre> <p>All traffic will be in plain text.</p> <pre><code>ssh 2020A7PS0198U@172.16.22.5\n</code></pre> <p>All traffic will be encrypted.</p>"},{"location":"CS_Electives/CyberSecurity/Lab/#wire-shark","title":"Wire Shark","text":"<p>You can analyze network. Click ethernet</p> <p>Understand what all nmap is doing</p> <pre><code>ip.addr==172.16.22.5\n</code></pre>"},{"location":"CS_Electives/CyberSecurity/Lab/#ip-address","title":"IP Address","text":"<p>Address for 2 computers to communicate with each other</p> <p>Public can </p> <p>Private can access another Private without </p> 10. Internal 172.16. Internal 172.168. Internal"},{"location":"CS_Electives/CyberSecurity/Lab/#dns","title":"DNS","text":"<p>Domain Naming Server</p> <p>Lookup of domain with the corresponding IP address $$ X. X. X \\ X \\in [0, 255] $$</p>"},{"location":"CS_Electives/CyberSecurity/Lab/#icmp","title":"ICMP","text":"<p>Internet Control Message Protocol</p>"},{"location":"CS_Electives/CyberSecurity/Lab/#automation-softwares","title":"Automation Softwares","text":"<pre><code>flowchart LR\n\n1 --&gt; 2 --&gt; 3\n\nsubgraph 1[Recon]\n    NMap\nend\n\nsubgraph 2[Vulnerability Identification]\n    Nessus\nend\n\nsubgraph 3[Exploitation]\n    Metasploit\n    CobaltStrike\n    BurpSuite\nend</code></pre>"},{"location":"CS_Electives/CyberSecurity/Lab/#advantages","title":"Advantages","text":"<ul> <li>Scalability</li> <li>Standardization</li> <li>Accuracy</li> <li>Reduced manual effort</li> </ul>"},{"location":"CS_Electives/CyberSecurity/Lab/#nessus","title":"Nessus","text":"<pre><code>curl --request G\n</code></pre> <pre><code>sudo apt install ./Nessus.deb\n</code></pre>"},{"location":"CS_Electives/CyberSecurity/Lab/#ngrok","title":"ngrok","text":"<p>This is like alias for wordpress localhosting</p>"},{"location":"CS_Electives/CyberSecurity/Lab/#idk","title":"IDK","text":"<pre><code>showmount -e 192.168.100.25\n\nmkdir /tmp/infosec ## not necessary\nmount -t nfs 192.168.100.25:/home /tmp/infosec\n</code></pre>"},{"location":"CS_Electives/Data_Engineering/","title":"Data Engineering","text":""},{"location":"CS_Electives/Data_Engineering/#references","title":"References","text":"<ul> <li> Designing Data Intensive applications<ul> <li> Kunal Cholera</li> <li> San Diego Machine Learning</li> </ul> </li> <li> Data Modelling | Kahan Data Solutions</li> <li> Certifications<ul> <li> Basic<ul> <li> AWS Serverless</li> <li> Cloud Data Engineering</li> <li> Scraping using python</li> </ul> </li> <li> Intermediate<ul> <li> Python Data Analysis | Data Engineering</li> <li> AWS Data Engineering</li> <li> Data Engineering with Python</li> <li> AWS Lambda<ul> <li> AWS Lambda Python</li> <li> https://www.udemy.com/course/aws-lambda-serverless-architecture/  serverless</li> </ul> </li> <li> dockers kubernetes</li> <li> AWS Data Speciality</li> <li> Data Engineering / ML GCP</li> <li> https://www.linkedin.com/learning/learning-docker-2018    Learn docker</li> <li> https://www.linkedin.com/learning/using-sql-with-python   SQL in python</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/","title":"Data Intensive Applications","text":"<p>Any of the following</p> <p>Any of the following generation/usage increases quickly: - Volume of data - Complexity of data - Speed of change in data</p>"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#pillars","title":"Pillars","text":"Pillar Properties Reliable Fault-toleranceNo authorized accessChaos TestingRobust to Full Machine FailuresBug-free, Automated bug testsEnvironments: Dev, Staging/Testing, ProdQuick roll-backs Scalable Handle high traffic volumeTraffic load with peak # of reads, writes, simultaneous usersCapacity planningResponse time vs throughputEnd user response time90<sup>th</sup>, 95<sup>th</sup> percentile SLO/A service level objectives/agreementsVertically-Scaling up (more powerful machine)Horizontally-Scaling out (distributed across smaller machines) Maintainable Add new people to workProductivityOperable: Configurable and testableSimple: easy to understand and ramp up, well-documentedEvolveable: easy to change"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#components","title":"Components","text":"Tools Databases Source of truth SQL Cache Temporary storage of expensive operation Memcache Full-text index Quickly searching data by keyword/filter ESIndexApache Lucener Message queues MEssaging passing passing between process Apache Kafka Stream Processing Apache SparkApache Samza Batch Processing Crunching last amount of data Apache SparkApache Hadoop Application code Connective tissue other components"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#databases","title":"Databases","text":"<p>Data Model - Relational model - Document-based model     - Not great for analytics - Graph model</p> <p>Aspects to keep in mind - Data storage - Data retrieval</p> <p>ID</p> <p>u K</p> OLTP OLAP Online Transaction Processing Database Online Analytical Processing Database Row-oriented Column-oriented Optimized for Writes Reads Flexibility High Low"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#structure","title":"Structure","text":"<ul> <li>Shallow dimension tables</li> <li>Dense fact tables</li> </ul>"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#pipeline","title":"Pipeline","text":"<ul> <li>ETL</li> <li>ELT</li> </ul>"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#code-compatibility","title":"Code Compatibility","text":"<ul> <li>Backward compatibility: Newer code can read data written by older code for old and new clients</li> <li>Forward Compatibility: Older code can read data written by newer code for old and new clients</li> </ul>"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#rolling-upgrades","title":"Rolling Upgrades","text":""},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#canary","title":"Canary","text":"<pre><code>flowchart TB\nut[User Traffic] --&gt;\nlb[Load Balancer]\n\nlb --&gt; mu[Most Users] --&gt; cv1[Code Version 1]\nlb --&gt; fu[Few Users] --&gt; cv2[Code Version 2]</code></pre>"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#replication","title":"Replication","text":"<ul> <li>Machine failures</li> <li>Latency for global audience</li> <li>Scale to large userbase</li> <li>Offline/network failures</li> </ul> <p>Types - Leader-Replica     - Writes go to leader     - Reads may/may not go to leader     - Reads go to replica - Multileader-Replica - Leaderless     - Write to all replicas     - Read from all replicas     - Eg: Amazon Dynamo, Voldemort, Cassandra</p> <p>Aspects to consider - Synchronous vs Asynchronous replication - Replication lag - Topology - Durability vs availability vs latency - Leader Failover - Conflict resolution between leaders</p>"},{"location":"CS_Electives/Data_Engineering/01_Data_Intensive_Applications/#database-partitioning","title":"Database Partitioning","text":"<p>Sharding/Splitting/Horizontal Scaling</p>"},{"location":"CS_Electives/Data_Mining/","title":"Data Mining","text":"<p>This course covers the concepts regarding Data Analysis.</p>"},{"location":"CS_Electives/Data_Mining/#why-data-mining","title":"Why Data Mining","text":"<ol> <li>Scalability</li> <li>Handling high-dimensional data</li> <li>Complex &amp; Heterogeneous Data</li> <li>Handling Poor Quality Data</li> <li>Data ownership and Distribution</li> </ol>"},{"location":"CS_Electives/Data_Mining/#applications-of-this-course","title":"Applications of this course","text":"<p>To fill in areas where traditional data analysis methods cannot be applied</p> <ul> <li>Optimize business operations</li> <li>Understand customers</li> <li>Computer-Aided Diagnosis</li> <li>Image<ul> <li>Segmentation</li> <li>Captioning</li> </ul> </li> <li>Object Detection</li> </ul>"},{"location":"CS_Electives/Data_Mining/#sources","title":"Sources","text":"<p>Kaggle, UCI ML repository</p>"},{"location":"CS_Electives/Data_Mining/#references","title":"References","text":"<ul> <li> Data Mining | Dr. Angel Arul Jothi</li> <li> From Data to Decisions: Measurement, Uncertainty, Analysis and Modeling | Chris Mack | University of Texas</li> <li> How to write a good scientific paper | Chris Mack | University of Texas</li> <li> Statistics literacy for non-statisticians | Mike x Cohen</li> <li> Big Data Analytics | Caltech</li> <li> MIT 14.310x Data Analysis for Social Scientists, Spring 2023</li> <li> IIT Roorkee July 2018 | Data Analytics with Python</li> <li> ORIE 5355 -- People, Data, Systems -- Fall 2021 -- Cornell Tech</li> <li> Mining Massive Datasets | Stanford University</li> <li> Quantitative Social Science Methods | Harvard</li> <li> Data Mining | University of Utah</li> <li> Visualization for Data Science | University of Utah</li> <li> Winter 2017, STAT 442 / 842 Data Visualization</li> <li> Data Visualization | IIT Madras</li> <li> Introduction to Bigdata | IIT Madras</li> <li> Empirical Methods CMU</li> <li> Fall 2022</li> <li> Spring 2021</li> <li> Introduction to Data Analysis, Design of Experiment, and Machine Learning | Ashraf Alam | Purdue University</li> <li> Data Analytics | Gary Holness | Clark University</li> <li> Intro to Data Science | Gary Holness | Clark University</li> <li> Statistical Research Methods | Mikko R\u00f6nkk\u00f6</li> <li> Data Visualization | Andrew Heiss | Georgia State University</li> <li> Data Pipelines for ML | Shaw Talebi</li> <li> Data Confidentiality | Jingchen Monika Hu</li> <li> Simulations &amp; Generating Synthetic Datasets | Aileen Nielsen</li> <li> Grammar of Graphics | Ben Lambert</li> <li> Analysis of Categorical Data | Chris Bilder</li> <li> Applied Multivariate Statistical Analysis | Chris Bilder</li> <li> Information Design: Data Visualization | San Francisco State University</li> <li> Data Visualization | Tamara Munzner</li> <li> Calling Bullshxt in the Age of Big Data</li> <li> Data Visualization | Brian Urlacher</li> <li> Intelligence Analysis | Brian Urlacher</li> <li> Data Mining | MarinStatLectures</li> <li> Quantitative Social Science Methods, I (Gov2001 at Harvard University)</li> <li> Research Methodology | MeanThat</li> <li> Research Methodology for Business | MeanThat</li> <li> Research Methodology | Brian Urlacher</li> <li> Applied Data Analysis and Statistical Inference | Quantitative Analysis Institute</li> <li> Data Analysis &amp; Decision Making | IITK<ul> <li> Part 1</li> <li> Part 2</li> <li> Part 3</li> </ul> </li> <li> Effective Data Science | Zak Varty</li> <li> Introduction to Data Science | Mine \u00c7etinkaya-Rundel | University of Edinburgh</li> <li> Statistical Methods for Life History Analysis</li> <li> Linear Regression and Process Control | University of Waterloo</li> <li> Data Analysis &amp; Decision Making | IITK</li> <li> Data Science for Everyone | Takuma Organizational &amp; Data Analytics</li> <li> Predictive Analytics | Takuma Organizational &amp; Data Analytics</li> <li> Earth 125 (Stats and data analysis) | Matthew E. Clapham  University of California, Santa Cruz</li> <li> Business Intelligence &amp; Analytics | IITM</li> <li> Business Analytics | IITM</li> <li> Business Analytics for Management Decision | IITM</li> <li> Intermediate Biostats for Public Health | University of Berkeley Public Health</li> <li> Computational Social Science | Patrick Kraft</li> <li> Techniques of Political Science Research | Patrick Kraft</li> <li> Advanced Techniques of Political Science Research | Patrick Kraft</li> <li> Data fallacies/Statistical fallacies | Dr Rock Britto</li> <li> Data Mining | Brian Zaharatos</li> <li> Data Storytelling | Heather Krause</li> <li> Data analysis in Physics | Erik Rosolowsky</li> <li> Data Mining | University of Utah</li> <li> Open Education Lab<ul> <li> Data Scientist's Toolbox</li> <li> Getting and Cleaning Data</li> <li> Exploratory Data Analysis</li> <li> Statistical Inference</li> <li> Regression Models</li> <li> Practical Machine Learning</li> <li> Reproducible Research</li> </ul> </li> <li> Data Visualization<ul> <li> Data Visualization | Baryon Design</li> <li> Data Communication and Visualization | Amelia McNamara</li> <li> Data Visualization | IIT Madras</li> <li> Data Visualisation | yuzaR Data Science</li> <li> Visualization for Data Science | University of Utah</li> </ul> </li> <li> A/B Testing<ul> <li> A/B Testing in Data Science Interviews by a Google Data Scientist | DataInterview</li> <li> A/B Testing Course | Data36 - Online Data Science Courses</li> <li> Crash Course in A/B Testing with Case Study | Tatev Karen Aslanyan | freeCodeCamp.org</li> </ul> </li> <li> Certifications<ul> <li> Basics<ul> <li> Data Visualization with Tableau</li> <li> Google Data Analytics</li> <li> Introduction to Data Analytics</li> <li> Excel Skills for Data Analytics</li> <li> Excel Basics for Data Analysis</li> <li> Exploratory Data Analysis With Python and Pandas</li> <li> Introduction to Statistics</li> </ul> </li> <li> Intermediate<ul> <li> Business Analytics</li> <li> Business intelligence and data analytics: Generate insights</li> <li> Ask Questions to Make Data-Driven Decisions</li> </ul> </li> <li> Advanced<ul> <li> Advanced Business Analytics</li> <li> Analytics for Decision Making</li> <li> UPenn Business Analytics Specialization<ul> <li> Operations Analytics</li> <li> People Analytics</li> <li> Accounting Analytics</li> <li> Customer Analytics</li> <li> Business Analytics Capstone</li> </ul> </li> </ul> </li> </ul> </li> <li> Blogs<ul> <li> Andrey Akinshin</li> </ul> </li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/","title":"Introduction","text":"<p>Data science is turning raw data into understanding, insight, and knowledge to drive data-driven decisions and solve problems - Collecting data - Analyzing data     - Statistics     - Machine learning     - Deep learning - Communicating analysis</p> <p>We cannot move away from domain knowledge and solely depend on algorithms</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#stages","title":"Stages","text":"<ol> <li>Theory</li> <li>\u2060Simulation</li> <li>\u2060Empirical</li> </ol> <p>Order should not be changed, as otherwise we can make up the story as we wish</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#idk","title":"IDK","text":"<p>Always use GUIs for exploration - ease - \u2060rapid iteration Use code to finalize - reproducibility - \u2060automation</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#data-professionals","title":"Data Professionals","text":""},{"location":"CS_Electives/Data_Mining/01_Intro/#decision-making","title":"Decision-Making","text":"<p>Iterative process with feedback loops; not linear</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#knowledge-hierarchy","title":"Knowledge Hierarchy","text":"<p>Chain of increasing value</p> <pre><code>flowchart LR\nData --&gt;\nInformation --&gt;\nKnowledge --&gt;\nDecision</code></pre> Data Collection of numbers with known context and uncertainty estimates Information Right data at right time in right context, organized for access Knowledge Interpretation of information based on model (understanding) of cause and effect Decision Acting on knowledge for benefit"},{"location":"CS_Electives/Data_Mining/01_Intro/#process","title":"Process","text":"<ul> <li>Preparation: Plan to turn data into information, with a specific model and decision in mind</li> <li>Testing/Experimenting/Measurement</li> <li>Analysis, with uncertainty: Use model to turn information to knowledge</li> <li>Decision</li> <li>Using uncertainty</li> <li>Risk/benefit analysis</li> <li>Post-mortem: Learnings to improve things</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#notes","title":"Notes","text":"<ul> <li>All models are wrong, some are useful</li> <li>Applying data mining algorithms on data that you don\u2019t understand may result in false conclusions</li> <li>Always keep track of performed tests &amp; analyses, to factor in data snooping</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#questions","title":"Questions","text":"Question Why Precise (not vague)Bad:- Planning- Decision-makingGood- What plans/decisions- How are these plans/decisions made- How would data mining help What Goal, Level of aggregation, Forecast horizonBad- Sales- Market shareGood- Demand When FrequencyTime of day/year Who Human judgementComputer-generated with human judgementComputer-generatedConsiderations- Number &amp; frequency of predictions- Availability of historical data- Relative accuracy of options Where Predictions originate in different departments How"},{"location":"CS_Electives/Data_Mining/01_Intro/#fields-overview","title":"Fields Overview","text":"Analytics AI/ML Statistical Inference Goal Descriptive Predictive Prescriptive Decisions Large scale repetitive(with uncertainty) Small scale(with uncertainty)"},{"location":"CS_Electives/Data_Mining/01_Intro/#objectives","title":"Objectives","text":"Objective Prediction Estimation of unseen data Modelling/Characterization/Inference How do inputs affect outputObtain the Sample CEF/Conditional Distribution which closely matches the Population CEF/Conditional Distribution Optimization What input values produce desired outputs (both mean and variance) Control How to adjust controlled inputs to maximize control of outputs Simulation Causal Inference How does using treatment affect output <p>Use ML models to discover structural models, and then let the structural models to make the predictions, not the ML models</p> <ul> <li>Why: Black swans can be predicted by theory, even if they cannot be predicted by ML</li> <li>How: Use a non-parametric ML to identify important variables and then develop a parametric structural form model.</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#types-of-analysis","title":"Types of Analysis","text":"Type Topic Nature Time Comment Examples Explorative What could be happening Objective Past Hypothesis testing Explorations of correlations Descriptive/Positive What is happening? Objective Past No emotions/explanations if good or bad Increasing taxes will lower consumer spendingIncreasing interest rate will lower demand for loansRaising minimum wage will increase unemployment Normative Is this good or bad? Subjective Past \"Current inflation is higher than desirable\" Diagnostic Why is it happening? Objective/Subjective Past Helps in understanding root causeDecompose into internal &amp; external factors Inferential What can be concluded about a target population using sample data Objective/Subjective Past What generalizations or relationships can we draw from the data? Estimating average income for a country based on a survey sampleMaking inferences about consumer preferences from a focus group Predictive What will happen if condition happens Subjective Future Estimating future, using history Inflation will go up Prescriptive What to do Subjective Future what actions to be taken Taxes must be increased <p>The complexity increases as we go down the above list, but the value obtained increases as well</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#project-lifecycle","title":"Project Lifecycle","text":"<pre><code>flowchart TB\n\nsubgraph Scoping\n    dp[Define&lt;br/&gt;Project] --&gt;\n    me[\"Define Metrics&lt;br/&gt;(Accuracy, Recall)\"] --&gt;\n    re[Resources&lt;br/&gt;Budget] --&gt;\n    ba[\"Establish&lt;br /&gt;Baseline\"]\nend\n\nsubgraph Data\n    d[(Data Source)] --&gt;\n    l[Label &amp;&lt;br /&gt;Organize Data]\nend\n\nsubgraph Modelling\n  pre[Preprocessing] --&gt;\n    s[Modelling] --&gt;\n    train[Training] --&gt;\n  pp[Post&lt;br /&gt;Processing] --&gt;\n    vt[Validation &amp;&lt;br /&gt;Testing] --&gt;\n    e[Error Analysis] --&gt;\n    pre\nend\n\nsubgraph Deploy\n    dep[Deploy in&lt;br /&gt;Production] --&gt;\n    m[Monitor &amp;&lt;br /&gt;Maintain] &amp; dss[Decision&lt;br /&gt;Support System]\nend\n\nScoping --&gt; Data --&gt; Modelling --&gt; Deploy</code></pre> <p>https://www.youtube.com/watch?v=UyEtTyeahus&amp;list=PLkDaE6sCZn6GMoA0wbpJLi3t34Gd8l0aK&amp;index=5</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#data-mining","title":"Data Mining","text":"<p>Generate Decision Support Systems</p> <p>Non-trivial extraction of implicit, previously-unknown and potentially useful information from data</p> <p>Automatic/Semi-automatic means of discovering meaningful patterns from large quantities of data</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#predictive-tasks","title":"Predictive Tasks","text":"<p>Predict value of target/independent variable using values of independent variables</p> <ul> <li>Regression - Continuous</li> <li>Classification - Discrete</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#descriptive-tasks","title":"Descriptive Tasks","text":"<p>Goal is to find</p> <ul> <li>Patterns</li> <li>Associations/Relationships</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#association-analysis","title":"Association Analysis","text":"<p>Find hidden assocations and patterns, using association rules</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#applications","title":"Applications","text":"<ul> <li>Gene Discovery</li> <li>Market Baset Data Analysis   Find items that are bought together</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#clusteringcluster-analysis","title":"Clustering/Cluster Analysis","text":"<p>Grouping similar customers</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#metrics","title":"Metrics","text":"<ul> <li>Similarity</li> <li>Dissimilarity/Distance Metrics</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#applications_1","title":"Applications","text":"<ul> <li> <p>Grouping similar documents</p> </li> <li> <p>Clustering documents</p> </li> <li> <p>Vocabulary - All terms(key words) from all docs</p> </li> <li> <p>Generate document-term frequency matrix</p> Document \\vert  Term T1 T2 \u2026 Tn D1 D2 \u2026 Dm </li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#deviationoutlieranomaly-detection","title":"Deviation/Outlier/Anomaly Detection","text":"<p>Outlier is a data point that does not follow the norms.</p> <p>Don\u2019t mistake outlier for noise.</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#application","title":"Application","text":"<ul> <li> <p>Credit Card Fraud Detection</p> <ul> <li>Collect user profile such as Name, Age, Location</li> <li>Collect user behavior data</li> </ul> </li> <li> <p>Network Intrusion Detection</p> </li> <li>Identify anomalous behavior from surveillance camera videos</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#misconceptions","title":"Misconceptions","text":"<ul> <li>All forecasts will be inaccurate, so no point</li> <li>If we had the latest forecasting technology, all problems would be solved</li> </ul>"},{"location":"CS_Electives/Data_Mining/01_Intro/#idk_1","title":"IDK","text":"<p>Ensure you are looking at the correct scale</p> <p>Model \\(y_t/y_0\\) instead of \\(y_t\\) to standardize all time series</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#common-problems-with-analysis","title":"Common problems with analysis","text":"<ul> <li>Poorly-defined goals</li> <li>Data doesn\u2019t meet needs of analysis objectives</li> <li>Analysis makes unwarranted assumptions</li> <li>Model is wong</li> <li>Data doesn\u2019t support conclusion</li> </ul> <p>Learning Process</p> <ol> <li>Model building: Functional form</li> <li>Identify parameter weights</li> <li>Distribution of random errors</li> </ol> <p>Each of them can have different levels of generalizability</p> <p>For eg: Ohm\u2019s Law</p> <ol> <li>\\(V=IR\\) remains constant for all materials (under certain conditions)</li> <li>\\(R\\) Changes for different materials</li> <li>Errors are dependent on measurement and experimental methods, and are independent of materials</li> </ol>"},{"location":"CS_Electives/Data_Mining/01_Intro/#communication-of-results","title":"Communication of Results","text":"<p>Storytelling is important</p>"},{"location":"CS_Electives/Data_Mining/01_Intro/#pitfalls","title":"Pitfalls","text":"<ul> <li>Manipulation<ul> <li>Don't lie</li> <li>Emphasize the story, but make the full data available</li> </ul> </li> <li>Misrepresentation<ul> <li>Control expectations</li> <li>Exaggerate your work, but do not over-exaggerate</li> </ul> </li> <li>Ethos<ul> <li>Ethos \\(\\ne\\) Credentials</li> <li>Credentials do not make an expert</li> <li>Credentials do not not make an expert</li> </ul> </li> <li>Equity<ul> <li>Don't dumb down: Just translate in a simpler way</li> <li>Amplify underrepresented voices</li> </ul> </li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/","title":"Data","text":"<p>Data can be anything. It depends on the data engineer on what the input and output data is</p> <p>Data = results of measurement</p> <ul> <li>Definition of measurand (quantity being measured)</li> <li>Measurement value</li> <li>number</li> <li> <p>unit</p> </li> <li> <p>Experimental context</p> </li> <li>Test method</li> <li>sampling technique</li> <li> <p>environment</p> </li> <li> <p>Estimate of uncertainty</p> </li> <li>Measurement uncertainty: estimate of dispersion of measurement values around true value</li> <li>Context uncertainty: uncertainty of controlled and uncontrolled input parameters</li> <li>Metrology/Measurement model: science of measurement; theory, assumptions and definitions used in making measurement</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#types","title":"Types","text":"<ul> <li>Structured</li> <li>Numbers</li> <li>Tables </li> <li>Unstructured</li> <li>Audio</li> <li>Image</li> <li>Video</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#datasets","title":"Datasets","text":"<p>Collection of data in rows and columns</p> <ul> <li>Rows = Objects, Records, Samples, Instances</li> <li>Columns = Attributes, Variables, Dimensions, Features</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#types_1","title":"Types","text":"<ul> <li>Labelled has Target variable</li> <li>Unlabelled does not have target variable</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#data-collection","title":"Data Collection","text":""},{"location":"CS_Electives/Data_Mining/02_Data/#stages","title":"Stages","text":"<ul> <li>Motivation</li> <li>Composition</li> <li>Collection process</li> <li>Labelling</li> <li>Preprocessing</li> <li>Uses</li> <li>Distribution</li> <li>Maintenance</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#metadata","title":"Metadata","text":"Aspect Filename Format csv URL Domain healthcare Keywords medicine, drugs Type tabular Rows 500 Columns 18 Missing % 5.2% License MIT Release Date Jan 2024 Time range: FROM Aug 2020 Time range: TO Dec 2020 Description ### Means of data collection <p>Garbage-in, Garbage-out</p> <ul> <li>Manual Labelling</li> <li>Manually marking as cat/not cat, etc.</li> <li>Observing Behaviour</li> <li>taking data from user activity and seeing whether they purchased or not</li> <li>machine temperatures and observing for faults or not</li> <li>Download from the web</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#mistakes","title":"Mistakes","text":"<ol> <li>Waiting too long for implementing a data set</li> <li>implement it early so that AI team can give feedback to the IT team</li> <li>Not all data is valuable</li> <li>Messy</li> <li>Garbage in, garbage out</li> <li>incorrect data</li> <li>multiple types of data</li> </ol>"},{"location":"CS_Electives/Data_Mining/02_Data/#types-of-attributes","title":"Types of Attributes","text":"Nominal Ordinal Interval Ratio Order \u2705 \u2705 \u2705 Magnitude \u2705 \u2705 Absolute Zero \u2705 Mode \u2705 \u2705 \u2705 \u2705 \\(=\\) \u2705 \u2705 \u2705 \u2705 \\(&gt;, \\ge, &lt;, \\le\\) \u2705 \u2705 \u2705 \\(-, +\\) \u2705 \u2705 \\(/, \\times\\) \u2705 Type D D N N Median \u2705 \u2705 \u2705 Mean \u2705 \u2705 Min/Max \u2705 \u2705 t-Test \u2705 Example - Colors - Player Jersey #- Gender- Eye color- Employee ID - Ratings- Course Grades - Finishing positions in a race; 4star is not necessarily twice as good as 2 star - Temperature units - 100C &gt; 50C &gt; 0C; 0C, 0F doesn't mean no temperature; 50C isn't \\(\\frac{1}{2}\\) of 100C - pH scale - Age- Kelvin - 0K is absolute absence of heat; 50K = half of 100K - Number of children <ul> <li>D = Discrete/Qualitative/Categorical</li> <li>N = Numerical/Quantitative/Continuous</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#asymmetric-attributes","title":"Asymmetric Attributes","text":"<p>Attributes where only non-zero values are important. It can be</p> <ul> <li>Binary (0 or 1)</li> <li>Discrete (0, 1, 2, 3, \u2026)</li> <li>Continuous (0, 33.35, 52.99, \u2026)</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#characteristics-of-dataset","title":"Characteristics of Dataset","text":""},{"location":"CS_Electives/Data_Mining/02_Data/#minimum-sample-size","title":"Minimum Sample Size","text":"<p>To learn effectively</p> \\(n_\\text{min}\\) Structured: Tabular \\(k+1\\) Unstructured: Image \\(1000 \\times C\\) <p>where</p> <ul> <li>\\(n =\\) no of sample points</li> <li>\\(k =\\) no of input variables</li> <li>\\(C =\\) no of classes</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#dimensionality","title":"Dimensionality","text":"<p>No of features</p>"},{"location":"CS_Electives/Data_Mining/02_Data/#sparseness","title":"Sparseness","text":"<p>If majority of attributes have 0 as value, depending on the context</p>"},{"location":"CS_Electives/Data_Mining/02_Data/#resolution","title":"Resolution","text":"<p>Detail/Frequency of the data (hourly, daily, monthly, etc)</p>"},{"location":"CS_Electives/Data_Mining/02_Data/#types-of-datasets","title":"Types of Datasets","text":""},{"location":"CS_Electives/Data_Mining/02_Data/#records","title":"Records","text":"<p>Collection of records having fixed attributes, without any relationship with other records</p> Type Characteristic Example Data Matrix All attributes are numerical Usually what we have Sparse Data Matrix Majority of values are 0 - Frequency distribution kinda thingy for market basket data- Document term matrix Market Basket Data Every record of transactions, with collection of items - Association analysis market data"},{"location":"CS_Electives/Data_Mining/02_Data/#graph","title":"Graph","text":"Type Example Data objects with relationships Nodes(data objects) with edges (relationships) between them Google Search indexing Data objects that are graphs Chemical structures"},{"location":"CS_Electives/Data_Mining/02_Data/#ordered","title":"Ordered","text":"<p>Relationships between attributes</p>"},{"location":"CS_Electives/Data_Mining/02_Data/#sequentialtemporal","title":"Sequential/Temporal","text":"<p>Extension of record, where each record has a time associated with it.</p> <p>Even this can be time series data, if recorded periodically.</p> Time Customer Items Purchased t1 c1 A, B t2 c2 A, C"},{"location":"CS_Electives/Data_Mining/02_Data/#time-associated","title":"Time-Associated","text":"Customer Time and Items Purchased C1 \\(\\{t1, (A, B) \\}, \\{t2, (A, C) \\}\\) C2 \\(\\{t1, (B, C) \\}, \\{t2, (A, C) \\}\\)"},{"location":"CS_Electives/Data_Mining/02_Data/#sequence-data","title":"Sequence Data","text":"<p>Sequence of entities</p> <p>Eg: Genomic sequence data</p>"},{"location":"CS_Electives/Data_Mining/02_Data/#time-series-data","title":"Time Series Data","text":"<p>Series of observations over time recorded periodically</p> <p>Each record is a time series as well.</p> 12AM 6AM 12PM 6PM June 11 2020 June 12 2020 June 13 2020 June 14 2020"},{"location":"CS_Electives/Data_Mining/02_Data/#spatial-data","title":"Spatial Data","text":"<p>Data has spatial attributes, such as positions/areas</p> <p>Weather data collected for various locations</p>"},{"location":"CS_Electives/Data_Mining/02_Data/#spatio-temporal-data","title":"Spatio-Temporal Data","text":"<p>Data has both spatial and temporal attributes</p> Abu Dhabi Dubai Sharjah Ajman UAQ RAK Fujeirah June 11 2020 June 12 2020 June 13 2020 June 14 2020"},{"location":"CS_Electives/Data_Mining/02_Data/#issues-with-data-quality","title":"Issues with Data Quality","text":"Issue Solution is to ___ data object/attributes Example Improper sampling Unknown context Noise - Random component of measurement- Distorts the data Drop Anomaly/Rare events Obs that occur very rarely but it is possible Height of Person is 7\u20195 Artifacts/Spurious Obs Known Distortion that can be removed Height of Person is -10 Outliers/Flyers/Wild obs/Maverick Actual data, but very different from othersExtreme value of \\(y\\) Depends Height of Person is 8\u20195 Leveraged points Extreme value of \\(x\\) Influential points Outliers with high leverageRemoving the data point \u2018substantially\u2019 changes the regression results Missing Values Null values - Eliminate- Estimate/Interpolate- Ignore Inconsistent Data illogical data 50yr old with 5kg weight Duplicate Data De-Duplication - Same customer goes to multiple showrooms"},{"location":"CS_Electives/Data_Mining/02_Data/#estimation","title":"Estimation","text":"Attribute Type Interpolation Value Example Discrete Mode Grade Continuous Mean/Median(depending on the situation) Marks"},{"location":"CS_Electives/Data_Mining/02_Data/#data_1","title":"Data","text":"<p>Data can be structured/unstructured</p> <ul> <li>Each column = feature</li> <li>Each row = instance</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#data-split","title":"Data Split","text":"<ul> <li>Train-Inner Validation-Outer Validation-Test is usually 60:10:10:20</li> <li>Split should be mutually-exclusive, to ensure good out-of-sample accuracy</li> </ul> <p>The size of test set is important; small test set implies statistical uncertainty around the estimated average test error, and hence cannot claim algo A is better than algo B for given task.</p> <p>Random split is the best. However, random split will not work well all the time, where there is auto-correlation, for eg: time-series data</p> <pre><code>flowchart LR\n\ntd[(Training Data)] --&gt;\n|Training| m[Model] --&gt;\n|Validation| vd[(Validation)] --&gt;\n|Tuning| m ---&gt;\n|Testing| testing[(Testing Data)]</code></pre>"},{"location":"CS_Electives/Data_Mining/02_Data/#multi-dimensional-data","title":"Multi-Dimensional Data","text":"<p>can be hard to work with as</p> <ul> <li>requires more computing power</li> <li>harder to interpret</li> <li>harder to visualize</li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#feature-selection","title":"Feature Selection","text":""},{"location":"CS_Electives/Data_Mining/02_Data/#dimension-reduction","title":"Dimension Reduction","text":"<p>Using Principal Component Analysis</p> <p>Deriving simplified features from existing features</p> <p>Easy example: using area instead of length and breadth.</p>"},{"location":"CS_Electives/Data_Mining/02_Data/#categories-of-data","title":"Categories of Data","text":"Mediocristan Extremistan Each observation has low effect on summary statistics \u2705 \u274c Example IQ, Weight, Height, Calories, Test Scores Wealth, Sales, Populations, Pandemics Law of Large Numbers Requires more samples for approaching the true mean Mean is meaningless Regression does not work\\(R^2\\) reduces with larger sample sizes Payoffs diverge from probabilitiesIt\u2019s not just about how often you are right, but also what happens when you\u2019re wrong: Being wrong 1 time can erase the gain of being right 99 times"},{"location":"CS_Electives/Data_Mining/02_Data/#fat-tailedness","title":"\u201cFat-Tailedness\u201d","text":"<p>Degree to which rare events drive the aggregate statistics of a distribution</p> <ul> <li>Lower \\(\\alpha \\implies\\) Fatter tails</li> <li></li> <li>Kurtosis (breaks down for \\(\\alpha \\le 4\\))</li> <li>Variance of Log-Normal distribution</li> <li></li> <li>Taleb\u2019s \\(\\kappa\\) metric</li> <li></li> </ul>"},{"location":"CS_Electives/Data_Mining/02_Data/#leverage","title":"Leverage","text":"<p>Leverage points = data points with extreme value of input variable(s)</p> <p>Like outliers, high leverage data points can have outsize influence on learning</p> \\[ \\begin{aligned} h_{ii} &amp;= \\dfrac{\\text{cov}(\\hat y_i, y_i)}{\\text{var}(y_i)} &amp; h_{ii} &amp;\\in [0, 1] \\\\ \\sum h_{ii} &amp;= k \\implies \\bar h = p/n \\end{aligned} \\] Case \\(h_{ii}\\) Univariate \\(\\dfrac{1}{n} + \\dfrac{1}{n-1} \\left( \\dfrac{x_i - \\bar x}{s_x} \\right)^2\\) Multivariate \\(\\Bigg( X_\\text{out} (X_\\text{in}^T W X_\\text{in})^{-1} X_\\text{in}^T W \\Bigg)_{ii}\\) \\[ \\begin{aligned} \\hat y_\\text{out} &amp;= \\hat \\beta \\cdot X_\\text{out} \\\\ &amp;= (X_\\text{in}^T W X_\\text{in})^{-1} X_\\text{in}^T W y_\\text{in} \\cdot X_\\text{out} \\\\ &amp;= \\underbrace{X_\\text{out} (X_\\text{in}^T X_\\text{in})^{-1} X_\\text{in}^T W}_{H} \\cdot y_\\text{in} \\\\ \\implies \\hat y_\\text{out} &amp;= H \\cdot y_\\text{in} \\end{aligned} \\] <p></p> <p>High leverage points have lower variance</p> <p>$$ \\text{var}(u_i) = \\sigma^2_u (1-h_{ii}) \\ \\text{SE}(u_i) = \\text{RMSE} \\sqrt{1-h_{ii}} $$ </p> <p>Hence, when doing statistical tests on residuals (Grubbs\u2019 test, skewness, etc.) you should only use externally-studentized residuals </p> Internally Externally Data all data are included in the calculation \\(i\\)th data point is excluded from calculation of \\(\\text{RMSE}\\) Formula \\(\\text{isr}_i = \\dfrac{u_i}{\\text{SE}(u_i)} \\\\ = \\dfrac{u_i}{\\text{RMSE} \\sqrt{1-h_{ii}}}\\) \\(\\text{esr}_i = \\text{isr}_i \\sqrt{\\dfrac{n-p-1}{n-p- (\\text{isr}_i)^2}}\\) Distribution Complicated \\(t\\) distributed with DOF=\\(n-p-1\\) for \\(u \\in N(0, \\sigma_u)\\)"},{"location":"CS_Electives/Data_Mining/02_Data/#normalized-leverage","title":"Normalized Leverage","text":"\\[ \\begin{aligned} h_\\text{norm} &amp;= \\dfrac{h_{ii}}{\\bar h} \\\\ &amp;= h_{ii} \\times \\dfrac{n}{p} \\\\ \\end{aligned} \\]"},{"location":"CS_Electives/Data_Mining/02_Data/#williams-graph","title":"William\u2019s Graph","text":"<p>To inspect for both outliers and high-leverage data, plot the ESR vs Normalized Leverage</p> <p></p>"},{"location":"CS_Electives/Data_Mining/02_Data/#influence","title":"Influence","text":"<p>They are of concern, due to fragility of conclusions: our conclusions may depend only on a few influential data points</p> <p>We just identify influential points: We don\u2019t remove/adjust highly influential points</p> <p>\\(\\hat y_{j(i)}\\) is \\(\\hat y_j\\) without \\(i\\) in the training set</p> Formula Criterion\\(n \\le 20\\)\\(n &gt; 20\\) Cook\u2019s Distance \\(\\begin{aligned} &amp; D_i \\\\ &amp; = \\dfrac{\\sum\\limits_{j=1}^n (\\hat y_{j (i)} - \\hat y_j)}{k \\times \\text{MSE}} \\\\ &amp;= \\dfrac{u_i^2}{k \\times \\text{MSE}} \\times \\dfrac{h_{ii}}{(1-h_{ii})^2} \\\\ &amp;= \\dfrac{\\text{isr}_i^2}{k} \\times \\dfrac{h_{ii}}{(1-h_{ii})} \\end{aligned}\\) \\(1\\)\\(4/n \\quad \\approx F(k, n-k)\\).inv(0.5) Difference in Beta \\(\\begin{aligned} &amp; \\text{DFBETA}_{i, j} \\\\ &amp;= \\dfrac{\\beta_j - \\beta_{j(i)}}{\\text{SE}(\\beta_{k(i)})} \\end{aligned}\\) \\(1\\)\\(\\sqrt{4/n}\\) Difference in Fit \\(\\begin{aligned} &amp;\\text{DFFITS}_{i} \\\\ &amp;= \\dfrac{ \\hat y - \\hat y_{i(i)} }{ s_{u(i)} \\sqrt{h_{ii}} } \\\\ &amp;= \\text{esr}_i \\sqrt{ \\dfrac{h_{ii}}{1-h_{ii}} } \\end{aligned}\\) \\(1\\)\\(\\sqrt{4k/n}\\) Mahalanobis Distance"},{"location":"CS_Electives/Data_Mining/02_Data/#tidy-data","title":"Tidy Data","text":"<p>Also called long data</p> Characteristic Visual Each variable has its own column Each observation has its own row Each value has its own cell"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/","title":"Anomalous Points","text":""},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#types","title":"Types","text":"Type Leverage X outliers Observation with significantly large difference in \\(x\\)Bad leverage: high leverage and not in alignment with rest of the trendGood leverage: high leverage but in alignment with rest of the trend Outliers \\(y \\vert x\\) outliers Observation with significantly large difference in \\(y\\) given \\(x\\) Influence Observation which affects a model fit significantlyUsually outlier with high leverage, but not necessarily"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#causes","title":"Causes","text":"<ul> <li>True distribution has heavy tails</li> <li>Data \u201ccontaminated\u201d by another distribution withe either</li> <li>significantly different mean</li> <li>significantly larger variance</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#studentized-data","title":"Studentized Data","text":"<p>How many SD away from the mean is this data point</p> \\[ t_i =\\dfrac{x_i - \\bar x}{s_x} \\]"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#robustness-outliers","title":"Robustness &amp; Outliers","text":"\\[ \\begin{aligned} E[\\bar x] &amp;= \\mu + \\dfrac{x_o - \\mu}{n}  \\\\ E[s^2_x] &amp;= \\sigma^2_x + \\dfrac{(x_o - \\mu)^2}{n} \\end{aligned} \\] <p>For large outliers \\(x_o \\gg n\\mu, n\\sigma\\)</p> \\[ \\begin{aligned} \\bar x &amp;\\approx \\dfrac{x_o}{n} , s \\approx \\dfrac{\\vert x_o \\vert}{\\sqrt{n}} \\\\ \\implies T &amp;= \\dfrac{\\vert x_o - \\bar x \\vert}{s} \\approx \\dfrac{n-1}{\\sqrt{n}} \\end{aligned} \\]"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#testing-for-outliers","title":"Testing for Outliers","text":"<p>Outlier: Observation so different from others that it is suspected to be generated by a different mechanism with a one-time, large systematic error</p> <p>Useful only when \\(n&gt;20\\)</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#causes_1","title":"Causes","text":"<ul> <li>Error in measurement recording</li> <li>Failure of measurement process/tool</li> <li>One sample was fundamentally different from other samples being measured</li> <li>Failure of experimental process (eg: sample didn't receive proper treatment)</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#idk","title":"IDK","text":"<p>Detecting outliers is the first step to discover the mechanism that caused the outlier</p> <p>Sometimes the causes of outliers is more insightful that the analysis of the \u201cgood\u201d data</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#rareness-detection","title":"Rareness Detection","text":"\\[ x \\text{ is outlier} \\iff P(x) &lt; 1/n \\] <p>\\(p\\)-value \\(\\times n\\) = probability of getting one data point (out on \\(n\\)) this unusual or more due to random chance</p> <p>Assumes that we know the underlying distribution</p> <p>Chauvenet\u2019s criterion: reject if \\(p\\)-value \\(&lt;1/(2n)\\)</p> <p>Simple, assumes normal distribution, arbitrary cut-off, not rigorous</p> <p>Not recommended</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#multiple-of-iqr","title":"Multiple of IQR","text":"<ul> <li>IQR = Q3-Q1</li> <li>Outliers<ul> <li>Upper cutoff = Q3 + 1.5 IQR</li> <li>Lower cutoff = Q1 - 1.5 IQR</li> <li>Using this technique, usually about 1% of data points could be expected to be labelled as outliers</li> </ul> </li> <li>Far outliers<ul> <li>Upper cutoff = Q3 + 3 IQR</li> <li>Lower cutoff = Q1 - 3 IQR</li> </ul> </li> </ul> <p>Better alternative would be to used MAD</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#dixon-q-test","title":"Dixon \\(Q\\)-test","text":"<p>Identify one extreme data point $$ Q = \\dfrac{\\vert x_\\text{suspect} - x_\\text{closest} \\vert}{x_\\max - x_\\min} $$ Classify as outlier if \\(Q &gt; Q_\\alpha\\), where \\(\\alpha=\\) risk of rejecting good data</p> <ul> <li>Usually use \\(\\alpha&lt;\\) what you use for other tests</li> <li>For eg: use \\(\\alpha=0.01\\) instead of \\(0.05\\)</li> </ul> <p>Mostly used when \\(n&lt;20\\) and where calculating SD is difficult</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#problem","title":"Problem","text":"<p>Masking (what if there are multiple outliers)</p> <p></p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#grubbs-test","title":"Grubbs\u2019 Test","text":"<p>The test assumes that underlying distribution is normal; given this assumption holds true, Grubb\u2019s test has more power than Q-test</p> <p>Steps</p> <ol> <li>Identify number of outliers that you want to test</li> <li>For 2 outliers, we use a different critical value depending on whether the outliers are in the same/different tails</li> <li>Calculate Grubb\u2019s statistic</li> </ol> \\[ \\begin{aligned} \\text{G} &amp;= \\dfrac{\\text{SSE}_{\\cancel o}}{\\text{SSE}_{o}} \\\\ \\text{SSE} &amp;= \\sum (x_i - \\bar x)^2 \\end{aligned} \\] <p>where</p> <ul> <li>\\(\\text{SSE}_{\\cancel o} =\\) SSE for dataset without outlier (after removal)</li> <li>\\(\\text{SSE}_{o} =\\) SSE for dataset with outlier (before removal)</li> </ul> \\[ t_c = \\dfrac{n-1}{\\sqrt{n}} \\sqrt{ \\dfrac{ (t_{(\\alpha/2n), n-2})^2 }{ n-2 + (t_{(\\alpha/2n), n-2})^2 } } \\] <ul> <li>Usually, we take \\(\\alpha/2\\), but here we are looking at a collection of \\(n\\) numbers</li> <li>\\((n-2) =\\) degree of freedom</li> <li>\\((n-1)/\\sqrt{n} =\\) max value of \\(t\\)</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#multiple-outliers","title":"Multiple outliers","text":"<p>Iterative Grubb\u2019s Test Extreme Studentized Deviate</p> <p>To find unknown number of outliers \\(k\\), apply Grubb\u2019s test iteratively</p> <ol> <li>Search for outliers</li> <li>If outlier detected</li> <li>remove it</li> <li>else, stop</li> <li>Repeat steps 1-2</li> </ol> <p>Note: the \\(t_c\\) depends on \\(k\\)</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#peirces-criterion","title":"Peirce\u2019s Criterion","text":"<p>Compare probability of the data with outliers to probability of the data without the outliers</p> <p>Assumes a normal distribution</p> <p>Can remove multiple outliers in a single iteration</p> <p>Not as common as Grubb\u2019s test</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#handling-outliers","title":"Handling outliers","text":"<pre><code>flowchart LR\n\ni{Identify&lt;br /&gt;outlier cause?}\n\ndc{Data&lt;br /&gt;correction&lt;br /&gt;possible?}\n\nc[\"1. Correct data&lt;br /&gt;2. Include in analysis\"]\nr[\"1. Address outlier&lt;br /&gt;2. Document removal\"]\n\np[\"Perform analysis&lt;br /&gt;1. w/ outlier&lt;br /&gt;2. w/o outlier\"]\nda{\"Influential outlier?&lt;br/&gt;(Affects conclusions?)\"}\ndw[\"1. No issues&lt;br /&gt;2. Document everything\"]\nouch[\"1. Take more data (Repeat exp)&lt;br /&gt;2. Abandon normality assumption\"]\n\n\nstart([ ]) --&gt;\ni --&gt; |Y| dc --&gt;\n|Y| c\n\ndc --&gt; |N| r\n\ni --&gt; |N| p --&gt; da\n\nda --&gt; |N| dw\nda --&gt; |Y| ouch</code></pre> <p>Techniques to address outlier</p> <ul> <li>Delete outlier<ul> <li>Always delete spurious data</li> </ul> </li> <li>Truncate (delete both min and max data points)</li> <li>Winterize outlier (set value equal to closest neighbor)</li> <li>Replace outlier with expected value from Q-Q plot</li> <li>Use robust methods instead</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#identifying-causes","title":"Identifying causes","text":"<p>Always identify cause outlier as there could be lessons to be learnt</p> Time of identifying cause Comment Report? Before outlier detection Measurement instrument breaks and must be repaired; you suspect calibration will be off \u26a0\ufe0fDepends; not very useful, but good practice After outlier detection Beware of just-so stories \u2705 Never \u2705"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#idk_1","title":"IDK","text":"<p>Importance of outlier depends on decision you are trying to make</p> <p>Spurious vs outlier depends on what is important to you</p>"},{"location":"CS_Electives/Data_Mining/03_Anomalous_Points/#recommend-testing-sequence","title":"Recommend Testing Sequence","text":"<ol> <li>Graph the data: histogram, box plot, Q-Q plot</li> <li>Perform moment tests (mean, standard deviation, skewness, kurtosis)</li> <li>If non-normality detected, check for outliers</li> <li>If outliers removed, recheck for outliers</li> <li>If non-normal distribution suspected, use empirical CDF to identify candidate distributions</li> </ol>"},{"location":"CS_Electives/Data_Mining/03_Measurement/","title":"Measurement","text":""},{"location":"CS_Electives/Data_Mining/03_Measurement/#notes","title":"Notes","text":"<ul> <li>Most measurements are indirect: What we actually measure is different what we want to study</li> <li>For eg: measuring temperature with mercury thermometer: we look at the difference in mercury height</li> <li>Measurement can change the thing that you are measuring</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Measurement/#measurement-stability","title":"Measurement Stability","text":"<p>Temporal &amp; Spatial</p> <p>Repeated measurements are taken at different times, locations, conditions</p> <ul> <li>How constant is the sample</li> <li>How constant is the measurement process</li> <li>How constant is the measurement context</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Measurement/#observation-decomposition","title":"Observation Decomposition","text":"<p>Process observation</p> <ul> <li>Process True Value</li> <li>Process Error</li> <li>Measurement Error</li> <li>Procedure Error</li> <li>Sensor Error</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Measurement/#error-components","title":"Error Components","text":"<ul> <li>Systematic errors</li> <li>Produces bias</li> <li>We try to correct systematic error, but can never be totally free from systematic error</li> <li>We can put an upper limit on the expected systematic errors</li> <li>Random errors: Can be evaluated statistically, through repeated measurements</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Measurement/#measurement-metrics","title":"Measurement Metrics","text":"<ul> <li>Accuracy: 1 - systematic error</li> <li>Precision: standard deviation of repeated measurements (random error component)</li> <li>Repeatability: standard deviation of repeated measurements under conditions as nearly identical as possible</li> <li>Reproducibility: standard deviation of repeated measurements under conditions that vary (different operators, instruments, days, time)</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Measurement/#uncertainty-types","title":"Uncertainty Types","text":"<ul> <li>Type A: Process Noise</li> <li>Caused by fluctuations in nature that propagate through measurement model</li> <li>obtained by statistical analysis of repeated measurements</li> <li>Type B: Measurement Noise</li> <li>Types<ul> <li>Measurement Procedure Noise</li> <li>Incomplete definition of measurement</li> <li>Imperfect realization of procedure</li> <li>Sample not representative</li> <li>Environmental conditions</li> <li>Biases in reading analog scales</li> <li>Instrument resolution</li> <li>Values of constants used in calculations</li> <li>Changes in measuring instrument performance since last calibration</li> <li>Approximations/assumptions in measurement model</li> <li>Sensor Noise</li> </ul> </li> <li>Evaluated by scientific judgement (Prior experience or data, manufacture\u2019s specs)</li> </ul>"},{"location":"CS_Electives/Data_Mining/03_Measurement/#effective-degrees-of-freedom","title":"Effective Degrees of Freedom","text":"<p>When using combined uncertainty , we assume that the measurement is t-distributed</p> <p>Welch-Satterthwaite approximation $$ \\text{DOF}_\\text{eff} = \\dfrac{(\\sum u_i<sup>2)</sup>2}{\\sum (u_i^4/\\text{DOF}_i)} $$</p>"},{"location":"CS_Electives/Data_Mining/03_Measurement/#replication","title":"Replication","text":""},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/","title":"Data Preprocessing","text":"<p>You don\u2019t have to apply all these; it depends. You have to first understand the dataset.</p> Technique Meaning Advantage Disadvantage Aggregation Combining/Merge data objects/attributesContinuous: Sum, mean, max, max, min, etcDiscrete: Mode, Summarization, Ignoring - Low processing cost, space, time- Higher view- More stable Losing details Sampling Creating representative subset of a dataset, whose characteristics are similar to the original dataset Dimensionality Reduction Mathematical algorithm resulting in a set of new combination of old attributes Eliminate noise and unnecessary featuresBetter understandabilityReduce time, memory and other processing costEasier visualization Getting the original data is not possible after transformation Feature Subset Selection Removing irrelevant and redundant attributes Same as ^^ Extra resources required Feature Creation Create new attributes that can capture multiple important features more efficiently Discretization Convert continuous attribute into categorial/discrete (for classification) Binarization(Encoding) Convert continuous/categorical attribute into binary (association mining) Attribute Transformation Mathematical transformations <p>Feature selection and Dimensionality reduction are used for biomarkers analysis</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#types-of-sampling","title":"Types of Sampling","text":""},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#random-sampling","title":"Random Sampling","text":"Random Sampling Data object put back into original population? Duplicates? With replacement \u2705 \u2705 Without replacement \u274c \u274c"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#problem","title":"Problem","text":"<p>It may lead to misclassification, as not all classes are represented proportionally in the sample.</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#stratified-sampling","title":"Stratified Sampling","text":"<p>Different types of objects/classes with different frequency are used in the sample.</p> <p>Useful especially in imbalanced dataset, where all the classes have large variation in their counts.</p> <p>Ensures all classes of the population are well-represented in the sample.</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#steps","title":"Steps","text":"<ul> <li>Draw samples from each class<ul> <li>equal samples, or</li> <li>proportional samples, using % of the total of all classes</li> <li>Gives us imbalanced dataset</li> </ul> </li> <li>Combine these samples into a larger sample</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#progressiveadaptive-sampling","title":"Progressive/Adaptive Sampling","text":"<p>Useful when not sure about good sample size</p> <p>Computationally-expensive</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#steps_1","title":"Steps","text":"<pre><code>flowchart LR\ns[\"Start with small sample (100-1000)\"] --&gt;\na[Apply data mining algorithm] --&gt;\ne[Evaluate results] --&gt;|Increase Sample Size| s\n\ne --&gt;|Best Result Obtained| st[/Stop/]</code></pre>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#data-augmentation","title":"Data Augmentation","text":"<p>Think of all invariances that is important for your model</p> <ul> <li>Images</li> <li>Flip</li> <li>Crop</li> <li>Scale (Zoom)</li> <li>Translation (Position)</li> <li>Rotation</li> <li>Adding noise</li> <li>Warping<ul> <li>Stretching</li> <li>Shearing</li> <li>Lens distortions</li> </ul> </li> <li>Filters<ul> <li>Brightness</li> <li>Contrast</li> <li>Saturation</li> <li>Hue (don't do)</li> </ul> </li> <li>Mixup</li> <li>Convert labels</li> <li>\\(x' = \\lambda x_i + (1-\\lambda) x_j; y' = \\lambda y_i + (1-\\lambda) y_j\\)</li> <li> <p></p> </li> <li> <p>Fit it to a distribution</p> </li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#dimensionality-reduction","title":"Dimensionality Reduction","text":"<p>Unsupervised learning problem where we find a low-dimensional representation \\(\\mathcal Z\\) of \\(\\mathcal X\\)</p> <p>$$ \\begin{aligned} \\mathcal{Z} &amp;= f_\\theta(\\mathcal{X}) \\ f_\\theta &amp;: R^k \\to R^d \\ d &amp;&lt; k \\end{aligned} $$ Notes - Ensure to standardize data prior - Reducing dimensionality blindly is not always ideal     - These are for visualization, but not good for learning due to non-causal nature - Reduce dimensionality while preserving maximum information:     1. Cluster correlated features        For eg Cluster 1: Volatility features, Cluster 2: Scale features     2. Perform dimensionality reduction on each feature cluster separately     3. Obtain the first principal component for each cluster</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#algorithms","title":"Algorithms","text":"Technique Working Reduce dimensionality while Learning Type Comment No Hyperparameter Tuning Required Fast Deterministic Linearity LDA Maximize distance between classes Separating pre-known classes in the data Supervised \u2705 \u2705 \u2705 Linear PCA/SVD Maximize variance in dataFind linear combinations of predictor vars that are orthogonal to each other1. Calculate correlation matrix of predictors2. Find eigenvalues and corresponding eigenvectors of correlation matrix3. Orthogonalize design matrix by multiplying by a rotation matrix made up of eigenvectors\\(\\mu(\\text{PC}_i)=0 \\quad \\forall i\\)\\(\\sigma^2(\\text{PC}_i)=\\text{Eigenvalue} \\quad \\forall i\\)Learning more: Correlation matrix b/w PCs and original predictors Generating clusters previously not known Unsupervised \\(2k\\) contaminated points can destroy top \\(k\\) components \u2705 \u2705 \u2705 Linear Kernel PCA PLSPartial Least Squares Similar to PCA but supervisedCreate components correlated with the target ^^ Supervised \u2705 \u2705 \u2705 Linear Kernel PLS Laplacian Eigenmaps LLELocal Linear Embedding IsoMap MDS ^^ Unsupervised \u274c \u274c \u274c Non-Linear t-SNE ^^ Unsupervised \u274c \u274c \u274c Non-Linear UMAP ^^ Unsupervised \u274c \u2705 \u274c Non-Linear Variational auto-encoder Independent Component Analysis Maximize signal independence"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#pca","title":"PCA","text":"<ul> <li>Eigen Vectors Matrix<ul> <li>Each element represents how much (the weight) each original variable contributes to the corresponding principal component</li> <li>Row-wise sum of squared elements = 1, ie \\(\\sum_{\\text{feature } i} a_{ij}^2=1\\)</li> <li>Col-wise sum of squared elements = 1, ie \\(\\sum_{\\text{loading } j} a_{ij}^2=1\\)</li> </ul> </li> <li>Loadings matrix<ul> <li>Each element represents correlation between the original variable and the principal component</li> <li>Col-wise sum of squared elements = var(PC_i), ie \\(\\sum_{\\text{loading } j} a_{ij}^2 = \\sigma^2(\\text{PC}_j)\\)</li> </ul> </li> <li>Varimax rotation</li> </ul> <pre><code># apply PCA\npca = PCA(n_components=2)\npca.fit(X)\n\npca_eigenvectors_matrix = pd.DataFrame(\n    pca.components_.T,\n    columns=['PC1', 'PC2'],\n    index=iris.feature_names\n)\n\npca_corr_matrix = pd.DataFrame(\n    pca.components_.T * np.sqrt(pca.explained_variance_),\n    columns=['PC1', 'PC2'],\n    index=iris.feature_names\n)\n</code></pre>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#feature-selection","title":"Feature Selection","text":"<pre><code>flowchart LR\n\nAttributes --&gt;\nss[Search Strategy] --&gt;\nsa[/Subset of Attributes/] --&gt;\nEvaluation --&gt;\nsc{Stopping Criterion Reached?} --&gt;\n|No| ss\n\nsc --&gt;\n|Yes| sel[/Select Attributes/] --&gt;\nSomething</code></pre>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#mutual-information","title":"Mutual Information","text":"<p>Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency. The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances.</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#brute-force-approach","title":"Brute Force Approach","text":"<p>Consider a set with \\(n\\) attributes. Its power set contains \\(2^n\\) sets. Ignoring \\(\\phi\\), we get \\(2^{n-1}\\) sets.</p> <p>Steps</p> <ul> <li>Evaluate the performance of all possible combinations of subsets</li> <li>Choose the subset of attributes which gives the best results</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#embedded-approach","title":"Embedded Approach","text":"<p>The data mining algorithm itself performs the selection, without human intervention</p> <p>Eg: A decision tree automatically chooses the best attributes at every level</p> <p>Builds a model in the form of a tree</p> <ul> <li>Internal nodes = labelled with attributes</li> <li>Leaf nodes = class label</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#filter-approach","title":"Filter Approach","text":"<p>Independent of data mining algorithm</p> <pre><code>flowchart LR\no[(Original&lt;br /&gt; Feature Set)] --&gt;\n|Select&lt;br /&gt; Subset| r[(Reduced&lt;br /&gt; Feature Set)] --&gt;\n|Mining&lt;br /&gt; Algorithm| Result</code></pre> <p>eg: Select attributes whose evaluation criteria(pairwise correlation/Chi<sup>2</sup>, entory) is as high/low as possible</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#wrapper-approach","title":"Wrapper Approach","text":"<p>Use the data mining algorithm (capable of ranking importance of attributes) as a black box to find best subset of attributes</p> <pre><code>flowchart LR\no[(Original&lt;br /&gt; Feature Set)] --&gt;\ns[Select&lt;br /&gt; Subset] --&gt;\ndm[Mining&lt;br /&gt; Algorithm] --&gt;\nr[(Reduced&lt;br /&gt; Feature Set)] &amp; s\n\nsubgraph Black Box[\"Ran n times\"]\n    s\n    dm\nend</code></pre>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#feature-engineering","title":"Feature Engineering","text":""},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#feature-extraction","title":"Feature extraction","text":""},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#mapping-data-to-new-space","title":"Mapping data to new space","text":"<ul> <li>Time series data \\(\\to\\) frequency domain</li> <li>For eg, fourier transformation</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#feature-summary-statistics","title":"Feature Summary Statistics","text":"<ul> <li>Mean</li> <li>Std</li> <li>Correlation</li> </ul> <p>For time-series data, should only use past data - Make sure to use rolling statistics until the current point to avoid data leakage</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#attribute-transform","title":"Attribute Transform","text":"Non-Sequential\\(x'\\) Time-Series\\(x'_t\\) Property Simple \\(x^2, \\log x, \\vert  x  \\vert\\) Min-Max Normalization \\(\\dfrac{x - \\min(x)}{\\max(x) - \\min(x)}\\) \\(\\dfrac{x_t - \\min(x_{t-p, t-1})}{\\max(x_{t-p, t-1}) - \\min(x_{t-p, t-1})}\\) \\(0 \\le x \\le 1\\) Standard Normalization \\(\\dfrac{x - \\bar x}{s}\\) \\(\\dfrac{x_t - {\\bar x}_{t-p, t-1}}{s_{t-p, t-1}}\\) \\(\\mu' = 0, \\sigma' = 1\\) <p>Standardization</p> <ul> <li>Reduces collinearity: even if \\(r(x, x^2) \\ne 0\\) standardizing will ensure \\(r(\\tilde x, {\\tilde x}^2)=0\\)</li> <li>However, it does NOT reduce multicollinearity</li> </ul> <p>For time-series data, should only use past data - Make sure to use rolling statistics until the current point to avoid data leakage - This applies to normalization and any other inter-row operation</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#feature-construction","title":"Feature Construction","text":"<p>Construct new features from existing features</p> <p>Eg - Area = length * breadth - Density = mass/volume</p> <p>Operators</p> <ul> <li>Univariate</li> <li>Normalize: Divide</li> <li>Scale: Power, Power Root, Exponent, Log, Factorial</li> <li>Multivariate (interaction terms)</li> <li>Combine: Add, Multiply</li> <li>Contrast: Subtract, Divide, Absolute value</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#discretization","title":"Discretization","text":"<ol> <li> <p>Sort the data in ascending order</p> </li> <li> <p>Generate</p> <ul> <li> <p>\\(n-1\\) split points</p> </li> <li> <p>\\(n\\) bins \\(\\to\\) inclusive intervals (specified by the analyst)</p> </li> </ul> </li> </ol> <p>Then convert using binarization. But, why?</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#types","title":"Types","text":"Equal-Width Binning Equal-Frequency Binning Analyst specifies No of bins Frequency of data objects in each bin Width \\(\\frac{\\text{Max-Min}}{\\text{No of bins}}\\) Make sure atleast \\(n-1\\) bins have the correct frequency"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#discretizationencoding","title":"Discretization/Encoding","text":"Method 1 One-Hot Ridge One-Hot 1. Perform one-hot2. Perform Ridge Regression3. Multiply one-hot encodings with Ridge Coefficients m  m  m  m  m  m  m  m  m  m  m  m  m  m  m  m For \\(m\\) categories, we need ___ d No unusual rela"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#naming","title":"Naming","text":"Feature Transform Input variables Target Transform Output variables"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#target-transform","title":"Target Transform","text":"<p>Make sure the target range is standardized to ensure model can generalize, especially when using non-linear models such as Decision Trees/ANN</p> <p>Non-linear transforms not recommended, as you will face all the disadvantages of MSLE </p> <p>One idea could be to use \\(y_i\\) as sample weight?</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#box-coxbickel-doksum-transform","title":"Box-Cox/Bickel-Doksum Transform","text":"<p>\\(w_t = f(y_t)\\)</p> \\[ w_t = \\begin{cases} \\log \\vert y_t \\vert, &amp; \\lambda = 0 \\\\ \\dfrac{\\text{sign}(y_t) \\cdot \\vert y_t \\vert ^\\lambda - 1}{\\lambda}, &amp; \\lambda \\ne 0 \\end{cases} \\] \\(\\lambda\\) Transformation 1 None \\(\\dfrac{1}{2}\\) Square root plus linear transformation 0 Natural log -1 Inverse plus 1 <p>The model will predict \\(\\hat w_{t+h}\\)</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#back-transform","title":"Back Transform","text":"<p>\\(\\hat y_{t+h} = f^{-1}(\\hat w_{t+h})\\)</p> Point Estimate of response distribution \\(\\lambda=0\\) \\(\\lambda \\ne 0\\) Median \\(\\exp(\\hat w_{t+h})\\) \\({\\vert \\lambda \\hat w_{t+h} + 1 \\vert}^{1/\\lambda} \\cdot \\text{sign}(\\lambda \\hat w_{t+h} + 1)\\) Mean \\(\\exp(\\hat w_{t+h}) \\left[1 \\textcolor{hotpink}{+ \\dfrac{\\sigma^2_{\\tiny \\hat w_h}}{2}} \\right]\\) \\((\\lambda \\hat w_{t+h} + 1)^{1/\\lambda} \\left[1  \\textcolor{hotpink}{+ \\dfrac{\\sigma^2_{\\tiny \\hat w_h}}{2}} \\dfrac{(1-\\lambda)}{(\\lambda \\hat w_{t+h} + 1)^2} \\right]\\) Mode \\(\\exp(\\hat w_{t+h}) \\left[1 \\textcolor{hotpink}{- \\sigma^2_{\\tiny \\hat w_h}} \\right]\\) \\((\\lambda \\hat w_{t+h} + 1)^{1/\\lambda} \\left[1 \\textcolor{hotpink}{- \\sigma^2_{\\tiny \\hat w_h}} \\dfrac{(1-\\lambda)}{(\\lambda \\hat w_{t+h} + 1)^2} \\right]\\) <p>where - \\(\\sigma^2_{\\tiny \\hat w_h}\\) is the \\(h\\)-step forecast variance on the transformed scale</p> <p>Bias Correction - Back-transformed Prediction Intervals have correct coverage, but point forecasts are medians - Maintained     - Medians are maintained for monotonically increasing functions     - Means are not due to Jensen's inequality     - Mode: similarly to mean??? - Hence, if we need the mean/mode, we need to perform correction - The larger the forecast variance, the larger the difference b/w median, mean, and mode</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#linear-basis-function","title":"Linear Basis Function","text":"\\[ \\begin{aligned} \\phi_i &amp;= \\text{exp} \\left\\{ \\frac{-(x- \\mu_i)^2}{2 \\sigma^2} \\right\\} \\\\ &amp;= \\begin{cases} 0, &amp; |x_i - x| \\to \\infty \\\\ 1, &amp; |x_i - x| \\approx 0 \\end{cases} \\end{aligned} \\] <ul> <li>\\(\\mu\\) = pivot</li> <li>\\(\\sigma^2\\) = bandwidth</li> <li>Higher, smoother</li> <li>Lower, sharper</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#lda","title":"LDA","text":"<p>Linear Discriminant Analysis, using Fisher Linear Discriminant</p> <p>Maximizes separation using multiple classes, by seeking a projection that best discriminates the data</p> <p>It is also used a pre-processing step for ML application</p>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#goals","title":"Goals","text":"<ul> <li>Find directions along which the classes are best-separated (ie, increase discriminatory information)</li> <li>Maximize inter-class distance</li> <li>Minimize intra-class distance</li> <li>It takes into consideration the scatter(variance) within-classes and between-classes</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#steps_2","title":"Steps","text":"<ol> <li>Find within-class Scatter/Covariance matrix</li> </ol> <p>\\(S_w = S_1 + S_2\\)</p> <ul> <li>\\(S_1 \\to\\) Covariance matrix for class 1</li> <li>\\(S_2 \\to\\) Covariance matrix for class 2</li> </ul> \\[ S_1 = \\begin{bmatrix} \\text{cov}(x_1, x_1) &amp; \\text{cov}(x_1, x_2) \\\\    \\text{cov}(x_2, x_1) &amp; \\text{cov}(x_2, x_2) \\end{bmatrix} \\] \\[ \\begin{aligned} \\text{Cov}(x_j, x_k) &amp;= \\frac{1}{n_j - 1} \\sum_{i=1, x \\in C_j}^{n_1} (x_i - \\mu_1)(x_i - \\mu_1) \\\\ \\text{Cov}(x_1, x_1) &amp;= \\frac{1}{n_1 - 1} \\sum_{i=1, x \\in C_1}^{n_1} (x_i - \\mu_1)^2 \\end{aligned} \\] <ol> <li>Find between-class scatter matrix</li> </ol> \\[ S_B = (\\mu_1 - \\mu_2) (\\mu_1 - \\mu_2)^T \\] <ol> <li> <p>Find Eigen Value</p> </li> <li> <p>Find Eigen Vector</p> </li> <li> <p>Generate LDA Projection Normalized Eigen Vector</p> </li> <li> <p>Generate LDA score (projected value) in reduced dimensions</p> </li> </ol> \\[ \\text{LDA Score} = x_1 v_1 + x_2 v_2 \\]"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#eigen-value","title":"Eigen Value","text":"\\[ | A - \\lambda I | = 0 \\\\ |S_w^{-1} S_B - \\lambda I| = 0 \\] <ul> <li>\\(\\lambda =\\) Eigen Value(s)</li> <li>If we get multiple eigen values, we only take the highest eigen value</li> <li>It helps preserve more information. How??</li> <li>\\(I =\\) Identity Matrix</li> </ul> <p>We are taking \\(A=S_w^{-1} S_B\\) because taking \\(S_w^{-1}\\) helps us maximize \\(\\frac{1}{x}, x \\in S_w\\)</p> <ul> <li>Hence \\(x\\) is minimized</li> <li>Thereby, within-class distance is minimized</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#eigen-vector","title":"Eigen Vector","text":"\\[ (S_w^{-1} S_B - \\lambda I)  \\textcolor{hotpink}{V} = 0 \\] <ul> <li>\\(\\lambda =\\) Highest eigen value</li> <li>\\(V =\\) Eigen Vector</li> </ul>"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#normalized-eigen-vector","title":"Normalized Eigen Vector","text":"\\[ V_\\text{norm} = \\begin{bmatrix} \\frac{v_1}{\\sqrt{v_1^2 + v_2^2}} \\\\ \\frac{v_2}{\\sqrt{v_1^2 + v_2^2}} \\end{bmatrix} \\]"},{"location":"CS_Electives/Data_Mining/04_Data_Preprocessing/#missing-value-imputation","title":"Missing Value Imputation","text":"<p>This may be</p> <ul> <li>median</li> <li>mode</li> <li>min</li> <li> <p>max: for eg, sensors won\u2019t take reading if temperature is too high</p> </li> <li> <p>Just replacing value, without understanding the underlying process is not good</p> <ul> <li>The fact that the value is missing is an important information itself</li> <li>Better to just drop the row</li> <li>Also, imputation is bad as it may break the relationship<ul> <li>especially univariate imputation will break the relationship, imagine linear regression with imputation</li> <li>Last resort<ul> <li>Replace missing \\(x\\) with \\(\\arg \\max \\limits_x P(x_j \\vert x_{\\centernot j}, y)\\)</li> <li>Replace missing \\(y\\) with \\(\\arg \\max \\limits_x P(y \\vert x)\\)</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/","title":"Exploratory Data Analysis","text":"<p>Preliminary investigation of data, to understand its characteristics</p> <p>Helps identify appropriate pre-processing technique and data mining algorithm</p> <p>Involves</p> <ul> <li>Summary Statistics</li> <li>Visualization</li> </ul>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#summary-statistics","title":"Summary Statistics","text":"<p>Note: Statistics about the data \\(\\ne\\) data itself</p>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#uncertainty-of-estimate","title":"Uncertainty of estimate","text":"<ul> <li>Standard error: variability in sample estimate</li> <li>Confidence intervals: estimated range for the true parameter that is being estimated</li> </ul>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#robustness","title":"Robustness","text":"<p>Ability of a statistical procedure to handle a variety of distributions (non-normal) and contamination (outliers, etc)</p> <p>There is a trade-off between efficiency and robustness</p>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#breakdown-point","title":"Breakdown Point","text":"<p>Fraction of contaminated data in a dataset that can be tolerated by the statistical procedure</p> <p>Max logical BP is 0.5, because after that, you can\u2019t tell what is correct data and what is contaminated</p>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#contamination","title":"Contamination","text":"<p>Fraction of data comes from a different distribution</p> <p>There are 2 models for contamination</p> <ul> <li>Mean shift</li> <li>Variance shift</li> </ul>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#univariate-summary-statistics","title":"Univariate Summary Statistics","text":"<p>Minimal set of value(s) that captures the characteristics of large amounts of data, and show the properties of a distribution</p> Measure Statistic Meaning Formula Formula withMeasurement Error Moment Breakdown Point(Higher is better) SEStandard Error\\(\\sigma(\\text{Estimate})\\)(Lower is better) SE withmeasurement error SNRSignal Noise Ratio\\(\\dfrac{E [\\text{Estimate}]}{\\sigma(\\text{Estimate})}\\)(Higher is better) Comment Location Mean/Arithmetic Mean\\(\\mu\\) Central tendency of distribution \\(\\dfrac{\\sum x_i}{n}\\) Weighted with \\(w_i = \\dfrac{1}{\\sigma^2_m}\\) 1<sup>st</sup> \\(\\dfrac{1}{n}\\) \\(1 \\times \\dfrac{s}{\\sqrt{n}}\\)(assumes Normal dist) Trimmed Mean \\(k \\%\\) obs from top of dist are removed\\(k \\%\\) obs from bottom of dist are removed\\(\\implies 2k \\%\\) obs are removed in total \\(\\dfrac{k}{n}\\) \\(\\left( 1+\\dfrac{2k}{n} \\right)\\dfrac{s}{\\sqrt{n}}\\) For \\(k&gt;12.5\\), better to use median Winsorized Mean \\(k \\%\\) obs from top of dist are replaced with \\((1-k)\\)th percentile\\(k \\%\\) obs from bottom of dist are replaced with \\(k\\)th percentile\\(\\implies 2k \\%\\) obs are replaced in total \\(\\dfrac{k}{n}\\) \\(\\left( 1+\\dfrac{2k}{n} \\right)\\dfrac{s}{\\sqrt{n}}\\) For \\(k&gt;12.5\\), better to use median Weighted Mean \\(\\dfrac{\\sum w_i x_i}{\\sum w_i}\\) \\(\\dfrac{1}{n}\\) Geometric Mean \\(\\sqrt[{\\Large n}]{\\Pi x}\\) \\(\\dfrac{1}{n}\\) Root Mean Squared \\(\\sqrt{\\dfrac{\\sum_{i=1}^n (x_i)^2}{n}}\\) Gives more weightage to larger values Root Mean N \\(\\sqrt[p]{\\dfrac{\\sum_{i=1}^n (x_i)^p}{n}}\\) Gives more weightage based on power Harmonic Mean \\(\\dfrac{n}{\\sum \\frac{1}{x}}\\) \\(\\dfrac{1}{n}\\) Gives more weightage to smaller values Median Middle most observation50<sup>th</sup> quantile \\(\\begin{cases} x_{{n+1}/2}, &amp; n = \\text{odd} \\\\ \\dfrac{x_{n} + x_{n+1}}{2}, &amp; n = \\text{even}\\end{cases}\\) \\(\\dfrac{1}{2}\\)\\(\\dfrac{1}{n}\\) if new point if added, idk how to explain \\(1.253 \\dfrac{s}{\\sqrt{n}}\\) Robust to outliers SoftMedian 1. Sort the data in ascending order2. Calculate the median3. Assign weights \\(w_i\\) to each data point based on how close it is to the median, usually Gaussian Weighting\\(w_i = \\exp \\left \\{ \\dfrac{-(x_i - \\text{med})^2}{2 \\sigma^2} \\right\\}\\)4. Compute weighted average\\(\\dfrac{\\sum w_i x_i}{\\sum w_i}\\) Mode Most frequent observation Unstable for small samples Scale Variance\\(\\sigma^2\\)\\(\\mu_2\\) Squared average deviation of observations from mean \\(\\dfrac{1}{n} \\sum (x_i - \\mu)^2\\)\\(\\dfrac{1}{n} \\sum (x_i - \\bar x)^2 \\times \\dfrac{n}{n-1}\\) 2<sup>nd</sup> Centralised \\(\\dfrac{1}{n}\\) \\(2 s \\times \\dfrac{s}{\\sqrt{2 (n-1)}} \\times \\sqrt{1+ \\dfrac{n-1}{2n} \\gamma_4'}\\)(Assumes Normal dist) \\(\\dfrac{n-1}{2}\\) Adjusted variance \\(\\dfrac{1}{n-1} \\left( 1 - \\hat \\gamma_3 \\hat x + \\dfrac{\\hat \\gamma_4 - 1}{4} \\hat x^2 \\right)\\) Standard Deviation Average deviation of observations from mean \\(\\sqrt{\\text{Variance}}\\) \\(\\dfrac{1}{n}\\) \\(1 \\times \\dfrac{s}{\\sqrt{2 (n-1)}} \\times \\sqrt{1+ \\dfrac{n-1}{2n} \\gamma_4'}\\)(Assumes Normal dist) \\(\\sqrt{\\text{SNR}(\\sigma^2)}\\) MADMean Absolute Deviation Mean deviation of observations from mean \\(\\dfrac{\\sum \\vert x_i - \\mu \\vert}{n}\\)\\(\\dfrac{\\sum \\vert x_i - \\bar x \\vert}{n} \\times \\dfrac{n}{n-1}\\) MAD' corrects it to be comparable to standard deviation \\(1.253 \\times \\text{MAD}\\) MedADMedian Absolute Deviation Median deviation of observations from median \\(\\text{med} (\\vert x_i - \\text{med}_x \\vert)\\)\\(\\text{med} (\\vert x_i - \\hat {\\text{med}_x} \\vert ) \\times \\dfrac{n}{n-1}\\) \\(\\dfrac{1}{2}\\) \\(1.67 \\times \\dfrac{s}{\\sqrt{2 (n-1)}}\\) MedAD' corrects it to be comparable to standard deviation \\(1.4826 \\times \\text{MedAD'}\\) Skewness\\(\\gamma_3\\) Direction of tail \\(\\dfrac{\\sum (x_i - \\mu)^3}{n \\sigma^3}\\)\\(\\dfrac{\\mu - \\text{Mo}}{\\sigma}\\)\\(\\dfrac{3(\\mu - \\text{Md})}{\\text{MedAD'}}\\)\\(\\dfrac{(Q_3 - Q_2) - (Q_2 - Q_1)}{\\text{MedAD'}}\\)\\(\\dfrac{\\sum (x_i - \\bar x)^3}{n s^3} \\times \\dfrac{\\sqrt{n(n-1)}}{(n-2)}\\) 3<sup>rd</sup> Standardized \\(\\sqrt{\\dfrac{6n(n-1)}{(n-2)(n+1)(n+3)}}\\)\\(\\approx \\sqrt{\\dfrac{6}{n}} \\left[ 1 - \\dfrac{3}{2n} + O \\left(\\dfrac{1}{n^2} \\right) \\right]\\) 0: Symmetric\\([-0.5, 0.5]\\): Approximately-Symmetric\\([-1, 1]\\): Moderately-skewedelse: Higly-skewed Kurtosis\\(\\gamma_4\\) Peakedness of distribution \\(\\dfrac{\\sum (x_i - \\mu)^4}{n \\sigma^4}\\)\\(\\dfrac{(\\hat q_{.875} - \\hat q_{.625}) + (\\hat q_{.375} - \\hat q_{.125})}{\\text{MedAD'}}\\)\\(\\dfrac{\\hat q_{.975}+\\hat q_{.075}}{\\text{MedAD'}}\\)\\(\\dfrac{\\sum (x_i - \\bar x)^4}{n s^4} \\times \\dfrac{(n+1)(n-1)}{(n-2)(n-3)}\\) 4<sup>th</sup> standardized \\(2 \\times \\text{SE}(\\gamma_3) \\times \\sqrt{\\dfrac{n^2-1}{(n-3)(n+5)}}\\)\\(\\approx \\sqrt{\\dfrac{24}{n}} \\left[ 1- \\dfrac{2}{n} + O \\left(\\dfrac{1}{n^2} \\right) \\right]\\) Excess Kurtosis\\(\\gamma_4'\\) Kurtosis compared to Normal distribution \\(\\gamma_4-3\\) Max Min Percentile/Quantile Divides distributions into 100 parts \\(\\dfrac{1}{\\sqrt{n}} \\dfrac{\\sqrt{p (1-p)}}{f(q_p)}\\), where\\(f=\\) PDF\\(q_p=\\) obtained quantile \\(x\\) value for given \\(p\\) Unstable for small datasets Quartile Divides distributions into 4 parts Decile Divides distributions into 10 parts Range Range of values Max-Min Susceptible to outliers IQRInterquartile Range Q3 - Q1 \\(\\dfrac{1}{4}\\) \\(2.23 \\times \\dfrac{s}{\\sqrt{2(n-1)}}\\) Robust to outliers IRQ' corrects it to be comparable to standard deviation \\(0.7413 \\times \\text{IQR}\\) CVCoefficient of Variation \\(\\dfrac{\\sigma}{\\mu}\\) <p></p>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#standard-error-of-statistic","title":"Standard Error of Statistic","text":"<ul> <li>Standard deviation of statistic in sampling distribution</li> <li>Measure of uncertainty in the sample statistic wrt true population mean</li> </ul>"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#relationship-between-mean-median-mode","title":"Relationship between Mean, Median, Mode","text":"\\[ \\text{Mo} = 3 \\text{Md} - 2 \\mu \\]"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#skewness","title":"Skewness","text":"Skewness Property \\(&gt; 0\\) Mode &lt; Median &lt; Mean Positively Skewed \\(0\\) Mode = Median = Mean \\(&lt;0\\) Mean &lt; Median &lt; Mode Negatively Skewed"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#moment","title":"Moment","text":"\\[ \\begin{aligned} M_k &amp;= E(x^k) \\\\ &amp;= \\dfrac{(x-M_{k-1})^k}{n} \\\\ &amp;= \\dfrac{(x-m_{k-1})^k}{n} \\times \\dfrac{n}{n-k+1} \\end{aligned} \\]"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#multivariate-summary-statistics","title":"Multivariate Summary Statistics","text":"How 2 variables vary together Covariance \\(-\\infty &lt; C &lt; +\\infty\\) Correlation \\(-1 \\le r \\le +1\\)"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#covariance-matrix","title":"Covariance Matrix","text":"<p>It is always \\(n \\times n\\), where \\(n =\\) no of attributes</p> \\(A_1\\) \\(A_2\\) \\(A_3\\) \\(A_1\\) \\(\\sigma^2_{A_1}\\) \\(\\text{Cov}(A_1, A_2)\\) \\(\\text{Cov}(A_1, A_3)\\) \\(A_2\\) \\(\\text{Cov}(A_2, A_1)\\) \\(\\sigma^2_{A_2}\\) \\(\\text{Cov}(A_2, A_3)\\) \\(A_3\\) \\(\\text{Cov}(A_3, A_1)\\) \\(\\text{Cov}(A_3, A_2)\\) \\(\\sigma^2_{A_3}\\) <p>The diagonal elements will be variance of the corresponding attribute</p> \\[ \\begin{aligned} \\text{Cov}(x, y) &amp;= \\frac{1}{n} \\sum_{k=1}^n (x_k - \\bar x) (y_k - \\bar y) \\\\ \\implies \\text{Cov}(x, x) &amp;= \\frac{1}{n} \\sum_{k=1}^n (x_k - \\bar x) (y_k - \\bar y) \\\\ &amp;= \\frac{1}{n} \\sum_{k=1}^n (x_k - \\bar x) (x_k - \\bar x) \\\\ &amp;= \\frac{1}{n} \\sum_{k=1}^n (x_k - \\bar x)^2 \\\\ &amp;= \\sigma^2_x \\end{aligned} \\]"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#correlation-matrix","title":"Correlation Matrix","text":"\\(A_1\\) \\(A_2\\) \\(A_3\\) \\(A_1\\) \\(1\\) \\(r(A_1, A_2)\\) \\(r(A_1, A_3)\\) \\(A_2\\) \\(r(A_2, A_1)\\) \\(1\\) \\(r(A_2, A_3)\\) \\(A_3\\) \\(r(A_3, A_1)\\) \\(r(A_3, A_2)\\) \\(1\\) <p>The diagonal elements will be 1</p> \\[ \\begin{aligned} r(x, y) &amp;= \\frac{ \\text{Cov}(x, y) }{ \\sigma_x \\sigma_y } \\\\ \\implies r(x, x) &amp;= \\frac{ \\text{Cov}(x, x) }{ \\sigma_x \\sigma_x } \\\\ &amp;= \\frac{ \\frac{1}{n} \\sum_{k = 1}^n (x_k - \\bar x) (x_k - \\bar x) }{ \\left( \\sqrt{ \\frac{1}{n} (x_k - \\bar x)^2 } \\right)^2 } \\\\ &amp;= 1 \\end{aligned} \\]"},{"location":"CS_Electives/Data_Mining/05_Data_Exploration/#why-n-k-for-sample-statistics","title":"Why \\((n-k)\\) for sample statistics?","text":"<p>where \\(k=\\) No of estimators</p> <ol> <li>High probability that variance of sample is low, so we correct for that</li> <li>Lost degree of freedom</li> </ol>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/","title":"Data Visualization","text":"<p>Display of data in a graphical/tabular format</p> <p>Helps us understand the data; humans are better at recognizing visual patterns than numeric patterns</p> <p></p> <p>Limitation: Pareidolia; seeing patterns that do not exist</p>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#why-is-visualization-important","title":"Why is visualization important?","text":"<p>Widely different distributions can have the same statistical properties</p> Example Case Visualization Anscombe\u2019s Quartet Datasaurus Dozen All have the same mean, std, and correlation"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#characteristics-of-great-visualization","title":"Characteristics of Great Visualization","text":"<ul> <li> Story</li> <li> Truthful: not aimed to mislead viewers, accurate representation</li> <li> Perception: Easy to understand</li> <li> Functional: useful and enlightening</li> <li> Insightful: reveals something that wouldn't have been possible otherwise</li> <li> Aesthetics: Grammar of Graphics</li> <li> Beautiful</li> </ul>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#grammar-of-graphics","title":"Grammar of Graphics","text":"<ul> <li> Theme<ul> <li> Grid</li> <li> Background</li> <li> Typography</li> </ul> </li> <li> Labels<ul> <li> Title</li> <li> Subtitle</li> <li> Caption: Extra text, source of data, etc</li> <li> Axis Labels</li> <li> Legend<ul> <li> Title</li> <li> Items: try your best to align with the actual elements</li> </ul> </li> </ul> </li> <li> Coordinates<ul> <li> System<ul> <li> Cartesian</li> <li> Polar</li> </ul> </li> <li> Range<ul> <li> Do not skew the axis: Use the correct minimum &amp; max range</li> <li> Exceptions<ul> <li> only possible values are included<ul> <li> For eg: for human body temperature, you should show 98-105 F; you shouldn\u2019t start at 0</li> </ul> </li> <li> small movements matter<ul> <li> GDP across time</li> </ul> </li> <li> important time range</li> </ul> </li> <li> Tip: When presenting, show the full view, then zoom in clarifying the reason</li> </ul> </li> </ul> </li> <li> Facets: Subplots</li> <li> Scales: Axis<ul> <li> Discrete</li> <li> Continuous</li> <li> Continuous, breaks</li> <li> Continuous, Log</li> <li> Almost never use dual y-axes<ul> <li> Will lead to appearance of spurious correlations</li> <li> Exception: When the 2 axes measure the same thing. For eg<ul> <li> Axis 1: Percentages; Axis 2: Absolute value</li> <li> Axis 1: Celsius; Axis 2: Fahrenheit</li> </ul> </li> </ul> </li> </ul> </li> <li> Geometries: Type of Plot (check below)</li> <li> Aesthetics<ul> <li> Position-X</li> <li> Position-Y</li> <li> Color<ul> <li> Discrete</li> <li> Continuous</li> </ul> </li> <li> Size</li> <li> Shape</li> <li> Opacity</li> <li> Animation (for Time)</li> </ul> </li> <li> Data</li> </ul>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#plots","title":"Plots","text":"Type Chart Purpose Visual Limitations Uni-Variate Pie Chart Part of a whole Not easy to compare between parts as it uses angles and areas Bar Chart Comparing values of groups Lollipop Chart Comparing values of groups where only the end of the bar matters Column Chart Comparing value across time Waffle Chart Show values as squares Box/Box-Whiskers Plot Helps understand the distribution of a variable 1D Histogram Visualizes the frequency distribution of attributeRelative uncertainty of each bin frequency \\(\\propto \\dfrac{1}{\\sqrt{\\text{count}}}\\)The convention of analyzing these bins: Values are left-inclusive and right-exclusive; Last bin is right-inclusiveContinuous Data: binning - Shape may change dramatically depending on bin settings- Bins with few counts have high statistical uncertainty- Interpretation can be difficult without huge amounts of data Density Plot Smooth version of histogram- Bandwidth- Kernel Pyramid Histogram Violin Plot Smooth version of pyramid histogram Strip Jitter Q-Q Plot Quantile-Quantile plot comparing a distribution\u2019s quantiles with quantiles of a known distribution (such as Normal distribution) Beeswarm Ridge Plot Multi-variate density plot offsetting the densities Raincloud Plot Jitter plot + Box Plot + Violin Plot Treemap Hard to interpret Conditional Quantitative - Bin quantitative data- Make different plotsThis will be useful for error distribution inspection Bi-Variate Scatter Plot Line Plot Comparing trend of value across time 2D Histogram Helps understand frequency of co-occurance of 2 attributes Heatmap Looking at overall patterns Mosaic Plot Hard to interpret Stem &amp; Leaf Plots Understand the distribution of values of an attributeUseful when there aren\u2019t many valuesSteps- Split values into groups, where each group contains those values that are the same except for the last digit- Each group becomes a stem, while the last digit of a group are the leaves    - Stems will be the higher-order digits    - Leaves will be the lower-order digits- Plot stems vertically and leaves horizontally Tri-Variate Contour Plots Used for spacial data Multi-Variate Parallel Coordinates Pair Plot/Scatter plot matrix Basically a matrix of scatter plots May get overwhelming for large number of variables Correlogram Heatmap Correlogram Bar Regression Coefficients plot Marginal effects plot Comparison Sparklines Slopegraphs Geospatial/Map Choropleth May hide details, such as population IDK IDK 2D Map Requires 'projection'Best: RobinsonMost-common: Mercator, but worst Distortion of area Text Word cloud Looks cool, but not very usefulKinda like Pie ChartsJust use bar chart instead"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#cheat-sheet","title":"Cheat Sheet","text":""},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#uncertainty-visualization","title":"Uncertainty Visualization","text":"<p>Helps avoid misunderstanding of uncertainty</p> <ul> <li>Histogram</li> <li>Box plot</li> </ul>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#data-visualization-guidelines","title":"Data Visualization Guidelines","text":"Company Guideline Adobe https://spectrum.adobe.com/page/data-visualization-fundamentals/ Airbnb https://airbnb.io/visx Amazon Web Services https://cloudscape.design/patterns/general/data-vis/ Apple https://developer.apple.com/design/human-interface-guidelines/charts Aviva https://standards.aviva.com/framework/element-library/components/pie-chart/ Baltimore City Data Fellows Project https://storymaps.arcgis.com/stories/d19f7d4d2a9b49c7b8f68730e3cda1e6 BBC https://www.bbc.co.uk/gel/guidelines/how-to-design-infographics BBC https://bbc.github.io/rcookbook/ BBC Audiences https://public.tableau.com/profile/bbc.audiences#!/vizhome/BBCAudiencesTableauStyleGuide/Hello Cato Institute https://github.com/glosophy/CatoDataVizGuidelines/blob/master/PocketStyleBook.pdf Consumer Financial Protection Bureau https://cfpb.github.io/design-system/guidelines/data-visualization-guidelines Data Design System Collection https://airtable.com/appmJoE6s8PAWWHaU/shrSvvfZySawZHvQa/tblLVYunaKUqILW3k/viwZ8ay3WHvzmCC6Z?blocks=hide Dallas Morning News https://drive.google.com/file/d/16qdtjdnMPQt_rJDfSCEwr8sUUO555W4I/view Datavizcatalogue https://datavizcatalogue.com DHL https://www.dpdhl-brands.com/en/dhl/tables-and-charts Elastic https://eui.elastic.co/#/elastic-charts/creating-charts Finastra https://design.fusionfabric.cloud/data-visualization Gitlab https://design.gitlab.com/data-visualization/overview GitLab https://handbook.gitlab.com/handbook/business-technology/data-team/platform/tableau-style-guide/ Goldman Sachs https://design.gs.com/components/charts Google- Material Design https://material.io/design/communication/data-visualization.html Government of Canada https://design.gccollab.ca/data/data-overview/ Human Managed https://www.figma.com/file/jixsiIT7pCeiPMk8oiM6Qb/Data-viz-system?node-id=547%3A12066 Humanitarian Data Exchange HDX https://data.humdata.org/dataviz-guide/dataviz-elements/ International Business Communication Standards (IBCS\u00ae) https://www.ibcs.com/standards IBM https://www.ibm.com/design/v1/language/experience/data-visualization/ IBM https://www.ibm.com/design/language/data-visualization/overview Liferay https://liferay.design/lexicon/core-components/charts/ Mayo Clinic Genomic and Bioinformatic Services https://docs.google.com/document/d/1G1RluXmPC5xhiq8kddKYOOSl4Sqc3UtAHywva9FPh6g/edit London City Intelligence https://data.london.gov.uk/blog/city-intelligence-data-design-guidelines/ MailChimp https://ux.mailchimp.com/patterns/data Microsoft https://docs.microsoft.com/en-us/office/dev/add-ins/design/data-visualization-guidelines MinnPost http://code.minnpost.com/minnpost-styles/ Monash Climate Change  Communication Research Hub  (MCCCRH) https://apo.org.au/node/314650 Morning Star https://designsystem.morningstar.com/charts/chart-elements-status/ NZZ https://nzzdev.github.io/Storytelling-Styleguide/#/ Office for National Statistics https://style.ons.gov.uk/category/data-visualisation/ Opower https://ux.opower.com/opattern/how-to-charts.html Pearson https://accessibility.pearson.com/resources/dataviz/ Pinterest https://gestalt.pinterest.systems/foundations/data_visualization/overview Royal Statistical Society https://rss.org.uk/datavisguide Salesforce https://lightningdesignsystem.com/guidelines/charts/ semrush https://developer.semrush.com/intergalactic/data-display/chart-showcase/chart-showcase Shopify https://polaris.shopify.com/design/data-visualizationst Sonos https://www.agencysr.co.uk/works/data-visualisation-guidelines Sunlight Foundation https://sunlightfoundation.com/2014/03/12/datavizguide Trafford Data Lab https://www.trafforddatalab.io/graphics_companion/ The Economist https://design-system.economist.com/documents/CHARTstyleguide_20170505.pdf The Urban Institute https://urbaninstitute.github.io/graphics-styleguide/ Trafford Data Lab https://www.trafforddatalab.io/interactive_graphics_companion/ U.S. Design System https://designsystem.digital.gov/components/data-visualizations/ US Agency for International Development | Office of HIV/AIDS https://issuu.com/achafetz/docs/oha_styleguide Visa https://developer.visa.com/pages/chart-components VTEX https://styleguide.vtex.com/#/Components/%F0%9F%91%BB%20Experimental/Charts World Health Organization https://apps.who.int/gho/data/design-language/"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#idk","title":"IDK","text":"<ul> <li>Human visual system<ul> <li>detects differences, not absolute values</li> <li>attracted to edges<ul> <li>designer should maximize contrast with background if outlines of shapes are important</li> </ul> </li> <li>perceives surface color base on edge contrast informations</li> <li>higher contrast sensitivity in luminance than in chrominance </li> <li>color recognition is not an automatic process<ul> <li>stoop effect</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#clevelands-visual-operations-of-pattern-perception","title":"Cleveland's Visual Operations of Pattern Perception","text":"<ol> <li>Detection</li> <li>Assembly</li> <li>Estimation</li> </ol>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#gestalt-laws-of-perpetual-organization","title":"Gestalt Laws of Perpetual Organization","text":"<ol> <li>Emergence: mind sees the whole and then the parts. It often sees more than what is specifically states by its individual parts</li> <li>Invariance: mind recognizes simple objects independent of rotation, translation, scale deformations, and lighting</li> <li>Proximity: Elements closer together are perceived to be more related than elements farther apart</li> <li>Similarity: Similar elements that are perceived to be more related than dissimilar elements</li> <li>Enclosure: Elements enclosed together are perceived as belonging together</li> <li>Continuity: Mind tries to continue visual, auditory, and kinetic patterns</li> <li>Closure: Mind perceives set of individual elements as a single, recognizable pattern</li> <li>Symmetry: Mind perceives objects as symmetrical shapes that form around their center</li> <li>Figure-ground: elements are perceived as either figures (objects of focus) or ground (rest of the perceptual field)</li> <li>Connection: Elements connected together (for eg: by a line) are perceived as belonging together</li> <li>Common-fate: Elements that share a common fate (eg: moving in the same direction) are perceived as belonging together</li> </ol>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#tuftes-design-principles-for-graphical-excellence","title":"Tufte\u2019s design principles for graphical excellence","text":"<ol> <li>Maximize the data-ink ratio, within reason</li> <li>Mobilize every graphical element, perhaps several times over, to show the data</li> <li>Maximize data density and the size of the data matrix, within reason</li> <li>Establish context</li> <li>Show cause and effect, where possible</li> <li>Compare and contrast, utilize layering &amp; separation</li> <li>Escape flatland, use small multiples, parallel sequencing (reality is multivariate)</li> <li>Show multiple dimensions</li> <li>Utilize narratives of space and time</li> <li>Integrate image, number and text</li> </ol>"},{"location":"CS_Electives/Data_Mining/06_Data_Visualization/#encoding-methods","title":"Encoding Methods","text":"<p>From most effective to least effective</p> Variable Type Encoding Ordered Position on common scale Position on unaligned scale Length (1D size) Tilt/Angle/Slope Area (2D size) Depth (3D position) Color Luminance Color Saturation Curvature Volume (3D Size) Unordered Spatial region Color hue Motion Shape"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/","title":"Rule-Based Classifier","text":"<p>Knowledge about dataset is stored in the form of if-then rules, in a rule database \\(R\\)</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#rule","title":"Rule","text":"\\[ \\text{LHS} \\to \\text{RHS} \\] LHS RHS Contains Condition/Conjunct with attributes Class label Alternate Names AntecedantPre-Condition Consequent <p>If precondition of rule \\(r\\) matches attributes of record \\(x\\)</p> <ul> <li>\\(r\\) covers \\(x\\)</li> <li>\\(x\\) fires/triggers \\(r\\)</li> </ul>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#quality-of-classification-rule","title":"Quality of Classification Rule","text":"<p>Consider \\(r: A \\to y\\), where</p> <ul> <li>\\(r\\) is the rule</li> <li>\\(A\\) is the antecedent</li> <li>\\(D\\) is the dataset</li> <li>\\(|A|\\) is the number of records covered by rule</li> <li>\\(|D|\\) is the total number of records</li> </ul> Quality Measure Formula Coverage\\((r)\\) Fraction of records covered by rule \\(\\dfrac{\\vert A\\vert}{\\vert  D  \\vert}\\) Accuracy\\((r)\\)Confidence Factor Fraction of records for which the rule correctly predicted \\(\\dfrac{\\vert  A \\cap y \\vert}{\\vert  A  \\vert}\\)"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#steps","title":"Steps","text":"<ol> <li>Find rule(s) that match(es) antecedent of record</li> <li>Next steps:</li> </ol> Number of rules triggered Rules have same class label Steps 0 N/A Add default ruleFallback to default class 1 N/A Assign consequent of rule as class label of test record Multiple \u2705 Assign consequent of rules as class label of test record Multiple \u274c - Use the highest-priority ordered rule (computationally-expensive for training)or- Use majority voting scheme using unordered rules(computationally-expensive for testing)"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#default-rule","title":"Default Rule","text":"\\[ \\underbrace{}_\\text{Empty Antecedant} \\to \\underbrace{y_d}_\\text{Default class} \\]"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#default-class","title":"Default Class","text":"<p>Majority class represented by records not covered by rules in rulebase</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#desired-propertes-of-rule-based-classifier","title":"Desired Propertes of Rule-Based Classifier","text":"Desired Property Meaning Rules are Mutually-Exclusive Only 1 rule is triggered for any record Rules are Exhaustive \\(\\exists \\ge 1\\) rule(s) that covers every record"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#types-of-rules","title":"Types of Rules","text":"Ordered Unordered Priority assigned based on- coverage- accuracy No priority"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#i-missed-15min","title":"I missed 15min","text":""},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#extraction-from-decision-tree","title":"Extraction from Decision Tree","text":"<p>One rule is created for each path from root leaf</p> <p>Keep taking the edges and use \u2018and\u2019 as the conjuction</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#why","title":"Why?","text":"<p>Rules are easier to understand than larger trees</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#sequential-covering-algorithm","title":"Sequential Covering Algorithm","text":"<ol> <li>Start with empy decision list \\(R\\), training records \\(E\\), class \\(y\\)</li> <li>Learn-One-Rule function is used to extract the best rule for class \\(y\\) that covers the current set of training records</li> <li>Remove training records covered by the rule</li> <li>New rule is added to the bottom of the decision list \\(R\\)</li> <li>Repeat Steps 2, 3, 4 until stopping criterion is met</li> <li>Algorithm proceeds to generate rules for the next class</li> </ol> <p>During rule extraction, all training records for class \\(y\\) are considered to be +ve examples, while those that belong to other classes are considered to be -ve examples</p> <p>Rule is desirable such that it covers most of the +ve examples and none/very few -ve examples</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#learn-one-rule-function","title":"Learn-One-Rule Function","text":""},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#general-to-specific","title":"General-to-Specific","text":""},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#initial-seed-rule","title":"Initial Seed Rule","text":"\\[ \\underbrace{\\phantom{\\text{Empty Antecedent}}}_\\text{Empty Antecedent} \\to y_0 \\] <p>Keep refining this initial seed rule, by adding more conjucts</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#specific-to-general","title":"Specific-to-General","text":"\\[ \\text{1 example of } y_0 \\to y_0 \\] <p>Keep refining this initial seed rule, by removing conjucts</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#metrics","title":"Metrics","text":""},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#foil-information-gain","title":"Foil\u2019 Information Gain","text":"<p>First order inductive learner</p> <p>Higher value \\(\\implies\\) better rule</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#likelihood-ratio-statistic","title":"Likelihood Ratio Statistic","text":"<p>Let</p> <ul> <li>\\(k\\) be number of classes</li> <li>\\(f_i\\) be observed frequency of class \\(i\\) examples, that are covered by rule</li> <li>\\(e_i\\) be expected frequency of rule that makes random predictions<ul> <li>Probability of \\(i\\) x Number of records covered by rule</li> </ul> </li> </ul> \\[ \\begin{aligned} R &amp;= 2 \\sum_{i=1}^k \\  f_i \\ \\log_2 \\left(\\frac{f_i}{e_i} \\right) \\\\ e_i &amp;= \\text{Frac}_i \\times n_i \\end{aligned} \\] <p>Higher value \\(\\implies\\) better rule</p>"},{"location":"CS_Electives/Data_Mining/09_Rule-Based_Classifier/#types-of-rule-based-classifier-algorithms","title":"Types of Rule-Based Classifier Algorithms","text":"Direct Indirect Extract rules from data directly other classification models Example - Ripper- CN2- 1R - C4.5 Rules"},{"location":"CS_Electives/Deep_Learning/","title":"Deep Learning","text":""},{"location":"CS_Electives/Deep_Learning/#references","title":"References","text":"<ul> <li> Deep Learning | Dr. Tamizharasan</li> <li> Neural Networks: Zero to Hero | Andrej Karpathy</li> <li> Deep Learning for Computer Vision | Andrej Karpathy | Stanford</li> <li> Full Stack Deep Learning</li> <li> Deep Learning - Deep Understanding | Mike x Cohen</li> <li> MIT 6.S191: Introduction to Deep Learning</li> <li> Deep Learning in Life Sciences | MIT</li> <li> Deep Learning for Physicists | Florian Marquardt</li> <li> Deep Learning Crash Course | Leo Isikdogan</li> <li> Intro to Deep Learning | CMU</li> <li> Deep Learning Systems: Algorithms and Implementation | CMU</li> <li> Stanford</li> <li> Deep Learning Coursera | Andrew Ng</li> <li> Deep Learning | Stanford CS230</li> <li> Deep Learning | VU University Amsterdam</li> <li> Maziar Raissi | Applied Deep Learning</li> <li> Applied Deep Learning 2023 | TU Wien</li> <li> Deep Learning | T\u00fcbingen Machine Learning | Andreas Geiger, 2023</li> <li> Deep Learning | IIT Madras</li> <li> New</li> <li> Old<ul> <li> Part 1</li> <li> Part 2</li> </ul> </li> <li> Deep Learning Concepts (Simply Explained) | Pedram Jahangiry</li> <li> Deep Learning for Economics (Spring 2023) | Harvard</li> <li> Unleashing Novel Data at Scale | Harvard</li> <li> Neural Networks for Machine Learning \u2014 Geoffrey Hinton, UofT</li> <li> CS 152: Neural Networks/Deep Learning\u2014Spring, 2021 | Neil Rhodes</li> <li> Deep Learning for Autonomous Vehicles | MIT</li> <li> Local Explanations for Deep Learning Models</li> <li> Deep Learning (STAT 940) , Fall 2023 | University of Waterloo</li> <li> Deep Learning - F2023  University of Guelph</li> <li> Foundations of Deep Learning | Soheil Feizi | University of Maryland</li> <li> Deep Unsupervised Learning | UC Berkeley</li> <li> Deep Learning | Se Young Yun</li> <li> Geometric Deep Learning | Michael Bronstein | Oxford</li> <li> Deep Learning | Islem Rekik, Basira Lab | Imperial College London</li> <li> Deep Graph Learning | Islem Rekik, Basira Lab | Imperial College London</li> <li> Transformers United | Stanford</li> <li> Neural Networks | Hugo Larochelle | Universit\u00e9 de Sherbrooke</li> <li> Neural Networks | Meerkat Statistics</li> <li> Deep Learning Fundamentals | Lightning.ai</li> <li> Deep Learning | \u00c9cole polytechnique</li> <li> Deep Learning UC Berkeley</li> <li> Deep Learning | TUM</li> <li> Deep Learning | Meanxai<ul> <li> Part 1</li> <li> Part 2</li> </ul> </li> <li> Deep Learning | Nando de Freitas</li> <li> Neural Network Theory | Caltech</li> <li> Deep Learning | Professor Bryce</li> <li> Deep Learning | StatQuest</li> <li> Deep Learning | Alex Smola | UC Berkeley</li> <li> Deep Learning | UC Berkeley</li> <li> Local Explanations for Deep Learning Models | University of Utah</li> <li> Deep Learning | Deepmind x UCL</li> </ul>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/","title":"Deep Learning","text":"<p>Deep Learning is subset of machine learning, which involves a deep neural network. Large availability of data in present-day has led to the rise in demand for deep learning applications.</p> <p>Refer Machine Learning concepts, to understand this course well.</p>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#types","title":"Types","text":"<pre><code>flowchart TB\nDL --&gt; gm[Generative&lt;br/&gt;Models] &amp; ha[Hybrid&lt;br/&gt;Architecture] &amp; dm[Discriminative&lt;br/&gt;Models]\n\ngm --&gt; dbn[Deep&lt;br/&gt;Belief&lt;br/&gt;Networks] &amp; da[Deep&lt;br/&gt;Autoencoder] &amp; dbm[Deep&lt;br/&gt;Boltzmann&lt;br/&gt;Machine]\n\nha --&gt; dnn[Deep&lt;br/&gt;Neural&lt;br/&gt;Networks]\n\ndm --&gt; cnn[Convolutional&lt;br/&gt;Neural&lt;br/&gt;Network] &amp; dsn[Deep&lt;br/&gt;Stacking&lt;br/&gt;Networks]</code></pre>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#applications-of-dl","title":"Applications of DL","text":"<ul> <li>Object detection/counting</li> <li>Image/Video</li> <li>classification</li> <li>segmentation</li> <li>captioning</li> <li>sentence matching</li> <li>face recognition</li> <li>Natural language processing</li> <li>At the time of writing this sentence, ChatGPT\u2019s successor GPT4 has come out, and it looks pretty insane</li> </ul>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#advantages","title":"Advantages","text":"<ol> <li>Flexible</li> <li>Automatic</li> <li>Robust</li> <li>Generalizable</li> <li>Parallelizable \\(\\implies\\) Scalable</li> </ol>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#disadvantages","title":"Disadvantages","text":"<ol> <li>Low interpretability (Black box)</li> <li>Too many hyperparameters</li> <li>Tend to overfit; poor generalizability</li> <li>Require lot of data</li> <li>Computationally-expensive wrt to Resource Constraints</li> </ol>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#resource-constraints","title":"Resource Constraints","text":"<ol> <li>Processor Speed</li> <li>Memory Size</li> <li>Power Consumption</li> </ol>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#challenges","title":"Challenges","text":"<ul> <li>Difficult for generalization</li> <li>Difficult for efficient optimization</li> <li>Lack of adequate data (addressed through Transfer Learning, Shallow learning, Incremental learning)</li> <li>Data inconsistencies</li> <li>Low battery life of edge devices (h/w controlling data flow at boundary b/w 2 networks)</li> <li>Resource-constrained algorithm development issues</li> <li>Diversity in computing units</li> <li>Privacy &amp; security concerns (addressed through Encryption)</li> </ul>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#why-deep-learning","title":"Why Deep Learning?","text":"<ul> <li>Deep networks can represent complex functions with fewer parameters</li> <li>Each layer of the network learns a \u201crepresentation\u201d</li> </ul>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#image-representation","title":"Image Representation","text":"<p>Every images is a matrix of pixels, where each pixel is represented as a combination of red, green, blue; usually as a 8-bit value (0-255)</p> <p>So if the width and height of image are \\(w, h\\)</p>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#key-metrics","title":"Key Metrics","text":"<ul> <li>Accuracy</li> <li>Throughput</li> <li>Latency</li> <li>Energy efficiency</li> <li>Hardware costs</li> <li>Flexibility</li> </ul>"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#popular-datasets","title":"Popular Datasets","text":"Dataset Sample Size Content Classes MNIST 50,000 Images of handwritten digits (0-9) 10 CIFAR 60,000 Airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks 10 ImageNet"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#transfer-learning","title":"Transfer Learning","text":"......... SimilaritySize Similar Different Little Linear Classifier on FC7 Not optimal Large Finetune few layers Finetune more layers"},{"location":"CS_Electives/Deep_Learning/01_Introduction/#why-deep-learning_1","title":"Why Deep Learning?","text":"<p>Deep networks</p> <ol> <li>empirically work better for a given parameter count</li> <li>provably more efficient at representing functions that neural networks cannot actually learn (such as odd/even parity)</li> </ol>"},{"location":"CS_Electives/Deep_Learning/02_ANN/","title":"Artificial Neural Networks","text":"<p>A neural network refers to a type of hypothesis class containing multiple, parameterized differentiable functions (layers) composed together in a manner to map the input to the output</p> <p>It is made of layers of neurons, connected in a way that the input of one layer of neuron is the output of the previous layer of neurons (after activation)</p> <p>They are loosely based on how our human brain works: Biological structure -&gt; Biological function</p> <p></p> <p>You can think of a neural network as combining multiple non-linear decision surfaces into a single decision surface.</p> \\[ \\hat y = w \\times \\phi(x) \\] <p>where \\(\\phi\\) is a non-linear function</p> <p>Neural networks can be thought of \u2018learning\u2019 (and hence optimizing loss by tweaking)</p> <ul> <li>features (instead of manual feature specification)</li> <li>parameters</li> </ul>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#universal-function-approximation","title":"Universal Function Approximation","text":"<p>A 2 layer ANN is capable of approximate any function over a finite subset of the input space</p> <p>Catch: The size of NN should be equal to number of datapoints</p> <p>Over-exaggerated property; same property is shared by Nearest Neighbors and splines, but no one cares</p>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#artificial-neuron","title":"Artificial Neuron","text":"<p>Most basic unit of an artificial neural network</p>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#tasks","title":"Tasks","text":"<ol> <li>Receive input from other neurons and combine them together</li> <li>Perform some kind of transformation to give an output. This transformation is usually a mathematical combination of inputs and application of an activation function.</li> </ol>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#visual-representation","title":"Visual representation","text":""},{"location":"CS_Electives/Deep_Learning/02_ANN/#mp-neuron","title":"MP Neuron","text":"<p>McCulloch Pitts Neuron</p> <p>Highly simplified compulational model of neuron</p> <p>\\(g\\) aggregates inputs and the function \\(f\\) and gives \\(y \\in \\{ 0, 1 \\}\\)</p> \\[ \\begin{aligned} y &amp;= f \\circ g \\ (x) \\\\ &amp;= f \\Big( g (x) \\Big) \\end{aligned} \\] \\[ y = \\begin{cases} 1, &amp; \\sum x_i \\ge \\theta \\\\ 0, &amp; \\text{otherwise} \\end{cases} \\] <ul> <li>\\(\\sum x_i\\) is the summation of boolean inputs</li> <li>\\(\\theta\\) is threshold for the neuron</li> </ul>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#limitation","title":"\u274c Limitation","text":"<p>MP neuron can be used to represent linearly-separable functions</p>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#perceptron","title":"Perceptron","text":"<p>MP neuron with a mechanism to learn numerical weights for inputs</p> <p>\u2705 Input is no longer limited to boolean values</p> \\[ \\begin{aligned} y &amp;= \\begin{cases} 1, &amp; \\sum w_i x_i \\ge \\theta \\\\ 0, &amp; \\text{otherwise} \\end{cases} \\\\ \\Big( x_0 &amp;= 1, w_0 = -\\theta \\Big) \\end{aligned} \\] <ul> <li>\\(w_i\\) is weights for the inputs</li> </ul>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#key-terms-for-logic","title":"Key Terms for Logic","text":"<ul> <li>Pre-Activation (Aggregation)</li> <li>Activation (Decision)</li> </ul>"},{"location":"CS_Electives/Deep_Learning/02_ANN/#perceptron-learning-algorithm","title":"Perceptron Learning Algorithm","text":""},{"location":"CS_Electives/Deep_Learning/02_ANN/#perceptron-vs-sigmoidal-neuron","title":"Perceptron vs Sigmoidal Neuron","text":"Perceptron Sigmoid/Logistic Type of line Step Graph Gradual Curve Smooth Curve? \u274c \u2705 Continuous Curve? \u274c \u2705 Differentiable Curve? \u274c \u2705"},{"location":"CS_Electives/Deep_Learning/02_ANN/#general-form","title":"General Form","text":"\\[ \\begin{aligned} w_{ij}^{(l)} &amp;= \\begin{cases} l \\in [1, L] &amp; \\text{layers} \\\\ i \\in [0, d^{(l-1)}] &amp; \\text{inputs} \\\\ j \\in [1, d^{(l)}] &amp; \\text{outputs} \\end{cases} \\\\ x_{j}^{(l)} &amp;= \\sigma(s_j^{(L)}) \\\\ &amp;= \\sigma \\left( \\sum_{i=0}^{d^{(l-1)}} w_{ij}^{(l)} x_i^{(l-1)} \\right) \\end{aligned} \\]"},{"location":"CS_Electives/Deep_Learning/02_Architectures/","title":"Architectures","text":"Purpose Meaning MajorApplication ComputationComplexity Limitation Advantage Linear Combinations FCFully-Connected Poor scalability for large input sizesDo not capture \u201cintuitive\u201d invariances Spatial pattens CNN(Convolutional) - Require that activations between layers occur only in \u201clocal\u201d manner- Treat hidden layers themselves as spatial images- Share weights across all spatial locations Images, Videos High Reduce parameter countCapture [some] \u201cnatural\u201d invariances Temporal(Sequences) RNN(Recurrent) Forward-feed, backward-feed, and self-loop is allowed Time Series GRU Time Series LSTM Time Series Transformer Text Generation IDK ResNet(Residual Network) Add operator Time Series DenseNet Concat operator U-Net Basis of diffusion modelsSegmentationSuper-ResolutionDiffusion Models PINN(Physics-Informed) Lagrangian Deep Operator Fourier Neural Operator Graph Neural Networks"},{"location":"CS_Electives/Deep_Learning/02_Architectures/#idk","title":"IDK","text":""},{"location":"CS_Electives/Deep_Learning/02_Architectures/#note","title":"Note","text":"<p>skip connections of inputs</p> <ul> <li>For structured problems<ul> <li>DenseNet architecture</li> <li>The raw inputs may possess more meaningful information than the linear/non-linear combination</li> <li>Include concat of non-linear transformations, rather than pre-computing these transformations</li> </ul> </li> <li>For unstructured problems<ul> <li>ResNet is better</li> </ul> </li> </ul>"},{"location":"CS_Electives/Deep_Learning/03_Activation_Functions/","title":"Activation Functions","text":"Name Activation\\(f(x)\\) Inverse Activation\\(f^{-1} (y)\\) Output Type Range Free fromVanishing Gradients Zero-Centered Comment Identity \\(x\\) \\(y\\) Continuous \\([-1, 1]\\) \u2705 BinaryStep \\(\\begin{cases} 0, &amp;x &lt; 0 \\\\ 1, &amp; x \\ge 0 \\end{cases}\\) Binary \\({0, 1}\\) \u274c Tariff/Tanh \\(\\tanh(x)\\) \\(\\tanh^{-1}(y)\\) Discrete \\([-1, 1]\\) \u274c \u2705 Fast Softsign Tahn \\(\\dfrac{x}{1 + \\vert x \\vert}\\) ArcTan \\(\\tan^{-1} (x)\\) \\(\\tan(y)\\) Continuous \\((-\\pi/2, \\pi/2)\\) Exponential \\(e^x\\) \\(\\ln(y)\\) Continuous \\([0, \\infty]\\) ReLU (RectifiedLinear Unit) \\(\\begin{cases} 0, &amp;x &lt; 0 \\\\ x, &amp; x \\ge 0 \\end{cases}\\) Continuous \\([0, \\infty]\\) \u2705 \u274c \u2705 Computationally-efficient\u274c Discontinuous at \\(x=0\\)\u274c Dead neurons due to poor initialization, high learning rate; initialize with slight +ve bias SoftPlus(smooth alt to ReLU) \\(\\dfrac{1}{k} \\ln \\Bigg \\vert 1 + \\exp \\{ {k (x-x_0)} \\} \\Bigg \\vert\\) \\(\\ln(e^y-1)\\)\\(k ?\\) Continuous \\([0, \\infty]\\) \u274c Parametric/Leaky ReLU \\(\\begin{cases} \\alpha x, &amp;x &lt; 0 \\\\ x, &amp; x \\ge 0 \\end{cases}\\) Continuous \\([-\\infty, \\infty]\\) \u2705 \u2705 All positives of ReLU ExponentialLinear Unit \\(\\begin{cases} \\alpha (e^x-1), &amp;x &lt; 0 \\\\ x,&amp;  x \\ge 0 \\end{cases}\\) Continuous \\([-\\infty, \\infty]\\) \u2705 \u274c \\(\\exp\\) is computationally-expensive; though not significant in large networks Maxout \\(\\max(w_1 x + b_1, w_2 x + b_2)\\) \u2705 \u2705 Generalization of ReLU and Leaky ReLU\u274c double the no of parameters Generalized Logistic \\(a + (b-a) \\dfrac{1}{1+e^{-k(x-x_0)}}\\)\\(a=\\) minimum\\(b=\\) maximum\\(k=\\) steepness\\(x_0 =\\) \\(x\\) center \\(\\ln \\left \\vert \\dfrac{x-a}{b-x} \\right \\vert\\)what about \\(k\\) Continuous \\([a, b]\\) Depends on \\(a\\) and \\(b\\) \u274c \u274c \\(\\exp\\) is computationally-expensive; though not significant in large networks\u2705 Easy to interpret- \"probabilistic\"- saturating \"firing rate\" of neuron Sigmoid/Standard Logistic/Soft Step \\(\\dfrac{1}{1+e^{-x}}\\) \\(\\ln \\left \\vert \\dfrac{x}{1-x} \\right \\vert\\) Binary-Continuous \\([0, 1]\\) \u274c \u274c \\(\\exp\\) is computationally-expensive; though not significant in large networks\u2705 Easy to interpret- \"probabilistic\"- saturating \"firing rate\" of neuron Fast Softsign Sigmoid \\(0.5 \\Bigg( 1+\\dfrac{x}{1 + \\vert x \\vert} \\Bigg)\\) Softmax \\(\\dfrac{e^{x_i}}{\\sum_{j=1}^k e^{x_j}}\\)where \\(k=\\) no of classessuch that \\(\\dfrac{\\sum p_i}{k} = 1\\) Discrete-Continuous \\([0, 1]\\) \u274c Softmax with Temperature \\(\\dfrac{e^{x_i/{\\small T}}}{\\sum_{j=1}^k e^{x_j/{\\small T}}}\\) Discrete-Continuous \u274c Exposes more \u201cdark knowledge\u201d"},{"location":"CS_Electives/Deep_Learning/03_Activation_Functions/#softmax-with-temperature","title":"Softmax with temperature","text":""},{"location":"CS_Electives/Deep_Learning/03_Activation_Functions/#why-use-activation-function-for-hidden-layers","title":"Why use activation function for hidden layers?","text":"<p>Else, it would just be regular linear regression/logistic regression, so no point of hidden layers</p> <p>Not using activation function \\(\\implies\\) using identity activation function</p> <p>The only place identity activation function is acceptable is for the final output activation function in regression.</p>"},{"location":"CS_Electives/Deep_Learning/03_Activation_Functions/#linear-regression","title":"Linear Regression","text":"<pre><code>flowchart LR\na((x1)) &amp; b((x2)) --&gt;\nd((h1)) &amp; e((h2)) --&gt;\ny((\"&amp;ycirc;\"))</code></pre> \\[ \\begin{aligned} \\hat y &amp;= w_{h_1 \\hat y} h_1 + w_{h_2 \\hat y} h_2 \\\\ &amp;= w_{h_1 \\hat y} (w_{x_1 h_1} x_1 + w_{x_2 h_1} x_2) + w_{h_2 \\hat y} (w_{x_1 h_2} x_1 + w_{x_2 h_2} x_2) \\\\ &amp;= \\cdots \\\\ &amp;= w_1 x_1 + w_2 x_2 \\end{aligned} \\]"},{"location":"CS_Electives/Deep_Learning/03_Activation_Functions/#logistic-regression","title":"Logistic Regression","text":"<pre><code>flowchart LR\na((x1)) &amp; b((x2)) --&gt;\nd((h1)) &amp; e((h2)) --&gt;\ns((\"&amp;sigma;\")) --&gt;\ny((\"&amp;ycirc;\"))</code></pre> \\[ \\begin{aligned} \\hat y &amp;= \\sigma(w_{h_1 \\hat y} h_1 + w_{h_2 \\hat y} h_2) \\\\ &amp;= \\sigma(w_{h_1 \\hat y} (w_{x_1 h_1} x_1 + w_{x_2 h_1} x_2) + w_{h_2 \\hat y} (w_{x_1 h_2} x_1 + w_{x_2 h_2} x_2)) \\\\ &amp;= \\cdots \\\\ &amp;= \\sigma(w_1 x_1 + w_2 x_2) \\end{aligned} \\]"},{"location":"CS_Electives/Deep_Learning/03_Activation_Functions/#why-is-non-zero-centering-bad","title":"Why is non-zero-centering bad?","text":"<p>Since Non-zero-centered activation function such as sigmoid always outputs +ve values, it constrains gradients of all parameters to be - all +ve   or - all -ve</p> <p>This leads to sub-optimal steps (zig-zag) in the update procedure, leading to slower convergence</p>"},{"location":"CS_Electives/Deep_Learning/03_Fully_Connected/","title":"Fully Connected Networks","text":""},{"location":"CS_Electives/Deep_Learning/03_Fully_Connected/#mlp","title":"MLP","text":"<p>Multi-Layer Perceptron</p> <p>Simple neural network with 3 Layers</p> <pre><code>flowchart LR\n\nx1 &amp; x2 --&gt;\nh1 &amp; h2 &amp; h3 &amp; h4 --&gt;\ny\n\nsubgraph il[Input&lt;br /&gt;Layer]\n    x1 &amp; x2\nend\n\nsubgraph hl[Hidden&lt;br /&gt;Layer]\n    h1 &amp; h2 &amp; h3 &amp; h4\nend\n\nsubgraph ol[Output&lt;br /&gt;Layer]\n    y\nend</code></pre> <p>For an input layer with \\(n\\) nodes, we will have</p> <ul> <li>1 output</li> <li>\\(2^n\\) nodes in hidden layer</li> </ul>"},{"location":"CS_Electives/Deep_Learning/03_Fully_Connected/#feed-forward","title":"Feed-Forward","text":"<p>NN (with \\(&gt; 3\\) layers) where every layer feeds forward to the next layer; backward/self-loop is not allowed</p> <p>For an input layer with \\(n\\) nodes, we will have</p> <ul> <li> \\[   hidden layers =    \\] </li> <li> <p>\\(W_i\\) is the weights to layer \\(i\\)</p> </li> </ul> \\[ \\begin{aligned} \\textcolor{hotpink}{\\text{PreActivation}_{H_1}} &amp;= b_1 + w_1 x_1 + w_2 x_2 + \\dots \\\\ \\text{Activation}_{H_1} &amp;= \\frac{1}{1 + e^{- \\textcolor{hotpink}{\\text{PreActivation}_{H_1}}}} \\end{aligned} \\]"},{"location":"CS_Electives/Deep_Learning/03_Fully_Connected/#decision-boundary","title":"Decision Boundary","text":"Hidden Layers Shape of Region 0 Open 1 Closed/Open \\(\\ge 2\\) Closed <p>As you increase the number of hidden layers, the possibility of open decision boundary decreases (which is good).</p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/","title":"Sequence Models","text":"<p>Consider a phenomenon where an observation is determined by its past values, eg: any time series variable, such as weather, precipitation, etc.</p> \\[ p(x) = p(x_1) \\cdot p(x_2 | x_1) \\ldots p(x_t | x_1, \\dots, x_{t\u22121}) \\]"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#why-not-regular-ann","title":"Why not regular ANN?","text":"<ol> <li>ANN requires fixed number of input &amp; output neurons. </li> <li>However, with sequential data, we do not know the length of the input</li> <li>theoretically, we could convert all inputs to fixed size by padding shorter sentences, but this is infeasible</li> <li>ANN does not care about order of input</li> </ol>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#memoryless-models","title":"Memoryless Models","text":""},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#auto-regressive-model","title":"Auto-Regressive Model","text":"<p>Predict next term in a sequence from a fixed number of previous terms using \u2018delay taps\u2019</p> <p></p> \\[ p(x_t | x_1, ..., x_{t\u22121}) = p\\Big(x_t | f (x_1, ...x_{t\u22121}) \\Big) \\]"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#markov-assumption-based-auto-regressive-model","title":"Markov Assumption-based Auto-Regressive Model","text":"<p>Assume that only a limited past upto time period \\(\\tau\\) affects the present value</p> <p></p> \\[ \\begin{aligned} p(x_t | x_1, ...x_{t\u22121}) &amp;= p\\Big(x_t | f (x_{t\u2212\u03c4}, \\dots, x_{t\u22121}) \\Big) \\\\ \\implies \\hat x &amp;= f(x_{t-\\tau}, \\dots, x_{t-1} ) \\end{aligned} \\] <p>We predict the next step and iterate.</p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#feed-forward-network","title":"Feed-Forward Network","text":"<p>Generalized auto-regressive models with one/more layers of non-linear hidden units</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#memory-models","title":"Memory Models","text":"<p>Generative models</p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#linear-dynamic-systems-stochastic","title":"Linear Dynamic Systems (Stochastic)","text":"<p>Real-valued hidden state that cannot be observed directly</p> <p>Hidden state has linear dynamics with Gaussian noise and produces the observations using a linear model with Gaussian noise. However, there may also be driving inputs.</p> <p>A linearly transformed Gaussian is a Gaussian. So the distribution over the hidden state given the data so far is Gaussian. It can be computed using \u201cKalman filtering\u201d.</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#hidden-markov-models-stochastic","title":"Hidden Markov Models (Stochastic)","text":"<p>have a discrete one-of-N hidden state</p> <p>Transitions between states are stochastic and controlled by a transition matrix. The outputs produced by a state are stochastic. We cannot be sure which state produced a given output. So the state is \u201chidden\u201d. It is easy to represent a probability distribution across N states with N numbers.</p> <p>To predict the next output we need to infer the probability distribution over hidden states. HMMs have efficient algorithms for inference and learning.</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#limitations","title":"Limitations","text":"<p>At each time step it must select one of its hidden states. So with N hidden states it can only remember \\(\\log(N)\\) bits about what it generated so far.</p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#latent-variable-modelrnn-deterministic","title":"Latent Variable Model/RNN (Deterministic)","text":"<p>layered, feed-forward net with shared weights</p> <p>Next page</p>"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#language-modelling","title":"Language Modelling","text":"<p>Inputs are tokens, not necessarily real numbers</p> \\[ p(w_1, w_2, \\dots, w_T) = \\Pi_{t=1}^T \\ p(w_t|w_1,...,w_{t\u22121}) \\] <p>For eg: Consider the sentence <code>Statistics is fun.</code> We can model it as:</p> \\[ \\begin{aligned} p(\\text{Statistics, is, fun, . }) &amp;= p(\\text{Statistics}) \\\\ &amp; \\times p(\\text{is | Statistics})\\\\ &amp; \\times p(\\text{fun | Statistics, is}) \\\\ &amp; \\times p( . | \\text{Statistics, is, fun}) \\end{aligned} \\] \\[ \\hat p(\\text{is|Statistics}) = \\frac{n \\text{(Statistics is)}}{n \\text{(Statistics)}} \\]"},{"location":"CS_Electives/Deep_Learning/03_Sequence_Models/#applications","title":"Applications","text":"<p>Named Entity Tagging is when we identify the entities in a input sequence. For eg: Kelly worked at Google; Kelly is a person and Google is an organization.</p>"},{"location":"CS_Electives/Deep_Learning/03_Training/","title":"IDK","text":""},{"location":"CS_Electives/Deep_Learning/03_Training/#optimization","title":"Optimization","text":"<p>Refer to Optimization Algorithms</p>"},{"location":"CS_Electives/Deep_Learning/03_Training/#regularization","title":"Regularization","text":""},{"location":"CS_Electives/Deep_Learning/03_Training/#dropout","title":"Dropout","text":""},{"location":"CS_Electives/Deep_Learning/03_Training/#regular-dropout","title":"Regular Dropout","text":"<p>May lead to missing relevant information, since sequential part may involve variable-length inputs</p>"},{"location":"CS_Electives/Deep_Learning/03_Training/#variational-dropout","title":"Variational Dropout","text":"<p>IDK</p>"},{"location":"CS_Electives/Deep_Learning/03_Training/#zoneout","title":"Zoneout","text":"<p>Skip hidden state update and keep the same as previously during training</p> \\[ h_t = h_{t\u22121} \\] <p></p> <ul> <li>Robustness against skipping observations in sequence</li> <li>Robustness of state representation relative to hidden state updates</li> </ul>"},{"location":"CS_Electives/Deep_Learning/03_Training/#dropconnect","title":"DropConnect","text":""},{"location":"CS_Electives/Deep_Learning/03_Training/#parameter-averaging","title":"Parameter Averaging","text":"<p>Train RNN and average weights over run</p>"},{"location":"CS_Electives/Deep_Learning/03_Training/#stochastic-weight-averaging","title":"Stochastic Weight Averaging","text":"<p>Parameter averaging + Continuously varying learning rate</p>"},{"location":"CS_Electives/Deep_Learning/03_Training/#fraternal-dropout","title":"Fraternal Dropout","text":"<p>Dropout while minimizing variation between outputs to increase robustness to parameterization</p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/","title":"Convolutional Neural Networks","text":"<p>Convolutional Neural Networks is a type of architecture that exploits special properties of image data and are used in computer vision applications.</p> <p>Convolution intuition: efficient \"loop\" that allows us to forward linear layers over space</p> <p>Images are a 3-dimensional array of features: each pixel in the 2-D space contains three numbers from 0\u2013255 (inclusive) corresponding to the Red, Green and Blue.</p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#intuition","title":"Intuition","text":"<ul> <li>Low-level/frequency features</li> <li>Medium-level/frequency features</li> <li>High-level/frequency features</li> <li>Logits</li> </ul>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#components","title":"Components","text":"<ul> <li>Conv layer</li> <li>Activation function (usually ReLU)</li> <li>Pooling</li> <li>Fully-connected</li> </ul> <p>The first important type of layer that a CNN has is called the Convolution (Conv) layer. It uses parameter sharing and applies the same smaller set of parameters spatially across the image. - Number of filters is usually chosen as powers of 2, as many libraries handle these dimensions more efficiently. - Size of filters is usually odd, as they have an integer center</p> <p>Essentially the parameters (i.e. weights) associated to the input remain the same but the input itself is different as the layer computes the output of the neurons at different regions of the image.</p> <p>Hyperparameters of conv layers are  - Filter size - corresponds to how many input features in the width and height dimensions one neuron takes in - Stride - how many pixels we want to move (towards the right/down direction) when we apply the neuron again</p> <p>Then we have the pooling layer. The purpose of the pooling layer is to reduce the spatial size (width and height) of the layers. This reduces the number of parameters (and thus computation) required in future layers.</p> <p>We use a fully connected layers at the end of our CNNs. When we reach this stage, we can flatten the neurons into a one-dimensional array of features.</p> <p></p> <p></p> <p>We control output shape via padding, strides and channels</p> <p>Very nice Youtube explanations. Watch this!</p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#advantages","title":"Advantages","text":"<ul> <li>Universal visual feature extractor</li> <li>Can be used as building blocks in conjunction with architectures such as RNN/FCNN for complex tasks</li> </ul>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#disadvantages","title":"Disadvantages","text":"<ul> <li>High computational cost</li> <li>Large data requirements</li> </ul>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#variables-in-this-page","title":"Variables in this page","text":"Variable Meaning \\(I\\) Input matrix \\(i\\) Size of input matrix \\(f\\) Size of filter matrix \\(p\\) Padding applied to input matrix (default=0) \\(s\\) Stride length \\(n\\) no of filters \\(c\\) no of channels- Grayscale: 1- Color: 3 \\(b\\) Bias"},{"location":"CS_Electives/Deep_Learning/04_CNN/#principles","title":"Principles","text":"<ul> <li>Translation invariance</li> <li>Locality</li> </ul>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#types-of-layers","title":"Types of Layers","text":"Convolutional Layer Pooling Layer Purpose Extracting spatially-invariant featuresControl output shape via padding, strides and channelsEdge DetectionImage Sharpening Gradually reduce spatial resolution of hidden representationsSome degree of invariance to translationImage size reduction, without much data lossImage Sharpening Operation Cross-Correlation Pooling Representation$O = $ \\(I \\star F + b\\)\\(\\sum (I \\star F + b)\\) (multiple channels) \\(O_{i, j} =\\) \\(\\sum_{k=1}^f \\sum_{l=1}^f F_{k, l} \\odot  I_{i+k, j+l} + b\\) \\(\\sum_{k=1}^f \\sum_{l=1}^f \\text{func}(F_{k, l} \\odot  I_{i+k, j+l})\\) Steps tocalculate 1. Perform padding2. Start from the left3. Place kernel filter over input matrix(if there are multiple channels, place each filters over corr matrix)4. Output value of one element = sum of products + Bias(if there are multiple channels, then sum of product of all the channels result in one single value)5. Perform stride rightward6. Repeat steps 3-5, until there are no remaining columns on the right7. Repeat steps 2-6, until there are no remaining rows on the left 1. Start from the left2. Place filter over input matrix3. Output value of one element = func(product of elements), where func = max, min, avg4. Perform stride rightward5. Repeat steps 3-5, until there are no remaining columns on the right6. Repeat steps 2-5, until there are no remaining rows on the left Defaultstride length 1 \\(f\\) Size ofoutput \\(\\dfrac{i-f \\textcolor{hotpink}{+2p}}{s} + 1\\) \\(\\dfrac{i-f}{s} + 1\\) When Applied First Only after convolutional layer CommonPaddingValue \\(f-1\\) 0 CommonStrideValue 1 1 No ofinput channels \\(c\\) 1 No of outputimages \\(n\\) 1 No ofoutput channels per output image 1 1 \\[ \\text{Total output dimension } o' = o \\times n \\times c \\]"},{"location":"CS_Electives/Deep_Learning/04_CNN/#depthwise-separable-convolution","title":"Depthwise Separable Convolution","text":"<p>Fewer multiplications</p> <ol> <li>Perform convolution for each channel separately</li> <li>Perform convolution of the outputs of step 1</li> </ol> \\[ \\begin{aligned} \\text{Improvement} &amp;= \\dfrac{\\text{No of operations in Depthwise Separable}}{\\text{No of operations in Standard Conv}} \\\\ &amp;= \\dfrac{1}{\\text{No of filters}} + \\dfrac{1}{\\text{Filter Dimensions}^2} \\end{aligned} \\]"},{"location":"CS_Electives/Deep_Learning/04_CNN/#notes","title":"Notes","text":"<ul> <li>Convolution and cross-correlation operations are slightly different, but it doesn\u2019t matter if kernel is symmetric</li> <li>Since images are of different sizes, instead of using weight matrix of fixed size, convolution is applied various times depending on size of input</li> <li>1 x 1 Convolutional Layer doesn\u2019t recognize spatial patterns, but fuses channels</li> <li>\\(\\times\\) is not multiplication; it is depth/no of activation maps</li> </ul>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#example","title":"Example","text":"<p>The following shows convolution on with 0 padding and stride 1.</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#convolutional-layer","title":"Convolutional Layer","text":"<p>Each filter in the conversation layer produces an \u201cactivation map\u201d</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#padding-striding","title":"Padding &amp; Striding","text":"Padding Striding Meaning Number of extra row(s) and columns added around matrixIf \\(p =\\) odd, then pad \\(\\lceil p/2 \\rceil\\) on one side and \\(\\lfloor p/2 \\rfloor\\) on the other Step length in movement of kernel filter on input image Purpose Overcome loss of pixels, by increasing effective image size Zero padding means padding using 0s"},{"location":"CS_Electives/Deep_Learning/04_CNN/#operations","title":"Operations","text":"Padding Pooling Aggregate information Striding Depth-wise/Grouped Group together channels so that groups of channels in output only depend on corresponding groups of channels in inputEnforce filter weight matrices to be block-diagonal Dilations Dilate convolution filter so that it covers more of the imageRequires padding to ensure same size as input"},{"location":"CS_Electives/Deep_Learning/04_CNN/#derivative","title":"Derivative","text":"<p>Adjoint $$ \\begin{aligned} \\bar v \\dfrac{\\partial \\text{conv}(x, W)}{\\partial x} &amp;= \\text{conv}(\\bar v, \\text{flip}(w)) \\ \\bar v \\dfrac{\\partial \\text{conv}(x, W)}{\\partial W} &amp;=  \\end{aligned} $$</p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#common-filters","title":"Common Filters","text":"Application Filter Used Vertical edges detection \\(\\begin{bmatrix}1 &amp; 0 &amp; -1 \\\\ 1 &amp; 0 &amp; -1 \\\\ 1 &amp; 0 &amp; -1\\end{bmatrix}\\) Horizontal edge detection \\(\\begin{bmatrix}1 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ -1 &amp; -1 &amp; -1\\end{bmatrix}\\) Blur <p>Edge-Detection example</p> <p></p> <p>Smoothing</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#advanced-cnn","title":"Advanced CNN","text":"RCNN Fast-RCNN Faster RCNN Major idea Region-Based Do not recompute features for every box independently Integrate bounding box proposals in CNN predictions Steps 1. Generate category-independent region proposals (~2k)2. Compute 4096-dimensional CNN feature vector from each region proposal3. Classify regions w/ class-specific linear SVMs 1. Produce single convolutional feature map with several convolutional &amp; max-pooling layers 2. Region of interest (RoI) pooling layer extracts fixed-length feature vector from region feature map 1. Compute proposals with a deep convolutional Region Proposal Network (RPN)2. Merge RPN and Fast-RCNN into a single network Advantages SimpleImproved mAP compared to RNN Higher mAPSingle end-to-end training stageNo disk storage required Cost-free region proposalsOne network optimizing four losses- RPN classification (anchor good/bad)- RPN regression (anchor -&gt; proposal)- Fast RCNN classification (over classes)- Fast RCNN regression (proposal -&gt; box) Disadvantages Slow inference: full forward pass of CNN for each regionMultistage pipelineDisk storage required for feature cachingTraining is expensiveClassifiers &amp; regressors are post-hoc: CNN features are not updated in response to classifier and regressor Proposals generation is computationally expensive Flowchart"},{"location":"CS_Electives/Deep_Learning/04_CNN/#yolo","title":"YOLO","text":"<p>You Only Look Once</p> <p>Single CNN</p> <p>No proposal for bounding box</p> <p>Treat this as a single regression (not classification), straight from images pixels to bounding box coordinates and class probabilities</p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#steps","title":"Steps","text":"<ol> <li>Residual block</li> <li>Input split into 7x7 grids</li> <li>Each cell trains a detector<ol> <li>Detector needs to predict object\u2019s class distributions</li> <li>detector has 2 bounding box predictor to predict bounding box and confidence scores</li> </ol> </li> <li>Generate probability for each grid having an object</li> <li>Confidence Score = probability * IOU</li> <li>Bounding box regression</li> <li>IoU (Intersection over Union)</li> <li>Non-max supression</li> </ol>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#non-max-supression","title":"Non-Max Supression","text":"<pre><code>Algorithm Non-Max Supression\n    Input: A list of proposal boxes B, corresponding confidence scores S and overlap threshold N\n    Output:\n        List of filtered proposals D\n\n    select proposal with highest confidence score, remove it from B and add it to the fnal proposal list D\n    Compare IOU of this proposal with all the proposal. If IOU &gt; N, remove proposal from B\n\n    more steps are there\n</code></pre>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#popular-architectures","title":"Popular Architectures","text":"Architecture Name Description LeNet-5 Recognizing handwritten digits AlexNet VGGNet DenseCap Image captioning SqueezeNet GoogLeNet Inception Modules (Network inside a network) DCNN ResNet CUImage SENet &amp; SE-ResNet"},{"location":"CS_Electives/Deep_Learning/04_CNN/#visualization-of-conv-layer","title":"Visualization of Conv layer","text":"<ul> <li>Visualize patches (images) that maximally activate neurons</li> <li>Visualize raw weights of filters/kernels<ul> <li>only interpretable on the first conv layer</li> </ul> </li> <li>Visualize representation space from last FC layer before classifier (t-SNE)</li> <li>Occlusion experiments<ul> <li></li> <li>as a function of position of blank pixels</li> </ul> </li> <li>Human experiment comparisons</li> <li>Visualize activations<ul> <li>Deconv approaches (single backward pass)<ol> <li>Feed image into network</li> <li>Forward pass until interested neuron</li> <li>Set the gradient of the interested neuron to be 1.0, and all other neurons of the layer to be 0.0</li> <li>Backward pass to the image<ul> <li>Default backprop<ul> <li></li> </ul> </li> <li>Guided backprop<ul> <li></li> <li>Only let the gradients of the neurons with +ve activations and +ve gradients to pass</li> </ul> </li> <li>Deconvnet<ul> <li>Change the backward pass of ReLU: Only let the gradients of the neurons with +ve gradients to pass</li> </ul> </li> </ul> </li> </ol> </li> <li>Optimization over image approaches (optimization): Find an image that maximizes the class score<ol> <li>Feed in zeros to the network</li> <li>Set gradient of scores vector to all 0.0, except the interested class's gradient which is to be 1.0<ol> <li>This can be extended to arbitrary neuron</li> </ol> </li> <li>Backward pass to the image</li> <li>Do a small \"image update\"</li> <li>Forward the new image to the network</li> <li>Objective function<ul> <li>\\(\\arg \\max_{I} S_c(I) - \\lambda \\vert \\vert I \\vert \\vert_2^2\\)</li> <li>\\(\\arg \\max_{I} S_c(I)\\)<ul> <li>but blur image after every update</li> <li>take any pixel with small norm to zero (to encourage sparsity)</li> </ul> </li> </ul> </li> <li>Go to step 2</li> <li>Once converged<ol> <li>Visualize the final image<ul> <li></li> </ul> </li> <li>Visualize the data gradient<ul> <li></li> <li>\\(M_{ij} = \\arg \\max_c \\vert w_{h(i, j, c)} \\vert\\)<ul> <li>At each pixel take the absolute value</li> <li>Max over all channels</li> </ul> </li> <li>This can be used in <code>grabcut</code> for segmentation<ul> <li></li> </ul> </li> </ul> </li> <li>Reconstruction of original image<ul> <li></li> </ul> </li> </ol> </li> </ol> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#hallucination","title":"Hallucination","text":""},{"location":"CS_Electives/Deep_Learning/04_CNN/#deepdream","title":"DeepDream","text":"<p>Set the gradients of the neurons in the layer you want to hallucinate at to be equal to the activations</p> <p>Goal: Amplify the neurons which most activates the hallucination</p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#neuralstyle","title":"NeuralStyle","text":"<ol> <li>Take 2 images<ol> <li>Content image</li> <li>Style image</li> </ol> </li> <li>Extract content targets (ConvNet activations of all layers for the given content image)</li> <li>Extract style targets (Gram matrices of ConvNet activations of all layers for the given style image): \\(G = V^T T\\)</li> <li>Optimize for generating a new image with<ol> <li>Content of content image: activations match content</li> <li>Style of style image: Gram matrices of activations match style</li> </ol> </li> <li>Since it is a lightweight optimization problem with just 2 images, L-BFGS outperforms Adam</li> </ol>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#more-smaller-filters-are-better","title":"More smaller filters are better","text":"<p>Three 3x3 conv vs one 7x7 - same receptive field - fewer parameters - more non-linearity - more efficient compute</p>"},{"location":"CS_Electives/Deep_Learning/04_CNN/#deconvolution","title":"Deconvolution","text":"<p>Same as backward pass for regular convolution</p> <p>Misnomer; actual \"deconvolution\" means \"inverse of convolution\"; better terms - backward convolution - upconvolution - convolution transpose - fractionally-strided convolution</p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/","title":"Recurrent Neural Networks","text":"<p>A recurrent neural network (RNN) is a NN architecture mainly used for sequences, such as speech recognition and natural language processing (NLP).</p> <p></p> <p>A recurrent neural network looks similar to a traditional neural network except that a memory-state is added to the neurons.</p> <p>At every time step, the following are the same - function - set of parameters</p> <p></p> <p></p> <p>A RNN cell is a neural network that is used by the RNN.</p> <p>As you can see, it\u2019s the same cell repeats over time. The weights are updated as time progresses.</p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#idk","title":"IDK","text":"<p>We introduce a latent variable, that summarizes all the relevant information about the past</p> <p></p> <p></p> \\[ h_t = f(x_1, \\dots, x_{t\u22121}) = f(h_{t\u22121},x_{t\u22121}) \\]"},{"location":"CS_Electives/Deep_Learning/04_RNN/#hidden-state-update","title":"Hidden State Update","text":"\\[ h_t = \\phi \\Big(W_{hh} h_{t\u22121} + W_{hx} x_{t\u22121} + b_h \\Big) \\]"},{"location":"CS_Electives/Deep_Learning/04_RNN/#observation-update","title":"Observation Update","text":"\\[ o_t = \\phi(W_{ho} h_t + b_o) \\]"},{"location":"CS_Electives/Deep_Learning/04_RNN/#advantages","title":"Advantages","text":"<ol> <li>Require much less training data to reach the same level of performance as other models</li> <li>Improve faster than other methods with larger datasets</li> <li>Distributed hidden state allows storage of information about pass efficiently</li> <li>Non-linear dynamics allows them to update their hidden state in complicated ways</li> <li>With enough neurons &amp; time, RNNs can compute anything that can be done by a computer</li> <li>Good behaviors</li> <li>Can oscillate (good for motor control)</li> <li>Can settle to point attractors (good for retrieving memories)</li> <li>Can behave chaotically (bad for info processing)</li> </ol>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#disadvantages","title":"Disadvantages","text":"<ol> <li>High training cost</li> <li>Difficulty dealing with long-range dependencies</li> <li>Order of input samples affects the model</li> <li>Poor gradient flow<ol> <li>vanishing gradients: largest eigenvalue &lt; 1<ol> <li>Can control using gradient clipping</li> </ol> </li> <li>exploding gradients: largest eigenvalue &gt; 1<ol> <li>Can control through additive interactions by using GRU/LSTM instead</li> </ol> </li> </ol> </li> </ol>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#an-example-rnn-computational-graph","title":"An Example RNN Computational Graph","text":""},{"location":"CS_Electives/Deep_Learning/04_RNN/#implementing-rnn-cell","title":"Implementing RNN Cell","text":""},{"location":"CS_Electives/Deep_Learning/04_RNN/#tokenizationinput-encoding","title":"Tokenization/Input Encoding","text":"<p>Map text into sequence of IDs</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#granularity","title":"Granularity","text":"Granularity ID for each Limitation Character character Spellings not incorporated Word word Costly for large vocabularies Byte Pair Frequent subsequence (like syllables)"},{"location":"CS_Electives/Deep_Learning/04_RNN/#minibatch-generation","title":"Minibatch Generation","text":"Partitioning Independent samples? No need to reset hidden state? Random Pick random offestDistribute sequences @ random over mini batches \u2705 \u274c Sequential Pick random offesetDistribute sequences in sequence over mini batches \u274c \u2705(we can keep hidden state across mini batches) <p>Sequential sampling is much more accurate than random, since state is carried through</p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#hidden-state-mechanics","title":"Hidden State Mechanics","text":"<ul> <li>Input vector sequence \\(x_1, \\dots, x_t\\)</li> <li>Hidden states \\(h_1, \\dots, x_t\\), where \\(h_t = f(h_{t-1}, x_t)\\)</li> <li>Output vector sequence \\(o_1, \\dots, o_t\\), where \\(o_t = g(h_t)\\)</li> </ul> <p>Often outputs of current state are used as input for next hidden state (and thus output)</p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#output-decoding","title":"Output Decoding","text":"\\[ P(y|o) \\propto \\exp(V_y^T \\ o) = \\exp(o[y]) \\]"},{"location":"CS_Electives/Deep_Learning/04_RNN/#gradients","title":"Gradients","text":"<p>Long chain of dependencies for back-propagation</p> <p>Need to keep a lot of intermediate values in memory</p> <p>Gradients can have problems</p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#accuracy","title":"Accuracy","text":"<p>Accuracy is usually measured in terms of log-likelihood. However, this makes outputs of different length incomparable (bad model on short output has higher likelihood than excellent model on very long output).</p> <p>Hence, we normalize log-likelihood to sequence length</p> \\[ \\begin{aligned} \\pi &amp;= - \\textcolor{hotpink}{\\frac{1}{T}} \\sum_{t=1}^T \\log P(y_t|\\text{model}) \\\\ \\text{Perplexity} &amp;= \\exp(\\pi) \\end{aligned} \\] <p>Perplexity is effectively number of possible choices on average</p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#truncated-bptt","title":"Truncated BPTT","text":"<p>Back-Propagation Through Time</p> Truncation Style None CostlyDivergent Fixed-Intervals Standard ApproachApproximationWorks well Variable Length Exit after reweighingDoesn\u2019t work better in practice Random Variable <p></p>"},{"location":"CS_Electives/Deep_Learning/04_RNN/#multi-layer-rnn","title":"Multi-Layer RNN","text":"\\[ h_t^l = \\phi w^l \\begin{pmatrix} h_{t}^{l-1} \\\\ h_{t-1}^{l} \\end{pmatrix} \\]"},{"location":"CS_Electives/Deep_Learning/05_GRU/","title":"Gated Recurrent Unit","text":"<p>Solves vanishing gradients issue of RNN</p> <p>Intuition: LSTM is to RNN what ResNet is to PlainNet</p> <p>Not all observations are equally relevant, so we need a mechanism to </p> Update gate\u00a0\\(Z\\) Pay attention Reset gate\u00a0\\(R\\) Forget"},{"location":"CS_Electives/Deep_Learning/05_GRU/#operations","title":"Operations","text":""},{"location":"CS_Electives/Deep_Learning/05_GRU/#gating","title":"Gating","text":"\\[ \\begin{aligned} R_t &amp;= \u03c3(X_t W_{xr} + H_{t\u22121} W_{hr} + b_r) \\\\ Z_t &amp;= \u03c3(X_t W_{xz} + H_{t\u22121} W_{hz} + b_z) \\\\ \\tilde H_t &amp;= \\tanh \\Big( X_t W_{xh} + (R_t \\odot H_{t\u22121}) W_{hh} + b_h \\Big) \\\\ H t &amp;= \\Big[ Z_t \\odot H_{t\u22121} \\Big] + \\Big[ (1\u2212Z_t) \\odot \\tilde H_t \\Big] \\end{aligned} \\]"},{"location":"CS_Electives/Deep_Learning/06_LSTM/","title":"Long Short-Term Memory","text":"<p>RNN only has Short-Term memory, which does not work for well long sentences, and hence for use-cases such as Grammar Checking, we prefer LSTM</p> <p>Solves vanishing gradients issue of RNN</p> <p>Intuition: LSTM is to RNN what ResNet is to PlainNet</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/06_LSTM/#gates","title":"Gates","text":"Gate Function Forget Control forgetting/retaining info currently in memory Initialize with a slight +ve bias to allow gradient flow at the beginning of training, and then slowly start forgetting Input Control whether to add new info to memory Output Control effect of hidden state on output \\[ \\begin{aligned} I_t &amp;= \\sigma(X_t W_{xi} + H_{t\u22121} W_{hi} + b_i) \\\\ F_t &amp;= \\sigma(X_t W_{xf} + H_{t\u22121} W_{hf} + b_f ) \\\\ O_t &amp;= \\sigma(X_t W_{xo} + H_{t\u22121} W_{ho} + b_o) \\\\ \\tilde C_t &amp;= \\tanh(X_t W_{xc} + H_{t\u22121} W_{hc} + b_c) \\\\ \\\\ C_t &amp;= F_t \\odot C_{t\u22121} + I_t \\odot \\tilde C_t \\\\ h_t &amp;= O_t \\odot \\tanh(C_t) \\end{aligned} \\] <ul> <li>\\(\\tilde C_t\\) is the candidate memory</li> <li>\\(C_t\\)\u00a0is the long-term memory</li> </ul>"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/","title":"Advanced RNN","text":""},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#non-linear-units","title":"Non-Linear Units","text":"<p>Replace \\(\\phi\\) of updates with MLP</p> <p>\u2705 Keeps structure of latent space</p> <p>\u274c Costly (due to more complex gradients)</p>"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#deep-rnn","title":"Deep RNN","text":"<p>Rather than using just 1 hidden layer, we use more hidden layers, ie, each time stamp of RNN has multiple cells</p> <p></p> \\[ \\begin{aligned} H_t^j &amp;= f_j(H_{t-1}^j, H_t^{j\u22121}) \\\\ O_t &amp;= g(H_t^L) \\end{aligned} \\]"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#bidirectional-rnn","title":"Bidirectional RNN","text":""},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#context","title":"Context","text":"<ul> <li>I am happy</li> <li>I am very hungry</li> <li>I am so hungry, I could eat 2 plates of rice</li> </ul> <p>Very different words to fill in, depending on past and future context of a word</p> <p>Traditional RNNs only look at the past. In interpolation (fill in) we also use the future.</p>"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#implementation","title":"Implementation","text":"<ul> <li>One RNN forward</li> <li>One RNN backward</li> <li>Combine both hidden states for output generation</li> </ul>"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#idk","title":"idk","text":"<p>Bi-RNN does not work for sequence generation</p> Training Testing <p>However, we can still use it to encode the sequence</p>"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#residual-rnn","title":"Residual RNN","text":"<p>Input of every second layer is also added to its output (residual connection)</p> <p></p> \\[ \\bar H_t^{(2i)} = H_t^{(2i)} + H_t^{(2i)\u22121} \\]"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#adding-layers","title":"Adding Layers","text":"<p>Adding a layer to a model changes function \u2028class.</p> <p></p> <p>We want to add to the function class, using Taylor expansion\u2028 style parametrization</p> \\[ f(x) = x + g(x) \\] <p></p>"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#variants","title":"Variants","text":"<ul> <li>Simple addition</li> <li>Nonlinearity before addition</li> <li>Could also concatenate</li> </ul>"},{"location":"CS_Electives/Deep_Learning/07_Advanced_RNN/#densenet-rnn","title":"DenseNet RNN","text":"<p>Concatenate outputs of previous layers as input to next layer, with occasional transition layers to reduce dimensionality</p> <p></p> \\[ \\bar H_t^{(t)} = [H_t^{(t)}, \\bar H_t^{t\u22121}] \\]"},{"location":"CS_Electives/Deep_Learning/07_Transformers/","title":"Transformers","text":""},{"location":"CS_Electives/Deep_Learning/07_Transformers/#spatial-transformer","title":"Spatial Transformer","text":"<p>Differentiable (and hence, learnable) way of cropping images, allowing attention models to attend to arbitrary regions</p> <p></p> <p></p> <ol> <li>Function mapping pixel coordinates \\((x_t, y_t)\\) of output to pixel coordinates \\(x_s, y_s\\) of input<ol> <li></li> </ol> </li> <li>Repeat for all pixels in output to get a sampling grid</li> <li>Use bilinear interpolation to compute output</li> </ol> <p></p>"},{"location":"CS_Electives/Deep_Learning/07_Transformers/#llm-transformer","title":"LLM Transformer","text":""},{"location":"CS_Electives/Deep_Learning/08_Encoder_Decoder/","title":"08 Encoder Decoder","text":"<ul> <li>Encoder processes inputs</li> <li>Decoder generates outputs</li> </ul>"},{"location":"CS_Electives/Deep_Learning/08_Encoder_Decoder/#seq2seq","title":"Seq2Seq","text":"<p>Used for language translation</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/08_Encoder_Decoder/#encoder","title":"Encoder","text":"<p>Reads input sequence</p> <p>Standard RNN model without output layer</p> <p>Encoder\u2019s hidden state in last time step is used as the decoder\u2019s initial hidden state</p>"},{"location":"CS_Electives/Deep_Learning/08_Encoder_Decoder/#decoder","title":"Decoder","text":"<p>RNN that generates output</p> <p>Fed with the targeted sentence during training</p>"},{"location":"CS_Electives/Deep_Learning/08_Encoder_Decoder/#search-algorithms-for-picking-weights","title":"Search Algorithms for Picking Weights","text":"<p>Let</p> <ul> <li>\\(n =\\) output vocabulary size</li> <li>\\(T = L =\\) max sequence length</li> </ul> Search Algorithm Time Complexity Greedy Used in seq2seq model during predictionIt could be suboptimal \\(O(nT)\\) Exhaustive Compute probability for every possible sequencePick the best sequence \\(O(n^T)\\)\u274c computationally infeasible Beam We keep the best \\(k\\) (beam size) candidates for each timeExamine \\(kn\\) sequences by adding new item to a candidate, and then keep the top-\\(k\\) onesFinal score of each candidate\\(= \\frac{1}{L_\\alpha} \\log P(y_1, \\dots, y_L)\\)$= \\frac{1}{L_\\alpha} \\sum_{t=1}^L \\log P(y_t y_1, \\dots, y_{t-1}, c)$Often, \\(\\alpha = 0.7\\) <p></p> <p></p>"},{"location":"CS_Electives/Deep_Learning/08_Encoder_Decoder/#disadvantage","title":"Disadvantage","text":"<p>Not suitable for large sentences, since the context vector might not be able to encapsulate the effect of very much previous words.</p>"},{"location":"CS_Electives/Deep_Learning/09_Attention_Mechanism/","title":"09 Attention Mechanism","text":"<p>Key idea: Generate context as a function as all hidden states, not just the last one.</p> <p></p> <p></p>"},{"location":"CS_Electives/Deep_Learning/10_YOLO/","title":"10 YOLO","text":"<p>You only look once (YOLO) at an image to predict what objects are present and where they are.</p>"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#abstract","title":"Abstract","text":"<p>Traditional object detection repurposes classifiers to perform detection; YOLO frames object detection as a regression problem to spatially separated bounding boxes and associated class probabilities</p> <p>A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance</p> <p>YOLO makes more localization errors but is less likely to predict false positives on background</p>"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#working","title":"Working","text":"<p>A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes. YOLO trains on full images and directly optimizes detection performance.</p>"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#idk","title":"IDK","text":"<p>YOLO sees the entire image during training and test time, so it implicitly encodes contextual information about classes as well as their appearance. </p> <p>Meanwhile, Fast R-CNN mistakes background patches in an image for objects because it can\u2019t see the larger context</p>"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#advantages","title":"Advantages","text":"<ol> <li>Fast</li> <li>Reasons globally</li> <li>Better understanding of general representations of objects, compared to other models; ie, real-life, artwork, etc</li> </ol>"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#disadvantages","title":"Disadvantages","text":"<ul> <li>Lower accuracy than state-of-the-art systems; [however, higher accuracy (better mAP) than many models]</li> <li>Struggles with small objects that appear in groups, such as flocks of birds</li> <li>Each grid cell only predicts two boxes and can only have one class</li> <li>This spatial constraint limits no of nearby objects that the model can predict</li> <li>Struggles to generalize to objects in unseen aspect ratios/configurations</li> <li>Loss function treats errors the same in small and large bounding boxes</li> <li>Errors due to Incorrect localizations</li> </ul>"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#detection","title":"Detection","text":"<p>System divides the input image into an \\(S \\times S\\) grid. If the center of an object falls into a grid cell, that grid cell is responsible for detecting that object.</p> <p>Each grid cell predicts B bounding boxes and confidence scores for those boxes; each bounding box consists of 5 predictions: \\(x, y, w, h\\), and confidence. These confidence scores reflect how confident the model is that the box contains an object and how accurate it thinks the box is that it predicts.</p> \\[ \\text{Confidence} = P(\\text{Object}) \\times \\text{IOU} \\] <p>Each grid cell also predicts C conditional class probabilities \\(P(\\text{Class}_i|\\text{Object})\\)</p> \\[ P(\\text{Class}_i|\\text{Object}) \\times P(\\text{Object}) \\times \\text{IOU} = Pr(\\text{Class}_i) \\times \\text{IOU} \\]"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#network-design","title":"Network Design","text":"<p>Architecture is inspired by the GoogLeNet model for image classification. However, YOLO does not use inception modules used by GoogLeNet</p> <p>Pretrain the convolutional layers on the ImageNet classification task at half the resolution (224 \u00d7 224 input image) and then double the resolution for detection</p> Default YOLO Fast YOLO Convolutional Layers 24 9 Convolutional Layers Size \\(3 \\times 3\\) Same Reduction Layers Size \\(1 \\times 1\\) Same Fully-Connected Layers 2 Same Reduction \\(1 \\times 1\\) Same Final Output \\(7 \\times 7 \\times 30\\) Same"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#activation-function","title":"Activation Function","text":"Layer Function Final Layer Linear Other layers \\(\\phi(x) = \\begin{cases} x, &amp; x&gt;0 \\\\ 0.1x, &amp; \\text{otherwise} \\end{cases}\\)"},{"location":"CS_Electives/Deep_Learning/10_YOLO/#error-function","title":"Error Function","text":"<p>Sum-Squared error</p> <p>Easy to optimize, but not aligned with the goal of maximizing mAP</p>"},{"location":"CS_Electives/Deep_Learning/11_ResNet/","title":"Residual Network","text":"\\[ \\hat y_{t+k} = y_t + \\hat f_k(y_t) \\]"},{"location":"CS_Electives/Deep_Learning/11_ResNet/#advantages","title":"Advantages","text":"<ul> <li>Better gradient flow: avoids vanishing gradients</li> </ul>"},{"location":"CS_Electives/Deep_Learning/12_Unsupervised_Deep_Learning/","title":"Unsupervised Deep Learning","text":""},{"location":"CS_Electives/Deep_Learning/12_Unsupervised_Deep_Learning/#traditional-autoencoder","title":"Traditional Autoencoder","text":"<p>Feature learning, dimensionality reduction, anomaly detection</p> <pre><code>flowchart LR\nx1[\"x\"] --&gt;\n|Encoder| z[\"z\"] --&gt;\n|Decoder| x2[\"x\u0302\"]</code></pre> <ul> <li>Usually \\(\\vert z \\vert &lt; \\vert x \\vert\\), to find useful small subset of features</li> <li>Sometimes encoder and decoder share weights</li> <li>Use encoder to initialize a supervised model</li> </ul> <p>Error function will be \\(u_i = x_i - \\hat x_i\\)</p>"},{"location":"CS_Electives/Deep_Learning/12_Unsupervised_Deep_Learning/#variational-autoencoder","title":"Variational Autoencoder","text":"<ul> <li>Bayesian</li> <li>Useful to generate new data</li> </ul>"},{"location":"CS_Electives/Deep_Learning/12_Unsupervised_Deep_Learning/#gan","title":"GAN","text":"<p>Generative Adversarial Networks</p> <pre><code>flowchart LR\nn[/Noise/] ---&gt; g[Generator] --&gt; d\nrd[Real Data] --&gt;\nd[Discriminator] --&gt;\nrf{Real/Fake} -.-&gt;\n|Backpropagation| d &amp; g</code></pre>"},{"location":"CS_Electives/Deep_Learning/12_Unsupervised_Deep_Learning/#multiscale","title":"Multiscale","text":""},{"location":"CS_Electives/Deep_Learning/12_Unsupervised_Deep_Learning/#vector-math","title":"Vector Math","text":""},{"location":"CS_Electives/Deep_Learning/99_Deep_Learning_Systems/","title":"Deep Learning Systems","text":"<p>Easy-to-use automatic differentiation tools (Keras, Tensorflow, PyTorch) have been the biggest cause of rapid development in DL</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/99_Deep_Learning_Systems/#why-learn","title":"Why Learn?","text":"<p>Understand internals of deep learning systems helps</p> <ul> <li>build/improve deep learning systems</li> <li>so that you can use them better</li> <li>not too difficult</li> </ul>"},{"location":"CS_Electives/Deep_Learning/99_Deep_Learning_Systems/#frameworks","title":"Frameworks","text":"Paradigm PyTorch Imperative chainer Imperative Tensorflow 1.0 Declarative Theano Declarative Caffe Forward &amp; Backward layers Jax mxnet Paradigm Advantage Disadvantage Imperative Easy to debugAllow mixing of programming control flow and computational graph construction Eager execution Declarative Lazy execution Hard to debug Forward &amp; Backward layers"},{"location":"CS_Electives/Deep_Learning/Attention_Models/","title":"Attention Models","text":"<ul> <li>Attention is a communication mechanism</li> <li>Can be viewed as<ul> <li>nodes in directed graph looking at each other</li> <li>aggregating with a weight sum from all nodes that point to them</li> <li>with data-dependent weights</li> </ul> </li> </ul>"},{"location":"CS_Electives/Deep_Learning/Attention_Models/#advantages","title":"Advantages","text":"<ul> <li>Give interpretable outputs</li> </ul>"},{"location":"CS_Electives/Deep_Learning/Attention_Models/#disadvantages","title":"Disadvantages","text":"<ul> <li>Can only attend to fixed grid positions</li> </ul>"},{"location":"CS_Electives/Deep_Learning/Attention_Models/#soft-attention-for-translation","title":"Soft Attention for Translation","text":""},{"location":"CS_Electives/Deep_Learning/Attention_Models/#soft-attention-for-captioning","title":"Soft Attention for Captioning","text":"<p>Also generate a distribution of which pixels to look at next</p> <p></p>"},{"location":"CS_Electives/Deep_Learning/Attention_Models/#soft-vs-hard-attention","title":"Soft vs Hard Attention","text":"Soft Hard Summarize all locations Sample one location according to \\(p\\) \\(z\\) \\(p_a a + p_b b + p_c c + p_d d\\) that vector Advantage Derivative is nice Computationally-efficient as we focus on smaller chunks of input Disadvantage No efficiency improvement as we still need to process entire input Derivative is zero almost everywhereCannot use gradient descent; need reinforcement learning"},{"location":"CS_Electives/Deep_Learning/Attention_Models/#self-attention","title":"Self-Attention","text":"<ul> <li>No notion of space<ul> <li>Attention simply acts over a set of vectors</li> <li>Hence, need to positionally encode tokens</li> </ul> </li> <li>Types of attention<ul> <li>\"self-attention\": source of key, query, and value is all \\(X\\)</li> <li>\"cross-attention\": at least one source of key, query, and value is not \\(X\\)</li> </ul> </li> <li>Every self-attention \"head\" has:</li> </ul> Dimension key FC(X) \\((B, T, \\text{head size})\\) query FC(X) \\((B, T, \\text{head size})\\) weights <code>query @ key.T</code> \\((B, T, T)\\) value FC(X) \\((B, T, \\text{head size})\\) output weights @ value <ul> <li>Scale the weights by \\(1/\\sqrt{\\text{head size}}\\) to get unit gaussian</li> <li>If you need to enforce that every \\(t\\)th token should only interact with tokens \\(&lt; t\\)<ul> <li>Do an lower triangular mask on weights, with others being set to \\(- \\infty\\)</li> </ul> </li> <li>Do a softmax function to make all weights \\(\\in [0, 1]\\)</li> </ul> <pre><code>flowchart LR\n\ntc[t-context]\nt2[t-2]\nt1[t-1]\nt[t]\n\ntc  --&gt; t2 &amp; t1 &amp; t\nt2  --&gt; t1  &amp; t\nt1  --&gt; t</code></pre>"},{"location":"CS_Electives/Deep_Learning/Attention_Models/#multi-head-attention","title":"Multi-Head Attention","text":"<p>Multiple attention blocks in parallel and then concatenated</p>"},{"location":"CS_Electives/Deep_Learning/Masters/","title":"Masters","text":"<ul> <li> First line of SOP<ul> <li> \"We are probably in The Matrix\", my biology professor stated as he explained how even the mitochondria in our cells were very likely an organism of their own. This got me thinking</li> </ul> </li> <li> explore the domain</li> <li> However, I was still not convinced of the domain to specialize in, and did not want to rush into a masters program as it meant committing to a new step in my academic journey without being mindful</li> <li> research facilities;</li> <li> I would obtain exposure that was not possible during my time in Dubai. I would obtain exposure beyond what was possible during my time in Dubai.</li> <li> the interaction with students from other majors will provide a different experience from the one at BITS which only had engineering students </li> <li> Finally, I plan on joining the CompSoc and OUBbC clubs to ensure a well-rounded experience Additionally</li> <li> such as Google DeepMind, IBM, and OpenAI or OpenAI</li> <li> Secondly, my dedication to continuous learning and improvement whereby I have completed various online courses in the past four years purely out of interest.</li> <li> from being a starter in the university basketball team, juggling injuries, leading multiple clubs, co-curricular, social and charitable activities from being a starter in the university basketball team and juggling injuries to leading multiple clubs, co-curricular, social and charitable activities</li> <li> highest award in BITS==,==</li> <li> Economics and Finance</li> <li> while being mindful of social consequences outcome</li> <li> however, it has always been my hard <ul> <li> my continued emphasis on hard work</li> </ul> </li> <li> I am aware of the challenges I would face in terms of coursework, people, time-management and also adapting to a life in a country with a completely different culture and norms.<ul> <li>Simplify</li> </ul> </li> <li> <p>How you can contribute to Oxford?</p> <ul> <li>Clubs</li> <li>actively contribute</li> </ul> </li> <li> <p>Language Test Waiver</p> <ul> <li>University on KHDA Dubai website</li> <li>Dubai, UAE Government</li> </ul> </li> <li>OCIS<ul> <li>other regions (especially the Western world)</li> <li>This really induced a feel-good factor knowing that my work improved products that impact humans, which I aim to continue further and focus on leveraging AI/ML in even more human-centric domains such as Healthcare, Drug Discovery, Energy, Environment Management, Forecasting, and Investing.<ul> <li>remove drug discovery</li> <li>welfare</li> <li>livelihood</li> <li>community upliftment</li> <li>Islamic finance</li> <li>transform lives</li> </ul> </li> <li>deal career to develop over the next ten years.<ul> <li>expertise</li> </ul> </li> <li>In contrast to others,</li> <li>either way</li> </ul> </li> </ul>"},{"location":"CS_Electives/DevOps/","title":"DevOps","text":""},{"location":"CS_Electives/DevOps/01_Types_of_Apps/","title":"Types of Apps","text":"Advantages Disadvantages Monolithic Straighforward Hard to scale Multi-Tier Microservices Hard to pinpoint cause of errors due to interdependency between APIs"},{"location":"CS_Electives/DevOps/01_Unit_Testing/","title":"Unit Testing","text":""},{"location":"CS_Electives/DevOps/01_Unit_Testing/#test-naming-convention","title":"Test Naming Convention","text":"<pre><code>test_component_scenario_expectedOutcome\n</code></pre> <pre><code>def test_DataFrame_WhenDataFrameIsValid_ReturnColumns():\n  pass\n</code></pre>"},{"location":"CS_Electives/DevOps/01_Unit_Testing/#fixtures","title":"Fixtures","text":"<p>Template Object</p>"},{"location":"CS_Electives/DevOps/01_Unit_Testing/#mocking","title":"Mocking","text":""},{"location":"CS_Electives/Distributed_Systems/","title":"Distributed Systems","text":""},{"location":"CS_Electives/Distributed_Systems/#references","title":"References","text":"<ul> <li> Distributed Systems | MIT 6.824</li> </ul>"},{"location":"CS_Electives/Federated_Learning/","title":"Federated Learning","text":""},{"location":"CS_Electives/Federated_Learning/#references","title":"References","text":"<ul> <li> CS-E4740 Federated Learning | Alexander Jung | Aalto University (Finland)</li> <li> Lectures</li> <li> Material</li> <li> Google Workshop on Federated Learning and Analytics</li> <li> 2020</li> <li> 2021</li> </ul>"},{"location":"CS_Electives/Fintech/","title":"Fintech","text":""},{"location":"CS_Electives/Fintech/#references","title":"References","text":"<ul> <li>MIT 15.S08 FinTech: Shaping the Financial World</li> <li>DeFi | Campbell Harvey</li> </ul>"},{"location":"CS_Electives/Fintech/05_Blockchain/","title":"Introduction","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#traditional-banks","title":"Traditional Banks","text":"<p>Banks maintain ledger</p> <p>Ledger is a record of the </p> <p>Bank ledgers are not auditable</p> <pre><code>flowchart LR\n\nsubgraph Different Banks\ndirection LR\nA2((A)) --&gt;\nba2[[Bank A]] --&gt;\nbb2[[Bank B]] --&gt;\nB2((B))\nend\n\nsubgraph Same Banks\ndirection LR\nA1((A)) --&gt;\nba[[Bank]] --&gt;\nB1((B))\nend</code></pre>"},{"location":"CS_Electives/Fintech/05_Blockchain/#bad-incidents","title":"Bad Incidents","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#cyprus","title":"Cyprus","text":"<p>Take 30% of everyone\u2019s funds, just like that</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#india-demonetization","title":"India demonetization","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#charge-backs","title":"Charge-backs","text":"<p>Reversed transaction within 24-48hrs</p> <p>But counter-party can sue the payer</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#2008-recession","title":"2008 Recession","text":"<p>The taxpayers\u2019 money was used for bailing out banks</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#pre-requisities","title":"Pre-Requisities","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#symmetric-keys","title":"Symmetric Keys","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#asymmetric-keys","title":"Asymmetric Keys","text":"<ul> <li>Public key helps</li> <li>encrypt data</li> <li>verify signature</li> <li>Private key helps</li> <li>decrypt data</li> <li>sign messages</li> </ul>"},{"location":"CS_Electives/Fintech/05_Blockchain/#steps","title":"Steps","text":"<ol> <li>A takes B\u2019s public key</li> <li>A encrypt the file</li> <li>B receives file</li> <li>B uses B\u2019s private key to decrypt the file</li> </ol>"},{"location":"CS_Electives/Fintech/05_Blockchain/#blockchain","title":"Blockchain","text":"<p>Continuous database split into blocks</p> <p>Basically like a doubly-linked list</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#concensus","title":"Concensus","text":"<p>Permission</p> <p>Centralized party cannot edit </p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#hash-function","title":"Hash Function","text":"<p>Compression function that tranforms data into a simpler form</p> <p>Helps with verification, by serving as signature to data</p> <pre><code>flowchart LR\n\ngb[Genesis Block] --&gt;\nb1[Block 1] --&gt;\nb2[Block 2]</code></pre>"},{"location":"CS_Electives/Fintech/05_Blockchain/#components","title":"Components","text":"<ol> <li>Hash of current block</li> <li>Hash of previous block (except genesis block)</li> <li>Transactions and signatures</li> <li>Sender\u2019s signature, as they are the one initiating the transaction</li> <li>Timestamp</li> <li>Proof of Work</li> </ol>"},{"location":"CS_Electives/Fintech/05_Blockchain/#wallet","title":"Wallet","text":"<p>Front-end that keeps your details and interacts with the blockchain</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#bitcoin","title":"Bitcoin","text":"<p>Peer-to-peer network</p> <p>Trillion-Dollar Market</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#advantages","title":"Advantages","text":"<ul> <li>Resistant to inflation</li> <li>Overall supply </li> <li>Resistance to fraudulent</li> <li>Pseudo-anonymous</li> <li>You can find out the </li> <li>But you can\u2019t find out who it is</li> <li>Low transaction fees</li> </ul>"},{"location":"CS_Electives/Fintech/05_Blockchain/#parts-of-blockchain","title":"Parts of Blockchain","text":"<ol> <li>Users    The ones who send/receive transactions</li> <li>Nodes    Autonoumous computers which validate and timestamp transactions</li> <li>Miners    Subset of nodes, high computational, confirm transactions    Monitor transations</li> </ol>"},{"location":"CS_Electives/Fintech/05_Blockchain/#mining","title":"Mining","text":"<p>Every transcation has a transaction fee, which depends on </p> <p>The Bitcoin protocol rewards only the fastest miner solving a \u2018hash puzzle\u2019. The difficulty gets automatically adjusted by the network algorithm.</p> <p>Winner gets a freshly-minted bitcoin and the commission fee by the payer.</p> <p>There can only be 21M bitcoins total in the total. Every year, the reward gets divided into half. Currently, the reward is \\(6.25 \\text{ BTC}\\)</p> <p>Protocol is a set of rules</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#mempool","title":"Mempool","text":"<p>Memory pool</p> <p>On every 2 weeks, the difficulty algorithm updates the difficulty level</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#limitations","title":"Limitations","text":"<ul> <li>Time-Consuming</li> <li>10 min confirmation time</li> </ul>"},{"location":"CS_Electives/Fintech/05_Blockchain/#solutions","title":"Solutions","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#increase-the-block-size","title":"Increase the block size","text":"<ul> <li>So that more transactions fit into a block</li> <li>Introduce a second layer</li> <li>But not that great</li> </ul>"},{"location":"CS_Electives/Fintech/05_Blockchain/#lightning-network","title":"Lightning Network","text":"<ul> <li>Without this, throughput is only 7</li> <li>Depends on the internet speed of the nodes</li> <li>~ 3.9M transactions per second</li> </ul> <p>You just need to record 2 transactions</p> <ul> <li>Opening channel</li> <li>Closing channel</li> </ul> <p>Only disadvantage is that it depends on liquidity (of what?) ; hence, it is only recommend only for small transactions</p> <p>Another features relayed transactions through shortest paths between payer and receiver</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#stages-of-currencydigital-currency","title":"Stages of Currency/Digital Currency","text":"<pre><code>flowchart LR\n1[Collectible] --&gt;\n2[Store of Value] --&gt;\n3[Medium of Exchange]</code></pre>"},{"location":"CS_Electives/Fintech/05_Blockchain/#economic-majority","title":"Economic Majority","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#ring-signatures","title":"Ring Signatures","text":"<p>(not relevant here)</p>"},{"location":"CS_Electives/Fintech/05_Blockchain/#softwareswebsites-used","title":"Softwares/Websites Used","text":""},{"location":"CS_Electives/Fintech/05_Blockchain/#electrum","title":"Electrum","text":"<pre><code>open /Applications/Electrum.app --args --testnet\n</code></pre>"},{"location":"CS_Electives/Fintech/05_Blockchain/#other","title":"Other","text":"<ul> <li>mempool.emzy.de</li> <li>Bitcoin Testnet Faucet</li> <li>Parallel blockchain where developers use it for testing</li> </ul>"},{"location":"CS_Electives/Generative_AI/","title":"Generative AI","text":""},{"location":"CS_Electives/Generative_AI/#references","title":"References","text":"<ul> <li> Generative Adversarial Networks (GANs) Specialization</li> <li> Deep Generative Models (Cornell Tech CS 6785, Spring 2023) | Volodymyr Kuleshov</li> <li> Deep Generative Models | Stanford</li> <li> Intro to Deep Learning and Generative Models | Sebastian Raschka</li> <li> Generative AI for Everyone | Andrew Ng | Coursera</li> <li> Foundation Models &amp; Generative AI | MIT</li> <li> Future of AI | MIT</li> <li> MIT 6.S184: Flow Matching and Diffusion Models | Peter Holderrieth | MIT</li> </ul>"},{"location":"CS_Electives/Generative_AI/01_Introduction/","title":"Introduction","text":""},{"location":"CS_Electives/Generative_AI/01_Introduction/#generative-ai","title":"Generative AI","text":"<p>AI systems that can produce high quality unstructured content: text, images, audio</p> <p></p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#impact-on-jobs","title":"Impact on Jobs","text":"<p>More effect on</p> <ul> <li>higher-paid jobs </li> <li>knowledge workers</li> </ul> <p></p> <p></p> <p></p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#lifecycle-of-genai-project","title":"Lifecycle of GenAI Project","text":"<ol> <li>Scoping</li> <li>Build prototype</li> <li>Internal evaluation</li> <li>Improve system</li> <li>Deploy</li> <li>Monitor</li> </ol>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#llms","title":"LLMs","text":"<p>Large Language Models</p> <p>Supervised learning to repeatedly predict the next word</p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#applications","title":"Applications","text":"<ul> <li>Finding new information</li> <li>Writing</li> <li>Assistant</li> <li>Translation</li> <li>Reading</li> <li>Proof reading</li> <li>Summarization</li> <li>Chatting</li> </ul> <p>Advice for chatbots: Start with internal-facing that works with staff</p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#what-an-llm-can-do","title":"What an LLM can do","text":"<p>Rule of thumb</p> <p>Whatever a fresh undergraduate can do with the given prompt and</p> <ul> <li>No internet/other resources</li> <li>No training specific to your prompt</li> <li>No memory of previous tasks</li> </ul>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#prompting-tips","title":"Prompting Tips","text":"<ol> <li>Be detailed: Give LLM sufficient context &amp; information required to task at hand</li> <li>Be specific</li> <li>Guide the model to think through its answer: Suggest steps for performing task</li> <li>Experiment and Iterate</li> </ol>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#objective","title":"Objective","text":"<p>Helpful, Honest, Harmless</p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#how-it-works","title":"How it works","text":"<ul> <li>Instruction tuning</li> <li>RLHF: Reinforcement Learning from Human Feedback</li> <li>Train another Supervised Learning model for answer quality rewards</li> <li>Train LLM to generate responses with high response scores</li> </ul> <p>Can be used to reduce bias</p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#tool-use","title":"Tool-Use","text":""},{"location":"CS_Electives/Generative_AI/01_Introduction/#action","title":"Action","text":""},{"location":"CS_Electives/Generative_AI/01_Introduction/#reasoning","title":"Reasoning","text":""},{"location":"CS_Electives/Generative_AI/01_Introduction/#agents","title":"Agents","text":"<ul> <li>Use LLM to close and carry out complex sequence of actions</li> <li>Not ready at the time of typing this</li> </ul>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#image-generation","title":"Image Generation","text":"<p>Diffusion Model</p> <p>Noise + Prompt -&gt; Generated Image</p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#limitations","title":"Limitations","text":"<ul> <li>Knowledge cut-off</li> <li>Hallucinations: LLM can produce confident responses which are completely false</li> <li>Prompt size is limited</li> <li>Does not work with structured data</li> <li>Does not do arithmetic well</li> <li>Bias &amp; Toxicity</li> </ul>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#caveats","title":"Caveats","text":"<ul> <li>Be careful with confidential information</li> <li>Double-check: LLMs do not necessarily give reliable information</li> <li>For user service, better to have confirmation dialog before performing transaction</li> </ul>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#cost-of-llm","title":"Cost of LLM","text":"<p>Relatively cheap to use</p> <p>4 tokens ~ 3 words</p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#rag","title":"RAG","text":"<ol> <li>Given question, search relevant documents for answer</li> <li>Incorporate retrieved text into updated prompt</li> <li>Generate answer with new prompt with additional context</li> </ol>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#fine-tuning","title":"Fine-Tuning","text":"<ol> <li>To carry out a task that isn\u2019t easy to define in a prompt</li> <li>To help LLM gain specific knowledge</li> <li>To get a smaller model to perform a task</li> </ol>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#pre-training","title":"Pre-Training","text":"<ul> <li>Very costly</li> <li>Requires large amount of data</li> </ul> <p>For building a specific application, pre-training is the last resort</p>"},{"location":"CS_Electives/Generative_AI/01_Introduction/#llm-model-size","title":"LLM Model Size","text":"<p>General guidelines</p> Parameters Capability Example 1B Pattern-matchingBasic knowledge of the word Restaurant review sentiment 10B Greater world knowledgeCan follow basic instructions Food order chatbot &gt; 100B Rich world knowledgeComplex reasoning Brainstorming"},{"location":"CS_Electives/IoT/","title":"Internet of Things","text":"<p>Covers solid technical knowledge and skills to build Internet of Things (IoT) systems. IoT has evolved due to the convergence of multiple technologies - embedded systems, sensor technology, real-time data analytics, machine learning, etc. Traditional fields of embedded systems, wireless sensor networks, control systems, automation (including home and building automation), and others all contribute to enabling the IoT.</p> <p>This course comprehensively covers various technologies and tools used for enabling IoT solutions. Knowledge of various topics required for building IoT prototypes like sensors and actuators/ Communications and networking and data management is also imparted in this course. This course would also help the students understand the various IoT security challenges and solutions to address them.</p> <p>The course will also give the students exposure to how various real-world problems are being solved by IoT-based solutions (like in applications for smart cities smart farming, etc.). There would also be some hands-on sessions where students would learn how to build and program IoT systems and make end-to-end solutions for different applications.</p>"},{"location":"CS_Electives/IoT/#prerequisites","title":"Prerequisites","text":"<ul> <li> Computer Architecture</li> <li> Computer Networks</li> </ul>"},{"location":"CS_Electives/IoT/#references","title":"References","text":"<ul> <li> Internet of Things | Gary Holness | Clark University</li> <li> Introduction to Internet of Things | IIT</li> <li> Design for internet of things | IIS Bangalore</li> <li> Intro to Industry 4.0 and Industrial Internet of Things | IITK</li> <li> Industry 4.0 | IITM</li> <li> Advanced IOT Applications | IIS Bangalore</li> <li> IoT Summer School</li> <li> Paul McWhorter | Arduino Tutorials</li> <li> Paul McWhorter | Raspberry Pi Tutorials for Absolute Beginners</li> </ul>"},{"location":"CS_Electives/IoT/#current-video","title":"Current Video","text":"<p>https://www.youtube.com/watch?v=8wBQMbOntNc&amp;list=PLbRMhDVUMngdcLdH4-YF1uJI4IuhcDZPR&amp;index=14</p>"},{"location":"CS_Electives/IoT/01_Introduction/","title":"Introduction","text":"<p>Network of physical objects embedded with electronics, software, sensors and network connectivity that enables these objects to collect and exchange data</p>"},{"location":"CS_Electives/IoT/01_Introduction/#parts","title":"Parts","text":"<pre><code>flowchart LR\nstart((\" \")) --&gt;\n|Input Signal| Sensor --&gt;\nProcessor --&gt;\nActuator --&gt;\n|Output Signal| stop(\" \")</code></pre> <ul> <li>Sensor and actuators are transducers</li> <li>Transducers convert signal from one form to another<ul> <li>Microphones: sound to electrical</li> <li>Speaker: electrical to sound</li> <li>Antenna: electromagnetic to electricity and vice-versa</li> <li>Strain gauge: strain to electrical</li> </ul> </li> </ul>"},{"location":"CS_Electives/IoT/01_Introduction/#applications","title":"Applications","text":"<ul> <li>Wearable tech</li> <li>Healthcare devices</li> <li>Smart appliances</li> </ul>"},{"location":"CS_Electives/IoT/01_Introduction/#signals","title":"Signals","text":"Digital Analog Type Binary(0/1) Continuous(Usually 0-5v or 0-3.3v) Usually mapped to digital 0-255 or 0-1023 Example On/off LED Pulse-Width Modulation- Intensity of light- Brightness of LED- Speed of Motor"},{"location":"CS_Electives/IoT/01_Introduction/#standard-controllers-for-iot","title":"Standard Controllers for IoT","text":"Arduino Node MCU Raspberry Pi Type RISC RISC CISC Size of Projects Embedded Systems Small-Size Large-Size Cost WiFi \u274cNeed external ESP8266 module \u2705 \u2705 Programming C++ C++Lua PythonJavaC++ Flash Memory 32 KB 128 MB - GPIOGeneral Purpose I/O 13 10 17 ADCMeaning 6 1 0 Operating Voltage 5 v 3.3 v 5 v Clock Speed 16 MHz 26-52 MHz 1.2 GHz Supported Wifi Bands 2.4 GHz 2.4 GHz 2.4 GHz5 GHz (RPi 4 only)"},{"location":"CS_Electives/IoT/01_Introduction/#cps","title":"CPS","text":"<p>Cyber-Physical Systems</p>"},{"location":"CS_Electives/IoT/02_Communication_Protocols/","title":"Communication Protocols","text":"Full Form Methodology Architecture Participants Complexity Data Format Message size Port # Secure Methods Lightweight Designed for Local IEEE 802.15.4 \u2705 low powerlow costlow speedneighboring devices Zigbee 6LoWPAN Wireless HART Z-Wave ISA 100 Bluetooth NFC RFID Web HTTP Hyper Text Transfer Protocol Document-Centric Request/Response Protocol - Client- Server Complex ASCII Large 808080 \u274c GETPUTPOST \u274c HTTPS HTTP Secure 443 \u2705 \u274c MQTT Message Queue Telemetry Transfer Data-Centric Publish/Subscribe - Publisher- Broker- Subscriber Simple Binary with 2B header Small 1883 \u2705 \u2705 Devices: constrainedNetworks: low-bandwidth, high-latency, unreliable COAP Constraint Application Protocol"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/","title":"Cloud Platforms","text":""},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#arduino-iot-cloud","title":"Arduino IoT Cloud","text":"<p>HTTP</p> <ul> <li>Install Arduino create agent</li> <li>Go to create.arduino.cc/iot/</li> </ul>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#things","title":"Things","text":"<ol> <li>Create thing</li> <li>Create variables</li> <li>Select devices</li> <li>Select network</li> <li>Set timezone</li> <li>Full code editor</li> </ol>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#dashboards","title":"Dashboards","text":"<ol> <li>Create dashboard</li> <li>Add widgets</li> </ol>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#mobile-app","title":"Mobile App","text":"<p>Arduino IoT Cloud Remote</p>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#uploading-code-locally","title":"Uploading code locally","text":"<p>Install <code>ArduinoIoTCloud</code> library</p>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#blynk","title":"Blynk","text":"<p>HTTP</p> <p>blynk.cloud</p> <ol> <li>Create account</li> <li>Create new template</li> <li>Create new data stream &gt; Virtual Pin</li> <li>Digital: Input only</li> <li>Analog: Input only</li> <li>Virtual Pin: Input/Output</li> <li>Install Blynk library</li> </ol>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#thingspeak","title":"ThingSpeak","text":"<p>Developed by MathWorks, the same company that developed Matlab</p> <p>Uses HTTP Read and Write requests</p>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#adafruit-io","title":"AdaFruit IO","text":"<p>Uses MQTT</p>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#subscribe","title":"Subscribe","text":"<pre><code>Adafruit_MTT_Client mqtt(&amp;client, server, port, user, key);\nAdafruit_MTT_Subscribe toggle = Adafruit_MTT_Subscribe(\n  &amp;mqtt,\n  user\"/feeds/led\"\n);\n\nvoid mqtt_connect() {\n  if(mqtt.connected()){\n    return ;\n  }\n\n  Serial.println(\"Connecting to MQTT...\");\n\n  int retries = 3, status;\n\n  while(\n    (status = mqtt.connect()) != 0\n  ) {\n    Serial.println(mqtt.connectErrorString(status));\n    Serial.println(\"Retrying after 5sec\");\n\n    delay(5000);\n    retries--;\n\n    if(retries == 0) {\n      while(1); // reset NodeMCU\n    }\n  }\n\n  Serial.println(\"MQTT connected\");\n  mqtt.subscribe(&amp;toggle);\n}\n\nvoid setup() {\n  Serial.begin(9600);\n  pinMode(D2, OUTPUT);\n  Serial.println(\"Connecting to WiFi...\");\n  WiFi.begin(ssid, pass);\n  while(WiFi.status() != WL_CONNECTED) {\n    Serial.print(\".\");\n    delay(1000);\n  }\n  Serial.println(\"WiFi connected!\")\n}\n\nvoid loop() {\n  mqtt_connect();\n  Adafruit_MTT_Subscribe *subscription;\n\n  while(subscription = mqtt.readSubscription(5000)) {\n    if(subscription == &amp;toggle) {\n      char* data = (char*) toggle.lastread;\n      Serial.println(data);\n    }\n  }\n}\n</code></pre>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#publish","title":"Publish","text":"<pre><code>Adafruit_MTT_Client mqtt(&amp;client, server, port, user, key);\nAdafruit_MTT_Publish gauge = Adafruit_MTT_Publish(\n  &amp;mqtt,\n  user\"/feeds/sensor\"\n);\n\nint data;\n\nvoid mqtt_connect() {\n  if(mqtt.connected()){\n    return ;\n  }\n\n  Serial.println(\"Connecting to MQTT...\");\n\n  int retries = 3, status;\n\n  while(\n    (status = mqtt.connect()) != 0\n  ) {\n    Serial.println(mqtt.connectErrorString(status));\n    Serial.println(\"Retrying after 5sec\");\n\n    delay(5000);\n    retries--;\n\n    if(retries == 0) {\n      while(1); // reset NodeMCU\n    }\n  }\n\n  Serial.println(\"MQTT connected\");\n}\n\nvoid setup() {\n  Serial.begin(9600);\n  Serial.println(\"Connecting to WiFi...\");\n  WiFi.begin(ssid, pass);\n  while(WiFi.status() != WL_CONNECTED) {\n    Serial.print(\".\");\n    delay(1000);\n  }\n  Serial.println(\"WiFi connected!\")\n}\n\nvoid loop() {\n  mqtt_connect();\n\n  data = 100;\n\n  if(gauge.publish(data)) {\n    Serial.println(\"Published successful: \" + String(data));\n  } else {\n    Serial.println(\"Published failed: \" + String(data));\n  }\n  delay(5000);\n}\n</code></pre>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#ifttt","title":"IFTTT","text":"<ul> <li>WebHooks for HTTP Requests</li> </ul>"},{"location":"CS_Electives/IoT/03_Cloud_Platforms/#aws-iot-core","title":"AWS IoT Core","text":""},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/","title":"Custom IoT Server-Side Solution","text":"<p>This section will cover how to make our own IoT platform, using AWS EC2 (Amazon Web Services - Elastic Compute Cloud)</p> <p>Virtual Private Server</p> <p>Warning: Be careful about billings; only create one server and only use whatever services you are sure about</p>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#alternatives-to-aws","title":"Alternatives to AWS","text":"<ul> <li>Azure</li> <li>Google Cloud</li> <li>Digital Ocean</li> <li>Linode</li> </ul>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#setup","title":"Setup","text":"<ul> <li>EC2 dashboard</li> <li>Change datacenter location to preferred location</li> <li> <p>Launch Instance</p> </li> <li> <p>Choose AMI (Amazon Machine Image)</p> </li> <li>Operating system</li> <li>CPU architecture</li> <li>Choose Instance Type</li> <li>hardware configurations</li> <li>Choose instance details: You may skip this</li> <li>Add storage</li> <li>Add tags: you may skip this</li> <li>Configure security group</li> <li>Add rule: SSH</li> <li>Add rule: HTTP</li> <li>Review instance launch</li> <li>Create a new key pair</li> </ul>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#operating-system","title":"Operating System","text":"<ul> <li>Windows</li> <li>Linux (preferred)</li> <li>FOSS</li> <li>Secure</li> <li>Fast</li> </ul>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#installations","title":"Installations","text":"<ol> <li>Select instance</li> <li>Click <code>Connect</code></li> <li>Get public IP address</li> <li>Click <code>Connect</code></li> <li>Paste the below into the terminal Terminal</li> </ol> Purpose Option Web Server Apache Server/NGINX Server API Programming Language PHP/Python Database MySQL Database Management Tool PHPMyAdmin <pre><code># update all packages\nsudo apt-get update\n\n# install apache server\nsudo apt-get install apache2\n\n# start apache server\nsudo service apache2 start\n\n# install php\nsudo apt-get install php-dev libmcrypt-dev gcc make autoconf libc-dev pkg-config\n\n# restart apache server\nsudo service apache2 restart\n\n# change directory\ncd /etc/apache2/\n\n# instal mysql server\nsudo apt-get install mysql-server\n\n# Setup MySQL security\nsudo mysql_secure_installation\n# Press N for validate password component\n# Create password\n# Press Y for remaining questions\n\n# install phpmyadmin\nsudo apt-get install phpmyadmin\n# click yes for the questions\n\n# link phpmyadmin to mysql\nsudo ln -s /etc/phpmyadmin/apache.conf /etc/apache2/conf-available/phpmyadmin.conf\nsudo a2enconf phpmyadmin.conf\nsudo service apache2 reload\nsudo systemctl restart apache2\nsudo chmod -R 777 /var/www/html\n\n# login to mysql\nsudo mysql -uroot -p\n\n# create admin user with password for phpmyadmin\nCREATE USER 'admin'@'localhost' IDENTIFIED BY 'give_good_password';\nGRANT ALL PRIVILEGES ON *.* TO 'admin'@'localhost';\n\n# exit\nexit\n</code></pre>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#phpmyadmin","title":"phpmyadmin","text":"<p>Verify phpmyadmin</p> <ol> <li>Go to <code>http://public_ip/phpmyadmin</code></li> <li>Put username and password from what was inputted for phpmyadmin in terminal</li> </ol> <p>IDK</p> <ol> <li>Create database</li> <li>Create table</li> <li>Create columns</li> </ol>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#api","title":"API","text":""},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#basicphp","title":"<code>basic.php</code>","text":"<pre><code>&lt;?php\n\n$host   = \"localhost\";\n$user   = \"admin\";\n$pass   = \"password\";\n$db     = \"iot\";\n\n// connect to mysql\n$con = mysqli_connect(\n    $host,\n  $user,\n  $pass,\n  $db\n);\n\nif ($con) {\n  echo \"Connection successful!\";\n} else {\n  echo \"Connection failed!\";\n}\n\n?&gt;\n</code></pre>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#insertphp","title":"<code>insert.php</code>","text":"<p><code>http://.../insert.php?query_param=100&amp;query_param_2=200</code></p> <pre><code>&lt;?php\ndata_default_timezone_set(\"Asia/Kolkata\");\n\n$host   = \"localhost\";\n$user   = \"admin\";\n$pass   = \"password\";\n$db     = \"iot\";\n\n// connect to mysql\n$con = mysqli_connect(\n    $host,\n  $user,\n  $pass,\n  $db\n);\n\nif ($con) {\n\n  $query_param = $_GET[\"query_param\"];\n\n  if ($query_param) {\n    // to ensure empty values not inserted\n\n    $date = date(\"Y-m-d\");\n    $time = date(\"H:i:s\");\n\n    $query = \"\n    insert into table_name\n    (date, time, data)\n    values(\n    '$date', '$time', $data\n    );  \n    \";\n\n    if (mysqli.query($con, $sql)) {\n      echo \"Data inserted!\";\n    } else {\n      echo \"Insert failed!\";\n    }\n  } else {\n    echo \"Missing query parameter (s)\";\n  }\n\n} else {\n  echo \"Connection failed!\";\n}\n\n?&gt;\n</code></pre>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#get_readingsphp","title":"<code>get_readings.php</code>","text":"<p><code>http://.../get_readings.php</code></p> <pre><code>&lt;html&gt;\n&lt;head&gt;\n    &lt;meta http-equiv=\"refresh\" content=\"5\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;table&gt;\n&lt;tbody&gt;\n\n&lt;?php\n$host   = \"localhost\";\n$user   = \"admin\";\n$pass   = \"password\";\n$db     = \"iot\";\n\n// connect to mysql\n$con = mysqli_connect(\n    $host,\n  $user,\n  $pass,\n  $db\n);\n\nif ($con) {\n\n  $query = \"\n  select * from table_name\n  order by id desc\n  limit 100\n  \";\n\n  $query_result = mysqli.query($con, $sql)\n\n  if ($query_result) {\n\n    while (\n      $row = mysqli_fetch_array($query_result)\n    ){\n      // print_r($row);\n      echo \"\n      &lt;tr&gt;\n      &lt;td&gt;$row['data']&lt;/td&gt;\n      &lt;/tr&gt;\n      \"\n    }\n\n  } else {\n    echo \"Query failed!\";\n  }\n\n} else {\n  echo \"Connection failed!\";\n}\n\n?&gt;\n&lt;/tbody&gt;\n&lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#set_statusphp","title":"<code>set_status.php</code>","text":"<pre><code>&lt;html&gt;\n&lt;title&gt;Cloud Server Controlled LED&lt;/title&gt;\n&lt;body&gt;\n&lt;center&gt;\n&lt;h2 style='margin-top:50px;color:#123456;'&gt;Cloud Server Controlled LED&lt;/h2&gt;\n&lt;a href='?status=on'&gt;\n    &lt;button style='background-color:green;\n      font-size:20px;color:white;margin:10px;padding:5px;'&gt;\n      &lt;b&gt;LED ON&lt;/b&gt;\n    &lt;/button&gt;\n&lt;/a&gt;\n&lt;a href='?status=off'&gt;\n    &lt;button style='background-color:red;font-size:20px;color:white;\n    margin:10px;padding:5px;'&gt;\n    &lt;b&gt;LED OFF&lt;/b&gt;\n    &lt;/button&gt;\n&lt;/a&gt;\n&lt;/center&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n\n&lt;?php\nif(isset($_GET['status'])){\n    date_default_timezone_set(\"Asia/Kolkata\");\n\n  $host = \"localhost\";\n    $user = \"iot_user\";\n    $pass = \"iot@1122\";\n    $db = \"iot\";\n\n  $con = mysqli_connect($host,$user,$pass,$db);\n\n  $date = date(\"d-m-Y\");    // 06-01-2022\n    $time = date(\"H:i:s\");\n    $status = $_GET['status'];\n    $query = \"\n    insert into led\n    (date,time,status)\n    values('$date','$time','$status')\n    \";\n\n  mysqli_query($con, $query);\n}\n\n?&gt;\n</code></pre>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#get_statusphp","title":"<code>get_status.php</code>","text":"<pre><code>&lt;?php\n\n$host = \"localhost\";\n$user = \"iot_user\";\n$pass = \"iot@1122\";\n$db = \"iot\";\n\n$con = mysqli_connect($host,$user,$pass,$db);\n\n$query = \"\nselect *\nfrom table_name\norder by id desc\nlimit 1\n\";\n\n$query_result = mysqli_query($con, $query);\n\nwhile(\n  $row = mysqli_fetch_array($result)\n) {\n  echo $status;\n\n  break; // only one row any ways\n}\n\n?&gt;\n</code></pre>"},{"location":"CS_Electives/IoT/04_Custom_IoT_Server_Side_Solution/#uploading-api-files","title":"Uploading API files","text":"<p>Using: Filezilla</p> <ul> <li>General</li> <li>File &gt; Site Manager</li> <li>New Site<ul> <li>Protocol: SFTP</li> <li>Host: ip of the remote machine</li> <li>Logon type: Key file</li> </ul> </li> <li>Advanced</li> <li>Default remote directory: <code>/var/www/html</code></li> <li>Upload php files</li> </ul>"},{"location":"CS_Electives/IoT/Devices/","title":"Devices","text":""},{"location":"CS_Electives/IoT/Devices/#sensors-input","title":"Sensors (Input)","text":"<p>Devices that - detect the state of a physical environment - quantitatively provide a corresponding output as an electrical/optical signal</p>"},{"location":"CS_Electives/IoT/Devices/#characteristics-of-sensors","title":"Characteristics of Sensors","text":"Meaning Static After steady state condition, how the output of a sensor change in response to input change Range Highest and lowest value that can be sensed Resolution Smallest change in input that can be sensed Sensitivity Ratio of incremental change in response of system wrt incremental change in input Error Difference between true and measured value\\(u = y_m-y\\) Accuracy \\(1-E[u]\\) Precision \\(\\sigma(u)\\) Linearity Deviation of sensor curve from particular straight line Drift Difference in measurements from a specific reading when kept at that value for long period of time Repeatability Deviation between measurements in a sequence under same conditions Dynamic Properties of system's transient response to inputHow well sensor responds to changes in input Zero-order system Output shows a response to input signal with no delay First-order system Output approaches final value gradually Second-order system Output response oscillates before steady state"},{"location":"CS_Electives/IoT/Devices/#classification","title":"Classification","text":"Aspect Class Meaning Example Activity Passive Cannot independently sense input AccelerometerTemperatureWater-levelSoil moisture Active Can independently sense input RadarSounderLaser altimeter Signal Type Analog Digital Direction of Quantity Scalar Only magnitude Speedometer Vector Magnitude and direction AccelerometerGyroscope"},{"location":"CS_Electives/IoT/Devices/#sensor-fusion","title":"Sensor Fusion","text":"<p>Combining measurements of the same quantity from multiple sensors, to obtain a combined information with lower uncertainty than any of the individual sensors. Using multiple sensors for the quantity also allows us to verify each sensor wrt others.</p> <p>If we have \\(s\\) sensors, $$ \\begin{aligned} \\mu_\\text{S} &amp;= \\left( \\sum \\limits_s^S \\dfrac{\\mu_s}{\\sigma^2_s} \\right) \\sigma^2_{S} \\ \\sigma^2_\\text{S} &amp;= \\dfrac{1}{\\sum \\limits_s^S \\dfrac{1}{\\sigma^2_s} } \\end{aligned} $$ where \\(S\\)\u00a0refers to the combination of all the sensors</p>"},{"location":"CS_Electives/IoT/Devices/#effectors-output","title":"Effectors (Output)","text":"<p>Devices that perform some action such as emitting light, sound, motor, etc</p>"},{"location":"CS_Electives/IoT/Devices/#sensors","title":"Sensors","text":"<ul> <li>Motion<ul> <li>Gyroscope</li> <li>Radar</li> <li>Magnetometer</li> <li>Accelerometer</li> </ul> </li> <li>Acoustic<ul> <li>Ultrasonic</li> <li>Microphones</li> <li>Geophones</li> <li>Vibrometers</li> </ul> </li> <li>Environmental<ul> <li>Temperature</li> <li>Humidity</li> <li>Pressure</li> <li>Infrared</li> </ul> </li> <li>Touch sensors<ul> <li>Capacitive</li> <li>Infrared</li> </ul> </li> <li>Image Sensors<ul> <li>Thermal</li> <li>Camera</li> </ul> </li> <li>Biometric<ul> <li>Fingerprint</li> <li>Heart rate</li> <li>Face recognition</li> </ul> </li> <li>Force sensors<ul> <li>Pressure</li> <li>Strain</li> </ul> </li> <li>Rotation sensors<ul> <li>Encoders</li> </ul> </li> </ul>"},{"location":"CS_Electives/IoT/Devices/#actuator","title":"Actuator","text":"<pre><code>flowchart LR\ns[/Signal/] &amp; e[/Energy/] --&gt;\nActuator --&gt;\nmf[/\"Motion/Force/Light\"/]</code></pre> <ul> <li>Motor</li> <li>Valve controller</li> <li>LED light</li> </ul>"},{"location":"CS_Electives/IoT/Devices/#classification_1","title":"Classification","text":"Class Subclass Example Electric Linear Electric Bell Rotatory Motor Fluid Power Linear Cylinder, Piston Rotary Cylinder, Piston Chain Linear Sprockets, sections of chain Manual Linear GearboxesWheels Rotatory LeversHandwheels"},{"location":"CS_Electives/IoT/Devices/Color_Sensor/","title":"Color Sensor","text":"Sensor IR Filter Accuracy ISL29125 \u2705 Best TCS34725 \u2705 TCS3414 \u2705 TCS3200 \u274c TCS230 \u274c"},{"location":"CS_Electives/IoT/Devices/Color_Sensor/#ts230","title":"TS230","text":""},{"location":"CS_Electives/IoT/Devices/Color_Sensor/#calibration","title":"Calibration","text":"<pre><code>/*\n  Color Sensor Calibration\n  color-sensor-calib.ino\n  Calibrate RGB Color Sensor output Pulse Widths\n  Uses values obtained for RGB Sensor Demo sketch \n\n  DroneBot Workshop 2020\n  https://dronebotworkshop.com\n*/\n\n// Define color sensor pins\n\n#define S0 4\n#define S1 5\n#define S2 6\n#define S3 7\n#define sensorOut 8\n\n// Variables for Color Pulse Width Measurements\n\nint redPW = 0;\nint greenPW = 0;\nint bluePW = 0;\n\nvoid setup() {\n\n  // Set S0 - S3 as outputs\n  pinMode(S0, OUTPUT);\n  pinMode(S1, OUTPUT);\n  pinMode(S2, OUTPUT);\n  pinMode(S3, OUTPUT);\n\n  // Set Sensor output as input\n  pinMode(sensorOut, INPUT);\n\n  // Set Pulse Width scaling to 20%\n  digitalWrite(S0,HIGH);\n  digitalWrite(S1,LOW);\n\n  // Setup Serial Monitor\n  Serial.begin(9600);\n}\n\nvoid loop() {\n\n  // Read Red Pulse Width\n  redPW = getRedPW();\n  // Delay to stabilize sensor\n  delay(200);\n\n  // Read Green Pulse Width\n  greenPW = getGreenPW();\n  // Delay to stabilize sensor\n  delay(200);\n\n  // Read Blue Pulse Width\n  bluePW = getBluePW();\n  // Delay to stabilize sensor\n  delay(200);\n\n  // Print output to Serial Monitor\n  Serial.println(\n    \"RGB(\" +\n    String(redPW) + \",\" +\n    String(greenPW) + \",\" +\n    String(bluePW) +\n    \")\"\n  );\n}\n\n\n// Function to read Red Pulse Widths\nint getRedPW() {\n\n  // Set sensor to read Red only\n  digitalWrite(S2,LOW);\n  digitalWrite(S3,LOW);\n  // Define integer to represent Pulse Width\n  int PW;\n  // Read the output Pulse Width\n  PW = pulseIn(sensorOut, LOW);\n  // Return the value\n  return PW;\n\n}\n\n// Function to read Green Pulse Widths\nint getGreenPW() {\n\n  // Set sensor to read Green only\n  digitalWrite(S2,HIGH);\n  digitalWrite(S3,HIGH);\n  // Define integer to represent Pulse Width\n  int PW;\n  // Read the output Pulse Width\n  PW = pulseIn(sensorOut, LOW);\n  // Return the value\n  return PW;\n\n}\n\n// Function to read Blue Pulse Widths\nint getBluePW() {\n\n  // Set sensor to read Blue only\n  digitalWrite(S2,LOW);\n  digitalWrite(S3,HIGH);\n  // Define integer to represent Pulse Width\n  int PW;\n  // Read the output Pulse Width\n  PW = pulseIn(sensorOut, LOW);\n  // Return the value\n  return PW;\n\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/Color_Sensor/#get-values","title":"Get Values","text":"<pre><code>/*\n  RGB Color Sensor Demonstration\n  rgb-color-sensor-demo.ino\n  Read RGB values from Color Sensor\n  Must use calibration values from Color Sensor Calibration Sketch\n\n  DroneBot Workshop 2020\n  https://dronebotworkshop.com\n*/\n\n// Define color sensor pins\n\n#define S0 4\n#define S1 5\n#define S2 6\n#define S3 7\n#define sensorOut 8\n\n// Calibration Values\n// Get these from Calibration Sketch\n\nint redMin = 28; // Red minimum value pulse width from calibration\nint redMax = 204; // Red maximum value pulse width from calibration\nint greenMin = 30; // Green minimum value pulse width from calibration\nint greenMax = 242; // Green maximum value pulse width from calibration\nint blueMin = 26; // Blue minimum value pulse width from calibration\nint blueMax = 220; // Blue maximum value pulse width from calibration\n\n// Variables for Color Pulse Width Measurements\n\nint redPW = 0;\nint greenPW = 0;\nint bluePW = 0;\n\n// Variables for final Color values\n\nint redValue;\nint greenValue;\nint blueValue;\n\nvoid setup() {\n\n  // Set S0 - S3 as outputs\n  pinMode(S0, OUTPUT);\n  pinMode(S1, OUTPUT);\n  pinMode(S2, OUTPUT);\n  pinMode(S3, OUTPUT);\n\n  // Set Sensor output as input\n  pinMode(sensorOut, INPUT);\n\n  // Set Frequency scaling to 20%\n  digitalWrite(S0,HIGH);\n  digitalWrite(S1,LOW);\n\n  // Setup Serial Monitor\n  Serial.begin(9600);\n}\n\nvoid loop() {\n\n  // Read Red value\n  redPW = getRedPW();\n  // Map to value from 0-255\n  redValue = map(redPW, redMin,redMax,255,0);\n  // Delay to stabilize sensor\n  delay(200);\n\n  // Read Green value\n  greenPW = getGreenPW();\n  // Map to value from 0-255\n  greenValue = map(greenPW, greenMin,greenMax,255,0);\n  // Delay to stabilize sensor\n  delay(200);\n\n  // Read Blue value\n  bluePW = getBluePW();\n  // Map to value from 0-255\n  blueValue = map(bluePW, blueMin,blueMax,255,0);\n  // Delay to stabilize sensor\n  delay(200);\n\n  // Print output to Serial Monitor\n  Serial.println(\n    \"RGB(\" +\n    String(redValue) + \",\" +\n    String(greenValue) + \",\" +\n    String(blueValue) +\n    \")\"\n  );\n\n}\n\n\n// Function to read Red Pulse Widths\nint getRedPW() {\n\n  // Set sensor to read Red only\n  digitalWrite(S2,LOW);\n  digitalWrite(S3,LOW);\n  // Define integer to represent Pulse Width\n  int PW;\n  // Read the output Pulse Width\n  PW = pulseIn(sensorOut, LOW);\n  // Return the value\n  return PW;\n\n}\n\n// Function to read Green Pulse Widths\nint getGreenPW() {\n\n  // Set sensor to read Green only\n  digitalWrite(S2,HIGH);\n  digitalWrite(S3,HIGH);\n  // Define integer to represent Pulse Width\n  int PW;\n  // Read the output Pulse Width\n  PW = pulseIn(sensorOut, LOW);\n  // Return the value\n  return PW;\n\n}\n\n// Function to read Blue Pulse Widths\nint getBluePW() {\n\n  // Set sensor to read Blue only\n  digitalWrite(S2,LOW);\n  digitalWrite(S3,HIGH);\n  // Define integer to represent Pulse Width\n  int PW;\n  // Read the output Pulse Width\n  PW = pulseIn(sensorOut, LOW);\n  // Return the value\n  return PW;\n\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/Color_Sensor/#isl29125","title":"ISL29125","text":""},{"location":"CS_Electives/IoT/Devices/Color_Sensor/#calibration_1","title":"Calibration","text":"<pre><code>/******************************************************************************\nISL29125_basics.ino\nSimple example for using the ISL29125 RGB sensor library.\nJordan McConnell @ SparkFun Electronics\n11 Apr 2014\nhttps://github.com/sparkfun/ISL29125_Breakout\n\nThis example declares an SFE_ISL29125 object called RGB_sensor. The \nobject/sensor is initialized with a basic configuration so that it continuously\nsamples the light intensity of red, green and blue spectrums. These values are\nread from the sensor every 2 seconds and printed to the Serial monitor.\n\nDeveloped/Tested with:\nArduino Uno\nArduino IDE 1.0.5\n\nRequires:\nSFE_ISL29125_Library\n\nThis code is beerware.\nDistributed as-is; no warranty is given. \n******************************************************************************/\n\n#include &lt;Wire.h&gt;\n#include \"SFE_ISL29125.h\"\n\n// Declare sensor object\nSFE_ISL29125 RGB_sensor;\n\nvoid setup()\n{\n  // Initialize serial communication\n  Serial.begin(115200);\n\n  // Initialize the ISL29125 with simple configuration so it starts sampling\n  if (RGB_sensor.init())\n  {\n    Serial.println(\"Sensor Initialization Successful\\n\\r\");\n  }\n}\n\n// Read sensor values for each color and print them to serial monitor\nvoid loop()\n{\n  // Read sensor values (16 bit integers)\n  unsigned int red = RGB_sensor.readRed();\n  unsigned int green = RGB_sensor.readGreen();\n  unsigned int blue = RGB_sensor.readBlue();\n\n  // Print out readings, change HEX to DEC if you prefer decimal output\n  Serial.print(\"Red: \"); Serial.println(red,DEC);\n  Serial.print(\"Green: \"); Serial.println(green,DEC);\n  Serial.print(\"Blue: \"); Serial.println(blue,DEC);\n  Serial.println();\n  delay(2000);\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/Color_Sensor/#get-values_1","title":"Get Values","text":"<pre><code>/*\n  ISL29125 RGB sensor test\n  isl29125-test.ino\n  Displays RGB values for ISL29125 RGB sensor\n  Uses values obtained with Sparkfun ISL29125 RGB sensor basic demo\n  Uses Sparkfun ISL29125 Library\n\n  DroneBot Workshop 2020\n  https://dronebotworkshop.com\n*/\n\n// Include I2C Library\n#include &lt;Wire.h&gt;\n\n// Include Sparkfun ISL29125 Library\n#include \"SFE_ISL29125.h\"\n\n// Declare sensor object\nSFE_ISL29125 RGB_sensor;\n\n// Calibration values\n\nunsigned int redlow = 0;\nunsigned int redhigh = 0;\nunsigned int greenlow = 0;\nunsigned int greenhigh = 0;\nunsigned int bluelow = 0;\nunsigned int bluehigh = 0;\n\n// Declare RGB Values\nint redVal = 0;\nint greenVal = 0;\nint blueVal = 0;\n\n\nvoid setup()\n{\n  // Initialize serial communication\n  Serial.begin(115200);\n\n  // Initialize the ISL29125 with simple configuration so it starts sampling\n  if (RGB_sensor.init())\n  {\n    Serial.println(\"Sensor Initialization Successful\\n\\r\");\n  }\n}\n\n\nvoid loop()\n{\n  // Read sensor values (16 bit integers)\n  unsigned int red = RGB_sensor.readRed();\n  unsigned int green = RGB_sensor.readGreen();\n  unsigned int blue = RGB_sensor.readBlue();\n\n  // Convert to RGB values\n  int redV = map(red, redlow, redhigh, 0, 255);\n  int greenV = map(green, greenlow, greenhigh, 0, 255);\n  int blueV = map(blue, bluelow, bluehigh, 0, 255);\n\n  // Constrain to values of 0-255\n  redVal = constrain(redV, 0, 255);\n  greenVal = constrain(greenV, 0, 255);\n  blueVal = constrain(blueV, 0, 255);\n\n  Serial.print(\"Red: \"); \n  Serial.print(redVal);\n  Serial.print(\" - Green: \");\n  Serial.print(greenVal);\n  Serial.print(\" - Blue: \"); \n  Serial.println(blueVal);\n\n  // Delay for sensor to stabilize\n  delay(2000);\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/Color_Sensor/#references","title":"References","text":"<ul> <li>Arduino Color Sensing - TCS230 &amp; ISL29125</li> <li>#322 12 Light Sensors Tested: Measuring Light with Microcontrollers Arduino or ESP8266, ESP32 - YouTube </li> </ul>"},{"location":"CS_Electives/IoT/Devices/DHT/","title":"Digital Humidity and Temperature","text":"<p>Measure humidity and temperature</p> <p>2 variants</p> DHT 11 DHT 22 Temperature Range 0 - 50C -40 - 125C Temperature Accuracy \u00b1 2C \u00b1 0.5C Humidity Range 20-80% 0-100% Humidity Accuracy \u00b1 5% \u00b1 2-5% Sampling Rate(readings per second) 1Hz 0.5Hz Body Size 15.5 x 12 x 5.5 mm 15.1 x 25 x 7.7 mm Operating Voltage 3-5V 3-5V Max Current during measurement 2.5mA 2.5mA"},{"location":"CS_Electives/IoT/Devices/DHT/#working","title":"Working","text":"\\[ \\text{HH} \\ \\text{LH} \\ \\text{HT} \\ \\text{LT} \\ \\text{CP} \\] <p>where</p> <ul> <li>\\(HH=\\) High Humidity -&gt; Humidity Reading in %</li> <li>\\(LH=\\) Low Humidity</li> <li>\\(HT=\\) High Temperature -&gt; Temperature Reading</li> <li>\\(LT=\\) Low Temperature</li> <li>\\(CP=\\) Checksum Parity</li> </ul>"},{"location":"CS_Electives/IoT/Devices/DHT/#code","title":"Code","text":"<pre><code>#include &lt;DHT.h&gt; // not in-built\n\nDHT dht(pin_name, type_of_sensor);\n\ndht.begin();\n\ndht.readTemperature(); // returns Temperature in C\ndht.readTemperature(True); // returns Temperature in F\n// returns nan for invalid value \n\ndht.readHumidity() // returns Humidity %\n// returns nan for invalid value\n</code></pre> <pre><code>#include &lt;DHT.h&gt;\n\nDHT dht(D1, DHT11);\nfloat hum, temp;\n\nvoid setup() {\n  dht.begin();\n  Serial.begin(9600);\n}\nvoid loop() {\n  hum = dht.readHumidity();\n  temp = dht.readTemperature();\n\n  Serial.println(\n    String(hum) + \" \" + String(temp)\n  );\n\n  delay(5000);\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/DHT/#dependencies","title":"Dependencies","text":"<ul> <li>AdaFruit Unified Sensor</li> <li>DHT_Sensor</li> <li>Time</li> <li>TinyGSM</li> </ul>"},{"location":"CS_Electives/IoT/Devices/DHT/#sensor","title":"Sensor","text":"<p>3 pins</p> <ul> <li>VCC</li> <li>GND</li> <li>DOUT/Data/Signal</li> </ul>"},{"location":"CS_Electives/IoT/Devices/GPS/","title":"GPS","text":"<p>Receiver devices continuously receive signals from satellites and help calculate distance between receiver devices and network of satellites. The distance estimated with the help of 4/more satellites present in outer space help locate the exact position of the object.</p>"},{"location":"CS_Electives/IoT/Devices/IC/","title":"Integrated Chips","text":""},{"location":"CS_Electives/IoT/Devices/IC/#comparator-ic","title":"Comparator IC","text":"<p>Compares 2 voltages/currents and switch at the output to indicate which is larger</p> <p>It is an op-amp (operation amplifier)</p>"},{"location":"CS_Electives/IoT/Devices/IC/#lm358","title":"LM358","text":"<p>8-pins</p> <ul> <li>2 x 2 inputs</li> <li>2 outputs</li> <li>Ground</li> <li>VCC</li> </ul> <p></p>"},{"location":"CS_Electives/IoT/Devices/IMU/","title":"IMU","text":"<p>Inertial Measurement Unit</p> <p>Measure velocity, orientation, and gravitational forces together.</p>"},{"location":"CS_Electives/IoT/Devices/IMU/#components","title":"Components","text":"Component Detect Accelerometer Accelerations in \\(X, Y, Z\\) directions, using static &amp; dynamic forces Gyroscope Angular momentum orientation Magnetic Compass Direction"},{"location":"CS_Electives/IoT/Devices/IMU/#challenges","title":"Challenges","text":"<ul> <li>Interpretability</li> <li>Sensor drift: Sensors need to recalibrated regularly</li> </ul>"},{"location":"CS_Electives/IoT/Devices/IR/","title":"Infrared Sensor","text":"<p>Working principle: Reflection of light</p>"},{"location":"CS_Electives/IoT/Devices/IR/#uses","title":"Uses","text":"<ul> <li>Obstacle detection</li> <li>Differentiate between colors </li> </ul>"},{"location":"CS_Electives/IoT/Devices/IR/#components","title":"Components","text":"<ul> <li>Transmitter: IR LED</li> <li>Receiver: Photodiode (Reverse LED)</li> <li>Comparator IC for voltage comparison</li> <li>Potentiometer to set sensitivity of sensor, by controlling voltage threshold for comparator</li> <li>\\(V_s \\ne \\{0, V_{cc} \\}\\)</li> </ul>"},{"location":"CS_Electives/IoT/Devices/IR/#working-steps","title":"Working steps","text":"<ol> <li>Transmitter emits IR rays</li> <li>Light gets reflected by obstacle</li> <li>Receiver gets the reflected light</li> <li>Received light converted into voltage</li> </ol>"},{"location":"CS_Electives/IoT/Devices/IR/#limitations","title":"Limitations","text":"<ul> <li>Cannot obtain position of obstacle; only for Object-Detection (binary)</li> <li>Obstacle detection only works for light-colored obstacle</li> <li>dark colored objects will absorb light</li> </ul>"},{"location":"CS_Electives/IoT/Devices/IR/#circuit-diagram","title":"Circuit Diagram","text":""},{"location":"CS_Electives/IoT/Devices/IR/#code","title":"Code","text":"<pre><code>int objected_detected\n\nvoid setup(){\n  pinMode(D1, INPUT);       // sensor\n  pinMode(D2, OUTPUT);  // output device (LED)\n\n  Serial.begin(9600);\n}\nvoid loop(){\n  objected_detected = digitalRead(D1);\n\n  Serial.println(objected_detected);\n\n    if (objected_detected == 1) {\n    digitalWrite(D2, HIGH);\n  } else {\n    digitalWrite(D2, LOW);\n  }\n\n  delay(500);\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/LCD_Display/","title":"LCD Display","text":"<pre><code>/*\n  LiquidCrystal Library - Hello World\n\n Demonstrates the use a 16x2 LCD display.  The LiquidCrystal\n library works with all LCD displays that are compatible with the\n Hitachi HD44780 driver. There are many of them out there, and you\n can usually tell them by the 16-pin interface.\n\n This sketch prints \"Hello World!\" to the LCD\n and shows the time.\n\n  The circuit:\n * LCD RS pin to digital pin 12\n * LCD Enable pin to digital pin 11\n * LCD D4 pin to digital pin 5\n * LCD D5 pin to digital pin 4\n * LCD D6 pin to digital pin 3\n * LCD D7 pin to digital pin 2\n * LCD R/W pin to ground\n * LCD VSS pin to ground\n * LCD VCC pin to 5V\n * 10K resistor:\n * ends to +5V and ground\n * wiper to LCD VO pin (pin 3)\n\n This example code is in the public domain.\n\n https://docs.arduino.cc/learn/electronics/lcd-displays\n\n*/\n\n// include the library code:\n#include &lt;LiquidCrystal.h&gt;\n\n// initialize the library by associating any needed LCD interface pin\n// with the arduino pin number it is connected to\nconst int rs = 12, en = 11, d4 = 5, d5 = 4, d6 = 3, d7 = 2;\nLiquidCrystal lcd(rs, en, d4, d5, d6, d7);\n\nvoid setup() {\n  // set up the LCD's number of columns and rows:\n  lcd.begin(16, 2);\n  // Print a message to the LCD.\n  lcd.print(\"hello, world!\");\n}\n\nvoid loop() {\n  // set the cursor to column 0, line 1\n  // (note: line 1 is the second row, since counting begins with 0):\n  lcd.setCursor(0, 1);\n  // print the number of seconds since reset:\n  lcd.print(millis() / 1000);\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/LDR/","title":"LDR","text":"<p>Light Dependent Resistor</p> <p>Output \\(\\in [0, 1023]\\) $$ \\begin{aligned} R &amp;\\propto \\dfrac{1}{L_V} \\ \\implies I &amp;\\propto L_V \\end{aligned} $$ where</p> <ul> <li>\\(R =\\) Resistance</li> <li>\\(L_V =\\) Intensity of incident light</li> <li>\\(I =\\) Current</li> </ul>"},{"location":"CS_Electives/IoT/Devices/LDR/#applications","title":"Applications","text":"<ul> <li>Smart street lights</li> <li>Auto-brightness on Phone</li> </ul> <p>No polarity, as resistors don\u2019t have any polarity</p>"},{"location":"CS_Electives/IoT/Devices/LDR/#connection","title":"Connection","text":""},{"location":"CS_Electives/IoT/Devices/LDR/#code","title":"Code","text":"<pre><code>int reading;\n\nvoid setup(){\n  pinMode(A0, INPUT); // LDR\n  pinMode(D2, OUTPUT); // LED\n\n\n  Serial.begin(9600);\n}\nvoid loop(){\n  reading = analogRead(A0);\n\n  Serial.println(reading);\n\n  // if incident light too low -&gt; environment too dark\n  // then turn on output light\n  if (reading &lt; 50){\n    digitalWrite(D2, HIGH);\n  }\n  else {\n    digitalWrite(D2, LOW);\n  }\n\n  delay(500);\n}\n</code></pre>"},{"location":"CS_Electives/IoT/Devices/LED/","title":"LED","text":"<p>Light-Emitting Diode</p> <p>Polarized component (+ve Anode and -ve Cathode terminals)</p> <p></p>"},{"location":"CS_Electives/IoT/Devices/LED/#rgb-led","title":"RGB LED","text":"<p>Inputs Red, Green, Blue values</p>"},{"location":"CS_Electives/IoT/Devices/LiDar/","title":"LiDar","text":""},{"location":"CS_Electives/IoT/Devices/LiDar/#lidar_1","title":"LiDaR","text":"<p>Light Detection and Ranging</p> <p>Remote sensing method using light in the form of pulsed laser to measure ranges (variable distances).</p> <p>These light pulses generate precise, 2D/3D maps.</p> <p>Lidar instrument consists of a laser, scanner, specialized receiver.</p>"},{"location":"CS_Electives/IoT/Devices/Odometer/","title":"Odometer","text":"<p>Use of data from motion sensors to estimate change in position over time. It is used in robotics by some legged/wheeled robots to estimate their position wrt starting location.</p> <p>Types</p> <ul> <li>Wheel odometry</li> <li>Laser/Ultrasonic odometry</li> <li>GPS</li> <li>INS (Interval navigation system)</li> <li>Visual Odometry (VO)</li> </ul> <p>Encoders are fundamental robotics motion control as they provide accurate and precise feedback about angle, position, and speed.</p>"},{"location":"CS_Electives/IoT/Devices/Radar/","title":"Radar","text":"<p>Uses radio waves to detect vehicles and other obstructions in the environment.</p> <p>The duration of pulse returning can be used to determine the other objects\u2019 speed and direction of motion.</p>"},{"location":"CS_Electives/IoT/Devices/Relay/","title":"Relay","text":"<p>Electromagnetic switch</p> <p>Working principle: Electromagnetic induction</p> <p></p> <p>Be careful when working with relays, as they may short-circuit. Don\u2019t touch the back side and don\u2019t keep it near other conductors and electronics</p>"},{"location":"CS_Electives/IoT/Devices/Relay/#pins","title":"Pins","text":"<ul> <li>VCC: +5v</li> <li>GND</li> <li>IN: Input (D2)</li> <li>NC: Normally-closed/connected</li> <li>NO: Normally-open</li> <li>COM: Common</li> </ul> <p>Internal connections</p> <ul> <li>NC &amp; COM with spring</li> <li>NO &amp; IN</li> </ul> IN NO NC - COM NO - COM On Behaves like a magnet Break Attracted Off No effect RevertMakes a \u2018tick-tick\u2019 sound Break <p>If there is no \u2018tick-tick\u2019 sound, then the relay isn\u2019t getting sufficient voltage</p>"},{"location":"CS_Electives/IoT/Devices/Stereo_Camera/","title":"Stereo Cameras","text":"<p>Single camera/ordinary multi-camera system can only help in basic obstacle detection/surround view. However, in order to measure depth to infer and analyze distance between objects, cameras ned to act as a stereo pair</p> <p>Usually contain 2 cameras placed horizontally next to each other. It helps cameras to view the same area and assess the depth and distance of the object using pixel disparity technique.</p> <p>They are often paired with LiDar sensor to improve reliability and accuracy.</p> <p></p>"},{"location":"CS_Electives/IoT/Devices/Ultrasonic/","title":"Ultrasonic","text":"<p>Technical name: HC-SR04</p> <p>More precise than IR sensor</p> <p>Working principle: Reflection of soundwaves</p> <p>Ultrasonic waves travel faster than speed of audible sound</p> <p>Range: 3cm to 4m</p> <p>Accuracy: 3mm</p>"},{"location":"CS_Electives/IoT/Devices/Ultrasonic/#components","title":"Components","text":"<ul> <li>Emitter</li> <li> <p>Emitter sends out an Ultrasonic pulse at 40 kHz which travels through the air, and returns if it bounces back from an object.</p> </li> <li> <p>Receiver</p> </li> </ul>"},{"location":"CS_Electives/IoT/Devices/Ultrasonic/#measurement","title":"Measurement","text":"<p>Measures distance of object by emitting Ultrasonic sound waves, and converts reflected sound into electrical signal, and then by calculating the travel time &amp; speed of sound, the distance can be calculated. $$ D = S \\times \\dfrac{t}{2} $$</p>"},{"location":"CS_Electives/IoT/Devices/Ultrasonic/#pins","title":"Pins","text":"<ul> <li>VCC: +5v</li> <li>GND</li> <li>TRIG: Emitter (D3)</li> <li>ECHO: Receiver </li> </ul>"},{"location":"CS_Electives/IoT/Devices/Ultrasonic/#code","title":"Code","text":"<pre><code>int emit_duration = 10; // microseconds\nlong speed = 330; // m/s\nlong time;\n\nvoid setup() {\n  pinMode(2, OUTPUT); // trig\n  pinMode(3, INPUT); // echo\n\n  Serial.begin(9600);\n}\nvoid loop() {\n  // emit ultrasonic waves for 10 microsec\n  digitalWrite(2, HIGH);\n  delayMicroseconds(emit_duration);\n\n  digitalWrite(2, LOW);\n  delayMicroseconds(emit_duration);\n\n  time = pulseIn(3, HIGH); // microseconds\n  time /= 1000 * 1000; // seconds\n\n  distance = speed * (time/2);\n\n  delay(5000);\n}\n</code></pre>"},{"location":"CS_Electives/LLM/","title":"Large Language Models","text":""},{"location":"CS_Electives/LLM/#references","title":"References","text":"<ul> <li> Introduction to large language models</li> <li> LLM Bootcamp - Spring 2023 | The Full Stack</li> </ul>"},{"location":"CS_Electives/LLM/01_Introduction/","title":"Introduction","text":""},{"location":"CS_Electives/LLM/01_Introduction/#text-generation-methodologies","title":"Text Generation Methodologies","text":"<ul> <li>\\(n\\)-grams</li> <li>Bigrams</li> <li>Trigrams</li> <li>Bag of words</li> <li>Bag of tokens; token = subwords<ul> <li>Byte pair encoding</li> </ul> </li> </ul> <p>Tokenization causes issues - LLM cannot spell words - LLM cannot perform simple string processing tasks, such as reversing a string - LLM performs worse in non-English languages - LLM is bad at simple arithmetic - LLM prefers YAML over JSON with LLMs - LLM breaks due to special/unstable tokens     - <code>&lt;|endoftext|&gt;</code>     - trailing whitespace     - <code>SolidGoldMagikarp</code>     - special tokens - LLM is not end-to-end language modelling</p>"},{"location":"CS_Electives/LLM/01_Introduction/#architectures","title":"Architectures","text":"<ul> <li>MLP</li> <li>RNN</li> <li>GRU</li> <li>LSTM</li> <li>Transformers</li> </ul>"},{"location":"CS_Electives/Machine_Learning/","title":"Machine Learning","text":"<p>One of the hottest topics right now, covers foundational concepts related to the field of ML.</p> <p>The first few topics are common to all aspects of machine learning.</p>"},{"location":"CS_Electives/Machine_Learning/#references","title":"References","text":"<ul> <li> Machine Learning | Dr. Pranav | BITS Pilani Dubai Campus</li> <li> Modern Data Analysis for Economics</li> <li> Machine Learning From Data</li> <li> Machine Learning From Data | Prof Yaser Abu Mostafa | Caltech</li> <li> Machine Learning From Data | Rensselaer Prof. Malik Magdon-Ismail</li> <li> Machine Learning | Gary Holness | Clark University</li> <li> Machine Learning From Data | Uzma Mushtaque</li> <li> Machine Learning From Data | Course Handbook</li> <li> Nando de Freitas<ul> <li> Undergraduate</li> <li> Graduate</li> </ul> </li> <li> Quantum Machine Learning | University of Toronto</li> <li> Quantum Machine Learning | Qiskit</li> <li> Machine Learning | Stanford</li> <li> Machine Learning| Andrew Ng Coursera too introductory</li> <li> Stanford CS229: Machine Learning | Andrew Ng | 2018</li> <li> Stanford CS229M: Machine Learning Theory</li> <li> Advanced Machine Learning | Sergey Plis | Georgia State University</li> <li> Online Machine Learning | IIT Bombay</li> <li> Machine Learning | mathematicalmonk</li> <li> MIT 9.520/6.860S - Statistical Learning Theory and Applications</li> <li> Statistical Learning with Python | Stanford Online<ul> <li> Material</li> <li> Book</li> </ul> </li> <li> Intro to Machine Learning and Statistical Pattern Classification | Sebastian Raschka</li> <li> Machine Learning | WQU Saul Leung</li> <li> Multimodal Machine Learning | CMU Fall 2022</li> <li> MLOps | Andrew Ng Coursera</li> <li> Machine Learning Yearning | Andrew Ng</li> <li> Advanced Machine Learning | Florian Marquardt</li> <li> Applied Machine Learning (Cornell Tech CS 5787, Fall 2020) | Volodymyr Kuleshov</li> <li> Machine Learning for Intelligent Systems | Kilian Weinberger | Cornell</li> <li> Applied Machine Learning | Andreas Mueller</li> <li> Probabilistic Machine Learning | T\u00fcbingen Machine Learning | Philipp Hennig</li> <li> Towards Bayesian Regression | Kapil Sachdeva</li> <li> Advanced Machine Learning 2020, CSE, IIT Kharagpur</li> <li> Introductory Applied Machine Learning | University of Edinburgh | Victor Lavrenko</li> <li> Gaussian Processes | Imperial College</li> <li> Gaussian Processes | Modeling, Identification, Control (A. Sala)</li> <li> From Data to Decisions: Measurement, Uncertainty, Analysis and Modeling | Chris Mack | University of Texas</li> <li> Learning Theory | Se Young Yun</li> <li> Machine Learning Explainability | Stanford</li> <li> Machine Learning with Graphs | Stanford</li> <li> Fairness in Machine Learning | MIT</li> <li> MLOps | Pragmatic AI Labs</li> <li> Cluster Analysis | TU Dortmund</li> <li> Outlier Detection | TU Dortmund</li> <li> Evaluating Machine Learning Models and Their Diagnostic Value | Gael Varoquaux</li> <li> Machine learning in Python with scikit-learn | Gael Varoquaux | Inria</li> <li> Anomaly Detection | Aric LaBarr</li> <li> Bayesian Data Analysis</li> <li> Bayesian Evidential Learning</li> <li> Model Development | Dimitri Bianco</li> <li> Pitfalls<ul> <li> p-hacking</li> <li> Common Pitfalls of (Cybersecurity) Machine Learning Research | Patrik Goldschmidt</li> <li> Machine Learning Pitfalls</li> </ul> </li> <li> Machine Learning for Engineers</li> <li> Machine Learning with R | Equitable Equations</li> <li> Modern Anomaly &amp; Novelty Detection | LLMs Explained</li> <li> Machine Learning | Meanxai<ul> <li> Part 1</li> <li> Part 2</li> </ul> </li> <li> Machine Learning | Caltech</li> <li> Reliable Time-Series Forecasting | MLBoost<ul> <li>It is labelled as time-series forecasting, but this actually covers evaluation metrics common to ML</li> </ul> </li> <li> Supervised Learning | Zak Varty</li> <li> Regression | Brian Caffo</li> <li> Computational Science &amp; Engineering | John Kitchin<ul> <li> pycse</li> <li> Research</li> </ul> </li> <li> Distribution-Free Uncertainty Quantification | Anastasios Nikolas Angelopoulos</li> <li> Statistical learning 2102575 Y2024 | Gabby Suwichaya | Chulalongkorn University</li> <li> STATS 205 - Hierarchical Linear Models (Spring 2024) | JSB UCLA</li> <li> STATS M254 - Statistical Methods in Computational Biology (Spring 2024) | JSB UCLA</li> <li> Generalized Linear Model | Andy Field</li> <li> Conformal Prediction | PyLadies Amsterdam</li> <li> Regression Modeling | Amelia McNamara</li> <li> Machine Learning | StatQuest</li> <li> Machine Learning for Business Students | Shahin Ashkiani</li> <li> BIOS 6611</li> <li> Machine Learning Practice | The University of Oklahoma</li> <li> Introduction to Data Science| Orange Data Mining</li> <li> Generalized Linear Models | Julia Wrobel | ColoradoSPH</li> <li> Statistics and Data Science | Lucy Stats</li> <li> Statistical Machine Learning | Leslie Myint</li> <li> Machine Learning Lectures - Deep Understanding of the Theory | AMILE - Machine Learning with Christian Nabert</li> <li> Intuition for the Algorithms of Machine Learning | Cynthia Rudin</li> <li> Astrostatistics and Machine Learning | Institut Teknologi Bandung (ITB)</li> <li> Spatial Cluster Analysis | University of Chicago</li> <li> Statistics and machine learning | yuzaR Data Science</li> <li> Checking Error Assumptions for a Linear Regression Model | Joshua French</li> <li> Data Science Methods and Statistical Learning | Samin Aref</li> <li> Machine Learning Observability | Evidently AI</li> <li> Seminar Data Science for Economics | Tilburg University</li> <li> Machine Learning | University of Utah</li> <li> Machine Learning | Tile Stats</li> <li> Blogs/Videos<ul> <li> https://sarem-seitz.com/</li> <li> Winning with Simple, even Linear, Models | Vincent Warmerdam</li> <li> Calmcode | Vincent Warmerdam</li> <li> Mindful Modeler</li> </ul> </li> <li> Certifications<ul> <li> Basic<ul> <li> https://www.udemy.com/course/statistics-for-data-science-and-business-analysis/   statistics</li> <li> https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/   ML</li> <li> https://www.udemy.com/course/machine-learning-regression-and-classification-math-inc/ ML</li> <li> https://www.udemy.com/course/ensemble-machine-learning-in-python/ ML</li> <li> https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009t   ML</li> <li> https://www.coursera.org/learn/machine-learning   ML by Andrew</li> </ul> </li> <li> Intermediate<ul> <li> https://www.coursera.org/specializations/mathematics-machine-learning ML by Andrew</li> <li> https://www.coursera.org/specializations/deep-learning    Deep Learning by Andrew</li> </ul> </li> </ul> </li> <li> Papers<ul> <li> The ML Test Score: A Rubric for ML Production Readiness and Technical Debt Reduction | Google</li> <li> Software Engineering for Machine Learning: A Case Study | Microsoft</li> <li> A Data Quality-Driven View of MLOps</li> <li> How to avoid machine learning pitfalls: a guide for academic researchers</li> </ul> </li> <li> Books<ul> <li> Interpretable Machine Learning | Christoph Molnar</li> <li> Interpretable Machine Learning with Python | Serg Masis</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/#current-video","title":"Current Video","text":""},{"location":"CS_Electives/Machine_Learning/01_Intro/","title":"Introduction","text":""},{"location":"CS_Electives/Machine_Learning/01_Intro/#machine-learning","title":"Machine Learning","text":"<p>Field of study that enables computers to learn without being explicitly programmed; machine learns how to perform task \\(T\\) from experience \\(E\\) with performance measure \\(P\\).</p> <p>Machine learning is necessary when it is not possible for us to make rules, ie, easier for the machine to learn the rules on its own</p> <p></p> <pre><code>flowchart LR\n\nsubgraph Machine Learning\n    direction LR\n    i2[Past&lt;br/&gt;Input] &amp; o2[Past&lt;br/&gt;Output] --&gt;\n    a(( )) --&gt;\n    r2[Derived&lt;br/&gt;Rules/&lt;br/&gt;Functions]\n\n    r2 &amp; ni[New&lt;br/&gt;Input] --&gt;\n    c(( )) --&gt;\n    no[New&lt;br/&gt;Output]\nend\n\nsubgraph Traditional Programming\n    direction LR\n    r1[Standard&lt;br/&gt;Rules/&lt;br/&gt;Functions] &amp; i1[New&lt;br/&gt;Input] --&gt;\n    b(( )) --&gt;\n    o1[New&lt;br/&gt;Output]\nend</code></pre>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#why-do-we-need-ml","title":"Why do we need ML?","text":"<p>To perform tasks which are easy for humans, but difficult to generate a computer program for it</p>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#requirements","title":"Requirements","text":"<ol> <li>\\(\\exists\\) pattern</li> <li>If \\(\\not \\exists\\) pattern and its just noise, it is impossible to model it</li> <li>We cannot quantify pattern mathematically</li> <li>\\(\\exists\\) data</li> </ol>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#modelling-lifecycle","title":"Modelling Lifecycle","text":"<pre><code>flowchart TB\n\nsubgraph Mathematics\ndirection TB\nmp[Math problem]\nmm[Mathematical Model]\nms[Solution]\nend\n\nsubgraph Real World\ndirection TB\nrwp[/Real world&lt;br/&gt;problem/]\nd[/Data/]\nrws[/Real world&lt;br/&gt;solution/]\nend\n\nd --&gt; |Instantiate| mm\nd --&gt; |Validate| rws\n\nrwp --&gt;\n|Translation| mp --&gt;\n|Model with&lt;br/&gt;assumptions| mm --&gt;\n|Solve| ms --&gt;\n|Translation| rws --&gt;\n|Review &amp; correct| rwp</code></pre>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#guiding-principles","title":"Guiding Principles","text":"Principle Questions Relevance Is the use of ML in a given context solving an appropriate problem Representativeness Is the training data appropriately selected Value - Do the predictions inform human decisions in a meaningful way- Does the machine learning model produce more accurate predictions than alternative methods- Does it explain variation more completely than alternative methods Explainability - Data selection, Model selection, (un)intended consequences- How effectively is use of ML communicated Auditability Can the model's decision process be queried/monitored by external actors Equity The model should benefit/harm one group disproportionately Accountability/Responsibility Are there mechanisms in place to ensure that someone will be responsible for responding to feedback and redressing harms, if necessary?"},{"location":"CS_Electives/Machine_Learning/01_Intro/#learning-problem","title":"Learning Problem","text":"<p>Given training examples and hypothesis set of candidate models, generate a hypothesis function using a learning algorithm to estimate an unknown target function</p> <p></p> <p>\\(P(x)\\) quantifies relative importance of \\(x\\)</p> <p>Learning model</p> <ul> <li>Learning algorithm</li> <li>Hypothesis set</li> </ul>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#stages-of-machine-learning","title":"Stages of Machine Learning","text":"Stage Sub Steps 1 Data Collection 2 Observations - Influence Detection (Leverage &amp; Outliers) 3 Features - VIF for Multi-Collinearity- Feature importance- Feature selection 4 Causality - Causal Discovery- Causal Theory building 5 Model Building - Feature engineering- Model specification 6 Tuning - Model class/Learning algorithm selection- Hyperparameter tuning 7 IDK - Model comparison- Model selection 8 Evaluation - Performance- Robustness 9 Novelty Detection 10 Inference - Model prediction- Model explanation"},{"location":"CS_Electives/Machine_Learning/01_Intro/#model-engineering","title":"Model Engineering","text":"<pre><code>flowchart LR\nsubgraph Data Engineering\n    direction LR\n    dc[(Data&lt;br/&gt;Collection)] --&gt;\n    |Raw&lt;br/&gt;Data| di[(Data&lt;br/&gt;Ingestion)] --&gt;\n    |Indexed&lt;br/&gt;Data| da[(Data&lt;br/&gt;Analysis, Curation)] --&gt;\n    |Selected&lt;br/&gt;Data| dl[(Data&lt;br/&gt;Labelling)] --&gt;\n    |Labelled&lt;br/&gt;Data| dv[(Data&lt;br/&gt;Validation)] --&gt;\n    |Validated&lt;br/&gt;Data| dp[(Data&lt;br/&gt;Preparation)]\nend\n\ntd[Task&lt;br/&gt;Definition] --&gt;\ndc\n\nsubgraph ML Engineering\n    direction LR\n    l[Learning&lt;br/&gt;Type] --&gt;\n    c[Define&lt;br/&gt;Cost] --&gt;\n    mo[Optimization] --&gt;\n    |Trained&lt;br/&gt;Model| me[Evaluate] --&gt;\n    |KPIs| mv[Model&lt;br/&gt;Validation] --&gt;\n    |Certified&lt;br/&gt;Model| md[/Deploy/]\nend\n\nsubgraph Data Quality\nod{Outlier&lt;br/&gt;Detection}\nad{Anomaly&lt;br/&gt;Detection}\nootd{Out-of-Training-Distribution&lt;br/&gt;Detection}\nend\n\ndp --&gt; od --&gt; |Non-Outlier| ad\nod --&gt; |Non-Outlier| l\nod --&gt; |Outlier| outlier\n\nmd --&gt; rb\n\nsubgraph Models\n    rb[\"Rule-Based Model(s)\"]\n    rb_pc{Rule-based&lt;br/&gt;Confidence}\n\n    ml[\"ML Model(s)\"]\n    ml_pc{ML&lt;br/&gt;Confidence}\n\n    fb[\"Fallback Model(s)\"]\n    fb_pc{Fallback&lt;br/&gt;Confidence}\nend\n\nad --&gt; |Non-Anomalous| ootd\nad --&gt; |Anomalous| anomaly\n\nootd --&gt; |In-Training-Distribution| rb\nootd --&gt; |Out-of-Training-Distribution| ood\n\nrb --&gt; rb_pc\nrb_pc --&gt; |High| rb_pred\nrb_pc --&gt; |Low| ml\n\nml --&gt; ml_pc\nml_pc --&gt; |High| ml_pred\nml_pc --&gt; |Low| fb\n\nfb --&gt; fb_pc\nfb_pc --&gt; |High| fb_pred\nfb_pc --&gt; |Low| us\n\nsubgraph Outputs\n    outlier[/Outlier/]\n    anomaly[/Anomaly/]\n    ood[/Out of Training Distribution/]\n    rb_pred[/Rule-based Prediction/]\n    ml_pred[/ML Prediction/]\n    fb_pred[/Fallback Prediction/]\n    us[/Unsure/]\nend\n\nld[(Live &lt;br/&gt;Data)] --------&gt; od</code></pre> <ol> <li>Design<ol> <li>Why am I building?</li> <li>Who am I building for?</li> <li>What am I building?</li> <li>What are the consequences if it fails?</li> </ol> </li> <li>Development<ol> <li>What data will be collected to train the model</li> <li>Does the dataset follow AI ethics?</li> </ol> </li> <li>Deployment<ol> <li>How will model drift be monitored?</li> <li>How should preventive security measures be taken?</li> <li>How to react to security breaches?</li> </ol> </li> </ol> <p>Confidence - If different \"good\" models give significantly different results for a particular prediction, then it is low confidence</p>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#3-dimensions-of-prediction","title":"3 Dimensions of Prediction","text":"<ul> <li>Point estimate</li> <li>Time</li> <li>Probabilistic</li> <li>Intervals</li> <li>Density</li> <li>Trajectories/Scenarios</li> </ul>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#good-prediction-characteristics","title":"Good Prediction Characteristics","text":"<ul> <li>Forecast/Prediction consistency: Forecasts/Predictions should correspond to forecaster\u2019s best judgement on future events, based on the knowledge available at the time of issuing the Forecasts/Predictions</li> <li>Forecast/Prediction quality (accuracy): Forecasts/Predictions should describe future events as good as possible, regardless of what these Forecasts/Predictions may be used for</li> <li>Forecast/Prediction value: Forecasts/Predictions should bring additional benefits (monetary/others) when used as input to decision-making</li> </ul> <p>Hence, sometimes you may choose the Forecast/Prediction with the better value even if its quality is not the best</p>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#performance-vs-parsimony","title":"Performance vs Parsimony","text":"<ul> <li>Parsimonious models are more explainable</li> <li>Parsimonious models generalize better</li> <li>Small gains with deep models may disappear with dataset shift/non-stationary</li> </ul>"},{"location":"CS_Electives/Machine_Learning/01_Intro/#aspects","title":"Aspects","text":"Aspect Equivalent in Marco Polo game Loss Goal Model Class Map Optimization Search Data Sound"},{"location":"CS_Electives/Machine_Learning/01_Intro/#open-source-tools","title":"Open-source Tools","text":"Scikit-Learn TensorFLow Keras PyTorch MXNet CNTK Caffe PaddlePaddle Weka"},{"location":"CS_Electives/Machine_Learning/01_Intro/#doesnt-do-well-for-forecasting","title":"Doesn\u2019t do well for Forecasting","text":"<p>Machine Learning cannot provide reliable time-series forecasting, without causal reasoning. This is why AI/ML cannot be blindly trusted for stock price prediction.</p> <p>Related topics</p> <ul> <li>Model ends up being a Naive forecaster: just blindly predicts \\(\\hat y_{t+h} = y_t\\)</li> <li>Counter-factual simulation: Never-before-seen events, such as</li> <li>declining house prices</li> <li>Negative oil prices</li> <li>Distribution drift</li> <li>Turkey problem</li> </ul> <p>In the face of external factors that is not factored into the model, human intervention is required</p>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/","title":"Task \\(T\\)","text":"<p>Process of learning itself is not the task; learning is the means of attaining ability to perform the task</p> <p>Usually described in terms of how the machine learning system should process an instance (collection of features), which is usually represented as a vector.</p>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#tasks","title":"Tasks","text":"Task Meaning Function Mapping Example Confident Learning ML can be used to identify data-quality issues Regression Predicting a continuous numerical output \\({\\mathbb R}^n \\to {\\mathbb R}\\) Stock value prediction (not very good) Classification Categorizing input into a discrete outputor outputing a probability dist over classesDerived from regressionIf binary and very imbalanced dataset, use anomaly detection instead \\({\\mathbb R}^n \\to [1, C]\\)\\(C=\\) no of classes Categorizing imagesFraud detectionTime-Series structural break detectionPredicting stock price going up/down Anomaly Detection Identify abnormal events \\(\\mathbb R \\to [0, 1]\\) Fraud detectionTime-Series structural break detection Classification w/ missing inputs Learn distribution over all variables, solve by marginalizing over missing variables \\({\\mathbb R}^n \\to [1, C]\\) Clustering Assigning class label to set of unclassified items, to group observations into clusters \\(\\hat y = \\hat f(x) = \\text{Cluster}(x)\\)\\({\\mathbb R}^n \\to [1, C ]\\) Grouping similar imagesPortfolio construction Density estimation Estimating probability distribution from data \\({\\mathbb R}^n \\to P(x)\\) Transcription Convert unstructured data intro discrete textual form OCRSpeech Recognition Machine Translation Convert itinto a sequence of symbols into another language Natural Language Translation Structured Output Output data structure hasrelationships between elements ParsingImage segmentationImage captioning Synthesis &amp; Sampling Generate new samples similar to those intraining data Texture generationSpeech synthesisSupersampling images Data Imputation Predict values of missing entries Denoising Predict clean output from corrupt input Image/Video denoising Density Estimation Identify underlying probability distribution of set of inputs Localization Regression for position \\(\\mathbb{R}^n \\to \\{ x, y, w, h \\}\\) Image/Video object detectionImage/Video instance segmentation"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#cardinality","title":"Cardinality","text":"Type Diagram One-to-one RegressionClassification One-to-many Image captioningObject detection Many-to-one Sentiment classification Many-to-many Machine translation Many-to-many Video object classificationVideo frame-level classification"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#types-of-predictions","title":"Types of Predictions","text":"\\(x_\\text{new}\\) Uncertainty Intrapolation? \\(\\in X_\\text{train}\\) Low Interpolation \\(\\in [X_{\\text{train}_\\text{min}}, X_{\\text{train}_\\text{max}}]\\) Moderate Extrapolation \\(\\not \\in [X_{\\text{train}_\\text{min}}, X_{\\text{train}_\\text{max}}]\\) High Smoothing"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#regression","title":"Regression","text":"<ul> <li>Constrain range: use appropriate transformation/Activation_Functions<ul> <li>\\([a, b]\\): Generalized Logistic</li> <li>\\([0, b]\\): Softplus</li> <li>\\([a, 0]\\): -ve Softplus</li> </ul> </li> <li>If the target is zero-inflated<ul> <li>Classifier/Anomaly-Detection to flag as \\(0\\) or non-zero<ul> <li>If \\(0\\), then 0 is the prediction</li> <li>If non-zero, then prediction is the output of a regressor</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#probabilistic-regression","title":"Probabilistic Regression","text":"<ul> <li>Probability of prediction is required</li> <li>Understand impact of input</li> <li>Regression target is the sum of individual binary outcomes</li> </ul> \\[ y'_i = p_i = \\dfrac{y_i}{n_i} \\]"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#binary-aggregate-outcomes","title":"Binary Aggregate Outcomes","text":"\\[ \\begin{aligned} y_i &amp;\\sim \\text{Binomial}(n_i, p_i) \\\\ p_i &amp;= \\sigma(\\beta x_i) \\\\  %%\\implies y_i &amp;\\sim \\text{Bernoulli}\\Big( \\sigma(x_i' \\beta) \\Big) \\end{aligned} \\] <pre><code>  temperature        fields cultivated  percentCultivated\n1 13.18475               63         49  0.7777778\n2 12.35680              165        147  0.8909091\n3 17.57882               38         30  0.7894737\n4 20.86867              152         95  0.6250000\n5 13.88084               88         69  0.7840909\n6 17.18088              191        141  0.7382199\n</code></pre>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#multiple-aggregate-outcomes","title":"Multiple Aggregate Outcomes","text":"\\[ \\begin{aligned} y_i &amp;\\sim \\text{Multinomial}(n, p) \\\\ p_j &amp;= \\text{Softmax}(\\beta_j x) \\\\ &amp;= \\dfrac{\\exp(\\beta_j x)}{\\sum_k^K \\exp(\\beta_k x) } \\end{aligned} \\] <p>When \\(n_i=1,\\) this becomes multi-class classification</p> <p>Example</p> <pre><code>         temperature  rainfall fields noncrop corn wheat rice\n1    13.18475           75.26666     63       8   31    17    7\n2    12.35680           102.37572    165       7  100    30   28\n3    17.57882           101.61363     38       1   26     3    8\n4    20.86867           64.35788    152      45   78    12   17\n5    13.88084           107.54101     88       4   54    15   15\n</code></pre>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#classification","title":"Classification","text":""},{"location":"CS_Electives/Machine_Learning/02_Task_T/#decision-boundarysurface","title":"Decision Boundary/Surface","text":"<p>The boundary/surface that separates different classes</p> <p>Generated using decision function</p> <p>If we have \\(d\\) dimensional data, our decision boundary will have \\((d-1)\\) dimensions</p>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#linear-separability","title":"Linear Separability","text":"<p>Means the ability to separate points of different classes using a line, with/without non-linear Activation_Functions</p> \\[ f(u) = \\begin{cases} 1, &amp; u \\ge 0 \\\\ 0, &amp; \\text{otherwise} \\end{cases} \\] Logic Gate Linearly-Separable? Comment AND \u2705 OR \u2705 XOR \u274c Linearly separable if we add \\((x \\cdot y)\\) as a feature XNOR \u274c Linearly separable if we add \\((x \\cdot y)\\) as a feature <p></p>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#linearly-non-separable","title":"Linearly Non-Separable","text":"Slightly Seriously"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#discriminant-function","title":"Discriminant Function","text":"<p>Functions which takes an input vector \\(x\\) and assigns it to one of the \\(k\\) classes</p>"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#multi-class-classification","title":"Multi-Class Classification","text":"One-vs-Rest One-vs-One No of classifiers \\(k\\) \\(\\frac{k(k-1)}{2}\\) Retains valid probabilistic interpretation \u2705 \u274c Limitation Some point may have multiple classes/no classes at all Multiple classes assigned to some points"},{"location":"CS_Electives/Machine_Learning/02_Task_T/#clustering","title":"Clustering","text":""},{"location":"CS_Electives/Machine_Learning/02_Task_T/#analyzing-clusters","title":"Analyzing clusters","text":"<p>Understand the characteristics of each cluster</p> <ol> <li>Select features \\(x_j\\)</li> <li>Do not use all features to perform clustering</li> <li>where \\(x_j=\\) sensible features such as<ul> <li>Spending habits</li> </ul> </li> <li>Perform clustering</li> <li>Perform statistical analysis on \\(x_{\\centernot{j}}\\)</li> </ol> <p>For example: 4 clusters</p> \\(x_1=0\\) \\(x_1=1\\) \\(x_2=0\\) A B \\(x_2=1\\) C D"},{"location":"CS_Electives/Machine_Learning/03_Model/","title":"Model","text":""},{"location":"CS_Electives/Machine_Learning/03_Model/#idk","title":"IDK","text":""},{"location":"CS_Electives/Machine_Learning/03_Model/#true","title":"True","text":"\\[ \\begin{aligned} y &amp;= f(X) &amp;&amp; \\text{True Relationship} \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/03_Model/#observed","title":"Observed","text":"\\[ \\begin{aligned} \\tilde X &amp;= X + \\delta &amp;&amp; \\text{Observed Input} \\\\ \\tilde y &amp;= y + \\epsilon &amp;&amp; \\text{Observed Output} \\\\ \\\\ \\implies \\tilde y &amp;= \\tilde f(\\tilde X) &amp;&amp; \\text{Observed Relationship} \\\\ &amp;= f(\\tilde X) + \\epsilon \\end{aligned} $$ ### Estimated $$ \\begin{aligned} \\hat y &amp;= \\hat f_{\\small L, C, D, A, O}(\\tilde X; \\theta) + u \\\\ \\text{where } L &amp;= &amp;&amp;\\text{Loss - Functional Form, Weights} \\\\ C &amp;= &amp;&amp;\\text{Constraints} \\\\ D &amp;= \\{ \\tilde X, \\tilde y \\} &amp;&amp; \\text{Train data used (Observed, Noisy)} \\\\ A &amp;= &amp;&amp;\\text{Learning Algorithm - Functional Form, Hyperparameters, Randomness} \\\\ O &amp;= &amp;&amp;\\text{Optimization - Algorithm, Hyperparameters, Randomness} \\end{aligned} \\] <p>where</p> Denotation Term Comment \\(x\\) inputexplanatoryfeaturepredictorindependent \\(y\\) outputoutcometargetresponsedependent \\(\\hat y\\) prediction \\(E[y \\vert x]\\) CEF (Conditional Expectation Function) \\(f\\) Target function True relationship between \\(y\\) and \\(x\\) \\(\\hat f\\) Hypothesis functionModel Gives mapping b/w \\(x\\) and \\(y\\) to obtain CEF \\(p(y \\vert x)\\) Target distribution/Posterior distribution of \\(y\\) True data-generating process \\(\\hat p(y \\vert x)\\) Hypothesis distribution Gives mapping b/w \\(x\\) and \\(y\\) to obtain Conditional Distribution \\(u\\) Random component"},{"location":"CS_Electives/Machine_Learning/03_Model/#idk_1","title":"IDK","text":"<pre><code>flowchart LR\nd[Data&lt;br/&gt;Generation] --&gt;\n|Input| m[Modelling] --&gt;\n|Analysis| si[Scientific&lt;br/&gt;Investigation]\n\nsi --&gt;\n|Improve Model| m\n\nsi --&gt;\n|Improve DoE/Data Generation| d</code></pre>"},{"location":"CS_Electives/Machine_Learning/03_Model/#desired-properties","title":"Desired Properties","text":"<ul> <li>Unbiased: Mean of residuals = 0</li> <li>Efficient: Variance of residuals and learnt parameters is min</li> <li>Maximum likelihood \\(P(D, \\theta)\\)</li> <li>Robust</li> <li>Consistent: \\(n \\to \\infty \\implies E[u_i] \\to 0\\)</li> </ul> <p>Attributes of probabilistic forecast quality</p> <ol> <li>Reliable: probabilistic calibration</li> <li>For quantile forecasts with level \\(\\alpha\\), observations \\(y_{t+k}\\) should be less than \\(\\hat y_{t+k}\\) \\(\\alpha\\) times</li> <li>For interval forecasts with coverage \\(p\\), observations \\(y_{t+k}\\) should be within the interval \\(p\\) times</li> <li>For predictive densities composed of \\(m+1\\) quantile forecasts with nominal levels \\(\\alpha_0, \\alpha_1, \\dots, \\alpha_m\\), all these quantile forecasts are evaluated individually using the above</li> <li>Q-Q Plots</li> <li>Sharp: informative</li> <li>Concentration of probability: how tight the predictive densities are</li> <li>Perfect probabilistic forecast gives a probability of 100% on a single value</li> <li>CRPS<ol> <li>Average of each predictive density and corresponding observation</li> <li>\\(\\text{CRPS}_{t, h} = \\int_y \\ \\Big( \\hat F_{t+h \\vert t} - 1(y_{t+h} \\le y) \\Big)^2 \\ \\cdot dy\\)</li> <li>\\(\\text{CRPS}_h = \\text{avg}(\\text{CRPS}_{t, h})\\)</li> </ol> </li> <li>Skilled</li> <li>High resolution</li> </ol>"},{"location":"CS_Electives/Machine_Learning/03_Model/#scope","title":"Scope","text":"<p>Every model is only limited to its \u2018scope\u2019, which should be clearly documented</p> <ul> <li>Assumptions</li> <li>Domain: Set of \\(x\\)</li> <li>Range: Set of \\(y\\)</li> <li>\u2060Density: total no of points, no of points in leaves</li> </ul>"},{"location":"CS_Electives/Machine_Learning/03_Model/#idk_2","title":"IDK","text":"<ul> <li> <p>\"If you understand your solution better than the problem, then you are doing something wrong\" ~ Vincent Warmerdam</p> </li> <li>Think more about system design rather than just machine learning</li> <li>Simple linear models work. Most of the times non-linear/ensembles/deep learning models are not required</li> </ul>"},{"location":"CS_Electives/Machine_Learning/03_Model/#model-types","title":"Model Types","text":"Ideal Non-Parametric(Nearest Neighbor) Semi-Parametric Parametric \\(\\hat y\\) \\(\\text{Mean}(y \\vert x)\\) \\(\\text{Mean} \\Big(y \\vert x_i \\in N(x) \\Big)\\)\\(N(x)\\) is neighborhood of \\(x\\) \\(f(x)\\) Functional Form assumption None None Assumes functional form with a finite &amp; fixed number of parameters, before data is observed Advantages Perfect accuracy - learns complex patterns- in a high-dimensional space- without being specifically directed- learns interactions Compression of model into a single function Limitation Not possible to obtain Suffers from curse of dimensionality: Requires large dataset, especially when \\(k\\) is largeBlack box: Lacks interpretabilityLarge storage cost: Stores all training recordsComputationally-expensive Lost information? Visualization Space Complexity is function of Training set size Number of function parameters Number of function parameters Example Nearest Neighbor averaging Spline Linear Regression <p>Fundamentally, a parametric model can be though of data compression</p>"},{"location":"CS_Electives/Machine_Learning/03_Model/#modelling-types","title":"Modelling Types","text":"Discriminative/Reduced Form Generative/Structural/First-Principles Hybrid/Discrepancy Characteristic Mathematical/Statistical Theoretical(Scientific/Economic) Mix of first principles &amp; machine learning Effect ModifiersRead more Assumes that effect modifiers will remain same as during learning Incorporates effect modifiers Goal 1. \\(\\hat p(y \\vert x)\\)2. \\(\\hat y = \\hat E(y \\vert x)\\) 1. \\(\\hat p(x \\vert y)\\)2. \\(\\hat p(x, y)\\)3. \\(\\hat p(y \\vert x)\\)4. \\(\\hat y = \\hat E(y \\vert x)\\) \\(\\hat y = \\text{g}(x) + d(x)\\) This model defines a \u201cstory\u201d for how the data was generated. To obtain a data point1. Sample class \\(y \\sim \\text{Categorical}(p_1, p_2, \\dots, p_C)\\) with class proportions given by \\(p_c\\)2. Then, we sample \\(x\\) from the gaussian distribution \\(\\mathcal N(\\mu_c, \\Sigma_c)\\) for each class Includes Causal Theory \u274c \u2705 Same as Structural Intrapolation? \u2705 \u2705 \u2705 Interpolation \u26a0\ufe0f \u2705 \u26a0\ufe0f Extrapolation \u274c \u2705 \u274c Counter-factual simulation \u274c \u2705 \u274c Can adapt to data drift \u274c \u2705 \u26a0\ufe0f Stable for Equilibrium effects \u274c \u2705 \u26a0\ufe0f Synthetic data generation \u274c \u2705 \u274c Out-of-Sample Accuracy Low High(only for good theoretical model) Same as Structural Derivation Time 0 High Same as Structural Example models Non-Probabilistic classifiersLogistic regression Probabilistic classifiers (Bayesian/Gaussian) Comment The shortcoming of reduced form was seen in the 2008 RecessionThe prediction model for defaults was only for the case that housing prices go up, as there was data only for that. Hence, the model was not good for when the prices started going down. Learning \\(p(x, y)\\) can help understand \\(p(u, v)\\) if \\(\\{x, y \\}\\) and \\(\\{ u, v \\}\\) share a common underlying causal mechanismFor eg: Apples falling down trees and the earth orbiting around the sun both inform us of the gravitational constant. Example 1: General \\(f=\\sigma(kx), \\hat f = e^{kx}\\)\\(f = x^2, \\hat f = x\\)\\(f=e^x, \\hat f=x^2\\) \\(f = x^2, \\hat f = x^2\\) Example 2: Chemical Kinetics Fit curve to given data Solve the rate law equation for the given data Example 3: Astronomy Mars position wrt Earth, assuming that Mars revolves around the Earth Mars position wrt Earth, assuming that Mars &amp; Earth revolve around the Sun Example 4: Wage vs Education Relationship of wage vs education directly Relationship of wage vs education, with understanding of demand-supply curve (ie, effects of supply of college educated students in the market)eg: Kerala Example 5: Time-Series Forecasting Univariate model with lags and trends Multi-variate model with lags of \\(y\\) and \\(x\\) <p>Good compromise - Model response with causal factors - Model causal residuals with statistical factors</p>"},{"location":"CS_Electives/Machine_Learning/03_Model/#structural-vs-reduced-form","title":"Structural vs Reduced-Form","text":""},{"location":"CS_Electives/Machine_Learning/03_Model/#number-of-variables","title":"Number of Variables","text":"Univariate Regression Multi-Variate \\(\\hat y\\) \\(f(X_1)\\) \\(f(X_1, X_2, \\dots, X_n)\\) Equation \\(\\beta_0 + \\beta_1 X_1\\) \\(\\sum\\limits_{i=0}^n \\beta_i X_i\\) Best Fit Straight line Place"},{"location":"CS_Electives/Machine_Learning/03_Model/#degree-of-model","title":"Degree of Model","text":"Simple Linear Regression Polynomial Linear Regression Non-Linear Regression Equation \\(\\sum\\limits_{j=0}^k \\beta_j X_j\\) \\(\\sum \\limits_{j=0}^k \\sum\\limits_{i=0}^n \\beta_{ij} (X_j)^i\\) Any of the \\(\\beta\\) is not linear Example \\(\\beta_0 + \\beta_1 X_1 + \\beta_1 X_2\\) \\(\\beta_0 + \\beta_1 X_1 + \\beta_1 X_1^2 + \\beta_1 X_2^{10}\\) \\(\\beta_0 + e^{\\textcolor{hotpink}{\\beta_1} X_1}\\) Best Fit Straight line Curve Curve Solving method possible Closed-FormIterative Closed-FormIterative Iterative Limitations 1. Convergence may be slow2. Convergence to local minima vs global minima3. Solution may depend heavily on initial guess Comment You can alternatively perform transformation to make your regression linear, but this isn\u2019t best1. Your regression will minimize transformed errors, not your back-transformed errors (what actually matters). So the weights of errors will not be what is expected2. Transformed errors will be normal, but your back-transformed errors (what actually matters) won\u2019t be a normal <p>The term linear refers to the linearity in the coefficients \\(\\beta\\)s, not the predictors</p>"},{"location":"CS_Electives/Machine_Learning/03_Model/#jensens-inequality","title":"Jensen\u2019s Inequality","text":"\\[ E[\\log y] &lt; \\log (E[y]) \\] <p>Therefore $$ \\hat y = \\exp(\\beta_0 + \\beta_1 x) + u_i \\ E[y \\vert x] \\ne E[\\exp(\\beta_0 + \\beta_1 x)] $$ However, if you assume that \\(u \\sim N(0, \\sigma^2)\\) $$ E[y \\vert x] = \\exp(\\beta_0 + \\beta_1 x + \\dfrac{\\sigma^2}{2}) $$</p>"},{"location":"CS_Electives/Machine_Learning/03_Model/#boosted-hybrid-model","title":"Boosted Hybrid Model","text":"<p>Multi-Level Model</p> <p>Boosting with different function and/or model class for each component of \\(f(x)\\) $$ \\hat f(x) = \\sum_{j=1}^k \\hat f_j(x_j) \\ \\hat f: x_j \\to u_{j-1} \\ u_0 = y $$ <pre><code>flowchart LR\nx1 --&gt; h1\ny ---&gt; u1\nh1 --&gt; u1\n\nx2 --&gt; h2\nu1 --&gt; u2\nh2 ---&gt; u2</code></pre></p> <p>Model in the following order to avoid fitting the noise:</p> Step Model Capacity Component Frequency 1 Low High 2 Low Low 3 High High 4 Low Low <p>For eg: Time Series modelling</p> <ul> <li>Trend with LR: \\(\\hat f(t)\\)</li> <li>Seasonality with KNN</li> <li>Holidays with Decision Tree</li> <li>Residuals with XGBoost</li> </ul>"},{"location":"CS_Electives/Machine_Learning/03_Model/#categorial-inputs","title":"Categorial Inputs","text":""},{"location":"CS_Electives/Machine_Learning/03_Model/#binary","title":"Binary","text":"\\[ \\begin{aligned} \\hat y &amp;= \\beta_0 + \\beta_1 x + \\beta_2 T + + \\beta_3 x T + u \\\\ \\\\ T = 0 \\implies \\hat y &amp;= \\beta_0 + \\beta_1 x + u \\\\ T = 1 \\implies \\hat y &amp;= (\\beta_0 + \\beta_2) + (\\beta_1+\\beta_3) x + u \\end{aligned} \\] <p>where \\(T=\\) treatment/binary var</p>"},{"location":"CS_Electives/Machine_Learning/03_Model/#discrete-var","title":"Discrete Var","text":"<p>Dummy variable trap</p> <ul> <li>For \\(C\\) possible values of discrete var, If you have intercept/constant term and \\(C\\) dummy vars, you will have perfect multi-collinearity (dangerous), as all zeros is also a scenario</li> </ul> <p>Solution - \\(C\\) dummy variables, but no intercept - \\(C-1\\) dummy variables with intercept</p>"},{"location":"CS_Electives/Machine_Learning/03_Model/#model-constraintshints","title":"Model Constraints/Hints","text":"<p>Known properties of \\(f\\) that can be used to improve \\(\\hat f\\), especially with small datasets</p> <ul> <li>Monotonic constraints<ul> <li>Warning: does the constraint really makes sense for all possible values of other features?<ul> <li>If your house price model uses the features \u201cnumber of rooms\u201d and \u201cliving area\u201d<ul> <li>then a monotonic constraint on \u201cliving area\u201d might make sense (given any number of rooms)</li> <li>such constraint would be non-sensical for the number of rooms<ul> <li>Because having six rooms in a 1200 square feet home is not necessarily better than having just five rooms in an equally sized home</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>Interaction constraints: prevent non-sensical interactions<ul> <li>Let's say that the causal structure is \\(E = f(A, B), F = f(C, D), G = g(E, F)\\)</li> <li>If this is a hassle to model each independently, then have interactions constraints: \\(G = f(\\{A, B\\}, \\{C, D\\})\\)</li> </ul> </li> <li>Reflexivity</li> <li>Symmetry</li> <li>Rotational invariance</li> <li>Translational invariance</li> </ul> <p>Can be enforced through</p> <ul> <li>Modifying features</li> <li>Eg: using \\(\\vert x \\vert\\) instead of \\(x\\) for symmetry</li> <li>Regularization Penalty</li> <li>Data augmentation</li> </ul>"},{"location":"CS_Electives/Machine_Learning/03_Model/#latent-variable-models","title":"Latent Variable Models","text":""},{"location":"CS_Electives/Machine_Learning/03_Model/#examples","title":"Examples","text":"<ol> <li> <p>Image classification</p> </li> <li> <p>Contains variability due to gender, eye color, hair color, pose, etc</p> </li> <li> <p>Unless these images are annotated, these factors of variation are not explicitly available</p> </li> <li> <p>Classification</p> </li> <li> <p>Gaussian mixture models</p> </li> </ol>"},{"location":"CS_Electives/Machine_Learning/03_Model/#limitations","title":"Limitations","text":"<ul> <li>Computationally-expensive: requires approximations</li> </ul>"},{"location":"CS_Electives/Machine_Learning/03_Model/#general-techniques","title":"General Techniques","text":"<p>Not necessarily for least squares regression</p> <ul> <li>Hierarchical</li> <li>Ensembling: Reduce variance</li> <li>Bootstrapping: Robustness, confidence intervals</li> <li>RANSAC (RANdom Sample Consensus): Robustness<ul> <li>Disadvantage: Requires hyper-parameter tuning</li> </ul> </li> <li>Weighted</li> <li>Localized/Locally-Weighted<ul> <li>Query similar records, either by no of records or by KNN distance</li> </ul> </li> <li>Randomness aggregation: average models across multiple randomness-inducing hyperparameters<ul> <li>Random seed</li> <li>Random samples</li> <li>Learning rate</li> </ul> </li> <li>Iteratively ReWeighted</li> <li>Online learning</li> <li>Rolling<ul> <li>rolling apply function</li> <li>\u2060 function returns coefs</li> <li>\u2060 split coef into different cols</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/03_Model/#hierarchical","title":"Hierarchical","text":"<p>If there are multiple independent hierarchies, then run a model for each hierarchy - simple model for each hierarchy is better than one complex model for each group - especially useful for imbalanced hierarchies</p> <p>Complexity of atomic model for each hierarchy should be based on the amount of data available for that hierarchy - create a meta-estimator to conditionally apply a model</p>"},{"location":"CS_Electives/Machine_Learning/03_Model/#classification-threshold","title":"Classification Threshold","text":"\\[ p_\\text{threshold} = \\dfrac{ c(\\text{FP}) - c(\\text{TN}) }{ \\Bigg( c(\\text{FN}) + c(\\text{FP}) \\Bigg) - \\Bigg(c(\\text{TN}) + c(\\text{TP}) \\Bigg) } \\]"},{"location":"CS_Electives/Machine_Learning/04_Learning_Experience/","title":"Learning Experience \\(E\\)","text":""},{"location":"CS_Electives/Machine_Learning/04_Learning_Experience/#learning-paradigms","title":"Learning Paradigms","text":"Method Meaning Application Supervised Uses labelled data, to derive a mapping between input examples and target variable. \\(D_\\text{train} = X, y\\) Unsupervised Learning from unlabelled data \\(D_\\text{train} = X\\) Semi-Supervised \\(\\exists\\) labelled data and large amount of unlabelled data.Label the unlabelled data using the labelled data.For example, love is labelled as emotion, but lovely isn\u2019tCotraining, Semi-Supervised SVM Self-Supervised Supervised learning without explicit labels; labels created from the data Images: identify correct rotationsSequences: out-of-sequence correctionsText: word embeddings Lazy/Instance-Based Store the training examples instead of training explicit description of the target function.Output of the learning algorithm for a new instance not only depends on it, but also on its neighbors.The best algorithm is KNN (K-Nearest Neighbor) Algorithm.Useful for recommender system. ActiveAL Learning system is allowed to choose the data from which it learns.There exists a human annotator.Useful for gene expression/cancer classification Multiple Instance Weakly supervised learning where training instances are arranged in sets.Each set has a label, but the instances don\u2019t Transfer Reuse a pre-trained model as the starting point for a model on a new related task Reinforcement LearningRL Learning in realtime, from experience of interacting in the environment, without any fixed input dataset.It is similar to a kid learning from experience.Best algorithm is Q-Learning algorithm. \\(D_\\text{train} = X, \\text{Feedback}\\) Game playing Bayesian Learning Conditional-probabilistic learning toolEach observed training expmle can incrementally inc/dec the estimated probability that a hypothesis is correct.Useful when there is chance of false positive.For eg: Covid +ve DeepDL Multi-Layered ANNs Computer Vision FederatedFL Distributed Privacy Online Streaming"},{"location":"CS_Electives/Machine_Learning/04_Learning_Experience/#training-method","title":"Training Method","text":"Advantage Batch \\(\\hat f: X \\to y\\) Better model Streaming/Online/Passive-Aggressive \\(\\hat f_b: X_{i \\le b} \\to y_{i \\le b}\\)where \\(b= \\text{Mini-batch}\\) - Adaptive to new data points- Computationally-cheap Hybrid - Batch training start of day- Online training intra-day"},{"location":"CS_Electives/Machine_Learning/04_Learning_Experience/#types-of-learners","title":"Types of Learners","text":"<p>They are not adapted by the ML algo itself, but we can use nested learning, where other algorithms optimize the hyperparameter for the ML algo.</p> Eager Learner Lazy Learner Training Learns relationship between class label &amp; attributes Stores training records Evaluation Perform computations to classify evaluation record Training Speed Slow Fast Evaluation Speed Fast Slow Example - Decision Tree- Rule-Based Classifier - Nearest-neighbor classifier"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/","title":"Learning Theory","text":""},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#objectives-of-learning","title":"Objectives of Learning","text":"<ol> <li>Ensure fit: \\(E_\\text{in} \\approx 0\\)</li> <li>Ensure generalization: \\(E_\\text{out} - E_\\text{in} \\approx 0\\)</li> </ol>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#hypothesis","title":"Hypothesis","text":"<p>Estimated model \\(\\hat f(x) = \\hat y\\)</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#hypothesis-set","title":"Hypothesis Set","text":"<p>Set of all hypotheses \\(H = \\{ \\hat f_i(x) \\}\\), both by</p> <ul> <li>machine</li> <li>human</li> </ul>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#good-characteristics-of-hypotheses","title":"Good Characteristics of Hypotheses","text":""},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#parsimony","title":"Parsimony","text":"<p>An explanation of the data should be made as simple as possible, but no simpler</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#occams-razor","title":"Occam\u2019s Razor","text":"<p>The simplest model that fits the data is also the most plausible</p> <p>Simple</p> <ul> <li>Complexity of \\(h\\): MDL (Minimum Description Length)</li> <li>Complexity of \\(H\\): Entropy, VC Dimension</li> </ul> <p>\\(l\\) bits specify \\(h\\) \\(\\implies\\) \\(h\\) is one of the \\(2^l\\) elements of a set \\(H\\)</p> <p>Exception - Looks complex but is actually simple: SVM</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#why-is-simpler-better","title":"Why is simpler better?","text":"<p>Simpler means out-of-sample performance</p> <p>Fewer simple hypotheses than complex ones: \\(m_H(N)\\) \\(\\implies\\) less likely to fit a given dataset: \\(m_h(N)/2^N\\) \\(\\implies\\) more significant when it happens</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#falsifiability","title":"Falsifiability","text":"<p>If your data has chance of falsifying your assertion, then it does not provide any evidence for that assertion</p> <p>Fit that means nothing: linear regression fit with just 2 data points</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#data-snooping","title":"Data Snooping","text":"<p>Also called p-hacking, specification search, data dredging, fishing</p> <p>Process of trying a series of models until we obtain a satisfactory result, without accounting for such.</p> <p>This will result in your model matching a particular dataset</p> <p>This includes</p> <ul> <li>Parameters: Coefficients/Weights of the model</li> <li>Hyper-Parameters: Parameters that affect the learning of the model</li> </ul> <p>It is possible to find a statistically significant result even if doesn\u2019t exist, if you try hard enough</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#takeaways","title":"Takeaways","text":"<ul> <li>If a data set has affected any step in the learning process, its ability to assess the outcome of has been compromised. Hence it cannot be (fully) trusted in assessing the outcome.</li> <li>For a given problem type, if you perform an action which you would not do if the data were different, then you must penalize this action for generalization</li> <li>Using known properties of the target function does not have to be penalized, as it is not dataset-specific</li> </ul>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#solutions","title":"Solutions","text":"<ul> <li>Avoid data snooping: Always use domain knowledge to create your hypothesis set before even looking at the training data</li> <li>Account for data snooping: If not possible to avoid, look at the data but make sure to account for this</li> </ul>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#pitfalls","title":"Pitfalls","text":"<ul> <li>Explicit: Intentionally trying many models on the same dataset, thereby increasing size of hypothesis set</li> <li>Implicit</li> <li>Looking at the test data before choosing a model</li> <li> <p>Data leakage during feature engineering, such as normalization</p> </li> <li> <p>Adaptive analysis: When working with a public data set, we may already know what models work/don\u2019t work, so the Hypothesis space &gt; the model I formulate</p> </li> </ul> <p>For example:</p> <p></p> <p>If you look at the data beforehand $$ \\begin{aligned} H = &amp;{ \\ &amp; \\quad { 1, x_1, x_2, x_1 x_2, x_1^2, x_2^2 }, \\ &amp; \\quad { 1, x_1^2, x_2^2 }, \\ &amp; \\quad { 1, x_1^2 + x_2^2 }, \\ &amp; \\quad { x_1^2, x_2^2 - 0.6 } \\ &amp; } \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#what-to-do","title":"What to do?","text":"<ul> <li>Pre-registration: Fix your objective and theory before analysis<ul> <li>Prevents p-hacking</li> <li>Prevents file drawer problem: Hiding unfavorable evidence</li> </ul> </li> <li>Pre-analysis Plan: Fix your set of hypotheses before analysis<ul> <li>Prevents p-hacking</li> <li>Prevents multiple hypothesis testing</li> </ul> </li> <li>Use synthetic data before analysis<ul> <li>Do whatever you analysis with this data</li> </ul> </li> <li>Formulate the research qn and fix the what model before seeing training data.</li> <li>If you intend on data snooping and choose a model based on the data, then you should decide on the set of models you are going to choose from before seeing the data, and account for the data snooping in your analysis by</li> <li>Adjusting the significance level of your hypothesis tests by, for example, using the Bonferroni correction</li> <li>Using a test data set to evaluate the performance of your final estimated model. The test set should be allocated at the beginning and only used at the end. Once a data set has been used, it should be treated as contaminated for evaluating test performance</li> </ul>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#reporting-guidelines","title":"Reporting Guidelines","text":"<ul> <li>Aim for honesty &amp; transparency</li> <li>Clearly state research qn, research design, and reasoning behind model choice.</li> <li>Clearly state if analysis involves data snooping and how you have accounted for it.</li> <li>Report every hypothesis test you have performed relevant to the research question and highlight results that are robust across tests.</li> <li>Include a limitations section and point out any limitations and uncertainties in the analysis.</li> <li>Replicability/Reproducibility</li> <li>Documentation</li> </ul>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#validity-of-results-threats-to-validity","title":"Validity of Results &amp; Threats to Validity","text":"Validity Meaning Results valid for Transportability of results Threats Solution Construct Is your outcome measure the right one to measure the outcome? Nowhere \u274c Wrong KPIExample:Measuring student commitment with grades is not the best Correct KPI Statistical Conclusion Are your statistics correct? Nowhere \u274c Low statistical power More observations Violating assumptions of statistical tests Fishing &amp; p-hacking Don't run different DAGs on all the data; follow good train-test split Spurious statistical significance Internal Study population \u274c Calibration: Measurement error Calibration: Time frameIf study is too short, effect may not be detectable yetIf study is too long, attrition may occur Choose optimal time frame using domain knowledge Contamination: Hawthorne effectObserving people makes them behave differently Use completely-unobserved control groups Contamination: John Henry effectControl group works hard to prove they're as good as treatment groupUsually this happens because control group knows about the experiment Keep treatment and control groups separate and unaware of each other Contamination: Spillover effectControl groups naturally pick up what treatment group is gettingCauses: Externalities, social interaction, equilibrium effects Keep treatment and control groups separate and unaware of each other Contamination: Intervening eventsSomething happens that affects one of the groups and not the othereg: Natural disasters, random events No fix :/ Omitted variable bias Include variables Endogeneity bias(Simultaneity bias) IV Sampling biasSelf-Selection bias (who opts-in), Attrition (who opts-out), Time selection bias Randomize and/or inspect characteristics of who joins, who stays, who leaves, and when Over-controlling(Mediator bias, Collider bias) Do not over-control Trendseg: Child growth Use control group to remove trend Structural breaks eg: Recessions, cultural shifts Use control group to remove trend Seasonality Compare observations from same season Testing: Repeated exposure to questions/tasks will make people improve naturally Change testsUse control group that receives the test Regression to the meansuper-high/super-low performers are systematically-different from the rest of the sample Don't select super-high/super-low performers External Generalizability Other populations \u2705 Study volunteers may be W.E.I.R.D. Not everyone takes surveys/callsPeople who take surveys are systematically different from general population Different settings and circumstances Ecological fallacy Reductionist fallacy <p>Causal Biases (bad to worst) - Mediator bias - Omitted variable bias - Ecological fallacy - Reductionist fallacy - Confounder bias/Simpson's paradox - Collider bias/Berkson's fallacy</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#importance-of-causal-learning","title":"Importance of Causal Learning","text":""},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#russels-chicken","title":"Russel\u2019s Chicken","text":"<p>This short story shows how pure reliance on past data is bad.</p> <p>The chicken assumes that whenever the farmer comes, it is to feed it. However, there will one day, the farmer comes to kill it.</p> <p>Hence, the lack of understanding why something happens might be very dangerous.</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#2008-us-financial-crisis","title":"2008 US Financial Crisis","text":"<p>Default prediction was based on the historical data, in which housing prices were always rising</p> <p>However, this time, the house pricing were going down</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#simpsons-paradox","title":"Simpson\u2019s Paradox","text":"<p>Confounder Bias</p> <p>This paradox looks at the effectiveness of a drug.</p> <p>https://youtu.be/ebEkn-BiW5k</p> <p>Aggregate Reversal</p> <p>For example, in this study, the composition makes a difference, ie</p> <ul> <li>in the \u2018drug\u2019 group, there are more women than men</li> <li>in the \u2018no drug\u2019 group, there are more men than women</li> </ul> <p>This disparity will give an incorrect understanding</p> <p>Moreover, for this particular disease, women have a lower recovery rate than men. That should be taken into account as well.</p> <p>Let\u2019s take another example. Consider a simple example with 5 cats and 5 humans. Let 1 cat and 4 humans be given the drug. Now, the values in the table show the recovery rate.</p> Drug No Drug Cat \\(1/1 = 100\\%\\) \\(3/4 = 75\\%\\) Human \\(1/4 = 25\\%\\) \\(0/1 = 0\\%\\) Overall \\(2/5 = 40\\%\\) \\(3/5 = 60\\%\\) <p>If we look at individual groups, cats are better off with drugs, and so are the humans.</p> <p>However, when we look at overall we can see that the population as a whole is better without the drugs.</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#us-political-support","title":"US Political Support","text":"<p>Similar to Simpson\u2019s Paradox</p> <p>Aggregate Reversal</p> Level Richer you are, more likely to be a __ Reason Individual Republican Republican individuals are richer and want lower taxes State Democrat Richer societies are usually morally \u2018modern\u2019; Poorer one are usually conservative and religiousDemocrats have more \u2018modern\u2019 policies"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#sampling-bias","title":"Sampling Bias","text":"<p>Also called Sample Selection Bias</p> <p>Type of sampling bias that arises when we make inference about a larger population from a sample that is drawn from a distinct subpopulation</p> <p>If data is sampled in biased way, learning will produce a similarly biased outcome; problem for both causal and statistical learning</p> <p>Cause: Data is missing or sampled non-randomly - non-representative sample that is not a random sample of the population we are interested in   or - study population is different from the target population</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#case-studies","title":"Case Studies","text":"<ul> <li>Presidential election results: Telephone: Truman vs Dewey</li> <li>Credit approval</li> <li>Creating portfolio based on long-term performance of currently-trading companies of S&amp;P 500</li> <li>You are looking at currently-trading stocks</li> <li>Sampling bias caused by \u2018snooping\u2019</li> <li>Solution: look &amp; trade explicitly wrt S&amp;P 500, not the comprising companies?</li> </ul>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#types","title":"Types","text":"Censoring Truncation Given a random sample of individuals drawn from the population of interest, some variables \u2013 mainly the outcome \u2013 are observed only on individuals belonging to a subpopulation, while other variables are observed on all individuals in the sample If all variables are observed only on individuals belonging to a subpopulation greater information loss than censoring"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#solution-matching-distributions","title":"Solution: Matching distributions","text":"<p>Ensure that validation and test data matches the distribution of the true target population</p> <p>The train and dev set need not match the same distribution, but it is recommended to sub-sample them such that it matches the target population</p> <p>Doesn\u2019t work for</p> <ul> <li>Region with \\(p(x)=0\\) in-sample, but \\(p(x)&gt;0\\) out-of-sample</li> </ul> <p>How? Gaussian estimation/Adversarial Validation/Domain Classifier</p> <ol> <li>Balancing using only train data</li> <li>Obtain probability \\(p\\) for each datapoint belonging to the train data</li> <li> <p>Weight these with \\(1/p\\) to be sampled again</p> </li> <li> <p>Distribution matching using target population</p> </li> <li>Obtain probability \\(p\\) for each datapoint belonging to the train data</li> <li>Weight these with \\(1/p\\) to be sampled again</li> </ol>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#trading","title":"Trading","text":"<p>Real Estate, Cars, Classifieds</p> <ul> <li>In a normal market, the real values (i.e., deflated values) of some properties will rise while others may decline</li> <li>If the owners of properties with falling values tend to choose not to sell their properties, while owners of properties with rising values tend to choose to sell (or vice versa), then the sample of transacted properties is clearly not random and is biased towards a particular price outcome</li> <li>It is also plausible that the choices of whether to sell properties with rising and falling values change over the real estate cycle and thus the nature of the sample selection bias will change over time</li> <li>This changing bias results in an estimated transaction-based price index that differs from a theoretical price index that would track market values of the stock of all properties</li> </ul>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#survivorshipsurvival-bias","title":"Survivorship/Survival Bias","text":"<p>Special type of sample-selection bias</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#mutual-fund-performance","title":"Mutual Fund Performance","text":"<p>Suppose we are interested in how the size of assets under management affects a fund\u2019s performance. If we simply look at the relationship between fund size and returns among existing funds, however, there will be what is referred to as a survival bias: we do not observe funds that have closed due to bad performance.</p> <p>So if fund size negatively affects performance, we may end up under-estimating the magnitude of the effect.</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#planes-in-war","title":"Planes in war","text":"<p>The planes that returned from war had lot of spots with bullet shots.</p> <p>Some person suggested strengthening only those spots. Initially, that makes sense - these are the areas that got shot so we need to strengthen. But, that is wrong.</p> <p>Another person said that these are the planes that returned despite getting shot at these spots. That means that we have to focus on other places, because the planes that got shot there never returned.</p> <p>Clearly data can be misleading, without understanding the underlying cause</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#wages","title":"Wages","text":""},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#credit-card-default","title":"Credit card default","text":"<p>We cannot use the relationship between Income, balance, and default status for credit card holders to predict default rate for a random credit card applicant, since these people part of the available data have been filtered already as potentially good credit card users</p> <p>Hence, we can only use it predict default for a random person already having a credit card</p> <p>This is a case of censoring</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#success-stories","title":"Success Stories","text":"<p>Advice by someone successful</p>"},{"location":"CS_Electives/Machine_Learning/04_Learning_Theory/#transportability-of-results","title":"Transportability of Results","text":"<p>The ability of the result can be generalized/extrapolated correctly from one population to another.</p> <p>A causal effect learnt from a study is transportable from study population to target population if both are within the scope.</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/","title":"Statistics","text":"<p>Statistical concepts such as Parameter estimation, Bias, Variance help in the aspects of generalization, over-fitting and under-fitting</p> <p>IID: Independent &amp; identically distributed</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#estimation-types","title":"Estimation Types","text":"Estimation Type Regression Output Classification Output Point \\(E(y \\vert X)\\) \\(E(c_i \\vert X)\\) Probabilistic \\(E(y \\vert X)\\)\\(\\sigma^2(y \\vert X)\\) \\(P(c_i \\vert X)\\)This is not the model confidence! This is the likelihood"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#likelihood-vs-confidence","title":"Likelihood vs Confidence","text":"<ul> <li>Likelihood is the probability of classification being of a certain class</li> <li>Unreliable if input is unlike anything from training</li> <li>Confidence is the model\u2019s confidence that the likelihood is correct</li> </ul>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#idk","title":"IDK","text":"Expected deviation Bias from the true value Variance caused by any particular sample"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#function-estimation","title":"Function Estimation","text":"<p>Estimation of relationship b/w input &amp; target variables, ie predict a variable \\(y\\) given input \\(x\\)</p> \\[ y = \\hat y + \\epsilon \\] <p>where \\(\\epsilon\\) is Bayes Error</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#statistical-learning-theory","title":"Statistical Learning Theory","text":"<p>Helps understand performance when we observe only the training set, through assumptions about the dataset</p> <ul> <li>Train &amp; live data must have identical statistical properties<ul> <li>Training &amp; test data arise from same process</li> <li>Observations in each data set are independent</li> <li>Training set and testing set are identically distributed</li> <li>Techniques<ul> <li>Adversarial Validation/Domain Classifier</li> <li>Anomaly detection</li> <li>Data distributions<ul> <li>KL divergence</li> <li>Jensen-Shannon</li> <li>Kolmogorov-Smirnov test</li> <li>Population Stability Index</li> </ul> </li> </ul> </li> </ul> </li> <li>i.i.d<ul> <li>every observation is independent &amp; identically distributed</li> </ul> </li> <li>\\(X\\) values are fixed in repeated sampling</li> <li>No specification bias</li> <li>We need to use the correct functional form, which is theoretically consistent</li> <li>Distribution of \\(y \\vert X\\) is known<ul> <li>Distribution of \\(y \\vert X\\) can be any distribution, and the modelling should take that into account</li> <li>You cannot assume normal distribution blindly</li> <li>Distribution of \\(y\\) does not matter</li> </ul> </li> <li>No Unbiasedness</li> <li>Independent vars should not be correlated with each other</li> <li>If |correlation| &gt; 0.5 between 2 independent vars, then we drop one of the variables</li> <li>High DOF</li> <li>Degree of freedom \\(= n - k\\), where<ul> <li>\\(n =\\) number of observations</li> <li>\\(k =\\) no of independent variables</li> </ul> </li> <li>DOF \\(\\to\\) 0 leads to overfitting</li> <li>High coefficient of variation in \\(X\\)</li> <li>We need more variation in values of \\(X\\)</li> <li>Indian stock market is very volatile. But not in UAE; so it's hard to use it an independent var. Similarly, we cant use exchange rate in UAE as a regressor, as it is fixed to US dollars</li> <li>Groups are identical<ul> <li>if groups are different add indicator and interaction terms</li> </ul> </li> <li>No variable interaction<ul> <li>Variable interaction: effect of \\(x_i\\) on \\(y\\) depends on \\(x_j\\)</li> <li>Solution: add interaction terms</li> </ul> </li> <li>No collinearity</li> <li>No multicollinearity</li> <li>Homoskedasticity</li> <li>Constant variance</li> <li>\\(\\sigma^2 (y_i|x_i) = \\text{constant}\\) should be same \\(\\forall i\\)</li> <li>Check with<ul> <li>Numerical<ul> <li>rolling statistics (average, std)</li> </ul> </li> <li>Graphical<ul> <li>box plot with \\(x\\) axis as \\(x_j\\) and \\(y\\) axis as \\(y\\)</li> <li>ridge plot with \\(y\\) axis as \\(x_j\\) and \\(x\\) axis as \\(y\\)</li> <li>histogram with \\(x\\) axis as \\(y\\) and facet as \\(x_j\\)</li> </ul> </li> </ul> </li> <li>Causes of Heteroskedascity</li> <li>There is no measurement error \\(\\delta_i\\) in \\(X\\) or \\(Y\\)</li> <li>\\(X_\\text{measured} = X_\\text{true}\\)</li> <li>\\(y_\\text{measured} = y_\\text{true}\\)</li> <li>\\(E(\\delta_i)=0\\)</li> <li>\\(\\text{var}(\\delta_i | x_i) = \\sigma^2 (\\delta_i|x_i) = \\text{constant}\\) should be same \\(\\forall i\\)</li> <li>\\(\\text{Cov}(\\delta_i, x_i) = 0, \\text{Cov}(\\delta_i, u_i) = 0\\)<ul> <li>If there is measurement error, we need to perform correction</li> </ul> </li> <li>Stationarity<ul> <li>The statistical properties of the variables are bounded and remain constant over time</li> <li>This applies to both inputs and output variables</li> </ul> </li> <li>There is no autocorrelation<ul> <li>If there exists autocorrelation in time series, then we have to incorporate the lagged value of the dependent var as an explanatory var of itself</li> </ul> </li> <li>For the Variance of distribution of potential outcomes, the range of distribution stays same over time</li> <li>\\(\\sigma^2 (x) = \\sigma^2(x-\\bar x)\\):   else, the variable is volatile; hard to predict; we cannot use OLS and hence have to use weighted regression</li> <li>if variance decreases, value of \\(y\\) is more reliable as training data</li> <li>if variance increases, value of \\(y\\) is less reliable as training data<ul> <li>We use volatility modelling (calculating variance) to predict the pattern in variance</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#adversarial-validation","title":"Adversarial Validation","text":"<p>Create a new feature in the dataset as \u201cSet\u201d, which signifies if the data belongs to training/test set</p> <p>Train a classifier to predict which set</p> <p>ROC-AUC signifies how accurately the classifier can distinguish between the sets. Higher values \\(\\ge 0.8\\) imply that Train &amp; Test data not from same distribution.</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#input-error","title":"Input Error","text":"<p>For higher order model, errors in \\(x\\) will look like heteroskedasticity</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#attenuation-bias","title":"Attenuation Bias","text":"<p>High measurement error \\(\\delta\\) and random noise \\(u\\) causes our estimated coefficients to be lower than the true coefficient</p> <p>Hence, for straight line model, error in \\(x\\)  will bias the OLS estimate of slope towards zero $$ \\begin{aligned} \\lim_{n \\to \\infty} \\hat \\beta &amp;= \\beta \\times \\text{SNR} \\ \\text{Signal-Noise Ratio: SNR} &amp;= \\dfrac{\\sigma<sup>2_x}{\\sigma</sup>2_x \\textcolor{hotpink}{+ \\sigma^2_u + \\sigma^2_\\delta}} \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#errors-in-measurement-correction","title":"Errors-in-Measurement Correction","text":"<p>This can be applied to</p> <ul> <li>any learning algorithm</li> <li>for regressors or response variables(s)</li> </ul> <p>Let\u2019s say true values of a regressor variable \\(X_1\\) was measured as \\(X_1^*\\) with measurement error \\(\\delta_1\\), where \\(\\delta_1 \\ne N(0, 1)\\). Here, we cannot ignore the error.</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#step-1-measurement-error","title":"Step 1: Measurement Error","text":"<p>Use an appropriate distribution to model the measurement error. Not necessary that the error is random.</p> <p>For eg, if we assume that the error is a skewed normal-distributed with variance \\(\\sigma^2_{X_1}\\) signifying the uncertainty.</p> \\[ \\delta_1 = N(\\mu_{X_1}, \\sigma^2_{X_1}, \\text{Skew}_{X_1}, \\text{Kurt}_{X_1}) \\]"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#step-2-measurement","title":"Step 2: Measurement","text":"<p>Model the relationship between the error and the measured value.</p> <p>For eg, If we assume that the error is additive</p> \\[ \\begin{aligned} X_1^* &amp;= X_1 + \\delta_1 \\\\ \\implies X_1 &amp;= X_1^* \\textcolor{hotpink}{- \\delta_1} \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#step-3-model","title":"Step 3: Model","text":"<p>Since \\(X_1^*\\) is what we have, but we want the mapping with \\(X_1\\),</p> \\[ \\begin{aligned} \\hat y &amp;= f(X_1) \\\\ &amp;= f(X_1^* \\textcolor{hotpink}{- \\delta_1}) \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#example","title":"Example","text":"<p>Example: Modelling with linear regression using a regressor with measurement error $$ \\begin{aligned} \\implies \\hat y &amp;= \\theta_0 + \\theta_1 X_1 \\ &amp;= \\theta_0 + \\theta_1 (X_1^* - \\delta_1) \\ &amp;= \\theta_0 + \\theta_1 X_1^* \\textcolor{hotpink}{- \\theta_1 \\delta_1} \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#iia","title":"IIA","text":"<p>Independence of Irrelevant Alternatives</p> <p>The IIA property is the result of assuming that errors are independent of each other in a classification task</p> <p>The probability of \\(y = j\\) relative to \\(y = k\\) depends is not affected by the existence and the properties of other classes</p> <p>$$ \\begin{aligned} p(y=j \\vert x, z) &amp;= \\dfrac{ \\exp(\\beta_j x + \\textcolor{hotpink}{\\gamma_j z}) }{ \\sum_k^K \\exp(\\beta_k x + \\textcolor{hotpink}{\\gamma_k z} ) } \\ \\implies p(y=j \\vert x)  &amp;= \\int \\dfrac{ \\exp(\\beta_j x + \\textcolor{hotpink}{\\gamma_j z}) }{ \\sum_k^K \\exp(\\beta_k x + \\textcolor{hotpink}{\\gamma_k z} ) } f(z) \\cdot dz \\end{aligned} $$ where \\(\\gamma\\) is the effect of the other classes (substitutes/complementary goods)</p> <p>For IIA, \\(\\gamma=0\\)</p> <p>IIA property should be a desirable property for well-specified models</p> <ul> <li>the error for one alternative provides no information about the error for another alternative. This should be the property of a well-specified model such that the unobserved portion of utility is essentially \u201cwhite noise.</li> <li>However, when a model omits important unobserved variables that explain individual choice patterns, however, the errors can become correlated over alternatives</li> </ul>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#heteroskedascity","title":"Heteroskedascity","text":""},{"location":"CS_Electives/Machine_Learning/05_Statistics/#causes-of-heteroskedascity","title":"Causes of Heteroskedascity","text":"<ul> <li>Misspecified model</li> <li>If output is \\(\\bar y\\), but the sample size is different for each calculated mean</li> <li>\\(s_{\\bar y} = \\sigma_y/ \\sqrt{n}\\)</li> <li>Eg: Average income vs years of college</li> <li>Variance/standard error is relative to the \\(y\\)</li> <li>Eg: Precision of tool is relative to the observed value, such as weighing scale</li> <li>Variance has been experimentally determined for each \\(y\\) value</li> <li>Some distributions naturally have variance that is a function of the</li> <li>Mean: Poisson</li> <li>Mean &amp; Variance: Gamma</li> </ul>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#statistical-test","title":"Statistical Test","text":"<ul> <li>Sort residuals \\(u_i\\) wrt corresponding \\(\\vert y_i \\vert\\)</li> <li>Divide residuals (esr for fits) into \\(g\\) subgroups</li> <li>Test to see if sub-groups share same variance</li> <li>\\(H_0:\\) all groups have same variance</li> </ul> Distribution of statistic Null Hypothesis Formula Barlett Assumes normal distribution (sensitive to deviations from normality) \\(\\chi^2\\) distributed with \\((g-1)\\) DOF \\(k\\) sub-groups have equal variance \\(\\dfrac{(n-g) \\ln s^2_\\text{pool} - \\sum\\limits_{j=1}^g (n_j - 1) \\ln s^2_j }{ 1 + \\Big[ 1/[3(g-1)] \\Big] \\left[ \\Big( \\sum\\limits_{j=1}^g \\dfrac{1}{(n_j - 1)} \\Big) - \\dfrac{1}{n-g} \\right] }\\) Brown-Forsythe/Modified Levene compares deviations from median; it is robust to deviations from normality, but has lower power\\(n_j &gt; 25 \\quad \\forall j \\in k\\) \\(t\\) distribution with DOF = \\(n-g\\) Constant variance \\(\\dfrac{\\vert \\bar d_1 - \\bar d_2 \\vert}{s_\\text{pool} \\sqrt{\\dfrac{1}{n_1} + \\dfrac{1}{n_2}}}\\)\\(d_{ij}=\\vert x_{ij} - \\text{med}_j \\vert\\) White Test Perform linear regression of \\(u_i^2\\) with \\(x\\) and test \\(nR^2\\) as \\(X^2_{k-1}\\) Breusch-Pagan Variation of white test where \\(x\\) is replaced with any variable of interest Park Perform linear regression of \\(\\ln \\vert u_i^2 \\vert\\) vs \\(\\ln \\vert x \\vert\\) and test significance of slope different from 0 <p>where</p> <ul> <li>\\(n=\\) total number of data points</li> <li>\\(k=\\) number of subgroups</li> <li>\\(n_j=\\) sample size of \\(j\\)th sub-group</li> <li>\\(s^2_j =\\) variance of \\(j\\)th sub-group</li> <li>\\(s^2_\\text{pool} = \\dfrac{1}{n-k} \\sum\\limits_{j=1}^k (n_j - 1) s^2_j\\)</li> <li>\\(\\text{med}_j =\\) median of \\(j\\)th sub-group</li> </ul>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#correcting","title":"Correcting","text":"Dependence of variance on \\(y_i\\) Solution Known Weighted regression Data transformation Unknown GMM, generalized methods of moments estimation"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#collinearity","title":"Collinearity","text":"<p>2 variables are correlated</p> <ul> <li>Can be inspected through correlation matrix of 2 variables</li> </ul>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#implication","title":"Implication","text":"<ul> <li>Adding/removing predictor variables changes the estimated effect of the vars (for eg: regression coefficients)</li> <li>Standard errors of coefficients become larger</li> <li>Individual regression coefficients may not be significant, even if the overall model is significant</li> <li>Some regression coefficients may be significantly different than expected (even opposing sign)</li> <li>There can be multiple solutions for \\(\\beta\\)</li> <li> <p>Both variables will be insignificant if both are included in the regression model</p> </li> <li> <p>Dropping one will likely make the other significant</p> </li> <li> <p>Hence we can\u2019t remove two (or more) supposedly insignificant predictors simultaneously: significance depends on what other predictors are included</p> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#causes","title":"Causes","text":"Cause No data: Inappropriate sampling We only sample regions where predictors are correlated Inappropriate model If range of predictors is small: \\(r(x, x^2) \\ne 0\\) True Population Collinearity indeed exists in the true population (for eg, height and weight)"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#multicollinearity","title":"Multicollinearity","text":"<p>Special case of Collinearity: Collinearity between 3 or more variables, regardless of whether or no no pair of variables are correlated</p> <p>eg: \\(r(x_1, x_2) = r(x_1, x_3) = 0\\), but \\(r(x_1, x_2+x_3) \\ne 0\\)</p>"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#detection","title":"Detection","text":"Correlation matrix Mutual Information Matrix VIFVariance Inflation Factor How much is the variance of the \\(k\\)th model coefficient inflated compared to case of no inflation\\(\\text{VIF}(x_j \\vert x_j') = \\dfrac{1}{1 - R^2_{x_j \\vert x_{j'} }} ; \\quad j' \\in [0, k] - \\{ j \\}\\)\\(R^2_{x_j \\vert x_{j'}}\\) is the out-of-sample \\(R^2\\) when \\(x_j\\) is regressed against all other predictor vars, using linear/non-linear model; out-of-sample is important to alleviate any issues of overfitting- \\(1/\\text{VIF}_{x_j \\vert x_{j'}}=\\) \u201ctolerance\u201d- \\(\\text{VIF}_{x_j \\vert x_{j'}} = 1 \\implies\\) No collinearity between \\(x_j\\) and other vars- \\(\\text{VIF}_{x_j \\vert x_{j'}} \\ge 4 \\implies\\) Investigate- \\(\\text{VIF}_{x_j \\vert x_{j'}} \\ge 10 \\implies\\) Act\\(E[\\text{VIF}_{x_j \\vert x_{j'}}] \\quad \\forall j &gt; 1 \\implies\\) Problematic Eigensystem Analysis Find eigenvalues of correlation matrix, ie \\(\\tilde X^T \\tilde X\\)If all eigenvalues are about the same magnitude, no multicollinearityElse calculate condition number\\(\\kappa = \\lambda_\\max/\\lambda_\\min\\)If \\(\\kappa &gt; 100 \\implies\\) problem Tree-based Proximity with transposed input Computationally-expensive? Permutation feature similarity Features that show similar changes in importance when permuted together are considered similar1. Train a tree-based model3. Calculate score3. For each feature i:    - Permute its values    - Calculate permuted score    - For every other feature \\(j\\):      - Permute its values      - Calculate doubly permuted score"},{"location":"CS_Electives/Machine_Learning/05_Statistics/#solution","title":"Solution","text":"<ul> <li>Derive theoretical constraints relating input vars: helps simplify model; can be linear/non-linear</li> <li>If we only care about prediction, restrict scope of model for interpolation only, ie new inputs should coincide with range of predictor vars that exhibit the same pattern of multicollinearity</li> <li>Drop problematic variables, ie ones with highest VIF</li> <li>Collect more data that breaks pattern of multicollinearity</li> <li>Measure coefficients in separate experiment (then fix those coefficients)</li> <li>Regularization: Even for perfect multicollinearity, the ridge regression solution will always exist</li> <li>PCA</li> <li>Separates the high SE of coefficients from multicollinearity into components with low SE and high SE; you\u2019d only include the low SE components</li> <li>Helps identify unknown linear constraints</li> <li>Limitation: cannot help with non-linear relationship</li> </ul>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/","title":"Estimation","text":"\\(\\theta\\) is thought of as Maximize Frequentist Unknown constant \\(p(D \\vert \\hat \\theta)\\)Likelihood Bayesian Unknown random variable with PDF \\(p(\\hat \\theta \\vert D)\\)"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#mle","title":"MLE","text":"<p>Maximum Likelihood Estimation</p> <ol> <li>Predict a probability distribution \\(\\hat p(y \\vert x)\\)</li> <li>Get the likelihood of \\(\\hat p\\) wrt the data</li> <li>Update \\(\\hat p\\)\u00a0that maximizes the likelihood</li> <li>Go to step 1</li> </ol>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#idk","title":"IDK","text":"<p>To minimize the KL divergence between \\(\\hat p\\) and \\(p\\), and we maximize the likelihood of \\(\\hat p\\) $$ \\begin{aligned} \\arg \\min_{\\hat p} D_\\text{KL}(p \\vert \\vert \\hat p) &amp;= \\arg \\min_{\\hat p} E_{D \\sim p} \\ln \\left \\vert \\dfrac{\\hat p(x, y)}{p(x, y)} \\right \\vert \\ &amp;= \\arg \\min_{\\hat p} \\underbrace{E_{D \\sim p} \\ln p(x, y)}{\\mathclap {\\text{Constant}}} - \\underbrace{E} \\ln \\hat p(x, y){\\approx \\ln L(\\hat p),  n \\to \\infty} \\ &amp; \\approx \\arg \\min - L(\\hat p) = \\arg \\max_{\\hat p}  L(\\hat p) \\end{aligned} $$ Since we do not know \\(p\\), we can estimate \\(E_{D \\sim p} \\ln \\hat p(x, y)\\), using Monte-Carlo estimation and Law of Large numbers $$ E_{D \\sim p} \\ln \\hat p(x, y) {\\approx \\ln L(\\hat p),  n \\to \\infty} $$</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#likelihood","title":"Likelihood","text":"<p>Probability of observing data \\(x\\) according to pdf \\(p(x)\\)</p> \\[ \\begin{aligned} L(p) &amp;= Pr_q(x) \\\\ &amp;= \\prod_{i=1}^n p(x_i) \\\\ \\implies \\ln L(p) &amp;= \\sum_{i=1}^n \\ln p(x_i) \\\\ \\end{aligned} \\] \\[ \\begin{aligned} \\mathcal{L} &amp;= P(y_i \\vert x_i, \\hat \\theta) \\\\ &amp;= p(y_1, y_2, \\dots, y_n \\vert x_i,  \\hat \\theta) \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#estimation_1","title":"Estimation","text":"<p>Chooses a distribution \\(p(x)\\) that maximizes the (log) likelihood function for \\(x\\)</p> <p>Below example shows MLE for a single point</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#mle-for-regression","title":"MLE for Regression","text":"<p>If we assume that the data is normally distributed, and we want unbiased prediction, then \\(u_i \\sim N(0, \\sigma^2_i)\\) $$ \\begin{aligned} \\mathcal{L} &amp;= P(u_1, u_2, \\dots, u_n \\vert \\hat \\theta) \\ &amp;= \\prod_i^n P(u_i) \\ &amp;= \\prod_i^n \\dfrac{1}{\\sqrt{2 \\pi \\sigma^2_i}} \\times \\exp \\left[\\dfrac{-1}{2} \\left(\\dfrac{u_i-\\mu_i}{\\sigma_i} \\right)^2 \\right]\\ &amp;= \\prod_i^n \\dfrac{1}{\\sqrt{2 \\pi \\sigma^2_i}} \\times \\exp \\left[\\dfrac{-1}{2} \\left(\\dfrac{u_i }{\\sigma_i} \\right)^2 \\right] &amp; (\\mu_u=0) \\end{aligned} $$</p> <p>$$ \\begin{aligned} \\ln \\vert \\mathcal{L} \\vert &amp;= \\dfrac{-1}{2} \\Big[ n \\ln \\vert 2 \\pi \\sigma^2_i \\vert + \\chi^2 \\Big] \\ \\implies -2 \\ln \\vert \\mathcal{L} \\vert &amp;= n \\ln \\vert 2 \\pi \\sigma^2_i \\vert + \\chi^2 \\</p> <p>&amp;= n \\ln \\vert 2 \\pi \\vert + n \\ln \\vert \\text{MSE} \\vert + n + \\sum_i^n \\ln \\vert w_i \\vert \\ &amp;\\approx n \\ln \\vert \\text{MSE} \\vert \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#optimization","title":"Optimization","text":"\\[ \\begin{aligned} \\implies \\max(\\mathcal{L}) &amp; \\propto \\min (-2 \\ln \\mathcal{L}) \\\\ &amp; \\propto \\min (\\chi^2_{n-k, 0}) \\\\ \\implies \\mathcal{L} &amp; \\propto e^{-\\chi^2_{n-k, 0}} \\end{aligned} \\] <p>By setting derivative to 0, we can also use this to derive expression for Matrix Normal Expression</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#note","title":"Note","text":"<p>$$ \\begin{aligned} E[\\chi^2] &amp;= n-p \\</p> <p>\\implies E[-2 \\ln \\vert \\mathcal{L} \\vert] &amp;= n \\ln \\vert 2 \\pi \\sigma^2_i \\vert + (n-p) \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#mle-for-classification","title":"MLE for Classification","text":"<p>Assume that \\(y \\sim \\text{Bernoulli}(p)\\) $$ \\mathcal L = $$</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#m-estimation","title":"M-Estimation","text":"<p>Minimize some other loss function weighted compare to MLE, such as MAE, Huber, etc</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#bayesian","title":"Bayesian","text":"<p>When is it justified?</p> <ul> <li>Prior is valid: Better than MLE</li> <li>Prior is irrelevant: Just a computational catalyst</li> </ul> \\[ \\begin{aligned} \\underbrace{P(\\hat f = f \\vert D)}_{\\mathclap{\\text{Posterior Distribution} \\qquad}} &amp;= \\frac{     \\overbrace{P(D \\vert \\hat f=f)}^{\\mathclap{\\text{Likelihood} }}     \\times     \\overbrace{P(\\hat f = f)}^{\\mathclap{\\qquad \\quad \\text{Prior Distribution}}} }{     \\underbrace{P(D)}_{\\mathclap{\\qquad \\text{Normalizing constant}}} } \\\\ &amp; \\propto P(D \\vert \\hat f=f) \\times P(\\hat f=f) \\end{aligned} \\] <ul> <li>\\(D = y \\vert x\\)</li> <li>\\(P(\\hat f = f)\\) is the prior belief of our understanding of</li> <li>Distribution of model parameters</li> <li>Distribution of residuals</li> </ul> <p>Usually we need to solve Bayes\u2019 equation numerically using MCMC: Markov Chain Monte Carlo sampling. Result is set of points from posterior distribution that we summarize</p> <p>Disadvantage: We need to calculate a lot of probabilities -&gt; Computationally-expensive</p> Hypothesis Maximum Likelihood Model that best explains the training data \\(h_\\text{ML} = \\underset{h_i \\in H}{\\arg \\max} \\ P(D \\vert  h_i)\\) Maximum A Posteriori Probability Model that is most probable given the training data \\(h_\\text{MAP} = something\\)"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#steps","title":"Steps","text":"<ol> <li>Pick prior distribution</li> <li>Calculate likelihood function, similar to MLE</li> <li>Calculate posterior distribution, usually numerically</li> <li>Summarize posterior distribution</li> <li>MAP estimate</li> <li>Credible interval</li> </ol>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#prior-distribution","title":"Prior Distribution","text":"<p>\\(P(\\theta) = P(\\theta \\vert I)\\), where \\(I=\\) all info we have before data collection</p> Prior Uninformative/Objective/Baseline If we have no prior knowledge, then \\(P(\\theta \\vert I)=\\) constantHence, \\(P(\\hat \\theta \\vert D) = P(D \\vert \\hat \\theta)\\), so might as well perform MLE insteadeg: Uniform dist over expected range of possible values Informative/Substantive Based on previous data, experiments, knowledgeOne can assume that the prior for each parameter is independent of others \\(P(\\theta)=P(\\beta) P(\\sigma^2)\\), but usually a joint dist is requiredSetting prior to delta function fixes parameter independent of data (never done in practice, as it ignores the point of data) <p></p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#reparametrization","title":"Reparametrization","text":"<p>Helps make prior assignment easy</p> <p>For eg: $$ \\begin{aligned} \\hat y_i &amp;= \\beta_0 + \\beta_1 x_i \\ \\implies \\hat y_i &amp;= \\beta_0' + \\beta_1 (x_i - \\bar x) \\ \\ \\text{Hence }  \\beta_0 &amp;= \\hat y_i \\vert (x_i=0) \\ \\implies \\beta_0' &amp;= \\hat y_i \\vert (x_i = \\bar x) \\end{aligned} $$</p> <ul> <li>This makes it easier to specify the prior for the intercept</li> <li>We can assume that \\(\\beta_0'\\) is independent of \\(\\beta_1\\)\u2019s prior</li> </ul>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#conjugate-priors","title":"Conjugate Priors","text":"<p>Special cases of priors only for which analytical solutions of the posterior distribution are possible with given likelihood distribution</p> <p>For eg:</p> <ul> <li>iid normal errors</li> <li>conjugate prior for \\(\\beta\\) is normal</li> <li>conjugate prior for \\(\\sigma^2_u\\) is inverse gamma</li> </ul>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#posterior-distribution","title":"Posterior Distribution","text":"<p>Output of Bayesian estimation is not best fit parameters, it is the posterior distribution: probability distribution for each parameter and \\(\\sigma_e\\)</p> <p>We need to summarize the distribution</p> <ul> <li>Best estimate: Summary statistic such as</li> <li>mode (Maximum a posteriori)</li> <li>mean</li> <li>median</li> <li>etc</li> <li>Credible interval: Quantiles</li> </ul> <p>Posterior distribution describes how much the data has changed our prior beliefs</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#bernstein-von-mises-theorem","title":"Bernstein-von Mises Theorem","text":"<p>For very large \\(n\\), posterior distribution becomes independent of the prior distribution, as long as the prior \\(\\not \\in \\{0, 1 \\}\\)</p> <p>Posterior tends towards normal distribution equal to MLE (assuming iid)</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#problems","title":"Problems","text":"<ul> <li>Computationally-expensive</li> <li>Choosing appropriate prior</li> <li>Is it reasonable to treat every parameter as a random variable</li> </ul>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#mle-bayesian","title":"MLE + Bayesian","text":""},{"location":"CS_Electives/Machine_Learning/06_Estimation/#relationship","title":"Relationship","text":"<p>MLE = Bayesian with Jeffreys Prior</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#jeffreys-prior","title":"Jeffreys Prior","text":"\\[ P(\\beta, \\sigma^2_u) \\propto 1/\\sigma^2_u \\] <p>It is improper as it adds upto \\(\\infty\\), not \\(1\\)</p> <p>The resulting posterior distribution is \\(t\\) distributed about MLE parameter estimates</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#idk_1","title":"IDK","text":"<p>Taking \\(-\\ln\\) of Bayes\u2019 equation $$ \\begin{aligned} - \\ln p(\\hat \\theta \\vert D) &amp;= - \\ln L - \\ln p(\\hat \\theta) + \\underbrace{\\ln p(D)}\\text{constant} \\ \\min { - \\ln p(\\hat \\theta \\vert D) } &amp;= \\min { - \\ln L - \\ln p(\\hat \\theta) + \\cancel{\\ln p(D)} } \\ &amp;= \\min { \\chi^2 + \\sum \\left( \\dfrac{\\hat \\beta - \\mu_{\\beta}}{\\sigma_\\beta} \\right)^2 } \\ &amp;= \\text{Regularized Regression} \\end{aligned} $$}^{k</p>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#likelihood_1","title":"Likelihood","text":"<pre><code>def ll(X, y, pred):\n    # return log likelihood\n\n        mse = np.mean(\n      (y - pred)\n      **2\n    )\n\n    n = float(X.shape[0])\n    n_2 = n/2\n\n    return -n_2*np.log(2*np.pi) - n_2*np.log(mse) - n_2\n\ndef aic(X, y, pred):\n    p = X.shape[1]\n\n    return -2*ll(X, y, pred) + 2*p\n\nprint(aic(X, y, pred))\n</code></pre>"},{"location":"CS_Electives/Machine_Learning/06_Estimation/#estimating-entire-distribution","title":"Estimating entire distribution","text":"<p>Neural network with multiple outputs</p> <ol> <li>mean and multiple quantiles, rather than estimating mean and std... This relaxes the normality assumption</li> <li>Mean and std: Maximum likelihood estimation </li> </ol> <p>Cost function = sum of costs of each parameter, weighted by inverse of standard error for estimates - quantiles will tend to have more uncertainty in estimation, so less weight should be given</p>"},{"location":"CS_Electives/Machine_Learning/07_Information_Theory/","title":"Information Theory","text":""},{"location":"CS_Electives/Machine_Learning/07_Information_Theory/#entropy","title":"Entropy","text":"<p>Entropy, as it relates to machine learning, is a measure of the randomness in the information being processed. The higher the entropy, the harder it is to draw any conclusions from that information. </p> <p>Information entropy is developed to describe the avg amount of info needed to specify the state of a RV</p> <p>Quantifies how much new information about a RV \\(x\\) is obtained when we observe a specific value \\(x_i\\)</p> <ul> <li>Depends on \u2018degree of surprise\u2019: highly improbable value conveys more information than likely one</li> <li>If we know an event is certain to happen, we would receive no information when we actually observe it happening</li> </ul> <p>Let \\(h(x)\\) denote the information content of an event \\(x\\), such that</p> <ul> <li>\\(p(x) \\propto \\dfrac{1}{p(x)}\\)</li> <li>For 2 independent events \\(A\\) and \\(B\\)</li> </ul> \\[ \\begin{aligned} p(A \\land B) &amp;= p(A) \\cdot p(B) \\\\ \\implies h(AB) &amp;= h(A) + h(B) \\end{aligned} \\] \\[ h(x) = \\log \\left \\vert \\dfrac{1}{p(x)} \\right \\vert \\]"},{"location":"CS_Electives/Machine_Learning/07_Information_Theory/#shannoninformation-entropy","title":"Shannon/Information Entropy","text":"<p>Entropy of a probability distribution \\(p(x)\\) is the average amount of information transmitted by discrete random variable \\(x\\) $$ \\begin{aligned} H(p) &amp;= E_p[h(x)] \\ &amp;= \\sum_x p(x) \\log \\left \\vert \\dfrac{1}{p(x)} \\right \\vert \\end{aligned} $$</p> <ul> <li>Distributions with sharp peaks around a few values will have a relatively low entropy</li> <li>Those spread evenly across many values will have higher entropy</li> </ul> <p>If we use \\(\\ln\\) instead of \\(\\log\\) for \\(H(p)\\), then \\(H(p)\\) is a lower bound on the avg no of bits needed to encode a RV with pdf \\(p\\). Achieving this bound requires using an optimal coding scheme designed for \\(p\\), which assigns</p> <ul> <li>shorter codes to higher probability events</li> <li>longer codes to less probable events</li> </ul>"},{"location":"CS_Electives/Machine_Learning/07_Information_Theory/#cross-entropy","title":"Cross Entropy","text":"<p>The average amount of information needed to specify \\(x\\) as a result of using pdf \\(q(x)\\) instead of true \\(p(x)\\)</p> <p>If we use \\(\\ln\\) instead of \\(\\log\\), it is the average no of bits needed to encode a RV using a coding scheme designed for \\(q(x)\\) instead of true \\(p(x)\\) $$ \\begin{aligned} H(p, q) &amp;= E_p \\left[ \\log \\left \\vert \\dfrac{1}{q(x)} \\right \\vert \\right] \\ &amp;= \\sum_x p(x) \\log \\left \\vert \\dfrac{1}{q(x)} \\right \\vert \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/07_Information_Theory/#kl-divergence","title":"KL Divergence","text":"<p>Dissimilarity measure of 2 probability distributions</p> <p>Represents the avg additional info required to  specify \\(x\\) due to using \\(q(x)\\) instead of true \\(p(x)\\) $$ \\begin{aligned}  D_\\text{KL}(p \\vert \\vert q) &amp;= \\text{Cross Entropy} - \\text{Entropy} \\ &amp;= H(p, q) - H(p) \\ &amp; = \\sum_x \\log \\left \\vert \\dfrac{p(x)}{q(x)} \\right \\vert \\cdot p(x) &amp; \\text{(Discrete)} \\ &amp; = \\int_x \\log \\left \\vert \\dfrac{p(x)}{q(x)} \\right \\vert \\cdot p(x) &amp; \\text{(Continuous)} \\end{aligned} $$ Propreties</p> <ul> <li>\\(D_\\text{KL}(p \\vert \\vert q) = 0 \\iff p=q\\)</li> <li>KL divergence is asymmetric \\(\\implies D_\\text{KL}(p \\vert \\vert q) \\ne D_\\text{KL}(q \\vert \\vert p)\\). Hence it is not a proper distance measure</li> <li>Non-Negative: \\(D_\\text{KL}(p \\vert \\vert q) \\ge 0\\)</li> </ul> <p>Given a fixed distribution \\(p\\), optimizing for a \\(q\\) for the following 3 goals are equivalent</p> <ul> <li>minimize \\(D_\\text{KL}(p \\vert \\vert q)\\)</li> <li>minimize \\(H(p, q)\\)</li> <li>maximize \\(L(q \\vert x)\\), where \\(x \\sim p(x)\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/","title":"Cost Function","text":"<p>Choosing an appropriate (or defining custom) error, loss, and cost functions is the most important aspect in Machine Learning, but often overlooked - Defines \"what is bad\" for the model to correctly optimize for an appropriate scenario</p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#goals","title":"Goals","text":"<ul> <li> Quality of Prediction<ul> <li> Minimize error bias -&gt; accurate model</li> <li> Minimize error variance -&gt; precise model</li> </ul> </li> <li> Sensitivity to data<ul> <li> Minimize model bias</li> <li> Minimize model variance</li> </ul> </li> <li> Generalization aspects<ul> <li> Minimize difference between in-sample and out-of-sample</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#error","title":"Error","text":"<p>Using MLE, we define error as</p> \\[ \\begin{aligned} u_i &amp;= \\hat y_i - y_i \\\\ u_i' &amp;= \\dfrac{u_i}{\\sigma_{yi}} \\end{aligned} \\] <p>Usually we expect that \\(\\sigma_{yi}=1\\) and without any measurement noise</p> <p>Bayes\u2019 Error is the error incurred by an ideal model, which is one that makes predictions from true distribution \\(P(x,y)\\); even such a model incurs some error due to noise/overlap in the distributions</p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#total-regression","title":"Total Regression","text":"<p>Total Least Squares</p> <p>Note: TLS is non-convex, and can have multiple solutions - Workarounds     - perform OLS first to obtain initial weights     - perform TLS with regularization</p> <p>Methods</p> <ul> <li>Effective Variance</li> <li>Deming Regression</li> <li>Orthogonal regression</li> <li>Geometric mean</li> <li>Method of moments</li> <li>Full total regression</li> </ul> <p>Useful for when data has noise due to</p> <ul> <li>Measurement error</li> <li>Need for privacy etc, such as when conducting a salary survey.</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#effective-variance","title":"Effective Variance","text":"\\[ \\begin{aligned} \\sigma^2_{{\\text{eff}}_i} &amp;= \\text{Uncertainty due to } y + \\text{Uncertainty due to } x \\\\ &amp;= \\Big( \\sigma^2_{y_{i}} + \\sigma^2_{y_{i}, \\text{meas}} \\Big) + \\Bigg[ 1 + \\sum_{j=1}^m \\beta_{j}^2 \\left( \\sigma^2_{x_{ij}} + \\sigma^2_{x_{ij}, \\text{meas}} \\right) \\Bigg] \\end{aligned} \\] <p>where - \\(\\sigma^2(\\delta_{ij}) =\\) measurement error in \\(x_{ij}\\)     - For non-linear regression with \\(\\tilde x_j = g(x_j)\\), using delta approach  \\(\\sigma^2(\\delta_{ij}) = \\sigma^2(\\delta_{ij}) \\cdot \\Big(g'(x_j) \\Big)^2\\) - \\(\\beta_j = \\dfrac{\\partial f}{\\partial x_j}\\)     - applies for linear/non-linear/non-parametric models - the \\(1\\) comes due to     - \\(y = \\beta_0 + \\beta_1 x\\)     - \\(\\beta_0 + \\beta_1 x \\textcolor{hotpink}{-1}y =0\\)     - \\(\\sigma^2_x = \\beta_1^2 + 1\\)</p> <p>Use uncertainties package to calculate - Variance of measurement &amp; transformation function -&gt; pass to function -&gt; convert to ufloat -&gt; perform operation -&gt; return as numpy</p> <p>Total Regression via IRWLS - Iteratively ReWeighted Least Squares</p> <ol> <li>Run regression ignoring effective variance \\(\\sigma_{xi}\\)</li> <li>Use this model fit to calculate \\(\\beta_j = \\frac{\\partial L}{\\partial x_j} \\quad \\forall j\\) </li> <li>Calculate the effective variance \\(\\sigma^2_{i, \\text{eff}} \\quad \\forall i\\)</li> <li>Run weighted regression using 1/effective variance to weight the \\(u_i\\)</li> <li>Repeated steps 2-4 until parameters converge (usually only 1-2 few iterations)</li> </ol> <p></p> <p></p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#deming-regression","title":"Deming Regression","text":"\\[ \\begin{aligned} L &amp;= \\left( \\dfrac{u_i}{\\sigma_{yi}} \\right)^2  + \\lambda \\left( \\dfrac{\\hat x_i - x_i}{\\sigma_{xi}} \\right)^2 \\\\ \\lambda &amp;= \\dfrac{\\sigma^2(\\text{known measurement error}_x)}{\\sigma^2(\\text{known measurement error}_y)} \\\\ \\hat y_i &amp;= \\hat \\beta_0 + \\hat \\beta_1 x_i \\\\ \\hat x_i &amp;= \\dfrac{y_i - \\beta_0}{\\beta_1} \\end{aligned} \\] <p>OLS of \\(y_i \\vert \\hat x_i\\) produces same fit as Deming of \\(y_i \\vert x_i\\)</p> <p>Assumes that there is no model error: all uncertainty in \\(x\\) and \\(y\\) is due to measurement</p> <p>If Deming Regression and Method of Moments give different estimates, then the model specification may be incorrect</p> <p>Deming regression is a type of total regression where you penalize error in estimating x, but this is difficult for multi variate: So total regression is better for multivariate</p> Measurement Error of Regressor \\(\\lambda\\) 0 0 OLS Same as Response 1 Orthogonal"},{"location":"CS_Electives/Machine_Learning/08_Cost/#orthogonal-regression","title":"Orthogonal Regression","text":"<ul> <li>\\(\\sigma_x = \\sigma_y\\)</li> <li>Applied when you measure the same quantity with 2 different methods: for tool matching, calibration curves</li> <li>For straight-line model, \\(\\sigma^2_{y_i, \\text{eff}} \\propto (1 + {\\beta_1}^2)\\)</li> </ul> \\[ \\begin{aligned} \\sigma^2_{y_i, \\text{eff}} &amp;= \\sigma^2_y \\left[ 1 + \\left(\\dfrac{\\partial f}{\\partial x_i}\\right)^2 \\\\ \\right] \\\\ \\chi^2 &amp;= \\sum_{i=1}^n \\left[ \\dfrac{u_i}{\\sqrt{1+{\\beta_1}^2}} \\right]^2 \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#geometric-mean-regression","title":"Geometric Mean Regression","text":"<ul> <li>Estimate slope as geometric mean of OLS slopes from \\(y \\vert x\\)  and \\(x \\vert y\\)</li> <li>\\(\\beta_1 = \\dfrac{s_y}{s_y}\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#method-of-moments","title":"Method of Moments","text":"<p>If we know measurement error in \\(x:\\) \\(\\sigma_{\\delta_x}\\)</p> <p>Only good when \\(n&gt;50\\)</p> \\[ \\begin{aligned} \\beta_1' &amp;= \\dfrac{\\beta_1}{1 - \\left(\\dfrac{s_{\\delta_x}}{s_x} \\right)^2} \\\\ \\text{SE}(\\beta_1') &amp;= \\dfrac{\\beta_1}{\\sqrt{n}} \\sqrt{\\dfrac{(s_x s_y)^2 + 2 (\\beta_1 s^2_{\\delta_x})^2}{(s_{xy})^2} - 1} \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#mse-vs-chi-squared","title":"MSE vs Chi-Squared","text":"<ul> <li>MSE(\\(u_i\\)) may/may not \\(= \\chi^2_\\text{red}\\)</li> <li>MSE(\\(u_i'\\)) \\(= \\chi^2_\\text{red}\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#loss-functions-mathcal-ltheta","title":"Loss Functions \\({\\mathcal L}(\\theta)\\)","text":"\\[ \\text{Loss}_i = {\\mathcal L}(\\theta, u_i) \\] <ul> <li>Penalty for a single point (absolute value, squared, etc)</li> <li>Should always be tailor-made for each problem, unless impossible</li> <li>Need not be symmetric</li> <li>Regression: Under-prediction and over-prediction can be penalized differently</li> <li>Classification: False negative and false-positive can be penalized differently</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#properties-of-loss-function","title":"Properties of Loss Function","text":"Property Non-negativity \\({\\mathcal L}(u_i) \\ge 0, \\quad \\forall i\\) No penalty for no error \\({\\mathcal L}(0)=0\\) Monoticity \\(\\vert u_i \\vert &gt; \\vert u_j \\vert \\implies {\\mathcal L}(u_i) &gt; {\\mathcal L}(u_j)\\) Differentiable Continuous derivative Symmetry \\({\\mathcal L}(-u_i)={\\mathcal L}(+u_i)\\) Not necessary for custom loss"},{"location":"CS_Electives/Machine_Learning/08_Cost/#combining-loss-functions","title":"Combining loss functions","text":"\\[ L' = \\sum w_i L_i \\] <ul> <li>For asymmetric loss<ul> <li>\\(w_1 = \\mathcal I [u&lt;0], w_2 = \\mathcal I[u&gt;0]\\)</li> <li>If smoothness of combined loss required, \\(w_1 = \\sigma(u), w_2 = 1 - \\sigma(u)\\)</li> <li>Assymmetric MAE loss can be redefined as pinball/expectile loss, ...<ul> <li>Redefine \\(w_i\\) such that \\(\\sum w_i = 1\\)</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#weighted-loss","title":"Weighted Loss","text":"<p>Related to weighted regression $$ {\\mathcal L}'(\\theta) = {\\mathcal L}(w_i \\theta) $$</p> \\[ \\begin{aligned} u'_i &amp;= u_i \\times \\sqrt[a]{w_i} \\\\ \\text{SE}(u') &amp;= s_{u'} \\\\ &amp;= \\sqrt{\\dfrac{\\sum_{i=1}^n w_i (u_i)^2}{n-k}} \\\\ &amp;= \\sqrt{\\dfrac{\\sum_{i=1}^n (u_i')^2}{n-k}} \\end{aligned} \\] <p>where</p> <ul> <li>\\({\\mathcal J}(\\theta)\\) = usual loss function</li> <li>\\(a=\\) exponent of the loss function (square, etc)</li> </ul> Goal: Address \\(w_i\\) Prefer Comment Asymmetry of importance \\(\\Big( \\text{sgn}(u_i) - \\alpha \\Big)^2 \\\\ \\alpha \\in [-1, 1]\\) \\(\\begin{cases} \\text{Under-estimation}, &amp; \\alpha &lt; 0 \\\\ \\text{Over-estimation}, &amp; \\alpha &gt; 0 \\end{cases}\\) Be carefulBiased forecast will reduce trustInstead, Better to balance risk of overforecasting and underforecasting for each product independently using business rules Observation ErrorMeasurement/ProcessHeteroskedasticity \\(\\dfrac{1}{\\sigma^2_{yi}}\\)where \\(\\sigma^2_{y_i}\\) is the uncertainty associated with each observation Observations with low uncertainty Maximum likelihood estimation Input ErrorMeasurement/Process \\(\\dfrac{1}{\\sigma^2_{X_i}}\\)where \\(\\sigma^2_X\\) is the uncertainty associated Observations with high input measurement accuracy Observation Importance Importance Observations with high domain-knowledge importance For time series data, you can use \\(w_i = \\text{Radial basis function(t)}\\)- \\(\\mu = t_\\text{max}\\)- \\(\\sigma^2 = (t_\\text{max} - t_\\text{min})/2\\)"},{"location":"CS_Electives/Machine_Learning/08_Cost/#regression-loss","title":"Regression Loss","text":"Metric \\({\\mathcal L}(u_i)\\) Does not require MAD studentizing Optimizing gives __ of conditional distribution (not required to be Normal dist) Optimizing gives Influence\\(\\psi(u_i)\\)\\(\\dfrac{dL}{du}\\) \\(w_i\\) compared to AEie, weight for residual \\(w_i\\) compared to SE Preferred Value Unit Range Signifies Advantages\u2705 Disadvantages\u274c Comment \\(\\alpha\\) of advanced family Breakdown Point Efficiency Tuning factor for 95% efficiency Scale independent Insensitive to outliers Symmetric to over-underforecasting Symmetric to swapping of true and forecasted Can handle zeros Indicator/Zero-One/Misclassification \\(\\begin{cases} 0, &amp; u_i = 0 \\\\ 1, &amp; \\text{o.w} \\end{cases}\\) Mode Differentiable Mode Loss? Bin the continuous valuesSomething with PyTorch Mode BE(Bias Error) \\(u_i\\) \\(\\begin{cases} 0, &amp; \\text{Unbiased} \\\\ &gt;0, &amp; \\text{Over-prediction} \\\\ &lt;0, &amp; \\text{Under-pred} \\end{cases}\\) Unit of \\(y\\) \\((-\\infty, \\infty)\\) Direction of error biasTendency to overestimate/underestimate Cannot evaluate accuracy, as equal and opposite errors will cancel each other, which may lead to non-optimal model having error=0 L1/AE(Absolute Error)/Manhattan distance \\(\\vert  u_i  \\vert\\) Median Global minimum ignoring small portion \\(\\text{sgn}(u_i)\\) \\(1\\) \\(\\dfrac{1}{\\vert u_i \\vert}\\) \\(\\downarrow\\) Unit of \\(y\\) \\([0, \\infty)\\) Robust to outliers Not differentiable at origin, which causes problems for some optimization algoThere can be multiple optimal fitsDoes not penalize large deviations MLE for \\(\\chi^2\\) for Laplacian dist \\(74 \\%\\)??? L2/SE (Squared Error)/Euclidean distance \\({u_i}^2\\) Mean Global minimum affected by whole dataset \\(u_i\\) \\(u_i\\) \\(1\\) \\(\\downarrow\\) Unit of \\(y^2\\) \\([0, \\infty)\\) Variance of errors with mean as MDEMaximum log likelihood Penalizes large deviations Sensitive to outliers MLE for \\(\\chi^2\\) for normal dist \\(\\approx 2\\) \\(1/n\\) \\(100 \\%\\) Huber \\(\\begin{cases} \\dfrac{u_i^2}{2}, &amp; \\vert u_i \\vert &lt; \\epsilon \\\\ \\lambda \\vert u_i \\vert - \\dfrac{\\lambda^2}{2}, &amp; \\text{o.w} \\end{cases}\\)\\((\\lambda_\\text{rec} = 1.345 \\times \\text{MAD}_u)\\) \\(\\begin{cases} u_i, &amp; \\vert u_i \\vert \\le c \\\\ c \\cdot \\text{sgn}(u_i), &amp; \\text{o.w.} \\end{cases}\\) \\(\\begin{cases} 1, &amp; \\vert u_i \\vert &lt; c \\\\ c/\\vert u_i \\vert, &amp; \\text{o.w.} \\end{cases}\\) \\(\\downarrow\\) \\([0, \\infty)\\) Same as Smooth L1 Computationally-expensive for large datasets\\(\\epsilon\\) needs to be optimizedOnly first-derivative is defined Piece-wise combination of L1&amp;L2\\(H = \\epsilon \\times {L_1}_\\text{smooth}\\)Solution behaves like a trimmed mean: (conditional) mean of two (conditional) quantiles \\(95 \\%\\) \\(1.345\\) L1-L2Pseudo-Huber/Smooth L1/Charbonnier \\(\\delta^2 \\Bigg( \\sqrt{1 + \\dfrac{u_i}{\\delta}^2} - 1 \\Bigg)\\)\\(\\sqrt{1+x^2}\\) \\(\\dfrac{u_i}{\\sqrt{1+u_i^2}}\\) \\(\\dfrac{1}{\\sqrt{1+u_i^2}}\\) \\(\\downarrow\\) \\([0, \\infty)\\) Balance b/w L1 &amp; L2Prevents exploding gradientsRobust to outliersDouble differentiable Requires tuning parameter Piece-wise combination of L1&amp;L2 1 Log Cosh \\(\\begin{aligned} &amp; \\ln \\big( \\ \\cosh (u_i) \\ \\big) \\\\ &amp; \\approx \\begin{cases} \\dfrac{{u_i}^2}{2}, &amp; \\vert u_i \\vert \\to 0 \\\\ \\vert u_i \\vert - \\log 2, &amp; \\vert u_i \\vert \\to \\infty \\end{cases} \\end{aligned}\\) \\(\\downarrow\\) Doesn\u2019t require parameter tuningDouble differentiable Numerically unstable: Instead, use \\(u + \\text{softplus}(-2u) - \\log(2)\\) Smoother L1? \\(u_i \\cdot \\text{erf}(u_i)\\) Doesn\u2019t require parameter tuningDouble differentiable Generalized Power Cosh Loss \\(\\begin{aligned} u'_i = \\cosh(u_i) \\\\ \\begin{cases} \\log \\vert u'_i \\vert, &amp; \\lambda = 0 \\\\ \\dfrac{\\text{sign}(u'_i) \\vert u'_i \\vert ^\\lambda - 1}{\\lambda}, &amp; \\lambda \\ne 0 \\end{cases} \\end{aligned}\\) LinExVarian-Zellner \\(\\dfrac{2}{a^2} \\Bigg( \\exp \\{a u_i\\} - 1 - a u_i \\Bigg)\\) \\(a &gt; 0\\) penalizes\\(\\begin{cases} \\exp \\{ u_i \\} &amp; &lt;0 \\\\ u_i &amp; &gt;0 \\end{cases}\\)\\(a &lt; 0\\) penalizes\\(\\begin{cases} u_i &amp; &lt;0 \\\\ \\exp \\{u_i \\} &amp; &gt;0 \\end{cases}\\) Double differentiable Assymmetric loss functionWhen \\(a \\to 0\\), tends to Squared ErrorWhen \\(u_i \\to 0\\), regardless of \\(a\\), tends to Squared Error LinSqI tried? \\(\\sigma(u_i) \\cdot u_i^2 \\ + \\ (1-\\sigma(u_i)) \\cdot \\ln \\Big( \\cosh(u_i) \\Big)\\) \u2705 Tweedie Fair \\(c^2 \\Bigg( \\vert u_i \\vert/c - \\log \\Big( 1 + \\vert u_i \\vert/c \\Big) \\Bigg)\\) \\(\\dfrac{u_i}{1+(\\vert u_i \\vert/c)}\\) \\(\\dfrac{1}{1+(\\vert u_i \\vert/c)}\\) Triple differentiable Convex Cauchy/Lorentzian \\(\\dfrac{\\epsilon^2}{2} \\times \\log_b \\Big[ 1 + \\left( \\dfrac{{u_i}}{\\epsilon} \\right)^2 \\Big]\\)Usually \\(\\epsilon=1\\) and \\(b=e\\) \u2705 \\(\\dfrac{u_i}{1+(\\vert u_i \\vert/c)^2}\\) \\(\\dfrac{1}{1+(\\vert u_i \\vert/c)^2}\\) \\(\\downarrow\\) Same as Smooth L1 Not convex 0 \\(2.385\\) Arctan \\(\\tan^{-1} (u_i)\\)\\(\\dfrac{\\epsilon^2}{2} \\times \\tan^{-1} \\Big[ \\left( \\dfrac{{u_i}}{\\epsilon} \\right)^2 \\Big]\\) \u2705 Local minimum fitting small amount of data well, while ignoring large amount of data Not convex Andrews \\(1 - \\cos(u)\\) \\(\\begin{cases} u_i \\cdot \\dfrac{\\sin(u_i/c)}{u_i/c}, &amp; \\vert u_i \\vert \\le \\pi c \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(\\begin{cases} \\dfrac{\\sin(u_i/c)}{u_i/c}, &amp; \\vert u_i \\vert \\le \\pi c \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(1.339\\) Talworth \\(\\begin{cases} u_i, &amp; \\vert u_i \\vert &lt; c \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(\\begin{cases} 1, &amp; \\vert u_i \\vert &lt; c \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(2.795\\) Hampel \\(\\begin{cases} 1, &amp; \\vert u_i \\vert \\le a \\\\ a/\\vert u_i \\vert, &amp; \\vert u_i \\vert \\in (a, b] \\\\ a/\\vert u_i \\vert \\cdot \\dfrac{c- \\vert u_i \\vert}{c-b}, &amp; \\vert u_i \\vert \\in (b, c] \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(4, 2, 8\\) Logistic \\(\\dfrac{\\tanh(x/c)}{x/c}\\) \\(1.205\\) Log-Barrier \\(\\begin{cases} - \\epsilon^2 \\times \\log \\Big(1- \\left(\\dfrac{u_i}{\\epsilon} \\right)^2 \\Big) , &amp; \\vert u_i \\vert \\le \\epsilon \\\\ \\infty, &amp; \\text{o.w} \\end{cases}\\) \u274c Solution not guaranteed Regression loss \\(&lt; \\epsilon\\), and classification loss further \\(\\epsilon\\)-insensitive \\(\\begin{cases} 0, &amp; \\vert u_i \\vert \\le \\epsilon \\\\ \\vert u_i \\vert - \\epsilon, &amp; \\text{otherwise} \\end{cases}\\) \u274c Non-differentiable Tukey/Bisquare \\(\\begin{cases} \\dfrac{\\lambda^2}{6 \\left(1- \\left[1-\\left( \\dfrac{u_i}{\\lambda} \\right)^2 \\right]^3 \\right)}, &amp; \\vert u_i \\vert &lt; \\lambda \\\\ \\dfrac{\\lambda^2}{6}, &amp; \\text{o.w} \\end{cases}\\)\\(\\lambda_\\text{rec} = 4.685 \\times \\text{MAD}_u\\)\\(\\min \\{u_i^2, \\lambda^2 \\}\\) \u274c \\(\\begin{cases} u_i \\left(1-(u_i/c)^2 \\right)^2, &amp; \\vert u_i \\vert &lt; c \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(\\begin{cases} \\left(1-(u_i/c)^2 \\right)^2, &amp; \\vert u_i \\vert &lt; c \\\\ 0, &amp; \\text{o.w.} \\end{cases}\\) \\(\\downarrow\\) Robust to outliers Suffers from local minima (Use huber loss output as initial guess) Ignores values after a certain threshold \\(\\infty\\) \\(4.685\\) Welsch/Leclerc \\(\\dfrac{c^2}{2} \\Bigg( 1 - \\exp \\Big(-(u_i/c)^2 \\Big) \\Bigg)\\) \\(u_i \\exp \\left( \\dfrac{-(u_i/c)^2}{c} \\right)\\) \\(\\exp \\left( \\dfrac{-(u_i/c)^2}{c} \\right)\\) \\(2.985\\) Geman-Mclure \\(\\dfrac{u_i^2}{1+u_i^2}\\) \\(\\dfrac{u_i}{(1+u_i^2)^2}\\) \\(\\dfrac{1}{(1+u_i^2)^2}\\) -2 Quantile/Pinball \\(\\begin{cases} q \\vert u_i \\vert , &amp; \\hat y_i &lt; y_i \\\\ (1-q) \\vert u_i \\vert, &amp; \\text{o.w} \\end{cases}\\)\\(q = \\text{Quantile}\\) Quantile \\(\\downarrow\\) Unit of \\(y\\) Robust to outliers Computationally-expensive Expectile \\(\\begin{cases} e (u_i)^2 , &amp; \\hat y_i &lt; y_i \\\\ (1-e) (u_i)^2, &amp; \\text{o.w} \\end{cases}\\)\\(e = \\text{Expectile}\\) Expectile \\(\\downarrow\\) Unit of \\(y^2\\) Expectiles are a generalization of the expectation in the same way as quantiles are a generalization of the median APE(Absolute Percentage Error) \\(\\left \\lvert  \\dfrac{ u_i }{y_i}  \\right \\vert\\) \\(\\dfrac{1}{\\vert y_i \\vert}\\) \\(\\downarrow\\) % \\([0, \\infty)\\) Easy to understandRobust to outliers Gives low weightage to high response values, and high weightage to low response valuesExplodes when \\(y_i \\approx 0\\)Division by 0 error when \\(y_i=0\\)Asymmetric: \\(\\text{APE}(\\hat y, y) \\ne \\text{APE}(y, \\hat y) \\implies\\) When actuals and predicted are switched, the loss is differentSensitive to measurement unitsCan only be used for ratio response variables (Kelvin), not for others (eg: Celcius) adjMAPEAdjusted MAPESMAPESymmetric MAPE \\(\\left \\lvert  \\dfrac{ u_i }{\\hat y_i + y_i}  \\right \\vert\\) Asymmetric: Penalizes over-prediction more than under-prediction Denominator is meant to be mean(\\(\\hat y, y\\)), but the 2 is cancelled for appropriate range SSE(Squared Scaled Error) \\(\\dfrac{ 1 }{\\text{SE}(y_\\text{naive}, y)} \\cdot u_i^2\\) \\(\\downarrow\\) % \\([0, \\infty)\\) ASE(Absolute Scaled Error) \\(\\dfrac{ 1 }{\\text{AE}(y_\\text{naive}, y)} \\cdot \\vert u_i \\vert\\) \\(\\downarrow\\) % \\([0, \\infty)\\) ASE Modified \\(\\left \\lvert \\dfrac{ u_i }{y_\\text{naive} - y_i} \\right \\vert\\) \\(\\downarrow\\) % \\([0, \\infty)\\) Explodes when \\(\\bar y - y_i \\approx 0\\)Division by 0 error when \\(\\bar y - y_i \\approx 0\\) WMAPE(Weighted Mean Absolute Percentage Error) \\(\\dfrac{ \\sum \\vert  u_i \\vert  }{\\sum \\vert  y_i  \\vert}\\)\\(= \\dfrac{\\text{MAE} }{ \\text{mean}(\\vert y \\vert)}\\) \\(\\downarrow\\) % \\([0, \\infty)\\) Avoids the  limitations of MAPE Not as easy to interpret MALE \\(\\vert \\ \\log_{1p} \\vert \\hat y_i \\vert - \\log_{1p} \\vert y_i \\vert \\ \\vert\\) Median?? MSLE(Log Error) \\((\\log_{1p} \\vert \\hat y_i \\vert - \\log_{1p} \\vert y_i \\vert)^2\\) Geometric Mean \\(\\downarrow\\) Unit of \\(y^2\\) \\([0, \\infty)\\) Equivalent of log-transformation before fitting - Robust to outliers- Robust to skewness in response distribution- Linearizes relationship - Penalizes under-prediction more than over-prediction- Penalizes large errors very little, even lesser than  MAE (still larger than small errors, but weight penalty inc very little with error)- Less interpretability RAE(Relative Absolute Error) \\(\\dfrac{\\sum \\vert  u_i \\vert}{\\sum \\vert y_\\text{naive} - y_i  \\vert}\\) \\(\\downarrow\\) % \\([0, \\infty)\\) Scaled MAE RSE(Relative Square Error) \\(\\dfrac{\\sum  (u_i)^2 }{\\sum (y_\\text{naive} - y_i)^2 }\\) \\(\\downarrow\\) % \\([0, \\infty)\\) Scaled MSE Peer Loss \\({\\mathcal L}(\\hat y_i \\vert x_i, y_i) - L \\Big(y_{\\text{rand}_j} \\vert x_i, y_{\\text{rand}_j} \\Big)\\)\\({\\mathcal L}(\\hat y_i \\vert x_i, y_i) - L \\Big(\\hat y_j \\vert x_k, y_j \\Big)\\)Compare loss of actual prediction with predicting a random value Actual information gain Penalize overfitting to noise Winkler score \\(W_{p, t}\\) \\(\\dfrac{Q_{\\alpha/2, t} + Q_{1-\\alpha/2, t}}{\\alpha}\\) \\(\\downarrow\\) CRPS(Continuous Ranked Probability Scores) \\(\\overline Q_{p, t}, \\forall p\\) \\(\\downarrow\\) CRPS_SS(Skill Scores) \\(\\dfrac{\\text{CRPS}_\\text{Naive} - \\text{CRPS}_\\text{Method}}{\\text{CRPS}_\\text{Naive}}\\) \\(\\downarrow\\)"},{"location":"CS_Electives/Machine_Learning/08_Cost/#outlier-sensitivity","title":"Outlier Sensitivity","text":"<p>Robust estimators are only robust to non-influential outliers; if outliers have sufficient influence, it is unavoidable</p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#advanced-loss","title":"Advanced Loss","text":"\\[ {\\mathcal L}(u, \\alpha, c) = \\frac{\\vert \\alpha - 2 \\vert}{\\alpha} \\times \\left[ \\left( \\dfrac{(u/c)^2}{\\vert \\alpha - 2 \\vert} + 1 \\right)^{\\alpha/2} -1 \\right] \\] <p>If you don\u2019t want to optimize for \\(c\\), default \\(c=1\\)</p> <p></p> <p></p> <ul> <li>Monotonic wrt \\(\\vert u \\vert\\) and \\(\\alpha\\): useful for graduated non-convexity</li> <li>Smooth wrt \\(u\\) and \\(\\alpha\\)</li> <li>Bounded first and second derivatives: no exploding gradients, easy preconditioning</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#adaptive-loss","title":"Adaptive Loss","text":"<p>No hyper-parameter tuning!, as \\(\\alpha\\) is optimized for its most optimal value as well</p> <p>If the selection of \\(\\alpha\\) wants to discount the loss for outliers, it needs to increase the loss for inliers</p> \\[ \\begin{aligned} \\text{L}' &amp;= -\\log P(u \\vert \\alpha) \\\\ &amp;= {\\mathcal L}(u, \\alpha) + \\log Z(\\alpha) \\end{aligned} \\] <p></p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#classification-loss","title":"Classification Loss","text":"<p>Should be tuned to control which type of error we want to minimize</p> <ul> <li>overall error rate</li> <li>false positive rate (FPR)</li> <li>false negative rate (FNR)</li> </ul> <p>Imbalanced dataset: Re-weight loss function to ensure equal weightage for each target class</p> <ul> <li>Sample weight matching the probability of each class in the population data-generating distribution</li> <li> <p>For eg \\(\\sum_{i} w_{ic} = \\text{same}, \\forall c\\)</p> <ul> <li>\\(w_i = 1-f_c = 1-\\dfrac{n_c}{n}\\), where \\(n_i=\\) no of observations of class \\(c\\)</li> </ul> </li> <li> <p>Modify loss function</p> </li> <li>Under-sampling</li> </ul> Metric Formula Range Preferred Value Expected Initial Value Meaning Advantages Disadvantages Indicator/Zero-One/Misclassification \\(\\begin{cases} 0, &amp; \\hat y = y \\\\ 1, &amp; \\text{o.w} \\end{cases}\\) \\([0, 1]\\) \\(0\\) Produces a Bayes classifier that maximizes the posterior probability Easy to interpret Treats all error types equallyMinimizing is np-hardNot differentiable Modified Indicator \\(\\begin{cases} 0, &amp; \\hat y = y \\\\ a, &amp; \\text{FP} \\\\ b, &amp; \\text{FN} \\end{cases}\\) \\(0\\) Control on type of error to min Harder to interpret Smooth F1 Instead of accepting 0/1 integer predictions, let's accept probabilities instead. Thus if the ground truth is 1 and the model prediction is 0.4, we calculate it as 0.4 true positive and 0.6 false negative. If the ground truth is 0 and the model prediction is 0.4, we calculate it as 0.6 true negative and 0.4 false positive. CrossEntropy/Log Loss/Negative Log Likelihood/Softmax \\(-\\ln L\\)\\(L = \\left( \\dfrac{\\exp(\\hat p_i)}{\\sum_{c=1}^C \\exp(\\hat p_c)} \\right)\\), where \\(i=\\) correct class\\(- \\hat p_i + \\ln \\sum_{c=1}^C \\exp(\\hat p_c)\\)Logistic Regression (Binary CE)\\(-\\log \\Big(\\sigma(-\\hat y \\cdot y_i) \\Big) = \\log(1 + e^{-\\hat y \\cdot y_i})\\)\\(y, \\hat y \\in \\{-1, 1 \\}\\) \\([0, \\infty]\\) \\(\\downarrow\\) \\(- \\ln \\vert 1/C \\vert\\)\\(C=\\) no of classes Minimizing gives us \\(p=q\\) for \\(n&gt;&gt;0\\) (Proven using Lagrange Multiplier Problem)Information Gain \\(\\propto \\dfrac{1}{\\text{Entropy}}\\)Entropy: How much information gain we have Focal Loss \\(\\alpha (1-L)^\\gamma \\times -\\ln(L)\\)\\(\\alpha (1-p_t)^\\gamma \\times \\text{CE}\\)\\(L = \\exp(-\\text{CE}) =\\) likelihood \\([0, \\infty]\\) \\(0\\) Weighted CE Useful for imbalanced datasets For optimal, hyperparameters, domain-knowledge or tuning required Random Idea \\(-\\ln \\left( \\dfrac{\\hat p_i - m}{\\sum_{c=1}^C (\\hat p_c - m)} \\right)\\), where \\(i=\\) correct class\\(m = \\arg \\min (\\hat p_c)\\)Will this give the same properties as CE, without the expensive \\(\\exp\\) operation Gini Index \\(\\sum\\limits_c^C p_c (1 - \\hat p_c)\\) Hinge \\(\\max \\{ 0, 1 - y_i \\hat y_i \\}\\)\\(y \\in \\{ -1, 1 \\}\\)\\(\\begin{cases} 0, &amp; \\hat y = y \\\\ \\sum_{j \\ne y_i} \\max (0, s_j - s_{y_i} + 1), &amp; \\text{o.w} \\end{cases}\\) (multi-class) \\([0, \\infty)\\) \\(0\\) \\(C-1\\)\\(C=\\) no of classes Equivalent to \\(L_1\\) loss but only for predicting wrong classMaximize margin - Insensitive to outliers: Penalizes errors \u201cthat matter\u201d - Loss is non-differentiable at point- Does not have probabilistic interpretation- Solution not unique; need to use L2 regularization Exponential \\(\\exp (-\\hat y \\cdot y)\\)\\(y \\in \\{ -1, 1 \\}\\) Basic \\(e^{\\text{Cross Entropy}}\\) Sensitive to outliers KL (Kullback-Leibler) Divergence/Relative entropy/Cross Entropy - Entropy \\(H(p, q) - H(p)\\)\\(-\\sum_{c=1}^C p(y=c \\vert x) \\log q(y=c \\vert x)\\) Symmetric cross entropy \\(H(p, q) + H(p, q)\\)\\(-\\sum_{c=1}^C p(y=c \\vert x) \\log q(y=c \\vert x) + -\\sum_{c=1}^C q(y=c \\vert x) \\log p(y=c \\vert x)\\) <p></p> <p>Example for \\(y = 1\\)</p> <p></p> <p></p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#clustering-loss","title":"Clustering Loss","text":"\\[ {\\mathcal L}(\\theta) = D\\Big( x_i, \\text{centroid}(\\hat y_i) \\Big) \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#proximity-measures","title":"Proximity Measures","text":"<ul> <li>Similarity</li> <li>Dissimilarity</li> <li>Distance measure (subclass)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#range","title":"Range","text":"<p>May be</p> <ul> <li>\\([0, 1], [0, 10], [0, 100]\\)</li> <li>\\([0, \\infty)\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#types-of-proximity-measures","title":"Types of Proximity Measures","text":""},{"location":"CS_Electives/Machine_Learning/08_Cost/#similarity","title":"Similarity","text":"<p>For document, sparse data</p> <ul> <li>Jacard Similarity</li> <li>Cosine Similarity</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#dissimilarity","title":"Dissimilarity","text":"<p>For continuous data</p> <ul> <li>Correlation</li> <li>Euclidean</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#idk","title":"IDK","text":"Attribute Type Dissimilarity Similarity Nominal \\(\\begin{cases} 0, &amp; p=q \\\\1, &amp;p \\ne q \\end{cases}\\) \\(\\begin{cases} 1, &amp; p=q \\\\ 0, &amp;p \\ne q \\end{cases}\\) Ordinal \\(\\dfrac{\\vert  p-q \\vert}{n-1}\\)Values mapped to integers: \\([0, n-1]\\), where \\(n\\) is the no of values \\(1- \\dfrac{\\vert  p-q  \\vert}{n-1}\\) Interval/Ratio \\(\\vert p-q \\vert\\) \\(-d\\) \\(\\dfrac{1}{1+d}\\) \\(1 - \\dfrac{d-d_\\text{min}}{d_\\text{max}-d_\\text{min}}\\)"},{"location":"CS_Electives/Machine_Learning/08_Cost/#dissimilarity-matrix","title":"Dissimilarity Matrix","text":"<p>Symmetric \\(n \\times n\\) matrix, which stores a collection of dissimilarities for all pairs of \\(n\\) objects</p> <ul> <li>\\(d(2, 1) = d(1, 2)\\)</li> </ul> <p>It gives the distance from every object to every other object</p> <p>Something</p> <p>Example</p> ObjectIdentifier Test 1 Tets 2 Test 3 <p>Compute for test 2</p> 1 2 3 4 1 2 3 4"},{"location":"CS_Electives/Machine_Learning/08_Cost/#distance-between-data-objects","title":"Distance between data objects","text":""},{"location":"CS_Electives/Machine_Learning/08_Cost/#minkowskis-distance","title":"Minkowski\u2019s distance","text":"<p>Let</p> <ul> <li>\\(a, b\\) be data objects</li> <li>\\(n\\) be no of attributes</li> <li>\\(r\\) be parameter</li> </ul> <p>The distance between \\(x,y\\) is</p> \\[ d(a, b) = \\left( \\sum_{k=1}^n \\vert  a_k - b_k  \\vert^r \\right)^{\\frac{1}{r}} \\] \\(r\\) Type of Distance \\(d(x, y)\\) Gives Magnitude of Distance Remarks 1 City blockManhattanTaxicab\\(L_1\\) Norm \\(\\sum_{k=1}^n \\vert  a_k - b_k  \\vert\\) Distance along axes Maximum 2 Euclidean\\(L_2\\) Norm \\(\\sqrt{ \\sum_{k=1}^n \\vert  a_k - b_k  \\vert^2 }\\) Perpendicular Distance Shortest We need to standardize the data first \\(\\infty\\) ChebychevSupremum\\(L_{\\max}\\) norm\\(L_\\infty\\) norm \\(\\max (\\vert  x_k - y_k  \\vert )\\) Medium Makowski <p>Also, we have squared euclidean distance, which is used sometimes</p> \\[ d(x, y) = \\sum_{k=1}^n |a_k - b_k|^2 \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#properties-of-distance-metrics","title":"Properties of Distance Metrics","text":"Property Meaning Non-negativity \\(d(a, b) = 0\\) Symmetry \\(d(a, b) = d(b, a)\\) Triangular inequality \\(d(a, c) \\le d(a, b) + d(b, c)\\)"},{"location":"CS_Electives/Machine_Learning/08_Cost/#similarity-between-binary-vector","title":"Similarity between Binary Vector","text":"<p>\\(M_{00}\\) shows how often do they come together; \\(p, q\\) do not have 11 in the same attribute</p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#simple-matching-coefficient","title":"Simple Matching Coefficient","text":"\\[ \\text{SMC}(p, q) = \\frac{ M_{00} + M_{11} (\\text{Total no of matches}) }{ \\text{Number of attributes} } \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#jaccard-coefficient","title":"Jaccard Coefficient","text":"<p>We ignore the similarities of \\(M_{00}\\)</p> \\[ \\text{JC}(p, q) = \\frac{M_{11}}{M_{11} + M_{01} + M_{10}} \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#similarity-between-document-vectors","title":"Similarity between Document Vectors","text":""},{"location":"CS_Electives/Machine_Learning/08_Cost/#cosine-similarity","title":"Cosine Similarity","text":"\\[ \\begin{aligned} \\cos(x, y) &amp;= \\frac{ xy }{ \\vert  x \\vert  \\ \\ \\vert  y  \\vert  } \\sum_{i=1}^n x_i y_i \\\\ &amp;= x \\cdot y \\\\ \\vert  x  \\vert &amp;= \\sqrt{\\sum_{i=1}^n x_i^2} \\end{aligned}  \\] \\(\\cos (x, y)\\) Interpretation 1 Similarity 0 No similarity/Dissimilarity -1 Dissimilarity"},{"location":"CS_Electives/Machine_Learning/08_Cost/#document-vector","title":"Document Vector","text":"<p>Frequency of occurance of each term</p> \\[ \\cos(d_1, d_2) = \\frac{d_1 d_2}{ ||d_1|| \\ \\ ||d_2|| } \\sum_{i=1}^n d_1 d_2 \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#tanimatto-coefficientextended-jaccard-coefficient","title":"Tanimatto Coefficient/Extended Jaccard Coefficient","text":"\\[ T(p, q) = \\frac{ pq }{ ||p||^2 + ||q||^2 - pq } \\]"},{"location":"CS_Electives/Machine_Learning/08_Cost/#ranking-loss","title":"Ranking Loss","text":"NTCGNormalized Discounted Cumulative Gain Compares rankings to an ideal order where all relevant items are at the top of the list"},{"location":"CS_Electives/Machine_Learning/08_Cost/#costs-functions-mathcal-jtheta","title":"Costs Functions \\({\\mathcal J}(\\theta)\\)","text":"<p>Aggregated penalty for entire dataset (mean, median) which is calculated once for each epoch, which includes loss function and/or regularization</p> <p>This is the objective function on for our model to minimize $$ {\\mathcal J}(\\hat y, y) = f(  {\\mathcal L}(\\hat y, y)  ) $$ where \\(f=\\) summary statistic such as mean, etc</p> <p>You can optimize</p> <ul> <li>location: mean, median, etc</li> <li>scale: variance, MAD, IQR, etc</li> <li>Combination of both</li> </ul> <p>For eg:</p> <ul> <li>Mean(SE) = MSE, ie Mean Squared Error</li> <li>\\(\\text{RMSE} = \\sqrt{\\text{MSE}}\\)</li> <li>Normalized RMSE; not intuitive for multiple groups/hierarchies/SKUs<ul> <li>\\(\\dfrac{\\text{RMSE}}{\\bar y}\\)</li> <li>\\(\\dfrac{\\text{RMSE}}{\\sigma^2(y)}\\)</li> </ul> </li> <li>Mean Squared Bias \\(= \\dfrac{1}{n} \\left( \\sum\\limits_{u_i &gt; 0} u_i^2 - \\sum\\limits_{u_i &lt; 0} u_i^2 \\right)\\)</li> </ul> <p>A good regression cost - \\(\\text{MAE} + \\vert \\text{MBE} \\vert\\) - \\(\\text{MedAE} + \\vert \\text{MedBE} \\vert\\)</p>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#bessels-correction","title":"Bessel\u2019s Correction","text":"<p>Penalize number of predictors $$ \\begin{aligned} \\text{Cost}\\text{corrected} &amp;= \\text{Cost}\\text{corrected} \\times \\dfrac{n}{\\text{DOF}} \\ \\text{DOF} &amp;= n-k-e \\end{aligned} $$</p> <ul> <li>where</li> <li>\\(n=\\) no of samples</li> <li>\\(k=\\) no of parameters</li> <li> <p>\\(e=\\) no of intermediate estimates (such as \\(\\bar x\\) for variance)</p> </li> <li> <p>Modify accordingly for squares/root metrics</p> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#robustness-to-outliers","title":"Robustness to Outliers","text":"<ul> <li>Median: Very robust, but very low efficiency</li> <li>Trimmed Mean: Does not work well for small sample sizes</li> <li>MAD</li> <li>IQR</li> </ul>"},{"location":"CS_Electives/Machine_Learning/08_Cost/#idk_1","title":"IDK","text":"<ul> <li>Classification<ul> <li>The proportion of target groups should be balanced<ul> <li>If not,<ul> <li>Batch training<ul> <li>use weighted loss</li> </ul> </li> <li>Mini-batch training<ul> <li>Balanced mini batch training</li> <li>Weighed sampling for batch</li> <li>Weight loss within each batch</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li>Any<ul> <li>The proportion of input groups/hierarchies should be balanced.<ul> <li>If not, use hierarchical models to optimize the loss for each group/hierarchy</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/09_Optimization/","title":"Optimization","text":"<p>Refer to Optimization Algorithms</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/","title":"Generalization","text":"<p>The ability of trained model to be able to perform well on unseen data. Better validation result \\(\\implies\\) Better generalization</p> <p>The generalization gap (error difference b/w seen and unseen data) should be small</p> <p>The more models you try, the worse your generalization wrt that data due to increase in \\(\\vert H \\vert\\) as \\(H = \\bigcup_i H_i\\) where \\(H_i\\) is the \\(H\\) for each model. This is the essence behind importance of train-dev-val-test split</p> <p>Note: Always try to overfit with a very small sample and then focus on generalization</p> \\[ E_\\text{out} \\le E_\\text{in} + \\dfrac{\\Omega}{n} \\] <p>where</p> <ul> <li>\\(\\Omega =\\) Overfit/Complexity Penalty</li> </ul> <p>Lesson: Match the \u2018model complexity\u2019 to the data resources, not to the target complexity, ie, pick a hypothesis set that you can afford to navigate for the given training dataset</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#noise","title":"Noise","text":"<p>Part of \\(y\\) we cannot model</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#types","title":"Types","text":"Stochastic/Bayes\u2019 Error Deterministic Given by \\(u\\) \\(f^* - f\\) Meaning Observational error Part of \\(f\\) that \\(H\\) cannot capture, even when there is no stochastic noise Cause \\(P(y \\vert x)\\) 1. Complexity of \\(f\\)2. \\(H\\) Frequency High Low Smooth \u274c \u2705 For a given \\(x\\) Randomly distributed Fixed constant Comment No point trying to capture it, as you will learn a false pattern, given limited training dataset When teaching a kid, better to use easy-to-understand examples rather than the actual science Effect on overfitting <ul> <li>For a finite \\(n\\), \\(H\\) tends to fit both stochastic and deterministic noise</li> <li>Deterministic and Stochastic noise affect the Variance by making the model more susceptible to overfitting</li> <li>In presence of stochastic and/or deterministic noise, it is better to prefer smoother/simpler hypotheses, so that the model can avoid fitting the noise</li> <li> <p>For time-series modelling, we can use averaging/smoothing filter a pre-processing step</p> </li> <li> <p>For target \\(f\\) of high complexity, train model \\(\\hat f\\) with smooth \\(\\tilde y\\) (for eg: Moving Average) to reduce effect of deterministic noise</p> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#error-decomposition","title":"Error Decomposition","text":"Bias Variance\\(\\text{Var}(\\hat f)\\) Distribution Mismatch Indicates Inaccuracy Imprecision Data Sampling Issue Meaning Proximity of prediction is to true values Amount by which \\(\\hat y\\) would change for different training data Implication Underfitting Overfitting Denotation \\(\\hat f-f\\) \\(E \\Big[ \\ (\\hat f - f^*)^2 \\ \\Big]\\) Estimated through Train Error - Acceptable Error Dev error - Train Error Validation Error - Dev Error Reason for estimation In-sample performance Difference between in-sample and out-sample performance \\[ \\text{E}_\\text{out} = \\text{Bias}^2 + \\text{Variance} + \\text{Dist Mis} + \\text{DN} + \\text{SN} \\]"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#prediction-bias-variance","title":"Prediction Bias &amp; Variance","text":"<p>We want low value of both</p> <p>If a measurement is biased, the estimate will include a constant systematic error</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#bias-variance-tradeoff","title":"Bias-Variance Tradeoff","text":"<p>Usually U-Shaped</p> <p></p> <p>Each additional parameter adds the same amount of variance \\(\\sigma^2/n\\), regardless of whether its true coefficient is large or small (or zero).</p> <p>$$ \\begin{aligned} \\text{Variance} &amp;= \\sigma^2 \\left[ \\dfrac{1+k}{n} + 1 \\right] \\ &amp; \\approx O(k) \\end{aligned} $$ Hence, we can reduce variance by shrinking small coefficients to zero</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#tip","title":"Tip","text":"<p>When using feature selection/LASSO regularization, stop one standard deviation &gt; the optimal point, as even though bias has increased by a small amount, variance can be decreased a lot</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#vc-analysis","title":"VC Analysis","text":"<p>Let</p> <ul> <li>\\(E_\\text{in} =\\) error on seen train data</li> <li>\\(E_\\text{test} =\\) error on unseen test data</li> <li>\\(E_\\text{out} =\\) theoretical error on the unseen population</li> <li>\\(\\vert h \\vert =\\) size of hypothesis, estimated through the number of Dichotomies</li> <li>\\(\\vert H \\vert =\\) size of hypothesis set, estimated through the number of Dichotomies</li> </ul> <p>For test data, \\(\\vert H \\vert = 1\\), as it is not biased and we do not choose a hypothesis that looks good on it.</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#pictorial-representation","title":"Pictorial Representation","text":""},{"location":"CS_Electives/Machine_Learning/10_Generalization/#idk","title":"IDK","text":""},{"location":"CS_Electives/Machine_Learning/10_Generalization/#dichotomies","title":"Dichotomies","text":"<p>Prediction of hypothesis on data</p> <p>No of dichotomies \\(\\le 2^n\\)</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#growth-function","title":"Growth Function","text":"<p>counts the most dichotomies on \\(n\\) points $$ \\begin{aligned} m_H(n) &amp;= \\max_{x_i} \\vert H(x_i) \\vert \\qquad \\forall i \\in [1, n] \\ \\implies m_H(n) &amp;\\le 2^n \\end{aligned} $$ The hypothesis set is said to \u201cshatter\u201d \\(n\\) points</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#break-point","title":"Break Point","text":"<p>If no dataset of size \\(n_b\\) can be shattered by \\(H\\), then \\(n_k\\) is a break point for \\(H\\), ie Point at which you fail to get all possible dichotomies. This also implies that dataset of \\(n &gt; n_k\\) cannot be shattered as well $$ m_H(k) = 2^k $$</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#vc-dimension","title":"VC Dimension","text":"<p>\\(d_\\text{VC}(H)\\) is the most points \\(H\\) can shatter</p> <p>\\(d_\\text{VC}(H)\\) measures the effective number of parameters $$ \\begin{aligned} d_\\text{VC}(H) &amp;= \\arg \\max_n m_H(n) = 2^n \\ &amp;= n_b-1 \\end{aligned} $$</p> \\[ \\begin{aligned} d_\\text{vc} (H) &amp;= \\sum_i d_\\text{vc} (h_i) \\end{aligned} \\] <p>Independent of</p> <ul> <li>Learning algorithm</li> <li>Input distribution</li> <li>Target function</li> </ul> <p>Dependent on</p> <ul> <li>Final hypothesis \\(\\hat f\\)</li> <li>Training examples</li> <li>Hypothesis set</li> </ul> <p>\\(d_\\text{VC}(H)\\) is finite \\(\\implies\\) \\(\\hat f \\in H\\) will generalize</p> <p>Usually, \\(d_\\text{VC} \\le\\) no of parameters in the model </p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#sauers-lemma","title":"Sauer\u2019s Lemma","text":"\\[ \\begin{aligned} d_\\text{vc} (H) &lt; \\infty  \\implies m_H(n) \\le \\sum_{r=0}^{d_\\text{vc}(H)} nCr \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#conclusion","title":"Conclusion","text":"\\(m_H(n)\\) No break point \\(2^n\\) Any breakpoint \\(\\sum_{r=0}^{d_\\text{VC}(H)} n C_r\\)Polynomial in \\(n\\)"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#hoeffdings-inequality","title":"Hoeffding\u2019s Inequality","text":"\\[ \\begin{aligned} P( \\vert E_\\text{out} - E_\\text{test} \\vert &gt; \\epsilon) &amp; \\le \\sum_{i=1}^{\\vert H \\vert} P( \\vert E_\\text{out}(h_i) - E_\\text{in}(h_i) \\vert &gt; \\epsilon) \\\\ &amp; \\le {\\vert H \\vert} \\cdot 2 \\exp(-2 n \\epsilon^2) \\end{aligned} \\] <p>But this is a very loose bound (better to loose, than incorrectly tight), as we assume that each hypothesis is disjoint</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#vapnik-chervonenkis-inequality","title":"Vapnik-Chervonenkis Inequality","text":"\\[ \\begin{aligned} P( \\vert E_\\text{out} - E_\\text{test} \\vert &gt; \\epsilon) &amp; \\le {\\textcolor{hotpink}{2} \\cdot m_H(\\textcolor{hotpink}{2}n)} \\cdot \\exp \\left( -2 n \\left( \\dfrac{\\epsilon}{\\textcolor{hotpink}{4}} \\right)^2 \\right) \\\\ &amp; \\le \\underbrace{4 \\cdot m_H(2n) \\cdot \\exp \\left( \\frac{-1}{8} n \\epsilon^2 \\right)}_\\delta \\end{aligned} \\] <p>\\(\\delta\\) is like the significance level</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#why-difference-from-hoeffdings","title":"Why difference from Hoeffding\u2019s?","text":"<p>Empirical observation: The bounded quantity has the same monotonicity as the bound</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#generalization_1","title":"Generalization","text":"\\[ \\begin{aligned} \\epsilon &amp;= \\underbrace{\\sqrt{ \\dfrac{8}{n} \\ln \\left \\vert \\dfrac{4m_H(2n)}{\\delta} \\right \\vert }}_\\Omega  \\\\ &amp; = O \\left( \\sqrt{\\dfrac{d_{vc} \\ln n + \\ln \\vert 1/\\delta \\vert }{n}} \\right) \\\\ &amp; = O \\left( \\sqrt{d_{vc} \\dfrac{ \\ln \\vert n \\vert }{n}} \\right) \\end{aligned} \\] \\[ \\text{with prob} \\ge 1-\\delta, \\quad \\vert E_\\text{out} - E_\\text{in} \\vert \\le \\Omega(n, H, \\delta) \\]"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#recommend-test-size","title":"Recommend Test Size","text":"<p>Rule of thumb to get good generalization $$ n_\\text{test} \\ge 10 \\times d_\\text{VC}(H) $$</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#curse-of-dimensionality","title":"Curse of Dimensionality","text":"<p>When \\(k\\) is very large, then the \\(\\vert H \\vert\\) gets very large and hence, generalization becomes very poor</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#training-size","title":"Training Size","text":"<p>Generalization improves with size of training set, until a saturation point, after which it stops improving.</p> More data \\(\\implies\\) Parametric asymptote to an error value exceeding Bayes error Non-Parametric better generalization until best possible error is achieved"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#generalization-bound-vs-generalization-gap","title":"Generalization Bound vs Generalization Gap","text":"Generalization Gap Generalization Bound Associated with Model- Bias- Variance Testing method- Test Set Size- No of trials"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#linear-regression","title":"Linear Regression","text":"<p>Consider true \\(f = \\text{Linear} + u; \\quad u \\sim N(0, \\sigma^2_u)\\)</p> <ul> <li>Best approximation error \\(= \\sigma^2_u\\)</li> <li>Expected in-sample error \\(= \\sigma^2_u \\left[1- \\dfrac{k}{n} \\right]\\)</li> <li>Expected out-sample error \\(= \\sigma^2_u \\left[ 1 + \\dfrac{k}{n} \\right]\\)</li> <li>Expected generalization gap \\(= 2 \\sigma^2_u \\left( \\dfrac{k}{n} \\right)\\)</li> </ul> <p></p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#vc-vs-bias-variance","title":"VC vs Bias-Variance","text":""},{"location":"CS_Electives/Machine_Learning/10_Generalization/#scenarios","title":"Scenarios","text":"Scenarios Conclusion Desired Error &lt; Train Error Underfitting/Optimal Train Error \\(\\approx\\) Test Error \\(\\approx\\) Desired ErrorTrain Error &lt; Test Error &lt; Desired Error Optimal Train Error &lt;&lt; Test ErrorTrain Error &lt; Desired Error &lt; Test Error Overfitting"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#fitting-capacity","title":"Fitting &amp; Capacity","text":"<p>We can control the fitting of a model, by changing hypothesis space, and hence changing its capacity</p> Underfitting Appropriate-Fitting Overfitting Capacity Low Appropriate Low Low Bias(Fitting Signal) \u274c \u2705 \u2705 Low Variance(Avoiding Noise) \u2705 \u2705 \u274c Implication Acceptable Optimal Harmful Steps toaddress Increase model complexityIncrease training dataRemove noise from dataInc no of features Cross-ValidationMore training dataFeature ReductionEarly StoppingRegularization Causes - Small train set- Stochastic noise- Deterministic noise- Excessive model capacity <p></p> <p>The capacity of a model increases with increased degree of polynomial</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#interesting-note","title":"Interesting Note","text":"<p>Even if the target function is known to be of high complexity, for a small training dataset, a low capacity model will generalize better.</p> <p></p> <p></p> <p></p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>Harder to quantify than for supervised learning</p> <p>If model is probabilistic, we can detect overfitting by comparing in-sample and out-sample log-likelihood</p> <p>Detecting overfitting with larger datasets will be paradoxically harder</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#clustering","title":"Clustering","text":"<p>Overfitting: Fitting small, local clusters rather than the true global clusters</p>"},{"location":"CS_Electives/Machine_Learning/10_Generalization/#non-probabilistic","title":"Non-Probabilistic","text":""},{"location":"CS_Electives/Machine_Learning/10_Generalization/#probabilistic-models","title":"Probabilistic Models","text":"<p>Log likelihood on in-sample and out-sample data</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/","title":"Data Splitting","text":""},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#train-test","title":"Train-Test","text":"<p>The training set has an optimistic bias, since it is used to choose a hypothesis that looks good on it. Hence, we require a unseen set as it is not biased</p> <p>Once a data set has been used in the learning/validation process, it is \u201ccontaminated\u201d \u2013 it obtains an optimistic (deceptive) bias, and the error calculated on the data set no longer has the tight generalization bound.</p> <p>To simulate deployment, any data used for evaluation should be treated as if it does not exist at the time of modelling</p>"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#data-split-sets","title":"Data Split Sets","text":"Train DevelopmentEyeball DevelopmentBlack Box ValidationInner ValidationOuter Test(Holdout) Recommend split % 20 5 5 20 20 20 EDA('Seen' by analyst) \u2705 \u274c \u274c \u274c \u274c \u274c In-Sample('Seen' by model) \u2705 \u274c \u274c \u274c \u274c \u274c Pre-Processing 'learning'(Normalization, Standardization, \u2026) \u2705 \u274c \u274c \u274c \u274c \u274c Feature Selection \u2705 \u274c \u274c \u274c \u274c \u274c Causal Discovery \u2705 \u274c \u274c \u274c \u274c \u274c Feature Engineering 'learning' \u2705 \u274c \u274c \u274c \u274c \u274c Error Analysis(Inspection) \u2705 \u2705 \u274c \u274c \u274c \u274c Model Tuning \u2705 \u2705 \u274c \u274c \u274c \u274c Underfit Evaluation \u2705 \u2705 \u274c \u274c \u274c \u274c Overfit Evaluation \u274c \ud83d\udfe1 \u2705 \u274c \u274c \u274c Hyperparameter Tuning \u274c \u274c \u274c \u2705 \u274c \u274c Model Selection \u274c \u274c \u274c \u274c \u2705 \u274c Model Evaluation(Performance Reporting) \u274c \u274c \u274c \u274c \u274c \u2705 \\(\\hat f\\) \\({\\hat f}_\\text{in}\\) \\({\\hat f}_{\\text{dev}_e}\\) \\({\\hat f}_{\\text{dev}_b}\\) \\({\\hat f}_{\\text{val}_i}\\) \\({\\hat f}_{\\text{val}_o}\\) \\({\\hat f}_\\text{test}\\) \\(\\hat f\\) trained on Train Train Until dev_e Until dev_b Until val_i Until val_o \\(E\\) \\(E_\\text{in}\\) \\(E_{\\text{dev}_e}\\) \\(E_{\\text{dev}_b}\\) \\(E_{\\text{val}_i}\\) \\(E_{\\text{val}_o}\\) \\(E_\\text{test}\\) Error Names Training error/In-Sample Error/Empirical Error/Empirical Risk Eyeball Development Error Black Box Development Error Validation Error \\(\\hat E_\\text{out}\\)Expected errorPrediction errorRisk No of \\(\\hat f\\) Any Any Any Any Low(Usually &lt; 10?) \\(1\\) \\({\\vert H \\vert}_\\text{set}\\) \\(\\infty\\) \\(\\infty\\) \\(d_\\text{vc}\\) \\({\\vert H \\vert}_{\\text{val}_i}\\) \\({\\vert H \\vert}_{\\text{val}_o}\\) \\(1\\) Comment Used for \u201ctraining\u201d on \u201cfinalist\u201d set of hypotheses Should not be used for any model decision making Color Scheme Below Green Green Green Yellow Orange Red <p>\"\\(\\hat f\\) trained on\" implies that data should be split amongst to be used for - 60: Model fitting - 20: Model confidence interval generation (if required), else use this also for model fitting - 20: Model calibration     - Confidence interval calibration     - Classification proportion calibration</p> \\[ \\begin{aligned} \\mathbb{E}[E_\\text{test}] &amp;= E_\\text{out} \\\\ \\text{var}[E_\\text{test}] &amp;= \\dfrac{\\sigma^2_{u}}{n_\\text{test}} \\\\ \\end{aligned} \\] \\[ E_\\text{out} \\le E_\\text{set} + O \\left( \\sqrt{\\dfrac{\\ln {\\vert H \\vert}_\\text{set}}{n_\\text{set}}} \\right) \\]"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#test-size-tradeoff","title":"Test-Size Tradeoff","text":"\\[ E_\\text{out}(\\hat f) \\underbrace{\\approx}_\\mathclap{n^*_\\text{test} \\downarrow} E_\\text{out}(\\hat f_\\text{test}) \\underbrace{\\approx}_\\mathclap{n^*_\\text{test} \\uparrow} E_\\text{test}(\\hat f_\\text{test}) \\] Small Large Low Model Bias \u2705 \u274c Small Generalization Bound \u274c \u2705 Reliable \\(\\hat E_\\text{out}\\)\\(E_\\text{out}(\\hat f_\\text{test})-E_\\text{test}(\\hat f_\\text{test})\\) \u274c \u2705 Tested model and final model are sameSmall \\(E_\\text{out}(\\hat f) - E_\\text{out}(\\hat f_\\text{test})\\) \u2705 \u274c Extreme caseModel performance reporting \u201cwith no certainty, the model is excellent\u201d \u201cwith high certainty, the model is crap\u201d"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#usage","title":"Usage","text":"<ol> <li>Split data</li> <li>Competition<ol> <li>Create a self-hosted competition ('Kaggle' equivalent)</li> </ol> </li> <li>Overfit to single train sample</li> <li>Overfit to entire dataset<ul> <li>Beat baseline model(s)</li> </ul> </li> <li>Tune to generalize to dev set<ul> <li>Beat baseline model(s)</li> </ul> </li> <li>Tune hyperparameters on inner validation set</li> <li>Compare all models on \\(E_\\text{val}\\) on outer validation set<ul> <li>Must beat baseline model(s)</li> </ul> </li> <li>Select best model \\(\\hat f_{\\text{val}_o}^*\\)</li> <li>Get accuracy estimate of \\(\\hat f_\\text{val}^*\\) on test data: \\(E_\\text{test}\\)</li> </ol> <p>Single metric</p> <ul> <li>Use RMS (Root Mean Squared) of train and dev error estimate to compare models</li> <li>Harmonic mean not applicable as it gives more weight to smaller value</li> </ul> <p></p>"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#sampling-types","title":"Sampling Types","text":"<p>Repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model.</p> <p>Hence, these help address the issue of a simple validation: Results can be highly variable, depending on which observations are included in the training set and which are in the validation set</p> Bootstrapping Cross Validation Sampling w/ Replacement w/o Replacement Estimate uncertainty in model parameters \u2705 \u274c Estimate expected model evaluation metric \u2705 \u274c Estimate model stability: standard error in model evaluation metric \u2705 \u274c Model Tuning \u2705 (check if change caused statistically-significant improvement) \u2705 Hyperparameter Tuning \u2705 (check if change caused statistically-significant improvement) \u2705 Model Selection \u274c \u2705 Advantage Large repetitions of folds: No assumptions for standard error estimation Comment The resulting distribution will give the sampling distribution of the evaluation metric"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#cross-validation-types","title":"Cross Validation Types","text":"Purpose Comment Regular \\(k\\) fold Obtain uncertainty of evaluation estimates Higher \\(k\\) recommended for small datasets Leave-One-Out For very small datasets\\(n &lt; 20\\) \\(k=n\\) Shuffled Random Permutation Stratified Ensures that Train, Validation &amp; Test sets have same distribution Stratified Shuffle Grouped Grouped - Leave One Group Out Grouped with Random Permutation Walk-Forward Expanding Window Walk-Forward Rolling Window Blocking Purging Remove train obs whose labels overlap in time with test labels Purging &amp; Embargo Prevent data leakage due to serial correlation \\(x_{\\text{train}_{-1}} \\approx x_{\\text{test}_{0}}\\)\\(y_{\\text{train}_{-1}} \\approx y_{\\text{test}_{0}}\\) CPCV(Combinatorial Purged)"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#bootstrapping-types","title":"Bootstrapping Types","text":"Advantage Disadvantage Random sampling with replacement IID ARIMA Bootstrap Parametric Moving Block Bootstrap Non-parametric Circular Block Bootstrap Non-parametric Stationary Bootstrap Non-parametric Test-Set Bootstrap Only bootstrap the out-of-sample set (dev, val, test) No refitting: Great for Deep Learning Large out-of-sample size required for good bootstrapping 0.632 Bootstrap Metric = \\(\\dfrac{1}{k} \\text{Metric}_i\\)\\(\\text{Metric}_i = 0.632 \\cdot \\text{Metric}_\\text{test} + 0.368 \\cdot \\text{Metric}_\\text{train}\\) 0.632+ Bootstrap"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#validation-methods","title":"Validation Methods","text":"Type Cross-Sectional Time Series Comment Holdout \\(k\\)- Fold 1. Split dataset into \\(k\\) subsets2. Train model on \\((k-1)\\) subsets3. Evaluate performance on \\(1\\) subset4. Summary stats of all iterations Repeated \\(k\\)-Fold \u274c Repeat \\(k\\) fold with different splits and random seed Nested \\(k\\)-Fold Nested Repeated \\(k\\)-Fold \u274c <p>For - cross-sectional data     - make sure to shuffle all splits - time-series data, always add     - purging     - embargo     - step size/gap between splits         - estimates of error/loss for nearby splits will be correlated, so no point in estimating them         - larger step size \\(\\implies\\) fewer splits \\(\\implies\\) saves time         - always take step size \\(&gt;1\\), as it is pointless to have step size \\(= 1\\)</p>"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#decision-parameter-k","title":"Decision Parameter \\(k\\)","text":"<p>There is a tradeoff</p> Small \\(k\\) Large \\(k\\) Train Size Small Large Test Size Large Small Bias High Low Variance Low High <p>Usually \\(k\\) is taken</p> <ul> <li>Large dataset: 4</li> <li>Small dataset: 10</li> <li>Tiny dataset: \\(k=n\\) , ie LOOCV (Leave-One-Out CV)</li> </ul> <p></p>"},{"location":"CS_Electives/Machine_Learning/11_Data_Splitting/#data-leakage","title":"Data Leakage","text":"<p>Cases where some information from the training set has \u201cleaked\u201d into the validation/test set. Estimation of the performances is likely to be optimistic</p> <p>Due to data leakage, model trained for \\(y_t = f(x_j)\\) is more likely to be \u2018luckily\u2019 accurate, even if \\(x_j\\) is irrelevant</p> <p>Causes</p> <ul> <li>Perform feature selection using the whole dataset</li> <li>Perform dimensionality reduction using the whole dataset</li> <li>Perform parameter selection using the whole dataset</li> <li>Perform model or architecture search using the whole dataset</li> <li>Report the performance obtained on the validation set that was used to decide when to stop training (in deep learning)</li> <li>For a given patient, put some of its visits in the training set and some in the validation set</li> <li>For a given 3D medical image, put some 2D slices in the train- ing set and some in the validation set</li> </ul>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/","title":"Model Evaluation","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#goals","title":"Goals","text":"<p>Same as goals of cost minimization</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#guidelines","title":"Guidelines","text":"<ul> <li> Backtesting/model validation is not a technique to identify good models: It is a technique to stress test and fail poor models</li> <li> Always check if your model is able to learn from a synthetic dataset where you know the underlying data-generating process</li> <li> Always evaluate any step involving randomness with different random seeds to ensure accurate result<ul> <li> Group by random seed and check for discrepancies</li> </ul> </li> <li> Metrics computed from test set may not be representative of the true population</li> <li> Always look at multiple metrics; never trust a single one alone</li> <li> false positives and false negatives are seldom equivalent</li> <li> understand the problem to known the right tradeoff</li> <li> Always monitor the worst-case prediction<ul> <li> Maximum loss</li> <li> 95<sup>th</sup> percentile loss</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#baselinebenchark-models","title":"Baseline/Benchark models","text":"<p>Always establish a baseline</p> <ul> <li>Basic/Naive/Dummy predictions</li> <li>Regression<ul> <li>Mean</li> <li>Max</li> <li>Min</li> <li>Random</li> </ul> </li> <li>Classification<ul> <li>Mode</li> <li>Random</li> </ul> </li> <li>Time series specific<ul> <li>Persistence</li> <li>\\(\\hat y_{t+h} = y_t\\)</li> <li>Latest value available</li> <li>Great for short horizons</li> <li>Climatology</li> <li>\\(\\hat y_{t+h} = \\bar y_{i \\le t}\\)</li> <li>Average of all observations until present</li> <li>Great for short horizons</li> <li>Combination of Persistence and Climatology</li> <li>\\(\\hat y_{t+h} = \\beta_1 y_t + \\beta_2 \\bar y_{i \\le t}\\)</li> <li>Lag: \\(\\hat y_{t+h} = y_{t-k}\\)</li> <li>Seasonal Lag: \\(\\hat y_{t+h} = y_{t+h-m}\\)</li> <li>Moving average</li> <li>Exponential average</li> </ul> </li> <li>Human Level Performance</li> <li>Literature Review</li> <li>Performance of older system</li> </ul>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#significance","title":"Significance","text":"<p>All the evaluation should be performed relative to the baseline.</p> <p>For eg: Relative RMSE = RMSE(model)/RMSE(baseline), with \u201cgood\u201d threshold as 1</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#core-evaluation","title":"Core Evaluation","text":"<p>Mitigating bias, placing guardrails, enhancing reliability, reducing complexity, and ensuring privacy</p> Category Data Model Prediction Fairness - Resampling / Reweighting - Feature Engineering - Data Augmentation- Feature Selection  (Filter, Embedded, Wrapper) - Cost-sensitive Learning- Monotonic Constraints- Adversarial Debiasing - Regularization - Calibrating/Equalizing Odds- Prediction AbstentionFairness Model Certification Accountability - Feature Drift Detection- Data Augmentation- Adv. Preproc. Defenses- Feature Selection (Filter, Embedded, Wrapper)- Feature Engineering- Data Anonymization- Differential Privacy - Uncertainty Estimation / Conformal Prediction- Adversarial Robustness- Certified Training &amp; Inference - Adversarial Training- Regularization (plus other under fitting tuning)- Monotonic Constraints- Federated Learning- Other Adversarial Defenses (for espionage attacks) - Adv. Postprocessing Def- Calibrating/Equalizing OddsPrivacy-Preserving Inference Transparency - Feature Selection (Filter, Embedded, Wrapper)- Feature Engineering - Regularization (plus other under fitting tuning)- Model Constraints- White &amp; Glass-Box Models - Local Interpretation"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#probabilistic-evaluation","title":"Probabilistic Evaluation","text":"<p>Now, we need to see if any difference in accuracy across models/hyperparameters is statistically-significant, or just a matter of chance - Try different seeds and see the range; this range is purely due to randomness</p> <p>Summary Statistics: Don\u2019t just look at the mean evaluation metric of the multiple splits; also get the uncertainty associated with the validation process.</p> <ul> <li>It is invalid to use a standard hypothesis test (such as t-test) by taking number of folds as the sample size<ul> <li>the runs are not independent</li> <li>using folds incorrectly inflates the sample size</li> </ul> </li> <li>It is acceptable for a fixed test set</li> <li>Std obtained in model performance from cross-validation is standard error of mean estimate<ul> <li>hence, you cannot divide by no of folds</li> <li>Std obtained in model performance from cross-validation is standard error of mean estimate<ul> <li>True standard deviation is no of folds x SE</li> </ul> </li> </ul> </li> </ul> <p>Hence, treat the metrics across the folds as a a distribution - For regression: chi squared - For classification: binomial</p> <ul> <li>Standard error of accuracy estimate</li> <li>Standard deviation</li> <li>Quantiles</li> <li>PDF</li> <li>VaR</li> </ul>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#bessels-correction","title":"Bessel\u2019s Correction","text":"\\[ \\begin{aligned} \\text{Metric}_\\text{corrected} &amp;= \\text{Metric}_\\text{uncorrected} \\times \\dfrac{n}{\\text{DOF}} \\\\ \\text{DOF} &amp;= n-k-e \\end{aligned} \\] <ul> <li>where</li> <li>\\(n=\\) no of samples</li> <li>\\(k=\\) no of parameters</li> <li>\\(e=\\) no of intermediate estimates (such as \\(\\bar x\\) for variance)</li> <li>Do not perform this on metrics which are already corrected for degree of freedom (such as \\(R^2_\\text{adj}\\))</li> <li>Modify accordingly for squares/root metrics</li> </ul>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#transformed-metrics","title":"Transformed Metrics","text":"Normalization \u2060- Divide by variance?: Chi^2- \u2060Divide mean: RelMAE- Divide by MAD of benchmark: MASE- \u2060Divide coefficient of variation? Disaggregation - over &amp; under-prediction- each output class- each input group/hierarchy"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#regression-evaluation","title":"Regression Evaluation","text":"Metric Formula Unit Range Preferred Value Signifies Advantages\u2705 Disadvantages\u274c Comment Normalized Bias Normalized MAE \\(R^2\\)(Coefficient of Determination) \\(1 - \\text{RSE}\\) Unitless \\([0, 1]\\) \\(1\\) Proportion of changes in dependent var explained by regressors.Proportion of variance in \\(y\\) explained by model wrt variance explained by meanDemonstrates ___ of regressors- Relevance- Power- Importance Cannot use to compare same model on different samples, as it depends on variance of sampleSusceptible to spurious regression, as it increases automatically when increasing predictors Adjusted \\(R^2\\) \\(1 - \\left[\\dfrac{(n-1)}{(n-k-1)} (1-R^2)\\right]\\) Unitless \\([0, 1]\\) \\(1\\) Penalizes large number of predictors Accuracy \\(100 - \\text{MAPE}\\) % \\([0, 100]\\) \\(100 \\%\\) \\(\\chi^2_\\text{reduced}\\) \\(\\dfrac{\\chi^2}{n-k} = \\dfrac{1}{n-k}\\sum \\left( u_i/\\sigma_i \\right)^2\\) \\([0, \\infty]\\) \\(1\\) \\(\\approx 1:\\) Good fit\\(\\gg 1:\\) Underfit/Low variance estimate\\(\\ll 1:\\) Overfit/High variance estimate Spearman\u2019s Correlation \\(\\dfrac{ r(\\ rg( \\hat y), rg(y) \\ ) }{ \\sigma(\\ rg(\\hat y) \\ ) \\cdot \\sigma( \\ rg(y) \\ ) }\\) Unitless \\([-1, 1]\\) \\(1\\) Very robust against outliersInvariant under monotone transformations of \\(y\\) DW(Durbin-Watson Stat) \\(&gt; 2\\) Confidence of error term being random process Not appropriate when \\(k&gt;n\\) Similar to \\(t\\) or \\(z\\) valueIf \\(R^2 &gt;\\) DW Statistic, there is Spurious Regression AICAkaike Information Criterion \\(-2 \\ln L + 2k\\) \\(0\\) Leave-one-out cross validation score Penalizes predictors more heavily than \\(R_\\text{adj}^2\\) For small values of \\(n\\), selects too many predictorsNot appropriate when \\(k&gt;n\\) AIC Corrected \\(\\text{AIC} + \\dfrac{2k(k+1)}{n-k-1}\\) \\(0\\) Encourages feature selection BIC/SBIC/SC(Schwarz\u2019s Bayesian Information Criterion) \\(-2 \\ln L + k \\ln n\\) \\(0\\) Penalizes predictors more heavily than AIC HQICHannan-Quinn Information Criterion \\(-2 \\ln L + 2k \\ln \\vert \\ln n \\vert\\) \\(0\\) Calibration Sharpness <p>A good regression metric - \\(\\text{MAE} + \\vert \\text{MBE} \\vert\\), normalized by mean of series - \\(\\text{MedAE} + \\vert \\text{MedBE} \\vert\\), normalized by median of series</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#probabilistic-evaluation_1","title":"Probabilistic Evaluation","text":"<p>You can model the error such as MAE as a \\(\\chi^2\\) distribution with dof = \\(n-k\\)</p> <p>The uncertainty can be obtained from the distribution</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#spurious-regression","title":"Spurious Regression","text":"<p>Misleading statistical evidence of a relationship that does not truly exist</p> <p>Occurs when we perform regression between</p> <ul> <li>2 independent variables</li> </ul> <p>and/or</p> <ul> <li>2 non-stationary variables</li> </ul> <p>(Refer econometrics)</p> <p>You may get high \\(R^2\\) and \\(t\\) values, but \\(u_t\\) is not white noise (it is non-stationary)</p> <p>\\(\\sigma^2_u\\) becomes infinite as we go further in time</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#classification-evaluation","title":"Classification Evaluation","text":"<p>There is always a tradeoff b/w specificity and sensitivity</p> Metric Formula Preferred Value Unit Range Meaning Limitations Entropy of each classification \\(H_i = -\\sum \\hat y \\ln \\hat y\\) \\(\\downarrow\\) \\([0, \\infty)\\) Uncertainty in a single classification Mean Entropy \\(H_i = -\\sum \\hat y \\ln \\hat y\\) Uncertainty in classification of entire dataset Accuracy \\(1 - \\text{Error}\\)\\(\\dfrac{\\text{TP + TN}}{\\text{TP + FP + TN + FN}}\\) \\(\\uparrow\\) % \\([0, 100]\\) \\(\\dfrac{\\text{No of Correct Predictions}}{\\text{Total no of predictions}}\\) Error \\(\\dfrac{\\text{FP + FN}}{\\text{TP + FP + TN + FN}}\\) \\([0, 1]\\) \\(\\downarrow\\) \\(\\dfrac{\\text{Wrong Predictions}}{\\text{No of predictions}}\\) F ScoreF<sub>1</sub> ScoreF-Measure \\(\\dfrac{2}{\\dfrac{1}{\\text{Precision}} + \\dfrac{1}{\\text{Recall}}}\\) \\(\\uparrow\\) Unitless \\([0, 1]\\) Harmonic mean between precision and recallClose to lower value - Asymmetric to what is defined as +ve and -ve- Do not take into account TN Custom F1 Score \\(\\dfrac{2}{\\dfrac{1}{\\text{Precision}} + \\dfrac{1}{\\text{Recall}} + \\dfrac{1}{\\text{Specificity}} + \\dfrac{1}{\\text{NPV}} }\\) \\(\\uparrow\\) Unitless \\([0, 1]\\) ROC-AUCReceiver-Operator Characteristics-Area Under Curve Sensitivity vs (1-Specificity)= (1-FNR) vs FPR \\(\\uparrow\\) Unitless \\([0, 1]\\) AUC = Probability that algo ranks a +ve over a -veRobust to unbalanced dataset PrecisionPPV/Positive Predictive Value \\(\\dfrac{\\textcolor{hotpink}{\\text{TP}}}{\\textcolor{hotpink}{\\text{TP}} + \\text{FP}}\\) \\(\\uparrow\\) Unitless \\([0, 1]\\) Indicates how many +ve predictions were correct predictions RecallSensitivityTrue Positive Rate \\(\\dfrac{\\textcolor{hotpink}{\\text{TP}}}{\\textcolor{hotpink}{\\text{TP}} + \\text{FN}}\\) \\(\\uparrow\\) Unitless \\([0, 1]\\) Out of actual +ve values, how many were correctly predicted as +ve SpecificityTrue Negative Rate \\(\\dfrac{\\textcolor{hotpink}{\\text{TN}}}{\\textcolor{hotpink}{\\text{TN}} + \\text{FP}}\\) \\(\\uparrow\\) Unitless \\([0, 1]\\) Out of actual -ve values, how many were correctly predicted as -ve NPVNegative Predictive Value \\(\\dfrac{\\textcolor{hotpink}{\\text{TN}}}{\\textcolor{hotpink}{\\text{TN}} + \\text{FN}}\\) Unitless \\([0, 1]\\) Out of actual -ve values, how many were correctly predicted as -ve \\(F_\\beta\\) Score \\(\\dfrac{(1 + \\beta^2)}{{\\beta^2}} \\times \\dfrac{P \\times R}{P + R}\\) \\(\\uparrow\\) Unitless [0, 1] Balance between importance of precision/recall FP Rate \\(\\begin{aligned}\\alpha &amp;= \\dfrac{\\textcolor{hotpink}{\\text{FP}}}{\\textcolor{hotpink}{\\text{FP}} + \\text{TN}} \\\\ &amp;= 1 - \\text{Specificity} \\end{aligned}\\) \\(\\downarrow\\) Unitless \\([0, 1]\\) Out of the actual -ve, how many were misclassified as Positive FN Rate \\(\\begin{aligned}\\beta &amp;= \\dfrac{\\textcolor{hotpink}{\\text{FN}}}{\\textcolor{hotpink}{\\text{FN}} + \\text{TP}} \\\\ &amp;= 1 - \\text{Sensitivity} \\end{aligned}\\) \\(\\downarrow\\) Unitless \\([0, 1]\\) Out of the actual +ve, how many were misclassified as Negative Balanced Accuracy \\(\\frac{\\text{Sensitivity + Specificity}}2{}\\) Unitless MCCMathews Correlation Coefficient \\(\\dfrac{\\text{TP} \\cdot \\text{TN} - \\text{FP}\\cdot \\text{FN} }{\\sqrt{(\\text{TP}+\\text{FP})(\\text{TP}+\\text{FN})(\\text{TN}+\\text{FP})(\\text{TN}+\\text{FN})}}\\) \\(\\uparrow\\) Unitless \\([-1, 1]\\) 1 = perfect classification0 = random classification-1 = perfect misclassification Markdedness PPV + NPV - 1 Brier Score Scaled Nagelkerke\u2019s \\(R^2\\) Hosmer-Lemeshow Test Calibration: agreement b/w obs and predicted"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#graphs","title":"Graphs","text":"Graph Preferred Error Rate ROC Curve How does the classifier compare to a classifier that predicts randomly with \\(p=\\text{TPR}\\)How well model can discriminate between \\(y=0\\) and \\(y=1\\) Top-LeftAt least higher than 45deg line Calibration Graph Create bins of different predicted probabilitiesCalculate the fraction of \\(y=1\\) for each binConfidence intervals (more uncertainty for bins with fewer samples)Histogram showing fraction of samples in each bin Along 45deg line Confusion Probabilities"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#tradeoff-for-threshold","title":"Tradeoff for Threshold","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#probabilistic-evaluation_2","title":"Probabilistic Evaluation","text":"<p>For simple metrics that rely on counting successes, such as accuracy, sensitivity, PPV, NPV - the sampling distribution can be deduced from a binomial law - uncertainty via Proportion Testing</p> <ul> <li>\\(n=\\) Validation set size<ul> <li>= \\(\\sum \\limits_i^k n_\\text{fold}\\)</li> </ul> </li> <li>\\(\\hat p =\\) Average Accuracy of classifier = Estimated proportion<ul> <li>\\(= \\dfrac{1}{k} \\sum \\limits_i^k \\text{Accuracy}_\\text{fold}\\)</li> </ul> </li> </ul> <p></p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#decision-boundary","title":"Decision Boundary","text":"<p>Plot random distribution of values</p> <p>For eg:</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#confusion-matrix","title":"Confusion Matrix","text":"<p>\\(n \\times n\\) matrix, where \\(n\\) is the number of classes</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#binary-classification","title":"Binary Classification","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#multi-class-classification","title":"Multi-Class Classification","text":"<p>Confusion Matrix with respect to A</p> A B C A TP FN FN B FP TN TN C FP TN TN"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#classification-accuracy-measures","title":"Classification Accuracy Measures","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#jacquard-index","title":"Jacquard Index","text":"\\[ \\begin{aligned} J(y, \\hat y) &amp;= \\frac{|y \\cap \\hat y|}{|y \\cup \\hat y|} \\\\ &amp;= \\frac{|y \\cap \\hat y|}{|y| + |\\hat y| - |y \\cap \\hat y|} \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#multi-class-averaging","title":"Multi-Class Averaging","text":"Micro-Average All samples equally contribute to average \\(\\dfrac{1}{C}\\sum_{c=1}^C \\dfrac{\\dots}{\\dots}\\) Macro-Average All classes equally contribute to average \\(\\dfrac{\\sum_{c=1}^C \\dots}{\\sum_{c=1}^C \\dots}\\) Weighted-Average Each class\u2019 contribution to average is weighted by its size \\(\\sum_{c=1}^C \\dfrac{n_c}{n}  \\dfrac{\\dots}{\\dots}\\)"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#inspection","title":"Inspection","text":"Inspection Identify Error Analysis Systematic errors Bias-Variance Analysis General errors"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#error-analysis","title":"Error Analysis","text":"<p>Residual Inspection</p> <p>Perform all the inspection on</p> <ul> <li>train and dev data</li> <li>externally-studentized residuals, to correct for leverage</li> </ul> <p>There should be no explainable unsystematic component</p> <ul> <li>Symmetric distribution for values of error terms for a given value \\(x\\)</li> <li>Not over time/different values of \\(x\\)</li> <li>This means that</li> <li>you have used up all the possible factors</li> <li>\\(u_i\\) only contains the non-systematic component</li> </ul> Ensure Meaning Numerical Graphical Implication if violated Action if violated Random residuals - No relationship between error and independent variables- No relationship between error and predictions- If there is correlation, \\(\\exists\\) unexplained system component Normality testUnexplained components\\(r(a, b) = 0\\)\\(\\text{MI}(a, b) = 0\\)Moments\\(E(a \\vert b) = 0\\)\\(\\sigma^2(a \\vert b) = 1\\)\\(\\gamma_3(a \\vert b) = 0\\)\\(\\gamma_4(a \\vert b) \\le 3\\)\\(a \\in [u, \\vert u \\vert , u^2, \\sqrt {\\vert u \\vert}, \\log \\vert u \\vert, e^u]\\)\\(b \\in [ c, \\vert c \\vert , c^2, \\sqrt {\\vert c \\vert}, \\log \\vert c \\vert, e^c]\\)\\(c \\in [x_j, y, \\hat y]\\) Q-Q PlotHistogramParallel coordinates plot \u274c Unbiased parameters Fix model misspecification No autocorrelation - Random sequence of residuals should bounce between +ve and -ve according to a binomial distribution- Too many/few bounces may mean that sequence is not randomNo autocorrelation between \\(u_i\\) and \\(u_j\\) \\(r(u_i, u_j \\vert x_i, x_j )=0\\)Runs testDW Test Sequence Plot of \\(u_i\\) vs \\(t\\)Lag Plot of \\(u_i\\) vs \\(u_j\\) \u2705 Parameters remain unbiased\u274c MSE estimate will be lower than true residual varianceProperties of error terms in presence of \\(AR(1)\\) autocorrelation - \\(E[u_i]=0\\)- \\(\\text{var}(u_i)= \\sigma^2/(1-\\rho^2)\\)- \\(r(u_i, u_{i-p}) = \\rho^p \\text{var}(u_i) = \\rho^p \\sigma^2/(1-\\rho^2)\\) Fix model misspecificationIncorporate trendIncorporate lag (last resort)Autocorrelation analysis No effect of outliers Outlier removal/adjustment Low leverage &amp; influence of each point Data transformation Homoscedasticity(Constant variance) \\(\\sigma^2 (u_i \\vert x_i) = \\text{constant}\\) should be same \\(\\forall i\\) Weighted regression Error in input variables Total regression Correct model specification Model building Goodness of fit - MLE Percentiles- Kolmogorov Smirnov Significance in difference in residuals for models/baselines Ensure that all the models are truly different, or is the conclusion that one model is performing better than another due to chance Comparing Samples <p>More points - Parallel coordinates plot - Clustering - hdbscan - Group-wise analysis</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#why-is-this-important","title":"Why is this important?","text":"<p>For eg: Running OLS on Anscombe\u2019s quartet gives</p> <ul> <li>same curve fit for all</li> <li>Same \\(R^2\\), RMSE, standard errors for coefficients for all</li> </ul> <p>But clearly the fit is not equally optimal</p> <ol> <li>Only the first one is acceptable</li> <li>Model misspecification</li> <li>Outlier</li> <li>Leverage</li> </ol> <p></p> <p>which is shown in the residual plot</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#aggregated-inspection","title":"Aggregated Inspection","text":"<ul> <li>Aggregate the data based on metadata</li> <li>Evaluate metrics on groups</li> </ul> \\[ u_i \\vert g(x_i) \\\\ u_i \\vert g(y_i) \\] <p>where \\(g()\\) is the group, which can be \\(x_{ij}, y_i\\) or combination of these</p> <ul> <li>Image blurry/flipped/mislabelled</li> <li>Gender</li> <li>Age</li> <li>Age &amp; Gender</li> </ul> <p>Always bin by current information</p> <p>When evaluating</p> <ul> <li>Do not use true value as input (x-axis in graph) due to look-ahead-bias</li> <li>Do not bucket by true value for classification calibration plot or regression</li> </ul> <p>Either - bins from predicted y - \u2060or bins from y_train only - \u2060or bins from X</p> <p>Never use test set cuz it's information that's not seen</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#diebold-mariano-test","title":"Diebold-Mariano Test","text":"<p>Determine whether predictions of 2 models are significantly different</p> <p>Basically the same as Comparing Samples for residuals</p>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#bias-variance-analysis","title":"Bias-Variance Analysis","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#evaluation-curves","title":"Evaluation Curves","text":"<p>Related to Interpretation</p> <ul> <li>Always look at all curves with uncertainties wrt each epoch, train, hyper-parameter value.</li> <li>The uncertainty in-sample and out-sample should also be similar</li> <li>If train set metric uncertainty is small and test set metric uncertainty is large, this is bad even if the average loss metric is same</li> </ul> Learning Curve Loss Curve Validation Curve Loss vs Train Size Epochs Hyper-parameter value Comment Train Error increases with train size, because model overfits small train datasets Purpose: Detect BiasVarianceUtility of adding more data Optimization problemsUndertrainingOvertraining Model ComplexityOptimal Hyperparameters No retraining \u274c \u2705 \u274c No extra computation \u274c \u2705 \u274c Speed up If this takes too long, don't evaluate loss/accuracy every epoch- <code>train_eval_every</code>: saving results- <code>dev_eval_every</code>: forward pass, saving results"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#learning-curve","title":"Learning Curve","text":"<p>Based on the slope of the curves, determine if adding more data will help</p> Conclusion High Bias(Underfitting) High Variance(Overfitting) High BiasHigh Variance"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#loss-curve","title":"Loss Curve","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#same-model-variable-learning-rate","title":"Same Model, Variable Learning Rate","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#validation-curve","title":"Validation Curve","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#neural-network-distributions","title":"Neural Network Distributions","text":"Recommended Value Activation forward-pass distributions \\(N(0, 1)\\) Activation gradient distributions \\(N(0, 1)\\) Parameter forward-pass weight distributions \\(N(0, 1)\\) Parameter gradient distributions \\(N(0, 1)\\) Parameter gradient std:weights magnitude std \\(1\\) Parameter update std:weights magnitude std \\(10^{-3}\\) <p>Avoids</p> <ul> <li>Saturation</li> <li>Exploding</li> </ul>"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#example-plot","title":"Example Plot","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#object-detection","title":"Object Detection","text":"Metric Range Preferred Value mAPmean Average Precision Mean of Average precision across each class \\([0, 1]\\) \\(1\\) IOUIntersection Over Union \\(\\frac{\\text{Area}(T \\cap P)}{\\text{Area}(T \\cup P)}\\)- True bounding box = \\(T\\)- Proposed bounding box = \\(P\\) \\([0, 1]\\) \\(1\\)\\(&gt; 0.9\\) Excellent\\(&gt; 0.7\\) Goodo.w: Poor"},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#idk","title":"IDK","text":""},{"location":"CS_Electives/Machine_Learning/12_Evaluation/#clustering","title":"Clustering","text":"Evaluation Metric Comment WCSS within-cluster-sum-of-square Not ideal Silhouette Coefficient Good Calinski-Harabasz Index"},{"location":"CS_Electives/Machine_Learning/13_Feature_Selection/","title":"Feature Selection","text":"<p>The learning algorithm used for feature selection need not be the the same as final model for fitting</p> Model Null \\(\\beta_0 + u\\) Subset \\(\\beta_0 + \\sum_j^k' \\beta_j x_j + u; k'&lt;k\\) Full \\(\\beta_0 + \\sum_j^k \\beta_j x_j + u\\) <p>Also called as Subset/Variable Selection</p> <p>For \\(p\\) potential predictors, \\(\\exists \\ 2^p\\) possible models. Comparing all subsets is computationally-infeasible</p> Action Can handle multi-collinearity Can handle interactions Robust to overfitting Selection Type Constraint Type Methodology Advantage Disadvantage Drop useless features Too many missing values Variance threshold Correlation with target \u274c \u274c \u2705 2 vars uncorrelated with the target can become informative together Dropping redundant features (multi-collinear) \u274c Feature Information Mutual Information \u274c \u274c \u2705 Feature Importance Random Forest Feature Importance \u274c \u2705 \u274c - Add a random noise feature as a baseline- - Only applicable for tree-based models- Trained model has to be very accurate, an assumption rarely met- Whenever a model is overfitted, very likely that features with highest feature imp are the issue; they should be removed, but we incorrectly concluded that these features will have highest importance and should be retained MDA (Mean Decrease Accuracy)PFI (Permutation Feature Importance) \u274c \u2705 \u2705 Pre-Steps- Add a random noise feature as a baseline- Repeat with different random seeds to eliminate chanceSteps- Model trained w/ pure feature(s), evaluated on pure features - Model trained w/ pure feature(s), evaluated on permuted features - Model trained w/ permuted feature(s), evaluated on pure features- Model trained w/o feature(s)Evaluation- In-Sample metric- Out-sample metric: which features cause improvement in out-sample metric, compared to random baseline- Generalization Gap: which features cause model to overfit, compared to random baseline - Easy to interpret Feature Predictive Power/Specification Search Full Search \u274c \u2705 \u274c Discrete Hard Brute-Force Global optima Predictive power is not a good way to evaluateComputationally-expensive Forward stepwise selection \u274c \u274c \u274c Discrete Hard Starts with the null model, and then adds predictors one-at-a-time Computationally efficientLower sample size requirement Predictive power is not a good way to evaluate Backward Stepwise Selection \u274c \u274c \u274c Discrete Hard Start with the full model and remove predictors one-at-a-time Predictive power is not a good way to evaluateExpensiveLarge sample size requirement IDK LASSO \u2705 \u274c \u2705 Continuous Soft Refer to regularization <p>For handling multi-collinearity - Perform clustering of similar features     - Similar: Pairwise Correlation/Mutual information/VIF     - Clustering: Hierarchical is preferred over centroid-based     - Include random noise feature to understand what is significant relationship     -  - Modify feature selection to handle clusters, by choosing one of the below     - Don't choose one feature per cluster, as one of the correlated features may have important interaction     - Cluster MDI: sum of MDIs of features in each cluster     - Cluster MDA         - Shuffling all features in each cluster simultaneously         - Ensure intra-cluster is maintained, meaning you should not change the relationship between the correlated features by shuffling them independently</p> <p>You can explore the obtained importance/predictive power by disaggregation - over &amp; under-prediction - each output class - each input group/hierarchy</p>"},{"location":"CS_Electives/Machine_Learning/13_Feature_Selection/#forward","title":"Forward","text":"<ol> <li>Let M0 denote the null model.</li> <li>Fit all univariate models. Choose the one with the best in-sample fit (smallest RSS, highest R2) and add that variable \u2013 say x(1)\u2013 to M0. Call the resulting model M1.</li> <li>Fit all bivariate models that include x(1): y \u223c \u03b20 + \u03b2(1)x(1) + \u03b2j xj , and add xj from the one with the best in-sample fit to M1. Call the resulting model M2.</li> <li>Continue until your model selection rule (cross-validation error, AIC, BIC) is lower for the current model than for any of the models that add one variable.</li> </ol>"},{"location":"CS_Electives/Machine_Learning/13_Feature_Selection/#idk","title":"IDK","text":"<ul> <li>\\(\\alpha_\\text{add}\\) usually \\(0.05\\) or \\(0.10\\)</li> <li>\\(\\alpha_\\text{remove} &gt; \\alpha_\\text{add}\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/13_Feature_Selection/#forward-stepwise-regression","title":"Forward Stepwise Regression","text":"<ol> <li>Write down full possible model with all predictors, functions, interactions, etc</li> <li>Regress \\(y\\) against each model term individually</li> <li>Pick \\(\\alpha_\\text{add}\\) and \\(\\alpha_\\text{remove}\\) such that \\(\\alpha_\\text{add}&lt;\\alpha_\\text{remove}\\)</li> <li>Pick best regressor<ol> <li>Calculate \\(t=\\beta_j/\\text{SE}(\\beta_j)\\)</li> <li>Calculate \\(p\\) value for each term</li> <li>Pick smallest \\(p\\)-value \\(p^*_j\\)</li> <li>\\(p^*_j&lt;\\alpha_\\text{add} \\implies\\) add parameter \\(j\\)</li> </ol> </li> <li>Check if previous term should be removed</li> <li>For all previously-added regressors, find the one with the lowest \\(t\\) score and hence highest \\(p\\) value \\(p^*_{j'}\\)</li> <li>If \\(p^*_{j'} &gt; \\alpha_\\text{remove}\\), remove \\(j'\\)</li> <li>Repeat step 4-5 until no improvement</li> </ol>"},{"location":"CS_Electives/Machine_Learning/13_Feature_Selection/#omitted-variable-bias","title":"Omitted Variable Bias","text":"<p>If a correct regressor \\(x_j\\) is missing from the model, then the remaining model parameters will be biased if \\(x_j\\) is related to the other vars</p> <p>The bias will be proportional to the correlation between the missing \\(x_j\\) and the regressors used in the model</p>"},{"location":"CS_Electives/Machine_Learning/13_Feature_Selection/#uncounted-dof","title":"Uncounted DOF","text":"<p>Every time you test a regressor term for the model, it is an addition to the degree of freedom, whether or not you include it in the model</p> <p>Causes data snooping</p> <p>DOF = \\(n-p +\\) no of trials</p>"},{"location":"CS_Electives/Machine_Learning/14_Hyperparameter_Tuning/","title":"Hyper-Parameter Tuning","text":"<p>Sometimes better to do in log-space, rather than linear space</p> Advantage Disadvantage Manual Time-Consuming Grid Search Computationally-expensive Random Search Non-deterministic Evolutionary Randomization, Natural Selection, Mutation Bayesian Probabilistic model of relationship b/w cost function and hyper-parameters, using information gathered from trials Gradient-Based Treat hyper parameter tuning like parameter fitting Early-Stopping Focus resources on settings that look promisingeg: Successive Halving"},{"location":"CS_Electives/Machine_Learning/14_Hyperparameter_Tuning/#speed-up","title":"Speed Up","text":"<ul> <li>Parallelizing</li> <li>Caching</li> <li>Random sampling: Won\u2019t work with caching</li> </ul>"},{"location":"CS_Electives/Machine_Learning/14_Hyperparameter_Tuning/#clustering","title":"Clustering","text":""},{"location":"CS_Electives/Machine_Learning/14_Hyperparameter_Tuning/#elbow-method","title":"Elbow Method","text":"<p>Plot cost function as function of no of clusters</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/14_Hyperparameter_Tuning/#visualization","title":"Visualization","text":"Visualization More than 3 hyperparameters Simple Contour \u274c \u2705 Parallel Coordinates \u2705 \u274c"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/","title":"Model Tuning","text":"<p>Be data-driven with model tuning, by closely-examining actual performance</p> <p>Sometimes you need to decide if it is worth fixing certain type of error</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#regularization","title":"Regularization","text":"<p>Methods that constrain the complexity of a model</p> <ul> <li>Goal: Improve out-of-sample error by reducing overfitting &amp; variance</li> <li>Tradeoff: Compromising on an increased bias</li> </ul> <p></p> <p>Regularization allows a continuous spectrum of model complexity, rather than discrete jumps</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#reducing-capacity","title":"Reducing Capacity","text":"<p>Reduce the number of</p> <ul> <li>parameters (weights)</li> <li>layers (neural net)</li> <li>units per layers (neural net)</li> <li>Bottle neck layers (neural net)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#bottleneck-layers-for-neural-nets","title":"Bottleneck Layer(s) for neural nets","text":"<p>Let</p> <ul> <li>Let layer \\(i\\) and layer \\(j\\) be adjacent layers</li> <li>\\(w_i\\) be weights of layer \\(i\\)</li> <li>\\(\\vert w_i \\vert\\) be the number of units in a layer \\(i\\)</li> <li>\\(w_b\\) be the bottleneck layer</li> <li>effective only if \\(\\vert w_b \\vert &lt; \\arg \\min(\\vert w_i \\vert, \\vert w_j \\vert)\\)</li> </ul> \\[ \\begin{aligned} \\text{Before: } &amp; \\vert w_i \\vert \\cdot \\vert w_j \\vert \\\\ \\text{After: } &amp; \\vert w_i \\vert \\cdot \\vert w_b \\vert + \\vert w_b \\vert \\cdot \\vert w_j \\vert \\end{aligned} \\] <p>Example</p> <pre><code>flowchart LR\na[10&lt;br/&gt;units] --&gt;|100&lt;br/&gt;connections| b[10&lt;br/&gt;units]\nc[10&lt;br/&gt;units] --&gt;|10&lt;br/&gt;connections| d[1&lt;br/&gt;unit] --&gt;|10&lt;br/&gt;connections| e[10&lt;br/&gt;units]</code></pre>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#increase-dof","title":"Increase DOF","text":"<ul> <li>Reduce \\(k\\)</li> <li>Feature Selection</li> <li>Dimensionality Reduction</li> <li>Increase \\(n\\)</li> <li>Data augmentation</li> </ul>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#allow-more-opportunities","title":"Allow more opportunities","text":"<p>Test-time data augmentation</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#subsampling-at-each-iteration","title":"Subsampling at each iteration","text":"<ul> <li>columns</li> <li>rows</li> </ul>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#weight-decay","title":"Weight Decay","text":"<p>Also called as</p> <ul> <li>Shrinkage Term</li> <li>Regularization Penalty</li> </ul> <p>Reduce errors by fitting the function appropriately on the given training set, to help reduce variance, and hence avoid overfitting, while minimally affecting bias.</p> <p>This is done by adding a penalty term in the cost function.</p> <p>Note:</p> <ul> <li>All input features must be standardized</li> <li>Intercept should not be penalized</li> <li>You can use different penalty for each term<ul> <li>You can perform different regularizer and norm based on expected knowledge of distribution of parameter</li> </ul> </li> <li>Regularization should be used carefully for causal estimation<ul> <li>Prediction:<ol> <li>Low-bias</li> <li>Minimum variance</li> </ol> </li> <li>Causal inference:<ol> <li>Unbiased</li> <li>Low variance</li> </ol> </li> </ul> </li> </ul> \\[ \\begin{aligned} J'(\\theta) &amp;= J(\\theta) + \\dfrac{\\lambda}{n}  \\underbrace{\\textcolor{hotpink}{R(\\theta)}}_ {\\mathclap {\\qquad \\text{Reg Penalty}}} \\end{aligned} \\] <p>where</p> <ul> <li>\\(\\sigma_u =\\) Random Standard Deviation: Stochastic Noise</li> <li>\\(Q_f =\\) Target Complexity: Deterministic Noise</li> </ul> <p>This is similar to $$ \\begin{aligned} E_\\text{aug} &amp;= E_\\text{in} + \\dfrac{\\Omega}{n} \\ &amp;\\updownarrow \\ E_\\text{out} &amp;\\le E_\\text{in} + \\dfrac{\\Omega}{n} \\end{aligned} $$</p> <p>Hence, \\(E_\\text{aug}\\) is a better proxy for \\(E_\\text{out}\\) than \\(E_\\text{in}\\)</p> Regularizer Penalty Effect Robust to outliers Unique solution? Comments \\(\\hat \\beta\\) Limitations Bayesian Interpretation \\(L_0\\) \\(\\sum \\limits_{j=1}^k (\\beta_j \\ne 0)\\)Number of non-zero coefficients Enforces sparsity (Feature selection) Computationally-expensiveNot ConvexNo closed-form soln (requires grad descent) Max Norm \\(\\arg\\max \\ \\{ \\beta_j \\}\\) \\(L_1\\)(Lasso: Least Absolute Shrinkage &amp; Selection Operator) \\(\\sum \\limits_{j=1}^k \\gamma_j {\\left \\vert \\dfrac{{\\beta_j - \\mu_{\\beta^*_j} } }{\\sigma_{\\beta^*_j}} \\right \\vert}\\) Encourages sparsity (Feature selection)Eliminates low effect features completely \u2705 \u274c ConvexNo closed-form soln (requires grad descent) \\(\\begin{cases} \\text{sign}({\\hat \\beta}_\\text{OLS}) \\times \\left( \\vert {\\hat \\beta}_\\text{OLS} \\vert - \\lambda/2 \\right) , &amp; \\vert {\\hat \\beta}_\\text{OLS} \\vert &gt; \\lambda/2, \\\\ 0, &amp; \\text{otherwise} \\end{cases}\\) when \\(\\exists\\) highly-correlated features- Results can be random/arbitrary and unstable - Multiple solutions Laplace prior \\(L_2\\)(Rigde) \\(\\sum \\limits_{j=1}^k \\gamma_j \\left( \\dfrac{\\beta_j - \\mu_{\\beta^*_j}}{\\sigma_{\\beta_j^*}} \\right)^2\\) Scale down parametersReduces multi-collinearity \u274c \u2705 ConvexClosed-form soln exists \\(\\dfrac{{\\hat \\beta}_\\text{OLS}}{1 + \\lambda}\\) Normal prior \\(L_q\\) \\(\\sum \\limits_{j=1}^k \\gamma_j {\\left \\vert \\dfrac{{\\beta_j - \\mu_{\\beta^*_j} } }{\\sigma_{\\beta^*_j}} \\right \\vert^q}\\) \\(L_3\\)(Elastic Net) \\(\\alpha L_1 + (1-\\alpha) L_2\\) Not very \u2705 Entropy \\(\\sum \\limits_{j=1}^k - P(\\beta_j) \\ln P(\\beta_j)\\) Encourage parameters to be differentEncourages sparsityCause high variation in between parameters SR3(Sparse Relaxed) Max \\(\\max \\{ \\vert \\beta_j \\vert \\}\\) Lipschitz \\(\\prod_j^k \\vert \\vert \\beta_j \\vert \\vert_p\\)Smaller \\(p \\implies\\) smoother function Enforce smooth function and gradientsRobust to noise Gradient of Loss \\(\\vert \\vert \\nabla_{\\!\\! \\beta} \\ L \\vert \\vert_p\\)\\(p=2\\) usuallyRegularization Penalty = Norm of gradient of loss wrt to weights Enforce smooth function and gradients <p>where</p> <ul> <li>\\(\\mu_{\\beta^*_j}\\) is the prior-known most probable value of \\(\\beta_j\\)</li> <li>\\(\\sigma_{\\beta^*_j}\\) is the prior-known standard deviation of \\(\\beta_j\\)</li> <li>\\(\\gamma_j\\): Weightage of weight decay</li> <li>Penalize some parameters more than others</li> <li>Useful to penalize higher order terms with \\(\\gamma_j = 2^q\\), where \\(q=\\) complexity of term</li> </ul> <p>\\(\\mu_{\\beta^*_j}\\) and \\(\\sigma_{\\beta^*_j}\\) incorporate desirable Bayesian aspects in our model.</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#bayesian-interpretation","title":"Bayesian Interpretation","text":"<p>Regularization amounts to the use of informative priors, where we introduce our knowledge or belief about the target function in the form of priors, and use them to \u201cregulate\u201d the behavior of the hypothesis we choose</p> <p>Incorporating \\(\\hat \\beta\\) into the regularization incorporates maximum likelihood estimate of the coefficients.</p> <p>Didn\u2019t understand: The standard deviation of the prior distribution corresponds to regularization strength \\(\\lambda\\)</p> <p>Example</p> \\(y\\) \\(\\hat \\beta\\) \\(\\beta x\\) 0 \\(x^\\beta\\) 1 <p></p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#idk","title":"IDK","text":""},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#contours-of-regularizers","title":"Contours of Regularizers","text":""},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#limitations","title":"Limitations","text":"<p>Magnitude of parameters may not always be the best estimate of complexity, especially for Deep Neural Networks</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#why-is-standardization-required","title":"Why is standardization required?","text":"<ul> <li>magnitudes of parameters need to be comparable</li> <li>Penalized estimates are not scale equivariant: multiplying \\(x_j\\) by a constant \\(c\\) can cause a significant change in \\(\\hat \\beta\\) when using regularization</li> </ul>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#feature-selection-paths","title":"Feature Selection Paths","text":""},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#penalty-coefficient-magnitude","title":"Penalty Coefficient Magnitude","text":""},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#penalty-coefficient-vs-noise","title":"Penalty Coefficient vs Noise","text":"Stochastic Noise Deterministic Noise \\[ \\begin{aligned} \\lambda^* &amp;\\propto \\sigma^2_u \\\\ \\lambda^* &amp;\\propto Q_f^2 \\end{aligned} \\] <p>where \\(\\lambda^* =\\) Optimal \\(\\lambda\\)</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#frequentist-interpretation","title":"Frequentist Interpretation","text":"<p>\\(\\lambda\\) regulates the smoothness of the spline that solves $$ \\min_h \\left { J(\\theta, x_i, y_i) + \\lambda \\int [h''(t)]^2 \\cdot dt \\right } $$ Penalizing the squared \\(k\\)th derivative leads to a natural spline of degree \\(2k \u2212 1\\)</p> \\(\\lambda\\) Reduces Comment 0 Bias Interpolates every \\((x_i, y_i)\\) \\(\\infty\\) Variance Becomes linear least squares line"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#idk_1","title":"IDK","text":"\\[ \\begin{aligned} &amp;\\arg \\min J(\\theta) \\\\ &amp;\\text{subject to: } \\sum_{j=1}^k (\\beta_j)^2 \\le C \\end{aligned} \\] \\[ \\lambda \\propto \\dfrac{1}{C} \\]"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#optimization-equivalent","title":"Optimization Equivalent","text":"<p>This is equivalent to:</p> <p>At each iteration, shrink the weights by the gradient of the regularization penalty before taking the gradient step</p> <p>For L2: \\((1-\\nu \\lambda)\\) $$ \\begin{aligned} w_{t+1} &amp;= w_{t} - \\nu \\Big[ \\nabla w_t + \\nabla R(w_t) \\Big] \\ &amp;= \\Big[ 1 - \\nu  \\nabla R(w_t) \\Big] w_{t} - \\nu  \\nabla w_t \\</p> <p>\\implies \\text{With L2} &amp;= (1- \\nu \\lambda) w_{t} - \\nu g(t) \\end{aligned} $$</p> <p>Most deep learning libraries incorporate weight decay in the optimizer; however, this isn\u2019t the most conceptually best way to approach weight decay - better to incorporate in the loss function</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#hinted-regularization","title":"Hinted Regularization","text":"<p>Penalize deviation from Model Hints </p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#multi-stage-regularization","title":"Multi-Stage Regularization","text":"Stage Goal 1 variable selection LASSO 2 estimation Any method <p>Intuition: Since vars in 2<sup>nd</sup> stage have less \"competition\" from noise variables, estimating using selected variables could give better results</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#system-equation-penalty","title":"System Equation Penalty","text":"<p>Useful if you know the underlying systematic differential equation</p> <p>$$ J'(\\theta) = J(\\theta) + \\text{DE} \\ \\text{RHS(DE)} = 0 $$ Refer to PINNs for more information</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#idk_2","title":"IDK","text":""},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#early-stopping","title":"Early Stopping","text":"<ul> <li>This applies to all evaluation curves </li> <li>Stopping criteria</li> <li>In-Sample error &lt; Out-Sample error</li> <li>Evaluation metric<ul> <li>RMSE \\(\\le \\sigma_u\\)</li> <li>MAPE \\(\\le 1-\\text{Accuracy}_\\text{req}\\)</li> </ul> </li> <li>Stop few iterations/value before the optimal point, to reduce variance further: \\(e_\\text{stop} &lt; e^*\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#dropout","title":"Dropout","text":"<p>Dropout is applied on the output of hidden fully-connected layers</p> <p></p> <p>Advantages - Forces network to have redundant representation     - Makes networks \u201crobust\u201d to missing activations     - Reduce dependence on any single neuron - Can be interpreted as training large ensemble of models (that share parameters)     - Each binary mask is one model, gets trained on only ~one datapoint - Stochastic approximation</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#training","title":"Training","text":"<p>Stochastically drop out units with probability \\(p_\\text{drop}\\) and keep with \\(p_\\text{keep}=1-p_\\text{drop}\\)</p> \\[ (w'_t)_j = \\begin{cases} 0, &amp; \\text{with prob } p \\\\ (w_t)_j, &amp; \\text{o.w} \\end{cases} \\] <p>Annealed dropout</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#evaluationproduction","title":"Evaluation/Production","text":"<p>At inference time, dropout is inactive, as we should not predict stochastically</p> Approach Time Advantages Disadvantage Naive approach Test Simply not use dropout All units receive \\((1/p_\\text{drop})\\) times as many incoming signals compared to training, so responses will be different Test-Time Rescaling Test Multiply weights by \\(p_\\text{keep}\\) Comparing  similar architectures w/ and w/o dropout requires implementing 2 different networks at test time Dropout Inversion(preferred) Train Divide weights by \\(p_\\text{keep}\\) Overcome limitations of Test-Time RescalingAllows for annealed dropout"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#ensembling","title":"Ensembling","text":"<p>Reduces variance from high-variance models, such as trees</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#noise-injection","title":"Noise Injection","text":"<ul> <li>Add noise to inputs</li> <li>Add noise to outputs</li> </ul> <p>Behaves similar to L2 regularization</p>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#label-smoothing","title":"Label Smoothing","text":"<p>The output of \\(\\sigma, \\tanh\\) never actually really output the maximum/minimum range values. So the model will keep trying to make the predictions go to exact \\(0/1\\) (which is never attainable), making it prone to overfitting</p> <p>Using label smoothing, model becomes less confident with extremely confident labels (which we want to avoid). Now, the penalty given to a model due to an incorrect prediction will be slightly lower than using hard labels which would result in smaller gradients</p> Modify Target \\(y' = \\begin{cases} y - \\epsilon, &amp; y = y_\\text{true} \\\\ y + \\dfrac{\\epsilon}{C-1}, &amp; \\text{o.w} \\end{cases}\\) Loss \\(L' = (1-\\epsilon) L_i + \\dfrac{\\epsilon}{C-1} \\sum_j L_j\\) <p>where</p> <ul> <li>\\(y_\\text{true}\\) is the true label</li> <li>\\(C=\\) total number of classes/labels</li> <li>\\(\\epsilon \\approx 0\\)</li> </ul> <p>Extreme cases for \\(\\epsilon\\)</p> <ul> <li>\\(\\epsilon=0\\): original</li> <li>\\(\\epsilon=1\\): uniform</li> </ul>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#active-teaching","title":"Active Teaching","text":"<pre><code>flowchart LR\nc(( ))\nm[ML]\n\nd[(Dataset)] --&gt; m &amp; EDA\n\nEDA --&gt;\nrb[Rule-Based System]\n\nsubgraph Active Teaching\n  rb &amp; m &lt;--&gt;|Compare &amp; Update| c\nend</code></pre>"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#neural-network","title":"Neural Network","text":"Phase Hessian Mode Connectivity Model Similarity Treatment 1 Large -ve Low Larger network 2 Large +ve Low Smaller learning rate 3 Small -ve Low Larger network 4-A Small \\(\\approx 0\\) Low Increase train size 4-B Small \\(\\approx 0\\) High \u2705"},{"location":"CS_Electives/Machine_Learning/14_Model_Tuning/#activations","title":"Activations","text":"<p>Ensure Neural Network Distributions</p> <ul> <li>Initialization of parameters</li> <li>Better learning rate</li> <li>Better optimization algorithm</li> <li>Residual connections</li> <li>Normalization</li> <li>Batch</li> <li>Layer</li> <li>Group</li> </ul>"},{"location":"CS_Electives/Machine_Learning/15_Model_Selection/","title":"Selection","text":"<p>Note: Make sure to correct for multiple hypothesis testing</p>"},{"location":"CS_Electives/Machine_Learning/15_Model_Selection/#model-selection","title":"Model Selection","text":"<ol> <li>Fit multiple models \\(g_i\\) on the training data and eyeball dev data</li> <li>Use dev data for hyper parameter tuning of each model \\(g_i\\)</li> <li>Use external validation data for model selection and obtain \\(g^*\\)</li> <li>Combine the training and validation data. Refit \\(g^*\\) on this set to obtain \\(g^{**}\\)</li> <li>Assess the performance of \\(g^{**}\\) on the test data</li> </ol> <p>Finally, train \\(g^{**}\\) on the entire data to obtain \\(\\hat f\\)</p> <p>Check the results on the self-hosted competition</p>"},{"location":"CS_Electives/Machine_Learning/16_Statistical_Inference/","title":"16 Statistical Inference","text":""},{"location":"CS_Electives/Machine_Learning/16_Statistical_Inference/#statistical-inference","title":"Statistical Inference","text":"<p>Deals with the problem of uncertainty in estimates due to sample variability</p> <p>Does not deal with</p> <ul> <li>Whether model specification is correct</li> <li>Whether \\(x\\) has causal effect on \\(y\\)</li> <li>Whether model is good for describing causal effect of \\(x\\) on \\(y\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/16_Statistical_Inference/#hypotheses-testing","title":"Hypotheses Testing","text":""},{"location":"CS_Electives/Machine_Learning/16_Statistical_Inference/#selective-inference","title":"Selective Inference","text":"<p>Assessing strength of evidence after obtaining the \u2018best model\u2019 through searching from a large number of models</p> <p>If not taken into account, the effects of selection can greatly exaggerate the apparent strengths of relationships.</p> <p>Also called as Post-Selection Inference</p>"},{"location":"CS_Electives/Machine_Learning/16_Statistical_Inference/#context","title":"Context","text":"<p>To conduct statistical inference for procedures that involve model selection, such as forward stepwise regression or the lasso, it is tempting to look only at the final selected model. However, such inference is generally invalid</p> <p>The problem is essentially the same as those of specification search and data-snooping: an observed correlation of 0.9 between x and y may be noteworthy. However, if x is found by searching over 100 variables looking for the one with the highest observed correlation with y, then the finding is no longer as impressive and could well be due to chance</p> <p></p> <p></p>"},{"location":"CS_Electives/Machine_Learning/16_Statistical_Inference/#solution-conditional-coverage","title":"Solution: Conditional Coverage","text":"<p>Make the inference conditional on the model selected</p> <p>Construct CI for \\(\\beta_{j, M}\\) conditional on model \\(M\\) being selected: $$ P(\\beta_{j, M} \\in C_{j,m} \\vert M \\text{ selected}) \\ge 1 - \\alpha $$</p>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/","title":"Uncertainty","text":""},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#types-of-uncertainty","title":"Types of Uncertainty","text":"Others\u2019 knowledgeOur knowledge Known Unknown Known Things we are certain of We know there are things we can\u2019t predicteg: Random Process Unknown Others know but you don\u2019t knoweg: Insufficient data Completely unexpected/unforeseeable eventseg: Unknown distribution Epistemic Aleatoric Uncertainty in Model Data Cause - Model misspecification- Missing training data - Measurement errors- Process random noise Reducible through more training data \u2705 \u274c Can be learnt by model??? \u274c \u2705"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#uncertainty-quantification-methods","title":"Uncertainty Quantification Methods","text":"Concept Assumption Works for non-linear Limitations Asymptotic approach Central limit theorem - Assumes normal distribution of response residuals- Assumes homoscedascity of response residuals \u274c - Requires large sample size to satisfy asymptotic condition- Requires appropriate formula for calculating standard error (not possible for complex models) Bootstrapping(preferred) Random sampling with replacement \u2705 Higher computation cost Delta Approach \u2705 Conformal Prediction"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#uncertainty-intervals","title":"Uncertainty Intervals","text":"\\[ \\begin{aligned} \\{y_u, y_l\\} &amp;= \\hat y \\pm \\Delta y \\end{aligned} \\] \\(\\Delta y\\) Normal Assumption \\(t_{n_\\text{cal}, \\alpha/2} \\times \\text{SE}\\) Conformal Prediction \\(S^{-1} \\left[ q_{\\frac{\\lceil (n+1)\\alpha \\rceil}{n}} \\right]\\)"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#normal-assumption","title":"Normal Assumption","text":"Coefficient Confidence Interval Response Confidence Interval Response Prediction Interval Notation \\(\\sigma_{\\hat \\beta}\\) \\(\\sigma \\Big[ \\hat \\mu \\vert x_{i, \\text{new}} \\Big]\\) \\(\\sigma \\Big[ \\hat y_{i, \\text{new}} \\vert x_{i, \\text{new}} \\Big]\\) The upper and lower bound for estimated __ at a given level of significance \\(\\hat \\beta\\) \\(\\hat \\mu \\vert x_{i, \\text{new}}\\) \\(\\hat y \\vert x_{i, \\text{new}}\\)\\(=\\hat \\mu \\vert x_{i, \\text{new}} + \\hat u \\vert x_{i, \\text{new}}\\) Univariate Linear Regression(Asymptotic Approach) \\(\\left\\{ \\text{RMSE} \\sqrt{\\dfrac{1}{n_\\text{cal}} + \\dfrac{\\bar x^2}{n_\\text{cal} \\sigma^2_x}} , \\dfrac{\\text{RMSE}}{\\sqrt{n_\\text{cal} \\sigma^2_x} }\\right\\}\\) \\(\\text{RMSE} \\times \\sqrt{\\dfrac{1}{n_\\text{cal}} + \\dfrac{(x_{i, \\text{new}}- \\bar x )^2}{n_\\text{cal} \\sigma_x^2}}\\) \\(\\text{RMSE} \\times \\sqrt{\\dfrac{1}{n_\\text{cal}} + \\dfrac{(x_{i, \\text{new}} - \\bar x )^2}{n_\\text{cal} \\sigma_x^2} \\ \\textcolor{hotpink}{+ 1}}\\) Multivariate Linear Regression(Asymptotic Approach) \\({\\text{RMSE} \\times \\sqrt{\\text{Cov}_{jj}}}\\) \\(\\text{RMSE} \\times \\sqrt{X_{i, \\text{new}}^T \\cdot \\text{Cov} \\cdot X_{i, \\text{new}} }\\) \\(\\text{RMSE} \\times \\sqrt{X_{i, \\text{new}}^T \\cdot \\text{Cov} \\cdot X_{i, \\text{new}}  \\ \\textcolor{hotpink}{+ 1}}\\) Multivariate Non-Linear Regression(Asymptotic + Delta Approach) \\({\\text{RMSE} \\times \\sqrt{\\text{IF}_{jj}}}\\) \\(\\text{RMSE} \\times \\sqrt{ J_{i, \\text{new}}^T \\cdot \\text{IF} \\cdot J_{i, \\text{new}} }\\) \\(\\text{RMSE} \\times  \\sqrt{J_{i, \\text{new}}^T \\cdot \\text{IF} \\cdot J_{i, \\text{new}}  \\ \\textcolor{hotpink}{+ 1} }\\) <p>where - \\(\\text{Cov}\\): Covariance matrix     - \\(\\text{Cov} = (X' X)^{-1}\\) - \\(J\\): Jacobean matrix     - \\(J_{i, \\text{new}} = \\dfrac{\\partial \\hat y_{i, \\text{new}}}{\\partial \\beta}\\) - \\(H\\): Hessian matrix     - \\(H \\approx (J^T J)\\) - \\(\\text{IF}:\\) Inverse Fischer     - \\(\\text{IF} = H^{-1}\\)</p> <p>High values for non-diagonal elements of \\(\\text{Cov}_\\beta\\) means that the errors of \\(\\beta\\) are correlated with each other.</p> <p>Degree of freedom \\(= n - k - 1\\), where</p> <ul> <li>\\(n =\\) sample size</li> <li>\\(k=\\) no of input variables</li> </ul> <p>Confidence and prediction intervals are narrowest at \\(X = \\bar X\\), and get wider further from this point.</p> <p></p> <p>Under homoskedasticity, $$ \\begin{aligned} \\hat V(\\hat \\beta) &amp;= (X' X)^{-1} \\hat \\sigma^2 \\ &amp;=\\dfrac{\\hat \\sigma^2}{\\hat u_j' \\hat u_j} \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#note","title":"Note","text":"<ul> <li>RMSE = RMSE of validation data</li> <li>If your validation error distribution is not normal, or you have a lot of data, you can use the quantiles of validation error distribution for the confidence intervals</li> </ul>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#intervals-using-models-prediction","title":"Intervals using Models\u2019 Prediction","text":"<p>For each data point, take __ of multiple models</p> <ul> <li>average</li> <li>5<sup>th</sup> quantile</li> <li>95<sup>th</sup> quantile</li> </ul>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#predictive-density","title":"Predictive Density","text":"<p>Describes the full probabilistic distribution \\(\\forall x\\)</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#trajectoriesscenarios","title":"Trajectories/Scenarios","text":"<p>Equally-likely samples of multivariate predictive densities</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#uncertainty-propagation","title":"Uncertainty Propagation","text":"Function Variance \\(aA\\) \\(= a^2\\sigma_A^2\\) \\(aA + bB\\) \\(= a^2\\sigma_A^2 + b^2\\sigma_B^2 + 2ab\\,\\text{Cov(A, B)}\\) \\(aA - bB\\) \\(= a^2\\sigma_A^2 + b^2\\sigma_B^2 - 2ab\\,\\text{Cov(A, B)}\\) \\(AB\\) \\(\\approx f^2 \\left[\\left(\\frac{\\sigma_A}{A}\\right)^2 + \\left(\\frac{\\sigma_B}{B}\\right)^2 + 2\\frac{\\text{Cov(A, B)}}{AB} \\right]\\) \\(\\frac{A}{B}\\) \\(\\approx f^2 \\left[\\left(\\frac{\\sigma_A}{A}\\right)^2 + \\left(\\frac{\\sigma_B}{B}\\right)^2 - 2\\frac{\\text{Cov(A, B)}}{AB} \\right]\\) \\(\\frac{A}{A+B}\\) \\(\\approx \\frac{f^2}{\\left(A+B\\right)^2} \\left(\\frac{B^2}{A^2}\\sigma_A^2  +\\sigma_B^2 - 2\\frac{B}{A} \\text{Cov(A, B)} \\right)\\) \\(a A^{b}\\) \\(\\approx \\left( {a}{b}{A}^{b-1}{\\sigma_A} \\right)^2 = \\left( \\frac{{f}{b}{\\sigma_A}}{A} \\right)^2\\) \\(a \\ln(bA)\\) \\(\\approx \\left(a \\frac{\\sigma_A}{A} \\right)^2\\)[^4] \\(a \\log_{10}(bA)\\) \\(\\approx \\left(a \\frac{\\sigma_A}{A \\ln(10)} \\right)^2\\)[^5] \\(a e^{bA}\\) \\(\\approx f^2 \\left( b\\sigma_A \\right)^2\\)[^6] \\(a^{bA}\\) \\(\\approx f^2 (b\\ln(a)\\sigma_A)^2\\) \\(a \\sin(bA)\\) \\(\\approx \\left[ a b \\cos(b A) \\sigma_A \\right]^2\\) \\(a \\cos \\left( b A \\right)\\) \\(\\approx \\left[ a b \\sin(b A) \\sigma_A \\right]^2\\) \\(a \\tan \\left( b A \\right)\\) \\(\\left[ a b \\sec^2(b A) \\sigma_A \\right]^2\\) \\(A^B\\) \\(\\approx f^2 \\left[ \\left( \\frac{B}{A}\\sigma_A \\right)^2 +\\left( \\ln(A)\\sigma_B \\right)^2 + 2 \\frac{B \\ln(A)}{A} \\text{Cov(A, B)} \\right]\\) \\(\\sqrt{aA^2 \\pm bB^2}\\) \\(\\approx \\left(\\frac{A}{f}\\right)^2 a^2\\sigma_A^2 + \\left(\\frac{B}{f}\\right)^2 b^2\\sigma_B^2 \\pm 2ab\\frac{AB}{f^2}\\,\\text{Cov(A, B)}\\) <p>For uncorrelated variables (\\(\\rho_{AB}=0\\), \\(\\text{Cov(A, B)}=0\\)) expressions for more complicated functions can be derived by combining simpler functions. For example, repeated multiplication, assuming no correlation, gives \\(f = ABC; \\qquad \\left(\\frac{\\sigma_f}{f}\\right)^2 \\approx \\left(\\frac{\\sigma_A}{A}\\right)^2 + \\left(\\frac{\\sigma_B}{B}\\right)^2+ \\left(\\frac{\\sigma_C}{C}\\right)^2.\\)</p> <p>For the case \\(f = AB\\) we also have Goodman's expression[^7] for the exact variance: for the uncorrelated case it is \\(V(XY)= E(X)^2 V(Y) + E(Y)^2 V(X) + E((X-E(X))^2 (Y-E(Y))^2)\\) and therefore we have: \\(\\sigma_f^2 = A^2\\sigma_B^2 + B^2\\sigma_A^2 +  \\sigma_A^2\\sigma_B^2\\)</p>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#effect-of-correlation-on-differences","title":"Effect of correlation on differences","text":"<p>If A and B are uncorrelated, their difference A-B will have more variance than either of them. An increasing positive correlation (\\(\\rho_{AB}\\to 1\\)) will decrease the variance of the difference, converging to zero variance for perfectly correlated variables with the same variance. On the other hand, a negative correlation (\\(\\rho_{AB}\\to -1\\)) will further increase the variance of the difference, compared to the uncorrelated case.</p> <p>For example, the self-subtraction f=A-A has zero variance \\(\\sigma_f^2=0\\) only if the variate is perfectly autocorrelated (\\(\\rho_A=1\\)). If A is uncorrelated, \\(\\rho_A=0\\), then the output variance is twice the input variance, \\(\\sigma_f^2=2\\sigma^2_A\\). And if A is perfectly anticorrelated, \\(\\rho_A=-1\\), then the input variance is quadrupled in the output, \\(\\sigma_f^2=4\\sigma^2_A\\) (notice \\(1-\\rho_A=2\\) for f = aA \u2212 aA in the table above).</p>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#value-at-risk-models","title":"Value at Risk Models","text":"<ul> <li>Derive the risk profile of the firm</li> <li>Protect firm against unacceptably large concentrations</li> <li>Quantify potential losses</li> </ul> <ol> <li>Collect data</li> <li>Graph the data to inspect data quality</li> <li>Transform prices data into returns form (percentage diff of prices)</li> <li>Look at the frequency distribution</li> <li>Obtain the standard deviation (volatility)</li> <li>Multiply volatility with one-sided \\(Z_1\\) to estimate 99% worst-case loss</li> </ol>"},{"location":"CS_Electives/Machine_Learning/17_Uncertainty/#classification","title":"Classification","text":"\\[ [\\text{Bin}(n, p)_{1-\\alpha/2}, \\text{Bin}(n, p)_{\\alpha/2}] \\]"},{"location":"CS_Electives/Machine_Learning/18_Interpretation/","title":"Model Interpretation","text":"<p>Association \\(\\ne\\) Causation</p>"},{"location":"CS_Electives/Machine_Learning/18_Interpretation/#classification-of-inference-techniques","title":"Classification of Inference Techniques","text":"<ul> <li>IDK</li> <li>Model-Specific</li> <li>Model-Agnostic</li> <li>Scope</li> <li>Global: Explanation for entire dataset</li> <li>Local: Explanation for single data point</li> </ul>"},{"location":"CS_Electives/Machine_Learning/18_Interpretation/#inference-techniques","title":"Inference Techniques","text":"IDK Scope Limitations Simple Linear Regression\\(y = \\beta_0 + \\beta_j x_j + \\beta_\\text{ind} G + \\beta_\\text{int} x_j G\\) Model-Specific Global \\(\\beta_0\\) is the baseline value of \\(y\\) when \\(x_j=0\\)\\(\\beta_j\\) is the change in \\(y\\) for every unit increase in \\(x_j\\)\\(\\beta_\\text{ind}\\) is the change in baseline for group \\(G\\), ie baseline will now be \\((\\beta_0 + \\beta_\\text{ind})\\)\\(\\beta_\\text{int}\\) is the additional change in \\(y\\) in group \\(G\\), ie for every unit increase in \\(x_j\\), \\(y\\) changes by \\((\\beta_j + \\beta_\\text{int})\\) units for group \\(G\\) \\(\\ln \\vert y \\vert = \\beta_0 + \\beta_j x_j\\) Model-Specific Global For every unit increase in \\(x_j\\), percentage change in \\(y\\) is \\(\\beta_j\\) units \\(\\ln \\vert y \\vert = \\beta_0 + \\beta_j \\ln \\vert x_j \\vert\\) Model-Specific Global Elasticity of \\(y\\) wrt \\(x_j\\) is given by \\(\\beta_j\\)\\(\\beta_j = \\dfrac{\\% \\Delta y}{\\% \\Delta x_j}\\) SAGE Model-Agnostic Global Variable/Feature Importance Model-Agnostic Global Decrease of in-sample error due to splits over \\(x\\), averaged over all trees of ensemble Partial Dependence Model-Agnostic Global Partial derivative of \\(y\\) wrt \\(x\\): Marginal effect of \\(x\\) on \\(y\\) after integrating out all other vars SHAP Model-Agnostic Local Does not account for interactions SHAP-Interactions Model-Agnostic Local LIME Model-Agnostic Local"},{"location":"CS_Electives/Machine_Learning/19_Compression/","title":"Model Compression","text":"Quantization Reducing precision from Float64 to Int8 Pruning Removing unnecessary aspects of the modelRemoving neurons in ANN"},{"location":"CS_Electives/Machine_Learning/20_Production/","title":"Production","text":"<p>Stage after deploying the model to work with live data - Model conversion - Optimization     - Performance         - Latency         - Throughput     - Energy-consumption - Security &amp; Privacy - Online learning</p>"},{"location":"CS_Electives/Machine_Learning/20_Production/#drift","title":"Drift","text":"<p>Train &amp; live data distributions change over time</p> <p>Causes - Structural break - Data integrity issues</p>"},{"location":"CS_Electives/Machine_Learning/20_Production/#types","title":"Types","text":"Type Data Change Relationship Change Subtype Change in Solution Example Example cause Data Drift \u2705 \u274c Feature/Covariate \\(p(x)\\) Applicants from new market Product launch in new market Prior/Output/Label \\(p(y)\\) Price of goods increase Inflation Concept Drift \u274c \u2705 \\(p(y \\vert x)\\) - Give higher sample weight to recent datapoints- Use batch-streaming hybrid  - Works when we have the label associated with every data point, such as in Recommender Systems Price-elasticity of demand changes New competitor in your existing market <p>Check with - Adversarial Validation/Domain Classifier - Anomaly Detection</p> <ul> <li>If label and drift happen together and cancel each other out, there is no concept drift.</li> <li>Else, concept drift will be caused by one/both since they are linked by Bayes'  equation</li> </ul>"},{"location":"CS_Electives/Machine_Learning/20_Production/#speed","title":"Speed","text":""},{"location":"CS_Electives/Machine_Learning/20_Production/#deployment-checklist","title":"Deployment Checklist","text":""},{"location":"CS_Electives/Machine_Learning/20_Production/#idk","title":"IDK","text":"Aspect Type Advantages Disadvantages Comment Inference Precomputed Simple Computationally-expensive Recommendation systems to be used for email marketing campaigns Realtime/Inference-time Training Batch Train the model before inference Realtime/Inference-time Train the model at inference - Reduces train cost- Reduces train time- Do not train on observations that will never be required- Improves model performance - Possible latency Useful if your inference use-case only requires a small subset of training dataset- filter at inference time- train at inference time- predict at inference timeComplexity of model should be based on the amount of samples Retraining Full Batch Periodically retrain on entire dataset Simple - Computationally-expensive New Batch Periodically update the existing model with new observations Online/Streaming/On-the-fly Update model as new observations appear - Computationally-efficient - Complex"},{"location":"CS_Electives/Machine_Learning/20_Production/#model-location","title":"Model Location","text":"Cloud Edge/Browser Cheaper \u274c \u2705 Small models(Load + Inference) Slower Faster Large models(Load + Inference) Faster Slower Offline support \u274c \u2705 User Privacy \u274c \u2705 Model Privacy \u2705 \u274c"},{"location":"CS_Electives/Machine_Learning/20_Production/#compute-requirements","title":"Compute requirements","text":"<p>CPU/GPU/Memory</p>"},{"location":"CS_Electives/Machine_Learning/20_Production/#latency-throughput-qps","title":"Latency, throughput (QPS)","text":""},{"location":"CS_Electives/Machine_Learning/20_Production/#logging","title":"Logging","text":""},{"location":"CS_Electives/Machine_Learning/20_Production/#security-privacy","title":"Security &amp; Privacy","text":""},{"location":"CS_Electives/Machine_Learning/20_Production/#scenarios-of-deployment","title":"Scenarios of Deployment","text":"<ul> <li>New product/capability</li> <li>Automate/assist with manual task</li> <li>Replace previous ML system</li> </ul>"},{"location":"CS_Electives/Machine_Learning/20_Production/#types-of-deployment","title":"Types of Deployment","text":"Type Canary Roll out to small fraction of traffic initiallyMonitor system and ramp up traffic gradually Blue-Green Fully deploy new version (green)Keep old model dormant, and rollback to it if required (blue)"},{"location":"CS_Electives/Machine_Learning/20_Production/#degrees-of-automation","title":"Degrees of Automation","text":"Human-Only Shadow Mode AI Assistance Partial Automation Full automation"},{"location":"CS_Electives/Machine_Learning/20_Production/#monitoring","title":"Monitoring","text":"<ul> <li>Brainstorm potential problems</li> <li>Brainstorm appropriate metrics to identify the problems</li> <li>Software Metrics<ul> <li>Memory</li> <li>Compute</li> <li>Latency</li> <li>Throughput</li> <li>Server load</li> </ul> </li> <li>Data<ul> <li>Data Distributions</li> <li>Input Metrics<ul> <li>Average Input length</li> <li>Fraction of rows with missing values</li> <li>Average image brightness</li> </ul> </li> <li>Output metrics<ul> <li>Missing outputs</li> <li>No of times user redoes search</li> <li>CTR (ClickThrough Rate): No of clicks that your ad receives divided by the number of times your ad</li> </ul> </li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/20_Production/#model-serving","title":"Model Serving","text":""},{"location":"CS_Electives/Machine_Learning/20_Production/#adversarial-attacks","title":"Adversarial Attacks","text":"<p>Fool model by adding noise</p> <p></p> <p>This is not a problem with Deep Learning and/or ConvNets. Same issue comes up with Neural Networks in any other modalities. Primary cause of neural networks' vulnerability adversarial perturbation is their linear nature (and very high-dimensional, sparsely-populated input spaces).</p> <p>The exact adversarial noise can easily be learnt - known model weights: directly - unknown model weights: through backpropagation</p> <p>eg: Confidently predicting the class even though it is extrapolating</p> <p></p> <p>Solution - Data augmentation; not sufficient - Train for adversarial robustness; not sufficient     1. Create adversarial examples     2. Add them to train data, tagged as \"adversarial class\" - Not clear what is the guaranteed workaround</p>"},{"location":"CS_Electives/Machine_Learning/21_Performance_Optimization/","title":"Performance Optimization","text":"<ul> <li>Subsample</li> <li>Multi-Threading</li> <li>Caching</li> <li>Partial fit</li> </ul>"},{"location":"CS_Electives/Machine_Learning/22_Learning_Algorithms/","title":"Learning Algorithms","text":"Algorithm Learning Type Task Comment Assumptions Pre-Processing Probabilistic Parametric Scope \\(d_\\text{VC}\\) Bias Variance Generalization Advantages Disadvantages Time ComplexityTraining Time ComplexityInference Space ComplexityTraining Space ComplexityInference Least Squares Supervised Regression Mean has linear relationship with inputsConstant variance \u274c \u2705 Global \\(k+1\\) High Low Good\\(n &gt;&gt; k\\) \\(O(n_\\text{train} p^2 + p^3)\\) \\(O(n_\\text{inf} p)\\) LogisticRegression Supervised Classification Binary \u2705 \u2705 Global \\(k+1\\) High Low Good\\(n &gt;&gt; k\\) \\(O(n_\\text{train} p)\\) \\(O(n_\\text{inf} p)\\) Naive Bayes Supervised \\(O(n_\\text{train} p)\\) \\(O(n_\\text{inf} p)\\) OrderedRegression Supervised Classification Ordered Piecewise Constant Supervised Regression/Classification \u274c \u274c Local Piecewise Polynomial Supervised Regression/Classification \u274c \u274c Local SVM Supervised Regression/Classification Margin-Based \u274c \u2705 Computationally-expensive Gaussian Processes Supervised Regression/Classification \u2705 \u2705 KNNNearest Neighbor Supervised Regression/Classification Good baseline modelCan use mean, median, mode for regressionCan use weightage, voting for classification Underlying relationship b/w \\(x\\) and \\(y\\) is continuous - Feature scaling- Dimensionality reduction \u274c \u274c + Lazy-learner: no train time, new train data can be added without re-training+ Can perform multi-class out-of-the-box Lazy-learner: High space complexity, high inference time- Cannot use categorical features- Does not work well for large \\(n\\) or \\(p\\): need to calculate the distance of inference record wrt training records- Sensitive to noise- Sensitive to missing data- Sensitive to scale- Cannot extrapolate Decision Tree Supervised Regression/Classification Automatic Piecewise ConstantExactly opposite in characteristics wrt to OLS \u274c \u274c Local Low High - Highly-interpretable- Auto-detect non-linear relationships- Auto-model variable interactions- Fast evaluation: Traversal only occurs on subset of attributes - Poor regressive performance- Unstable: Tree struct sensitive to train data; changing train data changes tree- Require large no of splits for even simple relationships- Cannot extrapolate Linear Tree Supervised Regression/Classification Automatic Piecewise Polynomial \u274c \u274c Local Can extrapolate Linear Forest Supervised Regression/Classification Linear Boosting Supervised Regression/Classification Random Forest Supervised Regression/Classification Bagged Trees \u274c \u274c Local - Cannot extrapolate XGBoost Supervised Regression/Classification Boosted Trees \u274c \u274c Local - Cannot extrapolate CatBoost Supervised Regression/Classification Boosted Trees \u274c \u274c Local - Cannot extrapolate LightGBM Supervised Regression/Classification Boosted Trees \u274c \u274c Local - Cannot extrapolate Random Forest Proximity Supervised Missing value imputationAnomaly DetectionClustering K-MeansK-Medoids Unsupervised Clustering Euclidean distance assumes spherical clusters \u274c \u274c Gaussian Mixtures Unsupervised Clustering Hierarchical Clustering Unsupervised Clustering One-Many Clustering Unsupervised Clustering Graph Clustering Unsupervised Clustering KNN Unsupervised Anomaly Detection Kernel Density Estimation Unsupervised Anomaly Detection \u2705 Isolation Forest Unsupervised Anomaly Detection As contamination will mostly be unknownGet score without contamination offset(normalize for easier interpretation)Visualization1. rank by the score2. \u2060plot histogram of scores3. parallel coordinates \u274c Requires pre-specified contamination fraction One-Class SVM Unsupervised Anomaly Detection Autoencoders Unsupervised Anomaly detection via reconstruction loss Reconstruction loss will be high for anomalous events Kernel PCA, UMAP Unsupervised Dimensionality reductionAnomaly detection via reconstruction loss Cluster Analysis Unsupervised Anomaly Detection IDK Unsupervised Ranking/Scoring 1. Robust Scaler for \\(x_{ij}\\)2. \\(x_{ij} - \\min (x_{j}), \\forall j\\), to prevent unintended consequences in step 33. Convert into euclidean distance from origin4. Clustering5. Score - Discrete score: Larger distance of cluster center from origin - Continuous score: Not sure yet Q-Learning Re-Inforcement Learning \u274c \u274c"},{"location":"CS_Electives/Machine_Learning/22_Learning_Algorithms/#curse-of-dimensionality","title":"Curse of Dimensionality","text":"<p>As the no of dimensions increases, relative distances tend to 0</p> <p>Distance-based models are the most affected</p> <ul> <li>KNN</li> <li>K-Means</li> <li>Tree-based classification</li> <li>SVM?</li> </ul> \\[ \\begin{aligned} \\dfrac{d_a}{d_b} &amp;= \\dfrac{ \\sqrt{\\sum_j^k d^2_{a, j}} }{ \\sqrt{\\sum_j^k d^2_{b, j}} } \\\\ \\text{When } d \\to \\infty,  \\dfrac{d_a}{d_b} &amp;\\approx \\dfrac{ \\sqrt{d^2_{a, \\text{nominal}} + n^2k} }{ \\sqrt{d^2_{b, \\text{nominal}} + n^2k} } \\\\ &amp;\\approx 1  \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/","title":"Least Squares","text":""},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#ols-regression","title":"OLS Regression","text":"<p>OLS: Ordinary Least Squares</p> \\[ \\hat y = \\hat \\beta_0 + \\sum_{j=1}^k \\hat \\beta_j X_j \\] <ul> <li>\\(\\hat \\beta_0\\) is the value of \\(y\\) when \\(x_j=0, \\forall j \\in [1, k]\\)</li> <li>\\(\\hat \\beta_j\\) shows the change in \\(y\\) associated (not necessarily caused) with an increase of \\(X_j\\) by 1 unit</li> </ul> \\[ \\begin{aligned} \\hat \\beta &amp;= \\dfrac{\\text{Cov}(X, y)}{V(X)} \\\\ \\hat \\beta_0 &amp;= E[y] - E[X]' \\hat \\beta \\\\ \\text{Simple model} \\implies \\hat \\beta_1 &amp;= \\dfrac{\\sigma_{xy}}{\\sigma_x} \\\\ \\hat \\beta_0 &amp;= \\bar y - \\beta_1 \\bar x \\\\ \\end{aligned} \\] \\[ \\text{Frisch-Waugh-Lovell} \\\\ \\implies \\hat \\beta_j  = \\dfrac{\\sigma_{u_j, y}}{\\sigma_{u_j}} \\] <p>where \\(u_j\\) is the residual from a regression of \\(x_j\\) with all other features</p> <p>In vector form, $$ \\begin{aligned} \\hat \\beta &amp;= (X'X)^{-1} X' Y \\ \\hat \\beta_j &amp;=\\dfrac{{\\hat u_j}' Y}{{\\hat u_j}' \\hat u_j} \\</p> <p>(X'X) \\hat \\beta &amp;= X' Y &amp; \\text{(more stable numerically)} \\end{aligned} $$</p> <p>Mini-batch computation: May have small approximation error</p> \\[ \\begin{aligned} &amp;(X'X) \\approx \\sum_{g=1}^G (X'_g X_g) \\\\ &amp;(X'y) \\approx \\sum_{g=1}^G X'_g y_g \\\\ \\\\ \\implies &amp; \\hat \\beta \\approx \\left\\{ \\sum_{g=1}^G (X'_g X_g) \\right\\}^{-1} \\sum_{g=1}^G X'_g y_g \\\\ \\implies &amp; \\left\\{ \\sum_{g=1}^G (X'_g X_g) \\right\\}^{-1} \\hat \\beta \\approx \\sum_{g=1}^G X'_g y_g \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#properties","title":"Properties","text":"<ul> <li>Regression is performed with linear parameters</li> <li>Easy computation, just from the data points</li> <li>Point estimators (specific; not internal)</li> <li>Regression Line passes through \\((\\bar x, \\bar y)\\)</li> <li>Mean value of estimated values = Mean value of actual values \\(E(\\hat y) = E(y)\\)</li> <li>Mean value of error/residual terms = 0: \\(\\sum u_i = 0\\)</li> <li>Predicted value and residuals are not correlated with each other: \\(\\sum \\hat u_i \\hat y_i = 0\\)</li> <li>Error terms are uncorrelated \\(x\\): \\(\\sum \\hat u_i x_i = 0\\)</li> <li>Each \\(\\hat \\beta_j\\) is the slope coefficient on a scatter plot with \\(y\\) on the \\(y\\)-axis and \\(u_j^*\\) on the x-axis</li> <li>\\(u_j^*\\) isolates the value of \\(x_j\\) from other \\(x_i, i \\ne j\\)</li> <li>OLS is BLUE (Best Linear Unbiased Estimator)<ul> <li>Gauss Markov Theorem</li> <li>Linearity of OLS Estimators</li> <li>Unbiasness of OLS Estimators</li> <li>Minimum variance of OLS Estimators</li> <li>OLS estimators are consistent: They will converge to the true value as the sample size increases \\(\\to \\infty\\)</li> </ul> </li> <li>Gives the MLE with \\(u \\sim N(0, \\text{MSE})\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#geometric-interpretation","title":"Geometric Interpretation","text":"<p>OLS fit \\(\\hat y\\) is the projection of \\(y\\) onto the linear space spanned by \\(\\{ 1, x_1, \\dots , x_k \\}\\)</p> <p></p> <p>Projection/Hat Matrix $$ \\begin{aligned} \\hat Y &amp;= HY \\ H &amp;= X (X' X)^{-1} X' \\ H^2 &amp;= H \\ (I-H)^2 &amp;= (I-H) \\ \\text{trace}(H) &amp;= 1+p \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#asymptotic-variance-of-estimator","title":"Asymptotic Variance of Estimator","text":"<p>Using central limit theorem, $$ \\sqrt{n}(\\hat \\beta - \\beta) \\sim N(0, \\sigma_{\\hat \\beta}) \\ \\implies  \\dfrac{(\\hat \\beta - \\beta)}{\\sigma_{\\hat \\beta}} \\sim N(0, 1) $$</p> \\[ \\begin{aligned} \\sigma_{\\hat \\beta} &amp;= (X' X)^{-1} (X' \\ohm X) (X'X)^{-1} \\\\ \\ohm &amp;= \\text{diag}(\\hat e_1^2, \\dots, \\hat e^2_n) \\end{aligned} \\] <p>Assuming homoskedascity of errors $$ \\begin{aligned} \\sigma_{\\hat \\beta} &amp;= \\dfrac{\\text{MSE}}{\\hat u_j \\hat u_j} \\ &amp;= (X' X)^{-1} \\cdot \\text{MSE} \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#wls","title":"WLS","text":"<p>Weighted Least Squares</p>"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#irwls","title":"IRWLS","text":"<p>Iteratively ReWeighted Least Squares</p> <ol> <li>Run regression with all sample weights as 1 or with 1/effective variance</li> <li>Calculate custom loss for each data point (LAD, MAD, Huber, etc)</li> <li>Calculate weights as a inverse function of custom loss, wrt L2 loss</li> <li>Run weighted regression</li> <li>Repeated steps 2-4 until parameters converge (usually only 5-10 few iterations)</li> </ol> <p>Note: you can use any regression algorithm that supports weighting: WLS, Ridge, Lasso, RandomForest, etc.</p>"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#correlation-vs-r2","title":"Correlation vs \\(R^2\\)","text":"Correlation \\(R^2\\) Range \\([-1, 1]\\) \\([0, 1]\\) Symmetric? \u2705 \u274c \\(r(x, y) = r(y, x)\\) \\(R^2(x, y) \\ne R^2(y, x)\\) Independent on scale of variables? \u2705 \u2705 \\(r(kx, y) = r(x, y)\\) \\(R^2(kx, y) = R^2(x, y)\\) Independent on origin? \u274c \u2705 \\(r(x-c, y) \\ne r(x, y)\\) \\(R^2(x-c, y) \\ne R^2(x, y)\\) Relevance for non-linear relationship? \u274c \u2705 \\(r(\\frac{1}{x}, y) \\approx 0\\) \\(R^2(\\frac{1}{x}, y)\\) not necessarily 0 Gives direction of causation/association(not exactly the value of causality) \u274c \u2705"},{"location":"CS_Electives/Machine_Learning/23_Least_Squares/#isotonic-regression","title":"Isotonic Regression","text":"<p>Minimizes error ensuring increasing/decreasing trend only</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/24_IDK/","title":"IDK","text":"<p>Deriving the coefficients as a distribution</p> <p>Limitation: only works for a single parameter $$ n_\\text{eff} = \\dfrac{n(n-1)}{2} $$</p>"},{"location":"CS_Electives/Machine_Learning/24_IDK/#linear-fit","title":"Linear Fit","text":"\\[ \\begin{aligned} y &amp;= mx + c \\\\ \\implies m &amp;= \\dfrac{y_i-y_j}{x_i - x_j} \\sim \\text{pdf}(m) \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/24_IDK/#exponential-curve","title":"Exponential Curve","text":"\\[ \\begin{aligned} c_t &amp;= c_0 e^{kt} \\\\ k &amp;= \\dfrac{-\\ln \\vert c_i / c_j \\vert}{i-j} \\sim \\text{pdf}(k) \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/24_Piecewise_Regression/","title":"Piecewise Regression","text":"<p>Breaks input space into distinct regions and fits different relationship for each region.</p>"},{"location":"CS_Electives/Machine_Learning/24_Piecewise_Regression/#linear-basis-function-models","title":"Linear Basis Function Models","text":"\\[ \\begin{aligned} \\hat y &amp;= \\sum_{m=1}^M \\hat \\beta_m \\phi_m + u \\\\ &amp;= \\beta' \\Phi + u \\\\ &amp;= (\\Phi' \\Phi)^{-1} \\Phi' Y \\end{aligned} \\] <p>where \\(\\phi(x) =\\) basis function</p>"},{"location":"CS_Electives/Machine_Learning/24_Piecewise_Regression/#piecewise-constant-regression","title":"Piecewise Constant Regression","text":"<p>For every \\(x \\in R_m\\), we make the same prediction, which is simply the mean of the response values for the training observations in \\(R_m\\)</p> <ul> <li>Divide range of \\(x\\) into \\(m\\) regions by creating \\((m-1)\\) knots (cut-points) \\(\\epsilon_1, \\dots, \\epsilon_{M-1}\\)</li> <li>Construct dummy variables: \\(\\phi_m(x) = I(\\epsilon_{m-1} \\le x &lt; \\epsilon_m), \\forall m \\in M\\)</li> <li>Fit model \\(\\hat y = \\sum_{m=1}^M \\hat \\beta_m \\phi_m + u\\)</li> <li>\\(\\hat y = \\sum_{m=1}^M \\hat \\beta_m \\phi_m\\) is called as step function/piece-wise constant function</li> <li>\\(\\hat \\beta_m = \\bar y_m = \\dfrac{\\sum_{x_i \\in R_m} y_i}{n_m}\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/24_Piecewise_Regression/#piecewise-polynomial-regression","title":"Piecewise Polynomial Regression","text":""},{"location":"CS_Electives/Machine_Learning/24_Piecewise_Regression/#splines","title":"Splines","text":"<p>So we specify \\(\\alpha_{10} + \\alpha_{11} \\epsilon = \\alpha_{20}\\)</p> <p>Spline with one knot $$ \\hat y = \\beta_0 + \\beta_1 x + \\beta(x- \\epsilon)_+ + u $$ where</p> <ul> <li>\\(\\beta_0 = \\alpha_{10}, \\beta_1 = \\alpha_{11}, \\beta_2 = \\alpha_{21}-\\alpha_{11}\\)</li> <li>\\((x-\\epsilon)_+ = (x-\\epsilon) I (x \\ge \\epsilon)\\)</li> </ul> <p></p> <p></p> Limitation Spline Degree \\(d\\) spline is a piece-wise degree \\(d\\) polynomial with continuity in derivatives up to degree \\((d-1)\\) at each knot- Continuous- Smooth \\((d+m)\\) degrees of freedom\\((m-1)\\) knots High variance at boundary Natural Spline Function is linear beyond the boundary knots, to produce more stable estimates"},{"location":"CS_Electives/Machine_Learning/24_Piecewise_Regression/#generalized-additive-models","title":"Generalized Additive Models","text":"\\[ \\begin{aligned} \\hat y &amp;= w_0 + \\sum_{i=1}^k w_i(x_i) + u \\\\ w_j(x_j) &amp;= \\sum_{m=1}^{M_j} \\beta_{jm} \\phi_{jm} (x_j) \\end{aligned} \\] <p>Allow for flexible nonlinear relationships in each dimension of the input space while maintaining additive structure of linear models</p> <p>Can be fit using least squares, as it is a linear basis function model</p>"},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/","title":"Generalized Linear Model","text":""},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#condition","title":"Condition","text":"<p>GLM will give similar performance to directly optimizing the ideal loss function only when \\(n\\) is large</p>"},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#steps","title":"Steps","text":"<ol> <li>Let \\(y\\) have a probability distributions as long as it is from the exponential family</li> <li>Included<ul> <li>Normal, log-normal, exponential, gamma, chi-squared, beta, Bernoulli, poisson, binomial, etc</li> </ul> </li> <li>Not included:<ul> <li>Student\u2019s \\(t\\) due to heavy tails</li> <li>Mixed distributions (with different location/scale parameters)</li> </ul> </li> <li> <p>Allow for any transformation (link function) of \\(y\\), such that transformation is monodic and differentiable</p> </li> <li> <p>Write linear parameters</p> </li> <li> <p>Derive MLE</p> </li> </ol>"},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#transformations","title":"Transformations","text":"Distribution Typical Uses Link Name Link Function\\(x = g(y)\\) Prediction Function\\(\\hat y\\) Normal/Gaussian Linear response data Identity \\(y\\) \\(\\hat f\\) Bernoulli/Binomial Outcome of single yes/no occurence Logit(Logistic) \\(\\ln \\left \\vert \\dfrac{y}{1-y} \\right \\vert\\) \\(\\sigma(\\hat f)\\) Exponential/Gamma Exponential response dataScale parameters Negative Inverse \\(\\dfrac{-1}{y}\\) \\(\\dfrac{-1}{\\hat f}\\) Inverse Gaussian Inverse Squared \\(\\dfrac{1}{y^2}\\) \\(\\dfrac{1}{\\sqrt{\\hat f}}\\) Poisson Count of occurrences in fixed amount of time/space Log \\(\\ln \\vert y \\vert\\) \\(e^{\\hat f}\\) Negative Binomial Poisson with varying variance Quasi Normal with constant variance Quasi-binomial Binomial with constant variance Quasi-poisson Poisson with constant variance <p>Better to fit for Gamma than Poisson - Hard to determine optimal time interval for Poisson     - In scenarios where events occur in bursts or have high variability, the Poisson distribution may not adequately capture this overdispersion     - if many occurrences happen in a short time frame, using a large time interval with Poisson will result in this going unnoticed     - Gamma would flag these anomalies due to its flexibility in handling varying rates - Hard to determine optimal phase of interval for Poisson     - Starting at 00:00 vs 00:05 will give different results - You can invert the obtain \\(\\lambda\\) from Gamma and get the poisson distribution</p>"},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#uncertainty","title":"Uncertainty","text":""},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#delta-method","title":"Delta Method","text":"<p>Delta Method</p>"},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#transformation-method","title":"Transformation Method","text":"<p>Generalized linear model: https://fromthebottomoftheheap.net/2018/12/10/confidence-intervals-for-glms/</p> <p>Exponential regression confidence intervals will use similar logic</p> <p>Assume that \\(f\\) inside \\(e^f\\) is t-distributed with - mean 0 - std = model rmse (in the link space) - dof = \\(n-k\\)</p> <p>As this is time series,</p> \\[ \\begin{aligned} var(f_t+h) &amp;= \\sum_{i=1}^h var(f_t+i) \\\\ var(f_t+h) &amp;= h*var(f_t) \\end{aligned} \\] <p>Compute statistics independently in the link scale - Standard deviation - Quantiles - Confidence intervals</p> <p>Finally, back-transform each statistic independently to response scale</p>"},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#example","title":"Example","text":"<ul> <li>\\(y = a e^x\\)<ul> <li>\\(Q(y, q) = a e^{Q(x, q)}\\)</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/25_Generalized_Linear_Model/#bias-correction","title":"Bias Correction","text":"<p>All  - transformed targets fitted using OLS (whether or not for GLM) - optimizing for logarithmic loss functions</p> <p>Require bias correction for mean, as only median is maintained for monotonically-increasing Link functions</p>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/","title":"Logistic Regression","text":"<p>Logistic regression minimizes the cross-entropy error</p> <p>Uses Sigmoid Function and binary cross-entropy loss</p> <p>Decision of such a discriminant function is always singly-connected and convex. $$ \\begin{aligned} p(y=k) &amp;= \\dfrac{     \\exp(\\beta_k x) }{     \\sum_k^K \\exp(\\beta_k x) } \\ \\beta_0 &amp;= 0, \\beta_1 = 1 \\ \\implies p(y=1) &amp;= \\dfrac{     e^{x} }{     1 + e^{\\beta x} } \\ p(y=0) &amp;= \\dfrac{     1 }{     1 + e^{\\beta x} } \\ \\implies \\ln \\dfrac{P(y=j)}{P(y=k)} &amp;= (\\beta_j-\\beta_k)' X \\end{aligned} $$</p> \\[ \\begin{aligned} p &amp;= P(y=1|x) \\\\ &amp;= \\sigma(\\beta^T x) \\\\ &amp;= \\frac{1}{1 + \\exp(-\\beta^T x)} \\\\ \\implies \\beta^T x &amp;= \\text{logit}(p) \\\\ &amp;= \\ln \\left \\vert \\dfrac{p}{1-p} \\right \\vert \\end{aligned} \\] <p>$$ \\begin{aligned} \\hat \\beta &amp;= \\arg \\max_\\beta L(\\beta) \\</p> <p>&amp;= \\arg \\min_\\beta -\\log L(\\beta) &amp;= \\sum_{i=1}^n \\ln P(y_i \\vert x_i; \\beta) \\ -\\log L(\\beta) &amp;= \\sum_{i=1}^n y_i \\log \\sigma (x_i' \\beta) + (1-y_i) \\log(1- \\sigma(x_i' \\beta)) \\end{aligned} $$</p> <p>Logistic regression assumes that the log odds is a linear function</p> <p>We need to choose class \\(0\\) to be the reference level, and normalize \\(\\beta_0=0\\)</p> <p>Meaning: \\(\\exp( \\beta x')\\) is the probability of \\(y=1\\) relative to \\(y=0\\)</p>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#disadvantages","title":"Disadvantages","text":"<ol> <li>Decision boundary dependent on order of training data in mini-batches</li> <li>Suboptimal decision boundary: Does not give maximum-margin decision boundary</li> </ol>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#classification","title":"Classification","text":""},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#binary","title":"Binary","text":"\\[ \\begin{aligned} \\hat y &amp;= \\begin{cases} 1, &amp; p \\ge p_1 \\\\ 0, &amp; p \\le p_0 \\\\ \\text{Unsure} &amp; \\text{o.w} \\end{cases} \\\\ p_1 &amp;= \\dfrac{1}{1 + c} \\end{aligned} \\] <p>where</p> <ul> <li>\\(c =\\) relative cost of FN wrt FP (misclassifying \\(y=1\\) wrt \\(y=0\\))</li> <li>\\(c =\\) usually 1</li> <li>\\(p_0, p_1 =\\) thresholds</li> <li>\\(p_0, p_1\\) are commonly taken as 0.5</li> </ul>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#multi-class","title":"Multi-Class","text":"<p>Softmax function = generalized logistic function for multi-class</p> <p>Linear decision boundary $$ \\begin{aligned} p(y=j) &amp;= \\dfrac{\\exp(\\beta_j x)}{\\sum_k^K \\exp(\\beta_k x) } \\ \\ \\ln \\dfrac{P(y=j)}{P(y=k)} &amp;= (\\beta_j-\\beta_k)' X \\ \\implies \\ln \\dfrac{P(y=j)}{P(y=k)} &amp;= (\\beta_j)' X &amp; (\\beta_k = 0) \\end{aligned} $$ where \\(K\\) = number of classes</p> <p></p> <p>We need to choose one class \\(k\\) to be the reference level, and normalize \\(\\beta_k=0\\)</p> <p>Meaning: \\(\\exp( \\beta_j x')\\) is the probability of \\(y=j\\) relative to \\(y=k\\)</p>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#decision-boundary","title":"Decision Boundary","text":"<p>Decision boundary is obtained by solving for \\(P(y=k_i) = P(y=k_j)\\)</p> <p>The decision boundary between 2 classes does not depend on another class</p>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#class-share","title":"Class Share","text":"<p>Consider alternative \\(j\\) $$ \\begin{aligned} P(y_i=j) &amp;= \\int P(y_i=j \\vert x_i) f(x_i) \\cdot d x_i \\ &amp; \\approx \\dfrac{1}{n} \\sum_{i=1}^n P(y_i=j \\vert x_i) \\end{aligned} $$</p> <p>We can average individual conditional choice probabilities to get an estimate of the class share of each alternative in the population.</p>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#counterfactual-analysis","title":"Counterfactual Analysis","text":"<p>Logistic regression assumes IIA, hence does not take into account similarity of classes for evaluating class share when there is a class is added/dropped</p> <p>This assumption is fine for in-sample prediction, but inappropriate for counterfactual analysis</p>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#probabilistic-regression","title":"Probabilistic Regression","text":""},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#binary_1","title":"Binary","text":""},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#multi","title":"Multi","text":""},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#ols-vs-logistic","title":"OLS vs Logistic","text":"<p>OLS is not appropriate for classification</p> <ul> <li>OLS is not probabilistic, as it\u2019s range can be outside \\([0, 1]\\)</li> <li>OLS assumes \\(\\sigma^2_{y \\vert x} = \\sigma^2\\), but \\(\\sigma^2_{y \\vert x} = p(1-p)\\) in true Bernoulli distribution and hence is not constant</li> <li>OLS tries to find \\(\\hat y_i\\) close to \\(y_i\\), even though we just need \\(y_i = (\\hat y &gt; 0.5)\\)</li> <li>OLS is sensitive to outliers, due to large deviation and high cost function</li> <li>OLS penalizes cases where \\(y_i=1\\) and \\(\\hat y&gt;1\\), ie it penalizes predictions that are \u201ctoo correct\u201d</li> <li>OLS penalizes observations with large positive margins and hence is not a suitable loss function for classification</li> </ul> <p></p> <p></p> <ul> <li>Classes can be masked by others, especially when no of classes is large and no of predictors is small</li> <li>OLS estimates normal linear model, but classification has a distribution very different from Gaussian</li> <li><ul> <li>Decision boundaries produced by linear regression between 1 and 2 and between 2 and 3 are the same, so we would never predict class 2</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#idk","title":"IDK","text":"<p>Don\u2019t think of logistic/softmax regression as linear regression followed by logistic/softmax function</p> <p>Think of the logistic/softmax function embedded in the loss function itself</p>"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#odds","title":"Odds","text":"\\[ \\begin{aligned} \\text{Odds}  &amp;= \\dfrac{p(1)}{p(0)} \\\\ &amp;= \\dfrac{p}{1-p} \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/25_Logistic_Regression/#regularization","title":"Regularization","text":"<p>Regularization __ of probabilistic boundary - Increases width - Changes orientation - Changes position</p> <p></p> <p>\\(c = \\dfrac{1}{\\alpha}\\)</p>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/","title":"Bayesian Learning","text":"<p>Focus marginalization rather than optimization</p> <p>Rather than use a single setting of parameters \\(w\\), use all settings weighted by their posterior probabilities in a Bayesian model average</p> <p></p>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#advantages","title":"Advantages","text":"<p>Automatically calibrated complexity even with highly flexible models</p>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#limitations","title":"Limitations","text":"<p>Computationally-expensive for high dimensions</p>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#bayes-optimal-classifier","title":"Bayes Optimal Classifier","text":"<p>Given new instance \\(x\\)</p> <p>Consider \\(v=\\{v_1, v_2 \\}=\\{\\oplus, \\ominus \\}\\)</p> <p>The optimal classifier is given by</p> \\[ \\underset{v_j \\in V}{\\arg \\max} \\sum_{h_i \\in H} \\textcolor{hotpink}{P(v_j | h_i)} \\ P(h_i | D) \\]"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#disadvantage","title":"Disadvantage","text":"<p>Very costly to implement. We need to calculate a lot of probabilities</p>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#gibbs-algorithm","title":"Gibbs Algorithm","text":"<p>Consider we have multiple independent hypotheses</p> <ol> <li>Choose one hypothesis at random, according to \\(P(h|D)\\)</li> <li>Use this to classify new instance</li> </ol>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#disadvantage_1","title":"Disadvantage","text":"<p>Lower accuracy</p> <p>One more point in slide</p>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#naive-bayes","title":"Naive Bayes","text":""},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#bayesian-belief-network","title":"Bayesian Belief Network","text":""},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#bayesian-nn","title":"Bayesian NN","text":""},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#bayesian-classifier","title":"Bayesian Classifier","text":"<p>Called as \u2018Naive\u2019 classifier, due to following assumptions</p> <ul> <li>Empirically-proven</li> <li>Scales very well</li> </ul>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#naive-bayes-classification","title":"Naive Bayes Classification","text":"<p>Calculate posterior probability, based on assumption that all input attributes are conditionally-independent</p>"},{"location":"CS_Electives/Machine_Learning/26_Bayesian_Learning/#drawbacks","title":"Drawbacks","text":"<ol> <li>Doesn\u2019t work for continuous independent variable</li> <li>We need to use Gaussian Classifier</li> <li>Violation of Independence Assumption</li> <li>Zero outlook</li> </ol>"},{"location":"CS_Electives/Machine_Learning/27_SVM/","title":"Support Vector Machine","text":"<p>Goal: obtain hyperplane farthest from all sample points</p> <p>Larger margins \\(\\implies\\) fewer dichotomies \\(\\implies\\) smaller \\(d_\\text{vc}\\)</p> <p>Margin = Distance b/w boundary and edge point closest to it</p> <p>Note: \\(y \\in \\{ -1, 1 \\}\\), not \\(\\{ 0, 1 \\}\\)</p>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#hard-margin","title":"Hard Margin","text":"<p>Linearly-separable</p> <p>Consider \\(x_s\\) be the nearest data point to the plane \\(\\theta^T X + b=0\\)</p> <p>Constrain \\(\\theta: \\vert \\theta^T x_s + b \\vert = 1\\), so that we get a unique plane $$ \\underset{\\theta, \\gamma}{{\\arg\\max}}  \\gamma \\ \\text{subject to } \\min_{s} \\vert \\hat y_s \\vert = 1 %% \\text{subject to } y \\dfrac{\\hat y}{\\vert \\vert \\theta \\vert \\vert} \\ge \\gamma $$ Since \\(\\theta\\) is \\(\\perp\\) to the plane in the \\(x\\) space, margin = distance between \\(x_i\\) and the plane \\(\\theta^T X + b=0\\) is given by $$ \\begin{aligned} \\gamma &amp;= \\vert \\hat \\theta^T(x_i - x) \\vert \\ &amp;= \\left\\vert \\dfrac{\\theta}{\\vert \\vert \\theta \\vert \\vert} (x_i - x) \\right\\vert \\ &amp;= \\dfrac{1}{\\vert \\vert \\theta \\vert \\vert} \\vert \\theta^T x_i - \\theta^T x \\vert \\ &amp;= \\dfrac{1}{\\vert \\vert \\theta \\vert \\vert} \\vert (\\theta^T x_i + b) - (\\theta^T x + b) \\vert \\ &amp;= \\dfrac{1}{\\vert \\vert \\theta \\vert \\vert} \\vert 1 - 0 \\vert \\ &amp;= \\dfrac{1}{\\vert \\vert \\theta \\vert \\vert} \\end{aligned} $$</p> \\[ \\vert \\hat y_s \\vert = y_s \\hat y_s \\] <p>Optimization problem can be re-written as $$ \\begin{aligned} \\underset{\\theta}{\\arg \\max} \\frac{1}{\\vert \\vert \\theta\\vert \\vert} &amp; \\ \\text{Subject to constraint: } &amp;(\\hat y y) \\ge 1 \\quad \\forall i \\ =&amp; \\begin{cases} \\hat y \\ge 1, &amp; y_i &gt; 0 \\ \\hat y \\le -1, &amp; y_i &lt; 0  \\end{cases} \\end{aligned} $$</p> <p>Re-writing again $$ \\begin{aligned} \\underset{\\theta}{\\arg \\min} {\\vert\\vert \\theta \\vert\\vert}^2 &amp; \\ \\text{Subject to constraint: } &amp;(\\hat y y) \\ge 1 \\quad \\forall i \\ =&amp; \\begin{cases} \\hat y \\ge 1, &amp; y_i &gt; 0 \\ \\hat y \\le -1, &amp; y_i &lt; 0  \\end{cases} \\end{aligned} $$</p> <p>Re-writing again $$ \\begin{aligned} &amp;\\underset{\\theta}{\\arg \\min}  {\\vert\\vert \\theta \\vert\\vert}^2 - \\sum_\\mathclap{s \\in \\text{Sup Vec}}\\alpha_s \\Big( \\hat y y - 1 \\Big) \\ &amp; \\max \\alpha_s \\ge 0 \\quad \\forall s \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#limitations","title":"Limitations","text":"<ul> <li>Does not work for Non-separable problems</li> </ul>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#soft-marginhinge-loss","title":"Soft Margin/Hinge Loss","text":"<p>Non-separable</p> <p>Quantify margin violation: \\(y_i \\hat y_i \\le 1\\) not satisfied $$ y_i \\hat y_i \\ge 1-\\epsilon_i \\ \\epsilon_i \\ge 0 \\ \\implies \\text{Total violation} = \\sum_{i=1}^n \\epsilon_i $$</p> \\[ \\arg \\min_\\theta \\vert \\vert \\theta \\vert \\vert^2 + C \\sum_{i=1}^n \\epsilon_i \\\\ \\text{Subject to: } \\epsilon_i = \\max \\{ 0, 1 - y_i \\hat y_i \\} \\quad \\forall i \\] \\[ \\arg \\min_\\theta \\vert \\vert \\theta \\vert \\vert^2 + C \\sum_{i=1}^n \\max \\{ 0, 1 - y_i \\hat y_i \\} \\] <p>Since it doesn\u2019t matter which term we multiply by \\(c&gt;0\\), this is equivalent to $$ \\arg \\min_\\theta \\underbrace{L(y, \\hat y)}{\\mathclap{\\text{Hinge Loss}}} + \\underbrace{\\dfrac{\\lambda}{2}\\vert \\vert \\theta \\vert \\vert^2} $$}}</p> <p>Regularization optimizes for max margin</p>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#gradient","title":"Gradient","text":"\\[ \\nabla J(\\theta) = \\begin{cases} -y \\cdot x, &amp; y \\hat y &gt; 1 \\\\ 0, &amp; \\text{o.w} \\end{cases} \\]"},{"location":"CS_Electives/Machine_Learning/27_SVM/#types","title":"Types","text":"<ul> <li>Primal: better for large \\(n\\)</li> <li>Dual: better for large \\(k\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#types-of-svs","title":"Types of SVs","text":"Margin SV Non-Margin SV \\(\\alpha_s\\) \\(\\in (0, C)\\) \\(= C\\) \\(\\epsilon_i\\) \\(=0\\) \\(&gt;0\\)"},{"location":"CS_Electives/Machine_Learning/27_SVM/#generalization","title":"Generalization","text":"<p>Since the complexity of the plane only depends on the support vectors, \\(d_\\text{vc} = \\text{\\# of SVs}\\) $$ \\mathbb{E} [E_\\text{out}] \\le \\dfrac{\\mathbb{E}  [\\text{# of SV}]}{n-1} $$</p>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#kernel-trick","title":"Kernel Trick","text":"<p>Complex \\(h\\), but still simple \\(H\\), as complexity of plane only depends on support vectors</p> <p>Kernel function: \\(\\phi(x, x')\\) is valid \\(\\iff\\)</p> <ul> <li>It is symmetric</li> <li>Mercer\u2019s condition: Matrix \\([k(x_i, x_j)]\\) is +ve semi-definite</li> </ul> <p>Linear transformation function for Non-Linearly-Separable</p> <p>For eg, to increase the dimensionality, we can use \\(\\phi(x) = (x, x^2)\\)</p> Kernel Function \\(\\phi(x)\\) Linear \\(x\\) Polynomial \\((mx+c)^n\\) Gaussian \\(\\exp \\left( \\dfrac{-\\vert  x-y  \\vert^2}{2 \\sigma^2} \\right)\\)  where \\(\\sigma^2 =\\) Variance of sample RBF(Radial Basis Function)Most powerful, but not necessary in most cases \\(\\exp( -\\gamma \\vert  x_i - x_j  \\vert^2 )\\) <p>Interesting observation</p> <ul> <li>Features \\(\\phi(x)\\) are never used</li> <li>Only dot product \\(\\phi(x)^T \\phi(x)\\) is used</li> </ul> <p>We can compute dot product between \\(O(k^2)\\) features in \\(O(k)\\) time</p> <p>Implication</p> <ul> <li>Faster for high-dimensions</li> <li>Can be applied for any model class that use dot products</li> <li>Supervised: SVM, Linear Regression, Logistic regression</li> <li>Unsupervised: PCA, Density Estimation</li> </ul>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#advantages","title":"Advantages","text":"<ul> <li>Can handle high-dimensionality with lower computational cost</li> </ul>"},{"location":"CS_Electives/Machine_Learning/27_SVM/#disadvantage","title":"Disadvantage","text":"<ul> <li>Still computationally-expensive: \\(O(n^2)\\), as we need compute distance \\(\\phi(x_i, x_j) \\quad \\forall i, j\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/","title":"Decision Trees","text":"<p>Piecewise constant model that adaptively learns to divide predictor space into different regions, and then fits a model in each region, without human intervention for deciding the cuts</p> <p>Can be applied for regression and classification</p>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#advantages","title":"Advantages","text":"<ul> <li>Interpretable, for small trees</li> <li>Little data processing required</li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#disadvantages","title":"Disadvantages","text":"<ul> <li>Small trees are not powerful</li> <li>Large trees tend to overfit, and are hard to regularize</li> <li>Do not work well for modelling linear relationships</li> <li>Cannot extrapolate well</li> <li>Decision regions tend to be highly-fragmented</li> <li>Resulting function (also Decision boundary for classification) is very non-smooth and blocky</li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#terms","title":"Terms","text":"Term Meaning Internal Nodes Labelled by attributes names, to be tested on an attributeContain the splitting attributes Leaf/Terminal Nodes Labelled by class labels Edges determined by the nuo of outcomes on n attribute test conditions Size Number of leaves"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#goal","title":"Goal","text":"<p>Find cuts to obtain \\(R_m\\) and improve in-sample fit, while minimizing out-of-sample loss</p> <p>Since it is computationally-infeasible to consider every possible partition of the predictor space, we adopt a forward stepwise procedure</p>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#decision-tree-approaches","title":"Decision Tree Approaches","text":"Approach Steps Disadvantage Greedy Divide the problem into different steps, take decisions at each stepBuild tree in Top-Down mannerSplit train set into purer subsets (the best split) @ every node Backtracking is not possible Recursive"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#regression-tree","title":"Regression Tree","text":"\\[ \\begin{aligned} \\hat y &amp;= \\sum_{m=1}^M \\hat y_m \\cdot I \\{ x \\in R_m \\} \\\\ \\hat y_m &amp;= \\underset{x_i \\in R_m}{\\text{mean}} \\ (y_i) \\end{aligned} \\] <p>where</p> <ul> <li>\\(M =\\) no of leaves = no of regions</li> <li>\\(R_m =\\) region \\(m\\)</li> <li>\\(n_m=\\) no of obs in \\(R_m\\)</li> </ul> <p>For every observation that falls into the region Rm, we make the same prediction, which is simply the mean of the response values for the training observations in \\(R_m\\)</p>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#cart-algorithm","title":"CART Algorithm","text":"<p>Greedy recursive partitioning algorithm that divides predictor space through successive binary splits, until a stopping criterion is reached.</p> <p>This is greedy because at each step of the tree-building process, the optimal split is made at that particular step, rather than looking ahead and picking a split that will lead to a better tree in some future step</p>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#steps","title":"Steps","text":"<ol> <li> <p>At each step, generate binary split to divide predictor space into two regions that achieves the biggest reduction in \\(E_\\text{in}\\)</p> </li> <li> <p>The 2 regions are as homogenous in response \\(y\\) as possible</p> <ul> <li>\\(R_\\text{left} = \\{ x \\in R: x_j &lt; s \\}\\)</li> <li>\\(R_\\text{right} = \\{ x \\in R: x_j \\ge s \\}\\)</li> </ul> </li> <li> <p>For regression this means choosing \\(j, s\\) such that</p> <p>\\(\\arg \\min\\limits_{j, s} \\left \\{ \\sum \\limits_{x_j \\in R_\\text{left}} L(y_i, \\hat y_\\text{left}) + \\sum \\limits_{x_j \\in R_\\text{right}} L(y_i, \\hat y_\\text{right}) \\right \\}\\)</p> </li> <li> <p>Prune the tree by choosing a subtree \\(T \\subset T_0\\) that minimizes</p> </li> </ol> <p>\\(\\sum \\limits_{m=1}^{\\vert T \\vert} \\sum \\limits_{x_j \\in R_m} L(y_i, \\hat y_m) + \\alpha \\vert T \\vert, \\quad \\forall \\alpha \\ge 0\\)</p> <ul> <li>\\(\\vert T \\vert =\\) size of tree</li> <li>\\(\\alpha\\) controls tradeoff b/w subtree\u2019s complexity and fit to training data<ul> <li>\\(\\alpha=0 \\implies T=T_0\\)</li> <li>\\(\\vert T \\vert \\propto \\dfrac{1}{\\alpha}\\)</li> <li>Optimal \\(\\alpha\\) obtained through cross-validation</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#classification-tree","title":"Classification Tree","text":"\\[ \\begin{aligned} \\hat y &amp;= \\sum_{m=1}^M \\hat c_m \\cdot I (x \\in R_m) \\\\ \\hat c_m &amp;= \\underset{x_i \\in R_m}{\\text{mode}} \\ (y_i) \\end{aligned} \\] <p>\\(\\hat c_m =\\) most frequent class in \\(R_m\\) </p>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#node-impurity","title":"Node Impurity","text":"Misclassification Rate \\(1 - {\\hat p}_m\\) Gini-Index \\(\\sum \\limits_c^C \\hat p_c^m (1 - \\hat p_c^m)\\) Cross-Entropy \\(- \\sum \\limits_c^C \\hat p_c^m \\cdot \\ln \\hat p_c^m\\)"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#steps_1","title":"Steps","text":"<ol> <li> <p>Pick an independent variable</p> </li> <li> <p>Find Entropy of all classes of that independent variable</p> </li> </ol> \\[ H(C_i) = -P_\\text{Pos} \\log_2 (P_\\text{Pos}) -P_\\text{Neg} \\log_2 (P_\\text{Neg}) \\] <ol> <li>Calculate gain of each independent variable for current set/subset of data</li> </ol> \\[ \\begin{aligned} &amp;\\text{Gain}\\Big( \\text{Value}(C_1), C_2 \\Big) \\\\ =&amp; H \\Big(\\text{Value}(C_1) \\Big) \\\\    &amp; - \\left[ \\sum_{i=1} \\frac{n (C_2=\\text{Value}_i)}{n \\Big(\\text{Value}(C_1) \\Big)} \\times H(C_2=\\text{Value}_i) \\right] \\end{aligned} \\] <ol> <li> <p>Pick the independent variable with the highest gain</p> </li> <li> <p>Recursively repeat for each independent variable</p> </li> </ol>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#hunts-algorithm","title":"Hunt\u2019s Algorithm","text":"<p>Let</p> <ul> <li>\\(t\\) be a node</li> <li>\\(D_t\\) be train dataset @ node \\(t\\)</li> <li> <p>\\(y\\) be set of class labels \\(\\{ C_1, C_2, \\dots, C_n \\}\\)</p> </li> <li> <p>Make node \\(t\\) into a leaf node. Label \\(t\\) with class label \\(y_t\\)</p> </li> <li>Split using appropriate attribute</li> <li>Apply splitting criteria for each attribute and obtain impurity of split using that attribute</li> <li>Pick the attribute that gives the lowest impurity</li> <li>Label the node \\(t\\) with this attribute</li> <li>Determine the outcomes</li> <li>Create nodes for each outcome</li> <li>Draw the edges</li> <li>Split the dataset</li> <li>Repeat the steps for each subtree now</li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#additional-cases","title":"Additional Cases","text":""},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#empty-subset","title":"Empty Subset","text":"<p>Let\u2019s say when splitting your data, you end up having an empty subset of the data</p> <ol> <li>Make node \\(t\\) into a leaf node</li> <li>\\(t\\) is labelled as the majority class of the parent dataset</li> </ol>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#all-records-have-identical-attribute-values","title":"All records have identical attribute values","text":"<ol> <li>Make \\(t\\) into a leaf node</li> <li>\\(t\\) is labelled as the majority class represented in the current subset</li> </ol>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#number-of-records-fall-below-minimum-threshold-value","title":"Number of records fall below minimum threshold value","text":"<ul> <li>Make \\(t\\) into a leaf node</li> <li>\\(t\\) is labelled as the majority class represented in the current subset</li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#splitting-continuous-attributes","title":"Splitting Continuous Attributes","text":""},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#binary-split","title":"Binary Split","text":"<p>Choose a splitting value that results in a purer partition</p>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#multi-way-split","title":"Multi-Way Split","text":"<ul> <li>Apply discretization</li> <li>Each bin will be a different node</li> </ul> <pre><code>flowchart LR\n\nsubgraph Multi-Way Split\ndirection TB\ns2((Salary))\n\na2(( ))\nb2(( ))\nc2(( ))\nd2(( ))\ne2(( ))\n\ns2 --&gt;|&lt; 10k| a2\ns2 --&gt;|10k - 30k| b2\ns2 --&gt;|30k - 50k| c2\ns2 --&gt;|50k - 80k| d2\ns2 --&gt;| &gt; 80k| e2\nend\n\nsubgraph Binary\ndirection TB\ns1((Salary))\n\nend</code></pre>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#challenges","title":"Challenges","text":"<ul> <li>How to split training records?</li> <li>Find best splitting attribute (Test on Attribute)</li> <li>Measure for goodness of split</li> <li>Stopping conditions   Stop at situations that result in fully-grown tree (the tree has learnt all the important characteristics, which may not be optimal; in that case we may require some other stopping conditions)<ul> <li>When all records at a node have the same attribute value</li> <li>When all records at a node have the same class label value</li> <li>When a node receives an empty subset</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#attribute-test-condition-and-outcomes","title":"Attribute Test Condition and Outcomes","text":""},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#nominal","title":"Nominal","text":"<p>Binary split will have \\(2^{k-1} - 1\\) combinations of the binary split, where \\(k=\\) no of values. For eg:</p> <pre><code>flowchart LR\n\nsubgraph 1\ndirection TB\naa[Attribute] --&gt; v1a[v1] &amp; notv1a[\"Not v1 &lt;br&gt; (v2 or v3 or v4)\"]\nend\n\nsubgraph 2\ndirection TB\nab[Attribute] --&gt; v1b[v1 or v2] &amp; notv1b[\"Not (v1 or v2) &lt;br&gt; (v3 or v4)\"]\nend</code></pre>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#missed-this-class","title":"Missed this class","text":"<p>Lec20.pdf </p>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#terms_1","title":"Terms","text":"<p>Variables</p> \\[ \\Delta = I(Parent) - \\sum_{j=1}^k \\underbrace{ \\frac{N(V_j)}{N} I (V_j) }_\\text{Weighted Average Impurity} \\] <ul> <li>\\(I(\\text{Parent}) =\\) Impurity at parent</li> <li>\\(N =\\) no of records before split (parent)</li> <li>\\(k =\\) no of splits</li> <li>\\(V_j =\\) denote a split</li> <li>\\(N(V_j) =\\) no of records at split \\(V_j\\)</li> <li>\\(I(V_k) =\\) impurity at child(split) \\(V_j\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#steps-to-choose-splitting-attribute","title":"Steps to choose splitting attribute","text":"<ul> <li>Compute degree of impurity of parent node (before splitting)</li> <li>Compute degree of impurity of child nodes (after splitting)</li> <li>Compute weighted average impurity of split</li> <li>Compute gain \\((\\Delta)\\)   Larger the gain, better the test condition</li> <li>Choose attribute with largest gain</li> <li>Repeat for all attributes</li> </ul>"},{"location":"CS_Electives/Machine_Learning/28_Decision_Trees/#note","title":"Note","text":"<p>Information gain means the impurity measure is entropy</p>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/","title":"Gaussian Classifier","text":"\\[ \\begin{aligned} P(y=c|x) &amp; = \\dfrac{P(x, y=c)}{P(x)} \\\\ &amp; = \\dfrac{P(x|y=c) \\times P(y=c)}{P(x)} \\\\ &amp; \\propto P(x|y=c) \\times P(y=c) \\end{aligned} \\] <p>We assume Normally-distributed</p>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#gaussian-mixture","title":"Gaussian Mixture","text":"<p>A mixture of \\(K\\) Gaussians is a distribution \\(p(x)\\) of the form $$ p(x) = \\sum_{k=1}^K p_k N(x; \\mu_k, \\Sigma_k) $$ where</p> <ul> <li>\\(N\\) is a multi-variate Gaussian distribution</li> <li>\\(\\Sigma_k =\\) covariance</li> <li>\\(p_k =\\) probability of \\(x\\)</li> </ul> <p></p>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#gaussian-discriminant-analysis","title":"Gaussian Discriminant Analysis","text":"<p>Also called Quadratic Discriminant Analysis, as the shape of the decision boundary is quadratic</p> <p>Hence, if we have \\(C\\) classes $$ \\begin{alignedat}{1} p(x, y) &amp;= \\sum_{c=1}^c \\hat p(y=c) &amp;&amp;\\cdot \\hat p(x \\vert y=c) \\ &amp;= \\sum_{c=1}^C p_c &amp;&amp;\\cdot N(x; \\mu_c, \\Sigma_c) \\end{alignedat} $$ Guessing parameters</p> <p></p> <p>For \\(C\\) Classes, there are \\(3C\\) parameters $$ \\begin{aligned} \\hat \\theta &amp; = { \\ &amp; \\mu_1, \\Sigma_1, p_1 \\ &amp; \\dots \\ &amp; \\mu_C, \\Sigma_C, p_C \\ } \\end{aligned} $$</p> \\[ \\begin{aligned} \\mu_c &amp;= E[x \\vert y = c] \\\\ \\Sigma_c &amp;= \\Sigma[x \\vert y = c] \\\\ p_c &amp;= \\dfrac{n_c}{n} \\end{aligned} \\]"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#special-cases","title":"Special Cases","text":"<ul> <li>LDA: \\(\\Sigma_k = \\text{same}\\)</li> <li>Gaussian Naive Bayes: \\(\\Sigma_k = \\text{diagonal}\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#bernoulli-naive-bayes","title":"Bernoulli Naive Bayes","text":"<ul> <li>\\(P(y):\\) categorical distribution</li> <li>\\(P(x_j \\vert y):\\) Bernoulli distribution</li> </ul>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#assumption","title":"Assumption","text":"<p>Assume that every input var is independent of each other $$ \\begin{aligned} &amp;p(x_j \\vert y)  \\perp p(x_{\\centernot j} \\vert y) \\ \\implies &amp;p(x \\vert y) = \\prod_{j=1}^k p(x_j \\vert y) \\end{aligned} $$ \\(p(x_j \\vert y)\\) is assumed as Bernoulli distribution, hence there is only one parameter for each input var</p> <p>\\(p(x \\vert y)\\) has only \\(k\\)\u00a0parameters in total</p>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#why","title":"Why?","text":"<p>To handle discrete input data of high dimensionality</p> <p>Solution: assume that \\(x\\) is sampled from a categorical distribution that assigns a probability to each possible state of \\(x\\)</p> <p>However, if the dimensionality of \\(x\\) is too high, \\(x\\) can take a large domain of values. Hence, we would need to specify \\((C_j)^k-1\\) parameters for the categorical distribution, where</p> <ul> <li>\\(C_j=\\) no of classes in discrete variable \\(x_j\\)</li> <li>\\(k=\\) no of dimensions</li> </ul>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#limitations","title":"Limitations","text":"<ul> <li>This is not a perfect assumption, as inputs may be correlated with each other for eg in NLP</li> <li>\u201cDoctor\u201d will be accompanied with \u201cPatient\u201d in the same \u2018bag of words\u2019</li> </ul>"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#idk","title":"IDK","text":"\\[ \\begin{aligned} \\ln \\mathcal{L}(x \\vert C) &amp;= \\ln \\mathcal{L}(x \\vert \\mu_c, \\sigma_c^2) \\\\ &amp;= \\ln P(x \\vert \\mu_c, \\sigma_c^2) \\\\ \\end{aligned} \\] \\[ \\ln \\underbrace{\\mathcal{L} (C|x)}_{\\mathclap {\\text{Posterior}}} = \\ln \\underbrace{\\mathcal{L}(x|C)}_{\\mathclap {\\text{Likelihood}}} + \\ln \\underbrace{\\mathcal{L} (C)}_{\\mathclap{\\text{Posterior}}} \\]"},{"location":"CS_Electives/Machine_Learning/29_Gaussian_Classifier/#2-classes","title":"2 Classes","text":"\\[ \\begin{aligned} \\ln \\frac{P(C_1 | x)}{P(C_2 | x)} &amp;= \\ln P(C_1 | x) - \\ln P(C_2 | x) \\\\ &amp;= \\frac{-1}{2} () \\end{aligned} \\] <ul> <li>If log ratio \\(\\ge 0\\), assign to \\(C_1\\)</li> <li>If log ratio \\(&lt;0\\), assign to \\(C_2\\)</li> </ul> <p>We need to ensure that we have equal sample of both classes, so that the prior probabilities of both the classes in the formula is the same.</p>"},{"location":"CS_Electives/Machine_Learning/30_KNN/","title":"\\(k\\) Nearest Neighbor","text":"<p>Represents each record as a datapoint with \\(m\\) dimensional space, where \\(m\\) is the number of attributes</p>"},{"location":"CS_Electives/Machine_Learning/30_KNN/#requirements","title":"Requirements","text":"<ul> <li>Set of labelled records</li> <li>Normalized Proximity/Distance metric</li> <li>Min-Max normalization</li> <li>\\(Z\\)-normalization</li> <li>Odd value of \\(k\\)</li> </ul>"},{"location":"CS_Electives/Machine_Learning/30_KNN/#choosing-k","title":"Choosing \\(k\\)","text":"<p>Similar to bias-variance tradeoff $$ \\begin{aligned} \\text{Flexibility} &amp;\\propto \\dfrac{1}{k} \\</p> <p>\\implies \\text{Bias} &amp;\\propto k \\ \\text{Variance} &amp;\\propto \\dfrac{1}{k} \\end{aligned} $$</p>"},{"location":"CS_Electives/Machine_Learning/30_KNN/#value-of-k","title":"Value of \\(k\\)","text":"\\(k\\) Problems Low Bias Low Variance too small OverfittingSusceptible to noise \u2705 \u274c too large UnderfittingSusceptible to far-off points: Neighborhood includes points from other classes \u274c \u2705 <p>Finding optimal \\(k\\) 1. Use a test set 2. Let \\(k = 3\\) 3. Record error rate of regressor/classifier 4. \\(k = k+2\\) 5. Repeat steps 3 and 4, until value of \\(k\\) for which    1. error is min    2. accuracy is maximum</p>"},{"location":"CS_Electives/Machine_Learning/30_KNN/#types","title":"Types","text":"Classification Regression Output Class label is the majority label of \\(k\\) nearest neighbors Predicted value will be the average of the continuous labels of \\(k\\)-nearest neighbors Steps - Compute distance between test record and all train records- Identify \\(k\\) neighbors of test records  (Low distance=high similarity)- Use majority voiting to find the class label of test sample"},{"location":"CS_Electives/Machine_Learning/30_KNN/#distance-weighted-knn","title":"Distance-Weighted KNN","text":"<p>Closer points are given larger weights for the majority voting scheme</p>"},{"location":"CS_Electives/Machine_Learning/30_KNN/#efficient-knn-loocv","title":"Efficient KNN LOOCV","text":"<ul> <li>Tie-breaking condition<ul> <li>For all i, j = 1, . . . , n with i \u0338= j, we have xi \u0338= xj and dX (x\u2113, xi) \u0338= dX (x\u2113, xj ) for all \u2113 = 1, . . . , n.</li> </ul> </li> <li>Under the tie-breaking condition, the LOOCV estimate of the mean square error for \\(k\\)-NN regression is identical to the mean square error of \\((k+1)\\)-NN regression evaluated on the training data, multiplied by the scaling factor \\(\\dfrac{(k+1)^2}{k^2}\\)</li> <li>Therefore, to compute the LOOCV score, one only needs to fit \\((k+1)\\)-NN regression only once, and does not need to repeat training-validation of \\(k\\)-NN regression for the number of training data</li> <li>https://openreview.net/forum?id=SBE2q9qwZj</li> </ul>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/","title":"Ensemble Learning","text":"<p>Reduce variance of models</p> <p>Why do they work</p> <ul> <li>Statistical: Average predictions</li> <li>Computational: Average local optima</li> <li>Representational: Extend hypothesis space</li> </ul> <p></p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#advantages","title":"Advantages","text":"<ul> <li>Improved accuracy</li> <li>Reduced variance</li> <li>Noisy useless signals will average out and have no effect</li> </ul>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#disadvantages","title":"Disadvantages","text":"<ul> <li>Not interpretable</li> <li>Do not work with unstructured data (images, audio)</li> <li>Computationally-expensive</li> </ul>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#steps","title":"Steps","text":"<ol> <li>Divide dataset into subsets</li> <li>For each subset, apply a model<ul> <li>This model is usually decision tree</li> </ul> </li> <li>Aggegrate the results</li> </ol>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#stability-of-classifier","title":"Stability of Classifier","text":"<p>For unstable models, we have to change model when adding new point</p> <p>For stable models, not required</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#learning-techniques","title":"Learning Techniques","text":"Single Bagging(Boostrap aggregation) Boosting Boosted Bagging Boosted Bagging Blending/Stacking/Voting Training sequence N/A Parallel Sequential Sequential+Parallel Parallel+Sequential Parallel/Sequential Forward stage-wise also to fit an adaptive additive model (adaptive basis functions) Sequentially boost parallelly-built forests Parallelly bag sequentially-built trees \\(\\hat f = \\sum_{m=1}^{M} \\alpha_i \\hat f_i\\) Individual Learners Overfitting UnderfittingSlightly better than average No of learners 1 \\(p\\) \\(q\\) \\(p \\times q\\) \\(q \\times p\\) \\(n\\) Training Complete training Random sampling with replacement Random sampling with replacement over weighted data Aggregage the results at the end Only pass over the mis-classified pointsWe boost the probability of mis-classified points to be picked again Preferred for Linear Data Non-Linear Data Example Random forest XGBoost Comment - Only effective for low-bias, high-variance models- Only effective if misclassification rate of individual classifiers &lt;0.5 Training Speed Fast Fast (parallel training) Slow(but boosting may require significantly fewer 10 base estimators) Support custom loss functions \u274c \u274c \u2705 \u2705 \u2705 Advantages Disadvantages OverfittingNot recommended Do not support custom loss functions Overfitting Example Decision TreeExtra Tree Random ForestExtra Trees AdaBoostXGBoostLightGBMCatBoost Boosted Random ForestBoosted Extra Trees Bagging AdaBoostBagging XGBoostBagging LightGBMBagging CatBoost"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#bagging","title":"Bagging","text":"<p>\u201cWisdom of the crowds\u201d</p> <p>Bagged classifier\u2019s misclassification rate behaves like a binomial distribution</p> <p>Bagging a good classifier can improve predictive accuracy, but bagging a bad one hurts $$ \\text{Variance}' = \\dfrac{1}{k} \\text{Variance} + \\dfrac{k-1}{k} C $$ where \\(C=\\) covariance between each bagging classifier</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#classification","title":"Classification","text":"\\(\\hat y_i\\) Majority/Hard Vote Soft Voting"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#random-forest","title":"Random Forest","text":"<p>Bagging with reduced correlation b/w sampled trees, through random selection of input variables \\(m&lt;&lt;k\\) for each split</p> <p>Usually \\(m = \\sqrt{p}\\)</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#proximity-matrix","title":"Proximity Matrix","text":"<p>Similarity/Distance matrix can be derived from the individual trees, which can be used for - Clustering - Anomaly detection</p> <p>Make sure to specify an appropriate group (hierarchy/target) to effectively calculate average proximity</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#boosting","title":"Boosting","text":"<p>\\(\\lambda\\) is the learning rate</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#regression","title":"Regression","text":"<ol> <li> <p>Set \\(\\hat f(x) = 0 \\implies u_i = y_i \\quad \\forall i\\)</p> </li> <li> <p>For \\(b=1, \\dots, B:\\)</p> </li> <li> <p>Fit a regression model \\(\\hat f_b(x)\\) to the training data to obtain \\(\\hat y_b\\)</p> </li> <li> <p>Update \\(\\hat y\\) with a shrunken version of \\(\\hat f_b\\): \\(\\hat y = \\hat y + \\lambda \\hat y_b\\),</p> </li> <li> <p>Update the residuals: \\(u_i = u_i - \\lambda \\hat y_b\\)</p> </li> <li> <p>Output: \\(\\hat y = \\sum_{b=1}^B \\lambda \\hat y_b\\)</p> </li> </ol> <p>In each iteration, we fit the model to residuals: this enables re-weighting training data so that obs that did not fit well (\\(r_i\\) large)  become more imp in next iteration.</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#classification_1","title":"Classification","text":"<p>**Ada**ptive **Boost**ing</p> <p>The boosted classifier is a weighted sum of individual classifiers, with weights proportional to each classifier\u2019s accuracy on the training set (good classifiers get more weight)</p> <p>In AdaBoost, if an individual classifier has accuracy &lt; 50%, we flip the sign of its predictions and turn it into a classifier with accuracy &gt; 50%. This is achieved by making \\(\\alpha_b\\) &lt; 0 so that the classifier enters negatively into the final hypothesis.</p> <p>In each iteration, we re-weight the obs in the training data such that misclassified points in the previous round see their weights increase compared to correctly classified points. Hence, successive classifiers focus more on misclassified points.</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#steps_1","title":"Steps","text":"<ol> <li> <p>Let \\(y \\in \\{ -1, 1 \\}\\)</p> </li> <li> <p>Let \\(w_i = 1/n \\quad \\forall i\\)</p> </li> <li> <p>For \\(b= 1, \\dots, B\\)</p> </li> <li> <p>Fit a classifier \\(\\hat f_b\\) to the training data by minimizing the weighted error</p> <p>\\(\\dfrac{\\sum_{i=1}^n w_i (\\hat y_b \\ne y_i)}{\\sum_{i=1}^n w_i}\\)</p> </li> <li> <p>Let \\(\\alpha_b = \\log \\vert (1-\\epsilon_b)/\\epsilon_b \\vert\\) where \\(\\epsilon_b\\) is the weighted error of \\(\\hat f_b (x)\\)</p> </li> <li> <p>\\(L_i = \\exp \\Big( \\alpha_b (\\hat y_b \\ne y_i) \\Big)\\)</p> </li> <li> <p>Update \\(w_i\\)</p> <p>\\(w_i = w_i \\cdot L_i\\)</p> </li> <li> <p>Output: \\(\\hat y = \\text{sign} (\\sum_{b=1}^B \\alpha_b \\cdot \\hat y_b)\\)</p> </li> </ol>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#optimization","title":"Optimization","text":"<p>Instead of doing a global minimization, the boosting strategy follows a forward stage-wise procedure by adding basis functions one by one</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#stage-wise-vs-step-wise","title":"Stage-wise vs step-wise","text":"Stage-wise Step-wise Coefficients updated at each step One All Optimality Worse Better Computation Cost Low High"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#additive-boosting","title":"Additive Boosting","text":"\\[ \\hat f = \\sum_{l=1}^L \\alpha_l \\hat f_l(x; \\theta_l) \\] <p>Where \\(\\hat f_l\\) is linear/non-linear</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#fsam","title":"FSAM","text":"<p>Forward Stage-wise Additive Modeling</p> <p>At each iteration for learner \\(l\\)</p> \\[ \\arg \\min \\limits_{\\alpha_l, \\theta_l} \\sum_{i=1}^n \\mathcal L \\Big( y_i, \\underbrace{\\hat f_{[\\small {1, l-1}]}(x_i)}_{\\mathclap{\\text{Constant}}} +  \\alpha_l \\hat f_{l}(x_i, \\theta_l) \\Big) \\]"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#limitations","title":"Limitations","text":"<ul> <li>Greedy search: local search; We may miss something better</li> <li>May overfit</li> <li>Optimization is computationally expensive</li> </ul>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#extratrees","title":"ExtraTrees","text":"<p>Extremely Randomized Trees</p> <p>Similar to Random Forest, but results in trees that are less correlated with each other, by selecting splits randomly from the range of feature values</p> Random Forest Extra Trees Computational Speed Slower due to optimal splits Faster due to random splits Data Sampling Bootstrapped samples Entire dataset without replacement Node Splitting Optimal split Random split Bias Higher bias potential Lower bias potential Variance Medium Low"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#gradient-boosting","title":"Gradient Boosting","text":"<p>Performs functional optimization of the cost function: Functional gradient descent with approximate gradients $$ \\begin{aligned} \\hat f_e(x) &amp; \\leftarrow \\hat f_{e-1}(x) - \\eta \\nabla_f J(f) \\ \\hat f_0(x) &amp;= 0 \\end{aligned} $$ Works with any differentiable loss function</p>"},{"location":"CS_Electives/Machine_Learning/31_Ensemble_Learning/#neural-networks","title":"Neural Networks","text":"<ul> <li>Average predictions of multiple model checkpoints across epochs of single model</li> <li>Model averaging across epochs</li> </ul>"},{"location":"CS_Electives/Machine_Learning/32_KMeans_Clustering/","title":"K-Means","text":"<p>Input: \\(k =\\) number of clusters</p> <p>Output: Set of \\(k\\) clusters</p>"},{"location":"CS_Electives/Machine_Learning/32_KMeans_Clustering/#steps","title":"Steps","text":"<ol> <li> <p>Normalize \\(X\\)</p> </li> <li> <p>Randomly choose \\(k\\) objects from the dataset as the initial cluster centroids    (centroid = center of a cluster)</p> </li> <li> <p>For each of the objects</p> </li> <li> <p>Compute distance between current objects and \\(k\\) cluster centroids</p> </li> <li> <p>Assign current object to that cluster to which it is closest</p> <p>If distance of a point between 2 clusters is same, then we assign the point to first centroid.</p> </li> <li> <p>Compute \u2018cluster centers\u2019 \\(m\\) of each cluster. These become the new cluster centroids</p> </li> </ol> \\[ \\begin{aligned} m_k &amp;= \\Big(\\text{mean}(X), \\text{mean}(Y) \\Big) \\\\ X &amp;= \\text{List of } x \\text{ coordinates} \\\\ Y &amp;= \\text{List of } y \\text{ coordinates} \\end{aligned} \\] <ol> <li> <p>Repeat steps 2-3 until convergence criterion is satisfied</p> </li> <li> <p>Stop</p> </li> </ol>"},{"location":"CS_Electives/Machine_Learning/32_KMeans_Clustering/#convergence-criterion","title":"Convergence Criterion","text":"<ul> <li>Particular number of iterations   We can derive this by testing and plotting graph of accuracy vs iterations</li> </ul> <p>or</p> <ul> <li>when clusters don\u2019t change over subsequent iterations</li> </ul>"},{"location":"CS_Electives/Machine_Learning/32_KMeans_Clustering/#limitations","title":"Limitations","text":"<ul> <li>Clustering stuck in local minima: convergence dependent on initialization</li> <li>Measuring clustering quality is hard &amp; relies on heuristics</li> <li>Non-probabilistic: Cluster assignment is binary</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_Gaussian_Mixture_Clustering/","title":"Gaussian EM K-Means Clustering","text":"<p>Probabilistic clustering which requires K means as well; the output of k means is fed into this model</p>"},{"location":"CS_Electives/Machine_Learning/33_Gaussian_Mixture_Clustering/#em-for-gaussian-mixture","title":"EM for Gaussian Mixture","text":"<p>Alternates between 2 steps</p> <ol> <li>E-Step: Given an estimate \\(\\theta_e\\)\u00a0of the weights, compute \\(P_\\theta(y \\vert x_i)\\) and use it to \u2018hallucinate\u2019 expected cluster assignments \\(z_i\\)</li> <li>M-Step: Find a new \\(\\theta_{e+1}\\) that maximizes the marginal log-likelihood by optimizing \\(P_\\theta(x_i, z_i)\\) given the \\(z_i\\) from step 1</li> </ol> \\[ \\begin{aligned} \\theta_{e+1} &amp;= \\arg \\max_\\theta \\sum_{i=1}^n \\mathbb E_{z_i \\sim P_{\\theta_e} (y \\vert x_i)} \\log P_\\theta(x_i, z_i) \\\\ &amp;= \\arg \\max_\\theta \\sum_{i=1}^n \\sum_{c=1}^C P_{\\theta_e}(y=c \\vert x_i) \\log P_\\theta(x_i, y=k) \\end{aligned} \\] \\[ \\begin{aligned} P_\\theta(y=c \\vert x) &amp;= \\dfrac{P_\\theta (y=c, x)}{P_\\theta(x)} \\\\ &amp;= \\dfrac{P_\\theta (y=c) P_\\theta (x \\vert y=c)}{ \\sum_{c=1}^C P_\\theta (y=c) P_\\theta (x \\vert y=k) } \\end{aligned} \\] <ol> <li>Go to step 1</li> </ol> <p>This process increases the marginal likelihood at each step and eventually converges</p>"},{"location":"CS_Electives/Machine_Learning/33_Gaussian_Mixture_Clustering/#advantages","title":"Advantages","text":"<ul> <li>Easy to implement</li> <li>Guaranteed to converge?</li> <li>Works for many ML models</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_Gaussian_Mixture_Clustering/#limitations","title":"Limitations","text":"<ul> <li>Can get stuck in local optima</li> <li>May not be able to compute \\(P_{\\theta_e} (y \\vert x_i)\\)\u00a0in each model</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_Gaussian_Mixture_Clustering/#steps","title":"Steps","text":"<p>Expectation Maximization</p> <ol> <li> <p>Initialize gaussian parameters \\(\\mu_k, \\Sigma_k, \\pi_k\\)</p> </li> <li> <p>\\(\\mu_k \\leftarrow \\mu_k\\)</p> </li> <li>\\(\\Sigma_k \\leftarrow \\text{cov \\(\\Big(\\) cluster(\\)k\\() \\(\\Big)\\)}\\)</li> <li> <p>\\(\\pi_k = \\frac{\\text{No of points in } k}{\\text{Total no of points}}\\)</p> </li> <li> <p>E Step: Assign each point \\(X_n\\) an assignment score \\(\\gamma(z_{nk})\\) for each cluster \\(k\\)</p> </li> </ol> \\[ \\gamma(z_{nk}) = \\frac{ \\pi_k N(x_n|\\mu_k, \\Sigma_k) }{ \\sum_{i=1}^K \\pi_i N(x_n|\\mu_i, \\Sigma_i) } \\] <ol> <li>M Step: Given scores, adjust \\(\\mu_k, \\pi_k, \\Sigma_k\\) for each cluster \\(k\\)</li> </ol> \\[ \\begin{aligned} \\text{Let } N_k &amp;= \\sum_{n=1}^N \\gamma(z_{nk}) \\\\ N &amp;= \\text{Sample Size} \\\\ \\mu_k^\\text{new} &amp;= \\frac{1}{N_k} \\sum_{n=1}^N \\gamma(z_{nk}) x_n \\\\ \\Sigma_k^\\text{new} &amp;= \\frac{1}{N_k} \\sum_{n=1}^N \\gamma(z_{nk}) (x_n - \\mu_k^\\text{new}) (x_n - \\mu_k^\\text{new})^T \\\\ \\pi_k^\\text{new} &amp;= \\frac{N_k}{N} \\end{aligned} \\] <ol> <li>Evaluate log likelihood</li> </ol> \\[ \\ln p(X| \\mu, \\Sigma, \\pi) = \\sum_{n=1}^N \\ln \\left| \\sum_{k=1}^K \\pi_k N(x_n | \\mu_k, \\Sigma_k) \\right| \\] <ol> <li>Stop if likelihood/parameters converge</li> </ol>"},{"location":"CS_Electives/Machine_Learning/33_Gaussian_Mixture_Clustering/#k-means-vs-gaussian-mixture","title":"K Means vs Gaussian Mixture","text":"K means Gaussian Mixture Classifier model Probability model Probabilistic? \u274c \u2705 Classifier Type Hard Soft Pamater to fit to data \\(\\mu_k\\) \\(\\mu_k, \\Sigma_k, \\pi_k\\) \u274c Disadvantage If a class may belong to multiple clusters, we have to assign the first oneIf sample size is too small, initial grouping determines clusters significantly Complex \u2705 Advantage SimpleFast and efficient, with \\(O(tkn),\\) where- \\(t =\\) no of iterations- \\(k =\\) no of clusters- \\(n =\\) no of sample points If a class may belong to multiple clusters, we have a probability to back it up"},{"location":"CS_Electives/Machine_Learning/33_KDE/","title":"Density Estimation","text":""},{"location":"CS_Electives/Machine_Learning/33_KDE/#histogram-de","title":"Histogram DE","text":"<p>Limitations</p> <ul> <li>No of grid cells inc exponentially with dimensionality \\(k\\)</li> <li>Histogram is not \u2018smooth\u2019</li> <li>Shape of histogram depends on bin positions</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_KDE/#kde","title":"KDE","text":"<p>Kernel Density Estimation</p> <p>Hyperparameter: Bandwidth \\(w\\)</p> <p></p> <p>Histogram has \\(b\\) bins of width \\(w\\) at fixed positions</p> <p>KDE effectively places a bin of width \\(w\\) at each \\(x \\in \\mathcal X\\)</p> <p>To obtain \\(P(x)\\), we count the % of points that fall in the bin centered at \\(x\\)</p>"},{"location":"CS_Electives/Machine_Learning/33_KDE/#tophat-kde","title":"Tophat KDE","text":"\\[ \\begin{aligned} P_w(x) &amp;= \\dfrac{n(x ; w)}{n} \\\\ n(x ; w) &amp;= \\Bigg\\vert \\Big\\{ x_i: \\vert \\vert x_i - x \\vert \\vert \\le w/2 \\Big\\} \\Bigg\\vert \\end{aligned} \\] <p>\\(n(x; w)=\\) no points that are within a bin of width \\(w\\) centered at \\(x\\)</p> <p>To make it smooth, replace histogram counts with weighted averages $$ P(x) \\propto \\sum_{i=1}^n K(x, x_i) $$ Interpretation</p> <ul> <li>We count the no of points \u2018near\u2019 \\(x\\), but each \\(x_i\\) has a weight \\(K(x, x_i)\\) that depends on the similarity between \\(x\\) and \\(x_i\\)</li> <li>We place a \u2018micro-density\u2019 \\(K(x, x_i)\\) at each \\(x_i\\); the final density \\(P(x)\\)\u00a0is their sum</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_KDE/#common-kernels","title":"Common Kernels","text":"<ul> <li>Linear</li> <li>Gaussian</li> <li>Tophat</li> <li>Epanechnikov</li> <li>Exponential</li> <li>Cosine</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_KDE/#advantages","title":"Advantages","text":"<ul> <li>Can approximate any data distribution arbitrarily well</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_KDE/#disadvantages","title":"Disadvantages","text":"<ul> <li>No of datapoints required for a good fit increases exponentially with dimensionality</li> <li>High space complexity: Need to store entire dataset to make queries</li> </ul>"},{"location":"CS_Electives/Machine_Learning/33_Recommender_Systems/","title":"Recommendation Systems","text":"<p>Goal: Identify item(s) most relevant to a user</p>"},{"location":"CS_Electives/Machine_Learning/33_Recommender_Systems/#types","title":"Types","text":"Focus Free from New User Cold Start Problem Free from New Item Cold Start Problem Personalized Contextual(eg: time of day) Scalable Rank Popularity-based Top items \u2705 \u274c \u274c \u2705 \u2705 \u2705 Classifier Predict if each item would be liked or not \u2705 \u2705 \u2705 \u274c \u274c Content-based filtering Recommend similar items \u274c \u274c \u2705 \u2705 \u26a0\ufe0f \u2705 User-based Recommend items that similar users liked Collaborative Item-based filtering Recommend similar items, given co-occurence of purchases \u274c \u274c \u2705 \u2705 \u26a0\ufe0f \u2705 Collaborative User-based filtering Recommend items that similar users liked, given purchase history \u274c \u274c \u2705 \u2705 \u26a0\ufe0f \u2705 Matrix Factorization/Model-based collaborative filtering Perform collaborative filtering on a low-dimensional spaceSplit original sparse matrix into constituent dense- learnt embedding space for user matrix- learnt embedding space for item matrix \u274c \u274c \u2705 \u2705"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/","title":"Anomaly Detection","text":"<ul> <li>Outliers/Leverage: training data contamination</li> <li>Novelty: new data different from training data</li> </ul> <p>Check out Anomalous Points</p> <p>Residual technique - Perform robust regression, then inspect residuals wrt MAD of all residuals     - Will not work if the model is not robust - IDK     - For identifying high leverage (X outliers)         - Perform non-linear regression of \\(x_j\\) on all other cols: ineffective for more than 1 outlier             - \\(\\hat x_j = f(X_{-j}, y)\\)             - If anomaly, then remove             - Perform for each \\(j\\)     - For identifying X novelties         - Perform non-linear regression of \\(x_j\\) on all other available cols             - \\(\\hat x_j = f(X_{-j})\\), as usually \\(y\\) will not be available             - If anomaly, then remove             - Perform for each \\(j\\)</p>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#limitations","title":"Limitations","text":"<ul> <li>False positives are a problem</li> <li>No temporal coherence: several anomalous events in sequence do not get priority over the same events randomly sampled in time</li> </ul>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#note","title":"Note","text":"<ul> <li>When using AD as a secondary model to filter data for the primary model, you need not use the same input features for both</li> <li>Anomaly detection could be used on variables that are not directly to the output<ul> <li>Even if variable \\(w\\) does not affect \\(y\\), the change in \\(Z\\) could mean that<ul> <li>\\(Z\\) is a cause of \\(y\\), with unknown relationship with \\(y\\): obviously important to detect change in system</li> <li>\\(Z\\) is an effect modifier, but unknown relationship: the structural relationship between \\(X\\) and \\(y\\) could change</li> <li>the structural relationship governing the entire system including \\(X\\) and \\(y\\) could have changed</li> </ul> </li> </ul> </li> </ul> <p>Let</p> <ul> <li>\\(\\mathcal{X}, \\mathcal{y} \\in \\mathcal{D}\\) be all the data you have</li> <li>\\(\\mathcal{X}_a\\) be used for primary model</li> <li>\\(X_b\\) be used for anomaly detection</li> </ul> <p>Then, all these perfectly reasonable - \\(\\vert \\mathcal{X}_a \\vert  = \\vert \\mathcal{X}_b \\vert\\) - \\(\\vert \\mathcal{X}_a \\vert &gt; \\vert \\mathcal{X}_b \\vert\\) - \\(\\vert \\mathcal{X}_a \\vert &lt; \\vert \\mathcal{X}_b \\vert\\)</p>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#univariate","title":"Univariate","text":"<ul> <li>IQR</li> <li>MAD</li> </ul>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#density-estimation","title":"Density Estimation","text":""},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#procedure-methodology","title":"Procedure Methodology","text":"Training Only non-anomalous samples Validation Verify with known values, then validate, and then update model Testing Verify with known values and then test"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#anomaly-detection-vs-classification","title":"Anomaly Detection vs Classification","text":"Anomaly Detection Classification Anomalous training samples requirement None(only required for tuning) Large Non-anomalous training samples requirement Large Large Can handle novelties \u2705 \u274c Example Unseen defectsFraud Known defects (scratches)Spam mail"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#feature-engineering","title":"Feature Engineering","text":"<p>Include features that have very small/large values for anomalies</p> <p>If anomalies don\u2019t have such values, then try to find a combination of features such as \\(x_1 \\cdot x_2\\) to achieve it</p>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#dealing-with-non-gaussian-features","title":"Dealing with Non-Gaussian Features","text":"<p>Transformation of training, validation, and test set.</p> <p></p> <p>If you have x values as 0, then \\(\\log(x)\\) as \\(\\log(0)\\) is undefined. So you use \\(\\log(x+c)\\), where \\(c&gt;0\\)</p>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#categorical-events","title":"Categorical Events","text":"<p>Challenge: No metric space allowing comparison</p> <p>Solution: Self-supervised learning</p>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#idk","title":"IDK","text":"<ul> <li>Clustering<ul> <li>Dimensionality reduction using local retention algorithm: UMAP, t-SNE</li> <li>Clustering using hierarchical and density-based: HDBScan</li> </ul> </li> <li>Dimensionality reduction reconstruction loss<ul> <li>Kernel PCA</li> <li>UMAP</li> <li>Auto-encoder</li> </ul> </li> <li>Clustering in Dimensionality reduction embedding space</li> <li>Take in all features<ul> <li>For every col and multiplicative and divisive interaction, calculate min and max</li> </ul> </li> </ul>"},{"location":"CS_Electives/Machine_Learning/34_Anomaly_Detection/#idk_1","title":"IDK","text":"<p>Iterative outlier detection 1. Detect outliers 2. Handle them - remove/winsorize 3. Go to step 1</p>"},{"location":"CS_Electives/Machine_Learning/36_Active_Learning/","title":"Active Learning","text":"<pre><code>---\ntitle: Active Learning\n---\nflowchart LR\n1[Label&lt;br/&gt;small sample] --&gt;\n2[Train&lt;br/&gt;model] --&gt;\n3[Predict&lt;br/&gt;unlabelled] --&gt;\n4[\"Query Selection&lt;br/&gt;(Rank poor predictions)\"] --&gt;\n1</code></pre>"},{"location":"CS_Electives/Machine_Learning/36_Active_Learning/#query-selection-strategies","title":"Query Selection Strategies","text":"Type Strategy Measure Advantage Heuristic Uncertainty Sampling Least confidentSmallest marginHighest entropy QBC (Query By Committee) Vote entropy of enseble models Expected Model Change Gradient of loss function wrt parameters Expected Error Reduction Variance Reduction Density Weighted Methods Average similarity to entire unlabelled pool of examples Outliers ignored Approximate Posterior Monte-Carlo Dropout Stochastic Weight Modelling"},{"location":"CS_Electives/Machine_Learning/37_Gaussian_Processes/","title":"Gaussian Processes","text":""},{"location":"CS_Electives/Machine_Learning/38_Data-Centric/","title":"Data-Centric","text":"<ul> <li>Confident learning</li> </ul>"},{"location":"CS_Electives/NLP/","title":"Natural Language Processing","text":""},{"location":"CS_Electives/NLP/#references","title":"References","text":"<ul> <li> Natural Language Processing Specialization</li> <li> Natural Language Processing | University of Utah</li> <li> Natural Language Processing with Deep Learning | Stanford</li> <li> Natural Language Understanding | Stanford XCS224U</li> <li> Natural Language Processing | Michael Collins</li> <li> Natural Language Processing | University of Michigan</li> <li> Text Mining and Analytics [FULL COURSE] | UIUC</li> <li> Text Retrieval and Search Engines | UIUC</li> <li> NLP and Text Mining | TU Dortmund</li> <li> Text Mining | Orange Data Mining</li> </ul>"},{"location":"CS_Electives/NLP/01_Text_Classification/","title":"Text Classification","text":"<ul> <li>Devise features by hand: Does the message contain \u201cchurch\u201d. Does the email contain an Indian organization\u2019s domain</li> <li>Bag of words: Count of occurrences off each word of a pre-defined \u2018vocabulary\u2019</li> </ul> <p>Pre-Processing</p> <ul> <li>Stemming: only keep the root of the word</li> <li>\u201cslowly\u201d and \u201cslow\u201d both mapped to \u201cslow\u201d</li> <li>Filtering</li> <li>Stopwords: articles</li> <li>Filler words</li> <li>rare words</li> </ul> \\[ \\begin{aligned} \\text{tf(term)} &amp;= \\dfrac{n_\\text{term}}{n_\\text{terms in document}} \\\\ \\text{idf(term)} &amp;= \\ln \\left \\vert \\dfrac{n_\\text{documents}}{n_\\text{documents containing term}} \\right \\vert \\\\ \\text{tf-idf(term)} &amp;= \\text{tf(term)} \\times \\text{idf(term)} \\end{aligned} \\]"},{"location":"CS_Electives/NLP/02_Topic_Modelling/","title":"Topic Modelling","text":""},{"location":"CS_Electives/NLP/02_Topic_Modelling/#lda","title":"LDA","text":"<p>Topic words</p>"},{"location":"CS_Electives/NLP/03_Sentiment_Analysis/","title":"Sentiment Analysis","text":""},{"location":"CS_Electives/NLP/04_Fingerprinting/","title":"Fingerprinting","text":""},{"location":"CS_Electives/NLP/04_Fingerprinting/#tf-idf","title":"TF-IDF","text":"<p>How unique a word in a document is in a pool of multiple documents</p>"},{"location":"CS_Electives/NNFL/","title":"Neural Networks &amp; Fuzzy Logic","text":""},{"location":"CS_Electives/NNFL/#references","title":"References","text":"<ul> <li> NOC Jan 2019: Fuzzy Logic and Neural Networks | IIT Kharagpur</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/","title":"Optimization for ML","text":""},{"location":"CS_Electives/Optimization_for_AI/#references","title":"References","text":"<ul> <li> Convex Optimization | Stanford</li> <li> Adaptive and Cooperative Algorithms; Search Algorithms; Game Theory | University of Waterloo</li> <li> Optimization Methods for Machine Learning and Engineering | Julius Pfrommer</li> <li> Optimization in Machine Learning 2022 | Ganesh Ramakrishnan</li> <li> Optimization | CMU Machine Learning</li> <li> https://mmas.github.io/optimization-scipy</li> <li> https://scipy-lectures.org/advanced/mathematical_optimization/</li> <li> Deep Learning Optimizers</li> <li> Optimization Techniques - W2023</li> <li> Convex Optimization for AI | Han Dean | CMU</li> <li> Optimization | Se Young Yun</li> <li> Convex Optimization | Stanford</li> <li> Optimization | Constantine Caramanis</li> <li> Nonlinear Optimization | Abhishek Gupta</li> <li> Nonlinear and Dynamic Programming | Abhishek Gupta</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/","title":"Optimization","text":"<p>Find a set of parameters that minimizes the loss function for the given data and algorithm</p> \\[ \\underset{\\theta}{\\arg \\min} \\ L( \\ y, \\hat f_\\theta(D) \\ ) \\] <p></p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#idk","title":"IDK","text":"<p>Always test optimization procedure on known solution</p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#training-process","title":"Training Process","text":"<pre><code>flowchart LR\ni[Initialize \u03b8] --&gt;\nj[Calculate cost function] --&gt;\na{Acceptable?} --&gt;\n|Yes| stop([Stop])\n\na --&gt;\n|No| change[Update \u03b8] --&gt;\nj</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#steps","title":"Steps","text":"<ul> <li>Forward pass</li> <li>Backward pass</li> <li>Weights update</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#optimization-parameters","title":"Optimization Parameters","text":""},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#objective-function","title":"Objective Function","text":"<p>An objective function has a unique global minimum if it is</p> <ul> <li>differentiable</li> <li>convex</li> </ul> <p></p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#hard-constraints-and-bounds","title":"Hard Constraints and Bounds","text":"<p>Useful if you know the underlying systematic differential equation</p> <p>$$ \\text{DE} = 0 $$ Refer to PINNs for more information</p> <p>When it is not possible to use a discontinuous hard constraint/bound (such as \\(\\beta \\ge k\\)), you can add a barrier function to the cost function $$ J' = J + B $$ where \\(B\\) can be</p> <ul> <li>Exponential barrier: \\(\\pm \\exp \\{ m (\\beta - k) \\}\\)</li> <li>where \\(m=\\) barrier coefficient</li> </ul> <p></p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#soft-constraints-regularization","title":"Soft Constraints: Regularization","text":"<p>Encourages (not guaranteed) certain parameters to end in range values, through penalizing deviation from prior/preferred values</p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#weights-initialization-algorithm","title":"Weights Initialization Algorithm","text":"<ul> <li>Zero (bad)</li> <li>Random</li> <li>Glorot (Xavier)</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#nature-of-optimization","title":"Nature of Optimization","text":"Matrix/Normal Equation Iterative Matrix Iterative Hybrid Use Normal method first then Iterative Matrix \\(\\alpha\\) not required \u2705 \u2705 \u274c \u274c Feature scaling not required \u2705 \u2705 \u274c \u274c No of iterations to converge \\(1\\) \\(i_1 \\in [1, 10]\\) \\(i_2 \\in [100, \\infty)\\) \\(i_1 + i_2\\) Space Complexity for each iteration \\(O(kn^2)\\) \\(O(kn^2)\\) \\(O(kn)\\) \\(O(kn^2)\\) Time Complexity \\(O(n^3)\\) \\(O(i_1 kn^3)\\) \\(O(i_2 kn^2)\\) \\(O(i_1 kn^3) + O(i_2 kn^2)\\) Time to converge:Large datasets \\((n &gt; 10^4)\\) Slower Slower Faster Slower Time to converge:Small datasets Faster Faster Slower Fastest Compatibility Doesn\u2019t work for classification Works for all algorithms No of features Doesn't work when \\(X^TX\\) is non-invertible Works for all algorithms Stop criteria None Loss Function Necessary Properties Convex ConvexDouble-differentiable (some algos) Double-differentiable Global Optimal guaranteed \u2705 \u2705 \u274c \u2705 Good Initialization requirement Not required Approximate Very strict Approximate Example Weighted Least Squares Iteratively ReWeighted Least SquaresNewton-CGNewton-CG Gradient Descent <p>Gradient-based methods find min of a function by moving in the direction in which the function decreases most steeply</p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#optimization-algorithms","title":"Optimization Algorithms","text":"<p>Optimization Algorithms</p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#batch-size","title":"Batch Size","text":"Optimizer Meaning Comment Gradient-Free Weight Update Rule\\(w_{t+1}\\) Advantages Disadvantages BGD(Batch Gradient Descent) Update weights after viewing the entire dataset: \\(n\\) sample points \u274c Guaranteed convergence to local minimum Computationally-expensive for large datasetProne to getting stuck at non-optimal local minima for non-convex cost functions SGD(Stochastic Gradient Descent) Update weights after viewing every sample point \u274c \\(w_t - \\eta g(w_t)\\) Cheaper computationFaster updatesRandomization helps escape \u2018shallow\u2019 local minima May not converge to global minima for non-convex cost functionsNoisy/Oscillating/Erratic convergence MBGD(Mini-Batch Gradient Descent) Update weights after viewing the \\(b\\) sample points, where \\(b &lt; n\\)Usually \\(b=32\\) Middle ground between BGD and SGDGeneralizes better than Adam \u274c Mini-Batch without update Accumulate gradients across batches and then make final updatesIt might be expensive to keep track of all losses, so take cumulative sum of cost and then divide by total number of samples"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#speed-up-training","title":"Speed Up Training","text":"<ul> <li>Subsetting</li> <li>Feature-scaling</li> <li>Pruning</li> <li>Good Weight initialization</li> <li>Good Activation functions</li> <li>Transfer learning: Re-use parts of pre-trained network</li> <li>Using mini-batch updates</li> <li>Learning rate scheduling</li> <li>Faster optimization algorithm</li> <li>Use GPU/TPU</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#subsetting","title":"Subsetting","text":"<ol> <li>Sample Size</li> <li>Mini-Batch</li> <li>Stochastic</li> <li>Input Features</li> </ol> <p>You can do either</p> <ul> <li>drop with both approaches</li> <li>Bagging with each sub-model using the subset</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#feature-scaling","title":"Feature Scaling","text":"<p>Helps to speed up gradient descent by making it easier for the algorithm to reach minimum faster</p> <p>Get every feature to approx \\(-1 \\le x_i \\le 1\\) range</p> <p>Atleast try to get \\(-3 \\le x_i \\le 3\\) or \\(-\\frac13 \\le x_i \\le \\frac13\\)</p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#standardization","title":"Standardization","text":"\\[ \\begin{aligned} x'_i &amp;= z_i \\\\ &amp;= \\frac{ x_i - \\bar x }{s} \\end{aligned} \\]"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#learning-rate","title":"Learning Rate","text":""},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#convex-function","title":"Convex Function","text":"<p>Convex function is one where $$ \\begin{aligned} f(\\alpha x + \\beta y) &amp;\\le \\alpha f(x) + \\beta f(y) \\ \\alpha + \\beta &amp;= 1; \\alpha, \\beta \\ge 0 \\end{aligned} $$</p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#robust-optimization","title":"Robust Optimization","text":""},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#limitations","title":"Limitations","text":"<ul> <li>Parameters must be independent</li> <li>Cannot handle equality constraints</li> <li>Hard to estimate min and max value of parameter</li> <li>Method is extremely conservative</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#batch-size_1","title":"Batch Size","text":""},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#resources","title":"Resources","text":"<p>Let \\(b=\\) batch size $$ \\begin{aligned} \\text{Space Requirement} &amp;\\propto \\dfrac{1}{b} \\ \\text{Time Requirement} &amp;\\propto b \\end{aligned} $$</p> <ul> <li>Larger batch size means larger memory required to train a single batch at one time</li> <li>Larger batch size means fewer updates per epoch</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#generalization","title":"Generalization","text":"<p>The following is only empirically-proven $$ \\begin{aligned} \\text{Generalization} &amp;\\propto \\dfrac{1}{b} \\end{aligned} $$ The noise from smaller batch size helps escape suboptimal local minimum</p> <p></p> <p></p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#learning-rate_1","title":"Learning Rate","text":"<p>Should be scaled according to batch size $$ \\text{LR}' = \\text{LR} \\times (b/32) $$</p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#batching","title":"Batching","text":"<p>When training a neural network, we usually divide our data in mini-batches and go through them one by one. The network predicts batch labels, which are used to compute the loss with respect to the actual targets. Next, we perform backward pass to compute gradients and update model weights in the direction of those gradients.</p> <ul> <li>Full dataset does not fit in memory</li> <li>Faster convergence due to stochasticity</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#approaches-to-obtain-gradient","title":"Approaches to obtain gradient","text":"<ul> <li>Exact: Use matrix differential calculus, Jacobians, Kronecker products, &amp; vectorization</li> <li>Approximation</li> <li>Pretend everything everything is a scalar</li> <li>use typical chain rule</li> <li>rearrange/transpose matrices/vectors to make the sizes work</li> <li>verify result numerically </li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#initialization","title":"Initialization","text":"<p>Initialization is very important: Weights don\u2019t move \u201cthat much\u201d, so weights tend often stay much closer to initial points than to the \u201cfinal\u201d point after optimization from different initial point</p> <p>If you initialize all the weights as 0, ANN will not learn anything - all your gradients will be the same - all the parameter updates will be the same Ideally this is what we want</p> \\[ W_{t=0} = N(0, \\sigma^2 I) \\] <p>Kaiming Normal Initialization: based on central limit theorem, we want the entire distribution to become \\(N(0, 1)\\)</p> <p>Poor initialization can lead to vanishing gradients</p> Problem Visualization Vanishing Exploding <p>The choice of \\(\\sigma^2\\) will affect</p> <ol> <li>Magnitude/Norm of forward activations</li> <li>Magnitude/Norm of gradients</li> </ol> \\(\\sigma^2\\) Norms Too low Vanishing Optimal Right Too high Exploding <p></p> <p>Here \\(n=\\) no of neurons</p> \\(\\sigma = \\sqrt{\\dfrac{\\text{Gain}}{n}}\\)Gain = Linear \\(1\\) Sigmoid \\(1\\) Tanh \\(5/3\\) RELU \\(\\sqrt{2}\\) Because ReLU will cause half the components of the activations to be set to 0, so we need twice the variance to achieve the same final variance <p>Even when trained successfully, the effects/scales present at initialization persist throughout training</p> <p></p>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#solution","title":"Solution","text":"<p>Normalization just before activation function </p> <p></p> BatchNormalization LayerNormalization GroupNormalization Normalize activations of each feature across all inputs at a layer in a mini-batch each input across all features at a layer in a mini-batch \\(\\hat w_{i}\\) \\(\\tilde w_i = \\dfrac{w_{i} - E_b[w_{i}]}{\\sqrt{\\sigma^2_b(w_{i}) + \\epsilon}}\\)\\(\\gamma_i \\tilde w_i + \\beta_i\\): allows network to learn optimal distribution for activation function, and/or undo batch norm \\(\\dfrac{w_{i} - E_i[w_{i}]}{\\sqrt{\\sigma^2_i(w_{i}) + \\epsilon}}\\) Visualization Advantages - Improves gradient flow through network- Allows for higher learning rates- Reduces strong dependence on initialization- Acts as a form of regularization due to stochastic inter-dependence of samples, and slightly reduces need for dropout Limitation Inter-dependence of training samples causes unwanted effects (Soln: below) Harder to train standard FCN to low loss, because the relative sizes between activations is lost <p>Where</p> <ul> <li>\\(i=\\) layer number</li> <li>\\(\\epsilon={10}^{-5}\\)</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#soln","title":"Soln","text":"<ol> <li>Training: Compute running average of mean \\(\\hat \\mu_{i+1}\\) &amp; variance \\(\\hat \\sigma^2_{i+1}\\) for all features at each layer</li> <li>Inference: Normalize by these quantities</li> </ol> \\[ (w'_{i+1})_j = \\dfrac{(w_{i+1})_j - (\\hat \\mu_{i+1})_j}{(\\hat \\sigma_{i+1})_j + \\epsilon} \\]"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#stopping-criteria","title":"Stopping Criteria","text":"<p>Use an <code>or</code> combination of the following</p> <ul> <li>\\(J(\\theta) \\le\\)  Cost Threshold</li> <li>\\(\\vert J(\\theta)_e - J(\\theta)_{e-1} \\vert \\le\\) Convergence threshold</li> <li>where \\(e=\\) epochs</li> <li> <p>Moving average of the previous 5?</p> </li> <li> <p>Evaluation metric \\(\\le\\) Evaluation threshold</p> </li> <li>This may be different from the cost function</li> <li>MSE for cost; MAPE for evaluation</li> <li>\\(n_{\\text{iter}} \\ge\\) Iter Threshold</li> <li>Time taken \\(\\ge\\)  Duration threshold</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#idk_1","title":"IDK","text":"<p>For each epoch, you can subsample the training set and then create batches</p> <ul> <li>Cheaper epochs</li> <li>More stochastic</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/01_Introduction/#hyperparameters","title":"Hyperparameters","text":"<ul> <li>Batch size</li> <li>Initialization</li> <li>Optimizer algorithm</li> <li>Learning rate</li> <li>No of epochs</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/","title":"Optimization Algorithms","text":"<p>Need not be just gradient-based</p> <ul> <li>The algorithms from AI course can also be used</li> <li>Even brute force is fine for small datasets; since this evaluates all possibilities and does not take any approximations/gradients, this would be robust to noisy data</li> </ul> <p>Gradient-based algorithms are preferred for large datasets</p> Optimizer Meaning Comment Gradient-Free Weight Update Rule\\(w_{t+1}\\) Advantages Disadvantages Newton-Raphson \u274c \\(w_{t+1} = w_t - H^{-1} g(w_t)\\) Quadratic convergence - converges in a few stepsNo hyperparameters (learning rate) Computationally-expensive: Can\u2019t efficiently solve for Newton step, even using automatic differentiationFor non-convex optimization, it is very unclear if we even want to use Newton directionDoes not work well for mini-batch training Newton-CG Approximation of Hessian \u274c Same as Newton-Raphson Same as Newton-RaphsonApproximation is faster than Newton-Raphson Same as Newton-Raphson L-BGFS Quasi-Newton\u2019s method Not commonly used \u274c Nelder-Mead Simplex method \u2705 Gradient Descent Generalizes better than Adam \u274c \\(w_t - \\eta g(w_t)\\) GD + Momentum \u201cAveraging\u201d of step directions\u201cglobal\u201d structure similar to BGFS \u274c \\(w_t - \\eta u_{t}\\)\\(u_{t+1} = \\beta u_t + (1-\\beta) g(w_t); u_0 = 0\\)\\(\\beta \\in [0, 1):\\) momentum averaging parameter Smoothens out steps Can introduce oscillation/non-descent behavior GD + Unbiased Momentum \u274c \\(w_t - \\dfrac{\\eta u_{t}}{1 - \\beta^{t+1}}\\)Dividing by \\(1-\\beta^{t+1}\\) unbiases the update Ensures updates have equal expected magnitude across all iterations Sometimes you want the initial steps to be smaller than the later states NagNesterov Accelerated GradientGD + Nesterov Momentum Lookahead gradient from momentum step \u274c \\(w_t - \\eta u_{t\\textcolor{hotpink}{-1}}\\)\\(u_{t+1} = \\beta u_t + (1-\\beta) g(w_t \\textcolor{hotpink}{- \\eta u_t}); u_0 = 0\\) AdaDelta \u274c \\(w_t + v_{t+1}\\)\\(v_{t+1} = \\rho v_t - \\eta g(w_t)\\)or\\(v_{t+1} = \\rho v_t - \\eta g(w_t + \\rho v_t)\\) AdaGrad Decreases the momentum for each parameter, based on how much that parameter has made progressCan only decrease the moment \u274c \\(w_{i, t+1} = w_{i, t} - \\dfrac{\\eta}{\\epsilon + \\sqrt{v_{i, t+1}}} g(w_{i, t})^2\\) \\(v_{i, t+1} = v_{i, t} + g(w_{i, t})^2\\)\\(\\epsilon &gt; 0\\) Learning rate tends to zero after a long time RMSProp Keeps a memory of previous gradientsCan increase/decrease the moment \u274c \\(w_{t+1} = w_{i, t} - \\dfrac{\\eta}{\\epsilon + \\sqrt{v_{t+1}}} g(w_{t})^2\\) \\(v_{t+1} = \\beta v_{t} + (1-\\beta) g(w_t)^2\\)\\(\\epsilon &gt; 0, \\beta \\in [0, 1]\\) Adam(Adaptive Moment Estimation) Basically AdaGrad with MomentumScales the updates for each parameter differently \u274c \\(w_{t+1} = w_{t} - \\dfrac{\\eta}{\\epsilon + \\sqrt{\\hat v_{t+1}}} \\hat m_{t+1}\\)\\(\\hat m_{t+1} = \\dfrac{m_{t+1}}{1-{\\beta_1}^{t+1}}\\)\\(m_{t+1} = \\beta_1 m_t + (1-\\beta_1) g(w_t)\\)\\(\\hat v_{t+1} = \\dfrac{v_{t+1}}{1-{\\beta_2}^{t+1}}\\)\\(v_{t+1} = \\beta_2 v_t + (1-\\beta_2) g(w_t)^2\\)\\(\\epsilon &gt; 0; \\beta_1, \\beta_2 \\in [0, 1]\\) AdamW AdamW is Adam with weight decay rather than L2-regularizationAdamW seems to consistently outperform Adam in terms of both the error achieved and the training time. <p>Rule of thumb: recommended learning rate \\(\\eta = 3e^{-4}\\)</p>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#newtons-method","title":"Newton\u2019s Method","text":"<p>Integrates more \u201cglobal\u201d structure into optimization methods, which scales gradients according to the inverse of the Hessian Equivalent to approximating the function as quadratic using second-order Taylor expansion, then solving for optimal solution</p> <ul> <li>\\(\\eta=1:\\) Full step</li> <li>o.w: Damped Newton method</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#brute-force-regression","title":"Brute-Force Regression","text":"<pre><code>m_hat = (0, 5, 0.1) # min, max, precision\nc_hat = (0, 5, 0.1) # min, max, precision\n</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#imports","title":"Imports","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#generate-synthetic-data","title":"Generate Synthetic Data","text":"<p>\\(y = mx + c\\)</p> <pre><code>def equation(x, m, c):\n  return m*x + c\n</code></pre> <pre><code>x = np.arange(1, 10+1, 1)\n\nm_true = 2\nc_true = 3\ny = equation(x, m_true, c_true)\n</code></pre> <pre><code>m_hat_range = np.arange(m_hat[0], m_hat[1]+m_hat[2], m_hat[2])\nc_hat_range = np.arange(c_hat[0], c_hat[1]+c_hat[2], c_hat[2])\n\ndata = (\n  np.column_stack(\n    (\n        x,\n        y\n    ),\n  )\n)\n\nm, c = (\n  np.meshgrid(\n    m_hat_range,\n    c_hat_range\n  )\n)\nparams = (\n  np.column_stack(\n    (\n        m.flatten(),\n        c.flatten()\n    ),\n  )\n)\n\ndf = pd.DataFrame(\n    data = np.column_stack(\n        (\n            np.tile(data, (params.shape[0], 1)),\n            np.tile(params, (data.shape[0], 1))\n        )\n    ),\n    columns = [\"x\", \"y\", \"m\", \"c\"]\n)\n</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#forward-pass","title":"Forward Pass","text":"<pre><code>df[\"pred\"] = equation(df[\"x\"], df[\"m\"], df[\"c\"])\n</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#backward-pass","title":"Backward Pass","text":"<pre><code>df[\"error\"] = df[\"pred\"] - df[\"y\"]\ndf[\"loss\"] = df[\"error\"]**2\n</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#results","title":"Results","text":"<pre><code>results = (\n    df\n    .groupby([\"m\", \"c\"])\n    [\"loss\"]\n    .mean()\n    .reset_index()\n    .rename(columns = {\n        \"loss\": \"cost\"\n    })\n)\n</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#loss-landscape","title":"Loss Landscape","text":"<pre><code>fig, ax = plt.subplots()\n\nax = plt.tricontourf(\n    results[\"m\"],\n    results[\"c\"],\n    results[\"cost\"].pow(0.1),\n    levels = 1_000,\n    cmap=\"Reds_r\"\n)\nfig.colorbar(ax)\nplt.show()\n</code></pre>"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#most-optimal-parameters","title":"Most Optimal Parameters","text":"<pre><code>(\n    results\n    .sort_values(\"cost\", ascending=True)\n    .reset_index(drop=True)\n    .head(5)\n)\n</code></pre> m c cost 2.0 3.0 0.00 2.0 2.9 0.01 2.0 3.1 0.01 2.0 2.8 0.04 2.0 3.2 0.04"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#gradient-descent","title":"Gradient Descent","text":"<p>Similar to trial and error</p> <ol> <li>Start with some \\(\\theta\\) vector</li> <li>Keep changing \\(\\theta_0, \\theta_1, \\dots, \\theta_n\\) using derivative of cost function, until minimum for \\(J(\\theta)\\) is obtained - Simultaneously</li> </ol> \\[ \\theta_{\\text{new}} = \\theta_{\\text{prev}} - \\eta \\  {\\nabla J} \\] Meaning \\(\\theta_{\\text{new}}\\) Coefficients obtained from current iteration(Output of current iteration) \\(\\theta_{\\text{old}}\\) Coefficients obtained from previous iteration(Output of previous iteration) \\(\\eta\\) Learning Rate \\(\\nabla J\\) Gradient vector of \\(J (\\theta)\\)"},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#gradients-of-the-loss-function","title":"Gradients of the Loss Function","text":""},{"location":"CS_Electives/Optimization_for_AI/02_Optimization_Algorithms/#learning-rate-eta","title":"Learning Rate \\(\\eta\\)","text":"<p>\\(0 &lt; \\eta &lt; 1\\)</p> <ul> <li>Large value may lead to underfitting/overfitting</li> <li>Small value will lead to more time taken</li> </ul> <p>Rule of thumb: recommended learning rate \\(\\eta = 3 e {-4}\\)</p> <p>Can be</p> <ul> <li>constant</li> <li>decay<ul> <li>Step: \\(\\alpha_t = \\alpha_{t-a}/2\\)<ul> <li>Decay by half every few epochs</li> </ul> </li> <li>Exponential: \\(\\alpha_t = \\alpha_0 e^{-kt}\\)</li> <li>1/t: \\(\\alpha_t = \\alpha_0/(1+kt)\\)</li> </ul> </li> </ul> <p></p>"},{"location":"CS_Electives/Optimization_for_AI/03/","title":"03","text":""},{"location":"CS_Electives/Optimization_for_AI/03/#worst-first-backpropagation","title":"Worst-First Backpropagation","text":"<p>Backpropagation is expensive, so only focus on Top k</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#gradient-accumulation","title":"Gradient Accumulation","text":"<ul> <li>Use a small batch size</li> <li>Save the gradients at each batch</li> <li>Update network weights once every couple of batches</li> </ul> <p>Purpose</p> <ul> <li>Helps to imitate a larger batch size</li> <li>For large GPU memory intensive architectures</li> </ul> <p>Notes</p> <ul> <li>Some network architectures have batch-specific operations. For instance, batch normalization is performed on a batch level and therefore may yield slightly different results when using the same effective batch size with and without gradient accumulation</li> <li>It is important to also update weights on the last batch, to ensure that the last batches are not discarded and used for optimizing the network</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/03/#performance-improvement","title":"Performance Improvement","text":""},{"location":"CS_Electives/Optimization_for_AI/03/#evaluation-frequency","title":"Evaluation Frequency","text":"<ul> <li><code>train_eval_every</code></li> <li><code>dev_eval_every</code></li> </ul> <p>10 is a good number</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#1-consider-using-another-learning-rate-schedule","title":"1. Consider using another learning rate schedule","text":"<p>The learning rate (schedule) you choose has a large impact on the speed of convergence as well as the generalization performance of your model.</p> <p>Cyclical Learning Rates and the 1Cycle learning rate schedule are both methods introduced by Leslie N. Smith (here and here), and then popularised by fast.ai's Jeremy Howard and Sylvain Gugger (here and here). Essentially, the 1Cycle learning rate schedule looks something like this:</p> <p></p> <p>Sylvain writes:</p> <p>[1cycle consists of]  two steps of equal lengths, one going from a lower learning rate to a higher one than go back to the minimum. The maximum should be the value picked with the Learning Rate Finder, and the lower one can be ten times lower. Then, the length of this cycle should be slightly less than the total number of epochs, and, in the last part of training, we should allow the learning rate to decrease more than the minimum, by several orders of magnitude.</p> <p>In the best case this schedule achieves a massive speed-up \u2013 what Smith calls Superconvergence \u2013 as compared to conventional learning rate schedules. Using the 1Cycle policy he needs ~10x fewer training iterations of a ResNet-56 on ImageNet to match the performance of the original paper, for instance). The schedule seems to perform robustly well across common architectures and optimizers.</p> <p>PyTorch implements both of these methods <code>torch.optim.lr_scheduler.CyclicLR</code> and <code>torch.optim.lr_scheduler.OneCycleLR,</code> see the documentation.</p> <p>One drawback of these schedulers is that they introduce a number of additional hyperparameters. This post and this repo, offer a nice overview and implementation of how good hyper-parameters can be found including the Learning Rate Finder mentioned above.</p> <p>Why does this work? It doesn't seem entirely clear but one possible explanation might be that regularly increasing the learning rate helps to traverse saddle points in the loss landscape more quickly.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#2-use-multiple-workers-and-pinned-memory-in-dataloader","title":"2. Use multiple workers and pinned memory in DataLoader","text":"<p>When using torch.utils.data.DataLoader, set <code>num_workers &gt; 0</code>, rather than the default value of 0, and <code>pin_memory=True</code>, rather than the default value of False. Details of this are explained here.</p> <p>Szymon Micacz achieves a 2x speed-up for a single training epoch by using four workers and pinned memory.</p> <p>A rule of thumb that people are using to choose the number of workers is to set it to four times the number of available GPUs with both a larger and smaller number of workers leading to a slow down.</p> <p>Note that increasing num_workerswill increase your CPU memory consumption.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#3-max-out-the-batch-size","title":"3. Max out the batch size","text":"<p>This is a somewhat contentious point. Generally, however, it seems like using the largest batch size your GPU memory permits will accelerate your training (see NVIDIA's Szymon Migacz, for instance). Note that you will also have to adjust other hyperparameters, such as the learning rate, if you modify the batch size. A rule of thumb here is to double the learning rate as you double the batch size.</p> <p>OpenAI has a nice empirical paper on the number of convergence steps needed for different batch sizes. Daniel Huynh runs some experiments with different batch sizes (also using the 1Cycle policy discussed above) where he achieves a 4x speed-up by going from batch size 64 to 512.</p> <p>One of the downsides of using large batch sizes, however, is that they might lead to solutions that generalize worse than those trained with smaller batches.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#4-use-automatic-mixed-precision-amp","title":"4. Use Automatic Mixed Precision (AMP)","text":"<p>The release of PyTorch 1.6 included a native implementation of Automatic Mixed Precision training to PyTorch. The main idea here is that certain operations can be run faster and without a loss of accuracy at semi-precision (FP16) rather than in the single-precision (FP32) used elsewhere. AMP, then, automatically decide which operation should be executed in which format. This allows both for faster training and a smaller memory footprint.</p> <p>Benchmarking a number of common language and vision models on NVIDIA V100 GPUs, Huang and colleagues find that using AMP over regular FP32 training yields roughly 2x \u2013 but upto 5.5x \u2013 training speed-ups.</p> <p>Currently, only CUDA ops can be autocast in this way. See the documentation here for more details on this and other limitations.</p> <p>u/SVPERBlA points out that you can squeeze out some additional performance (~ 20%) from AMP on NVIDIA Tensor Core GPUs if you convert your tensors to the Channels Last memory format. Refer to this section in the NVIDIA docs for an explanation of the speedup and more about NCHW versus NHWC tensor formats.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#5-consider-using-another-optimizer","title":"5. Consider using another optimizer","text":"<p>Both Adam and AdamW work well with the 1Cycle policy described above.</p> <p>There are also a few not-yet-native optimizers that have received a lot of attention recently, most notably LARS (pip installable implementation) and LAMB.</p> <p>NVIDA's APEX implements fused versions of a number of common optimizers such as Adam. This implementation avoid a number of passes to and from GPU memory as compared to the PyTorch implementation of Adam, yielding speed-ups in the range of 5%.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#6-turn-on-cudnn-benchmarking","title":"6. Turn on cudNN benchmarking","text":"<p>If your model architecture remains fixed and your input size stays constant, setting <code>torch.backends.cudnn.benchmark = True</code> might be beneficial (docs). This enables the cudNN autotuner which will benchmark a number of different ways of computing convolutions in cudNN and then use the fastest method from then on.</p> <p>For a rough reference on the type of speed-up you can expect from this, Szymon Migacz achieves a speed-up of 70% on a forward pass for a convolution and a 27% speed-up for a forward + backward pass of the same convolution.</p> <p>One caveat here is that this autotuning might become very slow if you max out the batch size as mentioned above.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#7-beware-of-frequently-transferring-data-between-cpus-and-gpus","title":"7. Beware of frequently transferring data between CPUs and GPUs","text":"<p>Beware of frequently transferring tensors from a GPU to a CPU using <code>tensor.cpu()</code> and vice versa using <code>tensor.cuda()</code> as these are relatively expensive. The same applies for <code>.item()</code> and <code>.numpy()</code> \u2013 use <code>.detach()</code> instead.</p> <p>If you are creating a new tensor, you can also directly assign it to your GPU using the keyword argument <code>device=torch.device('cuda:0')</code>.</p> <p>If you do need to transfer data, using <code>.to(non_blocking=True)</code>, might be useful as long as you don't have any synchronization points after the transfer.</p> <p>If you really have to, you might want to give Santosh Gupta's SpeedTorch a try, although it doesn't seem entirely clear when this actually does/doesn't provide speed-ups.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#8-use-gradientactivation-checkpointing","title":"8. Use gradient/activation checkpointing","text":"<p>Quoting directly from the documentation:</p> <p>Checkpointing works by trading compute for memory. Rather than storing all intermediate activations of the entire computation graph for computing backward, the checkpointed part does not save intermediate activations, and instead recomputes them in backward pass. It can be applied on any part of a model.</p> <p>Specifically, in the forward pass, function will run in torch.no_grad() manner, i.e., not storing the intermediate activations. Instead, the forward pass saves the inputs tuple and the functionparameter. In the backwards pass, the saved inputs and function is retrieved, and the forward pass is computed on function again, now tracking the intermediate activations, and then the gradients are calculated using these activation values.</p> <p>So while this will might slightly increase your run time for a given batch size, you'll significantly reduce your memory footprint. This in turn will allow you to further increase the batch size you're using allowing for better GPU utilization.</p> <p>While checkpointing is implemented natively as <code>torch.utils.checkpoint</code>(docs), it does seem to take some thought and effort to implement properly. Priya Goyal has a good tutorial demonstrating some of the key aspects of checkpointing.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#9-use-gradient-accumulation","title":"9. Use gradient accumulation","text":"<p>Another approach to increasing the batch size is to accumulate gradients across multiple <code>.backward()</code> passes before calling optimizer.step().</p> <p>Following a post by Hugging Face's Thomas Wolf, gradient accumulation can be implemented as follows:</p> <pre><code>model.zero_grad()                                   # Reset gradients tensors\nfor i, (inputs, labels) in enumerate(training_set):\n    predictions = model(inputs)                     # Forward pass\n    loss = loss_function(predictions, labels)       # Compute loss function\n    loss = loss / accumulation_steps                # Normalize our loss (if averaged)\n    loss.backward()                                 # Backward pass\n    if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n        optimizer.step()                            # Now we can do an optimizer step\n        model.zero_grad()                           # Reset gradients tensors\n        if (i+1) % evaluation_steps == 0:           # Evaluate the model when we...\n            evaluate_model()                        # ...have no gradients accumulate\n</code></pre> <p>This method was developed mainly to circumvent GPU memory limitations and I'm not entirely clear on the trade-off between having additional <code>.backward()</code> loops. This discussion on the fastai forum seems to suggest that it can in fact accelerate training, so it's probably worth a try.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#10-use-distributed-data-parallel-for-multi-gpu-training","title":"10. Use Distributed Data Parallel for multi-GPU training","text":"<p>Methods to accelerate distributed training probably warrant their own post but one simple one is to use <code>torch.nn.DistributedDataParallel</code> rather than <code>torch.nn.DataParallel</code>. By doing so, each GPU will be driven by a dedicated CPU core avoiding the GIL issues of DataParallel.</p> <p>In general, I can strongly recommend reading the documentation on distributed training.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#11-set-gradients-to-none-rather-than-0","title":"11. Set gradients to None rather than 0","text":"<p>Use <code>.zero_grad(set_to_none=True)</code> rather than <code>.zero_grad()</code>.</p> <p>Doing so will let the memory allocator handle the gradients rather than actively setting them to 0. This will lead to yield a modest speed-up as they say in the documentation, so don't expect any miracles.</p> <p>Watch out, doing this is not side-effect free! Check the docs for the details on this.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#12-use-as_tensor-rather-than-tensor","title":"12. Use .as_tensor() rather than .tensor()","text":"<p><code>torch.tensor()</code> always copies data. If you have a numpy array that you want to convert, use <code>torch.as_tensor()</code> or <code>torch.from_numpy()</code> to avoid copying the data.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#13-turn-on-debugging-tools-only-when-actually-needed","title":"13. Turn on debugging tools only when actually needed","text":"<p>PyTorch offers a number of useful debugging tools like the autograd.profiler, autograd.grad_check, and autograd.anomaly_detection. Make sure to use them to better understand when needed but to also turn them off when you don't need them as they will slow down your training.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#14-use-gradient-clipping","title":"14. Use gradient clipping","text":"<p>Originally used to avoid exploding gradients in RNNs, there is both some empirical evidence as well as some theoretical support that clipping gradients (roughly speaking: <code>gradient = min(gradient, threshold)</code>) accelerates convergence.</p> <p>Hugging Face's Transformer implementation is a really clean example of how to use gradient clipping as well as some of the other methods such as AMP mentioned in this post.</p> <p>In PyTorch this can be done using <code>torch.nn.utils.clip_grad_norm_</code>(documentation).</p> <p>It's not entirely clear to me which models benefit how much from gradient clipping but it seems to be robustly useful for RNNs, Transformer-based and ResNets architectures and a range of different optimizers.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#15-turn-off-bias-before-batchnorm","title":"15. Turn off bias before BatchNorm","text":"<p>This is a very simple one: turn off the bias of layers before BatchNormalization layers. For a 2-D convolutional layer, this can be done by setting the bias keyword to False: <code>torch.nn.Conv2d(..., bias=False, ...)</code>.  (Here's a reminder why this makes sense.)</p> <p>You will save some parameters, I would however expect the speed-up of this to be relatively small as compared to some of the other methods mentioned here.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#17-use-input-and-batch-normalization","title":"17. Use input and batch normalization","text":"<p>You're probably already doing this but you might want to double-check:</p> <ul> <li>Are you normalizing your input?</li> <li>Are you using batch-normalization?</li> </ul> <p>And here's a reminder of why you probably should.</p>"},{"location":"CS_Electives/Optimization_for_AI/03/#bonus-tip-from-the-comments-use-jit-to-fuse-point-wise-operations","title":"Bonus tip from the comments: Use JIT to fuse point-wise operations.","text":"<p>If you have adjacent point-wise operations you can use PyTorch JIT to combine them into one FusionGroup which can then be launched on a single kernel rather than multiple kernels as would have been done per default. You'll also save some memory reads and writes.</p> <p>Szymon Migacz shows how you can use the <code>@torch.jit.script</code> decorator to fuse the operations in a GELU, for instance:</p> <pre><code>@torch.jit.script\ndef fused_gelu(x):\n    return x * 0.5 * (1.0 + torch.erf(x / 1.41421))\n</code></pre> <p>In this case, fusing the operations leads to a 5x speed-up for the execution of <code>fused_gelu</code> as compared to the unfused version.</p> <p>See also this post for an example of how Torchscript can be used to accelerate an RNN.</p> <p>Hat tip to u/Patient_Atmosphere45 for the suggestion.</p>"},{"location":"CS_Electives/Optimization_for_AI/04_Gradients/","title":"Gradients","text":""},{"location":"CS_Electives/Optimization_for_AI/04_Gradients/#gradient-issues","title":"Gradient Issues","text":"<p>Especially for FP32 or lower precision</p> Gradients __ exponentially during back-propagation Weight gradients Cause Solution Vanishing (Converging) shrink Too small Deep Networks Weight-initializationWeights Scaling Exploding (Diverging) grow Too large Deep Networks Weight-initializationClipping Large loss due to target with large range* Target normalization <ul> <li>A target variable with a large spread of values, in turn, may result in large error gradient values causing weight values to change dramatically, making the learning process unstable</li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/04_Gradients/#gradient-clipping","title":"Gradient Clipping","text":"<p>rescales gradient to size at most \\(\\theta\\).</p> \\[ g \\leftarrow \\min \\left( 1, \\frac{\\theta}{\\vert g \\vert}  \\right) g \\] <p>If the weights are large, the gradients grow exponentially during back-propagation</p>"},{"location":"CS_Electives/Optimization_for_AI/05_Gradient_Estimation/","title":"Gradient Estimation","text":""},{"location":"CS_Electives/Optimization_for_AI/05_Gradient_Estimation/#types","title":"Types","text":"Error Disadvantage Accurate Estimate Low Computational-Cost Easy to write Numerical \\(\\lim \\limits_{\\epsilon \\to 0} \\dfrac{f(x + \\epsilon) - f(x)}{\\epsilon}\\) \\(O(\\epsilon)\\) Less accurate \u274c \u274c \u2705 NumericalType 2 \\(\\lim \\limits_{\\epsilon \\to 0} \\dfrac{f(x + \\epsilon) - f(x-\\epsilon)}{2\\epsilon}\\) \\(O(\\epsilon^2)\\) Numerical error \u274c \u274c \u2705 Manual Analytic Derive gradient by sum, product, chain rules Tedious \u2705 \u274c \u274c Backpropagation Run backward operations the same forward graph \u2705 \u2705 Forward mode automatic Output: Computational graphDefine \\(\\dot v_i = \\dfrac{\\partial v_i}{\\partial x_j}\\)where \\(v_i\\) is an intermediate result \\(n\\) forward passes required to get gradient of each input \u2705 \u274c Reverse mode automatic Output: Computational graphDefine adjoint \\(\\bar v_i = \\dfrac{\\partial y}{\\partial v_i}\\)where \\(v_i\\) is an  intermediate result\\(\\overline{v_{k \\to i}} = \\bar v_i \\dfrac{\\partial v_i}{\\partial v_k}\\)"},{"location":"CS_Electives/Optimization_for_AI/05_Gradient_Estimation/#numerical-gradient-checking","title":"Numerical gradient checking","text":"<p>Always use analytic gradient, but check implementation with numeric gradient</p> \\[ \\Delta^T \\nabla_x f(x) = \\dfrac{f(x + \\epsilon \\delta) - f(x - \\epsilon \\delta)}{2 \\epsilon} + O(\\epsilon^2) \\] <p>Pick \\(\\delta\\) from unit ball</p>"},{"location":"CS_Electives/Optimization_for_AI/05_Gradient_Estimation/#backpropagation","title":"Backpropagation","text":""},{"location":"CS_Electives/Optimization_for_AI/05_Gradient_Estimation/#steps","title":"Steps","text":"<ol> <li>Forward pass<ol> <li>Compute result of operations</li> <li>Save intermediates required for gradient computation</li> </ol> </li> <li>Calculate loss</li> <li>Backward pass<ol> <li>Compute gradient of loss function wrt inputs, using chain rule recursively</li> </ol> </li> </ol>"},{"location":"CS_Electives/Optimization_for_AI/05_Gradient_Estimation/#idk","title":"IDK","text":"<ul> <li>Gradients accumulate at branches<ul> <li>Gradients are accumulated as the same node may be referenced multiple times in the forward pass</li> </ul> </li> <li>Clear gradients before backward pass</li> <li>Sum and broadcasting are duals of each other in terms of forward and backward pass</li> <li>IDK<ul> <li>add/sum: gradient distributor</li> <li>max: gradient router<ul> <li>very rare for multiple values to be max</li> </ul> </li> <li>mul: gradient swapper</li> </ul> </li> </ul>"},{"location":"CS_Electives/Optimization_for_AI/05_Gradient_Estimation/#idk_1","title":"IDK","text":"<p>Basically just chain rule + intelligent caching of intermediate results</p> <p>Computationally-cheap, but large storage required for caching intermediate results</p> <p>Each layer needs to be able to perform vector Jacobian product: multiply the \u201cincoming backward gradient\u201d by its derivatives</p> \\[ \\begin{aligned} \\dfrac{\\partial J}{\\partial \\theta_l} &amp;= \\dfrac{\\partial J}{\\partial y_L} \\left( \\prod_{i=l}^L \\dfrac{\\partial y_i}{\\partial y_{i-1}} \\right) \\dfrac{\\partial y_l}{\\partial \\theta_l} \\end{aligned} \\] <p></p>"},{"location":"CS_Electives/Programmable_Electronics/","title":"Programmable Electronics","text":"<p>ASIC: application-specific IC</p> <p>FPGA: Field Programmable Gate Arrays</p>"},{"location":"CS_Electives/Programmable_Electronics/#references","title":"References","text":"<ul> <li> ECE5760 DE2/115 lectures 2011 | Bruce Land</li> <li> Introduction to FPGA | DigiKey</li> <li> Learn FPGA | Invent Box Tutorials</li> <li> Neural Networks on FPGA | Piero Nexus</li> </ul>"},{"location":"CS_Electives/Quantum_Computing/","title":"Quantum Computing","text":""},{"location":"CS_Electives/Quantum_Computing/#references","title":"References","text":"<ul> <li> Quantum Computation | John Preskill | Caltech</li> </ul>"},{"location":"CS_Electives/RL/","title":"Reinforcement Learning","text":""},{"location":"CS_Electives/RL/#references","title":"References","text":"<ul> <li> Reinforcement Learning | Deeplizard</li> <li> Deep Reinforcement Learning For Finance 101 | Bam Tungom</li> <li> Reinforcement Learning by the book | Mutual Information</li> <li> Reinforcement Learning | MIT</li> <li> Reinforcement Learning | DeepMind x UCL</li> <li> Reinforcement Learning (HMC CS 181V)\u2014Spring, 2020 | Neil Rhodes</li> <li> Reinforcement Learning | IIT Madras</li> <li> Deep RL | UC Berkeley</li> <li> Foundations of Reinforcement Learning | Princeton</li> <li> Reinforcement Learning | Abhishek Gupta</li> <li> Reinforcement Learning | University of Alberta</li> </ul>"},{"location":"CS_Electives/Robotics/","title":"Robotics","text":""},{"location":"CS_Electives/Robotics/#references","title":"References","text":"<ul> <li> Introduction to Robotics and Robots | Paul McWhorter</li> <li> Underactuated Robotics | MIT</li> <li> Robotic Manipulation | MIT</li> <li> CS287 Advanced Robotics at UC Berkeley Fall 2019</li> <li> Robotics | University of Michigan</li> </ul>"},{"location":"CS_Electives/Tiny_ML/","title":"TinyML","text":"<p>Rather than adding more compute power, focus on improving compute efficiency</p> <p>Will mainly focus on the following applications: Speech, Computer Vision, NLP</p>"},{"location":"CS_Electives/Tiny_ML/#topics","title":"Topics","text":"<ul> <li>Hardware<ul> <li>Architecture &amp; Dataflow</li> <li>Metrics and Analysis</li> <li>Efficiency</li> <li>Micro-architecture/Circuits</li> </ul> </li> <li>Model Optimization</li> <li>Software: Optimize DNN operations through software compilation/kernel implementations<ul> <li>Domain-specific compilers; eg: TVM</li> <li>Kernel implementations</li> <li>Mapping onto hardware</li> </ul> </li> <li>Systems</li> <li>Environmental issues</li> </ul>"},{"location":"CS_Electives/Tiny_ML/#pre-requisites","title":"Pre-Requisites","text":"<ul> <li>Computer architecture</li> <li>Machine Learning</li> <li>Python programming</li> <li>PyTorch Basics</li> </ul>"},{"location":"CS_Electives/Tiny_ML/#reading","title":"Reading","text":"Textbook Efficient processing of deep neural networks Introduction A New Golden Age for Computer Architecture- PDF- HTML DNN Computations TB Chap 1, 2What\u2019s the backward-forward FLOP ratio for Neural Networks?Optimizing RNNs in CuDNN 5What are keys, queries, and values in attention mechanisms?Attention is all you need Hardware Book: Chapter 3In-datacenter Performance Analysis of a Tensor Processing UnitOptional: Computer Architecture: A Quantitative Approach. Ch 7Book: Chapter 5Think Fast: a TSP for Accelerating Deep Learning WorkloadsFYI: OCP Microscaling (MX) Format SpecificationBook: Chapter 8Serving DNNs in Real-time with Project BrainwaveTen Lessons from 3 Generations Shaped Google TPUv4iOptional: EIE: Efficient Inference Engine on Compressed DNNOptional: Survey on sparse hardware acceleration Microarchitecture Deep learning with INT8 on Xilinx devicesOn-Chip Memory Design for Low-Power CNN AcceleratorsOptional: Making Floating Point Math Highly Efficient for AI HardwareOptional: Book: Chapter 10 Quantization Book: Chapter 7Quantization and Training of NNs for Efficient INT-only InferenceTraining DNNs with 8-bit Floating-Point Numbers Pruning Book: Chapter 8Learning Both Weights and Connections for Efficient NNsThe Lottery Ticket Hypothesis TinyML TinyML Progress, Challenges and Roadmap Knowledge Distillation Distilling the Knowledge in a Neural NetworkKnowledge Distillation: A Survey Neural Architecture Search Book: Chapter 9Neural Architecture Search with Reinforcement LearningBRP-NAS: Prediction-based NAS using GCNsAutoML Codesign of a CNN and its Hardware Accelerator Kernel Computation Book: Chapter 4Fast algorithms for CNNsEnd-to-end ASR Model Compression using Reinforcement LearningOptional: TNet Mapping Book: Chapter 6Optimizing RNNs on GPUsDLA: Compiler and FPGA Overlay for DNN Inference Acceleration TVM TVM: An Automated Optimizing Compiler for Deep Learning Pre-/Postprocessing AI Tax: The Hidden Cost of AI Data-Center ApplicationsRethinking Data Storage and Preprocessing in DatacentersFaster Neural Networks Straight from JPEG Distributed Training Horovod: Fast and Easy Distributed Deep Learning in TensorflowLarge Scale Distributed Deep Learning Federated Learning Google AI Blog Post on FLCommunication Efficient Learning of DNNs from Decentralized DataTowards Federated Learning at Scale: System Design Ethical/Environmental Issues Chasing Carbon: The Elusive Environmental Footprint of ComputingOn the Dangers of Stochastic Parrots: Can Language Models be Too BigThe Carbon Footprint of ML Training will Plateau, then Shrink"},{"location":"CS_Electives/Tiny_ML/#references","title":"References","text":"<ul> <li> Machine Learning Hardware and Systems (Cornell Tech, Spring 2022)</li> <li> Videos</li> <li> Material</li> <li> TinyML and Efficient Deep Learning Computing | EfficientML.ai - MIT HAN Lab</li> <li> Tiny Machine Learning | UPenn</li> <li> AutoDL | Applied Deep Learning | Maziar Raissi</li> <li> TinyML - Digikey</li> </ul>"},{"location":"CS_Electives/Tiny_ML/#current-video","title":"Current Video","text":"<p>https://www.youtube.com/watch?v=QF0S29IXTWk&amp;list=PL7rtKJAz_mPe6kAbiH6Ucq02Vpa95qvBJ&amp;index=79</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/","title":"Introduction","text":"<p>Hardware and systems are essential for the progress of deep learning.</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#tinyml","title":"TinyML","text":"<ul> <li>Machine Learning on embedded systems</li> <li>Often overlooked</li> <li>Useful to integrate ML with IoT Systems</li> </ul>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#example","title":"Example","text":""},{"location":"CS_Electives/Tiny_ML/00_Introduction/#procedure","title":"Procedure","text":""},{"location":"CS_Electives/Tiny_ML/00_Introduction/#applications","title":"Applications","text":"<ul> <li>Industry<ul> <li>Predictive maintenance<ul> <li>Reducing downtime</li> <li>Increasing efficiency</li> <li>Cost-efficiency</li> </ul> </li> <li>Monitoring</li> </ul> </li> <li>Environment<ul> <li>Detailed insights on animals</li> <li>Less wasted data</li> <li>Cost-effective</li> <li>Overcome limitations of human labor</li> </ul> </li> <li>Humans<ul> <li>Improving accessibility<ul> <li>Hands-free</li> <li>Voice control</li> </ul> </li> <li>UI + UX intuitiveness</li> </ul> </li> </ul>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#embedded-systems","title":"Embedded Systems","text":"<p>Device with - extremely low power consumption (usually &lt; 1 mW) - Sensor, Processor, Output all-in-one</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#existing-systems","title":"Existing Systems","text":"<p>Nano 33 BLE Sense: AI-enabled ARM-based developmental microcontroller board</p> <p></p> <p>OV 7675 Camera module</p> <p>TinyML Shield: Alternative to Breadboard</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#arm-cortex-processor-profiles","title":"ARM Cortex Processor Profiles","text":"<ul> <li>ARM designs the processor core &amp; ISA, but they don\u2019t fabricate the chips</li> <li>The company (Qualcomm, Apple) bundles it with other design for system-on-chip</li> <li>The company (Google, Samsung, etc) places order to fabrication company (TSMC)</li> </ul>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#cortex-m-isa","title":"Cortex-M ISA","text":""},{"location":"CS_Electives/Tiny_ML/00_Introduction/#embedded-systems-os","title":"Embedded Systems OS","text":"<ul> <li>RTOS</li> <li>Arm MBED OS</li> </ul> <p>You can remove unnecessary OS modules</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#constraints-and-optimization","title":"Constraints and Optimization","text":"<p>Contraints - Small size - Low power - Low bandwidth - Low cost</p> <p>Requirement - Low latency - High throughput</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#hardware","title":"Hardware","text":"<p>No more \u201cfree lunch\u201d from material science improvements</p> Comment Moore\u2019s law Slowing downIn 1970-2010, we were able to put more transistors on a chip and get exponentially more performance; but now this is ending Dennard scaling essential stopped <p>Costly for companies to use cloud-based systems; would prefer edge-computing to reduce their energy consumption</p> <p>Can\u2019t rely on material technology for performance: After a point in shrinking size of transistors to fit more on a single chip, side-effects (such as electrons shoot in unwanted directions) cause higher power usage. Hence, domain-specific H/W architectures (GPUs, TPUs) are important</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#compute","title":"Compute","text":""},{"location":"CS_Electives/Tiny_ML/00_Introduction/#memory-allocation","title":"Memory Allocation","text":"<p>Since products are expected to run for a long duration (months, years) - memory allocation is very important - need to guarantee that memory allocation will not end up fragmented - Contiguous memory cannot be allocated even if there is enough memory overall</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#memory-usage","title":"Memory Usage","text":"<ul> <li>Need to be resource-aware</li> <li>Less compute</li> <li>Less memory</li> <li>Use quantization</li> </ul>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#storage","title":"Storage","text":""},{"location":"CS_Electives/Tiny_ML/00_Introduction/#software","title":"Software","text":"<ul> <li>Missing library features<ul> <li>Dynamic memory allocation is not always possible, to avoid running out of memory</li> </ul> </li> <li>Limited OS system support; for eg: no <code>printf</code></li> </ul>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#operating-system","title":"Operating System","text":"<p>Usually no Operating System, to save resources and enable specialization in the actual task</p> <p>Sometimes there are OS - Free RTOS - arm MBED OS</p> <p>Example of Android Platform Architecture in general purpose computer</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#libraries","title":"Libraries","text":"<ul> <li>Portability is a problem</li> </ul>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#applications_1","title":"Applications","text":""},{"location":"CS_Electives/Tiny_ML/00_Introduction/#model","title":"Model","text":"<p>There is a tradeoff between Accuracy and 1. Operations (usually, FLOPS) 2. Model size (usually, no of parameters)</p> <p></p> <p>Solutions - Quantization - Pruning - Knowledge distillation - AutoML</p>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#training-systems","title":"Training Systems","text":"<ul> <li>Pre/Post Processing</li> <li>Distributed training</li> <li>Federated learning</li> </ul>"},{"location":"CS_Electives/Tiny_ML/00_Introduction/#runtimeinference-systems","title":"Runtime/Inference Systems","text":"<p>Focused only on inference - Less memory - Less compute power</p>"},{"location":"CS_Electives/Tiny_ML/01_DNN_Computations/","title":"DNN Computations","text":""},{"location":"CS_Electives/Tiny_ML/01_DNN_Computations/#computational-view","title":"Computational View","text":"Aspect Questions Memory Parameters SizeDoes it fit on-chipHow long does it take to load from off-chipCan I overlap loading with computationIs there re-use of loaded parameters Activation SizeDoes it fit on-chipHow long does it need to be on-chip Compute MACs(Multiply-ACcumulates) What is the available parallelism in each layer?Does it fit the HW?Can I overlap compute with memory access Data dependencies Which (parts of) tensors need to be ready before starting to process a layer <p>Operation in an epoch</p> Bottleneck operation Compute utilization ratio Memory utilization ratio Forward pass Multiplication Backward pass Multiplication 2x of forward pass 1x of forward pass Gradient update Subtraction"},{"location":"CS_Electives/Tiny_ML/01_DNN_Computations/#io-bound-vs-cpu-bound","title":"I/O-Bound vs CPU-Bound","text":"<p>Memory-Bound vs Compute-Bound</p> <ul> <li>Does it take more time to do computation or fetch data from memory</li> <li>Depends on factors</li> <li>Memory bandwidth</li> <li>Compute speed/parallelism</li> <li>Size of operands</li> <li>Size of (intermediate) result</li> <li>On-Chip buffering resources</li> </ul> Memory-Bound Compute-Bound Parameters to fetch Many Few Stalls other Compute Memory ImplicationEven if you have the best __, it won\u2019t make a difference GPU RAM, hard drive Not concerning \u274c \u2705 IDK Unnecessarily over-optimized memory controller"},{"location":"CS_Electives/Tiny_ML/01_DNN_Computations/#double-buffering","title":"Double-Buffering","text":"<p>DNN \u201cfit\u201d on a processor: DNN\u2019s parameters and activations fit on the processor\u2019s external memory</p> <p>Why do GPUs have smaller external memories, ie why is VRAM smaller than RAM? Because VRAM is much faster, and hence more expensive</p>"},{"location":"CS_Electives/Tiny_ML/01_DNN_Computations/#model-checkpointing","title":"Model Checkpointing","text":"<ul> <li>General: Store all activations from forward pass, to use during backward pass</li> <li>Checkpointing: skips some of those activations and recalculate on the fly during backward pass</li> </ul> <p>Implication: less memory usage, but more computation</p>"},{"location":"CS_Electives/Tiny_ML/01_DNN_Computations/#common-dnn-layers","title":"Common DNN Layers","text":"Type of bound Compute complexity(Operations) Memory complexity(No of parameters) Comment Convolution Compute \\(k \\times 2 \\times rs \\times w h \\times c\\) \\(k \\times rs \\times c\\) Depth-wise convolution Compute \\(k \\times 2 \\times rs \\times w h\\) \\(k \\times rs\\) Linear/Fully-Connected Memory \\(k\\) Batched Linear Equal \\(k\\) Pooling Equal \\(O(1)\\) \\(O(1)\\) Can reuse hardware for convolutions with max/avg filter Normalization Equal \\(O(1)\\) \\(O(1)\\) Batch-norm becomes a simple scale+shift operation during inference Activation Functions Equal \\(O(1)\\) \\(O(1)\\) AF that cannot be compute in-place would need gradients to be computed before &amp; after the AFSome AF have parameters Convolution \\(w\\) Input width \\(h\\) Input height \\(c\\) No of input channels \\(s\\) Filter width \\(r\\) Filter height \\(k\\) No of filters in convolutionNo of weight tensors"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/","title":"Efficiency","text":"<p>All elements on a single layer of a network are parallelizable</p>"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#cpu-chip-area","title":"CPU Chip Area","text":""},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#hardware-types","title":"Hardware Types","text":"Purpose General CPU (Central Processing Unit) Low LatencyControl Flow GPU (Graphics Processing Unit) High throughputData flow TPU (Tensor Processing Unit)NPU (Neural Processing Unit) Specialized FPGA (Field Programmable Gate Assembly) Re-Programmable Logic ASIC (Application Specific Integrated Circuit) Fixed logic"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#performance-metrics","title":"Performance Metrics","text":"Metric Common Units Affected by Hardware Affected by DNN Compute FLOPs/s **F**loating-point **op**erations per **s**econd \u2705 \u274c OPs/s Non floating-point **op**erations per **s**econd \u2705 \u274c MACs/s Multipy-Accumulate Ops/s Half FLOPs/s \u2705 \u2705 Latency No of sec per operation s \u2705 \u2705 Throughput No of operations per second Ops/s \u2705 \u2705 Memory Capacity GB \u274c \u274c Bandwidth GB/s \u274c \u274c Workload Operational intensity Op/B \u274c \u2705 HW Utilization \u2705 \u2705"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#ops","title":"OPs","text":"\\[ \\begin{aligned} &amp;\\text{OPs} \\\\ &amp;= \\text{Ops/sec} \\\\ &amp;= \\underbrace{ \\dfrac{1}{\\text{Cycles/Op}} \\times \\text{Cycles/sec} }_\\text{for single PE} \\times \\text{No of PEs} \\end{aligned} \\] <p>PE = Processing Element</p>"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#roofline-plot","title":"Roofline Plot","text":"<p>Characterize performance of given hardware device across different workloads, to help identify if a workload is memory-bound or compute-bound</p> <p></p> Speed up Technique Memory-bound Algorithmic improvement(reduce precision) Faster memory chip Compute-Bound Faster PE(Overclocking)"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#operational-intensity","title":"Operational Intensity","text":"\\[ \\begin{aligned} \\text{Operational Intensity} &amp;= \\dfrac{\\text{No of Ops}}{\\text{Mem Footprint}} \\\\ \\text{No of Ops} &amp;= \\text{Multiplications} + \\text{Additions} \\\\ \\text{Mem Footprint} &amp;= \\text{Size of parameters} + \\text{Size of activations} \\end{aligned} \\] <p>Quantifies the ratio of computations to memory footprint of a DNN</p> <p>The same DNN can have different operational intensity on different hardware, if each device supports different numerical precision (Size of data affects operational intensity)</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#idk","title":"IDK","text":""},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#performance-bottlenecks","title":"Performance Bottlenecks","text":"<ul> <li>Memory access efficiency</li> <li>Uncoalesced reads</li> <li>Compute utilization</li> <li>Overhead of control logic</li> <li>Complex DNN topologies</li> <li>Control flow and data hazards may stall execution even if hardware is available</li> </ul>"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#hardware-efficiency","title":"Hardware Efficiency","text":""},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#energy-breakdown","title":"Energy breakdown","text":""},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#hardware-efficiency-approaches","title":"Hardware Efficiency Approaches","text":"Approach Technique Arithmetic Specialized instructions Amortize overheadReduce overhead fractionPerform complex/fused operations with the same data fetchSIMDMatrix Multiple UnitHFMAHDP4AHMMA Quantization Lower numerical precision Memory Locality Move data to inexpensive on-chip memory Re-use Avoid expensive memory fetchesTemporal: Read once, use same data multiple times by same PESIMD, SIMTSpatial: Read once, use data multiple times by multiple PEsDataflow processingWeights stationary (CNNs)Input stationary (Fully-Connected Layers)Output stationary Operations Sparsity Skip ineffectual operationsActivation Sparsity (Sparse Activation Functions: ReLU)Weight Sparsity (Regularization/Pruning)Block SparsityCoarse-grainedFine-grained - Overhead Interleaving Model storage CSC Representation(Compressed Sparse Column) Model Optim:Change DNN arch (and hence workload) to better fit HW Compression Distillation AutoML <p>Floating-point <code>add</code> is more expensive relative to <code>integer</code>, compared to multiplication , due to shifting operations</p>"},{"location":"CS_Electives/Tiny_ML/02_Efficiency/#guidelines-for-dsas","title":"Guidelines for DSAs","text":"<p>Domain-Specific Architectures</p> <ul> <li>Dedicated memory to minimize distance of data transfer</li> <li>Invest resources saved from dropping advanced micro-architectural optimizations into more arithmetic units/larger memories</li> <li>Use easiest form of parallelism that matches the domain</li> <li>Reduce data size and type to simplest needed for the domain</li> <li>Use domain-specific programming language to port code to DSA</li> </ul>"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/","title":"Microarchitecture","text":"<ul> <li>Arithmetic unit design</li> <li>Memory organization</li> </ul>"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#processing-element","title":"Processing Element","text":"<p>Should support dot product</p> <ul> <li>Multiplier with 2 elements</li> <li>Accumulator with 2 elements</li> </ul> <p>Accumulator: Adder that keeps result in storage</p> <p>Inference in INT8 precision =&gt; Multipliers are INT8, because adders and accumulators need wide range to perform accurate accumulation of many numbers</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#sequential","title":"Sequential","text":"Step 1 2"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#paralllelvectorized","title":"Paralllel/Vectorized","text":"Step 1 2"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#pipelined","title":"Pipelined","text":"<p>Initiation interval: How often we can start computation of a new element in a loop</p> <p>Break down computation into multiple steps with intermediate registers</p>"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#interleaved","title":"Interleaved","text":""},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#precision","title":"Precision","text":"<p>Block Floating Point</p> <ul> <li>One exponent for each exponent</li> </ul> <p></p>"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#on-chip-memory","title":"On-Chip Memory","text":"<p>Bit-width of address = no of data entries</p> <p>Connecting RAM to MAC</p> Simple Use separate memories for 2 operands Increase no of read ports Problems with adding many read ports to SRAM1. Large size2. Inc power consumption3. Slow4. In FPGA, you need to duplicate your memorie Banking Use multiple small memories"},{"location":"CS_Electives/Tiny_ML/03_Microarchitecture/#computing-paradigms","title":"Computing Paradigms","text":"Processing Why? In-Sensor Data movement from sensor to processor is costlyFor eg, if you only need class label as output, why unnecessarily transfer 8MP image to processor Near-Memory In-Memory(Analog Processing) - Weights stored as charges- Activations delivered as analog voltages- By activating pre-charge circuity on the word &amp; bit lines, we can perform multiplication between input activation voltage &amp; stored weights"},{"location":"CS_Electives/Tiny_ML/05_Quantization/","title":"Quantization","text":"<p>Mapping input values from a large set (often continuous) to output values in a (countable) smaller set (often discrete)</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#advantages","title":"Advantages","text":"<ol> <li>Faster operations</li> <li>Lower memory usage</li> <li>Lower power consumption</li> <li>Lower latency</li> <li>Smaller chip area (no need of FP hardware)</li> </ol>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#disadvantages","title":"Disadvantages","text":"<ul> <li>Loss in accuracy<ul> <li></li> </ul> </li> <li>Decompressing back to FP32<ul> <li>Loss in resolution of weights</li> <li>Loss in accuracy of weights</li> </ul> </li> </ul>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#types","title":"Types","text":"<ul> <li>What to quantize<ul> <li>Weights &amp; Biases</li> <li>Activations</li> <li>Inputs</li> </ul> </li> <li>How<ul> <li>Linear/Non-linear</li> <li>Symmetric/Assymmetric</li> <li>Quantization-aware training</li> </ul> </li> <li>Training/Inference</li> <li>Error   Tradeoff between 2 types</li> <li>Clipping<ul> <li>To reduce, you need to inc the range: dec \\(r_\\min\\) and inc \\(r_\\max\\)</li> </ul> </li> <li>Rounding<ul> <li>To reduce, you need to reduce the range: inc \\(r_\\min\\)\u00a0and dec \\(r_\\max\\)</li> </ul> </li> <li>Per-tensor, per-channel</li> </ul>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#rounding","title":"Rounding","text":"Speed Accuracy Nearest Good Ceil Poor Floor Fastest Poor Stochastic(Randomly up/down) Good(but large standard deviation) Logarithmic Adaptive rounding"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#linear-quantization","title":"Linear Quantization","text":"\\[ \\begin{aligned} q &amp;= \\text{clip} \\{ \\ \\text{round}(r/s) + z, 0, 2^b - 1 \\ \\} \\\\ s &amp;= \\dfrac{r_\\max - r_\\min}{2^b - 1} \\end{aligned} \\] <p>where</p> <ul> <li>\\(S =\\) scale factor</li> <li>\\(z =\\) zero point</li> <li>If \\(z=0:\\) symmetric quantization</li> <li>If \\(z \\ne 0:\\) asymmetric quantization</li> <li>\\(r_\\min\\) and \\(r_\\max\\) is usually 10<sup>th</sup> and 90<sup>th</sup> percentile</li> <li>Clip function works on any values outside the range</li> </ul> <p>Dequantization $$ r = S(q - Z) $$</p> \\[ \\begin{aligned} \\hat y &amp;= W X \\\\ &amp; \\approx S_W (W_q - Z_w) S_X (X_q -Z_x) \\\\ &amp; \\approx S_W W_q S_X Z_x &amp; (\\text{Symmetric}) \\\\ &amp; \\approx S_W W_q S_X (W_q X_q) \\\\ &amp; \\quad + \\underbrace{S_w Z_w S_x Z_x + S_x Z_x S_w W_q}_{\\text{precomputed offline } \\&amp; \\\\ \\text{ folded into bias addition}} \\\\ &amp; \\qquad  + \\underbrace{S_w Z_w S_x X_q}_\\text{Online overhead} &amp; \\text{(Assymmetric)} \\end{aligned} \\] <ul> <li>\\(W_q =\\) constant during inference</li> <li>\\(X_q =\\) new data</li> </ul> <p>Online overhead is roughly equivalent to cost of adding 1 channel</p> <ul> <li>for multiple channels, it is insignificant overhead</li> <li>for single channels, it is significant overhead</li> </ul> <p>Solution</p> <ul> <li>Use symmetric quantization for weights</li> <li>Use asymmetric quantization for activations</li> </ul>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#scale-value","title":"Scale Value","text":"Per-Tensor Per-Channel Meaning Single scale/zero for entire tensor Single scale/zero for each channel in tensor Accuracy Poor(as channels can have different ranges) Good Support in hardware Good Decent?"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#types_1","title":"Types","text":""},{"location":"CS_Electives/Tiny_ML/05_Quantization/#post-training","title":"Post Training","text":"<ul> <li>Training \u2013&gt; Quantization</li> <li>Weights</li> <li>Frozen &amp; do not change</li> <li>Can precompute scale &amp; zero point</li> <li>Activations</li> <li>scale &amp; zero-points can be calibrated using a mini batch of data</li> <li>Inputs also can be quantized to enforce int x int operations</li> </ul> <p>How to find scale and zero-point</p> <ul> <li>Run \u2018representative\u2019 mini-batches of data through DNN &amp; capture \\(r_\\max\\) and \\(r_\\min\\)</li> </ul>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#quantization-aware-training","title":"Quantization-Aware Training","text":"<p>Emulate inference-time quantization during training to improve model robustness, and then use Post Training Quantization</p> <p></p> <p></p> <p>\u201cFake quantization\u201d nodes</p> <ul> <li>Input: float</li> <li>Output: float</li> <li>Operation:</li> <li>Quantize</li> <li>Dequantize</li> <li>Result</li> <li>Floats that are clip and rounded like ints</li> </ul> <p></p>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#non-linear-quantization","title":"Non-Linear Quantization","text":"<p>K-means clustering</p> <ul> <li>Represent each group of numbers by a single \u201ccentroid\u201d</li> <li>Choose how many clusters you want</li> <li>For \\(k\\)\u00a0Clusters, you need \\(\\log_2 k\\)\u00a0bits to represent centroids</li> </ul> <p></p> <p>De-quantization function: Lookup table</p> Cluster Index Centroid Value 0 0.153 1 0.223 \u2026 \u2026 <p></p> <p>Advantages</p> <ul> <li>No effect on operation itself - still full precision</li> <li>Storage footprint reduced drastically</li> <li>Accuracy [typically] well preserved</li> </ul> <p>Disadvantages</p> <ul> <li>Only applicable to weights</li> </ul> <p>Outliers in LLM quantization</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/05_Quantization/#product-quantization","title":"Product Quantization","text":"<p>Quantize group of numbers into a \u2018prototype\u2019</p> <p>Steps</p> <ol> <li>Prototype learning</li> <li>In an initial, offline training phase, cluster the rows of \\(A\\) (or training set \\(\\tilde A\\)) using \\(k\\) means to create prototypes</li> <li>A separate \\(k\\) means is run in each of the \\(C\\) disjoint subspaces to produce \\(C\\) sets of \\(k\\)\u00a0prototypes</li> <li>Encoding function</li> <li>Determine the most similar prototype to \\(a\\) in each subspace</li> <li>Store these assignments as integer indices using \\(C \\log_2 (k)\\) bits</li> <li>Table construction</li> <li>Precompute the dot products between \\(b\\) and each prototype in each subspace</li> <li>Store these partial dot products in \\(C\\)\u00a0lookup tables of size \\(k\\)</li> <li>Aggregation</li> <li>Use the indices and tables to lookup the estimated partial \\(a^T b\\) in each subspace</li> <li>Sum the results across all \\(C\\)\u00a0subspaces</li> </ol> <p></p>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/","title":"Pruning","text":"<ol> <li>Train ANN</li> <li>Remove \\(p \\%\\) of parameters with smallest magnitude</li> </ol>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#terms","title":"Terms","text":"Pruning Rate \\(p\\) Sparsity Rate \\(1-p\\) Compression \\(1/s\\)"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#pruning-mask","title":"Pruning Mask","text":"<p>The filter that causes the pruning $$ Y = X \\cdot (W \\odot M) $$</p>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#weight-distribution","title":"Weight Distribution","text":""},{"location":"CS_Electives/Tiny_ML/06_Pruning/#when","title":"When","text":"<ul> <li>Before training: at initiationization</li> <li>During training</li> <li>After training</li> </ul> <p>Pruning at initialization</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#what","title":"What","text":"Local Global Remove least important \\(p \\%\\) of weights in each layer Remove least important \\(p \\%\\) of weights in entire DNN Better Disadvantage May cause layer collapse: Removal of all parameters of certain layer <p>Solution for Layer collapse</p> <ul> <li>Hard constraints: if lyre collapse then stop pruning</li> <li>Iterative pruning: fine-tuning helps to equalize the weight magnitudes</li> </ul> Unstructured Structured Remove blocks of size of dot product in hardware Remove Individual weights ChannelsFilters (N:M) Advantage Can be accelerated on any hardware Higher rates Compression Better Limitation May cause shape mismatch: no of channels not equal for inputs into future layer, thereby not allowing it <p></p> <p></p>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#encourage-sparsity","title":"Encourage Sparsity","text":"<p>Add regularization penalty to weights</p> <ul> <li>L1-norm</li> <li>L2-norm</li> <li>L\\(\\infty\\)-norm</li> </ul> <p></p>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#pruning-criteria","title":"Pruning Criteria","text":"<p>How to prune</p> <p>Remove least important</p> <ul> <li>Magnitude</li> <li>Gradient</li> <li>Learned</li> <li>Information</li> <li>Salience: The change in the loss function with and without a parameter</li> <li>Gradient-based</li> <li>Information-based</li> </ul>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#salience","title":"Salience","text":"\\[ \\Delta L_j (w; D) = L( 1 \\cdot w; D) - L \\Big( (1-e_j) \\cdot w; D \\Big) \\] <p>where</p> <ul> <li>\\(\\Delta L_j =\\) change in loss function</li> <li>\\(w=\\) weights</li> <li>\\(D =\\) dataset</li> <li>\\(1 =\\) unit vector</li> <li>\\((1-e_j) =\\)\u00a0pruning mask</li> </ul> <p>However, this is intractable</p>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#optimal-brain-damage","title":"Optimal brain damage","text":"<p>The hessian of a neural network is intractable to compute</p> <p>Salience $$ s_j = \\begin{cases} \\vert w_j \\vert &amp; \\text{magnitude-based} \\ \\dfrac{w^2_j}{2 \\times H^{-1}_{jj}} &amp; \\text{gradient-based}  \\end{cases} $$ Delete the lowest saliency parameters</p>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#mutual-information","title":"Mutual Information","text":"<p>Measure of how information is present in one var about another var $$ \\begin{aligned} \\vert \\Delta L(h_i) \\vert &amp;= \\vert L(D, h_i=0) - L(D, h_i=1) \\vert &amp; \\text{(1)} \\ &amp; = \\left \\vert \\dfrac{\\partial L}{\\partial h_i} h_i \\right \\vert &amp; \\text{(2)} \\end{aligned} $$</p> <ol> <li>Impact on loss function \\(L\\) when activation channel \\(h_i\\) is set to 0 and when it is not</li> <li>Gradient of loss function wrt activation map -&gt; intuitively prunes channels that don\u2019t impact loss function</li> </ol>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#fisher-information","title":"Fisher information","text":""},{"location":"CS_Electives/Tiny_ML/06_Pruning/#how-often","title":"How often","text":"<ul> <li>One-shot</li> <li>Iterative</li> </ul>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#iterative-magnitude-pruning-imp","title":"Iterative Magnitude  Pruning (IMP)","text":"<ol> <li>Train ANN</li> <li>Remove \\(p \\%\\) of params with smallest magnitude</li> <li>Retrain ANN: \u2018Fine-tune\u2019</li> <li>Repeat steps 2-3</li> </ol>"},{"location":"CS_Electives/Tiny_ML/06_Pruning/#weight-distributions","title":"Weight distributions","text":""},{"location":"CS_Electives/Tiny_ML/06_Pruning/#idk","title":"IDK","text":"<ul> <li>Dynamic iterative pruning: Allow parameters to \u2018come back to life\u2019: Correction of a pruning decision</li> <li>Runtime pruning: Learn which parameters/channels to drop at runtime based on input data</li> <li>Learnt pruning mask: Use back propagation to learn aspects of pruning algo during training</li> <li>What to prune</li> <li>Pruning Threshold per layer</li> </ul>"},{"location":"CS_Electives/Tiny_ML/07_Knowledge_Distillation/","title":"Knowledge Distillation","text":"<p>Distill \u201cknowledge\u201d from large ANN to small ANN</p> <ul> <li>Larger DNNs are easier to train</li> <li>Smaller DNNs are easier to deploy</li> </ul> <p>Targets</p> <ul> <li>Hard targets: No info about wrong classes</li> <li>Soft targets: Have info about wrong classes</li> <li>Get using expert annotation</li> <li>From a trained NN</li> </ul> <p></p> <ul> <li>Training</li> <li>Use softmax with temperature, usually \\(T=5\\) </li> <li>Loss function: Distillation loss + Student loss</li> <li>Inference</li> <li>T=1</li> </ul> <p>Teacher target can be from an ensemble of</p> <ul> <li>multiple initializations</li> <li>multiple teacher architectures</li> <li>Specialists &amp; generalists</li> </ul>"},{"location":"CS_Electives/Tiny_ML/07_Knowledge_Distillation/#distillation-types","title":"Distillation Types","text":"Type Offline Pre-trained teacher network Collaborative/mutual learning Teacher &amp; student trained simultaneously Self-distillation Eg: Progressive hierarchical inference"},{"location":"CS_Electives/Tiny_ML/07_Knowledge_Distillation/#distillation-algorithms","title":"Distillation Algorithms","text":"Adversarial Teacher also acts as discriminator in GAN to supplement training data to \u201cteach\u201d true data distribution Multi-Teacher Cross-Modal Teacher trained on RGB distills info to student learning on heat maps.Unlabeled image pairs needed Graph-Based Attention-Based Data-Free Quantized Use full-precision network to transfer knowledge to quantized network Lifelong NAS-Based"},{"location":"CS_Electives/Tiny_ML/07_Knowledge_Distillation/#knowledge-types","title":"Knowledge Types","text":"Response-based Output probs as soft targets Most common Feature-based - Output/weights of 1 or more \u201chint layers\u201d and minimize MSE lossor- Minimize difference in attention maps between student &amp; teacher Relation-based Correlations between feature maps; eg: Gramian"},{"location":"CS_Electives/Tiny_ML/08_NAS/","title":"Neural Architecture Search","text":"<ul> <li>Number of layers</li> <li>Operation at each layer</li> <li>Hyper-parameters of each operation</li> <li>Topology &amp; connectivity</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#objective","title":"Objective","text":"<ul> <li>Minimize: Loss/Accuracy</li> <li>Minimize: Time taken to train</li> <li>Minimize: Latency</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#search-space","title":"Search Space","text":"<ul> <li>Operation types \\(o\\)</li> <li>Number of layers \\(n\\)</li> </ul> <p>Total number of possible DNNs \\(= o^d\\)</p>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#training-techniques","title":"Training Techniques","text":"<ul> <li>Full training</li> <li>Proxy instead of training</li> <li>Parameter sharing</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#algorithms","title":"Algorithms","text":"<ul> <li>Random search</li> <li>Reinforcement learning</li> <li>Genetic algorithms</li> <li>Prediction-based search</li> <li>Differential architecture search</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#reinforcement-learning","title":"Reinforcement Learning","text":"<pre><code>flowchart LR\nc[\"Controller&lt;br&gt;DNN\"] ---&gt;\n|Sample arhicterue A&lt;br&gt;with prob p| t[\"Train child network&lt;br&gt;with architecture A&lt;br&gt;to obtain accuracy R\"] ---&gt;\n|Compute gradient of p&lt;br&gt;and scale it by R&lt;br&gt;to update controller| c</code></pre> <p>Policy gradient algorithm</p> <ul> <li>Function parameterized with parameters \\(\\theta\\): DNN</li> <li>Action: DNN architecture parameters</li> <li>State space: All set of possible DNNs in search space</li> <li>Reward to update \\(\\theta\\): Objective (accuracy)</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#predictor-based-search","title":"Predictor-based search","text":"<p>We don\u2019t need exact accuracy of architecture; just need the relative rankings of different architectures</p> <ol> <li>Train predictor on \\(T\\) DNNs</li> <li>Use predictor to sort \\(N\\) models, where \\(N &gt;&gt; T\\)</li> </ol> <p></p>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#differentiable-architecture-search","title":"Differentiable Architecture Search","text":"<p>Optimize architecture parameters \\(\\alpha\\) during training, then keep operations with largest \\(\\alpha\\)</p> <ul> <li>Bi-level optimization</li> <li>DARTS</li> </ul> <p></p>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#nas-efficiency","title":"NAS Efficiency","text":"<ul> <li>More efficient search algorithm</li> <li>Smaller search space</li> <li>Inexpensive accuracy proxy rather than training</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#cell-based-nas","title":"Cell-based NAS","text":"<p>\\(c\\) cells, \\(o\\) ops per cell, each op has \\(k\\) choices</p> Search Space Micro Search for a \u201ccell\u201dPlace the same cell everywhere \\(k^o\\) Macro Search for each cell independently \\(k^{o^c}\\) <p></p>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#parameter-sharing","title":"Parameter Sharing","text":"<p>Use trained parameters from previous sample</p> <p>1000x faster than conventional NAS</p> <p>Inspired by Transfer Learning</p>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#training-proxies","title":"Training Proxies","text":"<p>Instead of training to convergence to evaluate each model, estimate accuracy by reducing</p> <ul> <li>Number of epochs</li> <li>Subsample training set</li> <li>Lower data resolution</li> <li>Downscale model being evaluated</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#hardware-aware-nas","title":"Hardware-aware NAS","text":"<p>Customize DNN architecture for specific device</p> <ul> <li>Hard constraint: Reject models slower than target</li> <li>Soft constraint: Weighted sum of accuracy &amp; latency</li> </ul> <p>Latency evaluation</p> <ul> <li>Run inference on target device</li> <li>Estimation</li> <li>Graph neural networks</li> <li>No of parameters</li> <li>Use FLOPs</li> </ul>"},{"location":"CS_Electives/Tiny_ML/08_NAS/#codesign-nas","title":"Codesign NAS","text":"<p>Add hardware search space</p>"},{"location":"CS_Electives/Tiny_ML/09_Kernel_Computation/","title":"Kernel Computation","text":""},{"location":"CS_Electives/Tiny_ML/09_Kernel_Computation/#machine-learning-software-stack","title":"Machine Learning Software Stack","text":"<p>PyTorch is just a wrapper for writing CuDNN/MKL-DNN code</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/09_Kernel_Computation/#kernel-implementations","title":"Kernel Implementations","text":"Limitation Im2col Convert image windows to columns of matrixorReplicate weights instead and flatten imageUse to implement convolution as matrix multiplication Data replication at algorithmic level may increase demand for external memory bandwidth Strassen\u2019s MM transform Reduce no of multiplications in MM through reorganizing operations and offline computation Transform limitation Winograd Conversion transform Reduce no of multiplications in Conv through reorganizing operations and offline computationSpecific to- supported filter size- tile size of input Transform limitation Alpha Tensor FFT-Transform Conv becomes multiplicationFilter needs to zero-pad to ensure same size as outputOnly useful for filter size &gt;= log of output size for effectiveness, else IFFT overhead exceeds the gain Transform limitationIFFT is costly overhead Log-domain multiplication \\(ab = 2^x 2^y = 2^{x+y} = 2^z\\)Only convert magnitude of numbersCompute sign using small circuit\\(s_c = s_a \\oplus s_b\\) Finding log &amp; exponents at high precision is expensiveNo straightforward add operation in log domain <p>Transform limitation: Requires transform to be performed at high precision to avoid accuracy detoriation</p>"},{"location":"CS_Electives/Tiny_ML/09_Kernel_Computation/#low-rank-approximation","title":"Low-Rank Approximation","text":"SVD: Singular Value Decomposition \\(M = U \\Sigma V\\)Speedup = \\(\\dfrac{mn}{k (m+n)}\\) Tensor decomposition Tucker DecompositionCanonical Polyadic"},{"location":"CS_Electives/Tiny_ML/10_Mapping/","title":"Mapping &amp; Compilation","text":""},{"location":"CS_Electives/Tiny_ML/10_Mapping/#parts-of-compiler","title":"Parts of Compiler","text":"<ul> <li>Frontend: Prog lang to IR (Intermediate Representation)</li> <li>Middle-end (Optimizer)</li> <li>Backend: IR to Assembly/Machine code (Code generator)</li> </ul>"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#ml-compilation-system","title":"ML Compilation System","text":""},{"location":"CS_Electives/Tiny_ML/10_Mapping/#mapping-onto-hardware","title":"Mapping onto Hardware","text":"<ul> <li>Dataflow choice</li> <li>Tiling</li> <li>Vectorization</li> <li>Bind ops to PEs</li> <li>On-chip memory management</li> </ul>"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#dataflow-selection","title":"Dataflow selection","text":"<p>Compiler can re-order loops without changing functionality</p> <p>Compiler heuristics can model approximate effect on runtime and memory access</p> <p>Eg: 1D Convolution</p> Weight stationary Output stationary Input stationary"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#tiling","title":"Tiling","text":"<p>Choose tile size on which to operate, to fit data in various parts of memory system</p> <p>Break a loop into nested loops, each of which can be mapped hierarchically onto memory system (DRAM, SRAM, Registers)</p> <p></p> <p>Other names</p> <ul> <li>CUDA: Thread Block</li> <li>OpenCL: Work Group</li> </ul> <p></p>"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#vectorization","title":"Vectorization","text":"<p>Parallelize operations within smallest tile, to leverage hardware parallelism</p> <p></p> <p></p>"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#binding","title":"Binding","text":"<p>Specify PE index \\(i\\) that will execute loop iteration \\(j\\)</p> <p>Applicable when no of PEs \\(\\ne\\) no of loop iterations</p>"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#on-chip-memory-management","title":"On-chip memory management","text":""},{"location":"CS_Electives/Tiny_ML/10_Mapping/#graph-compiler","title":"Graph Compiler","text":""},{"location":"CS_Electives/Tiny_ML/10_Mapping/#on-chip-buffer","title":"On-Chip buffer","text":"<p>\u201cSpatio-temporal tetris\u201d</p> <p>Mem management passes:</p> <ul> <li>Scheduling: order of subgraph execution</li> <li>Allocation: where to put data in buffer</li> <li>Slicing/fusing: how to break/merge operations</li> </ul> <p></p> <p></p>"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#mapping-space","title":"Mapping Space","text":"<p>Usually very large</p> <ul> <li>Many mappings are functionally-identical; eg: binding operations differently</li> <li>Many mappings are invalid; eg: tile size doesn\u2019t fit in memory</li> </ul> <p>Navigate space using heuristics</p> <p>Informed by device performance/energy models</p>"},{"location":"CS_Electives/Tiny_ML/10_Mapping/#dla-isa","title":"DLA ISA","text":"<ul> <li>Domain-specific, simple ISAs</li> <li>VLIW: Very Long Instruction Word is common</li> </ul> <p>As time progresses, for DLAs, compiler need not worry about loop nests/mapping data flows, as this is all handled in hardware</p> <p>Operation fusion: Coarse-grained optimizations</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/11_Processing/","title":"Pre/Post Processing","text":"<p>Amdahl\u2019s Law</p>"},{"location":"CS_Electives/Tiny_ML/11_Processing/#layers-of-overhead-for-dnn","title":"Layers of Overhead for DNN","text":"<p>At the application level, \u201coverheads\u201d can take more time than the DNN itself</p> <p></p> <p>Example: Face Recognition</p> <p></p> <p></p> <p></p>"},{"location":"CS_Electives/Tiny_ML/11_Processing/#host-accelerator","title":"Host + Accelerator","text":"<ul> <li> <p>Model</p> </li> <li> <p>Sits in CPU main memory</p> </li> <li> <p>Transferred over PCIe to GPU mem</p> </li> <li> <p>Input data</p> </li> <li> <p>Arrives over ethernet to CPU</p> </li> <li>Transferred over PCIe to CPU</li> <li>Inference/Training</li> <li>Result send back to CPU over PCIe</li> </ul> <p>Latency impacted by data transfers</p>"},{"location":"CS_Electives/Tiny_ML/11_Processing/#solution-1-multiple-gpu-cores","title":"Solution 1: Multiple GPU Cores","text":""},{"location":"CS_Electives/Tiny_ML/11_Processing/#solution-2-multiple-cpu-cores","title":"Solution 2: Multiple CPU Cores","text":""},{"location":"CS_Electives/Tiny_ML/11_Processing/#solution-3-dedicated-gpu-gpu-connections","title":"Solution 3: Dedicated GPU-GPU connections","text":"<p>NVLink</p> <p></p>"},{"location":"CS_Electives/Tiny_ML/11_Processing/#dedicated-fpga-for-packet-processing","title":"Dedicated FPGA for Packet Processing","text":""},{"location":"CS_Electives/Tiny_ML/11_Processing/#algorithm-codesign-opportunities","title":"Algorithm Codesign Opportunities","text":""},{"location":"CS_Electives/Tiny_ML/11_Processing/#on-device-deployment","title":"On-Device Deployment","text":"<p>CPU, GPU, NPU share the same memory on the SOC (System On Chip)</p>"},{"location":"CS_Electives/Tiny_ML/11_Processing/#mobile-cloud-inference","title":"Mobile-Cloud Inference","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/","title":"Decentralized Learning","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#types","title":"Types","text":"Distributed Offloading Federated Collaborative Learning Send data to central server for trainingDevice only used as sensor - Data never stored in data center- Encrypt data and only decrypt after averaging 1000 updates Each device maintains functional model Model Location Servers Servers DeviceAggregated on Cloud Device Data Location DeviceServers DeviceServers Device Device Design goals Speed PrivacyOnline learningSecurityScale Device Types Same Different Device Compute Power High Low Training Complex Simple Run training when phone chargingTransmit updates when WiFi available Training examples Next-word prediction Number of devices 10-1k 100k+ Network speed Fast Slow Network reliability Reliable Intermittent Data Distribution IID Non-IID(Each device has own data distribution)Not representative of training data Applications - Privacy  - Personal data from devices  - Health data from hospitals- Continuous data  - Smart home/city  - Autonomous vehicles Advantages - Save device battery- No need to support on-device training- Better accuracy? - Most secure: Data never aggregated to a central server that could be compromised- Most scalable: No central server with bandwidth limitations Limitations - poor privacy- worse scalability Not fully private: You can recover data from model parameters/gradient updatesConsumes higher total energy Challenges Poor network All challenges of FL Example Google Photos"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#terms","title":"Terms","text":"Straggler Device that doesn\u2019t return data on time Data Imbalance One devices has 10k samples, while 10k devices have 1 sample each"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#terms_1","title":"Terms","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#compression","title":"Compression","text":"<ul> <li>Gradient</li> <li>Data</li> </ul>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#quantization","title":"Quantization","text":"<p>Quantization to gradients before transmission</p> <p>Communication cost drops linearly with bit width</p>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#pruning","title":"Pruning","text":"<p>Prune gradients based magnitude and compress zeroes</p>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#distributed-training","title":"Distributed Training","text":"<ul> <li>Model Parallelism: Fully-Connected layers</li> <li>Data Parallelism: Convolutional layers</li> </ul>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#single-gpu-system","title":"Single GPU-system","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#model-parallelism","title":"Model Parallelism","text":"<p>All workers train on same batch</p> <p>Workers communicate as frequently as network allows</p> <p></p> <p>Necessary for models that do not fit on a single GPU</p> <p>No method to hide synchronization latency</p> <ul> <li>Have to wait for data to be sent from upstream model split</li> <li>Need to think about how pipelining would work for model-parallel training</li> </ul> <p>Types</p> <ul> <li>Inter-layer</li> <li>Intra-layer</li> </ul> <p>Limitations</p> <ul> <li>Overhead due to</li> <li>moving data from one GPU to another via CPU</li> <li>Synchronization</li> <li>Pipelining not easy</li> </ul>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#data-parallelism","title":"Data Parallelism","text":"<p>Each worker trains the same convolutional layers on a different data batch</p> <p>Workers communicate as frequently as network allows</p> Communication Overhead Advantage Limitation Single-GPU Multiple GPU Average gradients across minibatch on all GPUsOver PCIe, ethernet, NVLink depending on system \\(kn(n-1)\\) High communication overhead Parameter Server Parallel Parameter Sharing \\(k\\) per worker\\(kn/s\\) for server Ring Allreduce Each GPU has different chunks of the mini-batch \\(2k\\dfrac{n-1}{n}\\) ScalableCommunication cost independent of \\(n\\) <p>where - \\(n=\\) no of client GPUs - \\(k =\\) no of gradients - \\(s=\\) no of server GPUs</p>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#ring-allreduce","title":"Ring-Allreduce","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#step-1-reduce-scatter","title":"Step 1: Reduce-Scatter","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#step-2-allgather","title":"Step 2: Allgather","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#weight-updates-types","title":"Weight Updates Types","text":"Synchronous Asynchronous Working - Before forward pass, fetch latest parameters from server- Compute loss on each GPU using these latest parmeters- Gradients sent back to server to update model Speed per epoch Slow Fast Training convergence Fast Slow Accuracy Better Worse"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#pipeline-parallelism","title":"Pipeline Parallelism","text":""},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#federated-learning","title":"Federated Learning","text":"<p>\u201cFederated\u201d: Distributed but \u201creport to\u201d one central entity</p> <p>Conventional learning</p> <ul> <li>Data collection</li> <li>Data Labeling (if supervised)</li> <li>Data cleaning</li> <li>Model training</li> </ul> <p>But new data is generated very frequently</p>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#steps","title":"Steps","text":"<ol> <li>Download model from cloud to devices</li> <li>Personalization: Each device trains model on its own local data</li> <li>Devices send their model updates back to server</li> <li>Update global model</li> <li>Repeat steps 1-4</li> </ol> <p>Each iteration of this loop is called \u201cround\u201d of learning</p>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#algorithms","title":"Algorithms","text":"Handling Stragglers Handling Data Imbalance FedAvg The more data points a device has, the higher weight of device in updating global model Drop Poor FedProx Use partial results Discourage large weight updates through regularization\\(\\lambda {\\vert \\vert w' - w \\vert \\vert}^2\\)\\(w=\\) Weight of single device q-fed-avg Discourage large weight updates for any single device per-per-avg"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#data-labelling","title":"Data Labelling","text":"<p>How to get labels</p> <ul> <li>Sometimes explicit labeling not required: Next-work prediction</li> <li>Need to incentivize users to label own data: Google Photos</li> <li>Use data for unsupervised learning</li> </ul>"},{"location":"CS_Electives/Tiny_ML/12_Decentralized_Learning/#types_1","title":"Types","text":"Horizontal Vertical Transfer"},{"location":"Economics/","title":"Economics","text":"<p>Social science that studies - how people interact with __  for their livelihoods     - each other     - natural surroundings - how this changes over time</p> <p>Mixture of Sociology and Political Sciences</p> <p>Grounded on the principle that 'the market knows best'</p>"},{"location":"Economics/#fields","title":"Fields","text":"Field Studies Key Areas Methodology Tools Micro Individual units and how they interact with each other in a world with scarce resources ProducersConsumersFirms Macro Understand the economy as a wholeEffects of large scale economic decisions on entire societyNot just large-scale of microeconomics Economy- Output level- Inflation- Unemployment- Exchange rate- Large-scale interactions- Equilibrium effects Industrial Market structures and firm interactions Market power, competition, antitrust policy Theoretical models, empirical analysis Game theory, econometrics Managerial Business decision-making processes Demand analysis, cost analysis, pricing Application of economic principles Statistical analysis, forecasting"},{"location":"Economics/#model","title":"Model","text":"<p>Simplified representation of a system with assumptions</p> <p>Economic models are not like scientific laws</p>"},{"location":"Economics/#purpose","title":"Purpose","text":"<ul> <li>simplify economic decisions</li> <li>how to change outcomes</li> <li>focus on what's important</li> <li>built with assumptions</li> <li>omits details</li> </ul>"},{"location":"Economics/#characteristics-of-a-good-model","title":"Characteristics of a good model","text":"<ol> <li>Simple</li> <li>Easy to work with</li> <li>Insightful</li> <li>Generalizable</li> <li>Easy to test, and thereby accept/reject</li> <li>Empirically consistent</li> <li>Predictive precision</li> </ol>"},{"location":"Economics/#movies","title":"Movies","text":"<ul> <li> the good the bad the ugly</li> <li> coach carter movie</li> <li> the beautiful mind</li> </ul>"},{"location":"Economics/#references","title":"References","text":""},{"location":"Economics/Behavioral_Economics/","title":"Behavioral Economics","text":""},{"location":"Economics/Behavioral_Economics/#overview","title":"Overview","text":"<ol> <li>Introduction</li> <li>Preferences</li> <li>Time preferences</li> <li>Self-control</li> <li>Risk preferences</li> <li>Reference-dependent preferences</li> <li>Social preferences</li> <li>Unit</li> <li>Emotions, projection &amp; attribution bias</li> <li>Limited attention</li> <li>Beliefs &amp; learning</li> <li> <p>Mental accounting</p> </li> <li> <p>Unit</p> </li> <li>Malleability &amp; inaccessibility of preferences</li> <li>Happiness</li> <li>Mental health</li> <li> <p>Gender &amp; racial discrimination</p> </li> <li> <p>Unit</p> </li> <li>Frames, defaults, nudges</li> <li>Policy &amp; paternalism</li> <li>Poverty through lens of psychology</li> </ol>"},{"location":"Economics/Behavioral_Economics/#references","title":"References","text":"<ul> <li> MIT 14.13 Psychology and Economics</li> <li> Neuroeconomics | Saul Leung UvA</li> <li> Judgement &amp; Decision Making | Lace Padilla</li> <li> Behavioural Economics | Jason Collins<ul> <li> Videos</li> <li> Notes</li> </ul> </li> <li> Behavioural Finance | Jason Collins</li> <li> Applied consumer financial decision making | Jason Collins</li> <li> Corporate decision making | Jason Collins</li> </ul>"},{"location":"Economics/Behavioral_Economics/#next-video","title":"Next video","text":"<p>https://www.youtube.com/watch?v=iS2xziBbJdA&amp;list=PLU7KwChgei4GOqg7PiqcfEd0y6HVOclzg</p>"},{"location":"Economics/Behavioral_Economics/01_Introduction/","title":"Introduction","text":"<p>Behavioral economics discards the Assumptions of Classical Economics, and analyzes psychological factors.</p>"},{"location":"Economics/Behavioral_Economics/01_Introduction/#how-does-economics-view-human-behavior","title":"How does economics view human behavior?","text":"<p>Humans have goal-driven individual behavior with constrained optimization</p> <ol> <li>Utility function: What makes people happy</li> <li>Instantaneous</li> <li>Time, Risk, Social Preferences</li> <li>Beliefs: What do people believe about environment</li> <li>Physical environment</li> <li>Others\u2019 behavior</li> <li>Use of information to update beliefs</li> <li>Choice/Decision-making: How do people use the above to make decisions</li> <li>Some influences on behavior are not about utility/beliefs</li> <li>Frames, Defaults, Nudges; heuristics</li> </ol>"},{"location":"Economics/Behavioral_Economics/01_Introduction/#social-preferences","title":"Social Preferences","text":"<p>Classical economics assumes that humans are selfish</p> <p>Behavioral economics</p> <p>People care about others, but not pure altruism (behavior that benefits another at one\u2019s own expense)</p> <ol> <li>Helping others actually makes you happier</li> <li>To show-off to others</li> <li>Reciprocity</li> <li>Inequality aversion</li> </ol>"},{"location":"Economics/Behavioral_Economics/01_Introduction/#game-to-measure-peoples-preferences","title":"Game to measure people\u2019s preferences","text":"<p>Dictator\u2019s game</p> <p>Imagine you have been given <code>$10</code> to split between yourself and another, randomly-chosen person. You can keep any part of the <code>$10</code>, and give the rest to the other person.</p> <p>2 ways</p> <ol> <li>Recipient informed about the circumstances of the decision. Self-image</li> <li>Recipient might never notice (money is wired anonymously). Pure altruism </li> </ol>"},{"location":"Economics/Behavioral_Economics/01_Introduction/#anchoring","title":"Anchoring","text":"<p>People think in relative terms, not absolute terms of money</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/","title":"Time Preferences","text":"<p>Most non-trivial economic choices involve </p> <ol> <li>Determine tradeoffs between costs and benefits that occur across time points</li> <li>Determine values (utility) of costs and benefits, by weighing costs &amp; benefits against each other</li> </ol>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#present-bias","title":"Present Bias","text":"<p>Humans have a tendency to put more weight into the present rather than the future when making decision</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#utility-function","title":"Utility Function","text":"\\[ \\begin{aligned} \\max U_t &amp;= \\sum_{t = 0}^\\infty D(t) \\cdot u_{t_0 + t} \\\\ u_t &amp;= u(c_t, l_t, \\dots) \\end{aligned} \\] <p>where</p> \\(u_t\\) Instantaneous utility Captures how person feels at a specific momentFunction of consumption, leisure \\(U_t\\) Discounted utility Captures total utility obtained until a specific moment \\(D(t)\\) Discount Function Specifies weights on utility derived in \\(t\\) time periodsMeasures how utility in alter periods is discounted relative to earlier periodsReplaces complex psychology of how people think about futureUsually \\(\\in (0, 1]\\) \\(\\rho(t)\\) Discount Rate Rate of decline in the discount functionSpecifies rate at which value of \\(u\\) declines with delay \\(\\dfrac{-D'(t)}{D(t)}\\)"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#standard-utility-models","title":"Standard Utility Models","text":"Samuelson\u2019s Exponential Quasi-Hyperbolic Non-graphical model of Fisher\u2019s Time-Indifference CurveDeveloped as a simple approximation as a first start, not meant to be accurate \\(D(t)\\) \\(\\delta^t\\)\\(\\delta \\in [0, 1]\\) \\(\\beta \\delta^t\\)\\(\\delta \\to 1; \\delta \\approx 0.\\bar{9}\\)\\(\\beta \\in [0, 1]\\) \\(\\rho(t)\\) \\(- \\log \\vert \\delta \\vert \\approx 1-\\delta\\) Advantages Not affected by awareness issue - Separate short &amp; long-run discounting- Great patience for tradeoffs in the future than for tradeoff in present- Deals with preference reversals Limitation Constant discount rate1. Short vs Long-Run impatience2. Preference reversals3. Commitment devices Affected by awareness issue"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#estimating-delta","title":"Estimating \\(\\delta\\)","text":"<p>Ask the person the following question</p> <p>What \\(X\\) makes you indifferent between receiving <code>$15</code> today and <code>$X</code> at various time point \\(t\\)</p> <ul> <li>\\(t=1\\) day</li> <li>\\(t=1\\) month</li> <li>\\(t=1\\) year</li> </ul> <p>Assumes that utility is linear in money, ie marginal utility is constant, ie \\(u(X) = X\\)</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#idk","title":"IDK","text":""},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#short-vs-long-run-impatience","title":"Short vs Long-Run Impatience","text":"<p>People tend to be more patient in the long-run than in the short-run</p> <p>Eg: Credit card loans</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#preference-reversals","title":"Preference Reversals","text":"<p>In reality, dynamic consistency is not followed. People don\u2019t always follow through with their plans.</p> <p>Hence</p> <ul> <li>When thinking ahead to the future, we want to be patient</li> <li>When the time actually comes, we are impatient</li> <li>People are over-confident about their self-control</li> </ul> <p>Eg: Dieting, Gym membership</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#dynamictime-consistency","title":"Dynamic/Time Consistency","text":"<ul> <li>The action a person thinks they should take in the future always coincides with the action that they actually prefer to take once the time comes</li> <li>A person\u2019s preferences at different points in time are consistent with each other; there are no \u201cintra-personal conflicts\u201d </li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#commitment-devices","title":"Commitment Devices","text":"<p>Arrangement taken upon by agent to restrict their future choice set, by making certain choices more costly</p> <p>Demand for commitment requests (at least partial) sophistication</p> <p>When you know that your future preferences will be different from present preferences, you may engage in commitment devices to penalize (and hence eliminate) few options from the future. We disapprove of the tendency for instant gratification beforehand, but struggle to actually follow through</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#requirements-for-effectiveness-of-commitment-device","title":"Requirements for effectiveness of commitment device","text":"<ul> <li>Person needs to have a self-control problem: \\(\\beta &lt; 1\\)</li> <li>Person needs to at least partly be sophisticated: \\(\\hat \\beta &lt; 1\\)</li> <li>Commitment devices needs to be effective</li> <li>Person needs to believe that the commitment device is effective</li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#things-that-worsen-effectiveness-of-commitment-devices","title":"Things that worsen effectiveness of commitment devices","text":"<ul> <li>Time-inconsistent preferences: Each time period\u2019s self restrict set of choices for their future selves, and hence there may be difference in assessment of best action at each time period</li> <li>Substitution: Substitution across temptation goods worsens effectiveness of commitment devices. Avoiding one temptation good may lead to increases consumption of another</li> <li>Naivete: Person underestimates their present bias, and might</li> <li>Naive: Not demand a helpful commitment device</li> <li>Partial naive: Demand a unhelpful commitment device</li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#goods-types","title":"Goods Types","text":"Leisure Investment Example Eating Candy Going to GymFinishing assignmentsQuitting bad habitsFinding a job Costs Delayed Immediate Rewards Immediate Delayed ResultConsumption relative to long-run Over-consumption Under-consumption"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#behavior-types","title":"Behavior Types","text":"PerfectExponential Discounter Na\u00efvet\u00e9 Partial Na\u00efvet\u00e9 Sophistication \\(\\beta\\) \\(1\\) \\(&lt; 1\\) \\(&lt;1\\) \\(&lt; 1\\) \\(\\hat \\beta\\)What you think \\(\\beta\\) is in the future \\(\\beta\\) \\(1\\) \\(&gt; \\beta\\)Measures belief about future \\(\\beta\\) \\(\\beta\\) Optimism Perfect Over-optimistic(Assumes future self will through on optimal plan) Underestimate degree of future present bias Pessimistic Person self-aware of preference reversal N/A(No preference reversal) \u274c \u2705 \u2705 Overcommitment/Self-control problem \u274c \u274c \u2705 \u274c Set deadlines optimally \u2705 \u274c(No perceived need to choose deadlines) \u26a0\ufe0f(Tries, but fails) \u2705 Deadlines help Deadline not required \u2705 \u26a0\ufe0f \u2705 Take advantage of commitment devices Not required \u274c \u26a0\ufe0f(Tries, but fails) \u2705 No surprises of future present bias No present bias \u274c \u274c \u2705 Overcomes short-run impatience No impatience \u274c \u274c \u2705 Utility Evaluation Forward1. Start at beginning2. Solve for optimal plan, assuming future self follows plan3. Person takes first step in that plan4. Go to next period5. Go to step 2 Backward &amp; Forward1. Start at the end2. Solve for what the person thinks they will do (using \\(\\hat \\beta\\)) (this is like solving for sophisticated person with \\(\\hat \\beta = \\beta\\))3. Work your way to first period using backward induction until period 2 (using \\(\\hat \\beta\\))4. Solve for optimal action in period 1 (using \\(\\beta\\) and already derived prediction on future behavior)5. Move to next period6. Go to step 2 Backward1. Start at end2. Solve for optimal action3. Go back to previous period4. Solve for optimal action, considering what happens in next period5. Go to step 3 Investment Goods: Behavior No procrastination Na\u00efve Procrastination Sophisticated Procrastination Investment Goods: Welfare Cost 0 Large Low Leisure Goods: Behavior No precrastination Na\u00efve precrastination Sophisticated precrastination(self-aware about impatience, and hence consumes earlier) Leisure Goods: Welfare Cost 0 Low Large(does not wait until max enjoyment)"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#utility-evaluation","title":"Utility Evaluation","text":""},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#example","title":"Example","text":"<p>Consider the following table showing the utilities associated with watching a movie</p> <p></p> Na\u00efvet\u00e9 Sophistication Utility Evaluation t=0: Plans to go at t=3, so doesn\u2019t got=1: Plans to go at t=3, so doesn\u2019t got=2: Goes t=2: goes if she hasn\u2019tt=1: realizes she won\u2019t wait until t=3, she goest=0: realizes she won\u2019t wait until t=2 or 3, she goes Conclusion Goes at t=2, even though she planned to go at t=3 Just goes at t=0"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#indicators-of-behavior-types","title":"Indicators of Behavior Types","text":"<ul> <li>Naivete: Person mis-predicting future behavior</li> <li>Sophistication: Person\u2019s use of commitment devices</li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#uncertainties-about-future","title":"Uncertainties about Future","text":"<ul> <li>Present bias</li> <li>Planning Fallacy</li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#planning-fallacy","title":"Planning Fallacy","text":"<p>Cognitive bias where people underestimate the time, resources, and effort needed to complete a task, even when they have experience with similar tasks that took longer than planned</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#case-studies","title":"Case Studies","text":""},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#assignment-deadlines","title":"Assignment Deadlines","text":"<p>Order of effectiveness</p> <ol> <li>Imposed deadlines</li> <li>Self-imposed assignments</li> <li>no deadline for assignments</li> </ol>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#gym-membership-purchase","title":"Gym Membership Purchase","text":""},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#work","title":"Work","text":"<p>Dominated contract increases production</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#credit-card-companies","title":"Credit Card Companies","text":"<p>Consider 3 types of loans with the following interest rates for different duration of loans</p> Deal &lt; 6M &gt;= 6M Standard 10% 20% Teaser Offer 5% 20% Post-Teaser Offer 10% 15% <p>Why would more people choose the teaser offer?</p> <ul> <li>Naive borrows believe they will repay loan quickly</li> <li>They borrow more than expected</li> <li>Sophisticated borrowers don\u2019t want to use their cards in the future, so choose high future interest rate to restrain future borrowing</li> <li>Expensive commitment device</li> <li>Substitution to other credit cards would undo this strategy</li> </ul> <p>How do credit card companies use this info</p> <ul> <li>Identify who are naive and who are sophisticated</li> <li>Credit card companies want to exploit people until the point that they won\u2019t default</li> <li>Naive households are more likely to be offered hidden-fee structures</li> <li>Low introductory/teaser rates</li> <li>Photos, colors, fine print</li> <li>After introductory period, these cards feature higher interest rates, late fees and over-limit fees</li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#gym-membership-sale","title":"Gym Membership Sale","text":"<p>Similar to above, the gyms want to entice customers with cheap short-term fees but want to retain customers in the long-run as well</p>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#commitment-savings","title":"Commitment Savings","text":"Treatment Commitment offer:Restrict access to deposits SEED Encourage to save \u2705 Marketing Encourage to save \u274c Control None None <ul> <li>Offering commitment savings significant increased savings</li> <li>People still default on commitment contract</li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#alcohol-consumption","title":"Alcohol consumption","text":"<p>Low-income workers tend to drink a lot of alcohol</p> <p>Many say that</p> <ul> <li>They would like to reduce drinking</li> <li>They would happier if liquor stores closed</li> </ul> <p>Physical pain from work appears to contribute to self-control problems</p> <ul> <li>Alcohol is powerful anesthetic</li> <li>Pain increases short-run benefits of drinking while leaving long-run costs unaffected</li> </ul> <p>They can\u2019t just \u2018stop drinking\u2019 as they will face severe withdrawal syndromes</p> <ul> <li>Sobriety incentives reduce day drinking</li> <li>Individuals mostly substitute to night drinking</li> <li>No impact of incentives on labor-market outcomes</li> <li>Increased savings</li> </ul>"},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#smoking","title":"Smoking","text":""},{"location":"Economics/Behavioral_Economics/02_Time_Preferences/#farmers-fertilizers","title":"Farmers Fertilizers","text":"<p>Give option to Pre-buy fertilizer at time of harvest, much before time of sowing</p> <p>Time of sowing = when fertilizer needed</p> <p>Compared to discount at time of sowing</p> <ul> <li>More effective at getting farmers to purchase</li> <li>Expensive to give subsidies</li> <li>Subsidies will get wasted on everyone</li> <li>Subsidies may incentivize some to over-use fertilizers</li> </ul>"},{"location":"Economics/Behavioral_Economics/03_Risk_Preferences/","title":"Risk Preferences","text":""},{"location":"Economics/Causal_Inference/","title":"Causal Inference","text":""},{"location":"Economics/Causal_Inference/#references","title":"References","text":"<ul> <li> Modern Data Analysis for Economics</li> <li> Program Evaluation for Public Service | Andrew Heiss | Georgia State University</li> <li> Causal Inference | MIT</li> <li> Statistical Rethinking | Richard McElreath</li> <li> Using Big Data to Solve Economic and Social Problems | Harvard</li> <li> Causality | Shaw Talebi</li> <li> The Effect: An Introduction to Research Design and Causality</li> <li> Prediction in Causal Research | Galit Shmueli</li> <li>https://youtu.be/JQl0CeiMA5w</li> <li>https://youtu.be/8L26hmMYTRU</li> <li> Causal Inference with Applications | Harvard</li> <li> Videos</li> <li> Material</li> <li> Causal Inference Bootcamp: Introduction to Causality | Mod\u2022U: Powerful Concepts in Social Science</li> <li> Causal Inference | Intuitive MetriX \u2013 Ben Elsner</li> <li> Causal Inference | Jonas Peters</li> <li> Causal Inference | Brady Neal</li> <li> Machine Learning &amp; Causal Inference: A Short Course | Stanford Graduate School of Business</li> <li> Advanced Econometrics | University of Massachusetts Amherst | Matt Woerman</li> <li> Dynamic Structural Econometrics | University of Wisconsin</li> <li> Network Causality | Neuromath Academy</li> <li> Applied Causal Methods | Paul Goldsmith-Pinkham</li> <li> Impact Evaluation in Practice | World Bank</li> <li> Discrete Choice Models | Kenneth Train | UC Berkeley</li> <li> Discrete Choice Models | Michel Bierlaire<ul> <li> Introduction to discrete choice models</li> <li> Discrete choice models: selected topics</li> <li> </li> </ul> </li> <li> Crash course in good &amp; bad controls | Judea Pearl</li> <li> Causal Diagrams: Draw your assumptions before your conclusions | Harvard</li> <li> Causality | Norman Fenton</li> <li> Complex survey data analysis course with causal inference methods | Ehsan Karim | UBC</li> <li> Structural Equation Modelling | Sacha Epskamp<ul> <li> Part 1</li> <li> Part 2</li> </ul> </li> <li> Causal Inference | Leslie Myint</li> <li> Causal Machine Learning | Tilburg University</li> </ul>"},{"location":"Economics/Causal_Inference/#current-video","title":"Current Video","text":""},{"location":"Economics/Causal_Inference/01_Introduction/","title":"Introduction","text":""},{"location":"Economics/Causal_Inference/01_Introduction/#econometric-analysis","title":"Econometric Analysis","text":"<p>Machine Learning \\(\\to\\) Statistics \\(\\to\\) Econometrics</p> <p>The focus is on using the predictions of Machine Learning to analyse future causalities. This is more insight-oriented, as identifying patterns without understanding causes and implications is useless.</p> <p>Causation depends on - Correlation: \\(x\\) and \\(y\\) are statistically-related - Time order: \\(x \\to y; \\text{not } y \\to x\\) - Non-spuriousness</p>"},{"location":"Economics/Causal_Inference/01_Introduction/#relationships-between-variables","title":"Relationships between Variables","text":"<p>2 variables can be related in the following ways</p> <ol> <li>Causal relationship, but no association</li> <li>Causal relationship, with association</li> <li>Non-causal, no association: Not related<ul> <li>Average Treatment Effect = 0<ul> <li>25% are helped by medicine</li> <li>50% have no effect by medicine</li> <li>25% are hurt by medicine</li> </ul> </li> </ul> </li> <li>Non-causal, but associated by backdoor path: Spurious association</li> <li>Non-causal, but associated by chance<ul> <li>This is why it is important to quantify effect sizes</li> <li>Goes away with large sample sizes</li> </ul> </li> </ol>"},{"location":"Economics/Causal_Inference/01_Introduction/#statistical-vs-causal","title":"Statistical vs Causal","text":"Statistical Prediction Causal Prediction \\(\\hat y\\) \\(E \\big [y \\vert x = a \\big]\\) \\(E \\big [y \\vert \\text{do}(x = a) \\big]\\) What will be \\(y\\) if I ___\\(x=a\\)? observe set characteristic natural outcome manual action statement if \\(x\\) is correlated with \\(y\\) without any causal effect on \\(y\\), then we can only observe the correlation without the ability to change \\(y\\) by changing \\(x\\) if \\(x\\) has a causal effect on \\(y\\), then we can change \\(x\\) and expect it to cause a change in \\(y\\). True understanding enables predictions under a wide range of circumstances, including new hypothetical situations Unstable Stable Example 1 What is the expected health status of someone who has received hospitalization? What will the health status of a person if they receive hospitalization? Example 2 What is the expected sales of a company with a given amount of TV ad spending? How much will my sales increase if I increase my TV ad spending by a certain amount?"},{"location":"Economics/Causal_Inference/01_Introduction/#see-vs-do","title":"<code>see</code> vs <code>do</code>","text":"<ul> <li>\\(\\text{see}(x= 1)\\) means that you observe \\(x\\) as 1</li> <li>\\(\\text{do}(x= 1)\\) means that you manually perform some action to set \\(x\\) as 1</li> </ul> <p>If there is no way to manipulate a variable (for eg, \\(\\text{do}(x= 1)\\) is not possible), then it is hard to define what its causal effect means</p> <ul> <li>A thought experiment that is often used to determine whether a variable x is manipulable in principle is to imagine a hypothetical experiment that assigns different values to x</li> <li>Research questions that cannot be answered by any experiment are FUQ\u2019d: Fundamentally Unidentified Questions</li> </ul>"},{"location":"Economics/Causal_Inference/01_Introduction/#correlation-centernot-implies-causation","title":"Correlation \\(\\centernot \\implies\\) Causation","text":"<p>Correlation doesn\u2019t always imply causation. correlation is useful for prediction, but not for understanding exactly why.</p> <p>For eg, labor wage and their years of education has a strong correlation, but the reason for that could be</p> <ul> <li>education actually helps</li> <li>education just acts as the signal/proof for the employees that you possess knowledge</li> <li>or, it could just be that well-off people get better jobs, and coincidentally, they are getting more educated</li> </ul>"},{"location":"Economics/Causal_Inference/01_Introduction/#rain","title":"Rain","text":"<ul> <li>Barometer reading itself has no causal effect on rainfall</li> <li>Atmospheric pressure has causal effect on the rainfall</li> </ul>"},{"location":"Economics/Causal_Inference/01_Introduction/#hospital","title":"Hospital","text":"<p>Let\u2019s say there are 2 hospitals</p> A B Recovery Rate 0.6 0.4 <ul> <li>It seems like A is better than B. But A may not necessarily be the better hospital for me to go to</li> <li>What if A is a regular community hospital and B is a speciality hospital for cancer patients. Obviously, A will have a better recovery rate. </li> <li>So, statistical prediction (is not wrong) is accurate in saying that recovery rate for a patient going to hospital A is 0.6, because we are seeing the patient going there; the patient that goes there is a patient who chose to go there. If they were a serious patient, then they would\u2019ve gone to B.</li> <li>But we cannot conclude from this data on how good the hospitals would be for a random person</li> </ul>"},{"location":"Economics/Causal_Inference/01_Introduction/#ad-sales","title":"Ad-Sales","text":"<ul> <li>Sales and Advertisement have a high correlation. But doesn\u2019t necessarily mean that increasing advertisement will increase sales.</li> <li>This is because, the observed advertisement could be due to previous sales. So the observed advertisement here is a natural outcome, not an active decision; ie, last year i got high sales profits, so i increased my advertisement budget this year, or i got bad profit so i increased my ad budget to somehow increase the sales. it\u2019s like a reaction, not an active decision.</li> <li>However, when you actively decide to increase the ad budget, the change in sales depends on the causal effect of ad budget on sales</li> </ul> <p>Why don\u2019t companies do this causal analysis???</p> <ol> <li>they don\u2019t know their math and stats </li> <li>causal analysis is harder</li> </ol>"},{"location":"Economics/Causal_Inference/01_Introduction/#scope","title":"Scope","text":"<p>Scope is the set of populations in which a causal effect applies. A causal effect is only meaningful if we can define its scope.</p>"},{"location":"Economics/Causal_Inference/01_Introduction/#populations","title":"Populations","text":"Study Population Target Population Population where experiment/observational study is conducted we\u2019re interested in learning the causal effect Sample specific diverse Population specific diverse Social, cultural and economic environment specific diverse <p>The causal effect of \\(x\\) on \\(y\\) can differ in 2 populations because:</p> <ol> <li>Causal mechanism is different in both populations</li> </ol> <p>eg: Consider a country where oil prices are determined by market, and another country where prices are determined by govt. The effect of decreasing oil supply on gas price will be different </p> <ol> <li>Distribution of effect modifier \\(P(s)\\) is different</li> </ol> <p>Eg: Consider 2 countries with the same economic structure, but different population age structures. The effect of raising retirement age will be completely different.</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/","title":"Causal Learning","text":"<pre><code>flowchart LR\nt[Theory] --&gt; Model --&gt; Evidence --&gt; t</code></pre>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#types","title":"Types","text":"Causal Effect Learning Causal Mechanism Learning Causal Inference Learning Does \\(x\\) have a causal effect on y? If yes, how large is the effect If causal effect exists, what is the mechanism behind it? Understand rational decisions that can be taken, built on causal mechanism learning and prior causal inference - What- How much - Why- How - What can we do? - discovering patterns- making predictions - understanding - decison-making \u201cEffects of causes\u201d \u201cCauses of effects\u201d"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#manipulation-of-x","title":"Manipulation of \\(x\\)","text":"<p>Being able to manipulate \\(x\\) to see its effect on \\(y\\) is essential to understanding causality. If there is no way to manipulate \\(x\\), then it is difficult to understand causality. </p> <p>Morever, according to the instructor, it is pointless to causal inference as if we cannot change it (even theoretically), then we can\u2019t really make better decisions, you know? So many questions we analyze when doing research is basically useless.</p> <p>For eg, analyzing \u201cwhat is the causal effect of height on your income\u201d. This is kinda pointless, because it\u2019s not like we can change our height. Atleast \u201cwhat is the causal effect of democracy on economic growth\u201d is an acceptable analysic, because theoretically we can change the democracy level.</p> <p>I have an example. Analysing the \u2018causal effect of unemployment on economic growth\u2019 is not very useful, because even though we can hypothetically manipulate unemployment indirectly, we can\u2019t exactly control it directly.</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#type-of-manipulation","title":"Type of Manipulation","text":"<p>The mechanism with which you \u2018do\u2019 \\(x\\) will have different results. Hence, it is important to have a clear mechanism for \u2018do\u2019-ing \\(x\\) before starting your analysis.</p> <p>For eg, for the theoretical democracy example, are you going to forcefully implement a democracy? or will the citizens peacefully request?</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#experimentational-causal-analysis","title":"Experimentational Causal Analysis","text":"<p>once the experiment is over, the correlation is mathematically equal to the causation</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#steps","title":"Steps","text":"<ol> <li>manually set \\(x=1\\)</li> <li>observe the value of \\(y\\)</li> <li>repeat</li> <li>take average value of y</li> </ol>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#disadvantages","title":"Disadvantages","text":"<ol> <li>not always feasible (especially in economics), and it is not possible to perform the experiment</li> <li>everyone is different, the experiment might not give an accurate inference</li> </ol>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#example","title":"Example","text":"<p>RCT (Randomized Control Testing)</p> <ul> <li>test group is do(x=1) - taking drug</li> <li>control group is do(x=0) - not taking drug</li> </ul>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#causal-inference-in-ai","title":"Causal Inference in AI","text":"<ol> <li>how should a robot acquire causual information through interaction with its environment</li> <li>how should a robot receive causal information from humans</li> </ol> <p>According to the lecturer, a lot of modern-day AI is not \u2018intelligence\u2019. Just because the algorithm can recognize images by trained data is not exactly \u2018intelligence\u2019.</p> <p>True hallmark of intelligence is the ability to make causal inference, from looking at statistical patterns.</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#causal-inference-models","title":"Causal Inference Models","text":"<p>There are 2 types of models</p> <ol> <li>Rubin Model</li> <li>Judea Pearl Model    The instructor says that this is better, in his opinion</li> </ol>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#identifiability","title":"Identifiability","text":"<p>\\(\\theta(M)\\) is if it can be uniquely determined based on observations of \\(v\\).</p> <p>I didn\u2019t really understand this.</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#idk","title":"IDK","text":"<p>Requires prior knowledge regarding the data-generating causal mechanism.</p> <p>Such knowledge can only exist as a result of previously-observed information and conducted studies.</p> <p>Hence, causal inference builds on past causal inference</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#source-of-associations","title":"Source of Associations","text":"<p>Reasons why \\(x\\) and \\(y\\) can be associated</p> <ul> <li>\\(x\\) causes \\(y\\) directly</li> <li>\\(x\\) causes \\(y\\) indirectly</li> <li>\\(x\\) and \\(y\\) have common cause(s)</li> <li>Analysis is conditioned on their common descendant(s)</li> </ul>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#aggregate-reversal","title":"Aggregate Reversal","text":"<p>Same as Simpson's Paradox?</p> <p>Any statistical relationship between two variables may be reversed by including additional factors in the analysis</p> <p>If you just look at statistical data, it might be misleading.</p> <p>Once we divide the population into sub-population based on categories such as sex, then it becomes clearer. This is because why try understanding the underlying mechanism. This phenomenon is called as aggregate reversal.</p>"},{"location":"Economics/Causal_Inference/02_Causal_Learning/#time-varying-treatments","title":"Time-Varying Treatments","text":""},{"location":"Economics/Causal_Inference/02_Causal_Learning/#-time-varying-confounding","title":"- Time-varying confounding","text":""},{"location":"Economics/Causal_Inference/03_Treatment_Effects/","title":"Treatment Effect","text":""},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#effects","title":"Effects","text":"<p>Let \\(\\tau = y^1 - y^0\\).</p> <p>\\(\\tau\\) will have a distribution because it is a random variable (\\(\\tau_1, \\tau_2, \\dots, \\tau_i\\))</p> Term Meaning ITE \\(\\tau_i\\) Individual Treament Effectit is never observed, because we only observe \\(y_i^0\\) or \\(y_i^1\\) ATE \\(E[\\tau]\\) Average Treatment Effect CATE \\(E[\\tau \\vert Z=z]\\) Conditional ATE LATE \\(E[\\tau \\vert Z \\in z]\\) Local ATE ATT \\(E[\\tau \\vert x = 1]\\) Average Treatment effect on Treated ATU \\(E[\\tau \\vert x = 0]\\) Average Treatment effect on Untreated \\(E(y^1)\\) Expectation of outcome 1 of the entire population (hypothetical, counterfactual) \\(E(y^1 \\vert x = 1)\\) Expectation of outcome 1 of the treated sample ITT \\(E[y \\vert \\text{Treatment group}] - E[y \\vert \\text{Control group}]\\)\\(\\pi_C \\text{CACE} + \\pi_A \\text{ATACE} + \\pi_N \\text{NTACE} + \\pi_D \\text{DACE}\\)\\(=\\pi_C \\text{CACE} + \\pi_A 0 + \\pi_N 0 + 0 \\text{DACE}\\)\\(=\\pi_C \\text{CACE}\\) Intent to treatEffect of assignment to treatment group (not actual treatment) CACE \\(E[\\tau \\vert \\text{Complier}]\\)\\(\\dfrac{\\text{ITT}}{\\pi_C}\\) Complier Average Causal EffectLATE for Compliers <p>$$ \\begin{aligned} \\pi_C + \\pi_A &amp;= p(T=1 \\vert \\text{Treatment group}) \\ \\pi_A + \\pi_D &amp;= p(T=1 \\vert \\text{Control group}) \\ \\pi_N + \\pi_D &amp;= p(T=0 \\vert \\text{Treatment group}) \\ \\pi_N + \\pi_C &amp;= p(T=0 \\vert \\text{Control group}) \\end{aligned} $$ Usually, we assume that \\(\\pi_D=0\\)</p> <p>Why are there 3 different average variables? The people in each group is different. So, \\(\\tau\\) for the entire group, treated and untreated groups are different, due to \u2018selection effect\u2019. This is like people who go to uni vs don\u2019t. $$ \\begin{aligned} y &amp;= y^0 \\cdot I(x=0) \\times y^1 \\cdot I(x=1)\\ &amp;\\text{where \\(I\\) means if}\\</p> <p>\\implies y &amp;= f(x, y^0, y^1) \\end{aligned} $$</p>"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#ate","title":"ATE","text":"<ul> <li>ATE = difference of the mean = mean of the difference $$ \\begin{aligned} \\text{ATE} =&amp; E[y^1] - E[y^0] \\ =&amp; E[y^1 - y^0] \\end{aligned} $$</li> <li>ATE = weighted average of ATT and ATU $$ \\begin{aligned} \\text{ATE} =&amp; \\text{ATT}  \\cdot P(x=1) + \\text{ATU} \\cdot P(x=0) \\ =&amp; E(y^1 - y^0 | x = 1) \\cdot P(x=1) \\ &amp;+ E(y^1 - y^0 | x = 0) \\cdot P(x=0) \\ =&amp; \\int E[y^1 - y^0 \\vert s] \\cdot p(s) \\cdot ds \\end{aligned} $$ This reminds me of the total probability like in Bayes\u2019 conditional probability. But here, we are taking expectation \\(E\\) (mean), because it\u2019ll more accurate than taking one value from the PDF, as \\(\\tau\\) is a random variable</li> <li>ATE = Weighted average of CATE, given unconfoundedness: proving that treatment randomly assigned within each group \\(z_i\\)</li> </ul> <p>$$ \\widehat{\\text{ATE}} = \\sum_i \\widehat{\\text{CATE}}_i  \\cdot P(Z=z_i) $$ - ATE = ATT + Selection Bias     - Randomization makes selection bias 0</p> <p>ATE = Causal Effect $$ \\begin{aligned} E(y \\vert \\text{do}(x), s) &amp;= E(y \\vert x, s) \\ \\implies \\widehat{\\text{ATE}}(x, s) &amp;=\\dfrac{d}{dx} \\hat E[y \\vert \\text{do}(x)] \\ &amp;=\\dfrac{d}{dx} \\hat E[y \\vert \\text{do}(x), s] \\ &amp;= \\dfrac{d}{dx} E_s \\Big[ \\hat E[y \\vert \\text{do}(x), s] \\Big] \\ &amp;= \\dfrac{d}{dx} E_s \\Big[ \\hat E[y \\vert x, s] \\Big] \\ &amp;= E_s \\left[ \\dfrac{\\partial}{\\partial x} \\hat E[y \\vert x, s] \\right] \\end{aligned} $$</p> <p>HTE = Heterogeneous Treatment Effect = ATE with high dimensional \\(s\\) </p> <p>If \\(x\\) is binary $$ \\begin{aligned} x &amp;\\in { 0, 1 } \\ \\implies \\text{ATE}(x, s) &amp;= E[ y \\vert \\text{do}(x=1) ]  -  E[ y \\vert \\text{do}(x=0) ] \\ &amp;= E_s \\Bigg[ E[y \\vert x=1, s ]   -  E[ y \\vert x=0, s] \\Bigg] \\ \\end{aligned} $$</p> Treatment Model \\(\\widehat{\\text{ATE}}(x)\\) Binary Linear \\(\\hat \\beta_0 + \\hat \\beta_1 x + \\hat \\beta_2 s\\) Constant \\(\\hat \\beta_1\\) Multi-Level/Continuous Non-linear Functional"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#idk","title":"IDK","text":"\\(E[y^1 - y^0]\\) \\(E[y \\vert x=1] - E[y \\vert x=0]\\) Compares what would happen if the __ sample receives treatment \\(x=1\\) vs \\(x=0\\) same 2 different Provides Average causal effect Average difference in outcome b/w sub populations defined by treatment group"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#idk_1","title":"IDK","text":"<p>$$ \\begin{aligned}</p> <p>\\text{ATT} &amp;= E(y^1 - y^0 | x = 1) \\ &amp;= \\underbrace{E(y^1 | x = 1)}{E(y | x = 1)} - \\underbrace{E(y^0 | x = 1)} \\ \\text{ATU} &amp;= E(y^1 - y^0 | x = 0) \\ &amp;= \\underbrace{E(y^1 | x = 0)}}{\\text{Cannot be estimated}} - \\underbrace{E(y^0 | x = 0)} \\ %{ %%\\text{Similarly,} &amp;\\ %%\\text{ATE} %%&amp;= \\underbrace{E(y^1 | x = 0)}{\\text{Cannot be estimated}} - %%\\underbrace{E(y^0 | x = 0)} %} \\end{aligned} $$</p> <p>Solution: Randomized Treatment</p>"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#pdf-graph","title":"PDF Graph","text":"<p>$$ \\begin{aligned} \\text{ATE}(x) &amp;= \\int \\tau(x, y) P(y)  dy \\ &amp;= \\frac{     dE[y| \\text{ do}(x)] }{dx} \\</p> <p>T(x, y) &amp;= \\frac{     \\partial P(y | \\text{do}(x)) }{     \\partial x } \\ \\end{aligned} $$</p> <p>We could also interpret this entire distribution as a 3 variable joint PDF of the form \\(P(x, y^0, y^1)\\)</p>"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#idk_2","title":"IDK","text":"Treatment\\(x\\) Observed Outcome\\(y\\) Potential Outcome\\(y^0\\) Potential Outcome\\(y^1\\) ITE 0 -0.34 -0.34 3.46 3.8 0 1.67 1.67 4.03 2.36 0 -0.77 -0.77 3.08 3.85 0 2.64 2.64 0.90 -1.74 0 -0.02 -0.02 0.96 0.98 1 2.31 -1.52 2.31 3.83 1 2.79 1.05 2.79 1.74 1 1.53 -0.13 1.53 1.65 1 3.61 -1.41 3.61 5.02 1 3.36 0.60 3.36 2.76 <p>Here</p> <ul> <li>Modelling the ITE is correct</li> <li>Modelling \\(y\\) vs \\(x\\) is incorrect</li> </ul>"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#probabilistic","title":"Probabilistic","text":"<p>Causal effect of a treatment is a probability distribution: it is not the same for every individual.</p> <ul> <li>Learning the individual-level is nearly impossible</li> <li>Learning the pdf of the effect is hard</li> </ul> <p>Usually, the Average Treatment Effect is used</p> <p>But better to compare the distributions of the treatment and control group</p>"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#heterogeneous-treatment-effects","title":"Heterogeneous Treatment Effects","text":"<p>If we consider effect modifier \\(s\\) $$ \\begin{aligned} \\text{ATE} &amp;= \\dfrac{\\partial}{\\partial x} E[ y \\vert \\text{do}(x), s] \\ &amp;= \\int \\limits_s E[y^1 - y^0  |  s] \\cdot P(s) \\cdot ds \\ \\end{aligned} $$</p> <p>where \\(P(s)\\) is the distribution of effect modifier.</p> <p>Then, the result of the randomized test actually gives us \\(E[\\tilde \\tau]\\), which may not be equal to \\(E[\\tau]\\)</p>"},{"location":"Economics/Causal_Inference/03_Treatment_Effects/#example","title":"Example","text":"<p>For example, the yield depends on the season and the crop for which was grown previous year. Let\u2019s take the example of a a randomized test of a fertilizer used  in the summer.</p> <p>If no crop was grown the previous year, then we </p> Crop Grown in Field Last Year Result of Randomized Test \\(E[\\tilde \\tau]\\) No crop $E[\\tau Rice only $E[\\tau 50% Barley, 50% Rice $0.5 \\cdot E[\\tau"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/","title":"Discrete Choice Models","text":"<p>Discrete choice models are a class of econometric models of how individuals make choices, where \u201cindividuals\u201d is any unit of decision making, such as people, firms, governments</p> <p>These models are similar to a classification problem, but they are structural models of decision making based on utility maximization. Hence, they do not make the assumption of IIA and can handle it effectively.</p> <p>The ultimate goal of the researcher is to represent utility so well that the assumption of error independence is appropriate and then use Logistic regression incorporating all important features. In the absence of that, a discrete choice model that allows for correlated errors, such as the multinomial probit, can be used</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#rum-framework","title":"RUM Framework","text":"<p>Random Utility Maximization</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#problem-formalization","title":"Problem Formalization","text":"<p>Consider</p> <ul> <li>Individual \\(i\\) chooses \\(y\\) among \\(J\\) alternatives</li> <li>\\(x_{ij}\\) is the observed characteristics associated with individual \\(i\\) and alternative \\(k\\)</li> <li>\\(s_i:\\) Individual-specific factors (eg: income)<ul> <li>\\(r_j s_i\\)</li> </ul> </li> <li>\\(z_{ij}:\\) Alternative-specific factors with generic coefficients (eg: price)<ul> <li>\\(\\beta z_{ij}\\)</li> </ul> </li> <li>\\(w_{ij}:\\) Alternative-specific factors with alternative-specific coefficients (eg: price)<ul> <li>\\(\\alpha_j w_{ij}\\)</li> </ul> </li> <li>\\(u_{ij}\\) is the unobserved utility associated with alternative \\(j\\) for individual \\(i\\), that even the individual is not aware about</li> </ul> \\[ \\begin{aligned} u_{ij} &amp;= f_j(x_{ij}) + \\epsilon_{ij} \\\\ f_j &amp;= \\beta_j x_{ij} &amp;&amp; \\text{(Simple Model)} \\end{aligned} \\] <p>where \\(\\epsilon_{ij}\\) is the effect of unobserved factors, such that \\(\\epsilon \\sim^\\text{iid} F_e\\); different specifications of \\(f_j\\) and \\(F_e\\) lead to different discrete choice models</p> <p>Example: Temperature and Rainfall \\(x_{ij}\\) affects which crop \\(u_{ij}\\) is grown in each place \\(j\\)</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#assumption","title":"Assumption","text":"<ul> <li>Individual knows their \\(u_{ij}\\)</li> <li>Individual\u2019s decision is deterministic</li> </ul>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#choice","title":"Choice","text":"<p>A rational individual chooses the alternative that maximizes the utility $$ \\begin{aligned} u_i &amp;= \\max( { u_{ij} } ) \\ \\implies y_i &amp;= \\arg \\max_{j} { u_{ij} } \\end{aligned} $$</p> \\[ \\begin{aligned} P(y_i = k \\vert x) &amp;= P( u_{ik} &gt; u_{ij} ) &amp;&amp; \\forall j \\ne k \\in J \\\\ &amp;= P \\Big(     f_j - f_k &gt; \\epsilon_{ij} - \\epsilon_{ik} \\Big) \\\\ &amp;= F \\Big( f_j - f_k \\Big) &amp;&amp; (\\epsilon_{ij} - \\epsilon_{ik} \\sim F) \\end{aligned} \\] <p>where \\(P=\\) CCP (Conditional Choice Probability)</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#features","title":"Features","text":"<ul> <li>Only differences in utility matter; the absolute level of utility is irrelevant</li> <li>Hence, if a constant is added to the utility of all alternatives, then the alternative with the highest utility does not change</li> <li>The overall scale of utility is irrelevant</li> <li>Hence, if a positive scale is multiplied to the utility of all alternatives, then the alternative with the highest utility does not change</li> </ul>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#advantages","title":"Advantages","text":"<ul> <li>Better interpretability</li> <li>Structural model</li> </ul>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#limitations","title":"Limitations","text":"<ul> <li>Since \\(u_{ij}\\) is unobserved, we can only calculate the probability of individual choosing each alternative conditional on the variables we observe</li> <li>Due to the features, we cannot learn the level of utility associated with different alternatives, only the scaled differences among them</li> <li>We cannot estimate the intercept and scale associated with \\(s_i\\) for each utility</li> <li>We can only estimate the difference of the above between 2 utilities </li> </ul>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#estimation","title":"Estimation","text":"<ol> <li> <p>We need to normalize and scale such that \\(u_{ia} = 0\\)</p> </li> <li> <p>Subtract all terms by \\(u_{ia}\\)</p> </li> <li>Divide all terms to make \\(\\epsilon_{i} \\sim N(0, 1)\\)</li> </ol> <p>Reason: The parameters \\(\\mu_a, \\mu_b, \\sigma_a, \\sigma_b\\) are not separately identifiable, because an infinite number of models (corresponding to different values of \\(\\alpha\\) and \\(\\gamma\\)) are consistent with the same choice behavior</p> <ol> <li>As long as there is an intercept term \\(\\alpha_j\\), alternative-specific variables \\(z_{ij}\\) must vary with i in order to be identified</li> </ol> <p>Reason: Else, both will be constants and hence cannot be separately identified</p> <ol> <li>The scale coefficients \\(\\alpha\\) of individual-specific variables must be alternative-specific in order to be identified.</li> </ol> <p>Reason: Since only difference in utility matters, \\(\\alpha\\) cannot be identified</p> <ol> <li>Alternative-specific variables can have either alternative-specific coefficients or generic coefficients that do not change with alternatives</li> </ol> <p>Consider a binary choice problem \\(y \\in \\{ a, b \\}\\) $$ \\begin{aligned} u_{ia} &amp;= \\mu_a + \\epsilon_{ia} \\ u_{ib} &amp;= \\mu_a + \\epsilon_{ib} \\ \\end{aligned} $$ Estimate \\(\\Delta \\tilde \\mu_b = \\alpha(\\mu_b - \\mu_a)\\), which is the scaled difference between \\(\\mu_a\\) and \\(\\mu_b\\), by normalize the level and scale of utility.</p> <p></p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#probit-regression","title":"Probit Regression","text":"<p>Assumes that \\(\\epsilon\\) is a joint-normal distribution $$ \\epsilon_i \\sim N(0, \\Sigma) $$ where the covariance matrix \\(\\Sigma\\) uses the \u201cbase class\u201d as reference</p> <p>A model with \\(J\\) alternatives has \\(\\le \\dfrac{1}{2} J(J-1) - 1\\) covariance parameters after normalization, which can be evaluated using the below methods</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#binary","title":"Binary","text":"\\[ \\begin{aligned} \\epsilon_i &amp;= \\begin{bmatrix} \\epsilon_{ia} \\\\ \\epsilon_{ib} \\end{bmatrix} \\\\ &amp; \\sim N \\left( 0, \\begin{bmatrix} \\sigma_a^2 &amp; \\sigma_{ab} \\\\ \\cdot &amp; \\sigma_b^2 \\end{bmatrix} \\right) \\end{aligned} \\] \\[ \\epsilon_{ia} - \\epsilon_{ib} \\sim N(0, \\sigma_a^2 + \\sigma_b^2 - 2 \\sigma_{ab}) \\\\ \\alpha = u_{ia} \\\\ \\lambda = \\dfrac{1}{ \\sqrt{\\sigma_a^2 + \\sigma_b^2 - 2 \\sigma_{ab}} } \\]"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#multinomial","title":"Multinomial","text":"\\[ \\begin{aligned} \\epsilon_i &amp;= \\begin{bmatrix} \\epsilon_{i1} \\\\ \\epsilon_{i2} \\\\ \\dots \\\\ \\epsilon_{ij} \\end{bmatrix} \\\\ &amp; \\sim N \\left( 0, \\begin{bmatrix} \\sigma^2_1 &amp; \\sigma_{12} &amp; \\dots &amp;  \\sigma_{1j} \\\\ &amp; \\ddots &amp; \\\\ &amp; &amp; \\dots  &amp; \\sigma^2_j \\end{bmatrix} \\right) \\end{aligned} \\] <p>Multinomial probit models do not have the IIA property as they allow correlated errors</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#logistic-regression","title":"Logistic Regression","text":"<p>Assumes that \\(\\epsilon\\) is iid $$ \\epsilon_{ij} \\sim^\\text{iid} \\text{Gumbel}(0, \\sigma) $$ The difference between two extreme values is distributed as a logistic distribution $$ F(\\Delta) = \\dfrac{\\exp(\\Delta e)}{1 + \\exp(\\Delta e)} $$ The CDF of the logistic distribution is the sigmoid function</p> <p>We need to normalize the scale of \\(\\epsilon_i\\) such that \\(\\sigma=1\\) $$ \\begin{aligned} \\implies \\epsilon_{ij}' &amp; \\sim \\text{Gumbel}(0, 1) \\ &amp; \\sim N(0, 1) \\end{aligned} $$ As Gumbel and normal very similar $$ \\begin{aligned} P(y_i = k \\vert x_i) &amp;= P(u_{ik} &gt; u_{ij}) &amp;&amp; \\forall j \\ne k \\in J \\ &amp;= P(\\Delta e_i &lt; \\Delta f_i) \\ &amp;= \\dfrac{\\exp(f_{ik})}{\\sum_j^J \\exp(f_{ij})} &amp;&amp; (\\Delta e_i \\sim \\text{Logistic}) \\end{aligned} $$ Expected utility of individual \\(i\\) conditional on \\(x_i\\) $$ \\begin{aligned} E[u_i \\vert x_i] &amp;= E \\Big[ \\max_j { u_{ij} }  \\vert  x_i \\Big] \\ &amp;= \\log \\Big[ \\sum_j^J \\exp(f_{ij}) \\Big] + c &amp;&amp; (c = \\text{const}) \\end{aligned} $$ This is because we can add any \\(c\\) to the utilities and the model would be the same</p> <p>Proportional substitution is a manifestation of the IIA property of the logistic model</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#logistic-vs-probit","title":"Logistic vs Probit","text":"<p>Binary Logistic regression \\(\\approx\\) Binary probit regression</p> <p></p> Logistic Regression Probit Speed Faster(has closed form solution) Slower(no closed form solution) Can handle similarity between choices \u274c \u2705 Advantage Probit seems more realistic as it incorporates similarity of alternatives Disadvantage Might struggle for large number of alternatives due to difficult optimization <p>Example</p> <p></p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#marginal-effects","title":"Marginal Effects","text":"\\[ \\begin{aligned} \\dfrac{\\partial P(y_i = j \\vert x_i)}{\\partial s_i} &amp;= P(y_i = j \\vert x_i) \\left( \\gamma_j - \\sum_j \\gamma_l P(y_i = l \\vert x_i) \\right) \\\\ \\dfrac{\\partial P(y_i = j \\vert x_i)}{\\partial z_{ij}} &amp;= \\delta_j \\cdot P(y_i = j \\vert x_i) \\Big[ 1 - P(y_i = j \\vert x_i) \\Big] \\end{aligned} \\] Variable Sign of marginal effect Alternative-Specific Sign of coefficient Individual-Specific N/A"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#choice-probability-elasticity","title":"Choice Probability Elasticity","text":"Denotation Formula Meaning Own \\(e_{i}^{jj}\\) \\(\\delta z_{ij}[1- P(y_i = j \\vert x_i)]\\) \\(\\dfrac{\\partial P(y_i=j \\vert x_i)}{\\partial z_{ij}} \\times \\dfrac{z_{ij}}{P(y_i = j \\vert x_i)}\\) Cross \\(e_{i}^{jk}\\) \\(-\\delta z_{ij} \\cdot P(y_i = k \\vert x_i)\\) \\(\\dfrac{\\partial P(y_i=j \\vert x_i)}{\\partial z_{ik}} \\times \\dfrac{z_{ik}}{P(y_i = j \\vert x_i)}\\)"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#tobit-regression","title":"Tobit Regression","text":"<p>Applicable for - Censored - Truncated: Household expenditure - Zero-inflated</p> \\[ \\hat y = \\begin{cases} \\hat f(x), &amp; \\hat f(x) &gt; c \\\\ c, &amp;\\hat f(x) \\le c \\end{cases} \\] <p>OLS will be biased and inconsistent with/without removal of the truncated data</p>"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#mle","title":"MLE","text":"<p>$$ \\begin{aligned} L &amp;= \\prod_{i=1}^n P(y_i \\vert x_i) \\ &amp;= \\cancel{\\prod_{i=1 | y_i \\le c}^n P(y_i \\vert x_i)} \\times \\prod_{i=1 | y_i = c}^n P(y_i \\vert x_i) \\times \\prod_{i=1 | y_i \\ge c}^n P(y_i \\vert x_i) \\</p> <p>\\implies \\ln L &amp;= \\cancel{\\sum_{i=1 | y_i \\le c}^n P(y_i \\vert x_i)} + \\sum_{i=1 | y_i = c}^n P(y_i \\vert x_i) + \\sum_{i=1 | y_i \\ge c}^n P(y_i \\vert x_i) \\ &amp;= 0 + \\ln L_2 + \\ln L_3 \\ \\ P(y_i \\vert x_i)_2 &amp;= \\Phi(\\text{Distribution}, \\hat y, c) = \\text{Tobit extra term} \\ P(y_i \\vert x_i)_3 &amp;= \\phi(\\text{Distribution}, \\hat y, y) = \\text{Usual minimization} \\end{aligned} $$ For normal distribution,</p> \\[ P(y_i \\vert x_i)_2 = \\dfrac{y_i - C}{\\sigma_i} \\]"},{"location":"Economics/Causal_Inference/04_Discrete_Choice_Models/#ordinal-regression","title":"Ordinal Regression","text":"<p>For classifying ordered categories</p>"},{"location":"Economics/Causal_Inference/05_Discrete_Game/","title":"Discrete Game","text":"<p>Individual choices involve strategic interactions, which we can model using game theory.</p> <p>Similar to discrete choice models, but here individuals\u2019 choices affect each other\u2019s choices</p> <p>Each individual\u2019s choice can be considered the result of an equilibrium strategy. The resulting model is called a discrete game model. $$ u_{ij} = f(x_{ij}) + g(x_{i' j}) + \\epsilon_{ij} \\ i = \\text{other individuals} $$ Assume that players simultaneously make their decisions without knowing what the other players will do. Such a game is called a game of incomplete information. Because players do not know what others will do, their choices will depend on their beliefs (expectations) about other players\u2019 choice probabilities $$ \\begin{aligned} u_{i0} &amp;= \\epsilon_i^0 \\ u_{i1} &amp;= \\pi_i(y_j) + \\epsilon_i^1 \\ \\ y_i &amp;= \\arg \\max { u_{i0}, E_i[u_{i1}] } \\ &amp;= \\arg \\max { \\ &amp; \\quad  \\epsilon_i^0, \\ &amp; \\quad  \\pi_{i0} p_i (a_j=0) + \\pi_{i1} p_i (a_j = 1) + \\epsilon_i^1 \\ &amp; \\quad  } \\end{aligned} $$ where</p> <ul> <li>\\(\\pi_i =\\) profit function of \\(i\\)</li> <li>\\(y \\in \\{ 0, 1 \\}\\) is the choice</li> <li>\\(j\\) is another player</li> <li>\\(p_i(y_j)\\) is \\(i\\)\u2019s belief of \\(j\\)\u2019s probability of choosing \\(y_j\\)</li> <li>\\(E_i(y_j)\\) is \\(i\\)\u2019s belief of \\(j\\)\u2019s expected utility from choosing \\(y_j\\)</li> </ul> <p>Assumption:</p> <ul> <li>\\(\\pi_{i0} &gt; \\pi_{i1}\\) if players are competitors</li> <li>\\(\\pi_{i0} &lt; \\pi_{i1}\\) if players are complementers/symbiotic</li> </ul>"},{"location":"Economics/Causal_Inference/05_Discrete_Game/#nash-bayesian-equilibrium","title":"Nash Bayesian Equilibrium","text":"<p>In equilibrium, each player has the correct belief about the choice probabilities of other players, ie \\(p_i(y_j) = p(y_j) , \\forall i, j\\)</p> <p>Assuming</p>"},{"location":"Economics/Causal_Inference/05_Discrete_Game/#-epsilon_i0-epsilon_i1-sim-textgumbel0-1","title":"- \\(\\epsilon_i^0, \\epsilon_i^1 \\sim \\text{Gumbel}(0, 1)\\)","text":"\\[ \\begin{aligned} &amp;p(y_i = 1) \\\\ &amp;= \\dfrac{ \\exp[ \\pi_{i0} \\cdot p(y_j = 0) + \\pi_{i1} \\cdot p(y_j = 1) ] }{ 1 + \\exp[ \\pi_{i0} \\cdot p(y_j = 0) + \\pi_{i1} \\cdot p(y_j = 1) ] } \\\\ &amp; \\forall i, j \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/06_Rubin_Model/","title":"Rubin Model","text":"<p>Also called as Potential Outcomes Framework</p> <p>We find the \u2018treatment effect\u2019 of \\(x\\). This is just a fancy way of saying causal effect</p> <p>Uses statistical analysis of experiments to model causality</p> <p>Framework for causal inference that conceptualizes observed data as if they were outcomes of experiments, conducted through 1. actual experiments by researcher(s) 2. observational studies by subjects of the research</p>"},{"location":"Economics/Causal_Inference/06_Rubin_Model/#terms","title":"Terms","text":"Keyword Meaning \\(x\\) Treatment/Intervention/Mediation input \\(y\\) Outcome output \\(x \\perp (y^0, y^1)\\) Exchangeability/Exogenous input is independent \\(x \\perp \\!\\!\\! \\perp (y^0, y^1)\\) Conditional exchangeability input is independent only for a certain sub-population Endogeneous input is dependent (self-chosen)"},{"location":"Economics/Causal_Inference/06_Rubin_Model/#ill-defined-intervention","title":"ill-Defined Intervention","text":"<p>When the treatment is not defined specifically, there exists multiple variations of the treatment. Hence, derived effect will not be meaningful, and may be misleading.</p>"},{"location":"Economics/Causal_Inference/06_Rubin_Model/#effect-of-democracy-on-economic-growth","title":"Effect of democracy on economic growth","text":"<p>You need to keep in mind that there are multiple variations of</p> <ul> <li>democracy - parliamentary, presidential, \u2026</li> <li>country becoming democratic - peaceful transition, civil uprising, revolt, \u2026</li> </ul> <p>In this case, the \u2018effect of democracy on economic growth\u2019 will not be meaningful, as each of these various treatments will have different outcomes, and cannot be generalized.</p>"},{"location":"Economics/Causal_Inference/06_Rubin_Model/#effect-of-obesity-on-health","title":"Effect of obesity on health","text":"<ul> <li>What is obesity as a treatment?</li> <li>How do we intervene on obesity?</li> <li>Multiple channels to becoming obese or un-obese: (lack of) exercise, (un)healthy diet, surgery, ...</li> <li>The apparently straightforward comparison of the health outcomes of obese and non-obese individuals masks the true complexity of the interventions \u201cmake someone obese\u201d and \u201cmake someone non-obese.\u201d</li> </ul>"},{"location":"Economics/Causal_Inference/06_Rubin_Model/#potential-outcomes","title":"Potential Outcomes","text":"<p>Consider an input \\(x_i\\) which takes binary values \\(0/1\\). Then, there will be</p> <ul> <li>4 potential outcomes</li> <li>2 potential outcomes for each treatment</li> </ul> <p>Suppose the treatment is \\(x_1\\), then</p> \\(x = a\\) actual treatment \\(x \\ne a\\) counterfactual treatment \\(y^a\\) realized outcome \\(y^{\\ne a}\\) counterfactual outcome \\(\\{ y_i^a , y_i^{\\ne a} \\}\\) potential outcomes \\[ \\begin{aligned} y &amp;= \\sum_{a=1}^A y^a I(x=a) \\\\ \\text{Binary } x \\implies y &amp;= x y_i^1 + (1-x) y_i^0 \\end{aligned} \\] <p>\\(x\\) has causal effect on \\(y\\) \\(\\iff P(y^0) \\ne P(y^1)\\), where P is the probability. This is because</p> <ul> <li>if \\(x\\) has no effect, changing it won\u2019t have any effect on the probability of either outcome, so the probabilities will be equal.</li> <li>but if it has effect, then obviously the outcome probabilities will be different</li> </ul>"},{"location":"Economics/Causal_Inference/06_Rubin_Model/#shortcomings","title":"Shortcomings","text":"<ol> <li>Since it is more experiment-oriented, it is hard to analyze continuous treatment. It is only feasible to do binary \\(0/1\\) treatment.</li> <li>Cannot learn individual treatment effects, since counterfactual outcomes are not observed. This is the fundamental problem of causal inference</li> <li>We can only learn causal effects at population sample level</li> <li>Therefore, when learning a causal effect, we should always be clear       about the population sample on which it is defined</li> <li>According to Rubin, causal inference is a \u2018missing data\u2019 problem, but that\u2019s just like every other statistical predictive model</li> <li>It does not\u00a0model choice as assignment of unit\u2019s ability and eligibility for treatment; it models model choice as assignment to a treatment</li> </ol>"},{"location":"Economics/Causal_Inference/07_Random_Testing/","title":"Randomized Tests","text":""},{"location":"Economics/Causal_Inference/07_Random_Testing/#randomization","title":"Randomization","text":"<ul> <li>Ensures that correlation = causation</li> <li>Eliminates self-selection and trend effects</li> </ul> <p>Helps estimate counterfactual outcome by ensuring - \\(y^0, y^1 \\perp \\!\\!\\! \\perp x\\): independence/exchangeability of \\(y^0, y_1\\) wrt \\(x\\)   - Treatment \\(x\\) is exogenous - Similarity of population and treated sample</p> \\[ \\text{ATE = ATT = ATU} \\notag \\]"},{"location":"Economics/Causal_Inference/07_Random_Testing/#independence","title":"Independence","text":"<p>If you randomly assign \\(x\\) to people, then the \\(x\\) will be independent from everything. \\(x\\) will therefore be independent from \\(y_0\\) and \\(y_1\\).</p> <p>If \\(P(y|x=0) = P(y|x=1) = P(y)\\), then \\(x\\) and \\(y\\) are independent. This is because, whatever the value of \\(x\\) we put, the probability of \\(y\\) did not get changed.</p> <p>So conversely, if we are able to make \\(x\\) and \\(y^0\\) independent, then we can take $$ E(y^0 | x = 1) = E(y^0 | x = 0) = E(y | x = 0) $$</p> \\[ \\begin{aligned} E(y^1 - y^0) &amp;= E(y^1 | x = 1) - E(y^0 | x = 0) \\\\ &amp;= E(y | x = 1) - E(y | x = 0) \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/07_Random_Testing/#similarity","title":"Similarity","text":"<ol> <li>Randomly assign individuals to treatment and control group</li> <li>Ensure that demographics and confounders are balanced in each group</li> <li>Do not control any other variable after this for running regressions, as you will open causal paths</li> </ol>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#derivations-from-randomized-tests","title":"Derivations from Randomized Tests","text":"Property Meaning Association (Correlation) $P(y Causation \\(P(y^a) \\ne P(y^b)\\) Correlation \\(\\implies\\) Causation Random assignment of $x \\implies (y^a) = P(y"},{"location":"Economics/Causal_Inference/07_Random_Testing/#effect-of-randomization-on-deriving-ate","title":"Effect of Randomization on deriving ATE","text":""},{"location":"Economics/Causal_Inference/07_Random_Testing/#without-randomization","title":"Without Randomization","text":"<p>There will be statistical correlation without causal correlation (to be avoided). This is due to Self-Selection Effect. So the selection will be biased.</p> <p>$$ \\begin{aligned} &amp; E(y | x = 1) - E(y | x = 0)  \\ =&amp;  \\underbrace{     E( y|x = 1) \\textcolor{orange} {- E(y^0|x=1)} }\\text{ATT} \\ &amp;+ \\underbrace{ \\textcolor{orange}{ E(y^0|x=1) } - E(y | x = 0) } \\} \\ne \\text{ATU} </p> <p>\\ne &amp; E(y' - y^0) \\ \\ne &amp; \\text{ATE} \\end{aligned} $$</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#with-randomization","title":"With Randomization","text":"\\[ \\begin{aligned} A \\perp \\!\\!\\! \\perp B &amp;\\iff P(A) = P(A \\vert B=0) = P(A \\vert B=1) \\\\ \\\\ \\implies y^0 \\perp \\!\\!\\! \\perp x &amp;\\iff P(y^0) = P(y^0 \\vert x=0) = P(y^0 \\vert x=1) = P(y \\vert x=0) \\\\ \\implies y^1 \\perp \\!\\!\\! \\perp x &amp;\\iff P(y^1) = P(y^1 \\vert x=0) = P(y^1 \\vert x=1) = P(y \\vert x=1) \\end{aligned} \\] \\[ E[y^1 - y^0] = E[y \\vert x=1] - E[y \\vert x=0] \\] \\[ \\begin{aligned} &amp;\\text{ATE} = \\text{ATT} = \\text{ATE} \\\\ &amp;= E[y \\vert x=1] - E[y \\vert x=0] \\end{aligned} \\] <p>This only applies since main is a linear operator. This does not apply for non-linear operators: median, variance, percentiles</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#conditional-randomized-experiments","title":"Conditional Randomized Experiments","text":"<p>If one or more external parameters affect the causal effect of the treatment on the outcomes, then we have to do different randomized conditions.</p> <p>By independent testing at different conditions, we can keep the effect of the external parameter as a constant, and we will get the true causal effect of the treatment.</p> <p>It leads to conditional exchangeability, for the particular sub-population $$ x \\perp !!! \\perp (y^1, \\dots, y^A) | s $$ where \\(s\\) are the fixed Effect Modifiers $$ \\begin{aligned} E[y^a] &amp;= \\sum_{j=1}^S E[y^a \\vert s=j] \\cdot p(s=j) \\ &amp;= \\sum_{j=1}^S E[y \\vert x=a, s=j] \\cdot p(s=j) \\end{aligned} $$ In experimental design, effect modifiers \\(s\\) are called the nuisance factors that experimenter controls when performing the RCT. Nuisance factors are vars that can affect \\(y\\) either directly/indirectly, but is not of primary interest to the experimenter.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#self-selection-effectbias","title":"Self-Selection Effect/Bias","text":"<p>In economics, we assume that everyone</p> <ul> <li>is rational</li> <li>makes decisions/selections to maximize self-interests</li> </ul> <p>When individuals choose their own treatments, those who choose to receive a treatment may be systematically different than those who choose not to, leading to a correlation between treatment and outcome that is not due to direct causation</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#importance-of-control-group","title":"Importance of Control Group","text":"<p>We always need to have control group \\(x=0\\), to effectively quantify the causal effect.</p> <p>Let\u2019s say \\(x\\) is non-binary, for eg: \\(x=\\) Sunlight</p> <ul> <li>0: Rainy</li> <li>0.5: Cloudy</li> <li>1: Sunny</li> </ul> \\(E(y \\vert \\text{do}(x=0))\\) \\(E(y \\vert \\text{do}(x=0.5))\\) \\(E(y \\vert \\text{do}(x=1))\\) Conclusion:Changing from 0.5 to 1 is significant 0 100 101 \u274c 0 0 101 \u2705 100 100 101 \u2705"},{"location":"Economics/Causal_Inference/07_Random_Testing/#limitations","title":"Limitations","text":"<ul> <li>Susceptible to attrition: Worst threat to internal validity<ul> <li>If attrition is correlated with treatment, that's bad</li> <li>If attrition is systematic, that's bad</li> </ul> </li> <li>Noncompliance<ul> <li>Individuals assigned to treatment may not take it</li> <li>Individuals assigned to control may take treatment</li> <li>Intent-to-Treat vs Treatment-on-the-Treated</li> </ul> </li> <li>Not always good at external validity</li> <li>Without understanding the various Effect Modifiers, we will get wrong inferences<ul> <li>because you will mistake a local effect for a global effect that applies for all scenarios. Hence, there are limits for Random testing without understanding the causal mechanism. This clearly disproves the thinking that \u201cRCTs are the golden standard for causal inference\u201d</li> <li>Only Conditional Randomized Experiments give correct readings, because it helps obtain the true causality without effect of any other factors. For eg, a lot of Psychology studies are performed on Psychology students, hence it doesn\u2019t really give true research findings.</li> </ul> </li> <li>nearly impossible to perform random tests in economics, due to the following<ul> <li>infeasible (govt/monetary policies)</li> <li>ethical reasons (smoking - lung cancer)</li> <li>cost</li> <li>duration  (childhood intervention &amp; adult outcomes)</li> <li>Long duration studies often suffer from significant (non-random) attrition</li> </ul> </li> <li>Hinderances</li> <li>RCTs require special conditions if they are to be conducted successfully</li> <li>local agreements</li> <li>compliant subjects</li> <li>affordable administrators</li> <li>multiple blinding</li> <li>people competent to measure and record outcomes reliably</li> <li>High dimensional treatment/nuisance factors</li> <li>possibility of too many known/unknown effect modifiers</li> <li>if we do not control for the effect modifiers, the causal effect estimate obtained will be very local. This limits the usefulness of study</li> <li>Scaling-up of effects to the population may give opposite results of the RCT sample</li> <li>Predicting the same results at scale as in the trial can be problematic, as the larger target population can be very different from the study population, so the causal effects may not be transportable</li> <li>General equilibrium effects<ul> <li>even if the trial sample is a random sample of the target population, so that the target population \\(\\sim\\) the study population, applying the same intervention to everyone in the population could generate very different effects than in the trial</li> <li>Hence, the result we obtain is a local result conditional to the current equilibrium</li> </ul> </li> <li>Violation of SUTVA (Stable Unit Treatment Value Assumption)<ul> <li>SUTVA = Assumption that individual\u2019s potential outcome under a treatment does not depend on the treatments received by other individuals, as there is an assumption that there is no interaction b/w individuals.</li> <li>SUTVA can be thought of as an i.i.d. assumption on causal effects</li> <li>If the causal effect depends on how many individuals receive the treatment, then SUTVA is violated. Treatment dilution: treatment is less effective as more people get it</li> <li>In the scaling up effects explanation, we can see that market equilibrium is affecting the outcomes</li> </ul> </li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#scaling-up-of-rt","title":"Scaling-Up of RT","text":"<p>Govt policy to increase farmers\u2019 incomes through subsidized fertilizers, based on effectiveness in RCT. Increased production for the sample farmers would increase their revenue, but if all farmers used this fertilizer, then the overall supply would increase. Assuming that the demand for the produce is inelastic, then the price would reduce. Hence, the income of the farmers would actually reduce. Therefore, the policy of encouraging all farmers to use fertilizers would be bad.</p> <p>The same thing goes for effect of education on earnings. If everyone is now educated, the supply for high-skilled labor increases but the demand is still the same, hence its value decreases.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#sutva-violation","title":"SUTVA Violation","text":"<ul> <li>Violation of SUTVA can also be viewed as a problem of ill-defined interventions</li> <li>When SUTVA is violated</li> <li>Only slight violation can be tolerated</li> <li>the sample treatment and the population treatment are essentially different interventions</li> <li>If violated, then we need to take the interaction into account</li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#handling","title":"Handling","text":"<p>Others receiving the treatment must be considered as an effect modifier of the Randomized Test.</p> <ul> <li>Learn \\(p( \\ y_i \\vert \\text{do}(x_i) \\ )\\) or \\(p( \\ y_i \\vert \\text{do}(x_i), x_j \\ )\\) treating \\(x_j\\) as an effect modifier</li> <li>When estimating the treatment effect on a individual, if SUTVA is violated then we need to consider the treatments received by other individuals as effect modifiers</li> <li>Learn \\(p( \\ y_i \\vert \\text{do}(x_i, x_j) \\ )\\)</li> <li>This requires changing the unit of analysis from the original individual to a population of those units where interaction occurs and is confined in<ul> <li>We can define each individual \\(i\\) to be a \u201clocal population\u201d where such interference occurs and is confined in, and let the underlying population be a population of such local populations</li> </ul> </li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#why-does-violation-happen-a-lot","title":"Why does violation happen a lot?","text":"<p>Unlike medical sciences, socio-economic outcomes are often results of individual interaction. If the market is not perfectly-competitive, individual choices are rarely independent and each person\u2019s choice affects other people.</p> Scale Micro Social/Strategic Interaction(Firm competition in oligopolistic markets) Macro General Equilibrium effects <p>However, it is negligible in certain cases: buyers and sellers in competitive markets</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#examples-of-rct","title":"Examples of RCT","text":""},{"location":"Economics/Causal_Inference/07_Random_Testing/#exams","title":"Exams","text":"<p>For eg, if there are 2 exam sets. The treatments are</p> <ul> <li>\\(x = 0 \\to\\) easy set</li> <li>\\(x = 1 \\to\\) hard set</li> </ul> Scenario Variable Comment Asking students to volunteer for hard test $E(y x = 1)$ Only a certain type of students will volunteer to do so Self-Selection Effect Forcing everyone to take the hard test \\(E(y^1)\\) Everyone has received the input (taking hard test) Randomly assigning sets $E(y x=1) = E(y^1)$ The population and treated sample will very likely have the same type of people"},{"location":"Economics/Causal_Inference/07_Random_Testing/#demand-estimation","title":"Demand Estimation","text":""},{"location":"Economics/Causal_Inference/07_Random_Testing/#goal","title":"Goal","text":"<p>to know consumer demand for a product wrt price</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#given-data","title":"Given Data","text":"\\[ D = \\{ (p_1, q_1), \\dots, (p_n, q_n) \\} \\] <ul> <li>\\(q_i = Q_i^L \\cdot (p_i==L) \\ + \\ Q_i^H \\cdot (p_i==H)\\)</li> <li>\\(\\{ (p_1, Q_1^L, Q_1^H), \\dots, (p_n, Q_n^L, Q_n^H) \\} \\overset{\\text{iid}}{\\sim} P(p, Q^L, Q^H)\\)</li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#method","title":"Method","text":"<ul> <li>treatment - price \\(p\\)</li> <li>outcome - purchases \\(q\\)</li> </ul> <p>Let\u2019s assume there are only 2 inputs (price level) - \\(p \\in \\{ L, H \\}\\). Then \\(\\exists\\)</p> <ul> <li>2 potential outcomes (demand level) - \\(q \\in \\{ Q^L, Q^H \\}\\)</li> <li>Desired causal effect</li> </ul> \\[ \\text{ATE} = E[Q^L - Q^H] \\] <p>From the data, we can learn \\(P(q \\vert p = a), a \\in L, H\\)</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#problem-with-observational-data","title":"Problem with observational data","text":"<p>We cannot directly use P and Q to estimate the demand/supply function. This is because every data point is an equilibrium point and cannot be taken as the demand/supply curve. So, self-selection effect comes into play.</p> <p>Without exchangeability, \\(P(Q^a) \\ne P(Q^a \\vert p=a) = P(q \\vert p=a)\\)</p> <p>The group that \u201creceived\u201d the treatment \\(p=L\\) could be systematically different than the group that \u201creceived\u201d \\(p=H\\)</p> <ul> <li>People that buy when price is high can be richer than those who buy when price is low</li> <li>If we observe the person over time, then their income may be different when the price is low vs price is high</li> </ul> <p>Hence, there will be effect of income elasticity which will alter our understanding the price elasticity</p> <p>Changing price will not help in determination of the causal effect of price change. $$ \\text{ATE} \\ne E(q|p = l) - E(q|p = h) $$ This is because, in real life, \\(p\\) is not randomly-assigned. So, the people who buy at high price and low price are completely-different; the populations are different in both the cases. So, the effect of income comes into picture. Therefore, the true and direct causal effect of price will not be understood.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#solution","title":"Solution","text":"<p>Companies could run experiments by randomly assigning prices to customers in different markets and over time</p> <p>Companies could perform A/B testing by running experiments by randomly assigning prices in different markets and over time. This change in price will target the individual, so the true treatment effect will be learnt, as the income of people is quite constant.</p> <p>This is mainly used by online companies, as it is inexpensive to do so.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#giffen-behavior","title":"Giffen Behavior","text":"<p>cannot be trusted through observational data. This is because</p> <p>Higher prices are often associated with more purchases, but is it</p> <ul> <li>higher demand causing both higher prices and more purchases, or</li> <li>higher prices causing people to buy more (Giffen behavior)</li> </ul> <p>The prices are \u201cchosen\u201d, so the analysis using observed increased prices is not necessarily a treatment and does not help us obtain the true causal effect</p> <p>We need to keep in mind</p> <ol> <li>inflation</li> <li>increase in wages</li> </ol> <p>However, with randomized treatment (such as subsidies for the commodity), we can derive the true giffen behavior and hence make correct analysis.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#classroom-size","title":"Classroom Size","text":""},{"location":"Economics/Causal_Inference/07_Random_Testing/#goal_1","title":"Goal","text":"<p>to know the effect of classroom size on student performance</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#given-data_1","title":"Given Data","text":"\\[ D = \\{ (p_1, q_1), \\dots, (p_n, q_n) \\} \\]"},{"location":"Economics/Causal_Inference/07_Random_Testing/#method_1","title":"Method","text":"<ul> <li>treatment - classroom size</li> <li>outcome - student performance</li> </ul> <p>Let\u2019s assume there are only</p> <ul> <li>2 inputs (room size) - \\(s \\in \\{ S, L \\}\\)</li> <li>2 potential outcomes (performance) - \\(p \\in \\{ p^S, p^L \\}\\)</li> </ul> \\[ \\text{ATE} = E[p^L - p^S] \\]"},{"location":"Economics/Causal_Inference/07_Random_Testing/#problem","title":"Problem","text":"<p>Weaker students often deliberately grouped into smaller classes</p> <p>Hence, Many studies of education production using non-experimental data suggest there is little or no link between class size and student learning</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#solution_1","title":"Solution","text":"<p>Randomized assignment of classroom size is necessary, as usually the more well-off students will be in private schools , so clearly there is self-selection effect here. So we will take the same group of kids, and randomly assign a small and large room.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#study-in-tennesee-usa","title":"Study in Tennesee, USA","text":"<p>Random assignment of classroom sizes to students showed that students in smaller classrooms performed better.</p> <p>However, this may conclusion may not be accurate for the state of Tennesee itself, because there could be some other factors in play here. Maybe the students are not accustomed to the new large classrooms, which affects the performance. So over time, difference in performance might be nothing the more the students get used to it.</p> <p>This result definitely can**not** be used directly elsewhere. This is because the composition of tested sample and the other populations will be different:</p> <ul> <li>income</li> <li>race</li> <li>culture</li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#solution_2","title":"Solution","text":"<p>Causal Mechanism Learning</p> <p>In this case, let\u2019s analyze the following: </p> <p>How would a small class help in performance?</p> <p>hmm\u2026 because, students sit closer to the board. This mechanism is applicable everywhere. If this is the only mechanism, then we can confidently say that the results of the Tennessee experiment can be applied everywhere.</p> <p>For example, maybe smaller classrooms enable easier interactions between students and teachers. Hence, smaller classrooms helpful in the US/Europe where they have a lot of group work and interactions; but not in India/China as the teacher mostly just teaches without much interactions.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#fertilizer","title":"Fertilizer","text":""},{"location":"Economics/Causal_Inference/07_Random_Testing/#goal_2","title":"Goal","text":"<p>to know the effect of fertilizer on crop output</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#method_2","title":"Method","text":"<ul> <li>treatment - using fertilizer</li> <li>outcome - crop output</li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#problem_1","title":"Problem","text":"<p>The result might not be accurate with just randomized experiment. This is because, the effectiveness of fertilizer depends on the temperature (effect modifier)</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#solution_3","title":"Solution","text":"<p>Conditional Randomized Experiment</p> <p>Randomized experiments at different temperatures</p> <ul> <li>a randomized experiment at low temperature</li> <li>a randomized experiment at high temperature</li> </ul> <p>This is because, the temperature affects the causal effect of fertilizer on the crop output. By independent testing at different temperatures, we can keep the effect of temperature as a constant, and we will get the true causal effect of fertilizer.</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#fumigation-and-yield","title":"Fumigation and Yield","text":"<p>Fumigation is the use of fumigants to control eelworms which affects crop yield</p> <p>Suppose, in a place A, we conduct an RCT to study the effect of fumigation on yield by randomly selecting \\(N\\) barley fields and randomly applying fumigation to \\(M\\) of them. The result shows that fumigation increases barley yield by 20%.</p> <p>The understanding of the result depends on our understanding of the causal mechanism and its implied effect modifiers.</p> <p>We need to investigate the effect of</p> <ul> <li>season when the study was performed</li> <li>previous year\u2019s crop on that same field</li> <li>other prior known/hypothesised effect modifiers</li> </ul> <p>For eg: $$ \\begin{aligned} &amp;E(\\text{Causal effect} \\vert \\text{Summer}, \\text{Same Crop}) \\ \\ne &amp; E(\\text{Causal effect} \\vert \\text{Winter}, \\text{Same Crop}) \\ \\ne &amp; E(\\text{Causal effect} \\vert \\text{Summer}, \\text{Alternated Crop}) \\ \\ne &amp; E(\\text{Causal effect} \\vert \\text{Winter}, \\text{Alternated Crop}) \\end{aligned} $$ Hence, this causal effect is local</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#psychology-studies","title":"Psychology Studies","text":"<p>Studies of most Psychology studies are WEIRD: Western, Educated, Industrialized, Rich, Democratic, particularly American undergrads</p>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#when-best-to-do-rct","title":"When best to do RCT","text":"<ul> <li>Demand for treatment exceeds supply</li> <li>Treatment will be phased in over time</li> <li>Treatment is in equipoise (genuine uncertainty)</li> <li>Local culture open to randomization</li> <li>Monopolist system: A/B testing for online services</li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#when-not-to-do-rct","title":"When not to do RCT","text":"<ul> <li>When it is unethical or illegal</li> <li>When you need immediate results</li> <li>When you want to measure something that happened in the past</li> <li>When it involves universal ongoing phenomena (like pandemics)</li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#ab-testing","title":"A/B Testing","text":"<ul> <li>hashing of <code>user_id</code></li> </ul>"},{"location":"Economics/Causal_Inference/07_Random_Testing/#ab-testing-vs-aa-testing","title":"A/B Testing vs A/A Testing","text":"<p>A/A test  - ensure if testing system is working correctly - quantify the amount of variation that can occur between two identical groups naturally</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/","title":"Causal Model","text":"<p>A causal/scientific model \\(M\\) for a set of RVs \\(\\{ x_1, \\dots, x_n \\}\\) is a model of the joint distribution \\(p(x_1, \\dots, x_n)\\) as well as the causal structure governing \\(\\{ x_1, \\dots, x_n \\}\\) which describes the causal relationships among the variables and how the data-generating process occurs $$ M: y \\leftarrow x $$</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#causal-graph-model","title":"Causal Graph Model","text":"<p>Causal diagram/graph is a graph that can be used to represent a causal structure and hence, describe our quantitative knowledge about a causal mechanism</p> <p>Causal model that uses a causal graph to represent the causal structure is called as Causal Graph Model/Causal Bayesian/Belief network.</p> <ul> <li>Causal diagrams can make assumptions scientific and \"falsifiable\"</li> <li>Causal diagrams can help identify which variables to randomize, include in model, or ignore</li> </ul> <p>RCM was developed in statistics, causal graphical model is derived from CS/AI.</p> <p>You can use LLMs to help derive causal theory</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#parts-of-causal-model","title":"Parts of Causal Model","text":"<ol> <li>Causal Structure \\(G\\): Direction of causality (What causes what)</li> <li>Statistical Model \\(H\\): Joint distribution function</li> </ol> \\[ M = (H, G) \\]"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#example","title":"Example","text":"<p>Consider a model \\(y = 2x\\). This is a statistical model.</p> <p>If \\(y \\leftarrow 2x\\), then it means that \\(x\\) causes \\(y\\). This is a causal model.</p> <p>Let\u2019s analyze the \\(x,y\\) pairs for the following sequential changes.</p> Model 1. do\\((x=2)\\) 2. do\\((x=3)\\) 3. do\\((y=2)\\) Statistical 2, 4 3, 6 1, 2 Causal 2, 4 3, 6 3, 2 <p>This is because, \\(x\\) causes \\(y\\); not the other way around.</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#do-calculus","title":"<code>do</code>-calculus","text":"<p>Let - \\(G\\) be a DAG - \\(G_{\\bar T}\\) represent \\(G\\) post-intervention (ie with all links into treatment \\(T\\) removed) - \\(G_{\\underline T}\\) represent \\(G\\) with all links out of treatment \\(T\\) removed</p> <p>Rules 1. \\(P(y \\vert \\text{do}(t), z, w) = P(y \\vert \\text{do}(t), z) \\iff Y \\perp\\!\\!\\!\\perp W \\vert (Z, T)\\) in \\(G_{\\bar T}\\) 2. \\(P(y \\vert \\text{do}(t), z) = P(y \\vert t, z) \\iff Y \\perp\\!\\!\\!\\perp T \\vert Z\\) in \\(G_\\underline{T}\\) 3. \\(P(y \\vert \\text{do}(t), z) = P(y \\vert z) \\iff Y \\perp\\!\\!\\!\\perp T \\vert Z\\) in \\(G_{\\bar T}\\) and \\(Z\\) is not a descendent of \\(T\\)</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#causal-diagramgraph","title":"Causal Diagram/Graph","text":"<p>Directed graph that represents the causal structure of a model. It is represented using a bayesian network: DAG (Directed Acyclic Graph) in which each node has associated conditional probability of the node given in its parents. </p> <p>The joint distribution is obtained by taking the product of the conditional probabilities.</p> <p>$$ \\begin{aligned} p(x_1, \\dots, x_n) &amp;= \\Pi_{i=1}^n  p(  x_i \\vert \\text{pa}(x_i)  ) \\ x_i  &amp; {\\tiny \\coprod}  \\text{nd}(x_i) \\vert \\text{pa}(x_i) \\end{aligned} $$ where</p> <ul> <li>pa = parent</li> <li>nd = not descendant</li> </ul> <p>Useful when you are only interested in the causal structure, and not so much in the statistical model</p> <pre><code>flowchart TD\nB([B]) &amp; C([z]) --&gt; A([A])</code></pre> \\[ P(A, B, C) = P(A | B, C) \\cdot P(B) \\cdot P(C) \\]"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#why-dag","title":"Why DAG?","text":"<ul> <li>Directed, because we want causal effects directions</li> <li>Acyclic, because a variable cannot cause itself.</li> </ul> <p>my question is: What about recursive loops, such as our body\u2019s feedback loops</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#parts","title":"Parts","text":"Nodes - vars - Rounded - Unconditioned- Square - Conditioned Directed Edges - Causal directions 1. The presence of an arrow from \\(x_i\\) to \\(x_j\\) indicates either that \\(x_i\\) has a direct causal effect on \\(x_j\\) \u2013 an effect not mediated through any other vars on the graph, or that we are unwilling to assume such a effect does not exist2. The absence of an arrow from \\(x_i\\) to \\(x_j\\) indicates the absence of a direct effect; the absence of an arrow hence represents a more substantive assumption <pre><code>flowchart TB\na([a])\nw([w])\nx([x])\ny([y])\nz([z])\n\nx --&gt; y &amp; z\nz --&gt; a\n\nw --&gt; y</code></pre> Term Condition Above Example Parent Node from which arrow(s) originate \\(x\\) is parent of \\(y\\) and \\(z\\) Child Node to which arrow(s) end \\(y\\) and \\(z\\) are children of \\(x\\) Descendants Ancestors Exogenous vars w/o any parent \\(w, x\\) Endogenous vars w/ \\(\\ge 1\\) parent \\(y, z, a\\) Causal Path Uni-directional path \\(x z a\\)\\(z a\\) \\(x y \\(&lt;br /&gt;\\)w y\\) Non-Causal Path Bi-directed path \\(x y w\\) Confounder Structural DefinitionVariable that allows controlling for confoundingNon-Structural Definition, but not suitable for colliding confounderNode that satisfies:1. Node associated with treatment \\(T\\)2. Node associated with outcome \\(y\\), conditioned on treatment \\(T\\)3. Node not on causal path between \\(T\\) and \\(y\\) Collider Structural DefinitionNon-Structural Definition, but not suitable alwaysNode having multiple parents, where path \u2018collides\u2019 \\(y\\) in the path \\(x y w\\) Blocked Path Path with a- conditioned non-collideror- unconditioned collider, w/o conditioned descendants Back-Door Paths Non-causal paths b/w \\(x\\) and \\(y\\), which if left open, induce correlation b/w \\(x\\) and \\(y\\) without causation d-separated vars all paths b/w vars are blocked d-connected vars \\(\\exists\\) path between the vars which isn\u2019t blocked conditionally-independent vars If 2 vars are d-separated after conditioning on a set of vars conditionally-dependent/associated vars If 2 vars are d-connected after conditioning on a set of varsw/o faithfulness condition, this may not be true"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#properties","title":"Properties","text":"<p>Causal diagrams compatible with a joint distribution \\(p(x_1, \\dots, x_n)\\) must satisfy</p> Property Meaning Causal Markov Condition Every var is independent of any other vars (except its own effects) conditional on its direct causes Completeness All common causes (even if measured) of any pair of vars on the graph are on the graphThis property is as important as the requirement that all relevant factors are accounted for. Our ability to extract causal information from data is predicated on this untestable assumption Faithfulness The joint distribution \\(p(x_1, \\dots, x_n)\\) has all the conditional independence relations implied by the causal diagram, and only those conditional independence relations <ul> <li>\\(\\text{nd}:\\) non-descendent</li> <li>\\(\\text{pa}:\\) parents</li> </ul>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#validating-graphical-model","title":"Validating Graphical Model","text":"<p>Consider 2 variables \\(v_1\\) and \\(v_2\\) - If \\(v_1\\) is connected to \\(v_2\\), there should be a correlation - If \\(v_1\\) is not connected to \\(v_2\\), there should be no correlation between \\(v_1\\) and \\(v_2\\) given \\(\\text{pa}(v_1)\\), ie for each group of \\(\\text{pa}(v_1)\\)</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#causal-operations","title":"Causal Operations","text":"<p>Conditioning: Broad concept of considering or restricting analysis based on certain variables - Adjusting - Selecting</p> Adjusting Selecting Definition Including variables as covariates in a statistical model Choosing a subset of data where treatment and control groups are balanced Scope Specific method Specific method Implementation Typically through regression, propensity score methods, or weighting Often through matching techniques Sample size impact Generally retains full sample May reduce sample size Primary goal Control for confounding Create comparable groups Typical use Accounting for  confounders in full dataset Creating balanced comparison groups Flexibility with continuous variables Generally high Often requires categorization Risk of introducing bias Possible if adjusting for inappropriate variables Possible if selection criteria are inappropriate Population inference Often for entire population May be limited to specific subpopulation"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#causal-relations","title":"Causal Relations","text":""},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#general-framework","title":"General Framework","text":"<pre><code>flowchart TB\noc([Observed&lt;br/&gt;Confounders])\nuc([Unobserved&lt;br/&gt;Confounders])\noce([Observed&lt;br/&gt;Common&lt;br/&gt;Effects])\nuce([Unobserved&lt;br/&gt;Common&lt;br/&gt;Effects])\nx([x])\ny([y])\n\nx --&gt; y\noc ---&gt; x &amp; y\nuc -..-&gt; x &amp; y\n\nx &amp; y --&gt; oce\nx &amp; y -.-&gt; uce\n\nclassDef dotted stroke-dasharray:5\nclass uc,uce dotted\n\nlinkStyle 0 stroke:green</code></pre>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#types","title":"Types","text":"Type \\(x, y\\) are statistically-independentCorrelation \\(=\\) Causation\\(E[y \\vert x] = E[y \\vert \\text{do}(x)]\\) \\(E[y \\vert \\text{do}(x)]\\) Comment Path \u2018__\u2019 by collider \\(c\\) Example\\(z\\) Example\\(x\\) Example\\(y\\) Mutual Dependence/Confounding/Common Cau \u274c Info on \\(x\\) helps predict \\(y\\), even if \\(x\\) has no causal effect on \\(y\\) Smoker Carrying a lighter Cancer Conditioned Mutual Dependence \u2705 \\(\\sum_i E[y \\vert \\text{do}(x), c_i] \\cdot P(c_i)\\)\\(=\\sum_i E[y \\vert x, c_i] \\cdot P(c_i)\\) blocked Smoker=FALSE Carrying a lighter Cancer Mutual Causation/Common Effect \u2705 blocked Revenue of company Size of company Survival of company Conditioned Mutual Causation \u274c opened Revenue of company Size of company Survival of company=TRUE(we usually only have data for companies that survive)(Survivorship bias) Mediation \u274c Conditioned Mediation \u2705 blocked 1. Cancer2. Tax 1. Tar deposits in lung2. Economic consequences 1. Smoking2. Economic conditions <pre><code>flowchart TB\n\nsubgraph Mediation\n  subgraph ucm[Unconditioned]\n    direction TB\n    x1([x]) --&gt; c1([z]) --&gt; y1([y])\n    %% x1 --&gt; y1\n  end\n\n  subgraph cm[Conditioned]\n    direction TB\n    x2([x]) --&gt; c2[z] --- y2([y])\n    %% x2 --&gt; y2\n  end\nend\n\nsubgraph mc2[Mutual Causation 2]\n    subgraph ucmc2[Unconditioned]\n        direction TB\n        x8([x]) &amp; y8([y]) --&gt; w8([w]) --&gt; c8([z])\n        %% x8 --&gt; y8\n    end\n    subgraph cmc2[Conditioned]\n        direction TB\n        x7([x]) &amp; y7([y]) --&gt; w7([w]) --&gt; c7[z]\n        %% x7 --&gt; y7\n    end\nend\n\nsubgraph mc[Mutual Causation 1]\n    subgraph ucmc[Unconditioned]\n        direction TB\n        x4([x]) &amp; y4([y]) --&gt; c4([z])\n        %% x4 --&gt; y4\n    end\n    subgraph cmc[Conditioned]\n        direction TB\n        x3([x]) --&gt; c3\n        y3([y]) --&gt; c3[z]\n        %% x3 --&gt; y3\n    end\nend\n\nsubgraph md[Mutual Dependence]\n    subgraph ucmd[Unconditioned]\n        direction TB\n        c6([z]) --&gt; x6([x]) &amp; y6([y])\n        %% x6 --&gt; y6\n    end\n    subgraph cmd[Conditioned]\n        direction TB\n        c5[z] --- x5([x]) &amp; y5([y])\n        %% x5 --&gt; y5\n    end\nend\n\n%%linkStyle 4,24,23 stroke:none;</code></pre>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#variables","title":"Variables","text":"<p>Use dagitty for help - https://www.dagitty.net/ - https://ahmedthahir.github.io/dagitty/</p> Type Should adjust? Adjustment Stage Adjustment Reason Selection allowed?(Selection gives same result for population?) Selection Reason Independent \u274c Not related with \\(y\\) \u274c Treatment \u2705 2 Obviously \u2705 Non-treatment causes of \\(y\\) \u2705 2 Avoid omitted variable bias \u274c Cause/assignment of \\(T\\) \u2705 1 Correct for non-random assignment \u2705 Cause/assignment of non-treatment causes \u2705 1 Correct for non-random assignment \u2705 Consequence of \\(T\\) \u274c Not related with \\(y\\) \u274c Confounder \u2705 2 \\(z\\) affects \\(y\\)Close backdoor \u274c Cause/assignment of confounder \u2705 1 Correct for non-random assigment Effect modifier \u2705 2 Effect of \\(x\\) on \\(y\\) changes with \\(z\\) Instrumental vars \u26a0\ufe0f 1 Only if assignment to treatment not available Surrogate/Proxy Confounder \u26a0\ufe0f 1 Only if confounder not available MediatorConsequence of mediator \u274c Conditioning causes over-controlling: Will take away some effect of \\(x\\) on \\(y\\)Any result is only valid for the conditioned value of mediator \u2705 ColliderConsequence of Collider \u274c Conditioning causes endogeneity/selection effect- Can create fake causal effects- Can hide real causal effectsAny result is only valid for the conditioned value of collider \u274c Colliding mediatorColliding confounder \u274c Opens backdoor \u274c Consequence of \\(y\\) \u274c Logically-flawed; only predictive power, no causal power \u274c"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#confounding","title":"Confounding","text":""},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#self-selection-bias","title":"Self Selection Bias","text":"<p>Special case of confounding, when \\(z\\) affects the selection of \\(x\\) and also has a causal effect on \\(y\\), then \\(z\\) is confounder.</p> <pre><code>flowchart LR\nc([\"Ability/Talent&lt;br/&gt;(Z)\"])\nT([\"Education&lt;br/&gt;(T)\"])\ny([\"Earnings&lt;br/&gt;(y)\"])\n\nc --&gt;|Affects&lt;br/&gt;selection| T\nc --&gt;|Directly&lt;br/&gt;Affects| y\n\nT -.-&gt;|Associated but&lt;br/&gt;not necessarily causes| y</code></pre> <p>Here, education may not necessarily causally affect earnings.</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#unmeasured-confounding","title":"Unmeasured Confounding","text":"<p>We need to find new ways to identify causal effect</p> \\(z\\) fully observed \\(\\not \\exists\\) unmeasured confounding Selection on \u2705 \u2705 observables \u274c \u274c unobservables <p>However, in some cases, there can exist a set of observed vars conditioned such that it satisfies the back-door criterion, by blocking all non-causal paths b/w \\(x\\) and \\(y\\)</p> <pre><code>flowchart TB\n\nsubgraph Conditioned\n    direction TB\n  wc([w]) -.- zc &amp; yc\n  zc[z] --- xc([x]) --&gt; yc([y])\nend\n\nsubgraph Unconditioned\n    direction TB\n  wu([w]) -.-&gt; zu &amp; yu\n  zu([z]) --&gt; xu([x]) --&gt; yu([y])\nend\n\nlinkStyle 3,7 stroke:green\nlinkStyle 0,1,2 stroke:none\n\nclassDef dotted stroke-dasharray:5\nclass wu,wc dotted</code></pre> <p>\\(w\\) is a confounder to \\(x\\) and \\(y\\), but we do not need to observe it, as causal effect of \\(x\\) on \\(y\\) is identifiable by conditioning on \\(z\\)</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#mediator","title":"Mediator","text":""},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#collider","title":"Collider","text":""},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#collider-bias","title":"Collider Bias","text":"<p>'Jinxing'</p> <pre><code>flowchart LR\nT([\"Premature celebration&lt;br/&gt;(T)\"])\ny([\"Bad outcome&lt;br/&gt;(y)\"])\n\nc[\"Reporting&lt;br/&gt;(C)\"]\n\nT &amp; y --&gt; c\nT -.-&gt;|\"Associated but&lt;br/&gt;not necessarily causes\"| y</code></pre> <p>Only the bad outcomes that got 'jinxed' get reported</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#effect-modifiers","title":"Effect Modifiers","text":"<p>Confounders \\(s\\) that change the causal effect of a treatment \\(x\\), since their causal effect on the outcome \\(y\\) interacts with treatment\u2019s causal effect on \\(y\\)</p> <p>Controlling them help control conditionally randomized experiments.</p> <p>Consider the following causal diagram.</p> <pre><code>flowchart TD\n\nsubgraph After Simplification\n    others([s&lt;sup&gt;y&lt;/sup&gt;]) &amp; x2([X]) --&gt; y2([Y])\nend\n\nsubgraph Before Simplification\n    a([A]) &amp; b([B]) &amp; c([C]) &amp; w([W]) &amp; x1([X]) --&gt; y([Y])\nend</code></pre> <p>where \\(s^y\\) is anything other than \\(x\\) that can causally affect \\(y\\); ie, the set of potential effect modifiers</p> <p>An example could be gender, temperature, etc.</p> <p>Mathematically, \\(s\\) is an effect modifier if $$ \\begin{aligned} P(y) &amp;\\ne P(y \\vert s) \\ E[y \\vert \\text{do}(x)] &amp;\\ne E(y \\vert \\text{do}(x), s) \\end{aligned} $$</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#instrumental-variable","title":"Instrumental Variable","text":"<p>Independent var that affects \\(y\\) indirectly via \\(T\\) only</p> <p>Helps alleviate endogeneity bias due to simultaneity bias</p> <pre><code>flowchart TB\n\nsubgraph Scenario B\ndirection TB\nT2 --&gt; y2\nv((v)) --&gt; I2((I)) &amp; T2\nu2((u)) --&gt; T2((T)) &amp; y2((y))\nend\n\nsubgraph Scenario A\ndirection TB\nI((I)) --&gt; T --&gt; y\nu((u)) --&gt; T((T)) &amp; y((y))\nend\n\nclassDef green fill:green\nclass I2,I green</code></pre> <p>A variable \\(I\\) can serve as an instrumental variable for identifying the causal effect of \\(T\\) on \\(y\\) \\(\\iff\\) 1. Relevance: \\(I\\) is associated with treatment \\(T\\)     1. \\(r(I, T) \\ne 0\\)     2. Testable with stats 2. Exclusion: \\(I\\) indirectly affects \\(y\\) only through \\(x\\)     1. \\(I\\) affects \\(y\\): \\(r(y, I) \\ne 0\\)     2. \\(I\\) does not affect \\(y\\) directly: \\(r(y, I \\vert T) = 0\\)         1. Every open path connecting \\(I\\) and \\(y\\) has an arrow pointing into \\(x\\)         2. \\(I\\) is d-separated and independent from any common causes of \\(x\\) and \\(y\\), since \\(x\\) is a collider on their paths     3. Testable with stats and theory     4. Hardest condition to satisfy and prove 3. Exogeneity: \\(I\\) is not associated with omitted variables \\(u\\)     1. \\(r(I, u) = 0\\)     2. Testable with theory</p> <p>Rule of thumb: more surprising an IV is, the more likely it is a good one</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#education","title":"Education","text":"<p>Parent\u2019s education is IV for child wage through child education</p> <pre><code>flowchart TB\npe([\"Parents&lt;br/&gt;Education&lt;br/&gt;(IV)\"]) --&gt; ce([\"Child&lt;br/&gt;Education&lt;br/&gt;(x)\"]) --&gt; ci([\"Child&lt;br/&gt;Income&lt;br/&gt;(y)\"])\n\npe -.- ag([\"Child&lt;br/&gt;Age, Gender&lt;br/&gt;(s)\"]) --&gt; ce &amp; ci\ncity([\"City&lt;br/&gt;(FE)\"]) --&gt; pe &amp; ce &amp; a &amp; ci\n\na([\"Ability&lt;br/&gt;(s)\"]) -..-&gt; ce &amp; ci\n\nclassDef dotted stroke-dasharray:5\nclass a dotted\n\nclassDef highlight fill:darkred,color:white\nclass pe highlight\n\nlinkStyle 1 stroke:green</code></pre> <p>College-educated parents have +ve impact on children\u2019s college attainment, either through better home education or because they are more capable of affording college education.</p> <p>If we assume that more educated parents</p> <ul> <li>don\u2019t produce children with higher unobserved abilities/preferences that affect education and wages</li> <li>don\u2019t directly help children obtain higher wage jobs</li> </ul> <p>The statement holds true as the only way parent\u2019s education affects individual\u2019s earnings is through effect on child\u2019s education.</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#demand-elasticity","title":"Demand Elasticity","text":"<p><pre><code>flowchart LR\n\nop[Oil Price]\ncs[Climate @ Production]\ncd[Climate @ Consumption]\n\nsubgraph Supply\ndirection LR\nps[Supply Price]\nqs[Supply Quantity]\nend\n\nsubgraph Demand\ndirection LR\npd[Demand Price]\nqd[Demand Quantity]\nend\n\npset[\"Selling Price (x)\"]\nqeq[\"Sales Quantity&lt;br/&gt;ie, Equilibrium Quantity&lt;br/&gt;(y)\"]\n\nop &amp; cs --&gt; Supply --&gt; pset --&gt; qeq\ncd --&gt; Demand --&gt; qeq</code></pre> - IV through supply: Oil Price and Climate at production site - IV through demand: Climate at consumption site</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#promotion","title":"Promotion","text":"<p>Randomized promotion/encourage of usage of a policy is an instrument, as it matches all 3 criteria</p> <p>Will only give the CACE</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#fixed-effects","title":"Fixed Effects","text":"<p>Variable that captures effect of unobserved confounders</p> \\[ \\begin{aligned} \\hat y &amp;= \\beta_0 + \\beta_1 x + \\textcolor{hotpink}{\\tau} + u \\\\ \\implies \\widehat{\\text{ATE}} &amp;= \\beta_1 \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#city-is-a-fixed-effect","title":"City is a Fixed Effect","text":"<p>City captures ability, school quality, productivity and other unobserved factors</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#idk","title":"IDK","text":"\\[ \\begin{aligned} p(x_a, \\dots, x_b) &amp;= \\Pi_i \\  P(x_i \\vert \\text{pa}(x_i)) &amp;&amp; i = [a, b] \\\\ p(x_a, \\dots, x_b \\vert \\text{do}(x_c=1))  &amp;= \\Pi_i \\  P(x_i \\vert \\text{pa}(x_i)) &amp;&amp; i = [a, b], i \\ne c \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#intervention","title":"Intervention","text":"<p>\\(\\text{do}(x_i = a)\\) implies removing all arrows entering \\(x_i\\) while setting \\(x_i = a\\), hence removing the effect of all parents of \\(x_i\\)</p> <p>Hence \\(x_i\\) becomes endogenous after intervention</p> <pre><code>flowchart TB\n\nsubgraph Post-Intervention\ndirection TB\na2((a)) &amp; b2((b)) --- c2((c)) --&gt; d2((d))\nend\n\nsubgraph Pre-Intervention\ndirection TB\na1((a)) &amp; b1((b)) --&gt; c1((c)) --&gt; d1((d))\nend\n\nlinkStyle 0,1 stroke:none</code></pre> Pre-Intervention \\(p(A, B, C, D) = p(D \\vert C) \\cdot p(C \\vert A, B) \\cdot P(A) \\cdot p(B)\\) Post-Intervention \\(p( \\ A, B, C, D \\vert \\text{do}(C=c) \\ ) = p(D \\vert C=c) \\cdot P(A) \\cdot p(B)\\) \\[ p(A \\vert \\text{do}(C)) = p(A) \\\\ p(A \\vert C) \\ne p(A) \\]"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#adjustingconditioning","title":"Adjusting/Conditioning","text":"<p>To ensure that \\(E(y|x=1) = E(y^1)\\), we need to ensure that the population and treated-sample are the similar in their features.</p> <p>2 ways of eliminating the unwanted effect of confounders/effect modifier \\(z\\) - Adjusting - Remove the effect of \\(z\\) on other variables - Conditioning - Hold variable \\(z\\) constant</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#adjusting","title":"Adjusting","text":"<ul> <li>Eliminates self-selection effect from confounders</li> <li>Way to adjust for backdoors</li> <li>Reduces model dependence</li> </ul> <p>This allows for removal of unnecessary data</p> <p></p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#techniques","title":"Techniques","text":"Method Comment Technique Steps Selection Stratification/Conditioning Regression Matching Find untreated observations that are very similar to treated observations based on confounders KNNK-Nearest Neighbors PSMPropensity Score Matching Predict treatment probability as function of confoundersNot great for matching G-Methods Can be used in settings where treatments and confounders vary over time IPWInverse probability weighting Observations with high probability for treatment but don't get it (and vice-versa) have higher weights\\(\\dfrac{\\text{Treatment}}{\\text{Propensity}} + \\dfrac{1-\\text{Treatment}}{1-\\text{Propensity}}\\) Standardization/G-Formula G-Estimation"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#conditioning","title":"Conditioning","text":"<p>Rule of thumb - Condition common causes - Do not condition common effects</p> <p>If we condition on a set of vars \\(z\\) that block all open non-causal paths between treatment \\(x\\) and outcome \\(y\\), then</p> <ul> <li>the causal effect of \\(x\\) on \\(y\\) is identified (estimated from observed data)</li> <li>\\(z\\) is said to satisfy the \u2018back-door criterion\u2019</li> <li>Conditioning on z makes \\(x\\) exogenous to \\(y\\)</li> </ul>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#covariate-balance","title":"Covariate Balance","text":"<p>In a sample where is \\(z\\) is a conditioned confounder $$ P(z \\vert x = x_i) = P(z \\vert x = x_j) \\quad \\forall i, j $$</p> <p>If \\(x\\) is binary $$ \\begin{aligned} &amp; x \\in { 0, 1 } \\ \\implies &amp; P(z \\vert x=1) = P(z \\vert x=0) \\end{aligned} $$</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#matching","title":"Matching","text":"<p>Converting non-RCT observed sample into a sample that satisfies Covariate Balance, ie behaves similar to a RCT sample through control of observed confounding.</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#limitations-of-causal-graph","title":"Limitations of Causal Graph","text":""},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#effect-modifiers_1","title":"Effect Modifiers","text":"<p>There is no way for causal graph to represent the causal effect of input \\(x\\) on output \\(y\\) due to some effect modifier. For example</p> <pre><code>flowchart TD\nf((\"Fertilizer&lt;br/&gt; (x)\")) &amp; t((\"Temperature&lt;br/&gt; (s&lt;sup&gt;y&lt;/sup&gt;)\")) --&gt; y((\"Yield&lt;br/&gt; (y)\"))</code></pre> <p>Temperature does not affect how much usage of fertilizer, but we know that the temperature affects the effectiveness of the fertilizer, but we have no way of representing that here. However, the Causal Effect Formula will take care of that.</p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#cycles","title":"Cycles","text":"<p>Does not support cycles</p> <p>Workaround <pre><code>flowchart TB\n\nsubgraph After\ndirection TB\n1[a_t-1] --&gt; 2[b_t] --&gt; 3[a_t]\nend\n\nsubgraph Before\ndirection TB\na --&gt; b --&gt; a\nend</code></pre></p>"},{"location":"Economics/Causal_Inference/08_Causal_Graphical_Model/#measurement-bias","title":"Measurement Bias","text":"<p>The estimated causal relationship between observed values of \\(T\\) and \\(y\\) may be different from the true relationship</p> <p>This could be due to - Mismeasurement - Usage of instrumental variables or surrogate confounders</p> <p>Measurement error can be a confounder, mediator, collider</p> <p>Dimensions - Independence: measurement error in treatment and in outcome are independent - Differential: </p> Differential Dependent Comment \u274c \u274c No bias under the null \u274c \u2705 Backdoor path \u2705 \u274c Backdoor path \u2705 \u2705 Backdoor path"},{"location":"Economics/Causal_Inference/09_Causal_Discovery/","title":"09 Causal Discovery","text":"<p>Involves finding change in association - not necessarily correlation; can be mutual information as well</p>"},{"location":"Economics/Causal_Inference/09_Causal_Discovery/#algorithm","title":"Algorithm","text":"Algorithm PC"},{"location":"Economics/Causal_Inference/09_Causal_Discovery/#multiple-hypothesis-testing-correction","title":"Multiple Hypothesis Testing Correction","text":"<p>Make sure to do this</p>"},{"location":"Economics/Causal_Inference/09_Causal_Discovery/#implementation","title":"Implementation","text":"<p>To perform multiple testing correction with minimal changes, perform correction after discovery</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Estimation/","title":"Causal Effect Estimation","text":"Method Control Variables Minimum Model Observational Data Follow DAG Matching/IPW MatchingPropensity scores <code>outcome ~ treatment, matched_data</code><code>outcome ~ treatment, weights</code> RCT Not necessary <code>outcome ~ treatment</code> Diff-in-Diff Not necessary, unless DAG requires <code>outcome ~ before_after + T + T*before_after</code> RDD Not necessary <code>outcome ~ z + cutoff</code>Won't it be this <code>outcome ~ z + T + T*z</code> IV Not necessary, unless DAG requires <code>treatment_hat ~ instrument + w</code><code>outcome ~ treatment_hat + w</code>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Estimation/#rct","title":"RCT","text":"<p>CACE: Use 'assignment to treatment' as an instrument</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Estimation/#differences-in-differences","title":"Differences-in-Differences","text":"\\[ y_{it} = \\beta_0 + \\beta_1 T + \\beta_3 t + \\beta_4 (T \\times t) $$ $$ \\begin{aligned} E[\\Delta D] &amp;=  \\Big( E[y_{1 \\ t}] - E[y_{0 \\ t}] \\Big) - \\Big( E[y_{1 \\ t_0}] - E[y_{0 \\ t_0}] \\Big) \\\\ &amp;= \\hat \\beta_1(x=1) \\\\ &amp;= E(y \\vert x=1) - E(y \\vert x=1) \\\\ \\implies \\text{ATE} &amp;= \\widehat {\\text{ATE}}\\\\ &amp;\\approx 1 \\cdot \\text{ATT} + 0 \\cdot \\text{ATU} \\\\ &amp;\\approx \\text{ATT} \\\\ &amp;= E[\\Delta D] \\end{aligned} \\] <p>Technically, \\(\\hat \\beta_1\\) is an \"estimate\" of ATE via ATT, because the parallel trend assumption assumes what the treated series would be like in the absence of the treatment, not what the control series would be like given the treatment</p> <p></p> <p> </p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Estimation/#regression-discontinuity-design","title":"Regression Discontinuity Design","text":"<p>Causal effect cannot be obtained directly due to lack of overlap for different \\(s\\), hence we take the neighborhood</p> <p>Eg: Evaluating the treatment effect of college on students in the neighborhood of college acceptance cutoff, where the selection of students is random</p> <p> </p> <p>When a quasi-experiment partially determines the treatment status, the \u201cas if\u201d randomness can be used as an instrument for identifying the causal effect of interest</p> <p>$$ \\begin{aligned} \\widehat {\\text{LATE}} &amp;= \\lim_{z \\to {z_0}^+} E[ y \\vert x=1, z ]  - \\lim_{z \\to {z_0}^-} E[ y \\vert x=0, z ] \\ &amp;= \\lim_{z \\to {z_0}^+} E[ y \\vert z ]  - \\lim_{z \\to {z_0}^-} E[ y \\vert z ] \\end{aligned} $$ LATE = Local ATE - Not population-level treatment effect - The treatment effect for the people in the neighborhood of the cutoff</p> <p>Measuring the gap - Center the threshold \\(z\\) variable - Add indicator &amp; interaction terms $$ y = \\beta_0 + \\beta_1 z_\\text{cent} + \\beta_2 T + \\beta_3 T z_\\text{cent} $$</p> <p>Hyperparameters - Parametric/Non-Parametric models - Bandwidth: Size of neighborhood; far-off observations do not matter very much     -      - Check sensitivity of causal effect to bandwidth         - double &amp; halve the bandwidth - Kernels: Sample importance wrt distance from cutoff     -      - Check sensitivity of causal effect to kernels</p> <p>When reporting causal effect, do all possible hyperparameters and then the report the distribution</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Estimation/#fuzzy-rdd","title":"Fuzzy RDD","text":"<p>with instrumental variabes</p> <p>Use an IV to estimate which side of the cutoff people should have been on</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Estimation/#instrumental-variables","title":"Instrumental Variables","text":"<p>Isolate endogenous component of treatment using an \"instrument\"</p> \\[ \\begin{aligned} y &amp;= f(T, w, u) \\\\ &amp;= f(T_\\text{exog}, T_\\text{endo}, w, u) \\\\ \\implies y &amp;= f(T_\\text{exog}, w, u') \\\\ T_\\text{exog} &amp;= g(I) \\end{aligned} \\] \\(\\hat T\\) \\(\\hat y\\) \\(\\text{ATE}\\) IV Method \\(\\alpha_0 + \\textcolor{hotpink}{\\alpha_1 I} + \\sum_j \\alpha_j w_j + v\\) \\(\\beta_0 + \\textcolor{hotpink}{\\beta_1 I} + \\sum_j \\beta_j w_j + u\\) \\(\\dfrac{\\beta_1}{\\alpha_1}\\) 2SLS \\(\\alpha_0 + \\textcolor{hotpink}{\\alpha_1 I} + \\sum_j \\alpha_j w_j + v\\) \\(\\beta_0 + \\textcolor{orange}{\\beta_1 \\hat T} + \\sum_j \\beta_j w_j + u\\) \\(\\beta_1\\) <p>Note: any confounders \\(w\\) must be the same in both the stages</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/","title":"Causal Effect Learning","text":"<p>Causal effect learning = statistical learning with</p> <ul> <li>Target function: \\(E[y \\vert \\text{do}(x)]\\), instead of \\(E[y \\vert x]\\)   or</li> <li>Target distribution: \\(p(y|\\text{do}(x))\\), instead of \\(p(y \\vert x)\\)</li> </ul>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#stages-of-causal-effect-learning","title":"Stages of Causal Effect Learning","text":"<ol> <li>Identification of causes: Causal Reasoning    Just reasoning and understanding; no math, statistics</li> <li>Reformulate into statistical form</li> <li>Estimation</li> </ol>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#identifiability-of-causal-effects","title":"Identifiability of Causal Effects","text":"<p>Causal effect \\(\\theta(M)\\) is identifiable if it can be uniquely determined from \\(D\\)</p> <ul> <li>\\(M=\\) Model with vars \\(x=(x_1, \\dots, x_n)\\)</li> <li>\\(v = (v_1, \\dots, v_m) =\\) set of observed RVs</li> <li>\\(D \\sim p(v) =\\) Observed data</li> <li>\\(\\theta(M) = g_M(x)\\) be a function of \\(x\\) according to \\(M\\), which is the causal effect of \\(x_i\\) on \\(x_j\\)</li> </ul>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#identification","title":"Identification","text":"<p>Express \\(P(y \\vert \\text{do}(x) \\ )\\) in terms of \\(P(v)\\), where \\(v\\) is the set of observed variables \\(\\{ x, y, \\dots \\}\\)</p> <p>Questions</p> <ol> <li>Is it possible to learn the causal effect of our interest from the available observable variables.</li> <li>What causal assumptions do we need to make to do so?</li> </ol>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#types","title":"Types","text":"Type Identification Example Non-Parametric w/o any parametric assumptions on the relationships among the variables RCT Parametric Statistical and functional form assumptions are involved Observational studies"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#estimation","title":"Estimation","text":"<p>Learn the identified causal effect from a finite sample</p> <p>Once we have established identification using causal reasoning based on causal models, we are left with a pure statistical learning problem</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#types_1","title":"Types","text":"Type Estimation Non-Parametric w/o any parametric assumptions on the relationships among the variables Parametric Statistical and functional form assumptions are involved"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#idk","title":"IDK","text":"<p>Hence we have a matrix</p> Identification | Estimation Parametric Non-Parametric Parametric Non-Parametric"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#limitations-of-causal-effect-learning","title":"Limitations of Causal Effect learning","text":"<ul> <li>Causal effects do not exist in a vacuum. They are usually the effects of complex and scientific/economic processes</li> <li>Causal effects are limited to the scope of the study, ie, population-specific. When we talk about \u201cthe causal effect of \\(x\\) on \\(y\\)\u201d, it is always wrt to a specific population within a specific social, cultural, and economic environment.</li> </ul>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#intervention","title":"Intervention","text":"<p>The effect of an intervention \\(\\text{do}(x_i=a)\\) is to transform the pre-intervention distribution into the post-intervention distribution $$ \\begin{aligned} P(  x_{-i} \\vert \\text{do}(x_i=a)  ) &amp;= \\Pi_{j \\ne i}   p(  x_j \\vert \\text{pa}(x_j)  ) \\ &amp;= \\dfrac{p(x_{-i}, x_i = a)}{p(  x_i = a \\vert \\text{pa}(x_i)  )} \\ &amp;= p(  x_{-i} \\vert x_i = a, \\text{pa}(x_i)  ) \\times p(  \\text{pa}(x_i)  ) \\end{aligned} $$</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#causal-effect-formula","title":"Causal Effect Formula","text":""},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#general-formula","title":"General Formula","text":"\\[ \\begin{aligned} &amp;P(y| \\ \\text{do}(x) \\ ) \\\\ &amp;= \\int P(y| \\ \\text{do}(x), s^y \\ ) \\cdot P(s^y) \\cdot ds^y \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#rct","title":"RCT","text":"\\[ \\begin{aligned} &amp;P(y| \\ \\text{do}(x) \\ ) \\\\ &amp;= P(y \\vert x) \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#observational-studies","title":"Observational Studies","text":"<p>Let \\(z=\\text{pa}(x)\\), ie all the causes of \\(X\\)  $$ \\begin{aligned} p(  y \\vert \\text{do}(x)  ) &amp;= \\int p(y \\vert x, z) \\cdot p(z) \\cdot dz \\ &amp; \\quad \\text{(Causation)} \\ p(  y \\vert x  ) &amp;= \\int p(y \\vert x, z) \\cdot p(z \\vert x) \\cdot dz \\ &amp; \\quad \\text{(Correlation)} \\end{aligned} $$</p> <p>Assuming we observe a random sample of \\(\\{ x, y \\}\\) $$ \\begin{aligned} \\ x {\\small \\coprod} z \\implies p(z \\vert x) &amp;= p(z) \\ \\implies p(y \\vert \\text{do}(x), z) &amp;= p(y \\vert x, z) \\ E[y \\vert \\text{do}(x), z] &amp;= E[y \\vert x, z] \\end{aligned} $$</p> <p>$$ \\begin{aligned} &amp; p(  y \\vert \\text{do}(x=a)  ) \\ &amp;= \\int p( y \\vert \\text{do}(x=a), z ) \\cdot p(  z  ) \\cdot dz \\ &amp;= \\int p(y \\vert x=a, z) \\cdot p(  z  ) \\cdot dz \\ &amp;E(  y \\vert \\text{do}(x=a)  ) \\ &amp;= \\int E[y \\vert \\text{do}(x=a), z] \\cdot p(  z  ) \\cdot dz \\ &amp;= \\int E[y \\vert x=a, z] \\cdot p(  z  ) \\cdot dz \\end{aligned} $$ where</p> <ul> <li>\\(E[y \\vert x=a, z]\\) can be estimated from data using any appropriate statistical model</li> <li>\\(p(z)\\) can be estimated using empirical distribution</li> </ul> <p>What if we don't observe \\(z\\)?</p> \\(z\\) Fully Observed Identifiability of \\(p( \\ y \\vert \\text{do}(x) \\ )\\) \u2705 \u2705 Non-parametrically \u274c \u274c\u2705 Non-parametrically only if identification criteria satisfied"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#non-parametric-identification","title":"Non-Parametric Identification","text":"<p>Provide sufficient conditions</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#back-door-criterion","title":"Back-Door Criterion","text":"<p>Set of variables \\(s\\) satisfy this criterion \\(\\iff\\)</p> <ol> <li>conditioning on \\(s\\) blocks every back-door path from \\(x\\) to \\(y\\)</li> <li>no var in \\(s\\) is a descendant of \\(x\\): \\(s\\) only includes pre-treatment vars</li> </ol> <p>IDK</p> <ul> <li>\\(x\\) is exogenous to \\(y \\iff \\not \\exists\\) open back-door path from \\(x\\) to \\(y\\): \\(p(y \\vert \\text{do}(x)) = p(y \\vert x)\\)</li> <li>\\(x\\) is conditionally exogenous to \\(y \\iff \\not \\exists\\) open back-door path from \\(x\\) to \\(y\\) after conditioning on \\(s\\): \\(p(y \\vert \\text{do}(x), s) = p(y \\vert x, s)\\)</li> </ul> <p>When \\(x\\) is (conditionally) exogenous to y, individual units with different values of \\(x\\) are (conditionally) exchangeable with respect to \\(y\\), in which case an observational study resembles a (conditionally) randomized experiment: treatment assignment mechanism is ignorable $$ s^y \\coprod x \\vert s^B $$ where \\(s^B =\\) set of variables that meet back-door condition</p> <p>idk</p> <ul> <li>\\(\\exists\\) an open back-door path from \\(x\\) to a variable \\(s \\in s^y\\) such that \\(s \\centernot {\\small \\coprod} x \\iff \\exists\\) open back-door path from \\(x \\to y\\)</li> <li>There, if conditioning on \\(s^B\\) blocks all back-door paths from \\(x \\to y \\implies s {\\small \\coprod} x \\vert s^B, \\quad \\forall s \\in s^y\\)</li> <li>Therefore, back-door criterion can be equivalently states as requiring that no direct causes of \\(y\\) are correlated with \\(x\\) conditional on \\(s^B\\)</li> <li>\\(x\\) is exogenous to \\(y\\) conditioning on \\(s^B\\) if \\(s^y {\\small \\coprod} x \\vert s^B\\), else it is endogenous</li> </ul> \\[ \\begin{aligned} p( \\ y \\vert \\text{do}(x), s^B \\ ) &amp;= p( \\ y \\vert x, s^B \\ ) \\\\ p( \\ y \\vert \\text{do}(x) \\ ) &amp;= \\int_{s^B} p( \\ y \\vert x, s^B \\ ) \\cdot p(s^B) \\cdot d s^B \\\\ &amp;= \\sum_{s^B} p( \\ y \\vert x, s^B \\ ) \\cdot p(s^B) \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#front-door-criterion","title":"Front-Door Criterion","text":"<p>If we can establish an isolated and exhaustive mechanism that relates \\(x \\to y\\), then the causal effect of \\(x\\) on \\(y\\) can be calculated as it propagates through the mechanism</p> <p>A set of variables \\(s^F\\) satisfies the front-door criterion when</p> <ol> <li>conditioning on \\(s^F\\) blocks all causal paths from x to \\(y\\)</li> </ol> <p>and</p> <ol> <li>\\(x\\) is exogenous to \\(s^F\\), ie no open back-door paths exist from x to \\(s^F\\)</li> </ol> <p>and</p> <ol> <li>\\(s^F\\) is exogenous to \\(y\\) conditional on \\(x\\), ie conditioning on \\(x\\) blocks all back-door paths from \\(s^F\\) to \\(y\\)</li> </ol> <p></p> <pre><code>flowchart LR\nU --&gt; x &amp; y\nx --&gt; M --&gt; y</code></pre> <p>\\(x \\to M \\to y\\) represents an mechanism that is</p> <ul> <li>isolated: not affected by U</li> <li>exhaustive: only causal path from \\(x \\to y\\)</li> <li>all of the effects of \\(x\\) on \\(y\\) is mediated through \\(x\\)\u2019s effect on \\(M\\)</li> <li>\\(M\\)\u2019s effect on \\(y\\) is confounded by the back-door path \\(M \\leftarrow x \\leftarrow U \\to y\\) but \\(x\\) blocks this path</li> <li>We can find \\(p(y \\vert \\text{do}(x))\\)<ul> <li>directly find \\(p(M \\vert \\text{do}(x)) = p(M \\vert x)\\)</li> <li>use perform back-door adjustment to find \\(p(y \\vert \\text{do(M)})\\)</li> </ul> </li> </ul> \\[ \\begin{aligned} &amp;p( \\ y \\vert \\text{do}(x) \\ ) \\\\ &amp;= \\int p \\left( \\ y \\vert \\text{do}(s^F) \\ \\right) \\cdot p \\left( \\ s^F \\vert \\text{do}(x) \\ \\right) \\cdot ds^F \\\\ &amp;= \\int \\left[{\\small \\int} p \\left( \\ y \\vert (s^F, x) \\cdot p(x) \\cdot dx \\ \\right) \\right] \\cdot p \\left( \\ s^F \\vert \\text{do}(x) \\ \\right) \\cdot ds^F \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#parametric-identification","title":"Parametric Identification","text":"<p>If we use observational data, but neither the back-door nor the front-door criterion is satisfied by the variables that we observe, then we may need additional parametric assumptions in order to identify the causal effect of interest</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#sample-selection-bias","title":"Sample Selection Bias","text":"<p>Let \\(c \\in \\{0, 1\\}\\) indicate whether an individual unit belongs to the subpopulation.</p> <p>The subpopulation with \\(c = 0\\) and the subpopulation with \\(c = 1\\) are not exchangeable. Hence, analyses based on samples drawn from the subpopulation can be thought of as analyses using the whole population, but conditional on \\(c = 1\\)</p> <p>Suppose we want to learn \\(p(y)\\) in the whole population, then \\(c\\) can be considered as a treatment itself: \\(p(y ) = p (y | \\text{do} (c = 1))\\), i.e. the distribution of \\(y\\), where everyone is \u2018assigned\u2019 to the \u2018observed group\u2019</p> <p>Hence nonparametric identification of \\(p (y)\\) relies on whether we can make \\(c\\) exogenous to \\(y\\), which can be done by blocking all backdoor paths between \\(c\\) and \\(y\\)</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#credit-card-default","title":"Credit Card Default","text":"<p>Suppose credit card companies determine whether to accept \\(x\\) credit card applications based solely on income \\(I\\). Once a person is issued a credit card, income determines the probability of her default (\\(y\\))</p> <p>Assume we observe I for entire population, but only observe \\(y\\) for \\(x = 1\\)</p> <ul> <li>Observed: \\(p(y \\vert x=1)\\)</li> <li>Interested: \\(p(y \\vert \\text{do}(x=1))\\)</li> <li>Interested: \\(p(y)\\)</li> </ul> <pre><code>flowchart TB\nI((I)) --&gt; Y((y)) &amp; C[C=1]</code></pre> <p>Since there is sample selection bias to estimate effect of \\(c\\) on \\(y\\):</p> \\[ p (y |\\text{do}(c = 1)) \\ne p (y |c = 1) \\] <p>Since \\(I\\) satisfies backdoor condition for \\(c \\to y\\) $$ \\begin{aligned} p (y |\\text{do}(c = 1)) &amp;= p (y) \\ &amp;=\\int p( y \\vert c=1, I) \\cdot p(I) \\cdot dI \\end{aligned} $$</p> <p>There is no sample selection bias here in learning the causal effect of \\(I\\) on \\(y\\): $$ \\begin{aligned} &amp; p(y \\vert \\text{do}(I)) \\ &amp;= p (  y \\vert \\text{do}(I, c=1)  ) \\ &amp;= p (  y \\vert \\text{do}(I), c=1  ) \\end{aligned} $$</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#idk_1","title":"IDK","text":"<pre><code>flowchart TB\nx((x)) --&gt; C[C=1]\nL --&gt; C\nU((U)) --&gt; L((L))\nU ---&gt; y((y))\n\nx -.-&gt;|Cauality?| y</code></pre> <p>\\(C\\) is a collider on the path \\(x \\to C \\leftarrow L \\leftarrow U \\to y\\). Hence, the path is blocked without conditioning on \\(C\\) $$ p( y \\vert \\text{do}(x) ) \\ne  p( y \\vert x) $$ Conditioning \\(c=1\\) opens the path, making \\(A\\) and \\(y\\) associated without causal, leading sample selection bias in learning \\(p(y \\vert \\text{do}(A))\\) $$ p( y \\vert \\text{do}(x) ) \\ne  p( y \\vert  x) $$ Assume we observe</p> <ul> <li>\\(\\{ x, L \\}\\) for both \\(C = 0\\) and \\(C = 1\\)</li> <li>\\(y\\) only for \\(C = 1\\)</li> </ul> <p>Since conditioning on L blocks all back-door paths from \\(x \\to Y\\) and from \\(C \\to Y\\), we have $$ \\begin{aligned} &amp;p( y \\vert \\text{do}(x) ) \\ &amp;= p( y \\vert \\text{do}(x, c=1) ) \\ &amp;= \\int p( y \\vert x, L, c=1 ) \\cdot p(L) \\cdot dL \\end{aligned} $$ Hence, \\(p(y \\vert \\text{do}(x))\\) is non-parametrically identifiable and estimated</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#observational-studies-vs-rct","title":"Observational Studies vs RCT","text":"<p>RCT helps ensure that the links from \\(\\text{pa}(x)\\) to \\(x\\) are broken, so that \\(x \\coprod pa (x) \\implies p (\\text{pa} (x) |x = a) = p (\\text{pa} (x) |x = b)\\). The distribution of \\(\\text{pa}(x)\\) is balanced across the different values of treatment \\(x \\implies x\\) becomes exogenous, so there is no confounding to worry about</p> <p>Compared with observational studies, RCTs have less knowledge requirement: we do not need to know the treatment assignment mechanisms that generate the observational data, since we now determine the mechanism ourselves. In graph terms, only knowledge of the post-intervention causal diagram is needed</p> <p>A major limitation of RCTs, as already discussed, is that it is hard to generate data from a \\(p(y \\vert \\text{do}(x))\\) that is the result of a desired distribution of effect modifiers</p>"},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#idk_2","title":"IDK","text":""},{"location":"Economics/Causal_Inference/09_Causal_Effect_Learning/#fumigation-and-yield","title":"Fumigation and Yield","text":"<p>Suppose the mechanism that generates our observed data works as follows: fumigation (\\(X\\)) helps control eelworms (E), which affects crop yield (Y). Farmers\u2019 use of fumigation is affected by weather (W) and the price of fumigants (C). Weather also affects yield independently. Finally, we observe the equilibrium crop price (P), which is affected by both the price of fumigants and the realized crop yield</p> <pre><code>flowchart TB\nx((x)) --&gt; f((f)) &amp; y((y))\ny((y)) --&gt; p((p))\nc((c)) --&gt; f((f)) &amp; p((p))\nf((f)) --&gt; e((e))\ne((e)) --&gt; y((y))</code></pre> <p>Assuming \\(X\\) is binary and other variables are discrete $$ \\begin{aligned} &amp; P( y \\vert \\text{do}(X=1) ) \\ &amp;= \\sum_{w, c} p(y \\vert X=1, W=w, C=c) \\times p(W=w) \\times p(C=c) \\end{aligned} $$</p>"},{"location":"Economics/Causal_Inference/10_Econometrics/","title":"Econometrics","text":"<p>Seeks to link economic theory to data</p> <p>Intermediate between mathematics, statistics, and economics, we find a new discipline which for lack of a better name, may be called econometrics.</p> <p>Econometrics has as its aim to subject abstract laws of theoretical political economy or \u2019pure\u2019 economics to experimental and numerical verification, and thus to turn pure economics, as far as possible, into a science in the strict sense of the word.</p> <p>\u2026</p> <p>So far, we have been unable to find any better word than \"econometrics\". We are aware of the fact that in the beginning somebody might misinterpret this word to mean economic statistics only. But ... we believe that it will soon become clear to everybody that the society is interested in economic theory just as much as in anything else.</p> <p>~ Ragnar Frisch</p>"},{"location":"Economics/Causal_Inference/10_Econometrics/#causal-reasoning","title":"Causal Reasoning","text":"<p>The econometric approach to causal reasoning starts with assuming a \u201ctrue model\u201d $$ y = \\alpha_0 + \\alpha_1 x + u $$ where</p> <ul> <li>\\(x\\) is observed</li> <li>\\(u\\) is unobserved</li> <li>\\(\\alpha_1\\) represents the average   causal effect of \\(x\\) on \\(y\\)</li> </ul> <p>To estimate \\(\\beta\\), we run a linear regression $$ y = \\beta_0 + \\beta_1 x + e $$ \\(u\\) and \\(x\\) are uncorrelated \\(\\implies\\) back-door criterion is satisfied: \\(x\\) is exogenous and OLS estimation produces that \\(\\hat \\beta\\) that is a unbiased estimate of \\(\\beta\\). Else, \\(x\\) is endogenous and \\(\\beta\\) is biased estimate of \\(\\beta\\)</p> <p>\\(\\beta\\) is a statistical parameter; \\(\\alpha\\) is a causal parameter</p>"},{"location":"Economics/Causal_Inference/10_Econometrics/#limitations","title":"Limitations","text":""},{"location":"Economics/Causal_Inference/10_Econometrics/#statistical-vs-structural","title":"Statistical vs structural","text":"<p>The econometric approach does not clearly distinguish between causal reasoning and statistical modeling, ie what assumptions are causal and what are statistical - Just because does \\(x\\) and \\(y\\) are not statistically related, does not mean that \\(x\\) does not cause \\(y\\) - Most econometrics textbooks use one equation to represent both models, confusing what is causal and what is statistical.</p> <p>Econometric literature states: \u201cWhen the error term is correlated with the regressor, the estimation result is biased\u201d - By the \u201cerror term\u201d, it is referring to \\(u\\), not \\(e\\) - By \u201cestimation result is biased\u201d, it is saying that \\(E[\\hat \\beta] \\ne \\alpha\\)   - ie, \\(\\hat \\beta\\) is an unbiased estimate of statistical parameter \\(\\beta\\), but a biased estimate of the causal parameter \\(\\alpha\\)</p> <p>The requirement that \\(u\\) be (linearly) uncorrelated with \\(x\\) is often stated as an essential assumption on the linear regression model itself, under which the OLS estimator is unbiased \u2013 again confusing what is causal and what is statistical</p> <p>Failure to difference b/w statistical &amp; structural equations can lead to confusion.</p> <p>For eg, the following causal model with the causal effect of \\(x\\) on \\(y\\) is 0, ie no effect $$ \\begin{aligned} x &amp; \u223c U (0, 1) \\ y &amp; \u223c U (0, 1) \\ u &amp; \\leftarrow y\u2212x \\end{aligned} $$ However, the causal model implies the following statistical equation: \\(y = \\alpha x + u\\) , where \\(\\alpha = 1\\) and \\(u\\) is correlated with both \\(x\\) and \\(y\\)</p> <p>Failure to understand this as a statistical rather than structural equation will lead us to wrongly conclude that a regression of y on x will produce biased causal estimates \u2013 it won\u2019t. It will only produce a biased estimate of \\(\\alpha\\), but \\(\\alpha\\) is not the average causal effect of \\(x\\) on \\(y\\)</p>"},{"location":"Economics/Causal_Inference/10_Econometrics/#identification-estimation","title":"Identification &amp; Estimation","text":"<p>The econometric approach does not clearly distinguish between nonparametric and parametric identification, and between identification and estimation.</p> <p>Identification in the econometric approach refers to whether the parameters in a \u201ctrue model\u201d can be uniquely determined given infinite data on the observed variables. A \u201ctrue model\u201d, however, already makes parametric assumptions on the underlying causal structure.</p> <p>Therefore, while causal inference based on causal graphical models recognizes causal effect learning as a two-stage process \u2013 identification and estimation \u2013 and uses the back-door and front-door criteria to establish clear rules for nonparametric identification, the econometric approach fails to do so. This leads to confusion over how to apply statistical and machine learning models for causal inference.</p>"},{"location":"Economics/Causal_Inference/10_Econometrics/#control-variable-selection","title":"Control Variable Selection","text":"<p>The econometric approach does not provide an easily operational way of choosing control variables for identifying a desired causal effect.</p> <p>If \\(x\\) is endogenous, we can try to find control variables \\(z\\) such that: conditional on \\(z\\), \\(u\\) is no longer correlated with \\(x\\) in the following model $$ y = \\alpha_0 + \\alpha_1 x + \\alpha_2 z + u $$ Then, running a regression $$ y = \\beta_0 + \\beta_1 x + \\alpha_2 z + u $$ \\(\\hat \\beta\\) will be an unbiased estimate of \\(\\alpha\\)</p> <p>The requirement that \\(u\\) be (linearly) uncorrelated with \\(x\\) conditional on \\(z\\) can be thought of as implied by the back-door criterion. However, unlike the back-door criterion, the econometric approach to causal reasoning does not offer a clear guidance on the choice of \\(z\\), because it is not based on a clear thinking of the underlying causal mechanism (such as a causal diagram representation); clear thinking on causal mechanism forms part of the appeal of structural estimation over the reduced-form approach</p> <p>The statistics and econometrics literature often state that in order for causal effect to be identifiable by conditioning \u2013 there must be no unmeasured confounding (statistics) or selection on observables (econometrics). However, the back-door criterion shows that we do not need to observe and condition on all confounders, only a sufficient set of variables that renders all back-door paths blocked.</p> <p>There are now more than one \u201ctrue models\u201d, because for most problems, multiple sets of variables exist that can render all back-door paths blocked.</p> <ul> <li>The econometrics literature defines omitted variable bias as the bias that arises when a variable is omitted from the \u201ctrue model.\u201d But with more than one true model \u2013 with multiple sets of \\(z\\) that can sufficiently control for confounding \u2013 what is an omitted variable?</li> </ul> <p>Meaning of \u201ctrue model\u201d is now no longer clear. Once we include control variables \\(z\\), \u201ctrue model\u201d can no longer be interpreted as a structural equation in a causal model</p> <ul> <li>The back-door criterion makes it clear that z can include not only direct causes of \\(y\\), but also variables that are not causes of \\(y\\). Therefore, \u201ctrue model\u201d is no longer a structural equation specifying the relation between y and its determinants.</li> <li>The meaning of the equation itself has become unclear</li> <li>Unclear of its ability to offer meaningful guidance on the choice of \\(z\\)</li> <li>The back-door criterion also makes it clear that \\(z\\) should not include descendants of \\(x\\) and should not include colliders that may open a back-door path. The econometric approach offers none of these guidances</li> </ul>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/","title":"Causal Mechanism Learning","text":"<p>To understand the true meaning and scope of a causal effect, we need to understand the underlying causal mechanism, based on prior knowledge - information and analyses.</p> <p>This is important to understand</p> <ul> <li>causal effect - what it means, where it applies</li> <li>transportability of results</li> </ul> <p>Blindly following the causal effect, without understanding the underlying mechanism, is incorrect.</p> <p>The learning problem is to choose the causal model from a hypothesis set that best fits our observed data</p> <p>A causal structure is a set of conditional independence relations. Its identifiability depends on whether these relations can be uniquely determined by the set of conditional independence relations observed in the population.</p> <p>Causal relationships are more stable than causal effects and statistical relationships. That\u2019s why our knowledge about the physical world is largely encoded and transmitted in the qualitative language of causal relationships (\u201cpushing the glass off the table will cause it to break\u201d), rather than the quantitative language of causal effects and statistical relationships (\u201cpushing the glass off the table will result in a 95% probability of breakage.\u201d)</p>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#observationally-equivalent","title":"Observationally-equivalent","text":"<p>Causal structures that imply the same set of conditional independence relations: 2 DAGs are compatible with the same probability distribution $$ \\begin{aligned} &amp; A \\to B \\quad B \\to A \\ \\implies &amp; P(A, B)  \\ne P(A) \\cdot P(B) \\end{aligned} $$ In this case, they cannot be distinguished without resorting to manipulative experimentation or temporal information. Hence, experiments are required to identify observationally-equivalent causal structures</p>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#markov-equivalence","title":"Markov Equivalence","text":"<p>Two DAGs are observationally equivalent \\(\\iff\\) they have the same skeleton and the same set of immoralities, where</p> <ul> <li>skeleton: nodes of a directed graph</li> <li>immoralities: configuration of 3 nodes: A,B,C, such that</li> <li>C is a child of both A and B</li> <li>A and B not directly connected</li> <li>It\u2019s called immorality because C is a child of A and B, but they\u2019re not \u2018married\u2019</li> </ul>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#scientific-progress","title":"Scientific Progress","text":"<p>We (human beings) have been learning causal mechanisms by formulating models, then conducting experiments or observational studies, and based on the results of which, updating our belief about each model\u2019s probability of being true. This, in essence, is the process of scientific progress</p> <p>This view of scientific progress as continuous Bayesian updating based on evidence has been challenged by historians like Thomas Kuhn, who pointed out that the sociological nature of the scientific community leads to periodic paradigm shifts rather than continuous progress</p>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#structural-estimation","title":"Structural Estimation","text":"<p>Causal models based on theory are referred to as structural models. Their estimation is called structural estimation/\u201cidentification by functional form\u201d</p> <p>Structural estimation \\(\\ne\\) causal mechanism learning. Structural estimation is learning based on an assumed causal mechanism</p> <p>A complete structural model may specify preferences, technology, the information available to agents, the constraints under which they operate, and the rules of interaction among agents in market and social settings</p> <p>Structural models, by explicitly modeling the data-generating causal mechanisms, make clear what prior knowledge (assumptions) are relied upon to draw causal inference.</p> <p>By using theory to specify the functional forms of causal relationships, structural models can be used to</p> <ul> <li>identify causal effects or the values of unobserved variables that cannot be non-parametrically identified</li> <li>serve as a model selection mechanism for causal effects that can be identified non-parametrically</li> </ul> <p>Using structural models, what we learn from one set of data  \\(D \\sim p(x,y)\\) can be potentially used to explain and predict data drawn from another distribution, say \\(p(u,v)\\), if \\(\\{ x,y \\}\\) and \\(\\{ u, v \\}\\) are generated from a similar causal mechanism.</p> <ul> <li>In other words, what we learn from one observed phenomenon can be used to explain and predict other related phenomena.</li> <li>For example, we can learn individuals\u2019 risk aversion from their investment behavior, which can help explain &amp; predict their career choices.</li> </ul> <p>Structural models make it possible to predict effects of existing treatments in a new population/environment, or the effects of completely new treatments.</p> <ul> <li>To do so, a structural model must be \u201cdeep\u201d enough so that its parameters remain invariant in the new population/environment, or when new treatments are applied.</li> <li>The concept of invariance is closely related to the concept of stability for causal relationships. The need for invariant parameters is key to causal analysis and policy evaluation.</li> </ul> <p>Once we have learned a structural model, we can use it to generate synthetic data and perform counterfactual simulations.</p> <p>Structural models allow the economist to make welfare calculations and normative statements; Individual choices reveal information about their preferences and the potential outcomes they face</p> <p>Structural models can potentially deliver better predictive performance than statistical models trained on single data sets, because their parameters can be learned from a combination of data from various sources that share the same underlying causal mechanism</p>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#counterfactual-simulation","title":"Counterfactual Simulation","text":"<p>One of the main benefits of learning a structural model is that it allows us to predict the effect of a completely new treatment \u2013 a treatment that has never been observed before</p> <p>For eg: If in the observed data, \\(x_j =0\\) always, what would be the effect of \\(\\text{do} (x_j = 1)\\)?</p> <p>Because structural models are generative models, once we have learned a model, we can use it to generate synthetic data</p> <p>\\(D= \\{(x_{i, 1}, \\dots, x_{i,j} = a, x_{i,j+1}, x_{i,n}) \\}\\) from \\(p(x_1, \\dots, x_n|\\text{do}(x_j= a))\\)</p>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#dynamic-structural-model","title":"Dynamic Structural Model","text":"<p>In a changing environment, with new information arriving each period, individual are forward-looking when making decisions: choices are made partly based on expectations of the future.</p> <p>Decisions are also often influenced by the past. Since it can be costly to transition from one state to another, payoffs to different choices are often history-dependent: our past partly shapes our future.</p> <p>In dynamic models, treatment effects can be time-varying and it\u2019s often useful to distinguish between short-run and long-run effects</p>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#negative-political-advertising","title":"Negative Political Advertising","text":"<ul> <li>Candidate decides whether to go negative based on polling</li> <li>Going negative affects future polling, which in turn, affects future   negative advertising decisions.</li> <li>Outcome: final vote share.</li> </ul> <p>Static (single-shot) causal inference</p> <p></p> <p>Dynamic</p> <p></p>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#idk","title":"IDK","text":"\\[ L_t = \\beta_0 + \\beta_1 i_t \\] <p>where</p> <ul> <li>\\(L_t=\\) Leverage taken up by financial firms</li> <li>\\(i_t=\\) Interest rate set by central bank</li> </ul> <p>Problem</p> <ul> <li>\\(L_t\\) is forward-looking: Banks take up loans based on future expectations; nobody makes a decision-based on last year\u2019s interest rate only</li> <li>The effect is smooth &amp; gradual over time, not sudden</li> </ul>"},{"location":"Economics/Causal_Inference/11_Causal_Mechanism_Learning/#crop-supply","title":"Crop Supply","text":"<ul> <li>At the beginning of each period t, each field owner decides whether or not to plant the crop in the current period</li> <li>The decision is based on observed period\u2212t price as well as expectations of future prices.</li> <li>If a field has not been cultivated for k periods, then in order to (re)-cultivate it, the farmer needs to pay a one time cost c (k).</li> <li>Farmers have rational expectation: their expectations of future prices are unbiased conditional on the information they have.</li> <li>Here we assume that crop prices follow an AR(1) process, which is known to the farmers.</li> </ul> <p>Counter-factual simulation</p> <ul> <li>How would crop supply change in response to changes in crop prices   if farmers are myoptic: if they are not forward-looking?</li> <li>How would crop supply change in response to changes in crop prices if farmers are static: if they are neither forward-looking, nor subject to any re-cultivation costs, so that planting decisions are made entirely based on current prices?</li> </ul> <p></p> <p>In general, if we are interested in the effect of x on y, but x is self-selected based on expectations of y, then without any measures of such expectations, the causal effect cannot be non-parametrically identified and we need to rely on theory to specify how expectations are formed.</p> <ul> <li>Sub-population: little/no equilibrium at play</li> <li>Here, farmers take crop prices as given and decide whether or not to plant. Models like this are called dynamic discrete choice models</li> <li>Population: equilibrium at play</li> <li>If prices are endogenous \u2013 if farmers\u2019 planting decisions affect equilibrium prices \u2013 then we need to model both crop supply and crop demand. Such models are called dynamic general equilibrium models.</li> </ul>"},{"location":"Economics/Causal_Inference/12_Game_Theory/","title":"Game Theory","text":""},{"location":"Economics/Causal_Inference/12_Game_Theory/#auction","title":"Auction","text":"<p>Consider \\(n\\) risk-neutral bidders, with independent private value \\(v_i ~ F\\)</p> <p>Each bidder knows their own \\(v_i\\) and distribution \\(F\\), but not the \\(v_i\\) of others</p> <p>Observed winning bids are the Bayesian Nash equilibrium outcome of each game $$ \\begin{aligned} b_i &amp;= v_i - \\dfrac{1}{F(v_i)^{n-1}} \\int \\limits_0^{v_i} F(x)^{n-1} \\cdot dx \\ &amp;= v_i - \\dfrac{1}{n-1} \\dfrac{G_n(b_i)}{g_n(b_i)} \\end{aligned} $$ where</p> <ul> <li>\\(b_i\\) is the bid amount</li> <li>\\(g_n\\) is pdf of bid distribution</li> <li>\\(G_n\\) is cdf of bid distribution</li> </ul> <p>There is no confounding between \\(N\\) (the number of bidders) and \\(b_\\max\\) (the winning bid). Hence \\(f (N) \u2261 E [b_\\max|N]\\)non-parametrically identifies the effect of N on \\(b_\\max\\)</p> <p>The estimation problem is to learn \\(f (N)\\) from data. Here, theory helps specify the functional form of \\(f (N)\\) and therefore serves as a model selection mechanism</p> <p>Theory also helps us to learn the values of the bidders \u2013 which cannot be identified nonparametrically \u2013 by specifying the functional form of the mapping from \\(\\{ v_i \\}\\) to \\(\\{ b_i \\}\\)</p> <p>Furthermore, structural modelling will allows us to obtain other things as well such as: 2<sup>nd</sup>-highest bid, etc</p>"},{"location":"Economics/Causal_Inference/12_Game_Theory/#structural-estimation","title":"Structural Estimation","text":"<ol> <li>For each auction, non-parametrically estimate \\(g_n\\) and \\(G_n\\) from observed bids \\(b_1, \\dots, b_n\\)</li> <li>For each bidder, calculate</li> </ol> \\[ \\hat v_i = b_i + \\dfrac{1}{n-1} \\dfrac{\\hat G_n(b_i)}{\\hat g_n(b_i)} \\] <ol> <li>Estimate \\(\\hat F\\) using \\(\\hat v_i\\)</li> <li>Predict winning bid</li> </ol> \\[ \\begin{aligned} &amp;E[\\max \\{ b_i \\}] \\\\ &amp;= E \\Bigg[ \\max \\Big\\{ v_i - \\dfrac{1}{\\hat F(v_i)^{n-1}} \\int\\limits_0^{v_i} \\hat F(x^{n-1}) \\cdot dx \\Big\\} \\Bigg] \\end{aligned} \\]"},{"location":"Economics/Causal_Inference/12_Game_Theory/#monopoly","title":"Monopoly","text":"<p>In each market \\(m\\) with population \\(N_m\\) and mean income \\(I_m\\), consumers choose between monopoly product and an outside good. Individual utilities are given by:</p> <p>For each market \\(m\\), given demand \\(q_m(p)\\), the monopoly firm chooses \\(p\\) that maximizes its revenue $$ \\begin{aligned} u_{i0}^m &amp;= \\epsilon_{i0}^m \\ u_{i1}^m &amp;= \\beta_0 + \\beta_1 I_m - \\beta_2 p_m + \\epsilon_{i1}^m \\ \\pi_m &amp;= \\sigma(\\beta_0 + \\beta_1 I_m - \\beta_2 p_m) \\ &amp;=\\dfrac{1}{1 + \\dfrac{1}{\\exp(\\beta_0 + \\beta_1 I_m - \\beta_2 p_m)}} \\ p &amp;= \\max_p { p \\times q_m(p) - c(q_m(p)) } \\ c' (q_m) &amp;= p_m + [q'_m (p_m)]^{-1} q_m \\end{aligned} $$ where</p> <ul> <li>\\((u_{i0}^m, u_{i1}^m)\\) are indirect utilities of outside good and monopoly product resp</li> <li>\\(\\epsilon_{ij}^m \\sim \\text{Gumbel}(0, 1)\\)</li> <li>\\(q_m \\sim \\text{Binomial}(N_m, \\pi_m)\\)</li> <li>\\(c(q)\\) is the monopoly firm\u2019s cost function</li> </ul> <p>Estimated marginal cost and demand curves for a market with median income and population</p> <p></p> <p>Here, theory helps us to learn the marginal cost function of the monopoly firm as well as the consumer utility function \u2013 neither of which is observed and neither can be nonparametrically identified.</p> <p>Using the estimation results, we can conduct welfare analysis and make normative statements: For example, calculating the total deadweight loss due to monopoly</p>"},{"location":"Economics/Causal_Inference/13_Causal_Effect_Estimation_under_Unconfoundness/","title":"Causal Effect Estimation under Unconfoundedness","text":"<p>Causal effect estimation under sufficient control for confounding is called causal effect estimation under unconfoundedness.</p> <p>When there are open back-door paths from w to y, according to the back-door criterion, if we observe a set of pre-treatment variables \\(x\\) such that conditioning on \\(z\\) blocks these paths, then \\(E[y| \\text{do}(z)]\\) is non-parametrically identifiable</p>"},{"location":"Economics/Causal_Inference/13_Causal_Effect_Estimation_under_Unconfoundness/#disjunctive-cause-criterion","title":"Disjunctive Cause Criterion","text":"<p>Method to select what variables to control for confounding among the observed variables</p> <p>Control for all (observed) direct causes of \\(x\\) and \\(y\\)</p> <p>If there is possible elimination of back-door path, then DCC will guaranteed to enforce it: Let \\(V\\) be the set of variables selected based on the disjunctive cause criterion. If \\(\\exists\\) set of observed vars \\(z\\) that satisfy the back-door criterion, then \\(z \\subset V\\)</p> <p>Advantage: Analyst only needs to know the causes \\(x\\) and \\(y\\), without requiring understanding of interactions of other variables</p> <p>Disadvantage: Conditioning on a var may open up unobserved back-door path, but there is nothing else can be done</p>"},{"location":"Economics/Causal_Inference/13_Causal_Effect_Estimation_under_Unconfoundness/#monte-carlo-integration","title":"Monte-Carlo Integration","text":"<p>Assume we observe a set of vars that satisfy the back-door criterion $$ \\begin{aligned} &amp;E [y \\vert \\text{do}(x=a)] \\ &amp;= \\int E[y \\vert x = a, z] \\cdot p(z) \\cdot dz \\ &amp;= \\dfrac{1}{n} \\sum_i^n E[y_i \\vert x_i = a, z_i] \\ &amp;\\text{ATE}(x) \\ &amp;= \\dfrac{d E [ y \\vert \\text{do}(x) ] }{ dx } \\ &amp;= E [ y \\vert \\text{do}(x=1) ] - E [ y \\vert \\text{do}(x=0) ] \\ &amp; \\qquad (x \\text{ is binary}) \\ &amp;= E [ y \\vert x=1, z ] - E [ y \\vert x=0, z ] \\end{aligned} $$ \\(E[ y \\vert x, z]\\) can be estimated using machine learning model</p> <p>In linear regression $$ \\hat y = \\beta_0 + \\beta_1 x + \\beta_2 z \\ \\text{ATE} = \\beta_1 $$ Treatment effects can be</p> <ul> <li>Homogenous: same for all units</li> <li>Heterogenous: different for all units</li> </ul> <p></p> <p>Alternatively, you can estimate in the following manner $$ \\begin{aligned} \\hat y &amp;= \\begin{cases} \\hat y_1 = f_1(z), &amp; x=1 \\ \\hat y_0 = f_0(z), &amp; x=0 \\end{cases} \\ \\text{ATE} &amp;= \\hat y_1 - \\hat y_0 \\end{aligned} $$ Where \\(f_1\\) and \\(f_0\\) are completely different models</p> <p></p>"},{"location":"Economics/Causal_Inference/13_Causal_Effect_Estimation_under_Unconfoundness/#matching","title":"Matching","text":"<p>Matching is another method for controlling confounders. The goal of matching is to construct a new sample in which the confounding variables have the same distribution conditional on each value of the treatment variable.</p> <p>In randomized trials, covariate balance \u2013 the balance of \\(w\\) across values of \\(x\\) \u2013 is achieved at the design phase.</p> <p>Matching is a method that attempts to achieve covariate balance in observational studies, thereby making them resemble randomized trials.</p>"},{"location":"Economics/Causal_Inference/14_Program_Evaluation/","title":"Program Evaluation","text":"<p>Measuring the effect of a treatment - Data Science - Causal Inference</p>"},{"location":"Economics/Causal_Inference/14_Program_Evaluation/#elements-of-program","title":"Elements of Program","text":"<pre><code>flowchart LR\nInputs --&gt;\nActivities --&gt;\nOutputs --&gt;\nOutcomes</code></pre> Element Meaning Controllable Measurable Inputs Things that go into an activity \u2705 \u2705 MoneyPeopleTime Activities(Causes) Actions that convert inputs to outputsThings that the program does \u2705 \u2705 Output Tangible goods &amp; services produced by activitiesYou have control over these \u2705 \u2705 Outcome(Effects) What happens when the target population uses the outputs \u274c \u274c"},{"location":"Economics/Causal_Inference/14_Program_Evaluation/#program-theory","title":"Program Theory","text":"<ul> <li>How and why an intervention causes change</li> <li>Theory for the sequence of events that connects inputs to activities to outputs to outcomes</li> </ul>"},{"location":"Economics/Causal_Inference/14_Program_Evaluation/#steps","title":"Steps","text":"Results Chain Impact Theory How activities link to outcomes Logic Model"},{"location":"Economics/Causal_Inference/14_Program_Evaluation/#types-of-program-evaluation","title":"Types of Program Evaluation","text":"What When How Formative Evaluation/Needs Evaluation Is the program needed?What inputs &amp; activities does it need?What outcomes does it need to cause? Before InterviewsSurveys Economic evaluation/Cost-Benefit Analysis Is the program worth it?Do the benefits of helping the target population outweigh the costs of running the program? Before Net Present Value Process evaluation/Program monitoring Are inputs going to the right places?Are activities working correctly?Are activities producing right levels of outputs? During KPI Dashboards Outcome Evaluation Are activities and outputs leading to initial outcomes(short-term impact evaluation) During Causal inferenceSurveysInterviews Impact Evaluation Does the program cause lasting change in the outcome After Causal inference"},{"location":"Economics/Causal_Inference/14_Program_Evaluation/#types-of-impact-evaluation","title":"Types of Impact Evaluation","text":"Types Validity Requires structural model Example Evaluating the impacts of historical programs on outcomes in the same population/environment Internal \u26a0\ufe0f Policy in same country Forecasting the impacts of programs implemented in one population/environment in other populations/environments External \u2705 Policy in another country Forecasting the impacts of programs never historically experienced. External \u2705 Effect of tax <p>For all three types of problems, if we want to evaluate welfare impact, we need a structural model.</p>"},{"location":"Economics/Causal_Inference/14_Program_Evaluation/#ethics","title":"Ethics","text":"<ul> <li>In order to evaluate programs, control groups are essential<ul> <li>Dilemma: People who could benefit from the program would not be assigned to it</li> <li>\"Groups should not be excluded from an intervention that is known to be beneficial, solely for the purpose of evaluation\" ~ World Bank Impact Evaluation in Practice</li> </ul> </li> <li>Follow IRB (Institutional Review Board) guidelines<ul> <li>Respect for people: Make sure participants give informed consent</li> <li>Beneficence: Don't lie<ul> <li>Minimize potential harm</li> <li>Maximize potential benefit</li> </ul> </li> <li>Justice: Benefits &amp; burdens of research are equitably-shared by different groups</li> </ul> </li> <li>Maintain privacy: Any published data should be de-identified</li> </ul>"},{"location":"Economics/Development_Economics/","title":"Development Economics","text":""},{"location":"Economics/Development_Economics/#overview","title":"Overview","text":"<ol> <li>Why are some countries so poor and some so rich</li> <li>What are the particular economic problems faced by countries that are poor, and how do we model and understand these phenomena</li> <li>What could be done to help solve market failures in poor countries</li> <li>What went right</li> <li>What risk going wrong? Is the COVID-19 crisis reversal here to stay</li> <li>Poverty traps</li> <li>Human capital</li> <li>Source</li> <li>Heterogeneity</li> <li> <p>Why people are not investing optimally in</p> <ol> <li>Education</li> <li>Health</li> <li>Nutrition</li> </ol> </li> <li> <p>Capital</p> </li> <li>Heterogeneity</li> <li>Credit &amp; savings</li> <li> <p>Land</p> </li> <li> <p>Labor markets: Allocation of labor</p> </li> <li>Productivity<ol> <li>Technology</li> <li>Organization of firms</li> </ol> </li> </ol>"},{"location":"Economics/Development_Economics/#references","title":"References","text":"<ul> <li> Development Economics | MIT</li> <li> Development Macroeconomics | MIT</li> <li> The Challenge of World Poverty | MIT</li> <li> IIT Roorkee | Health Economics</li> <li> The Economy: A South Asian Perspective | The CORE Econ Team</li> </ul>"},{"location":"Economics/Development_Economics/01_Introduction/","title":"Introduction","text":""},{"location":"Economics/Development_Economics/01_Introduction/#steady-state-ramsey-model","title":"Steady State (Ramsey Model)","text":"\\[ A \\frac{\\partial f}{\\partial k} = \\rho \\] <p>where </p> <ul> <li>LHS = Return on capital</li> <li>\\(\\rho\\) = discount state</li> </ul> <p>Otherwise, people would save more</p>"},{"location":"Economics/Development_Economics/01_Introduction/#aggregate-production-function","title":"Aggregate Production Function","text":"\\[ y = A \\times f(k, h) \\] <p>where</p> <ul> <li>\\(y\\) is output (real GDP)</li> <li>\\(A\\) is measure of productivity of economy</li> <li></li> <li>\\(k\\) is capital per-capita</li> <li>\\(h\\) is human capital per-capita (skills, knowledge, etc)</li> </ul> <p>For most of history, Development Economics was mostly macro-oriented: focusing on aggregate income difference</p> <p>If the most of per-capita income difference \\(y\\) was mostly \\(k\\), just give the developing countries more \\(k\\), and likewise for \\(h\\).</p> <p>But just giving \\(k\\) would reduce the saving in the country due to Steady State (Ramsey Model), as \\(k\\) responds to A in equilibrium. If you increase \\(k\\) beyond steady state level, returns will be low, and the economy will adjust endogenously and move back to its previous point in time.</p> <p>Variation in policies lead to variation in the growth rate in A.</p>"},{"location":"Economics/Development_Economics/01_Introduction/#assumption-of-this-model","title":"Assumption of this model","text":"<p>Aggregation works as we are assuming that capital and human capital are optimally distributed by the economy, so the marginal return of investment is equalized.</p> <p>However, in reality, this is not true: some sectors of the economy within the same location may have different return to capital, as \\(h\\) and \\(k\\) are not allocated optimally. For eg, even though it would be more effective to invest into a highly-qualified stranger, we would prefer to invest in an average known-person. This ties back to Behavioral Economics.</p>"},{"location":"Economics/Development_Economics/01_Introduction/#income","title":"Income","text":"<p>Income and development are not always related.</p> <p>Countries with higher GDP may have worse infant mortality.</p>"},{"location":"Economics/Development_Economics/01_Introduction/#imf-stimulus","title":"IMF Stimulus","text":"<p>The emergency \u201cspecial drawing rights\u201d is allocated based on the country\u2019s contribution to the IMF. Thereby, the rich countries get money easily compared to poor countries.</p>"},{"location":"Economics/Development_Economics/01_Introduction/#poverty","title":"Poverty","text":""},{"location":"Economics/Development_Economics/01_Introduction/#poverty-rate","title":"Poverty Rate","text":"<p>How many people can a baseline basket of goods</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/","title":"Poverty Traps","text":"<p>Does being poor keep you poor?</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#the-s-curve","title":"The S-curve","text":"<p>This clearly shows that where you start affects where you end.</p> \\[ \\text{Economic Status}_\\text{present} = \\beta_0 + \\beta_1 \\text{Economic Status}_\\text{past} \\] <p>So, the poorest of the poorest need enough direct income transfers to push them up, else they will go back to their past state.</p> <p>The mistake in some models is that they assume upward concave curve rather than the S-curve, thereby missing the existence of the Poverty Trap.</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#capacity-curve","title":"Capacity Curve","text":"<p>Relationship between work capacity and income.</p> <p>Piece-rate, or piecemeal pay, means that employees are paid by the unit when completing a particular task, for instance, bushels harvested, trees pruned, or acres mowed. In this case, a worker is compensated by individual output and not by an hourly rate</p> <p></p> <p>Higher the income, more food calories. The first few calories are required as a minimum to function actively; however, after a certain point, there is decreased return.</p> <p>\\(v^*\\) represents the smallest possible wage at which people meaningful work. It is not an economy-wide parameter, but an individual parameter depending on the amount of non-labor income (I suppose passive income?)</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#aggregate-labor-supply","title":"Aggregate Labor Supply","text":"<p>Involuntary unemployment occurs when the economics forces maintain equilibrium due to balancing labor demand and labor supply.</p> <p></p> <p></p> <p></p> <p>The capacity curve changes whether or not the person had food the previous day. So, we can conclude that being today\u2019s employment helps in continued employment tomorrow.</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#distribution-of-land","title":"Distribution of Land","text":""},{"location":"Economics/Development_Economics/02_Poverty_Traps/#effective-reservation-wage","title":"Effective Reservation Wage","text":"<p>The thick curve is the effective reservation wage, as you need to be</p> <ul> <li>willing to work</li> <li>able to work</li> </ul>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#equilibria","title":"Equilibria","text":"<p>When the wage is very low, very few people can work</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#policies","title":"Policies","text":"Land reform - May improve production and employment- Can improve production without reducing involuntary unemployment Loans to poor This does not happen, as the poor will first focus on getting basic needs rather than investing in increasing their wealth sufficient to repay, and hence will default on their loans Minimum wage Direct income transfer - The poorest people get empowered by getting cash- Others would get lazy Investment in the poor As nutrition plays a big role in working productivity, employers of long-term contracts tend to invest in their workers. But this does not happen for short-term contracts.Due to this reasoning, slaves were better fed than poor workers. <p>An economy is Pareto efficient. Hence, it is not possible to improve the welfare of someone without decreasing the welfare of someone else.</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#intra-family-resource-allocation","title":"Intra-Family Resource Allocation","text":"<p>In a poor family, the most efficient way is to invest more resources into the person who is employed so that they can thereby bring in more income, rather than equally. Unfortunately, this may lead to malnourishment of the other person. Sometimes, this may be the only way possible for poor families.</p> <p>In most cases, this is how it goes</p> <pre><code>flowchart TB\n\nFather --&gt;\n|Remaining resources| Children --&gt;\n|Remaining resources| Mother --&gt;\n|Remaining resources| Elderly</code></pre>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#poverty-traps-characteristics","title":"Poverty Traps Characteristics","text":"<p>Strong relationships</p> \\[ \\begin{aligned} \\text{Income}_{t+1} &amp;\\propto \\text{Nutrition}_t \\\\ \\text{Productivity}_{t+1} &amp;\\propto \\text{Nutrition}_t \\end{aligned} \\] <p></p> \\[ y_{t+1} = (f \\circ g)(y_t) \\] <p>where</p> <ul> <li>\\(f =\\) Capacity Curve</li> <li>\\(g =\\) Decision to consume curve</li> </ul> <p>Multiple equilibrium points exist when the curve intersects the 45deg line at multiple points</p> <p>Intersection happens where slope = slope of 45deg line = \\(\\tan 45\\) = 1</p> <p>When \\(y_{t+1} = y_t\\), the convolution \\((f \\circ g)\\) has a slope &gt; 1. This happens when the product of the elasticity of \\(f\\) and \\(g\\) curve &gt; 1</p> <p>In some cases, food is affordable, so \\(g\\) won\u2019t be steep.</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#nutrition-based-poverty-trap","title":"Nutrition-based Poverty Trap","text":"<ul> <li>Not much basis for Nutrition-based Poverty Trap, as food is relatively cheap</li> <li>When people become richer, they tend to spend more on food</li> <li>Half of the increase into better food</li> <li>Half of the increase into more calories</li> <li>Clear relationship between per capita expenditure vs calorie consumption</li> <li>Relationship does not appear to be non-linear, at least in this range, despite the fact it is probably an over-estimate due to reverse-causality</li> <li>Strong log-linear relationship between price of calories and expenditures, indicating a lot of substitution towards more expensive calories</li> <li>Duration of study affects people behavior</li> <li>When subsidies are provided for short-period, people focus on eating \u201cbetter\u201d food than to improve nutritional status</li> <li>if this was a long-term, then the behavior may have been different</li> </ul>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#india","title":"India","text":"<p>As you can see, as people get richer, they eat more expensive calories. This means that they don\u2019t feel the pain of poverty trap, as they would rather than get more calories rather than expensive calories, with the same budget.</p> <p></p> <p></p> <p></p> <p>Even though the number of extremely poor people has gone down in India, the per capita consumption has not increased, as the Calorie Engel curve has moved rightward.</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#china","title":"China","text":"<p>Subsidize staple food in 2 regions fro randomly selected household</p> <p>In both regions, substitution towards more expensive calories</p> <p>Elasticity of calorie consumption with income is low</p>"},{"location":"Economics/Development_Economics/02_Poverty_Traps/#graduation-programs","title":"Graduation Programs","text":""},{"location":"Economics/Econometrics/","title":"Econometric Methods","text":""},{"location":"Economics/Econometrics/#structure-of-this-course","title":"Structure of this course","text":"<ol> <li>What kinds of data</li> <li>Techniques</li> <li>Inference    Explanation of results, by building a story</li> </ol>"},{"location":"Economics/Econometrics/#application-of-this-course","title":"Application of this course","text":"<ul> <li>Quantification of relationships</li> <li>Address questions like<ul> <li>Change in revenue when price changes</li> <li>Change in productivity of employee when wage rate is changed</li> <li>How does another year of education change earnings</li> </ul> </li> </ul>"},{"location":"Economics/Econometrics/#references","title":"References","text":"<ul> <li> Econometric Methods | Dr. Sartaj Rasool Rather</li> <li> Forecasting Principles &amp; Practice</li> <li> Website</li> <li> Course</li> <li> Slides</li> <li> MIT 18.S096 Topics in Mathematics w Applications in Finance</li> <li> Graduate Econometrics | Ben Lambert | Oxford</li> <li> Applied Methods for Computational Finance | LMU</li> <li> Computational Finance<ul> <li> Computational Finance</li> <li> Computational Finance Q&amp;A</li> </ul> </li> <li> Financial Engineering</li> <li> Business Analytics Using Forecasting | Galit Shmueli</li> <li> Introduction to Econometrics - 2021 | Pedram Jahangiry</li> <li> Forecasting | Michael Sinkey</li> <li> MIT 6.262 Discrete Stochastic Processes, Spring 2011</li> <li> MIT 15.S50 Poker Theory and Analysis: Applications of poker analytics to investment management and trading</li> <li> NPTEL-NOC IITM | Introduction to Econometrics</li> <li> IIT Roorkee July 2018 | Econometric Modelling</li> <li> NPTEL-NOC IITM | Applied Econometrics</li> <li> IIT KANPUR-NPTEL | Applied Statistics and Econometrics</li> <li> Monte Carlo Simulations</li> <li> Monte Carlo methods &amp; simulations | Jan Dufek | KTH Royal Institute of Technology</li> <li> Monte Carlo Methods | UCLA</li> <li> Monte Carlo Simulation in Python</li> <li> Lancaster CMAF</li> <li> Business Forecasting Principles</li> <li> Forecasting Lectures</li> <li> AcademicEgg</li> <li> Econometrics 1</li> <li> Econometrics 2</li> <li> Econometrics | MetricsProf</li> <li> Why Zillow's Models Failed | Dimitri Bianco</li> <li> Time Series Analysis | Aileen Nielsen<ul> <li> Part 1 | Scipy 2016</li> <li> Part 2 | PyData 2016</li> <li> Part 3 | PyCon 2017</li> <li> Part 4 | SciPy 2019</li> </ul> </li> <li> Deep Forecasting concepts | Pedram Jahangiry</li> <li> Time Series Analysis | Chris Bilder</li> <li> Time Series | Dimitri Bianco</li> <li> Time Series | Aric LaBarr</li> <li> Time Series | Chris Bilder</li> <li> Time Series Analysis | Cache Lack Math &amp; Stats Lectures</li> <li> Demand Forecasting | MaxusKnowledge</li> <li> Quantopian Lecture Series</li> <li> Financial Feature Engineering | PredictNow AI</li> <li> Advanced Quantitative Economics | Lazarski Open Courses</li> <li> Dynamic Economic Analysis | Lazarski Open Courses</li> <li> Intermediate Econometrics | Timo Kuosmanen</li> <li> Introduction to Econometrics | Lazarski Open Courses<ul> <li> Practical</li> <li> Theoretical</li> </ul> </li> <li> Introduction to Economic Analysis | Lazarski Open Courses</li> <li> Applied Econometric Analysis in Fisheries and Environmental Science | University of Washington</li> <li> Forecasting for Supply Chain Planning | Nicolas Vandeput</li> <li> Supply Chain Lectures | Lokad</li> </ul>"},{"location":"Economics/Econometrics/01_Intro/","title":"01 Intro","text":""},{"location":"Economics/Econometrics/01_Intro/#what-is-econometrics","title":"What is Econometrics?","text":"<p>How do we test economic theories are true using real-world data, using statistics.</p>"},{"location":"Economics/Econometrics/01_Intro/#types-of-data","title":"Types of Data","text":"Experimental Real-World Controlled Environments \u2705 \u274c"},{"location":"Economics/Econometrics/01_Intro/#why-econometrics","title":"Why Econometrics?","text":"Statistics Econometrics Analyze experimental data Real world data"},{"location":"Economics/Econometrics/01_Intro/#type-of-relationships","title":"Type of Relationships","text":"<ul> <li>One-way</li> <li>Simultaneous</li> </ul>"},{"location":"Economics/Econometrics/01_Intro/#problems","title":"Problems","text":""},{"location":"Economics/Econometrics/01_Intro/#noise","title":"Noise","text":"<p>Randomness due to nature of the real world.</p>"},{"location":"Economics/Econometrics/01_Intro/#heteroskedasticity","title":"Heteroskedasticity","text":"<p>Variance in distribution of possible outcomes will change over different time, location, settings.</p> <p>This is the biggest problem when using observational data, rather than experimental data.</p>"},{"location":"Economics/Econometrics/01_Intro/#auto-correlation","title":"Auto-Correlation","text":"<p>Tendency of a variable to be determined by its own past values.</p> <p>Mostly happens in time-series.</p>"},{"location":"Economics/Econometrics/01_Intro/#overnightcall-money-market","title":"Overnight/Call Money Market","text":"<p>Short-term lending from central bank to commercial banks.</p> <p>These interest rates are called call money rate. It will be different from the regular loans, and will change regularly.</p> <p>An interbank call money market is a short-term money market which allows for large financial institutions to borrow and lend money at interbank rates. The loans in the call money market are very short, usually lasting no longer than a week.</p>"},{"location":"Economics/Econometrics/01_Intro/#random-variable","title":"Random Variable","text":"<p>Numerical outcome of a random event</p> <p>There are multiple outcomes possible, and there exists an underlying probability distribution. Hence, for each possible outcome, there exists a corresponding probability.</p> <p>2 random variables cannot perfectly correlated; otherwise it has some cause.</p>"},{"location":"Economics/Econometrics/01_Intro/#systematic-event","title":"Systematic Event","text":"<p>only one outcome is possible</p> <p>\\(P(A)=1; P(A')=0\\)</p> <p>numerical outcome of a systematic event is systematic variable</p>"},{"location":"Economics/Econometrics/01_Intro/#africa-case-study","title":"Africa Case Study","text":"<p>People were dying due to malaria and dengue, as they were not having access proper shelter from the mosquitos.</p> <p>The first idea was to increase their income, by proving them direct income transfer, because they would use that money to take care of themselves.</p> <p>2 researchers at MIT studied these African Countries. These 2 researchers disagreed.</p> <p>There were 2 communities</p> <ul> <li>One community was given direct income transfers</li> <li>One community was given nets</li> </ul> <p>Giving nets was more effective, as the other community spent the money for other aspects such as food, baby requirements, purchasing books; they considered nets as a luxury.</p>"},{"location":"Economics/Econometrics/02_Methodology/","title":"02 Methodology","text":""},{"location":"Economics/Econometrics/02_Methodology/#methodology-for-measuring-relationships","title":"Methodology for measuring relationships","text":"<pre><code>flowchart LR\net[Hypothesis] --&gt;\nmm --&gt;\nem --&gt;\ndc[(Data&lt;br/&gt;Collection)] --&gt;\nEstimation --&gt;\nht[Hypothesis&lt;br/&gt;Testing] --&gt;\nForecasting --&gt;\np[Policy to&lt;br/&gt;affect behavior]\n\nsubgraph Model\n    mm[Mathematical]\n    em[Economic]\nend</code></pre>"},{"location":"Economics/Econometrics/02_Methodology/#theorylogic","title":"Theory/Logic","text":""},{"location":"Economics/Econometrics/02_Methodology/#hyphothesis","title":"Hyphothesis","text":"<p>Theoretical assertion whose truth can be tested</p> <p>Logical reasoning on how variables would be related, ie what could be the factors</p> <p>This is also called as specification of relationship. We need to make appropriate specification.</p> <p>An increase in \\(x\\) will cause an increase in \\(y\\)</p> <ul> <li>Null Hypthosis</li> <li>Alternate Hypthosis</li> </ul> <p>Problem with social sciences (business, economics, etc) is that there may be number of factors, but it is not feasible to incorporate all the features</p>"},{"location":"Economics/Econometrics/02_Methodology/#some-theories","title":"Some theories","text":""},{"location":"Economics/Econometrics/02_Methodology/#structural-changes","title":"Structural changes","text":"<p>Population shifting from primary sector (agriculture) to secondary sector(manufacturing, construction)</p> <p>Economic sectors are highly-interconnected.</p> <pre><code>flowchart LR\n\nPrimary --&gt;\n|Inflation of Raw Materials| Secondary --&gt;\n|Inflation of Tools| Primary</code></pre>"},{"location":"Economics/Econometrics/02_Methodology/#population-sentiment","title":"Population Sentiment","text":"<p>People will spend money because they feel secure.</p>"},{"location":"Economics/Econometrics/02_Methodology/#govt","title":"Govt","text":"<p>Govt gives out many schemes and development projects, in order to mitigate the effect of decreased private interest.</p>"},{"location":"Economics/Econometrics/02_Methodology/#moral-hazard","title":"Moral Hazard","text":"<p>Insurance will actually cause people to be less cautious.</p> <p>Check in India if the direct monetary support to infected bank agents actually increased the amount of cases.</p>"},{"location":"Economics/Econometrics/02_Methodology/#mathematical-model","title":"Mathematical Model","text":"<p>Expressing theory in terms of mathematical equations.</p> <p>\u274c Assumes that the relationship is perfect</p> Single Multi Simulateneous Dependency Direct Indirect Multiple Direct Direction Uni Uni Multi Uni-variate \\(y=f(x)\\) \\(y = f(x)\\)\\(x = g(z)\\) \\(y = f(x)\\)\\(x = g(y)\\) Multi-variate \\(y=f(x, z)\\) \\(y = f(x, a)\\)\\(x = g(z, b)\\) Example - Dubai economy depends on US, which depends on China- Risk &amp; Return - Attendance &amp; Performance- Demand &amp; Price- Basically all economic aspects The intermediary variable of multi-equation model is called as moderator <p>Let\u2019s say that, height of wife is a function of height of husband, but not vice-versa; it is a male-dominated society</p> <ul> <li>height of husband is independent</li> <li>height of wife is dependent</li> </ul> <p>Let\u2019s say that, height of wife is a function of height of husband, but vice-versa is also applicable, then it is a equal society.</p> <ul> <li>height of husband is independent</li> <li>height of wife is independent</li> </ul>"},{"location":"Economics/Econometrics/02_Methodology/#econometric-model","title":"Econometric Model","text":"<p>Similar to Mathematical Model, but understands that relationships are not perfect. There will remain some change unexplained by our mathematical model.</p> <p>The real world is complex and continuously changing, but human knowledge is limited.</p>"},{"location":"Economics/Econometrics/02_Methodology/#specifying-inexact-relationships","title":"Specifying inexact relationships","text":"\\[ y = \\beta_1 + \\beta_2 x + u \\] <ul> <li>\\(y\\) is actual value of the dependent variable</li> <li> <p>\\(\\beta_1 + \\beta_2 x\\) is the estimated/forecasted/predicted component of \\(y\\)</p> <ul> <li>\\(B_1\\) is the value of \\(y\\) even when \\(x=0\\) It is the value of \\(x\\), that is independent of \\(x\\)</li> <li> <p>For eg, consumption can be non-zero even if income is 0 (called as autonomous consumption spending)</p> </li> <li> <p>\\(B_2\\) is the change in \\(y\\) for a unit change in \\(x\\)</p> </li> </ul> </li> <li> <p>\\(u\\) is the residual/error/disturbance/unexplained component of \\(y\\)</p> <ul> <li>difference between estimated value and actual value</li> <li>component not explained by your initial mathematical model in terms of only \\(x\\)</li> <li>it is different for each point</li> </ul> </li> </ul> Nature of \\(u\\) Accepted? Note Random \u2705 Systematic \u274c \\(\\exists\\) some factor that can be used to better explain \\(y\\)Increase no of independent variables, until \\(u\\) becomes random"},{"location":"Economics/Econometrics/02_Methodology/#linear-vs-non-linear-model","title":"Linear vs Non-Linear Model","text":"<p>We have to decide based on theory and logic</p> <p>If you are not aware about the theory, then visualize and use trial-error</p>"},{"location":"Economics/Econometrics/02_Methodology/#types-of-regression","title":"Types of Regression","text":"Regression through Intercept Regression through Origin \\(y\\) has a minimum? \u2705 \u274c \\(B_1\\) required? \u2705 \u274cBasically no intercept Example Supply function"},{"location":"Economics/Econometrics/02_Methodology/#data","title":"Data","text":""},{"location":"Economics/Econometrics/02_Methodology/#why-do-we-need-data","title":"Why do we need data?","text":"<p>To estimate numerical values, we need data.</p>"},{"location":"Economics/Econometrics/02_Methodology/#types","title":"Types","text":"<p>Basics - Refer other notes</p> <ul> <li> <p>Cross Sectional Data</p> <ul> <li>Marks of all students in 1 year</li> </ul> </li> <li> <p>Time Series Data</p> <ul> <li>Marks of 1 student from all years</li> </ul> </li> <li> <p>Panel Data</p> <ul> <li>Marks of all students from all years</li> </ul> </li> <li> <p>Scale Data</p> <ul> <li>Qualitative data</li> <li>Ratings: Good-Poor</li> </ul> </li> </ul>"},{"location":"Economics/Econometrics/02_Methodology/#sources-of-data","title":"Sources of Data","text":""},{"location":"Economics/Econometrics/02_Methodology/#primary-data","title":"Primary Data","text":"<p>Data collected on your own, using sensors/surveys</p>"},{"location":"Economics/Econometrics/02_Methodology/#secondary-data","title":"Secondary Data","text":"<p>Data collected by someone else</p>"},{"location":"Economics/Econometrics/02_Methodology/#data-frequency","title":"Data Frequency","text":"<p>How often the data is collected</p> <ul> <li>High Frequency: Stock Prices (recorded every second)</li> <li>Low Frequency: GDP (recorded monthly)</li> </ul>"},{"location":"Economics/Econometrics/02_Methodology/#high-frequency-data-is-preferred-over-low-frequency","title":"High Frequency data is preferred over Low Frequency","text":"<p>This is because, monthly data does not capture small changes appearing between 2 time periods, those small changes may not even be visible if you collect low frequency data.</p>"},{"location":"Economics/Econometrics/02_Methodology/#data-quality","title":"Data Quality","text":"<p>We must check the following properties of the data</p> <ul> <li>Verify Characteristics<ul> <li>Mean</li> <li>Standard Deviation</li> <li>Skewness</li> </ul> </li> <li> <p>Ensure Reliability</p> <ul> <li>Sensors are working correctly</li> <li>Calculations were made correctly</li> </ul> </li> <li> <p>No Bias</p> <ul> <li>There should be no researcher bias</li> <li> <p>Picking a particular sample</p> </li> <li> <p>Ensuring participants of survey have been unbiased</p> </li> <li>For ex: Satisfaction of students in UAE</li> </ul> </li> </ul>"},{"location":"Economics/Econometrics/02_Methodology/#sample-estimation","title":"Sample Estimation","text":"<p>Obtain the values of parameters/coefficients, using a sample of data</p>"},{"location":"Economics/Econometrics/02_Methodology/#types_1","title":"Types","text":"<p>We have to choose a method based on</p> <ul> <li>Nature of relationship</li> <li>Distribution of variables</li> </ul>"},{"location":"Economics/Econometrics/02_Methodology/#ols","title":"OLS","text":"<p>Assumes normal distribution</p> <p>Finds the best fit to reduce error term</p>"},{"location":"Economics/Econometrics/02_Methodology/#maximum-likelihood","title":"Maximum Likelihood","text":"<p>Assumes normal or other distribution</p> <p>Finds the best fit to pick the data point corresponding to highest probability of occurance for each data point</p>"},{"location":"Economics/Econometrics/02_Methodology/#hypothesis-testing","title":"Hypothesis Testing","text":"<p>Testing if our hypothesis holds true</p> <p>Is our sample representative?</p>"},{"location":"Economics/Econometrics/02_Methodology/#sample-evidence-and-statistical-inference","title":"Sample Evidence and Statistical Inference","text":"<p>Is estimated value statistically closer to hypothesized/assume value?</p> <p>Here, we are only interested in the existence of a relationship.</p> <ul> <li>\\(H_0: B_1 = 0\\) (there exists a relationship)</li> <li>\\(H_1: B_1 \\ne 0\\) (there exists no relationship)</li> </ul>"},{"location":"Economics/Econometrics/02_Methodology/#localization-of-hypothesis","title":"Localization of Hypothesis","text":"Localization Meaning Local/Specific You cannot generalize a hypothesis for the entire test sample/population that only applies to a training sample. General Universally-applicable hypothesis"},{"location":"Economics/Econometrics/02_Methodology/#forecastprediction","title":"Forecast/Prediction","text":"<p>Using the estimated equation</p>"},{"location":"Economics/Econometrics/02_Methodology/#types_2","title":"Types","text":"Implementation type Model only learns from Static Initial training Dynamic latest data Sample type In-Sample Train and test on the same dataset Out-of-Sample Train on a datasetTest on a different dataset"},{"location":"Economics/Econometrics/02_Methodology/#evaluation","title":"Evaluation","text":"<p>Error is the deviation between predicted and actual value</p> Type Full Form Equation MAE Mean Absolute Error \\(\\sum_{i=1}^n \\vert  \\hat y_i - y_i  \\vert\\) MSE Mean Squared Error \\(\\sum_{i=1}^n (\\hat y_i - y_i)^2\\) RMSE Root Mean Squared Error \\(\\sqrt{ \\sum_{i=1}^n (\\hat y_i - y_i)^2 }\\)"},{"location":"Economics/Econometrics/02_Methodology/#policy-purposeimpact-analysis","title":"Policy Purpose/Impact Analysis","text":"<p>Understand the impact of a policy decision</p>"},{"location":"Economics/Econometrics/02_Methodology/#multiplier","title":"Multiplier","text":"\\[ M = \\frac{1}{1 - \\beta_2} \\] <p>An initial increase in income will increase the aggregate income to \\(M\\) times the initial aggregate income.</p>"},{"location":"Economics/Econometrics/02_Methodology/#disposal-income","title":"Disposal Income","text":"<p>Income ready for spending</p>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/","title":"03 Basic Regression Analysis","text":""},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#regression","title":"Regression","text":"<p>Examine relationship between different variables</p> <p>Dependence of one variable on another variable</p> <p>Identify PRF, using SRF</p>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#assumptions","title":"Assumptions","text":"<ul> <li>Dependent var \\(\\to\\) Random   Variable whose distribution changes for different variables</li> <li>Independent \\(\\to\\) Non-Random</li> </ul>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#purpose","title":"Purpose","text":"<p>Derive a function that traces through the conditional means of \\(y\\) corresponding to different values of \\(x\\)</p> <p>Expected value = mean = average Same meaning</p> \\[ E(y|x_i) = \\beta_0 + \\beta_1 x_i \\]"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#population","title":"Population","text":"<p>not necessarily humans</p> <p>It refers to any set of data (universal); different from sample (will be covered later).</p>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#prf","title":"PRF","text":"<p>Population Regression Function</p> <p>Also called as Conditional Expectation Function(CEF)</p> <p>It is theoretical; we almost never have access to this</p> <p>It is always linear wrt hyper-parameters, but may/may not be linear wrt variables</p>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#linearity","title":"Linearity","text":"Linear wrt variables Non-Linear wrt variables Linear wrt parameters \\(\\beta_0 + \\beta_1 x_1\\) \\(\\beta_0 + \\beta_2 {x_i}^2\\) Non-Linear wrt parameters \\(\\beta_0 + {\\beta_1}^2 x_1\\) \\(\\beta_0 + {\\beta_1}^2 {x_1}^2\\)"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#transformation","title":"Transformation","text":"\\[ y_t = e^\\alpha x^\\beta_t e^{u_t} \\iff \\ln y_t = \\alpha + \\beta \\ln x_t + u_t \\] <p>One more thing in slide</p> <p>Some models cannot be changed;  they are intrinsically non-linear</p> \\[ y_t = \\alpha + x^{\\color{orange} \\beta}_t + u_t \\]"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#stochastic-specification-of-prf","title":"Stochastic Specification of PRF","text":"\\[ \\begin{aligned} y_i &amp;= E(y|x_i) + u_i \\\\ &amp; \\updownarrow \\\\ u_i &amp;= y_i - E(y|x_i) \\end{aligned} \\]"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#components","title":"Components","text":"<ul> <li>Systematic/Deterministic/Common/Explained component</li> <li>Non-Systematic/Random/Disturbance/Idiosyncratic component<ul> <li>effect of all omitted variables</li> <li>random effects</li> <li>effect of measurement error</li> </ul> </li> </ul>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#equivalency-with-prf","title":"Equivalency with PRF","text":"<p>Stochastic Specification is equal to PRF, as long as \\(E(u_i|x_i) = 0\\); this does not mean that \\(u_i = 0 , \\forall i\\)</p> <p>Why? This is because only if it is so, the line passes through the expectations of \\(y\\) for different values of \\(x\\). It is mathematically possible only if so. (Draw graph and see)</p> \\[ E(y_i | x_i) = E(y|x_i) + E(u_i|x_i) \\]"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#why-do-we-need-stochastic-specification","title":"Why do we need Stochastic Specification?","text":"<ul> <li>Vagueness of theory<ul> <li>Social Sciences has no definite theory for any event</li> </ul> </li> <li>Randomness in human behavior</li> <li>Incorporates effect of missing data<ul> <li>Wealth data is not as easy to get as income data</li> </ul> </li> <li>More appropriate for inexact relatioships</li> <li>Captures effect of omitted variables<ul> <li>Some variables are not as important</li> </ul> </li> <li>Captures effect of poor proxy variables</li> <li>Principle of Parsimony   We usually try to limit to simple models</li> <li>Incorrect functional form<ul> <li>Unknown theory</li> <li>Linear/Non-Linear function</li> </ul> </li> <li>Incorporates measurement errors</li> </ul>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#proxy-variable","title":"Proxy Variable","text":"<p>A variable that is closely-associated with the variable we want to use.</p> <p>We use proxy variables, when the main variable is not available</p> <p>eg:</p> <ul> <li>Age and Experience</li> <li>CPI and Inflation</li> </ul>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#types-of-relationships","title":"Types of Relationships","text":"Statistical/Schochastic Deterministic Independent var Non-Random Non-Random Dependent var Random Non-Random eg Predicting Crop Yield Ohm\u2019s Law"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#terms","title":"Terms","text":"\\(y\\) \\(x\\) DependentExplainedPredictandRegressandResponseExogeneous IndependentExplanatoryPredictorRegressorStimulusEndogeneous"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#capital-flight","title":"Capital Flight","text":"<p>Capital moves from one country to another</p>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#regression-ne-causation","title":"Regression \\(\\ne\\) Causation","text":"<p>Does not help understand the direction of causality</p> <p>We need to use domain knowledge, and impose restriction that \\(x\\) causes \\(y\\)</p>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#regression-vs-correlation","title":"Regression vs Correlation","text":"Regression Correlation Understand Exact relationship Degree of linear association between 2 variables Assumption One Dependent variableOne/more independent variable Both \\(x\\) and \\(y\\) are random"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#exogeneous-vs-endogeneous","title":"Exogeneous vs Endogeneous","text":"<p>Exogeneous vs endogeneous depends on what you assume to be the system</p> Exogeneous Endogeneous In our control? \u274c \u2705 <ul> <li>Exo = out</li> <li>Endo = in</li> </ul>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#basic-concepts-of-regression","title":"Basic Concepts of Regression","text":"<ol> <li>Derive Conditional values of \\(y\\) wrt \\(x\\)</li> <li>Calculate Conditional probabilities of \\(y\\) for different values of \\(x\\)</li> <li>Calculate conditional mean</li> <li>Calculate the weighted average using probality of occurance<ul> <li>This is different mean from arithmetic mean(simple average)</li> </ul> </li> </ol> <p>The expected value of unconditional random variable \\(y\\) is ???</p>"},{"location":"Economics/Econometrics/03_Basic_Regression_Analysis/#variability-of-y","title":"Variability of \\(y\\)","text":"<p>The variation of \\(y\\) for different values of \\(x\\)</p> <p>Higher variability is preferred</p>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/","title":"04 Sample Regression Function","text":""},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#sample","title":"Sample","text":"<p>Subset of Population</p> <p>Useful, as we can never have access to the entire population</p> <p>We will only have limited values of \\(y\\) for given value(s) of \\(x\\); we don\u2019t have access to the true distribution of \\(y\\) for different values of \\(x\\)</p>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#srf","title":"SRF","text":"<p>Sample Regression Function</p> \\[ \\begin{aligned} \\hat y_i &amp;= \\hat \\beta_0 + \\hat \\beta_1 x_i \\\\ y_i &amp;= \\hat \\beta_0 + \\hat \\beta_1 x_i + \\hat u_i \\end{aligned} \\] <p>We try to make each of these hyperparameters close to their PRF counter-parts</p> <ul> <li>\\(\\hat \\beta_0\\) is an estimator of \\(\\beta_0\\) from the PRF</li> <li>\\(\\hat \\beta_1\\) is an estimator of \\(\\beta_1\\) from the PRF</li> <li>\\(\\hat u_i\\) is an approximation of \\(u_i\\) from the PRF</li> <li>\\(\\hat y_i\\) is the predicted value of dependent variable from sample data</li> <li>\\(y_i\\) is the true value of dependent variable</li> </ul> <p>We can use the SRF to approximate a variable\u2019s distribution, by using statistical distributions, such as Poisson, \\(t\\), Normal, \\(\\chi^2\\)</p>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#problem","title":"Problem","text":"<ul> <li>Over-estimation   SRF estimate may be higher than the PRF estimate</li> <li>Under-estimation   SRF estimate may be lower than the PRF estimate</li> </ul>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#issue-with-sample-data","title":"Issue with Sample Data","text":"<p>We will get different SRF for each sample</p> <p>Perfect fit is impossible, due to Sample Fluctuations</p> <ul> <li>The tendancy of each sample to be different from each other</li> <li>It is basically impossible to avoid this</li> </ul> <p>There is no way to say what best represents the PRF</p> <p>Sample can be mis-representing You have to be careful about interpreting the results</p> <ul> <li>Nature of random sample may cause SRF to over-estimate/under-estimate</li> <li>Biased choosing of sample<ul> <li>Researcher chooses a particular sample</li> <li>For eg</li> <li>I chose Ronaldo for 2<sup>nd</sup> year study project</li> <li>Choosing students of high attendance only</li> </ul> </li> </ul>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#sampling-distribution","title":"Sampling Distribution","text":"<p>The distribution of \\(\\hat \\beta_0, \\hat \\beta_1, \\hat u_i\\) for different samples</p>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#why-is-it-important","title":"Why is it important?","text":"<p>Helps us understand which pair of \\(\\hat \\beta_0, \\hat \\beta_1\\) is the closest to the PRF \\(\\beta_0, \\beta_1\\)</p>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#techniques-to-identify-srf","title":"Techniques to identify SRF","text":"<p>You don\u2019t have to memorize the formula, but you should know what is happening; that way you can debug any errors</p> <ul> <li>OLS</li> <li>Maximum Likelihood Estimation</li> </ul>"},{"location":"Economics/Econometrics/04_Sample_Regression_Function/#autocorrelation","title":"Autocorrelation","text":"<p>Correlation between values of the same variable</p> <p>Usually used for time series data</p> <p>We use ARIMA(AutoRegressive Integrated Moving Averages) Model It\u2019s just values based on lagged values</p>"},{"location":"Economics/Econometrics/05_OLS/","title":"OLS","text":"<p>Refer to 07_Regression.md </p>"},{"location":"Economics/Econometrics/06_Hypothesis_Testing/","title":"Hypothesis Testing","text":"<p>Refer to 07_Hypothesis_Testing</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/","title":"Continuous","text":""},{"location":"Economics/Econometrics/07_Time_Continuous/#challenge","title":"Challenge","text":"<p>How to describe probability distribution</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#brownian-motionwiener-process","title":"Brownian Motion/Wiener Process","text":"<p>Basically a continuous version of simple RW: \u2018Limit\u2019 of simple RW</p> <p>Denoted using \\(y_t = B(t)\\)</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#properties","title":"Properties","text":"<ul> <li>Always starts at 0: \\(P( y_0 = 0 ) = 1\\)</li> <li>Stationary \\(\\forall s \\in [0, t)\\)</li> <li>\\(y_t - y_s \\sim N(0, t-s)\\)<ul> <li>where \\((t-s)\\) is the length of the interval</li> </ul> </li> <li>Independent increment: If intervals \\([s_i, t_i]\\) are non-overlapping, then \\(y_{t_i} - y_{s_i}\\) are independent</li> </ul>"},{"location":"Economics/Econometrics/07_Time_Continuous/#characteristics","title":"Characteristics","text":"<ul> <li>Cross the independent axis indefinitely-often</li> <li>Does not deviate too much from \\(y_t = \\sqrt{t}\\)</li> <li>Not differentiable</li> <li>Standard calculus cannot be applied</li> <li>Requires Ito calculus</li> <li>Max series </li> </ul> \\[ \\begin{aligned} &amp; M_t = \\max_{s \\le t} (y_s) \\\\ \\implies &amp;P(M_t &gt; a) = 2 \\cdot P (y_t &gt; a) \\\\ &amp; \\forall \\ t, a &gt; 0 \\end{aligned} \\] <ul> <li>Quadratic variation</li> </ul> <p>$$ t = \\frac{i}{n} T \\ \\implies \\lim_{n \\to \\infty} \\sum_{i=1}^n (y_{t} - y_{t-1})^2 = T \\ \\forall T &gt; 0 \\</p> <p>\\implies (dB)^2 = dt $$</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#implications","title":"Implications","text":"\\[ \\dfrac{d y_t}{y_t} = d B_t \\\\ d y_t \\ne \\dfrac{d B_t}{dt} \\cdot dt \\\\ \\implies y_t \\ne e^{B_t} \\] <p>This is because \\(\\dfrac{d B_t}{dt}\\) is not defined since \\(B_t\\) is not differentiable</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#itos-lemma","title":"Ito\u2019s Lemma","text":"<p>Consider \\(y_t = f(B_t)\\), where \\(f\\) is a smooth function $$ \\begin{aligned} y_t &amp;= f(B_t) \\ \\implies df &amp; \\ne f'(B_t) \\cdot d B_t \\quad [\\because (dB)^2 = dt] \\ \\implies df &amp;= f'(B_t) \\cdot d B_t + \\dfrac{1}{2} f''(B_t) \\cdot dt \\end{aligned} $$</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#idk","title":"IDK","text":"<p>Assuming \\(\\mu, \\sigma\\) are constant $$ \\begin{aligned} dy_t &amp;= \\underbrace{\\mu dt}_\\text{Drift} + \\sigma d B_t \\ \\implies y_t &amp;= \\mu t + \\sigma B_t \\end{aligned} $$ Using Ito\u2019s Lemma (Basically Taylor\u2019s expansion) $$ d f(t, x) = \\dfrac{\\partial f}{\\partial t} + \\mu \\dfrac{\\partial f}{\\partial x} + \\dfrac{1}{2} \\sigma^2 \\dfrac{\\partial^2 f}{\\partial x^2} + \\dfrac{\\partial f}{\\partial x} d B_t $$</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#integration","title":"Integration","text":"\\[ \\begin{aligned} F(t, B_t) &amp;= \\int f(t, B_t) d B_t + \\int g(t, B_t) dt \\\\ dF &amp;= f dB_t + g dt \\end{aligned} \\] <p>Ito integral is the limit of Riemanian sums when we always take leftmost point of each integral</p> <p>Intuitively, it only uses the data you have seen so far</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#adapted-process","title":"Adapted Process","text":"<p>A strategy/decision \\(D_t\\) is said to be adapted to \\(y_t\\), if \\(D_t\\)\u00a0only depends on \\(y_s, s \\le t, \\forall t\\)</p> <p>If \\(D_t\\) only depends on \\(t\\) and not on \\(B_t\\), then \\(y_t = \\int D_t \\cdot d B_t\\) is normally-distributed at all times</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#ito-isometry","title":"Ito Isometry","text":"<p>Used to calculate variance of Brownian motion $$ \\begin{aligned} D_t &amp;\\text{ adapted to } B_t \\ \\implies V(B_t) &amp;= E \\left[ (\\int_0^t D_s \\cdot dB_s)^2 \\right] \\ &amp;= E \\left[ \\int_0^t D^2_t \\cdot ds \\right] \\end{aligned} $$ Due to quadratic variance</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#martingale","title":"Martingale","text":"<p>If \\(g(t, B_t)\\) is adapted to \\(B_t\\) then \\(\\int g(t, B_t) \\cdot dB_t\\),\u00a0as long as \\(g\\)\u00a0is \u201creasonable\u201d</p> <p>\\(g\\) is reasonable if \\(\\int \\int g^2 \\cdot dt \\cdot dB_t &lt; \\infty\\)</p> <p>If a stochastic differential equation does not have a drift term, then it is a martingale $$ d y_t = \\sigma \\cdot dB_t \\qquad [\\mu = 0] $$ Defining stock price as brownian motion, as it is a martingale process $$ \\begin{aligned} S_t &amp;= \\exp(\\frac{-\\sigma^2 t}{2} + \\sigma B_t) \\ \\implies \\dfrac{d S_t}{S_t} &amp;= \\sigma \\cdot d B_t \\end{aligned} $$</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#stochastic-differential-equation","title":"Stochastic Differential Equation","text":"\\[ d y_t = \\mu \\cdot dt + \\sigma \\cdot dB_t \\]"},{"location":"Economics/Econometrics/07_Time_Continuous/#change-of-measure","title":"Change of measure","text":"<p>Consider </p> <ul> <li>\\(B\\) is brownian process w/ drift and pdf \\(P\\)</li> <li>\\(\\tilde B\\) is brownian process w/o drift and pdf \\(\\tilde P\\)</li> </ul> \\[ \\exists z, \\text{ such that } P(t) = z(t) \\cdot \\tilde P(t) \\iff P \\equiv \\tilde P \\] \\[ P \\equiv P \\text{ if } \\\\ P (A) &gt; 0 \\iff \\tilde P (A) &gt; 0, \\quad \\forall A \\subseteq \\Omega \\] <p>\\(z\\)\u00a0is called the Radon-Nikodym derivative</p>"},{"location":"Economics/Econometrics/07_Time_Continuous/#girsanov-theorem","title":"Girsanov theorem","text":"\\[ z(t) = \\dfrac{d \\tilde P}{dP} (t) = e^{-\\mu t T - \\frac{\\mu^2 T}{2}} \\] \\[ E[y_t] = \\tilde E[\\tilde z_t y_t] \\\\ \\tilde E[y_t] = E[z_t y_t] \\]"},{"location":"Economics/Econometrics/07_Time_Series_Processes/","title":"Time Series Processes","text":""},{"location":"Economics/Econometrics/07_Time_Series_Processes/#time-series","title":"Time Series","text":"<p>Observation of random variable ordered by time</p> <p>Time series variable can be</p> <ul> <li>Time series at level (absolute value)</li> <li>Difference series (relative value)<ul> <li>First order difference \\(\\Delta y_t = y_t - y_{t-1}\\)</li> <li>Called as \u2018returns\u2019 in finance</li> <li>Second order difference \\((\\Delta y_t)_2 = \\Delta y_t - \\Delta y_{t-1}\\)</li> </ul> </li> </ul>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#univariate-time-series","title":"Univariate Time Series","text":"<p>Basic model only using a variable\u2019s own properties like lagged values, trend, seasonality, etc</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#why-do-we-use-different-techniques-for-time-series","title":"Why do we use different techniques for time series?","text":"<p>This is due to</p> <ul> <li>behavioral effect</li> <li>history/memory effect<ul> <li>Medical industry always looks at the records of your medical history</li> </ul> </li> <li>Inertia of change</li> <li>Limited data</li> </ul>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#components-of-time-series-processes","title":"Components of Time Series Processes","text":"Characteristic Frequency Example Level Average value of series Constant Trend Gradual Low Drift Exogeneous Constant Cycles &gt; 1 year Economy cycle Seasonality Daily, Weekly, Monthly Structural Break Holidays Eid, Christmas Auto-Correlation Relationship with past Shocks Power outage Noise Random High"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#auto-correlation","title":"Auto-correlation","text":"<p>Sometimes just auto-correlation is enough to learn the values of a value</p> \\[ y_t = \\beta_0 + \\beta_1 y_{t-1} + e_t \\] <p>If we take \\(j\\) lags,</p> \\[ y_t = \\beta_0 + \\sum_{i=1}^j \\beta_i y_{t-i} + e_t \\] <p>Generally, \\(i&gt;j \\implies \\beta_i &lt; \\beta_j\\)</p> <p>Impact of earlier lags is lower than impact of recent lags</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#shock","title":"Shock","text":"<p>\u2018Shock\u2019 is an abrupt/unexpected deviation(inc/dec) of the value of a variable from its expected value</p> <p>This incorporates influence of previous disturbance</p> <p>They cause a structural change in our model equation. Hence, we need to incorporate their effect.</p> \\[ \\text{Shock}_t = y_t - E(y_t) \\] <p>Basically, shock is basically \\(u_t\\) but it is fancily called as a shock, because they are large \\(u\\)</p> <p>Can be</p> Temporary Permanent Duration Short-term Long-Term Causes structural change Examples Change in financial activity due to Covid Change in financial activity due to 2008 Financial Crisis Heart rate change due to minor strokeHeart rate change due to playing Heart rate change due to major strokeHeart rate change due to big injury Goals scored change due to small fever Goals scored change due to big injury <p>Model becomes</p> \\[ y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 u_{t-1} \\]"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#structural-breaks","title":"Structural Breaks","text":"<p>Permanent change in the variable causes permanent change in relationship</p> <p>We can either use</p> <ul> <li>different models before and after structural break</li> <li>binary \u2018structural dummy variable\u2019 to capture this effect</li> </ul> <p>For eg, long-term injury</p> \\[ y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 B_t \\]"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#trend","title":"Trend","text":"<p>Tendency of time series to change at a certain expected rate.</p> <p>Trend can be</p> <ul> <li>deterministic/systematic (measurable)</li> <li>random/stochastic (not measurable \\(\\implies\\) cannot be incorporated)</li> </ul> <p>For eg: as age increases, humans have a trend of</p> <ul> <li>growing at a certain till the age of 20 or so</li> <li>reducing heart rate</li> </ul> <p>Model becomes</p> \\[ y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 t \\]"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#seasonalityperiodicity","title":"Seasonality/Periodicity","text":"\\[ y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 \\textcolor{hotpink}{S} \\] <p>Tendency of a variable to change in a certain manner at regular intervals.</p> <p>For eg</p> <ul> <li>demand for woolen clothes is high every winter</li> <li>demand for ice cream is high every summer</li> </ul> <p>Finance industry has \u2018anomalies\u2019</p> <p>Two ways to encode</p> Type Smooth Example \\(S\\) Binary \u274c Dummy \\(\\{0, 1\\}\\) Continuous \u2705 Cyclic Linear Basis \\(\\exp{\\left[\\dfrac{- 1}{2 \\alpha^2} (x_i - \\text{pivot})^2\\right]}\\)- Pivot is the center of the curve Preferred, as more control over amplitude and bandwidth \u2705 Fourier series \\(\\alpha \\cos \\left(\\dfrac{2 \\pi}{\\nu} t + \\phi \\right) + \\beta \\sin \\left( \\dfrac{2 \\pi}{\\nu} t + \\phi\\right)\\)Usually \\(\\alpha, \\beta = 1\\)\\(\\nu =\\) Frequency of seasonality- Quarterly = 4- Monthly = 12- Daily = 365.25\\(\\phi\\) is the offset"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#volatility","title":"Volatility","text":"<p>Annualized standard deviation of change of a random variable</p> <p>Measure of variation of a variable from its expected value</p> <p>If the variance is heteroskedastic (changes over time), the variable is volatile</p> \\[ \\begin{aligned} \\sigma^2_{y_t} &amp;= E \\Big [\\Big(y_t - E(u_t) \\Big)^2 \\Big] \\\\ &amp;= E \\Big [\\Big(y_t - \\textcolor{hotpink}{0} \\Big)^2 \\Big] \\\\ &amp;= E [y_t^2 ] \\\\ &amp;= y_t^2 \\\\ \\end{aligned} \\] \\[ y_t = \\beta_0 + \\beta_1 y_{t-1} + \\beta_2 \\sigma^2_{t-1} \\]"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#lag-terms","title":"Lag Terms","text":"\\[ \\begin{aligned} \\text{Let's say} \\to y_t &amp;= f(y_{t-2}) \\\\ y_t &amp;= f(y_{t-1}) \\\\ y_{t-1} &amp;= f(y_{t-2}) \\end{aligned} \\] \\[ y_t = \\rho_1 y_{t-1} + \\rho_2 y_{t-2} + u_t \\] <p>Here, \\(\\rho_1\\) and \\(\\rho_2\\) are partial-autocorrelation coefficient of \\(y_{t-1}\\) and \\(y_{t-2}\\) on \\(y_t\\)</p> \\[ y_t = \\rho_1 y_{t-2} + u_t \\] <p>Here, \\(\\rho_1\\) is total autocorrelation coefficient of \\(y_{t-2}\\) on \\(y_t\\)</p> <p>We choose the number of lags by trial-and-error and checking which coefficients are significant (\\(\\ne 0\\))</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#interactions","title":"Interactions","text":"<ul> <li>trend-level</li> <li>trend-autocorrelation</li> <li>trend-seasonality</li> <li>seasonality-level</li> <li>seasonality-autocorrelation</li> </ul>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#stochastic-data-generating-processes","title":"Stochastic Data-Generating Processes","text":"<p>Stochastic process is a sequence of random observations indexed by time</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#markov-chain","title":"Markov Chain","text":"<p>Stochastic process where effect of past on future is summarized only by current state $$ P(y_{t+1} = a \\vert x_0, x_1, \\dots x_t) = P(x_{t+1} = a \\vert x_t) $$ If possible values of \\(x_i\\) is a finite set, MC can be represented as a transition probability matrix</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#martingale","title":"Martingale","text":"<p>Stochastic processes which are a \u201cfair\u201d game $$ E[y_{t+1} \\vert y_t] = y_t $$ Follow optimal stopping theorem</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#subordinated","title":"Subordinated","text":""},{"location":"Economics/Econometrics/07_Time_Series_Processes/#stationarity","title":"Stationarity","text":"Type Meaning Features Comment Stationary \\(y_t\\) is independent of time Constant mean: \\(E(y_t) = \\mu\\)Constant variance: \\(\\text{Var}(y_t) = \\sigma^2\\)No trend, seasonalityMay have aperiodic cycles Covariance Stationary Constant mean: \\(E(y_t) = \\mu\\)Constant variance: \\(\\text{Var}(y_t) = \\sigma^2\\)No trend, seasonalityMay have aperiodic cyclesConstant auto-covariance: \\(\\text{Cov}(y_{t+h}, y_t) = \\gamma(\\tau)\\) Non-Stationary \\(y_t\\) statistical properties and hence distribution of \\(y_t\\) changes with time Mean, Variance, Skew, KurtosisTrend, Seasonality We need to transform this somehow, as OLS and GMM cannot be used for non-stationary processes, because the properties of OLS are violated <p>Distribution of \\(y_t\\) can be inspected with rolling statistics</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#types-of-stochastic-processes","title":"Types of Stochastic Processes","text":"<p>Consider \\(u_t = N(0, \\sigma^2)\\)</p> Process Characteristics \\(y_t\\) Comments Mean Variance Memory Example White Noise Stationary \\(u_t\\) PAC &amp; TAC for each lag = 0 0 \\(\\sigma^2\\) None If a financial series is a white noise series, then we say that the \u2018market is efficient\u2019 Ornstein Uhlenbeck Process/Vasicek Model StationaryMarkov chain \\(\\beta_1 y_{t-1} + u_t; \\ 0 &lt; \\vert \\beta_1 \\vert &lt; 1\\) Series has Mean-reverting Earlier past is less important compared to recent past.Less susceptible to permanent shockSeries oscilates 0/non-zero \\(\\sigma^2\\) Short GDP growthInterest rate spreadsReal exchange ratesValuation ratios (divides-price, earnings-price) Covariance Stationary \\(y_t = V_t + S_t\\) (Wold Representation Theorem)\\(V_t\\) is a linear combination of past values of \\(V_t\\) with constant coefficients\\(S_t = \\sum \\psi_i u_{t-i}\\) is an infinite moving-average process of error terms, where \\(\\psi_0=1, \\sum \\psi_i^2 &lt; \\infty\\); \\(\\eta_t\\) is linearly-unpredictable white noise and \\(u_t\\) is uncorrelated with \\(V_t\\) Simple Random Walk Non-StationaryMarkov chainMartingale \\(\\begin{aligned} &amp;= y_{t-1} + u_t \\\\ &amp;= y_0 + \\sum_{i=0}^t u_i \\end{aligned}\\) PAC &amp; TAC for each lag = 0\\(y_{t+h} - y_t\\) has the same dist as \\(y_h\\) \\(y_0\\) \\(t \\sigma^2\\) Long Explosive Process Non-Stationary \\(\\beta_1 y_{t-1} + u_t; \\  \\vert \\beta_1 \\vert &gt; 1\\) Random Walk w/ drift Non-Stationary \\(\\begin{aligned} &amp;= \\beta_0 + y_{t-1} + u_t \\\\ &amp;= t\\beta_0 + y_0 + \\sum_{i=0}^t u_i \\end{aligned}\\) \\(t \\beta_0 + y_0\\) \\(t \\sigma^2\\) Long Random Walk w/ drift and deterministic trend Non-Stationary \\(\\begin{aligned} &amp;= \\beta_0 + \\beta_1 t + y_{t-1} + u_t \\\\ &amp;= y_0 + t \\beta_0 + \\beta_1 \\sum_{i=1}^t i + \\sum_{i=1}^t u_t \\end{aligned}\\) \\(t \\beta_0 + \\beta_1 \\sum_{i=1}^t i + y_0\\) \\(t \\sigma^2\\) Long Random Walk w/ drift and non-deterministic trend Non-Stationary Same as above, but \\(\\beta_1\\) is non-deterministic <p>Impulse Response Function of covariance stationary process \\(y_t\\) is $$ \\begin{aligned} \\text{IR}(j) &amp;= \\dfrac{\\partial y_t}{\\partial \\eta_{t-j}} \\ &amp;= \\psi_j \\ \\implies \\sum \\text{IR}(j) &amp;= \\phi(L), \\text{with L=}1 \\ &amp;\\text{ (L is lag operator)} \\end{aligned} $$</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#differentiation","title":"Differentiation","text":"<p>When converting a non-stationary series \\(y_t\\) into a stationary series \\(y'_t\\), we want</p> <ul> <li>Obtain stationarity: ADF Stat at 95% CL as \\(-2.8623\\)</li> <li>Retain memory: Similarity to original series; High correlation b/w original series and differentiated series</li> </ul> \\[ y'_t = y_t - d y_{t-1} \\\\ d \\in [0, 1] \\\\ d_\\text{usual} \\in [0.3, 0.5] \\] \\(d\\) Stationarity Memory 0 \u274c \u2705 \\((0, 1)\\)(Fractional differencing) \u2705 \u2705 1 \u2705 \u274c <p></p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#fractional-differencingun-differencing","title":"Fractional Differencing/Un-differencing","text":"<p>To un-difference and approximately recover the original data:</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#pre-requisites","title":"Pre-Requisites","text":"<ol> <li>A fixed-sized window is used for differencing<ol> <li>Fractional differencing using a fixed window only considers a certain number (say, w) of past data points to compute the differenced value at each time step</li> <li>Unlike standard integer differencing, fractional differencing uses a weighted sum of previous values, with the weights decaying over history but not reaching zero until you hit a threshold.</li> </ol> </li> <li>The first window of original data points is saved<ol> <li>This means that to reconstruct (un-difference) a value at time t, you need the w most recent original (pre-differenced) or already reconstructed data points, starting with the first window.</li> </ol> </li> </ol>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#method","title":"Method","text":""},{"location":"Economics/Econometrics/07_Time_Series_Processes/#practical-steps-how-fractional-un-differencing-can-be-done","title":"Practical Steps: How Fractional Un-differencing Can Be Done","text":"<ol> <li>During differencing:<ul> <li>Apply fractional differencing with a fixed window length\u00a0w; store the first\u00a0w-1 original values (these are the boundary values you'll need later).</li> </ul> </li> <li>To un-difference:<ul> <li>For each point after the initial window, set up the equation represented by the differencing operation (i.e., the original is a weighted sum of the previous\u00a0w-1 originals and the differenced value).</li> <li>Solve this recursively using the saved initial values.</li> <li>This is analogous to \"unsmoothing\", where a moving-average (or filter) can be inverted as long as enough initial data is available to resolve the system</li> </ul> </li> </ol> <pre><code>import numpy as np\nfrom scipy.signal import lfilter\nfrom fracdiff import fdiff\n\ndef is_integer(d, tol=1e-10):\n    \"\"\"Check if d is effectively an integer within floating point tolerance.\"\"\"\n    return abs(d - round(d)) &lt; tol\n\ndef fracdiff_weights(d, N):\n    \"\"\"\n    Compute fractional differencing weights for given order d and window size N.\n    Correctly handles all real d, including negative and integer.\n    \"\"\"\n    if is_integer(d):\n        w = np.zeros(N)\n        w[round(d)] = (-1)**round(d)\n        return w\n    else:\n        k = np.arange(1, N)\n        mult = -(d - k + 1) / k\n        w = np.empty(N)\n        w[0] = 1.0\n        w[1:] = np.cumprod(mult)\n        return w\n\n\ndef unfracdiff(y, d, x0=None, window=10):\n    \"\"\"\n    Reconstruct the original series from a fractionally (or integer) differenced series y.\n\n    Parameters:\n        y: differenced series\n        d: differencing order (can be int or float)\n        x0: initial value(s) (scalar or array of size d for integer or window-1 for fractional)\n        window: used for fractional differencing only\n\n    Returns:\n        Reconstructed series x\n    \"\"\"\n    N = len(y)\n\n    if is_integer(d):\n        d = int(round(d))\n        if x0 is None:\n            x0 = np.zeros(d)\n        x = y.copy()\n        for j in range(d):\n            x = np.cumsum(x)\n        return x\n\n    else:\n        # Fractional case (non-integer)\n        if x0 is None:\n            raise ValueError(\"Initial values x0 (length=window-1) must be provided for fractional d.\")\n        w = fracdiff_weights(d, window)\n        a = w\n        b = [1.0]\n        # Pad y with initial values to simulate correct lfilter history\n        y_padded = y.copy()\n        # Apply inverse filter\n        x_reconstructed = lfilter(b, a, y_padded)\n        # Replace the initial window values with original x0\n        x_reconstructed[:window-1] = x0\n        return x_reconstructed\n\n\n# Example full working test\nimport numpy as np\nfrom fracdiff import fdiff\n\nx = np.random.random(10)\nd = 0.5                     # Can be integer (1, 2, ...) or fractional (0.5, 0.25, ...)\nwindow = 10\n\n# Differencing\nif is_integer(d):\n    x_shifted = x.copy()\n    for i in range(d):\n      x_shifted = np.diff(x_shifted, n=1, prepend=[0])\n    y = x_shifted.copy()\n    x0 = x[:int(d)]\nelse:\n    y = fdiff(x, n=d, window=window)\n    x0 = x[:window-1]  # Save initial window for un-fractional differencing\n\n# Un-differencing\nx_reconstructed = unfracdiff(y, d, x0=x0, window=10)\n\nprint(\"Original x:      \", x.round(1))\n\ntemp = np.ceil(d).astype(int)\nprint(\"Diff: \", np.concatenate(\n    ([np.nan]*temp, y.round(1)[temp:])\n))\nprint(\"Reconstructed x:\", x_reconstructed.round(1))\nprint()\nprint(\"Difference:\", (x - x_reconstructed).round(1))\n</code></pre>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#integratedds-process","title":"Integrated/DS Process","text":"<p>Difference Stationary Process</p> <p>A non-stationary series is said to be integrated of order \\(k\\), if mean and variance of \\(k^\\text{th}\\)-difference are time-invariant</p> <p>If the first-difference is non-stationary, we take second-difference, and so on</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#pure-random-walk-is-ds","title":"Pure random walk is DS","text":"\\[ \\begin{aligned} y_t &amp;= y_{t-1} + u_t \\\\ \\implies \\Delta y_t &amp;= \\Delta y_{t-1} + u_t \\quad \\text{(White Noise Process = Stationary)} \\end{aligned} \\]"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#random-walk-w-drift-is-ds","title":"Random walk w/ drift is DS","text":"\\[ \\begin{aligned} y_t &amp;= \\beta_0 + y_{t-1} + u_t \\\\ \\implies \\Delta y_t &amp;= \\beta_0 + \\Delta y_{t-1} + u_t \\quad \\text{(Stationary)} \\end{aligned} \\]"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#ts-process","title":"TS Process","text":"<p>Trend Stationary Process</p> <p>A non-stationary series is said to be \u2026, if mean and variance of de-trended series are time-invariant</p> <p>Assume a process is given by</p> \\[ y_t = \\beta_0 + \\beta_1 t + y_{t-1} + u_t \\] <p>where trend is deterministic/stochastic</p> <p>Then</p> <ul> <li>Time-varying mean</li> <li>Constant variance ???</li> </ul> <p>We perform de-trending \\(\\implies\\) subtract \\((\\beta_0 + \\beta_1 t)\\) from \\(y_t\\)</p> \\[ (y_t - \\beta_0 - \\beta_1 t) = y_{t-1} + u_t \\] <p>If</p> <ul> <li>\\(\\beta_2 = 0\\), the de-trended series is white noise process</li> <li>\\(\\beta_2 \\ne 0\\), the de-trended series is a stationary process</li> </ul> <p>Note Let\u2019s say \\(y_t = f(x_t)\\)</p> <p>If both \\(x_t\\) and \\(y_t\\) have equal trends, then no need to de-trend, as both the trends will cancel each other</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#unit-root-test-for-process-identification","title":"Unit Root Test for Process Identification","text":"\\[ y_t = \\textcolor{hotpink}{\\beta_1} y_{t-1} + u_t \\] \\(\\textcolor{hotpink}{\\beta_1}\\) \\(\\gamma\\) Process \\(0\\) White Noise \\((0, 1)\\) Stationary \\([1, \\infty)\\) Non-Stationary"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#augmented-dicky-fuller-test","title":"Augmented Dicky-Fuller Test","text":"<ul> <li>\\(H_0: \\beta_1=1\\)</li> <li>\\(H_0: \\beta_1 \\ne 1\\)</li> </ul> <p>Alternatively, subtract \\(y_{t-1}\\) on both sides of main equation</p> \\[ \\begin{aligned} y_t - y_{t-1} &amp;= \\beta_1 y_{t-1} - y_{t-1} + u_t \\\\ y_t - y_{t-1} &amp;= (\\beta_1-1) y_{t-1} + u_t \\\\ \\Delta y_t &amp;= \\gamma y_{t-1} + u_t &amp; (\\gamma = \\beta_1 - 1) \\end{aligned} \\] <ul> <li>\\(H_0: \\gamma=1\\) (Non-Stationary)</li> <li>\\(H_1: \\gamma \\ne 1\\) (Stationary)</li> </ul> <p>If p value \\(\\le 0.05\\)</p> <ul> <li>we reject null hypothesis and accept alternate hypothesis</li> <li>Hence, process is stationary</li> </ul> <p>We test the hypothesis using Dicky-Fuller distribution, to generate the critical region</p> Model Hypotheses \\(H_0\\) Test Statistic \\(\\Delta y_t =\\)"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#long-memory-series","title":"Long memory series","text":"<p>Earlier past is as important as recent past</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#q-statistic","title":"Q Statistic","text":"<p>Test statistic like \\(z\\) and \\(t\\) distribution, which is used to test \u2018joint hypothesis\u2019</p>"},{"location":"Economics/Econometrics/07_Time_Series_Processes/#inertia-of-time-series-variable","title":"Inertia of Time Series Variable","text":"<p>Persistance of value due to Autocorrelation</p> <p>Today\u2019s exchange rate is basically yesterday\u2019s exchange rate, plus-minus something</p>"},{"location":"Economics/Econometrics/08_Autocorrelation/","title":"Autocorrelation","text":""},{"location":"Economics/Econometrics/08_Autocorrelation/#durbin-watson-test","title":"Durbin-Watson Test","text":""},{"location":"Economics/Econometrics/08_Autocorrelation/#positive","title":"Positive","text":"<ul> <li>\\(H_0: \\rho = 0\\)</li> <li>\\(H_1: \\rho &gt; 0\\) (not negative)</li> </ul> \\[ \\begin{aligned} D &amp;= \\dfrac{ \\sum_{i=p}^n (u_i - u_{i-p})^2 }{ \\sum_{i=1}^n (u_i)^2 } \\\\ &amp; \\approx 2(1-\\rho) \\end{aligned} \\] <p>where \\(p=\\) lag being tested</p> <ul> <li>If \\(D&gt;D_h\\), cannot reject null hypothesis</li> <li>If \\(D&lt;D_l\\), reject null hypothesis</li> <li> <p>If \\(D_l &lt; D&lt;D_h\\), inconclusive</p> </li> <li> <p>\\(D \\ge 2 \\implies\\) no autocorrelation</p> </li> <li>\\(D \\to 0 \\implies\\) perfect autocorrelation</li> </ul>"},{"location":"Economics/Econometrics/08_Autocorrelation/#negative","title":"Negative","text":"<p>\\(D' = 4-D\\)</p>"},{"location":"Economics/Econometrics/08_Autocorrelation/#runs-test","title":"Runs Test","text":"<p>Run: any sequence on the same side of 0</p> <p>Usually one-tailed to test for +ve correlation</p> <ul> <li>+ve correlation: bounces less frequently</li> <li>-ve correlation: bounces very frequently; (not very common in data)</li> </ul> \\[ \\begin{aligned} \\bar R &amp;= \\dfrac{2 n_+ n_-}{n} + 1 \\\\ s^2_R &amp;= \\dfrac{2 n_+ n_- (2 n_+ n_- - n)}{n^2 (n-1)} \\\\ \\implies Z_R &amp;= \\dfrac{R-\\bar R}{s_R} \\sim N(0, 1) \\end{aligned} \\] <p>where</p> <ul> <li>\\(R=\\) number of runs in data</li> <li>\\(n_+=\\) number of +ve residuals</li> <li>\\(n_-=\\) number of -ve residuals</li> <li>\\(n=\\) total number of residuals</li> </ul>"},{"location":"Economics/Econometrics/08_Cointegrating_Process/","title":"Cointegrating Processes","text":"<p>Tendency of 2 variables (that are theoretically at equilibrium) to be related to each other</p> <p>2 processes that are integrated of order 1, but \\(\\exists\\) linear combination of the 2 variables that is stationary.</p> <p>If there is divergence, it will only be temporary, as there is bound to be error correction</p> <p>The coefficient associated with the 2 variables will be non-zero</p> <p>Usually happens with highly connected variables</p> <p>If there are \\(n\\) cointegrating variables, then there can be</p> <ul> <li>\\([1, n-1]\\) independent cointegrating relationships (not lesser or greater than this range)</li> <li>\\([1, n]\\) error correction relationships</li> </ul> <p>eg:</p> <ul> <li>Demand and Supply for a commodity</li> <li>US interest rate and UAE interest rate<ul> <li>US is leading market</li> <li>UAE is following market</li> </ul> </li> <li>Dubai and Sharjah rent</li> <li>GCC stock markets</li> </ul> <p>Consider \\(x, z\\) which are both \\(I(1)\\) processes; \\(x_t\\) and \\(z_t\\) are cointegrated processes \\(\\iff u_t\\) is stationary process,</p> \\[ \\begin{aligned} z_t &amp;= \\alpha_1 x + u_t &amp; \\text{(Long-Term Specification)} \\\\ \\implies u_t &amp;= z_t - \\alpha_1 x_t &amp; \\text{(Short-Term Specification)} \\\\ z_t - z_{t-1} &amp;= \\textcolor{hotpink}{-}\\alpha_D(z_{t-1} - \\alpha_1 x_{t-1}) + v_t \\\\ \\Delta z_t &amp;= \\textcolor{hotpink}{-}\\alpha_D(u_{t-1}) + v_t \\\\ &amp; \\text{if } x \\text{ also has correcting tendancy,} \\\\ \\implies \\Delta x_t &amp;= \\textcolor{orange}{+} \\alpha_G(u_{t-1}) + w_t \\end{aligned} \\] <ul> <li>\\(\\alpha_D\\)<ul> <li>Speed of adjustment parameter, or error correction coefficient</li> <li>\\(\\alpha_D \\in (0, 1)\\)</li> </ul> </li> <li>\\(u_t=\\)\u00a0Disequilibrium error/Cointegration residual</li> </ul>"},{"location":"Economics/Econometrics/08_Cointegrating_Process/#parts","title":"Parts","text":"<ul> <li>Attractor/Leader</li> <li>Attracted/Follower</li> </ul>"},{"location":"Economics/Econometrics/08_Cointegrating_Process/#correlation-vs-co-integration","title":"Correlation vs Co-integration","text":"<p>Co-integration  \\(\\  \\not \\!\\!\\!\\!\\! \\iff\\) Correlation</p> Correlation Co-Integration Co-movementDuration short-term long-term"},{"location":"Economics/Econometrics/08_Cointegrating_Process/#drunk-couple-and-dog","title":"Drunk Couple and Dog","text":""},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/","title":"Time Series Decomposition","text":"Advantages Disadvantages Classical ETS Easy to understand &amp; interpret 1. Estimate of trend is unavailable in the first few and last few observations2. Assumes that seasonal component repeats3. Not robust to outliers due to usage of means X-11 1. Relatively robust to outliers2. Completely automated choices for trend and seasonal changes3. Tried &amp; tested method 1. No prediction/confidence intervals2. Ad hoc method with no underlying model3. Only for quarterly &amp; monthly data X-12-ARIMA/X-13-ARIMA 1. Allow adjustments for trading days and explanatory variables2. Known outliers can be omitted3. Level shifts &amp; ramp effects can be modelled4. Missing values estimated and replaced5. Holiday factors can be estimated X-13-ARIMA-SEATS 1. Model-based2. Smooth trend estimate3. Allows estimates at end-points4. Incorporates changing seasonality STLSeasonal &amp; Trend Decomposition using Loess - Iterative alogirthm- Starts with \\(\\hat T = 0\\)- Uses mixture of loess and moving averages to successively refine trend &amp; seasonal estimates- Trend window controls loess bandwidth applied to de-seasonalized values- Season window controls loess bandwidth applied to detrended subseries- Seasonal component allowed to change over time; Rate of change controlled by analyst- Smoothness of trend controlled by analyst - Versatile- Robust- Handle any type of seasonality - Only additive (Use log/Box-Cox transformations for other)- No training day/calendar adjustments"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#ets","title":"ETS","text":"<p>Extras-Trend-Seasonality</p> <p>Classical Decomposition</p> \\(y_t\\) Appropriate when Addititive \\(S_t + T_t + R_t\\) Multiplicative \\(S_t \\times T_t \\times R_t\\) Magnitude of seasonal fluctuations proportional to level of series <p>Alternatively, use Box-Cox transformation, and then use additive decomposition. Logs turn multiplicative relationship into additive</p> \\[ \\begin{aligned} y_t &amp;= S_t \\times T_t \\times R_t \\\\  \\implies \\ln y_t &amp;= \\ln S_t + \\ln T_t + \\ln R_t \\end{aligned} \\]"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#trend-estimation","title":"Trend Estimation","text":"<p>Centered moving averages, to combat odd order</p> \\[ \\begin{aligned} \\hat T_t &amp;= \\dfrac{1}{2m} \\left( \\sum_{i = -(k+1)}^k y_{t+i} + \\sum_{i = -k}^{k+1} y_{t+i} \\right) \\\\ \\text{where } k &amp;= \\dfrac{m-1}{2} \\end{aligned} \\] Order (\\(m\\)) Curve Data Retention Larger Smoother, flatter Less(end points are lost) Smaller Noisy More <p>Moving average of the same length of a season/cycle removes its pattern</p>"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#seasonal-adjusted-data","title":"Seasonal Adjusted Data","text":"<p>Component excluding the seasonal component</p>"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#detrended-series","title":"Detrended Series","text":"\\[ \\begin{aligned} y_t - \\hat T_t &amp;= \\hat S_t + \\hat R_t \\\\ \\frac{y_t}{\\hat T_t} &amp;= \\hat S_t \\times \\hat R_t \\end{aligned} \\]"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#seasonal-component","title":"Seasonal component","text":"<p>Average of de-trended series for that season. For eg, average of all values in Januaries</p> <p>You can constraint the seasonal components such that</p> \\[ \\hat S_1 + \\hat S_2 + \\dots + \\hat S_{n} = 0 \\\\ \\hat S_1 \\times \\hat S_2 \\times \\dots \\times \\hat S_{n} = m \\]"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#remainder-component","title":"Remainder Component","text":"\\[ \\begin{aligned} \\hat R_t &amp;= y_t - (\\hat T_t + \\hat S_t) \\\\ \\hat R_t &amp;= \\dfrac{y_t}{\\hat T_t \\hat S_t} \\end{aligned} \\]"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#fourier-transforms","title":"Fourier Transforms","text":"<p>FT\u2019s limitation: FT is completely blind to time, in accordance with Heisenberg\u2019s Uncertainty principle. There\u2019s a tradeoff between correctly estimating the value of function in the frequency &amp; time domain.</p> <p>It is 1D representation</p>"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#types-of-fourier-transforms","title":"Types of Fourier Transforms","text":"Type Continuous Time &amp; Frequency Functional form of time series is known analytically \\(\\hat x(f) = \\int \\limits_{-\\infty}^\\infty x(t) e^{-2\\pi i f t} dt\\) Continuous Time, Discrete Frequency(Fourier Series) \\(\\hat x(f_n) = \\dfrac{1}{T} \\int \\limits_{0}^T x(t) e^{-2\\pi i f_n t} dt; f_n = \\dfrac{n}{T}\\) Discrete Time &amp; Frequency(Fourier Frequencies) \\(\\hat x(f_n) = \\sum \\limits_{k=0}^{N-1} x_t e^{- 2 \\pi i f_n (k \\Delta t)} \\Delta t; f_n = \\dfrac{n}{N \\Delta t}; \\hat x_n = \\hat x^*_{-n}\\) FFT(Fast Fourier Transform)"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#denoising-using-fft","title":"Denoising using FFT","text":"<ol> <li>Apply FFT</li> <li>Filter it to only the frequencies with the highest amplitude</li> <li>Take inverse FFT</li> </ol>"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#wavelet-transform","title":"Wavelet Transform","text":"<p>Overcomes FT\u2019s limitation: FT is completely blind to time, by obtaining an optimal balance between accuracy in frequency &amp; time domain</p>"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#wavelet","title":"Wavelet","text":"<p>Short-lived oscillation, localized in time</p> <ul> <li>Zero mean: \\(E[\\phi(t)]=0; \\int \\phi(t) \\cdot dt = 0\\) (Admissibility condition)</li> <li>Finite energy: \\(\\int [\\phi(t)]^2 \\cdot dt = k, k &lt; \\infty\\)</li> <li></li> </ul> Type \\(\\phi(t)\\) Daubechies Coiflet Symlet Haar Morlet \\(k_0 \\cdot e^{i w_0 t} \\cdot e^{-t^2/2}\\) Gaussian Shannon Meyer Mexican Hat"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#idk","title":"IDK","text":"<p>2D representation: \\(y(t) \\to T(t, f)\\) represents the contribution of frequency \\(f\\) at time \\(t\\)</p> <p>Scaled Wavelet \\(\\phi(t, a, b) = \\phi \\left(\\dfrac{t-b}{a} \\right)\\)</p> <p>The value of \\(T(a, b) =\\) contribution of \\(\\phi(t, a, b)\\) to comprising the signal $$ T(a, b) = \\int y(t) \\cdot \\phi(t, a, b) \\cdot dt $$ Demonstrates the goodness of fit: local similarity</p>"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#signals","title":"Signals","text":"Time Resolution Frequency Resolution Raw Time Series High \\(\\approx 0\\) Fourier Transform \\(\\approx 0\\) High Wavelet Transform Low for small frequenciesHigh for high frequenciesThis is intuitive, as high freq signals are usually short-lived, and small freq signals are usually long-lived"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#synthetic-data-generation","title":"Synthetic Data Generation","text":""},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#cholesky-decomposition","title":"Cholesky Decomposition","text":"<p>\\(C\\) is matrix that lower-diagonal matrix that when multiplied with its transpose gives the correlation matrix \\(\\Sigma\\)</p> <p>$$ C C' = \\Sigma $$ such that \\(\\Sigma\\) is positive-definite with no perfectly-correlated series: non-diagonal elements \\(\\ne 1\\), ie \\(\\Sigma = r_{ij} \\in [0, 1) \\quad \\forall i \\ne j\\)</p>"},{"location":"Economics/Econometrics/09_Time_Series_Decomposition/#data-generation","title":"Data Generation","text":"<p>Consider a multi-variate series \\(Y_t\\) with \\(N(0, \\sigma)\\)</p> <p>Multiplying \\(C\\) with a new random multi-variate series \\(Z_t\\) gives a series \\(Y'_t\\) with the same characteristics of \\(Y_t\\)</p> \\[ \\begin{aligned} Y'_t &amp;= Z_t \\cdot C' \\\\ Y'_t &amp;\\sim N(0, \\Sigma) \\end{aligned} \\] <pre><code>import pandas as pd\nimport numpy as np\n\n# Correlation\ncorr = Y.corr()\n# corr = np.array([ [1, 0.9, -0.9], [0.9, 1, -0.9], [-0.9, -0.9, 1] ])\n\n# Decomposition\nC = np.linalg.cholesky(corr)\n\n# Random Data Generation\nZ = np.random.randn(*Y.shape)\n# Z = 0 + 1 * np.random.randn(1_000, 3)\n\n# Correlating\nY_sim_temp = np.matmul(Z, C.T)\nY_sim = Y.mean(axis=0) + (Y.std(axis=0) * Y_sim_temp)\n\n# Inspection\ndf = pd.DataFrame(Y_sim)\ndf.corr()\n</code></pre> <p></p> <p></p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/","title":"Time Series Modelling","text":"<p>For all the following models</p> <ul> <li>The variable has to be stationary model<ul> <li>Else, use non-stationary \\(\\to\\) stationary transformation</li> </ul> </li> <li>We drop parameters if they are significantly equal to 0</li> <li>Always account for inflation, time value of money</li> </ul> <p>Difficulty</p> <ul> <li>The underlying data-generating process may change<ul> <li>Solution: Give higher sample weight to recent past</li> </ul> </li> </ul> <p>When doing any exploratory analysis, make sure to do in a time-series fashion - Rolling mean, median, quantile - Rolling std, IQR - Rolling correlation, mutual information</p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#uni-variate-vs-causal","title":"Uni-Variate vs Causal","text":"Uni-Variate Multi-variate Characteristic statistical Causal Differencing Causal Predictors Modelling Dymamics Response Preferred for Short-term Long-term Unknown features Known features such as time index, seasonal period length Limitations Temporal confoundingProne to overfitting: Assumes that factors will affect in the same manner throughout"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#temporal-confounding","title":"Temporal confounding","text":"<ul> <li>Lagged value is a mediator and opens backdoor, resulting in learning spurious autocorrelation </li> <li>Makes learning of exogenous effects harder</li> <li>Do not include unnecessary lag when you can model the underlying structure: Causal &gt; Statistical</li> </ul> <pre><code>flowchart TB\nxt1[\"x_t-1\"] --&gt;\nyt1[\"y_t-1\"]\n\nyt1 -.-&gt; yt\n\nxt1[\"x_t-1\"] ----&gt;\nyt[\"y_t\"]</code></pre> <p>Solution - Model response with causal factors - Model causal residuals with non-autoregressive uni-variate features such as trend, seasonality, etc. - Model final residuals with ARIMA     - After modelling everything, you can use lagged/seasonal lag/ error as predictor</p> <p>Danger of overparameterizing in time-series</p> <p>A new worrisome trend in finance is that some academic researchers are advocating for the use of overparameterized/overfit black-box machine learning algorithms to exploit the so-called double-descent phenomenon. While this approach may work well in physical systems, where the underlying laws are relatively constant, it is dangerous in finance. Economic systems are highly dynamic, and the parameters of the data-generating process are unlikely to remain stable, making overparameterized/overfit black-boxes hazardous to investors</p> <p>~ Marcos Lopez de Prado</p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#forecasting-types","title":"Forecasting Types","text":""},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#single-step-forecasting","title":"Single-Step Forecasting","text":""},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#multi-step-forecasting","title":"Multi-Step Forecasting","text":"<p>Rather than building a model for each step, you can define the model as</p> \\[ \\Delta^d y_{t+h} = f(h) + \\sum_{i=1}^p \\alpha_i \\Delta^d y_{t-1} + \\sum_{i=1}^q \\beta_i u_{t-1} + u_t \\] <p>where</p> <ul> <li>\\(h\\) is the horizon</li> <li>\\(f(h)\\) is the captured mapping for \\(h\\). You may have to perform binary encoding (such as one-hot, etc).</li> </ul>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#forecast-confidence-interval","title":"Forecast Confidence Interval","text":"<p>It shows the range upto which the forecast is expected to deviate</p> \\[ \\text{CI }{y_{t+h}} = \\hat y_{t+h} \\pm h \\sigma_{y+h} \\] <p>If standard deviation remains constant across all time points, \\(\\sigma_{y+h} = \\sigma_y\\)</p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#correlogram","title":"Correlogram","text":"If the correlogram of error term wrt previous lags has Accepted? Reason all bars inside the marked lines \u2705 \\(u_t\\) has no auto-correlation one/more bars outside marked lines \u274c \\(u_t\\) has auto-correlation"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#simplebaseline-models","title":"Simple/Baseline Models","text":"Method \\(\\hat y_{t+h}, \\ h&gt;=0\\) Appropriate for Average Average of past values \\(\\overline{ \\{ y_{t-k} \\} }\\) Naive Last value \\(y_{t-1}\\) Random walk process(Consequence of efficient market hypothesis) Seasonal Naive Last seasonal value \\({\\large y}_{t+h-mk}\\)where \\(m=\\) seasonal period Drift Method Last value plus average changeEquivalent to extrapolating line between first and last point \\({\\large y}_{t-1} + \\overline{ \\{ y_t - y_{t-1} \\} }\\) <p>Where \\(k &gt; 0\\)</p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#simulation-models","title":"Simulation Models","text":"<p>We do not use the observed values of the process as inputs</p> <p>Preferred for long-term forecasts</p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#advantages","title":"Advantages","text":"<ol> <li>Simple &amp; Intuitive</li> <li>Non-parametric</li> <li>Easy to aggregate</li> </ol>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#disadvantages","title":"Disadvantages","text":"<ol> <li>Needs lots of data for good sample</li> <li>Assumption required for new products</li> <li>Assumes stationarity</li> </ol>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#synthetic-data-generation-using-gaussian-copula","title":"Synthetic Data Generation using Gaussian Copula","text":"<p>You can use the below property to generate data similar to your original data $$ R \\Alpha^{\u00bd} E \\sim N(0, \\Sigma) $$</p> <ul> <li>\\(R\\) is an \\(n \\times 1\\) random normal vector</li> <li>\\(\\Alpha^{1/2}\\) is an \\(n \\times n\\) diagonal matrix with square roots of eigen values</li> <li>\\(E\\) is matrix of Eigen vectors</li> <li>\\(\\Sigma\\) is covariance matrix of \\(X\\)</li> </ul>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#ets-model","title":"ETS Model","text":"<p>Errors, Trend, Seasonality</p> \\[ \\hat y_t = f(t, S, u_t) \\]"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#monte-carlo-simulation","title":"Monte-Carlo Simulation","text":"<p>Allows us to model the random component of a process; can be used along with an existing model for systematic component</p> <p>System needs to describable in terms of pdf</p> \\[ \\hat y_t = f(\\hat y_{t-1}, u_t) \\]"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#fir-model","title":"FIR Model","text":"<p>Only using input features</p> \\[ \\hat y_t = f(X_{t-k}, u_t) \\] <p>\\(k\\) is the no of lagged input features</p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#output-error-modelrecursive-forecasting","title":"Output Error Model/Recursive Forecasting","text":"<p>FIR model using past estimations also. Ideally you should develop a model for this (infinite-step forecasting), and then work on using the same model for multi-step forecasting.</p> \\[ y_t = \\sum_{i=p} \\hat y_{t-i} +\\sum_{i=\\textcolor{hotpink}{0}} \\hat X_{t-k} + u_t \\]"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#state-space-models","title":"State Space Models","text":""},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#kalman-filter","title":"Kalman Filter","text":""},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#gmm","title":"GMM","text":"<p>Generalized method of moments</p> <p>Find relationship b/w moments of random variables</p> <p>Yule-Walker estimates</p>"},{"location":"Economics/Econometrics/10_Time_Series_Modelling/#types-of-errors","title":"Types of Errors","text":"Error Type Amplitude Phase"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/","title":"Auto-Regressive Models","text":""},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#ar-modelprocess","title":"AR Model/Process","text":"<pre><code>flowchart LR\nyt1[\"y&lt;sub&gt;t-1&lt;/sub&gt;\"] &amp; ut[\"u&lt;sub&gt;t&lt;/sub&gt;\"] --&gt; yt[\"y&lt;sub&gt;t&lt;/sub&gt;\"]</code></pre> <p>AutoRegressive Model</p> <p>Variable is regressed using its own lagged values; we assume \\(y_t\\) depends only on its own lagged values</p> <p>More lags \\(\\implies\\) we lose more date points \\(\\implies\\) low degree of freedom</p>"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#types","title":"Types","text":"<p>AR\\((p)\\) model means that there are \\(p\\) lags involved in the AR model</p> \\[ \\text{AR}(p) = \\sum_{i=1}^{p} \\alpha_i y_{t-i} + u_t \\] Model Order(No of lags involved) Example AR\\((1)\\) 1There is only \\(1\\) particular lag (not necessarily \\(y_{t-1}\\)) \\(y_t = \\beta_1 y_{t-\\textcolor{hotpink}{1}} + u_t \\\\ \\text{or} \\\\ y_t = \\beta_1 y_{t-\\textcolor{hotpink}{2}} + u_t \\\\ \\text{or} \\\\ \\dots \\\\ y_t = \\beta_1 y_{t-\\textcolor{hotpink}{100}} + u_t\\) AR\\((2)\\) 2 \\(y_t = \\beta_1 y_{t-\\textcolor{hotpink}{1}} + u_t,  y_{t-\\textcolor{hotpink}{2}} + u_t \\\\ \\text{or} \\\\ y_t = \\beta_1 y_{t-\\textcolor{hotpink}{1}} + u_t,  y_{t-\\textcolor{hotpink}{100}} + u_t\\)"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#ma-model","title":"MA Model","text":"<pre><code>flowchart LR\nyt1[\"u&lt;sub&gt;t-1&lt;/sub&gt;\"] &amp; ut[\"u&lt;sub&gt;t&lt;/sub&gt;\"] --&gt; yt[\"y&lt;sub&gt;t&lt;/sub&gt;\"]</code></pre> <p>Moving Averages Model</p> <p>MA\\((q)\\) model means that there are \\(q\\) lagged error differences involved in the MA model</p> \\[ \\text{MA}(q) = \\sum_{i=1}^{q} \\beta_i u_{t-i} + u_t \\] <p>\\(u_{t-i}\\) is a multiple regression with past errors as predictors. Don\u2019t confuse this with moving average smoothing!</p> Model Order(No of lags involved) Example MA\\((1)\\) 1There is only \\(1\\) particular lag (not necessarily \\(u_{t-1}\\)) \\(y_t = \\beta_1 u_{t-\\textcolor{hotpink}{1}} + u_t \\\\ \\Big(\\text{ie, } y_t = \\beta_1 (y_{t-\\textcolor{hotpink}{1}}-E[y_{t-\\textcolor{hotpink}{1}}]) + u_t \\Big)\\) MA\\((2)\\) 2 \\(y_t = \\beta_1 u_{t-\\textcolor{hotpink}{1}} + \\beta_2 u_{t-\\textcolor{hotpink}{2}} + u_t\\)"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#arma","title":"ARMA","text":"<p>Autoregressive Moving Average Model</p> <pre><code>flowchart LR\nyt1[\"y&lt;sub&gt;t-1&lt;/sub&gt;\"] &amp; ut1[\"u&lt;sub&gt;t-1&lt;/sub&gt;\"] &amp; ut[\"u&lt;sub&gt;t&lt;/sub&gt;\"] --&gt; yt[\"y&lt;sub&gt;t&lt;/sub&gt;\"]</code></pre> <p>ARMA\\((p, q)\\) model means that there are __ involved in the ARMA model</p> <ul> <li>\\(p\\) autoregressive lags</li> <li>\\(q\\) moving averages lags</li> </ul> \\[ \\text{ARMA}(p, q) = \\sum_{i=1}^{p} \\alpha_i y_{t-i} + \\sum_{i=1}^{q} \\beta_i u_{t-i} + u_t \\]"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#arima-process","title":"ARIMA Process","text":"<p>ARIMA\\((p, d, q)\\) model means</p> <ul> <li>\\(p\\)</li> <li>\\(d\\)</li> <li>\\(q\\)</li> </ul> \\[ \\Delta^d y_t = \\sum_{i=1}^p \\alpha_i \\Delta^d y_{t-1} + \\sum_{i=1}^q \\beta_i u_{t-1} + u_t \\] <p>If \\(y_t\\) is an integrated series of order(\\(\\textcolor{hotpink}{1}\\)), then we can use ARIMA\\((1, \\textcolor{hotpink}{1}, 1)\\)</p> \\[ \\Delta y_t = \\alpha_1 y_{t-1} + \\beta_1 u_{t-1} + u_t \\]"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#box-jenkins-decision-tree","title":"Box-Jenkins Decision Tree","text":"<p>for ARIMA Model Building</p> <pre><code>flowchart LR\nim[Identify Model] --&gt;\nep[Estimate Paramaters] --&gt;\nd --&gt;\nForecast\n\nd --&gt; rm[Revise Model] --&gt; ep\n\nsubgraph d[Diagnostics]\n    r2[R_adj^2]\n    RMSE\nend</code></pre> ACF Correlogram PACF Correlogram -&gt; Conclusion Model No significant spikes No significant spikes White Noise Damps out Spikes cut off at lag \\(p\\) Stationary AR\\((p)\\) Spikes cut off at lag \\(q\\) Damps out Stationary MA\\((q)\\) Damps out Damps out Stationary ARMA\\((p, q)\\) Spikes damp out very slowly Spikes cut off at lag \\(p\\) Random WalkNon-Stationary Monte-Carlo SimulationTake difference"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#var","title":"VAR","text":"<p>Vector AutoRegressive Model</p> <p>Each input variable time series should also be stationary</p> <p>\\(\\text{VAR}(p) \\equiv \\text{VAR}(1)\\) where $$ \\begin{aligned} z_t &amp;= { X_t, X_{t-1}, \\dots, X_{t-p+1} } \\ z_{t-1} &amp;= { X_{t-1}, X_{t-2}, \\dots, X_{t-p} } \\ D &amp;= \\begin{bmatrix} c \\ 0_m \\ \\vdots \\ 0_m \\end{bmatrix}, A = \\begin{bmatrix} \\phi_1  &amp; \\phi_2    &amp; \\cdots &amp; \\phi_p \\ I_m         &amp; 0             &amp; \\cdots &amp; 0 \\ \\vdots  &amp; \\ddots    &amp; \\ddots &amp; \\vdots \\ I_m         &amp; 0             &amp; I_m &amp; 0 \\end{bmatrix}, F = \\begin{bmatrix} u_t \\ 0_m \\ \\vdots \\ 0_m \\end{bmatrix} \\ \\implies z_t &amp;= D + A y_{t-1} + F \\end{aligned} $$</p>"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#stationary-varp","title":"Stationary VAR(p)","text":"<p>A VAR(p) model is stationary if one/both of the following</p> <ul> <li>All eigen values of the companion matrix \\(A\\) have modulus less than 1</li> <li>All roots of \\(\\text{det} ( \\ I_m - \\sum_{i=1}^p \\phi_i z^p \\ ) = 0\\) as a function of the complex variable \\(z\\) are outside the complex unit circle \\(\\vert z \\vert \\le 1\\)</li> </ul> <p>Mean: $$ \\begin{aligned} C &amp;= (I - \\sum_i^p \\phi_i) \\mu \\ E[y_t] \\implies \\mu &amp;= (I - \\sum_i^p \\phi_i)^{-1} C \\ y_t - \\mu &amp;= \\sum_i^p \\phi_i[y_{t-i} - \\mu]  + u_t \\end{aligned} $$</p>"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#optimality","title":"Optimality","text":"<p>Component-wise OLS estimates are equal to the GLS estimates accounting for the general case of innovation covariance matrix with possibly unequal comment variance and non-zero correlations </p>"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#varma","title":"VARMA","text":"<p>Vector AutoRegressive Moving Averages</p> <p>Simultaneous equations</p> <p>Consider the following regression</p> \\[ y_t = \\alpha_1 {x_1}_t + \\alpha_2 {x_2}_t + u_t \\]"},{"location":"Economics/Econometrics/11_Autoregressive_Modelling/#vecm","title":"VECM","text":"<p>Vector Error-Correction Model</p> <p>Useful when you want to perform VARMA without losing the \u201cstructure\u201d associated with differencing to enforce stationarity</p>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/","title":"Volatility Modelling","text":""},{"location":"Economics/Econometrics/12_Volatility_Modelling/#historicalsample-volatility-measures","title":"Historical/Sample Volatility Measures","text":"<p>Annualized Vol $$ \\text{Annualized Vol} = \\begin{cases} s \\sqrt{365.25} &amp; \\text{Daily data} \\ s \\sqrt{52} &amp; \\text{Weekly data} \\ s \\sqrt{12} &amp; \\text{Monthly data} \\end{cases} $$</p> <ul> <li>Simple Moving average of volatility</li> <li>Exponential Moving average of volatility</li> <li>Simple regression of volatility</li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#geometric-brownian-motion-model","title":"Geometric Brownian Motion Model","text":"<p>Assumes that volatility over time is stationary $$ \\begin{aligned} dy_t &amp;= \\mu y_t  dt + \\sigma y_t   dW_t \\ \\implies \\dfrac{dy_t}{y_t} &amp;= \\mu  dt + \\sigma  dW_t \\end{aligned} $$</p> <ul> <li>\\(dy_t\\) is infinitesimal increment in series</li> <li>\\(\\mu\\) is mean difference (per unit team) [drift term]</li> <li>\\(\\sigma\\) is volatility of series</li> <li>\\(dW_t\\) is infinitesimal increment of standard Brownian motion/Wiener process</li> <li>\\(dW_t = N(0, t'-t)\\)</li> <li>\\(dW_i\\) and \\(dW_j\\) are independent</li> </ul> \\[ \\begin{aligned} \\text{Let } R_j &amp;= \\log(y_j/y_{j-1}) \\\\ R_j &amp;\\sim N(\\mu \\Delta_j, \\sigma^2 \\Delta_j), \\Delta_j = t_j - t_{j-1} \\end{aligned} \\] <p>This is general case, to incorporate the possibility that the observations are at equal or unequal time intervals</p> <ul> <li>If \\(\\Delta j = 1\\)</li> <li>\\(\\hat \\mu = \\bar R\\)</li> <li>\\(\\hat \\sigma^2 = E[(R_t - \\bar R)^2]\\)</li> <li>else</li> <li></li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#garman-klass-estimator","title":"Garman-Klass Estimator","text":"<p>More information than just closing</p> <p>Sample information of</p> <ul> <li>Period-close (last)</li> <li>Period-high (max)</li> <li>Period-low (min)</li> <li>Period-open (first)</li> </ul> <p>Assume that</p> <ul> <li>\\(\\mu=0, \\Delta_j = 1\\)</li> <li>\\(f \\in (0, 1)\\) denote the fraction of the day prior to the market open</li> <li>\\(f \\times T\\) between the previous day\u2019s closing and the current day\u2019s opening, and an interval of length</li> <li>\\((1-f) \\times T\\) between the current opening and the current closing, during which the market is open for trading</li> <li>\\(T\\) is the time frame between two consecutive closing prices</li> </ul> \\[ \\begin{aligned} C_j &amp;= \\log \\vert y_{t_j} \\vert \\\\ O_j &amp;= \\log \\vert y_{t_{j-1}+f} \\vert \\\\ H_j &amp;= \\max_{t_{j-1} + f \\le t \\le t_j} \\log \\vert y_t \\vert \\\\ L_j &amp;= \\min_{t_{j-1} + f \\le t \\le t_j} \\log \\vert y_t \\vert \\end{aligned} \\] Return Series Denotation Estimate E[Estimate] Var(Estimate) Efficiency of estimate compared to close-close Close-Close \\(\\hat \\sigma_{cc}^2\\) \\((C_1 - C_0)^2\\) \\(\\sigma^2\\) \\(2 \\sigma^4\\) Close-Open \\(\\hat \\sigma_{co}^2\\) \\(\\dfrac{(O_1 - C_0)^2}{f}\\) \\(\\sigma^2\\) \\(2 \\sigma^4\\) 1 Open-Close \\(\\hat \\sigma_{oc}^2\\) \\(\\dfrac{(C_1 - O_1)^2}{1-f}\\) \\(\\sigma^2\\) \\(2 \\sigma^4\\) 1 Combining close-open &amp; open-close \\(\\hat \\sigma_*^2\\) \\(\\frac{1}{2}(\\hat \\sigma^2_{co} + \\hat \\sigma^2_{oc})\\) \\(\\sigma^2\\) \\(\\sigma^4\\) 2 Parkinson \\(\\hat \\sigma^2_{p}\\) \\(\\dfrac{(H_1-L_1)^2}{4 \\cdot \\log 2}\\)\\(f=0\\) 5.2 Garman &amp; Klass w/ \\(\\hat \\sigma^2_p\\) \\(\\hat \\sigma^2_{gkp}\\) \\(a \\hat \\sigma^2_{co} + (1-a) \\hat \\sigma^2_p\\)\\(a \\approx 0.17; 0 &lt; f &lt; 1\\) 6.2 \u201cBest Analytic Scale-Invariant Estimator\u201d of Volatility \\(\\hat \\sigma^2_{**}\\) \\(0.511(u_1-d_1)^2 - 0.019[ \\ c_1(u_1+d_1) - 2 u_1 d_1 \\ ] - 0.383 c_1^2\\)\\(u_j = H_j - O_j; d_j = L_j-O_j; c_j = C_j - O_j\\) are the normalized high/low/close values 7.4 Garman &amp; Klass w/ \\(\\hat \\sigma^2_{**}\\) \\(\\hat \\sigma^2_{gk**}\\) \\(a \\dfrac{(O_1 - C_0)^2}{f} + (1-a)\\dfrac{\\sigma^2_{**}}{1-f}\\)\\(a \\approx 0.12; 0&lt;f&lt;1\\) 8.4 \\[ \\hat \\sigma^2_{co} \\text{ and } \\hat \\sigma^2_{oc} \\text{ are independent} \\] <p>These expectations &amp; variances of volatility estimate are obtained as standard deviation follows \\(\\chi^2\\) distribution</p>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#poisson-jump-diffusion-model","title":"Poisson Jump Diffusion Model","text":"<p>Assumes that volatility over time is stationary</p> <p>Over time, a Brownian motion process is fully-continuous. It experiences shocks according to a Poisson process.</p> <ul> <li>Model is a Poisson mixture of Gaussian distributions</li> <li>Moment-Generating function derived as that of random sum of independent random values</li> <li>EM Algorithm expressible in closed form</li> <li>Shocks treated as latent variables which simplify computations</li> <li>Algo provides posterior estimates of number of shocks per time period</li> </ul> \\[ \\dfrac{dy_t}{t} = \\mu dt + \\sigma dW_t + \\gamma \\sigma Z_t d \\Pi_t \\] <ul> <li>\\(dy_t\\) = infinitesimal increment in series</li> <li>\\(\\mu =\\) mean return (per unit time)</li> <li>\\(\\sigma =\\) diffusion volatility of process</li> <li>\\(dW_t =\\) increment in standard Wiener process</li> <li>\\(d \\Pi_t =\\) increment of a Poisson process with rate \\(\\lambda\\) modelling the shock process</li> <li>\\((\\gamma \\sigma) \\times Z_t\\) is the magnitude of a return shock</li> <li>\\(Z_t = N(0, 1)\\)</li> <li>\\(\\gamma =\\) scale (\\(\\sigma\\) units) of shock magnitudes</li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#arch","title":"ARCH","text":"<p>AutoRegressive Conditional Heteroskedacity models</p> <ul> <li>Handles time-dependent volatility</li> <li>Specifies relative to discrete-time process for time series</li> <li>Implies that \\((u_t)^2\\) is an AR process</li> </ul> <p>Basically AR model of variance</p> <p>Type of Volatility Clustering</p> <pre><code>flowchart LR\nyt1[\"y&lt;sub&gt;t-1&lt;/sub&gt;\"] --&gt; sigmat[\"&amp;sigma;&lt;sub&gt;t&lt;/sub&gt;\"]\n\nsigmat &amp; ut[\"u&lt;sub&gt;t&lt;/sub&gt;\"] --&gt; yt[\"y&lt;sub&gt;t&lt;/sub&gt;\"]</code></pre> \\[ \\begin{aligned} y_t &amp;= \\sigma_t u_t \\\\ \\implies R_t &amp;= \\log \\vert y_t/y_{t-1} \\vert \\\\ &amp;= \\mu_t + u_t \\\\ u_t &amp;= Z_t \\times \\sigma_t; Z_t = N(0, 1) \\\\ \\implies \\sigma^2_t &amp;= \\text{Var}(R_t | F_{t-1}) \\\\ &amp;= \\alpha_0 + \\sum_{i=1}^p \\alpha_i (u_{t-i})^2 &amp; (\\alpha_i \\ge 0; \\sum_{i=1}^p \\alpha_i &lt; 1) \\end{aligned} \\] <p>where</p> <ul> <li>\\(\\mu_t\\) is the mean return conditional on \\(F_{t-1}\\)</li> <li>\\(F_{t-1}\\) is the information available till time \\(t-1\\)</li> </ul> <p>Adding \\((u_t)^2 - \\sigma^2_t\\) to both sides of ARCH model $$ (u_t)^2 = \\alpha_0 + \\sum_{i=1}^p \\alpha_i (u_{t-i})^2 + (u_t)^2 - \\sigma^2_t $$ where</p> <ul> <li>\\(E[(u_t)^2 - \\sigma^2_t \\vert F_t] = 0\\)</li> <li>\\(\\text{Var}[(u_t)^2 - \\sigma^2_t \\vert F_t] = \\text{Var}[{(u_t)^2}] = 2 \\sigma^4_t\\)</li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#lagrange-multiplier-test","title":"Lagrange Multiplier Test","text":"\\[ H_0: \\alpha_i = 0 , \\forall i \\in [1, p] \\] <ol> <li>Fit \\(AR(p)\\) on \\((u_t)^2\\)</li> </ol> <p>The \\(AR(p)\\) estimates of parameters are not MLEs under gaussian assumptions; they correspond to quasi-MLE</p> <ol> <li> <p>LM test statistic = \\(nR^2\\), where \\(R^2=\\) R-Squared of fitted \\(AR(p)\\)</p> </li> <li> <p>Under \\(H_0\\), \\(n R^2 \\approx {\\chi^2}_p\\)</p> </li> </ol>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#limitation","title":"Limitation","text":"<p>It can be \u201cbursty\u201d: Sudden jumps in volatility rather than smooth ones. Hence, it cannot effectively model persistent volatility</p>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#garch","title":"GARCH","text":"<p>Generalized AutoRegressive Conditional Heteroskedacity models</p> <p>Basically ARMA model of variance</p> <p>Type of Volatility Clustering</p> <pre><code>flowchart LR\nyt1[\"y&lt;sub&gt;t-1&lt;/sub&gt;\"] &amp; sigmat1[\"&amp;sigma;&lt;sub&gt;t-1&lt;/sub&gt;\"] --&gt; sigmat[\"&amp;sigma;&lt;sub&gt;t&lt;/sub&gt;\"]\nsigmat &amp; ut[\"u&lt;sub&gt;t&lt;/sub&gt;\"] --&gt; yt[\"y&lt;sub&gt;t&lt;/sub&gt;\"]</code></pre> \\[ \\begin{aligned} y_t &amp;= \\sigma_t u_t \\\\ \\sigma^2_t &amp;= \\alpha_0 + \\sum_{i=1}^p \\alpha_i (u_{t-i})^2 + \\sum_{j=1}^q \\beta_j \\sigma^2_{t-j} \\\\ &amp; (\\alpha_i \\ge 0; \\beta_j \\ge 0) \\end{aligned} \\] \\[ \\text{Garch}(p, q) = \\text{ARMA}( \\ \\max(p, q) \\ , q  \\ ) \\]"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#garch1-1","title":"GARCH(1, 1)","text":"\\[ \\sigma^2_t = \\alpha_0 + \\alpha_1 (u_{t-1})^2 + \\beta_1 \\sigma^2_{t-1} \\] <ul> <li>Fits most financial time-series</li> <li>Implies a ARMA(1, 1) with \\((u_t)^2 - \\sigma^2_t \\sim WN(0, 2 \\sigma^4)\\)</li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#diagonal-vectorization","title":"Diagonal Vectorization","text":"<p>\\(\\Sigma_t\\) is conditional covariance</p> <p></p> <p>Advantage</p> <ul> <li>Simple element-wise GARCH model</li> </ul> <p>Disadvantage</p> <ul> <li>\\(\\Sigma_t\\) not guaranteed to be positive-definite</li> <li>Prone to overfitting, so dimensionality reduction required</li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#stochastic-volatility-models","title":"Stochastic Volatility Models","text":""},{"location":"Economics/Econometrics/12_Volatility_Modelling/#implied-volatility","title":"Implied Volatility","text":"<p>From options/derivatives</p>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#volatility-clustering","title":"Volatility Clustering","text":"<ul> <li>Large \\(u_t^2\\) follow large \\(u_{t-1}^2\\)</li> <li>Small \\(u_t^2\\) follow large \\(u_{t-1}^2\\)</li> </ul> <p>GARCH Models can prescribe</p> <ul> <li>Large \\(\\sigma_t^2\\) follow large \\(\\sigma_{t-1}^2\\)</li> <li>Small \\(\\sigma_t^2\\) follow small \\(\\sigma_{t-1}^2\\)</li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#extended-garch","title":"Extended GARCH","text":"<ul> <li>EGARCH</li> <li>TGARCH</li> <li>PGARCH</li> <li>GARCH-In-Mean</li> </ul>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#uncertainty-quantification","title":"Uncertainty Quantification","text":"<p>The most appropriate solution would be to use \\(\\chi^2\\) distribution</p>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#before-you-start","title":"Before you start","text":"<p>Firstly, make sure to use a GLM with Gamma distribution and log link as variance is a \\(\\chi^2\\) distributed variable. Do not use OLS as it assumes normally-distributed variable.</p>"},{"location":"Economics/Econometrics/12_Volatility_Modelling/#confidence-interval","title":"Confidence Interval","text":"<p>Confidence intervals for significance level \\(\\alpha\\) is be given by</p> \\[ [ Q(\\sigma^2_t, \\alpha/2), Q(\\sigma^2_t, 1 - \\alpha/2) ] \\] <p>where - \\(Q(\\sigma^2_t, q) = \\dfrac{(n-1) {\\hat \\sigma_t}^2}{\\chi^2_q}\\) - \\(q\\) is the quantile required (ie, 5<sup>th</sup> quantile, 95<sup>th</sup> quantile, etc) - \\({\\hat \\sigma}^2_t\\) is the predicted volatility by the GARCH model - \\(n\\) is the number of sample points in the training data - \\(\\chi^2_q\\) is the \\(\\chi^2\\) for given critical value</p>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/","title":"Cointegration Modelling","text":""},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#error-correction-models","title":"Error Correction Models","text":"\\[ \\begin{aligned} \\Delta m_t &amp;= \\lambda_m (u_{t-1}) + \\epsilon_{mt} \\\\ &amp;= \\lambda_m (blah blah) + \\epsilon_{mt} \\\\ \\Delta p_t &amp;= \\\\ \\Delta y_t &amp;=  \\end{aligned} \\] <ul> <li>\\(\\epsilon\\) is white noise error</li> <li>\\(\\lambda\\) are velocity of adjustment parameters</li> </ul> <p>Atleast one of the \\(\\lambda\\) should be significant, otherwise there is no error correction \\(\\implies\\) no cointegration</p> <p>Cointegration and error correction are equivalent representation</p> <p>~ Granger representation theorem</p>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#vector-regressionstructural-estimation-model","title":"Vector regression/Structural estimation model","text":"<p>Used when there is no cointegration</p> <p>I missed this</p> <p>If the values of \\(\\lambda\\) are zero, then it is a simple VAR model and there is no cointegration. </p> <p></p>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#example-quantity-theory-of-money","title":"Example: Quantity Theory of Money","text":"\\[ MV = \\underbrace{PY}_{\\text{GDP}} \\] Integrated of order \\(M\\) Total quantity of money \\(I(1)\\) \\(V\\) Velocity of money Number of times a unit of currency is transferred in a year N/A(Constant value) \\(P\\) Price \\(I(1)\\) \\(Y\\) Real quantity of Output \\(I(1)\\) <p>As they are \\(I(1)\\), they are not mean-reverting variables. Hence, taking log on both sides of equation, and then transposing</p> \\[ \\beta_0 + \\beta_1 m_t - \\beta_2 p_t - \\beta_3 y_t = u_t \\] <p>Velocity is a constant, which is an intercept. Here it is represented by \\(\\beta_0\\), but can also represented by \\(1\\cdot V\\)</p> <p>If \\(u_t\\) is \\(I(0) \\implies M, V, P, Y\\) are cointegrating</p>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#notes","title":"Notes","text":"<ol> <li>There can be multiple cointegrating vectors \\(\\{\\beta_0, \\beta_1, \\beta_2, \\beta_3 \\} = \\{\\lambda \\beta_0, \\lambda \\beta_1, \\lambda \\beta_2, \\lambda \\beta_3 \\} \\iff \\lambda \\ne 0\\)</li> <li>If \\(m\\) and \\(p\\) are \\(I(2)\\) whereas \\(y\\) is \\(I(1)\\). The linear combination of these three variables will be \\(I(2)\\), hence the 3 are not cointegrated</li> <li>However, if a linear combination \\(\\beta_1 m + \\beta_2 p\\) is \\(I(1)\\), and this is cointegrated with y which is \\(I(1)\\), then we say there is multi-cointegration</li> <li>if monetary policy follows feedback rule that changes money supply based on inflation, then inflation will be another cointegrated variable</li> </ol>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#granger-causality","title":"Granger Causality","text":"<p>Let\u2019s say we have 2 variables \\(x, y\\). We can check if \\(x\\) granger causes \\(y\\)</p> \\[ y_t = \\beta_1 y_{t-1} + \\beta_2 x_{t-1} + u_t \\]"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#hypotheses","title":"Hypotheses","text":"<ul> <li>\\(H_0: \\beta_2 = 0\\) </li> <li>\\(y\\) is independent of \\(x\\)</li> <li>\\(x\\) does not granger cause \\(y\\)</li> <li>\\(H_1: \\beta_2 \\ne 0\\)</li> <li>\\(x \\to y\\)</li> <li>\\(x\\) granger causes \\(y\\)</li> </ul>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#procedure","title":"Procedure","text":"<ol> <li>We check if the \\(R_{adj}^2\\) has increased by incorporating \\(x_{t-1}\\), when compared to without it \\((y_t = \\beta_1 y_{t-1} + u_t)\\)</li> <li>Do a hypothesis test</li> <li>If \\(p \\le 0.05,\\) reject null hypothesis, and hence conclude that \\(x \\to y\\)</li> </ol>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#spread","title":"Spread","text":"<p> $$ \\begin{aligned} y_{1t} &amp;= x_t + u_{1t} \\ y_{2t} &amp;= \\gamma x_t + u_{2t} \\ z_t &amp;= y_{1t} - y_{2t} \\quad \\text{(Spread)}\\ &amp;= y_{1t} - \\gamma y_{2t} \\ &amp;= u_{1t} - \\gamma u_{2t} \\ y_1, y_2 &amp;\\text{ are co-integrating} \\iff z_t \\to \\text{Stationary Process} \\end{aligned} $$</p> <p>This mean-reverting tendency of the spread can be used for \u201cpairs trading\u201d/\u201cstatistical arbitrage\u201d</p> <p></p>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#estimating-gamma","title":"Estimating \\(\\gamma\\)","text":""},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#simple","title":"Simple","text":"\\[ \\begin{aligned} z_t \\implies y_{1t} - \\gamma y_{2t} &amp;= \\mu + u_t \\\\ y_{1t} &amp;= \\mu + \\gamma y_{2t} + u_t \\end{aligned} \\] <p>Perform linear regression for \\(\\gamma\\)</p>"},{"location":"Economics/Econometrics/13_Cointegration_Modelling/#kalman","title":"Kalman","text":"\\[ \\begin{aligned} z_t \\implies y_{1t} - \\gamma_\\textcolor{hotpink}{t} y_{2t} &amp;= \\mu_\\textcolor{hotpink}{t} + u_t \\\\ y_{1t} &amp;= \\mu_\\textcolor{hotpink}{t} + \\gamma_\\textcolor{hotpink}{t} y_{2t} + u_t \\\\ \\mu_{t+1} &amp;= \\mu_t + \\eta_{1t} \\\\ \\gamma_{t+1} &amp;= \\gamma_t + \\eta_{2t} \\end{aligned} \\]"},{"location":"Economics/Econometrics/14_Value_Modelling/","title":"Value Modelling","text":"VAR VAG Meaning Value at Risk Value at Gain \\(p_x = x \\%\\) VAR/VAG is values for __ of distribution Bottom \\(x \\%\\) Top \\(x \\%\\)Bottom \\((1-x) \\%\\) Probability of __ given level Losses &lt; Gains &gt; Preferred for Lending (concerned about receiving repayment) Investing (interested in gain) Example <p>Note: Both are one-sided tails</p>"},{"location":"Economics/Econometrics/14_Value_Modelling/#target-curve","title":"Target Curve","text":"<p>Cumulative Distribution of outcomes (rarely frequency distribution)</p> <p>Goes from VAR % to VAG %</p> <p></p>"},{"location":"Economics/Econometrics/14_Value_Modelling/#dominance","title":"Dominance","text":"<p>If target curve 1 always to right of another, it dominates</p> <p>But it is not necessary that one alternative always performs better than other in all situations, as best case for one situation may be bad for another situation</p>"},{"location":"Economics/Econometrics/14_Value_Modelling/#evaluation-methods","title":"Evaluation Methods","text":"Method Historical Percentile of historical values Parametric/Variance-Covariance 1. Calculate covariance matrix of all securities2. Annualize them3. Calculate portfolio standard deviation: \\(\\sigma_p = \\sqrt{w' \\Sigma w}\\) Monte Carlo Simulation 1. Obtain dist statistics: Mean, Variance, \u20262. Run simulation3. Get the required percentiles"},{"location":"Economics/Econometrics/15_Time_Series_Filters/","title":"Filters","text":"<p>Algorithms that use uncertain measurements from sensors to predict unknown variable with acceptable accuracy, to estimate the current state.</p> <p>Help identify underlying trends, by smoothing time series and hence filtering out noise</p> <p>They are not for prediction</p>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#working","title":"Working","text":"\\[ \\begin{aligned} y_t &amp;= y^*_t + u_{t, \\text{PN}} + u_{t, \\text{MN}} \\\\ \\implies {\\tilde y}_t &amp;= E[y_t] \\\\ &amp;= E[y^*_t] + E[u_{t, \\text{PN}}] + E[u_{t, \\text{MN}}] \\\\ &amp;= y^*_t + \\mu_\\text{PN} + \\mu_\\text{MN} \\\\ &amp;= y^*_t + 0 + 0 &amp; (\\mu_\\text{MN} = \\mu_\\text{PN} = 0) \\\\ &amp; \\approx y^*_t \\end{aligned} \\] <p>where</p> <ul> <li>\\(\\tilde y_t=\\) smoothed/filtered value</li> <li>\\(y_t=\\) observed value</li> <li>\\(y^*_t=\\) true value</li> <li>\\(u_{t, \\text{PN}} =\\) Process noise</li> <li>\\(u_{t, \\text{MN}} =\\) Measurement noise</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#filter-design","title":"Filter Design","text":"<ol> <li>Define problem which consists of the state</li> <li>Define the motion model</li> <li>Define how the state will be measured</li> <li>Define uncertainty in system\u2019s dynamic model</li> <li>Implement &amp; test the filter in controlled environment with known inputs &amp; outputs</li> <li>Tune the filter</li> </ol>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#notes","title":"Notes","text":"<ul> <li>Window size = Duration of Seasonality will remove it</li> <li>Be wary of over-smoothing</li> <li>Never go live without tuning filter</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#types-wrt-time-dependence","title":"Types wrt Time Dependence","text":"<ul> <li>Centered</li> <li>Lagging</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#filters-vs-rolling-statistics","title":"Filters vs Rolling Statistics","text":"<p>The Kalman filter is better suited for estimating things that change over time. The Kalman Filter lets you add more information about how the system you're filtering works. In other words, you can use a signal model to improve the output of the filter.</p> <p>Sure, a moving average filter can give very good results when you're expecting a close-to-constant output. But as soon as the signal you're modelling is dynamic (think speech or position measurements), then the simple moving average filter will not change quickly enough (or at all) compared with what the Kalman Filter will do.</p> <p>The Kalman filter uses the signal model, which captures your knowledge of how the signal changes, to improve its output in terms of the variance from \"truth\".</p>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#concepts","title":"Concepts","text":"Denotation Measurement \\(y_{t, t}\\) Estimation Current state \\(\\hat y_{t, t}\\) Prediction Future state \\(\\hat y_{t, t-1}\\)"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#applications","title":"Applications","text":"<p>These can be used in any field, but a few examples</p> <ul> <li>Guidance</li> <li>Navigation</li> <li>Control of vehicles</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#batch-vs-recursive","title":"Batch vs Recursive","text":"Batch Recursive Complexity \\(O(n)\\) \\(O(1)\\) Preferred"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#uncertainty","title":"Uncertainty","text":"<p>Variance of measurement errors provided by scale vendor/derived through calibration; Even though we can\u2019t accurately know the estimate error, we can estimate the uncertainty in the estimates</p> <p>Most modern systems are equipped with multiple sensors that provide estimation of hidden/unknown variables based on series of measurements</p> <p>One of the biggest challenges of tracking and control systems is to provide accurate and precise estimation of the hidden variables in the presence of uncertainty.</p>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#bias-variance","title":"Bias &amp; Variance","text":"<p>Very similar to Machine Learning Prediction Bias &amp; Variance </p>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#measurement-filters","title":"Measurement Filters","text":"System Alpha Static Beta Dynamic Adaptive Dynamic"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#alpha-filter","title":"Alpha Filter","text":""},{"location":"Economics/Econometrics/15_Time_Series_Filters/#average-filter","title":"Average Filter","text":"\\[ \\begin{aligned} &amp;\\text{Estimated current state} \\\\ &amp;= \\text{Mean of all measurements} \\\\ &amp;=\\text{Predicted current state} \\\\ &amp;\\quad + \\text{Factor} \\times (\\text{Measurement - Predicted current state}) \\end{aligned} \\] \\[ \\begin{aligned} \\hat y_{t, t} &amp;= \\hat y_{t, t-1} + \\alpha_t (y_t - \\hat y_{t, t-1}) \\\\ &amp;= \\alpha_t y_t + (1-\\alpha_t) \\hat y_{t, t-1}\\\\ \\hat y_{1, 0} &amp;= 0 \\\\ \\alpha_t &amp;= \\dfrac{1}{t} \\end{aligned} \\] <p>The \\(\\alpha\\) factor is called as Gain, and is taken as \\(\\alpha_t = \\dfrac{1}{t}\\). As number of measurements increase, each successive measurement has less weight in estimation, as \\(t \\uparrow \\implies \\alpha \\downarrow\\)</p> <p>Gives the less weight to recent data compared to past data</p> <p>Kalman filter requires an initial guess as a preset; it may be approximate. </p> <p>\\((y_{t, t} - \\hat y_{t, t-1})\\) is called the measurement residual</p>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#beta-filter","title":"Beta Filter","text":"\\(\\tilde y_{t+h}\\)(Recursive Additive) \\(\\tilde y_{t+h}\\)(Batch Additive) Weightage to history Parameter SMASimple Moving Average \\(\\tilde L_t\\)\\(\\tilde L_t = \\dfrac{1}{w} (y_t - y_{t-w}) + \\hat y_{t, t-1}\\) \\(\\dfrac{1}{w} \\sum_{i=0}^{w-1} y_{t-i}\\) Equally for recent and past history \\(w\\): Rolling Window Size EMAExponential Moving Average \\(\\tilde L_t\\)\\(\\tilde L_t = \\alpha_t y_t + (1-\\alpha_t) \\hat y_{t, t-1}\\) \\(\\sum_{i=0}^{w-1} \\alpha^{i+1} y_{t-i}\\) More weight to recent history Assumes that whole history is encapsulated in \\({\\tilde y}_{t-1}\\) Recommended \\(\\alpha=\\dfrac{2}{\\text{Window Size}}\\) Double EMA(Holt) \\(\\tilde L_t + h \\tilde T_t\\)\\(\\tilde T_t = \\beta(\\tilde L_t - \\tilde L_{t-1}) + (1-\\beta) \\tilde T_{t-1}\\)\\(\\tilde L_t = \\alpha L_t + (1-\\alpha) (\\tilde L_{t-1} + \\tilde T_{t-1})\\) Triple EMA(Holt-Winters) \\((\\tilde L_t + h \\tilde T_t) + \\tilde s_{t+h-s}\\)\\(\\tilde L_t = \\alpha (y_t-\\tilde S_{t-s}) + (1-\\alpha)({\\tilde L}_{t-1} + \\tilde T_{t-1})\\)\\(\\tilde T_t = \\beta(\\tilde L_t-\\tilde L_{t-1}) + (1-\\beta) {\\tilde T}_{t-1}\\)\\(\\tilde S_t = \\gamma (y_t - \\tilde L_{t-1} - \\tilde T_{t-1}) + (1-\\gamma) \\tilde S_{t-s}\\) <p>where</p> <ul> <li>\\(s=\\) seasonality duration</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#complex","title":"Complex","text":""},{"location":"Economics/Econometrics/15_Time_Series_Filters/#parameters","title":"Parameters","text":"\\(w, \\alpha\\) Curve Delay High Noisy Low Low Smooth High"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#dynamic-system","title":"Dynamic System","text":"<p>State(s) change over time</p> <p>Let\u2019s take the case of 2 states: position &amp; velocity $$ \\begin{align} \\hat y_{t, t} &amp;= \\hat y_{t, t-1} + \\Delta t  \\hat {\\dot x}{t, t-1} \\tag{1} \\ \\implies \\hat {\\dot x}} &amp;= \\hat {\\dot x{t, t-1} + \\beta \\left( \\dfrac{y_t - \\hat y \\ \\hat y_{1, 0} &amp;= 0; \\hat {\\dot x}_{1, 0} = 0 \\end{align} $$ However, if we assume constant velocity, but measurement residual in }}{\\Delta t} \\right) \\tag{2\\(x \\ne 0,\\) then it could be due to 2 reasons</p> More likely when Measurement error Sensor has low precision Velocity is not constant Sensor has high precision <ul> <li>Value of \\(\\beta = \\text{const}\\), unlike \\(\\alpha_t\\)</li> <li>\\(\\beta \\propto \\text{Precision} \\propto \\dfrac{1}{\\sigma_\\text{measurement}}\\)</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#adaptive-filter","title":"Adaptive Filter","text":""},{"location":"Economics/Econometrics/15_Time_Series_Filters/#kalman-filter","title":"Kalman Filter","text":"<p>A low-pass filter with dynamically-changing \\(\\alpha\\)</p> <p>Assumes that the following are normally-distributed</p> <ul> <li>measurements</li> <li>current state estimates</li> <li>next state estimates</li> </ul> <p>Also quantifies the uncertainties associated with the estimates</p> <p>Optimal filter that combines the prior state estimate with the measurement, such that uncertainty of current state estimate is minimized</p> <pre><code>flowchart LR\n\nsubgraph i[Inputs]\n    direction LR\n    mp[Measured&lt;br/&gt;Parameter]\n    mu[Measurement&lt;br/&gt;Uncertainty]\nend\n\nsubgraph kf[Kalman Filter]\n    direction LR\n    u[Update] --&gt; p[Predict] --&gt; ud[Unit&lt;br/&gt;Delay] --&gt; u\nend\n\nsubgraph o[Outputs]\n    direction LR\n    sse[System State&lt;br /&gt;Estimate]\n    eu[Estimate&lt;br /&gt;Uncertainty]\nend\n\nsubgraph ii[Initial Inputs]\n    direction LR\n    is[Initial State]\n    isu[Initial State&lt;br /&gt;Uncertainty]\nend\n\nii --&gt; p\ni ---&gt; sf[Sensor&lt;br /&gt;Fusion] --&gt; u --&gt; o</code></pre> <p>where</p> <ul> <li>\\(r\\) is the measurement uncertainty in variance</li> <li>\\(p\\) is the estimate uncertainty in variance</li> </ul> <p></p>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#equations","title":"Equations","text":"Purpose Equation name Static System Dynamic System Comments State Update State UpdateFiltering Equation \\(\\hat y_{t, t} = \\hat y_{t, t-1} + K_t (y_t - \\hat y_{t, t-1})\\) \ud83d\udc48 Covariance gainCorrector Equation \\(p_{t, t} = (1-K_t) p_{t, t-1}\\) \ud83d\udc48 Kalman GainWeight Equation \\(K_t = \\dfrac{p_{t, t-1}}{p_{t, t-1} + r_t}; \\in [0, 1]\\) \ud83d\udc48 When measurement uncertainty is large and estimate uncertainty estimate is small, \\(K_n \\approx 0\\), the new measurement is given low weightage State Prediction State ExtrapolationPrediction EquationTransition EquationDynamic ModelState Space Model \\(\\hat y_{t+1, t} = \\hat y_{t, t}\\) \\(\\hat y_{t+1, t} = \\hat y_{t, t} + \\Delta t \\ \\hat {\\dot x}_{t, t}\\)\\(\\hat {\\dot x}_{t+1, t} = \\hat {\\dot x}_{t, t}\\) Covariance ExtrapolationPredictor Covariance Equation \\(p_{t+1, t} = p_{t, t}\\) \\(p^y_{t+1, t} = p^y_{t, t} + \\Delta t^2 p^v_{t, t}\\)\\(p^v_{t+1, t} = p^v_{t, t}\\) Kalman Gain \\(\\approx 0\\) \\(\\approx 1\\)"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#advantages","title":"Advantages","text":"<ul> <li>Handles noise in initial estimate, state transitions, and observations </li> <li>Removes need to store historical data</li> <li>Can handle asynchronous measurements, ie measurements recorded by multiple sensors at different time points</li> <li>Computationally-efficient</li> <li>Suitable for real-time applications</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#disadvantages","title":"Disadvantages","text":"<ul> <li>Only for linear gaussian state space models.</li> <li>In practice, state transitions may be non-linear/noise and may be non-gaussian.</li> <li>Use other types of Kalman filters for this</li> </ul>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#kalman-smoother","title":"Kalman Smoother","text":""},{"location":"Economics/Econometrics/15_Time_Series_Filters/#extended-kalman-filter","title":"Extended Kalman Filter","text":"<p>Developed for non-linear dynamics</p> <p>Performs analytic linearization of the model at each point</p>"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#unscented-kalman-filter","title":"Unscented Kalman Filter","text":""},{"location":"Economics/Econometrics/15_Time_Series_Filters/#without-model-based-approach","title":"Without Model-Based Approach","text":"\\(\\mu'\\) \\({\\sigma^2}'\\) Estimation uncertainty Update Parameter/MeasurementUses Bayes\u2019 rule \\(\\left( \\dfrac{\\mu}{\\sigma^2} + \\dfrac{\\nu}{r^2} \\right) {\\sigma^2}'\\) \\(\\dfrac{1}{\\dfrac{1}{r^2} + \\dfrac{1}{\\sigma^2}}\\) decreases Predict Motion \\(\\mu + u\\) \\({\\sigma^2} + r^2\\) increases ## Other Estimators"},{"location":"Economics/Econometrics/15_Time_Series_Filters/#median","title":"Median","text":"\\[ \\widehat {\\text{med}}_{t, t} = \\widehat {\\text{med}}_{t, t-1} + \\alpha_t \\cdot \\text{sgn}(y_t - \\widehat {\\text{med}}_{t, t-1}) $$ $$ \\begin{aligned} \\widehat {\\text{Q}}_{q; t, t} = \\widehat {\\text{Q}}_{q; t, t-1} + \\alpha_t  \\Bigg( \\  \\text{sgn}(y_t - \\widehat {\\text{Q}}_{q; t, t}) + 2&amp;q - 1 \\ \\Bigg) \\\\ q &amp;\\in [0, 1] \\end{aligned} \\]"},{"location":"Economics/Environmental_Economics/","title":"Environmental Economics","text":"<ul> <li> Climate Economics: Economic Analysis of Climate, Climate Change and Climate Policy | Richard Tol</li> </ul>"},{"location":"Economics/Game_Theory/","title":"Game Theory","text":""},{"location":"Economics/Game_Theory/#references","title":"References","text":"<ul> <li> Algorithmic Game Theory | Professor Bryce</li> <li> Advanced Optimization and Game Theory for Energy Systems</li> <li> Game Theory and Mechanism Design | Abhishek Gupta</li> </ul>"},{"location":"Economics/Game_Theory/01_Introduction/","title":"Introduction","text":""},{"location":"Economics/Industrial_Organization/","title":"Industrial Organization","text":""},{"location":"Economics/Industrial_Organization/#references","title":"References","text":"<ul> <li> Industrial Organization | MIT</li> <li> Introduction to Organizations | MeanThat</li> <li> Organizational Behavior | MeanThat</li> <li> Organizational Design | MeanThat</li> <li> Organizational Change | MeanThat</li> <li> Industrial Organization | Matt Birch</li> <li> Industrial Organization | Liam Malloy</li> <li> Industrial Organization | IIT Madras</li> <li> Industrial Organization | Economics2Go</li> </ul>"},{"location":"Economics/Industrial_Organization/01_Introduction/","title":"Introduction","text":""},{"location":"Economics/Industrial_Organization/01_Introduction/#manager","title":"Manager","text":"<ol> <li>Price of factors</li> <li>Cost of production</li> <li>Revenue/profits</li> </ol>"},{"location":"Economics/Industrial_Organization/11_Industry/","title":"Industry","text":""},{"location":"Economics/Industrial_Organization/11_Industry/#industrial-revolution","title":"Industrial Revolution","text":"<ul> <li>Development of new technologies and approaches</li> <li>Prompts shifts in<ul> <li>economic models</li> <li>social architecture</li> </ul> </li> </ul>"},{"location":"Economics/Industrial_Organization/11_Industry/#industrial-revolutions","title":"Industrial Revolutions","text":"Industrial Revolution Year Name Driver Outcome 0(not industrial; just put here for ease-of-relating) 10, 000 yrs ago AgrictultureShift from foraging to farming ProductionTransportationCommunication 1 1760-1840 Industrial Revolution- Mechanization Steam EngineConstruction of railways Utilization of machines for production 2 1840-1950s Electrical Production of Electricity (mainly through Coal, Oil)Assembly lines Mass production 3 1960-2010 Digital Production of semiconductors MainframesPersonal computingInternet 4 2011- Smart Cheaper,  small, powerful sensorsIoTDataAI Connected DevicesAnalyticsAutonomous vehicles3D PrintingAdditive manufacturingNanotechnologyRenewablesQuantum ComputingGene sequencing ## Sustainability <ul> <li>Energy-efficiency</li> <li>Conservation of resources</li> <li>Low-waste</li> </ul>"},{"location":"Economics/Industrial_Organization/11_Industry/#globalization","title":"Globalization","text":"<ul> <li>Business models</li> <li>Supply chain management</li> <li>Energy price</li> <li>Information &amp; Communication Technology</li> <li>Emerging markets</li> </ul>"},{"location":"Economics/Industrial_Organization/11_Industry/#smart-operations","title":"Smart Operations","text":"<ul> <li>Monitor</li> <li>Control</li> <li>Optimize</li> <li>Automate</li> </ul>"},{"location":"Economics/International_Economics/","title":"International Economics","text":""},{"location":"Economics/International_Economics/#references","title":"References","text":"<ul> <li> International Economics | DrAdevedoEcon</li> <li> International Political Economy | Brian Urlacher</li> <li> International Economics | Timo Kuosmanen</li> <li> International Economics and Finance (IEF) | Lazarski Open Courses</li> </ul>"},{"location":"Economics/Macroeconomics/","title":"Microeconomics","text":""},{"location":"Economics/Macroeconomics/#references","title":"References","text":"<ul> <li> Principles of Economics | Dr. Sartaj Rasool Rather | BITS Pilani Dubai Campus</li> <li> Principles of Macroeconomics | MIT</li> <li> Introduction to Advanced Macroeconomic Analysis | Humbolt-University Berlin</li> <li> European Integration | Humbolt-University Berlin</li> <li> Advanced Macroeconomic Analysis | Humbolt-University Berlin</li> <li> Labor Markets with Search Frictions | Humbolt-University Berlin</li> <li> Public Finance and Public Policy | MIT</li> <li> Innovation Systems for Science, Technology, Energy, Manufacturing, and Health | MIT</li> <li> Game Theory 101 Full Course | William Spaniel</li> <li> Game Theory | Yale</li> <li> Game Theory with Ben Polak | YaleCourses</li> <li> Game Theory and Economics | IIT Guwahati</li> <li> Intermediate Macroeconomics | Matt Birch</li> <li> Econ 2450A Public Economics | Raj Chetty | Harvard</li> <li> Macroeconomics | Liam Malloy</li> <li> Intermediate Macroeconomics | Liam Malloy</li> <li> Environmental Economics | Matt Birch</li> <li> Macroeconomics | The Economy 2.0 | The CORE Econ Team</li> <li> Solow Growth Models | Christopher Ball</li> <li> Intermediate Macroeconomics | Todd R. Yarbrough</li> </ul>"},{"location":"Economics/Macroeconomics/#current-video","title":"Current Video","text":"<p>https://www.youtube.com/watch?v=qg_HT3CjFI4&amp;list=PLUl4u3cNGP62EXoZ4B3_Ob7lRRwpGQxkb&amp;index=9</p>"},{"location":"Economics/Macroeconomics/01_Intro/","title":"Introduction","text":"<p>The main instrument for central banks is the interest rates</p> <p>Inflation \\(\\propto\\) Wage Rate</p> <p>Immediately after the pandemic, there is a sudden growth as: - people are desperate to do something now - savings from all the time inside</p>"},{"location":"Economics/Macroeconomics/01_Intro/#phases-of-economy","title":"Phases of economy","text":"Phase Indicator Unemployment Inflation Policy:Incentivize Policy:Action Recovery Boom actual &lt; natural actual &gt; potential Recession Rule of thumb: 2 consecutive quarters of deflation actual &gt; natural actual &lt; potential Investments Lower interest rateSubsidies Consumer spending Universal Basic Income/Direct income transfers to people (only effective till a limit - excessive causes inflation)Tax reduction"},{"location":"Economics/Macroeconomics/01_Intro/#trickle-down-effect","title":"Trickle-down Effect","text":"<p>The benefits of improving a particular country/sector will improve others also eventually</p>"},{"location":"Economics/Macroeconomics/02_Core_Principles/","title":"Core Principles","text":""},{"location":"Economics/Macroeconomics/02_Core_Principles/#markets-are-usually-good","title":"Markets are usually good","text":""},{"location":"Economics/Macroeconomics/02_Core_Principles/#government","title":"Government","text":""},{"location":"Economics/Macroeconomics/02_Core_Principles/#standard-of-living","title":"Standard of living","text":"<p>Standard of living of a country depends on its production level</p> <p>Productivity: amount of goods and services produced by a worker during an hour of work - As efficiency increases, time to produce goods/services decreases, standard of living increases</p> <p>Disparities in standard of living is caused due to difference in productivity - i don\u2019t exactly agree with this cuz women have a history of earning less for the same productivity</p>"},{"location":"Economics/Macroeconomics/02_Core_Principles/#prices-rise-when-govt-prints-excess-money","title":"Prices rise when govt prints excess money","text":"<p>If you print money without them producing anything, money loses its value and inflation occurs However, if you print money due to increase in the country's output, then it's fine</p> <p>When prices of commodity increases, value of money reduces</p> <p>value of money \\(\\propto \\frac{1}{\\text{price of commodities} }\\)</p>"},{"location":"Economics/Macroeconomics/02_Core_Principles/#micro-effects","title":"Micro Effects","text":"<p>Money-givers gain</p> <p>Fixed income money-receivers lose eg: regular employees</p> <p>Variable income money-receivers not affected business people, freelancers</p>"},{"location":"Economics/Macroeconomics/02_Core_Principles/#macro-effects","title":"Macro Effects","text":"<p>Imports increase: demand for domestic products decreases, as they are costlier Exports decrease: as other countries do not want a more expensive product</p> <p>Hence, high inflation is not good</p>"},{"location":"Economics/Macroeconomics/02_Core_Principles/#welfare-cost","title":"Welfare Cost","text":"<p>The cost associated with any action that has macro-level consequences and affects entire society eg: taxes, interest rates have welfare costs associated with them</p>"},{"location":"Economics/Macroeconomics/02_Core_Principles/#economy-faces-a-short-run-trade-off-between-inflation-and-unemployment","title":"Economy faces a short-run trade-off between inflation and unemployment","text":"<p>Short run: period where contracts cannot be renegotiated (monthly, quarterly) Lon run: a long period (annually) which contains multiple renegotiations of contracts</p>"},{"location":"Economics/Macroeconomics/02_Core_Principles/#phillips-curve-relation","title":"Phillips Curve Relation","text":"<ul> <li>y-axis = inflation</li> <li>x-axis = unemployment</li> </ul> \\[ \\text{Inflation} \\propto \\frac{1}{\\text{Unemployment}} \\] \\[ \\begin{aligned} \\pi_t &amp;= \\alpha - \\beta U_t &amp;  (\\pi_t = - \\beta U_t + \\alpha, \\ y = mx+c) \\\\ \\text{Taking derivative wrt } \\pi_t \\implies \\beta &amp;= - \\frac{d \\pi_t}{dt} \\end{aligned} \\] <ul> <li>\\(\\pi_t =\\) Inflation</li> <li>\\(\\alpha =\\) inflation when there is no unemploment</li> <li>\\(\\beta =\\) cost for reducing unemployment by a unit</li> <li>\\(U_t =\\) actual rate of unemployment</li> </ul> <p>This relation is only short-run for long run, whatever is the inflation, unemployment tends to natural unemployment the graph will be a straigth line parallel to the y-axis</p> <p>During shortrun, the contracts for raw materials, employees is fixed but prices for commodity increases therefore, producers increase production to maximize profit (misperception by producers); this is done by increasing employees Unemployment rate decreases</p> <p>Moreover, workers suffer money illusion (only focus on the nominal income increase;  don\u2019t realise that the real income is the same)</p> <p>Then in the long run, few months later, the employees will renegotiate for higher wages; then the producers will hesitate as they no longer see the attraction for producing at such large volume and paying such wages; so they fire employees; therefore, the unemployment rate will increase again</p>"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/","title":"Macroeconomic Measures","text":"<p>In macro, production = income</p>"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#adjustment","title":"Adjustment","text":"Aspect Technique Value Location PPPPurchasing power parity Price corrected for location Big Mac Index Time Nominal Absolute price at a time Relative Price corrected for time, ie prices of base year CPI: Basket of goods Population per capita GDP per capita"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#aggregate-output","title":"Aggregate Output","text":"<p>Why is it in currency? - To make everything into a single unit of measurement</p> GDP GNP Full Form Gross Domestic Product Gross National Product Meaning 1. Total value of final goods and services produced within the borders of a country (regardless of nationality); final* is to ensure independence from ownership structure2. Sum of value added within the borders of a country (regardless of nationality)3. Sum of incomes (and profits) within the borders of a country (regardless of nationality) 1. Total value of final goods and services produced by nationals/citizens of a country (regardless of location); final* is to ensure independence from ownership structure2. Sum of value added by nationals/citizens of a country (regardless of location)3. Sum of incomes (and profits) of citizens of a country (regardless of location) Calculation Add+ Private Consumption+ Investment+ Govt expenditures+ ExportsSubtract- Imports Why? Easy to measure Limitations Includes govt expenditure to good/bad requirements: crime, natural disastersDoes not include informal activities"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#types","title":"Types","text":"Potential output Actual output Meaning Ideal output an economy can produce by using all its resources What an economy actually produces"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#employment","title":"Employment","text":"Term Meaning Employment \\(E\\) Number of people with a job Unemployment \\(U\\) Number of people seeking jobs but cannot getDoes not include discouraged workers and uninterested people Discouraged workers Number of people who give up looking for a job Labor Force \\(L\\) \\(E + U\\) Unemployment rate \\(u\\) Proportion of people seeking jobs but cannot get\\(\\dfrac{U}{L}\\) Participation Rate \\(\\dfrac{\\text{Labor Force}}{\\text{Total population of working age}}\\)"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#unemployment-rate","title":"Unemployment Rate","text":"Natural Rate Actual Rate Meaning Unemployment rate which exists regardless of whatever we do The current rate of unemployment it fluctuates a lotHowever, if you take the average of 20yrs or so, the average actual rate tends to the natural rate Factors 1. resources2. technology3. production capacity/no of factories4. population/size of the country"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#inflation","title":"Inflation","text":"<p>Sustained rise in the general level of price</p> <p>Inflation rate: Rate at which prices of commodities increase</p> \\[ \\pi_t = \\dfrac{P_t - P_{t-1}}{P_{t-1}} \\] +ve Inflation Deflation (-ve inflation) Meaning increase in prices of commodities decrease in prices of commodities Comment Happens when economy is growing More dangerous than high inflation <p>Usually targeted inflation - developed countries: 2-3% - developing countries: 5-8%</p> <p>Why is small inflation good? Incentivizes spending</p>"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#indicators","title":"Indicators","text":"Measure CPIConsumer Price Index Cost of living Core CPI CPI excluding volatile commodities: energy and food GDP Deflator \\(\\dfrac{\\text{Nominal GDP}}{\\text{Real GDP}}\\)"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#types_1","title":"Types","text":"Prices increase due to Cost-Push inflation increase in the cost for supply - cost of production- prices of raw materials- oil prices (transportation) for the name, think suppliers push the product to the consumers Demand-pull inflation increase in demand for the name, think consumers pull the product from the sellers Structural inflation suppliers are not able to keep up with the demand due to lack of infrastructure; ie, demand increases and producers want to increase output, but aren't able to do so"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#inflation-models","title":"Inflation Models","text":""},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#taylor-rule","title":"Taylor Rule","text":"<p>Inflation rate something</p> \\[ I_t = \\beta_1 + \\beta_2 (\\pi_t - \\pi_t^*) + e_t \\]"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#money-supply","title":"Money Supply","text":"\\[ I_t = \\beta_1 + \\beta_2 M_t + e_t \\]"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#inflation-welfare-cost-relation","title":"Inflation-Welfare Cost Relation","text":"Optimal Inflation Rate Developed Countries 2% Developing Countries 4-6%"},{"location":"Economics/Macroeconomics/02_Macroeconomic_Measures/#inflation-unemployment-output","title":"Inflation, Unemployment, Output","text":"\\[ \\text{Output} \\propto \\text{Inflation} \\propto \\dfrac{1}{\\text{Unmployment}} \\]"},{"location":"Economics/Macroeconomics/04_GS_Market/","title":"Goods &amp; Services Market","text":""},{"location":"Economics/Macroeconomics/04_GS_Market/#aggregate-demand","title":"Aggregate Demand","text":"Sign Component Symbol Meaning + Consumption \\(C\\) G&amp;S purchased by consumers + Investment \\(I\\) Sum of residential and non-residential investment + Government spending \\(G\\) Purchases of G&amp;S by federal, state, and local govts(excluding Govt transfers) + Exports \\(E\\) Goods &amp; services produced by country purchased by foreign countries - Imports Foreign goods &amp; services purchased by country + Inventory Investment Difference between production and sales <p>Behavioral Assumptions - Investment is exogenous of fiscal policy - Consumption is endogenous to disposable income</p>"},{"location":"Economics/Macroeconomics/04_GS_Market/#consumption","title":"Consumption","text":"<p>Assuming Consumption \\(\\propto\\) Income</p> \\[ C = c_0 + c_1 (I-T) \\] <ul> <li>\\(C =\\) total consumption</li> <li>\\(c_0 =\\) base/autonomous consumption<ul> <li>\\(c \\ne 0\\)</li> </ul> </li> <li>\\(c_1 =\\) MPC (Marginal Propensity to Consume)</li> <li>\\(I =\\) Income</li> <li>\\(T=\\) Taxes</li> <li>\\((I-T)=\\) disposable income</li> </ul> <p></p>"},{"location":"Economics/Macroeconomics/04_GS_Market/#idk","title":"IDk","text":"Short-Run Medium-Run Long-Run Equilibrium Output Factors - Aggregate Demand- Production- Income Equilibrium Condition \\(\\text{Aggregate Demand} = \\text{Aggregate Income}\\)\\(\\text{Aggregate Investment} = \\text{Aggregate Savings}\\) Equilibrium Output \\(\\dfrac{1}{1-c_1} (c_0 - T + I + G)\\) Increase in autonomous consumption \\(c_0\\)"},{"location":"Economics/Macroeconomics/04_GS_Market/#output-multiplier","title":"Output Multiplier","text":"<p>\\(m = \\dfrac{1}{1-c_1}\\) </p> <p>Implication - If \\(m&gt;1\\): even small consumer spending will lead to increased output - If \\(m \\le 1\\): lots of consumer spending required for growth</p>"},{"location":"Economics/Macroeconomics/04_GS_Market/#short-run","title":"Short-Run","text":"<pre><code>flowchart LR\nd[Demand] --&gt;\ns[Supply] --&gt;\ni[Income] --&gt;\nd</code></pre>"},{"location":"Economics/Macroeconomics/04_GS_Market/#paradox-of-saving","title":"Paradox of Saving","text":"\\[ \\begin{aligned} \\text{Investment} &amp;= \\bar S^G + S(Y) \\\\ S(Y) &amp;= \\dfrac{1}{1-c_1} Y &amp; (\\text{Output $Y$ = Income}) \\end{aligned} \\] <p>If savings \\(S(Y)\\) increase due to decrease in \\(c_1\\) - then savings &gt; investment, ie consumption decreases  - then \\(Y\\) reduces to restore equilibrium - this reduces income - this reduces consumption - this reduces output - vicious cycle</p> <p>where \\(Y =\\) Real output</p> <p></p> <p>This is why drastic contractionary fiscal policy is detrimental - introducing high GST/VAT - decrease in govt expenditure</p>"},{"location":"Economics/Macroeconomics/05_Policy/","title":"Policy","text":"Monetary Policy Fiscal Policy Short-Run objectives Interest ratesExchange rateMoney supplyAggregate Demand Long-Run objectives Price levelInflation Equilibrium Growth Instruments Repo ratesTrade of financial assets Government spendingTaxationSubsidies Authority Managed by central banks Managed by government (Congress/Parliament) Nature Indirect(effect on G&amp;S market via Financial Market) Direct(direct effects on G&amp;S market) Changes Implementation Lag Quicker Slower Changes Impact Lag Quicker Slower Inflation Control Directly targets inflation Indirectly influences inflation through spending Economic Impact Affects borrowing costs directly Affects aggregate demand through fiscal measures \\[ \\text{Interest Rate} \\propto \\text{Repo Rate} \\]"},{"location":"Economics/Macroeconomics/05_Policy/#money-supply","title":"Money Supply","text":"\\[ \\text{Inflation} \\propto \\text{Money Supply} \\propto \\dfrac{1}{\\text{Interest Rate}} \\] <p>However, this may not always be true</p> <ol> <li>Interest Rate \\(\\not \\propto\\) Repo Rate    Commericial banks may not follow the same as central bank, if they have high liquidity (lots of hot cash)</li> <li>Inflation \\(\\not \\propto \\frac{1}{\\text{Interest Rate}}\\)    People may not always spend more just because of higher money supply caused by lower interest rates</li> </ol>"},{"location":"Economics/Macroeconomics/05_Policy/#budget-deficit","title":"Budget Deficit","text":"<p>Scenario where Govt Expenditure &gt; Revenue. This happens a lot in developing countries, as they are trying to develop as rapidly as possible.</p> <p>High budget deficit leads to high inflation - When the govt spends a lot of money in development, then the demand for investment and labor will increase - Developing countries always try to spend more than their revenue, because they're trying to develop as quickly as possible</p>"},{"location":"Economics/Macroeconomics/05_Policy/#monetization-of-budget-deficit","title":"Monetization of budget deficit","text":"<p>When the govt prints money/borrows from banks, instead of selling assets</p> <p>This leads to inflation as there is more money in the system</p>"},{"location":"Economics/Macroeconomics/05_Policy/#money","title":"Money","text":"<p>Exchange Rate</p> Absolute exchange rate Real exchange rate Meaning Ratio of nominal value of 2 currencies Rate at which one commodity is exchanged for another Comment Also called as terms of tradeRatio of the goods/services you can buy with 2 currencies"},{"location":"Economics/Macroeconomics/05_Policy/#pegging","title":"Pegging","text":"<p>the absolute exchange rate is fixed against another currency</p> <p>isn\u2019t natural it is due to govt intervention</p> <p>for eg, in UAE Dirham, the Central Bank of UAE</p> <ul> <li>buys dollars when the value of dollars reduces<ul> <li>in order to create a fake shortage</li> <li>and hence increase value</li> </ul> </li> <li>sells dollars when the value of dollars decreases</li> </ul>"},{"location":"Economics/Macroeconomics/05_Policy/#demand-for-money","title":"Demand for Money","text":"<p>Tradeoff - Hold more money: ease of transactions, but opportunity cost of missing return - Hold more bonds: higher returns, but low liquidity</p> <p>How much of your wealth you hold in form of money and bonds depends on - price level of transactions - absolute income - interest rate</p>"},{"location":"Economics/Macroeconomics/05_Policy/#equilibrium-interest-rate","title":"Equilibrium Interest Rate","text":"\\[ M_s = M_d = \\$ Y L(i) \\] <p>In reality, \\(M_d\\) is very volatile - Seasonality - Holidays - Events</p> Nominal Income Interest Rates \\(\\implies\\) Money Supply Interest Rates Constant Constant Constant Constant Constant Decrease Increase Increase Constant Increase <p>Money supply changed through trade of bonds - Central bank buying bonds     - Decreases bond supply, increases price of bonds, decreases the interest rate     - Increased money supply, decrease money demand, decrease interest rate</p>"},{"location":"Economics/Managerial_Economics/","title":"Managerial Economics","text":""},{"location":"Economics/Managerial_Economics/#references","title":"References","text":"<ul> <li> Managerial Economics | SebastianWaiEcon</li> <li> Price Discrimination | Justin Eloriaga</li> <li> Managerial Economics | IIT Madras</li> </ul>"},{"location":"Economics/Microeconomics/","title":"Microeconomics","text":""},{"location":"Economics/Microeconomics/#references","title":"References","text":"<ul> <li> Principles of Economics | Dr. Sartaj Rasool Rather | BITS Pilani Dubai Campus</li> <li> Principles of Microeconomics | MIT</li> <li> Intermediate Microeconomic Theory | MIT</li> <li> Microeconomics for Public Policy | Andrew Heiss | Georgia State University</li> <li> Economics | Ashley Hodgson</li> <li> Intermediate Microeconomics | Ben Zamzow</li> <li> 60 Second Adventures in Economics | The Open University</li> <li> Microeconomics | Liam Malloy</li> <li> Intro to Microeconomics | Matt Birch</li> <li> Microeconomics | The Economy 2.0 | The CORE Econ Team</li> <li> Principles of Economics: Microeconomics | Marginal Revolution University</li> <li> Network Economics | Russel Haines | University of Munster</li> <li> Microeconomic Principles | Todd R. Yarbrough</li> </ul>"},{"location":"Economics/Microeconomics/01_Introduction/","title":"Introduction","text":"<p>Constrained optimization wrt trade-offs and scarcity to maximize utility with minimal cost</p> <p>Deals with</p> <ol> <li>what to produce</li> <li>how to produce</li> <li>for whom to produce</li> </ol>"},{"location":"Economics/Microeconomics/01_Introduction/#aspects","title":"Aspects","text":"<ul> <li>scarcity of resources</li> <li>forecasting</li> <li>factors of production</li> <li>proportion of input and output</li> <li>allocation of resources</li> </ul>"},{"location":"Economics/Microeconomics/01_Introduction/#assumptions-of-classical-economics","title":"Assumptions of Classical Economics","text":"<ol> <li>Stable &amp; well-defined Preferences<ol> <li>Completeness: no one feels unsure about preferences<ol> <li>Either \\(A &gt; B\\) or \\(B&lt;A\\) or \\(A \\sim B\\)</li> </ol> </li> <li>Transitivity: If you prefer \\(A &gt; B\\) and \\(B &gt; C\\), then you must prefer \\(A &gt; C\\)</li> <li>Non-satiation: More is better</li> <li>Can be represented as a utility function</li> </ol> </li> <li>Rational behavior<ol> <li>Want to maximize utility</li> <li>Only have self-interest</li> <li>People don\u2019t care about others\u2019 interests</li> <li>No peer-pressure</li> <li>risk-averse</li> <li>Perfect Bayesian information processors</li> <li>process information optimally</li> <li>pay perfect attention to all details</li> <li>don\u2019t forget information</li> <li>No biases</li> <li>preferences over final outcomes, not changes</li> <li>no \u201ctaste\u201d for beliefs/information; purely objective</li> </ol> </li> <li>Budget constraints<ol> <li>Budget = Income; ie no savings/borrowings</li> </ol> </li> </ol> <p>These may seem like we are making very incorrect assumptions. But these assumptions are required to understand the main concepts. For more accurate modelling, we use Behavioral Economics</p>"},{"location":"Economics/Microeconomics/01_Introduction/#preferences","title":"Preferences","text":"Strong \\(A &gt; B\\) Weak \\(A \\ge B\\) Indifference \\(A \\sim B\\)"},{"location":"Economics/Microeconomics/01_Introduction/#elements-of-market","title":"Elements of Market","text":"<ol> <li>Demand</li> <li>Supply</li> <li>Equilibrium</li> </ol> <p>These are built from the indifference and budget constraints curves of utility maximization</p>"},{"location":"Economics/Microeconomics/01_Introduction/#paradox-of-value","title":"Paradox of Value","text":"<p>The paradox of value is the contradiction that, although water is more necessary than diamonds for survival, diamonds are costlier</p> <p>This can only be explained through the elements of market</p>"},{"location":"Economics/Microeconomics/01_Introduction/#misc","title":"Misc","text":""},{"location":"Economics/Microeconomics/01_Introduction/#black-money","title":"Black Money","text":"<p>The money isn\u2019t necessarily illegal, the problem is that the transaction is unofficial, to avoid paying taxes for the transaction.</p>"},{"location":"Economics/Microeconomics/01_Introduction/#demonetization","title":"Demonetization","text":"<p>They assumed that all black wealth is in the form of cash, but if you look at data - 0.0002% of total wealth is in the form of cash - only ~1% of black wealth is in cash</p> <p>Demerits were the cost of - Printing the notes - Time of people in queues wasted and hence they did not perform productively - Informal sector shops lost everything, due to the above</p> <p>It mainly did one thing: introduction of a new commodity: old currency</p>"},{"location":"Economics/Microeconomics/01_Introduction/#fake-currency","title":"Fake Currency","text":"<p>Fake currency is only an issue if it facilitates illegal activities. However, as long as fake currency is used for legal activities, then there is no problem from the perspective of economics. However, if the proportion of fake money is too large, then there is risk of inflation</p>"},{"location":"Economics/Microeconomics/01_Introduction/#income","title":"Income","text":"Type Meaning Nominal income monetary income Real income \\(\\dfrac{\\text{Nominal income}}{\\text{Avg cost of purchases}}\\)Reflects purchasing power: the quantity of goods and services you can buy IDKisn\u2019t this the best? \\(\\text{Value of savings wrt exchange rate}\\)\\(\\text{Savings} = \\text{Nominal income}-\\text{Avg cost of purchases}\\)"},{"location":"Economics/Microeconomics/01_Introduction/#circular-flow-model","title":"Circular Flow Model","text":"<p>More cycles \\(\\implies\\)higher output</p> <p>Cashless economy allows to complete more cycles Credit card basically provides preponed salary; instigates flow from consumer sector to production sector</p>"},{"location":"Economics/Microeconomics/01_Introduction/#sectors-of-economy","title":"Sectors of Economy","text":"<ol> <li>consumer</li> <li>business/production</li> <li>financial</li> <li>Govt</li> <li>external/foreign/international</li> </ol> <p>All of these sectors are inter-linked and anything that affects one sector affects the others too - Agricultural inflation affects non-agricultural sectors, as agricultural products are used as raw materials - Agricultural sector depends on the manufacturing sector and vice-versa</p>"},{"location":"Economics/Microeconomics/01_Introduction/#2-sector","title":"2 sector","text":"<p>Consumer and production</p> <p>Production sector produces goods and services; consumers buy them</p> <p>Production sector provides jobs; consumers work</p>"},{"location":"Economics/Microeconomics/01_Introduction/#3-sector","title":"3 sector","text":"<p>Financial sector provides investments to the producers</p> <p>Consumers deposit the savings into the financial sector, and they gain more or assets go through depreciation</p>"},{"location":"Economics/Microeconomics/01_Introduction/#4-sector","title":"4 Sector","text":"<p>International sector allows</p> <ul> <li>imports/exports</li> <li>remittance(overseas transfers) - consumer the money sent back to the family in another country</li> <li>net lending overseas - financial sector gives out loans to other countries</li> <li>overseas income from foreign to all other sectors</li> </ul>"},{"location":"Economics/Microeconomics/01_Introduction/#5-sector","title":"5 sector","text":"<p>Govt</p> <ul> <li>consumers<ul> <li>collect taxes</li> <li>provide direct income transfers (like pensions)</li> </ul> </li> <li>business<ul> <li>collects taxes</li> <li>govt purchases</li> <li>transfer payments (tax holidays)</li> </ul> </li> <li> <p>financial sector</p> <ul> <li>loans in times of govt deficit</li> <li>liquidity injection Hot money/cash for the banks</li> <li>foreign sector</li> <li>import duties/taxes</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/01_Introduction/#idk","title":"Idk","text":"<p>There is always a conflict b/w efficiency vs equity.</p> Term Meaning Efficiency optimization to maximize output with minimum input doing things right Effectiveness Impact of output doing the right things"},{"location":"Economics/Microeconomics/01_Introduction/#commodities","title":"Commodities","text":"Goods Bads Something that generates pleasure generates displeasure You pay for it you receive payment"},{"location":"Economics/Microeconomics/01_Introduction/#categories","title":"Categories","text":"Category Meaning Example Excludability Excludable possible to exclude whoever did not pay for it netflix subscription Non-excludable impossible to exclude those who did not pay for it - national defence- community services- landscapes- fresh air Rivalry of consumption Rivaled Availability of a product is dependent of its consumption Non-rivalled Availability of a product is independent of its consumptionThat's one of the best things of digital revolution: it has enabled non-rivalry National defence, fresh air, lighthouses, netflix subscription"},{"location":"Economics/Microeconomics/01_Introduction/#types","title":"Types","text":"Type Rivalled Excludable Comment Example Public \u274c \u274c national defence Club \u274c \u2705 netflix CPRCommon Property Resources \u2705 \u274c prone to exploitation forests, natural goods Private \u2705 \u2705 food Repugnant Commodities that should not be traded due to violation of normsThis is to prioritize equity over efficiency - Organs- Babies- Votes- Cadavers Merit Commodities that everyone should get outside of markets - Education- Security- Healthcare- Transportation- Culture"},{"location":"Economics/Microeconomics/01_Introduction/#money","title":"Money","text":"<p>Medium of exchange that does not provide returns</p> <ol> <li>Facilitates trade<ol> <li>prevents the need for coincidence of wants; ie money prevents the need for both parties to want to exchange products that they want from the other person</li> </ol> </li> <li>Mode of deferred payment</li> <li>Unit of value</li> <li>Store of value</li> </ol> <p>Money could be - cash - digital wallet - checkable deposits</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/","title":"Systems &amp; Institutions","text":""},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#economic-systems","title":"Economic Systems","text":"<p>Arrangement of economic activity to produce and distribute goods &amp; services</p> Type Description Regulation Competition Variety in Products Example Limitations Private/Market-Based/Capitalist Dynamically affected by what the producers produce and consumers consumePure capitalism means that the market is free from government intervention3 Institutions- Private property- Markets- Firms Low/None High (encourages people to perform better; everyone tries to optimize) High USA Inequality: Wealth is heavily-skewed, to the point that consumers cannot buy anymore.- Most recessions have been due to low demand, not low supply- Producers produce for themselves, by themselves- Negligence of ethics: discrimination, environment Centralized/Command Central authority dictates High Low Low North KoreaSoviet Union Too many opportunities for corruptionInefficient Public Communism Type Hybrid Moderate Moderate Moderate India (Centralized railways, while others are market-based) <p>Firms: Organizations that use land, labor and capital to produce goods and services to generate profit</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#functions-of-market","title":"Functions of Market","text":"<ol> <li>Organizing economic activity</li> <li>Determining the optimal price<ul> <li>supply reflects the availability/abundance of the commodity</li> <li>demand reflects the willingness for purchasing commodity</li> <li>price for a product without a market(demand/supply) for it is undefined</li> </ul> </li> <li>Encourage efficiency and specialization</li> <li>Signaling of availability<ul> <li>Seasonality: Seasonal food</li> </ul> </li> <li>Allocation of resources</li> </ol> Price Reaction of Production Reaction of Demand Inc Inc Dec Dec Dec Inc <p>Not all market signals are pure market signals    Distortion of market signal: when govt creates policies to change pricing in a free market    Eg: subsidies</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#market-power","title":"Market Power","text":"<p>It is the power of firms to control their selling price. It allows them to determine their own profits. It depends on</p> <ul> <li>type and intensity of competition</li> <li>costs of production<ul> <li>this influences the type of competition in market, because it is cheaper for one firm to produce at a larger scale</li> <li>big companies threaten small by lowering their price, to make them run out of business; otherwise acquire their company</li> <li>eg: Facebook-Instagram</li> </ul> </li> </ul> <p>Sometimes, consumer may have greater market power. This occurs when there is only a sole consumer, but many sellers eg: Dubai Metro</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#market-failure","title":"Market Failure","text":"<ul> <li>Reasons why market is not functioning the way it is 'supposed' to be</li> <li>Prices do not capture the effects of individual actions<ul> <li>Public goods</li> <li>Externalities</li> <li>Monopolies</li> <li>Missing markets</li> <li>Asymmetric information</li> </ul> </li> </ul> <p>Market fails when it comes to non-excludable commodity</p> <p>Example - Fraud - Imperfect information</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#competition-in-markets","title":"Competition in Markets","text":"Type Example Monopoly 1 seller Monopoly supplier produces at the quantity where Marginal Revenue &amp; Marginal Cost intersect Duopoly 2 sellers Oligopoly few sellers have control, but not as much as monopoly/duopoly eg: telecom Monopolistic there are large no of sellersbut no of sellers is small enough that if one seller changes their price, other sellers will tend to change their price also in reaction aviation industry, snacks Perfectly-competitive Market when there are large no of sellers and buyers- no of sellers large enough such that change in price by one seller should not affect other sellers\u2019 decision- no of buyers large enough such that decision by one buyer should not affect other buyers\u2019 decisionDemand elasticity for a single firm is perfectly elastic: if a seller inc price, then the demand for their product becomes 0, as no one will be willing to buy from them. Producers are price-takers 1. Identical substitutes exist2. Perfect information3. Low search &amp; transaction costs - agricultural industry: one farmer stops producing rice does not affect other rice farmers- food consumption: one buyer stops eating rice does not affect other buyers of rice"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#monopoly","title":"Monopoly","text":"<ul> <li>private monopoly: unfair situation for consumers where there is only a sole producer of a product</li> <li> <p>natural monopoly: situation where there is a single producer (like govt), but not necessarily bad; eg: Railways</p> </li> <li> <p>monopoly can be addressed through govt subsidies for the monopoly</p> </li> <li>the monopoly company will tend to increase output to attain the new maximum marginal net benefit</li> <li>hence, the level of optimal output will be greater after subsidies than without it, and hence the producers increase the supply</li> <li>this will reduce the price and benefit the consumers</li> </ul>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#duopoly","title":"Duopoly","text":"<p>A situation with multiple buyers, but only 2 sellers</p> <p>Nash equilibrium (by John Nash) says that</p> <p>An agent who has a competitor will always design the best policy, with the assumption that the competitor will also design its own best policy</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#institutions","title":"Institutions","text":"<p>Rules for the system</p> <p>Coordination: Invisible hand: Everyone working in their own self-interest drives the collective market</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#democracy","title":"Democracy","text":"<p>3 key characteristics 1. Rule of law 2. Civil liberties 3. Inclusive, free, and decisive elections</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#government","title":"Government","text":"<p>Govt is the only actor allowed to use legitimate force</p> <p>Govt responsibilities 1. Protect property, civil &amp; human rights of citizens 2. Maximize surplus/efficiency 3. Generate efficient outcomes, such as prevent      1. Monopoly     2. Tragedy of Commons for CPR         For community resources(like fishing ponds, forests), the govt comes in to prevent over-utilization of the resources; supports sustainability 3. Market failure: Govt interferes in fields where private investors are not interested 4. Promote equality/equity     1. prevention of trade of whatever is socially harmful (alcohol, drugs)     2. keeps market's obsession with efficiency at the expensive of equity in check     3. reduces economic inequality 5. Socially desirable outcomes</p> <p>Dangers - Use of force to silence opponents: companies - Rent-seeking - Oligarchy - Self-Enrichment</p> <p>Well-designed governments have limits on government power - Elections - Constitution</p>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#government-failure","title":"Government Failure","text":"<ul> <li>Failure of political accountability<ul> <li>Economic infeasibility: Public policy may not be effective if it does not provide efficient incentives (Nash equilibrium)</li> <li>Administrative infeasibility: Public policy may not be effective if there is not sufficient state capacity or limited information</li> <li>Political infeasibility: Public policy may not be effective due to vote (incentives, intransitivity, Condorcet paradox), short-termism, unequal access, lobbyists</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#how-to-increase-public-participation","title":"How to increase public participation","text":"<ul> <li>Prevent large groups from free-riding by changing individual gains<ul> <li>Coercion: Increase cost of not acting</li> <li>Selective incentives: Increase the benefits of acting</li> <li>Federation: Make big group feel small</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/01_Systems_Institutitions/#ideal-institutional-mix-for-capitalism","title":"Ideal Institutional Mix for Capitalism","text":"<p>Democracy is not the requirement</p> <ul> <li> Incentives for innovation<ul> <li> Secure private property</li> <li> Competitive markets</li> </ul> </li> <li> Efficient firms:<ul> <li> Competent leadership</li> <li> Create goods at low cost</li> </ul> </li> <li> Public policy<ul> <li> Govt policies that foster these conditions</li> </ul> </li> <li> Public good provision<ul> <li> Govt fills gaps missed by private sector</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/02_Core_Principles/","title":"Core Principles","text":""},{"location":"Economics/Microeconomics/02_Core_Principles/#theres-always-trade-offs","title":"There's always Trade-offs","text":"<p>When choosing an option, you're always giving up on something else; ie there is always an opportunity cost</p> <p>It is due to scarcity of resources; every resource is finite; nothing comes free</p> <p>Eg: when i want to study, i'm giving up sleep</p>"},{"location":"Economics/Microeconomics/02_Core_Principles/#real-cost","title":"Real Cost","text":"<p>Cost of something is what you sacrifice to get it</p> <p>Real Cost = relative price = opportunity cost</p> \\[ \\text{OC} = \\frac{\\text{What you sacrifice}}{\\text{What you receive}} \\] <p>Fraction that shows what is to be sacrificed to pick an option A instead of B.</p> <p>This can be incorporated into daily life instead of regular pros/cons list, by adding a cost/benefit associated with every factor for a decision.</p> <p>It's not just monetary cost</p>"},{"location":"Economics/Microeconomics/02_Core_Principles/#rational-people-think-at-margin","title":"Rational people think at Margin","text":"<p>Rationality: making a decision considering all possibilities to obtain best outcome with minimal input and losses.</p> <p>Marginality: making decisions considering incremental benefits/costs associated with an action; not at total benefit/cost</p> <p>marginal profit (net benefit) = marginal benefit - marginal cost Proceed incrementing production as long as marginal net benefit \\(\\ge\\) 0</p>"},{"location":"Economics/Microeconomics/02_Core_Principles/#people-respond-to-incentives","title":"People respond to incentives","text":"<p>Incentive: instrument to induce an individual to act/react tool to change behavior</p> <p>Subsidies = +ve incentive Taxes = -ve incentive</p>"},{"location":"Economics/Microeconomics/02_Core_Principles/#trade","title":"Trade","text":"<p>Voluntary transaction between parties, resulting in their betterment.</p> <p>Trade offs are there as everything has pros/cons, gains/costs; other options could have been chosen, but did not as the customer takes the best option</p>"},{"location":"Economics/Microeconomics/02_Core_Principles/#trade-benefits-everyone","title":"Trade benefits everyone","text":"<ol> <li>Reduces cost of production through specialization    Specialists require lower resources for production, because they are really good at it; hence they can increase output</li> <li>Both parties gain a greater variety of goods and services</li> </ol> <p>Overall trade gains depends on</p> <ol> <li>choice set</li> <li>cost minimization</li> </ol> <p>Individual gains depends on</p> <ol> <li>Terms of trade    basically means the exchange rate</li> <li>Bargaining power</li> <li>nature of the product (Shelf life / perishability)       The one with the greater shelf life product will have greater bargaining power because they don't have to sell in a hurry</li> <li>elasticity of demand</li> </ol>"},{"location":"Economics/Microeconomics/02_Core_Principles/#benefits-of-scale","title":"Benefits of scale","text":"<p>You get larger benefits with lower costs if you focus on specialization at large scale</p> <p>Larger systems are more productive per unit input</p> <p>The average cost reduces when the volume of production increases</p> <p>eg: college mess cooking $$ \\text{Cost}(y) = y^\\alpha $$ Where \\(y =\\) output quantity</p> <p>Benefits of scale exists if \\(\\alpha &lt; 1\\)</p>"},{"location":"Economics/Microeconomics/03_Consumer_Theory/","title":"Consumer Theory","text":""},{"location":"Economics/Microeconomics/03_Consumer_Theory/#utility-maximization-model","title":"Utility-Maximization Model","text":"<p>Constrained optimization: Marginal Benefit = Marginal Cost 1. Objective: Maximize utility 2. Satisfy budget constraints</p>"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#utility","title":"Utility","text":""},{"location":"Economics/Microeconomics/03_Consumer_Theory/#indifference-curves","title":"Indifference Curves","text":"<p>At any point on the curve, the combination of the two will leave the consumer equally well off or equally satisfied\u2014hence indifferent.</p> Shows all combinations of __ that provide the same utility Slope gives Goods-Indifference Curve two commodities at the same time point MRS Fisher\u2019s Time-Indifference Curve same commodity at different time points"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#properties","title":"Properties","text":"Property Satisfies Assumption Higher indifference curve is preferred non-satiation Indifference curves are downward-sloping non-satiation Indifference curves never intersect transitivity Only one indifference curve through every combination completeness Convex to the origin Diminishing marginal utility &amp; MRS"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#utility_1","title":"Utility","text":"<p>Utility is ordinal; not nominal: can only rank</p> <p>Let \\(Q\\) be consumption</p> \\[ U \\propto Q \\]"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#marginal-utility","title":"Marginal Utility","text":"<p>Derivative of utility function</p> \\[ \\begin{aligned} \\dfrac{dU}{dQ} &amp;\\propto \\dfrac{1}{Q} \\\\ \\dfrac{dU}{dQ} &amp;&gt; 0 \\end{aligned} \\]"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#diminishing-marginal-utility","title":"Diminishing Marginal Utility","text":"<p>With increased consumption - total utility increases - marginal utility decreases</p> <p>This is why price of a good does not increase proportionately with the quantity. eg: Milk</p>"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#mrs","title":"MRS","text":"<p>Marginal Rate Substitute</p> <p>Rate at which you are willing to substitute one good for another</p> \\[ \\begin{aligned} \\text{MRS} &amp;= \\dfrac{dQ_2}{dQ_1} \\\\ &amp;= -\\dfrac{\\text{MU}_1}{\\text{MU}_2} \\end{aligned} \\]"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#diminishing-mrs","title":"Diminishing MRS","text":"<p>With increased consumption, MRS decreases</p>"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#budget","title":"Budget","text":""},{"location":"Economics/Microeconomics/03_Consumer_Theory/#expenditure","title":"Expenditure","text":"\\[ y = \\sum_i P_i Q_i \\] <p>where - \\(y =\\) spent amount - \\(P_i =\\) price of commodity \\(i\\) - \\(Q_i =\\) quantity of commodity \\(i\\)</p>"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#budget-line","title":"Budget Line","text":""},{"location":"Economics/Microeconomics/03_Consumer_Theory/#opportunity-set","title":"Opportunity Set","text":"<p>Set of choices available to you given the constraints</p>"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#mrt","title":"MRT","text":"<p>Marginal Rate of Transformation = Slope</p> <p>Shows the real/opportunity cost of \\(x\\) (how much we're sacrificing \\(y\\))</p> <p>MRT of producing/consuming \\(x\\) wrt \\(y\\) shows no of units of \\(y\\) to be sacrificed to increase the output/consumption of \\(x\\) by one unit</p> \\[ \\begin{aligned} y &amp;= f(x) \\\\ \\text{MRT}_{x,y} &amp;= -\\frac{\\mathrm{d} y}{\\mathrm{d} x} \\end{aligned} \\]"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#changes","title":"Changes","text":"Change Outcome Example Cost Change in Slope Increase in price of pizza Budget Change in intercept Decrease in income ## Choice <p>Highest indifference curve achievable given the budget: the tangency</p> <p></p> <p>Point at which MRT = MRS</p> <p>Rate at which you want = Rate at which market will allow</p>"},{"location":"Economics/Microeconomics/03_Consumer_Theory/#case-study","title":"Case Study","text":"<p>Cash Transfer vs Food Stamps</p> Cash Transfer Food Stamps Belief Everyone is responsible and makes the right choices Paternalism: Economist knows better than the person Limitation May lead to black market"},{"location":"Economics/Microeconomics/04_Demand/","title":"Demand","text":"<p>optimal quantity of commodities which consumers are willing and able to buy at a particular price, in a particular period</p> <p>if prices change, demand also changes</p>"},{"location":"Economics/Microeconomics/04_Demand/#law-of-demand","title":"Law of Demand","text":"<p>Assuming every factor (like preferences, current state affairs) remains constant</p> \\[ \\text{Demand} \\propto \\frac{1}{\\text{Price}} \\] <p>Causes - Income effect: +ve/-ve - Substitution effect/compensated demand: always -ve</p> Type of good Price Substitution effect Income effect Total effect Normal Inc -ve -ve -ve Dec +ve +ve +ve Inferior Inc -ve +ve depends Dec +ve -ve depends"},{"location":"Economics/Microeconomics/04_Demand/#individual-demand-curve","title":"Individual Demand Curve","text":"<p>Shows the relationship between price and quantity demanded</p> <p>Can vary from one individual to another even for the same commodity, due to Factors of Trade</p> <p>graph is a straight line with a negative slope</p> <ul> <li>x = Demand</li> <li>y = price</li> </ul> <p>Be careful of the slope, cuz the slope formula is for the inversed graph of the demand Curve Slope \\(= \\frac 1 {\\alpha_2}\\)</p> \\[ \\text{Demand as a function of price}\\\\ \\begin{aligned} D &amp;= f(P) \\\\ &amp;= \\alpha_1 - \\alpha_2 P \\\\ \\alpha_2 &amp;= -\\frac{\\partial D}{\\partial P} \\end{aligned} \\] Term Meaning \\(x\\) Demand \\(P\\) Price \\(\\alpha_2\\) Sensitivity of demand wrt priceThe no of units of demand decreases by when the price increases by 1 unit - Necessities have low sensitivity - Luxury goods have high sensitivity \\(\\alpha_1\\) Demand even when commodity is freeCaptures impact of all other factors that affect the demand (Income of consumers, advertising, etc)"},{"location":"Economics/Microeconomics/04_Demand/#change-in-price","title":"Change in Price","text":"Normal Good Inferior Good"},{"location":"Economics/Microeconomics/04_Demand/#graph-characteristics","title":"Graph Characteristics","text":"Horizontal Graph Vertical Graph Slope of graph \\(\\to 0\\) \\(\\to \\infty\\) \\(\\alpha_2\\) \\(\\to \\infty\\) \\(\\to 0\\) sensitivity High Low even a small change in price will cause variation in demand even large changes in price cause negligible change in demand Example when there are too many sellers and buyers; and only one seller changes the price medicines, food"},{"location":"Economics/Microeconomics/04_Demand/#market-demand","title":"Market Demand","text":"<p>total demand for a commodity in a market at a particular price</p> <p>summation of individual demands for commodity at particular prices</p>"},{"location":"Economics/Microeconomics/04_Demand/#giffen-goods","title":"Giffen Goods","text":"<p>Law of demand not applicable for them</p> <p>eg: BW TVs, Nokia Phone</p> <p>\\(\\text{demand} \\propto \\text{price}\\)</p>"},{"location":"Economics/Microeconomics/04_Demand/#factors-of-demand","title":"Factors of Demand","text":"<p>Out of the following factors, economic policies mainly target the expectations factor</p> \\[ x_1 =  \\alpha - \\alpha_1 p \\pm \\alpha_2 M \\pm \\alpha_3 W \\pm \\alpha_4 M^e \\pm \\alpha_5 p^e + \\alpha_6 A \\]"},{"location":"Economics/Microeconomics/04_Demand/#income-and-wealth","title":"Income and Wealth","text":"<p>More income and wealth means more spending and hence, higher demand</p> <ul> <li>Income is flow of money currently</li> <li>Wealth is what we have accumulated over time</li> </ul> RelationshipType ElasticDemand? Shift inindividual demand curve Consumption atsame price Example +ve \u2705 Rightward Greater Luxury Items Neutral \u274c None Same Staple foods -ve \u2705 Leftward Lower Inferior and Giffen goods"},{"location":"Economics/Microeconomics/04_Demand/#types-of-goods-based-on-income-elasticity","title":"Types of Goods based on Income Elasticity","text":"Type Income Elasticity Superior +ve Smartphones, LED TVs, Cars Necessities 0 Staple foods Inferior -ve B/W TV, tungsten bulbs, public transport"},{"location":"Economics/Microeconomics/04_Demand/#price-of-other-goods","title":"Price of Other goods","text":"<p>Cross Price is measured by \\(\\alpha_3\\)</p> <p>when price of complimentary good increases, the demand of main commodity decreases when price of substitute good increases, the demand of main commodity increases</p> <p>hence, if</p> <ul> <li>\\(\\alpha_3 &gt; 0\\) substitute</li> <li>\\(\\alpha_3 &lt; 0\\) complimentary</li> </ul>"},{"location":"Economics/Microeconomics/04_Demand/#types-of-goods-based-on-substitution","title":"Types of Goods based on substitution","text":"Type Meaning Example Complimentary goods Goods that are consumed together Car &amp; Petrol Substitute Goods Goods that are alternatives of each other Pepsi &amp; Coke"},{"location":"Economics/Microeconomics/04_Demand/#tastespreferences","title":"Tastes/Preferences","text":"<p>idk how to write this</p>"},{"location":"Economics/Microeconomics/04_Demand/#customer-expectations","title":"Customer Expectations","text":"Expectation Meaning Explanation Expected Price What I predict to be the price of the commodity in the future If expected price &gt; current price, then demand increases, which ends up increasing the price; whether or not it would\u2019ve happened naturally, nobody will know \ud83d\ude06; here, our expectations clearly affects the actual outcomeIf expected price &lt; current price, then demand decreases Expected What I predict to be my income in the future"},{"location":"Economics/Microeconomics/04_Demand/#market-size","title":"Market Size","text":"<p>No of buyers in the market</p> \\[ \\text{Demand} \\propto \\text{Market Size} \\]"},{"location":"Economics/Microeconomics/04_Demand/#advertising-expenditure","title":"Advertising Expenditure","text":"<p>Does not affect the product, but changes the perception of the product in consumers\u2019 heads</p> \\[ \\text{Demand} \\propto \\text{Advertising Expenditure} \\]"},{"location":"Economics/Microeconomics/04_Demand/#seasontime-of-the-year","title":"Season/Time of the Year","text":"<ul> <li>demand for cotton is greater in summer</li> <li>demand for wool is greater in winter</li> </ul>"},{"location":"Economics/Microeconomics/04_Demand/#jevons-paradox","title":"Jevon's Paradox","text":"<p>When advancements make a resource more efficient to use, per-capita consumption decreases, but aggregate consumption increases due to increased demand from reduction in cost</p> <p>Applications - Efficient cars decrease per-capita consumption but increase aggregate fuel consumption</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/","title":"Production Theory","text":"<p>Constrained optimization: Marginal Benefit = Marginal Cost 1. Maximize objective: Maximize Profit = Revenue - Cost 2. Constraint: Firms get to decide how much to produce</p> <p>Let - \\(q\\) be quantity produced by firm - \\(Q\\) be quantity produced by entire market</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#assumptions","title":"Assumptions","text":""},{"location":"Economics/Microeconomics/05_Production_Theory/#assumptions_1","title":"Assumptions","text":"Assumption Limitation All firms are identical: Same production quantity and marginal cost Not realistic Entry &amp; Exit not possible in the short run Entry &amp; Exit is possible in the long run without any barrier of entry Barriers to entry: Sunk costs, Input prices \\(r_k, r_l\\) are fixed Inputs could have upward sloping supplyWage rate increases with increased production"},{"location":"Economics/Microeconomics/05_Production_Theory/#quantity","title":"Quantity","text":""},{"location":"Economics/Microeconomics/05_Production_Theory/#factors-of-production","title":"Factors of Production","text":"Factor Example Short Run Long Run Land Fixed? Fixed? Labor \\(l\\) Variable Variable Capital \\(k\\) Machines, buildings Fixed Variable Technological innovation\\(A_t\\) <p>Long run is the time period for which all inputs are variable</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#production-function","title":"Production Function","text":"<p>Function that defines output as a function of input(s)</p> \\[ q = f(A_t, la, l, k) \\]"},{"location":"Economics/Microeconomics/05_Production_Theory/#total-factor-productivity","title":"Total Factor Productivity","text":"<p>Productivity increase due to technology/innovation, keeping other factors constant</p> <p>$$ A_t = \\dfrac{q}{k^\\alpha \\times l^\\beta} $$ \\(\\alpha, \\beta =\\) two inputs' respective shares of output</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#marginal-productivity","title":"Marginal Productivity","text":"\\[ \\begin{aligned} \\text{MP}_l^q &amp;= \\frac{\\partial q}{\\partial l} \\\\ \\text{MP}_k^q &amp;= \\frac{\\partial q}{\\partial k} \\end{aligned} \\]"},{"location":"Economics/Microeconomics/05_Production_Theory/#diminishing-marginal-productivity","title":"Diminishing Marginal Productivity","text":"<p>With increase in input - total productivity increases - marginal productivity decreases</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#graph","title":"Graph","text":"<ul> <li>y = MP</li> <li>x = input (l,k)</li> </ul> <p>The graph will be a straight line with a downward slope</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#isoquants","title":"Isoquants","text":"<ul> <li>Similar concept to indifference curves</li> <li>All the assumptions of indifference curves apply</li> </ul> Inputs \\(q\\) Perfectly Substitutable \\(l+k\\) Perfectly Non-SubstitutableLeontief Production Function \\(\\min(l, k)\\) Computers &amp; Programmers"},{"location":"Economics/Microeconomics/05_Production_Theory/#mrts","title":"MRTS","text":"<p>Marginal Rate of Technical Substitution</p> <p>Slope of Isoquant at a point, hence depends on the position on the isoquant</p> \\[ \\begin{aligned} \\text{MRTS} &amp;= -\\dfrac{\\partial k}{\\partial l} \\\\ &amp;= -\\dfrac{\\partial q}{\\partial l} \\times \\dfrac{\\partial k}{\\partial q} \\\\ &amp;= -\\dfrac{\\partial q}{\\partial l} / \\dfrac{\\partial q}{\\partial k} \\\\ &amp;= -\\text{MP}_l / \\text{MP}_k \\end{aligned} \\] <p></p> <p>Diminishing marginal productivity affects this</p> \\[ \\Delta l \\cdot \\text{MP}_l + \\Delta k \\cdot \\text{MP}_k = 0 \\]"},{"location":"Economics/Microeconomics/05_Production_Theory/#returns-to-scale","title":"Returns to Scale","text":"<p>What happens to production when you increase all inputs proportionally</p> <p>Not \\(k\\) vs \\(l\\)</p> Returns to Scale \\(f(a l, a k)\\) Example Constant \\(a \\cdot f(l, k)\\) Increasing \\(&gt; a \\cdot f(l, k)\\) Firm with increased inputs can specialize more Decreasing \\(&lt; a \\cdot f(l, k)\\) Firm with increased inputs means more confusion"},{"location":"Economics/Microeconomics/05_Production_Theory/#production-possibility-frontier","title":"Production Possibility Frontier","text":"<p>deals with the production capacity of an economy</p> <ul> <li>analyzes available resources</li> <li>predicts what can be produced with those resources, with the assumption that time and technology are constant</li> <li>analyzes various output mixes (combinations of different commodities)</li> </ul>"},{"location":"Economics/Microeconomics/05_Production_Theory/#production-possibility-curve","title":"Production Possibility curve","text":"<p>Curve that shows the optimal level of production for different combinations of outputs</p> <p>what is the maximum output that can be produced of various commodities</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#graph_1","title":"Graph","text":"<ul> <li>\\(y =\\) commodity 2</li> <li>\\(x =\\) commodity 1</li> </ul> <p>The graph will be a curve</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#mrt","title":"MRT","text":"<p>When we go from left to right, the slope increases from left to right, ie, cost of production of \\(x\\) increases</p> <ul> <li>\\(\\text{MP}_k^y, \\text{MP}_l^y\\) increases</li> <li>\\(\\text{MP}_k^x, \\text{MP}_l^x\\) decreases</li> </ul> <p>Example: if mango\u2019s MP is 2 and apple\u2019s MP is 4, then 4 units of apples are to be sacrificed to produce 2 units of mangoes</p> \\[ \\begin{aligned} x &amp;= l \\cdot MP_l + k \\cdot MP_k \\\\ \\mathrm{d} y &amp;= \\mathrm{d} l_{y}(MP_l^y) + \\mathrm{d} k_y(MP_k^y) \\\\ \\mathrm{d} x &amp;= \\mathrm{d} l_{x}(MP_l^x) + \\mathrm{d} k_x(MP_k^x) \\\\ \\frac{\\mathrm{d} y}{\\mathrm{d} x} &amp;= \\frac{MP_k^y}{MP_k^x} = \\frac{MP_l^y}{MP_l^x} \\end{aligned} \\]"},{"location":"Economics/Microeconomics/05_Production_Theory/#points-on-the-curve","title":"Points on the curve","text":"<ul> <li>inside are inefficient input mix - wasting profit</li> <li>on the curve are optimal input mix</li> <li>outside is impossible input mix</li> </ul>"},{"location":"Economics/Microeconomics/05_Production_Theory/#shift-of-ppc","title":"Shift of PPC","text":"<p>It depends on type of technological change that occurs</p> <p>also depends on change in the quantity and productivity of labor and capital</p> Type of Change increases productivity of labor increases productivity of capital Curve expands for Labor-intensive \u2705 \u274c motivates producers to increase labor rather than increasing machines labor-intensive good side Capital-intensive \u274c \u2705 motivates producers to increase machines rather than increasing  labor capital-intensive good side Neutral \u2705 \u2705 does not change the proportion in which labor and capital are used parallel shift (equal increase/decrease)"},{"location":"Economics/Microeconomics/05_Production_Theory/#output-mix","title":"Output Mix","text":"Efficient Inefficient Unattainable Curve optimal points on the curve points inside the curve points outside the curve Meaning Efficient performance Underperformance that level of output may be achieved in the future with the help of development, but not with the current resources Interpretation it is impossible to increase the output of one commodity without sacrificing the output of another it is possible to increase the output of one commodity without decreasing the output of another it is not possible to reach that output, even by using all resources Seen in Developed economies Developing economies"},{"location":"Economics/Microeconomics/05_Production_Theory/#costs","title":"Costs","text":""},{"location":"Economics/Microeconomics/05_Production_Theory/#types","title":"Types","text":"Category Type Meaning Example IDK Fixed Independent of quantity produced Machinery depreciation costLand Variable Dependent on quantity produced Wages of employeesUtilities bill Sunk Cannot be changed/undone regardless of whatever actionLong-Run Fixed Costs Education IDK explicit Direct Raw materials, labor costs implicit Indirect 1. i work in my own restaurant. I lost my time, which could\u2019ve been used somewhere else like some other restaurant/company2. investing in your company. I could\u2019ve invested it somewhere else, which could\u2019ve earned me more money"},{"location":"Economics/Microeconomics/05_Production_Theory/#cost-function","title":"Cost Function","text":"<p>$$ c = k r_k + l r_l $$ where - \\(r_k =\\) depreciation - \\(r_l =\\) wage rate</p> <p>Substituting for \\(k\\) or \\(l\\) from the production function will give the relationship between \\(C\\) and \\(q\\)</p> Marginal Cost \\(\\dfrac{\\partial c}{\\partial Q}\\) Average Cost \\(\\dfrac{c}{q}\\) AVCAverage Variable Cost \\(\\dfrac{c_v}{q}\\) AFCAverage Variable Cost \\(\\dfrac{c_f}{q}\\) ### Cost Curves <p></p> <ul> <li>AC decreases and then increases<ul> <li>Increasing quantity helps amortize the fixed cost</li> </ul> </li> </ul> Long-run Short-run \\(\\text{MC} = \\dfrac{r_l}{\\text{MP}_l}\\)"},{"location":"Economics/Microeconomics/05_Production_Theory/#isocost-curves","title":"Isocost Curves","text":""},{"location":"Economics/Microeconomics/05_Production_Theory/#efficient-input-mix","title":"Efficient Input Mix","text":"<p>Efficient input mix is the tangent of the isocost and isoquant curves</p> <p></p> <p>Increase in wages</p> <p></p> <p>At the optimal input mix - MRTS = \\(-\\dfrac{r_l}{r_k}\\) - \\(\\dfrac{\\text{MP}_l}{r_l} =\\dfrac{\\text{MP}_k}{r_k}\\)</p> <p>Efficient input mix is said to be</p> <ul> <li>Economically efficient   if the costs associated with an input mix is minimal</li> <li>Technically efficient   if it is impossible to maintain the same output, without keeping the same inputs   if any input decreases, the output also decreases<ul> <li>in India, we have a technically inefficient agricultural sector. This is proved by the fact that:   even though many people moved to tertiary sector, it did not affect agricultural output</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/05_Production_Theory/#long-run-cost-curve","title":"Long-Run Cost Curve","text":""},{"location":"Economics/Microeconomics/05_Production_Theory/#expansion-path","title":"Expansion Path","text":"<p>How does cost change with production quantity</p> \\(\\text{MP}_l = \\text{MP}_k\\) \\(\\text{MP}_l &gt; \\text{MP}_k\\) \\(\\text{MP}_l &lt; \\text{MP}_k\\)"},{"location":"Economics/Microeconomics/05_Production_Theory/#increasing-cost-of-inputs","title":"Increasing Cost of Inputs","text":""},{"location":"Economics/Microeconomics/05_Production_Theory/#long-run-vs-short-run","title":"Long-Run vs Short-Run","text":"<ul> <li>Long-run operations are always more efficient than short-run<ul> <li>You can optimize for both cost and capital in the long-run</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/05_Production_Theory/#profit","title":"Profit","text":"Type \\(\\pi\\) Accounting \\(R - C\\) Economic Corrected for opportunity costs ### Profit Maximization <p>Every company tries to maximize its profit.</p> <p>Profits can be maximized by cost minimization through optimization of input mix. The input mix depends on 1. productivity of input factor (high is preffered) 2. price of input factor (low is preffered)</p> <p>Labor is preferred for lower price; capital is preferred due to higher productivity</p> <p>Assumption: In the short run, no firm enters/exits; capital is a sunk cost</p> \\[ \\begin{aligned} \\pi_\\max &amp;= \\max_p \\Bigg \\{ R - C \\Bigg \\} \\\\ &amp;= \\max_p \\Bigg\\{ p q_m - c \\Big( q_m(p) \\Big) \\Bigg\\} \\end{aligned} \\] <p>where - \\(p\\) is unit sale price - \\(q(p)\\) is units sold - \\(c\u00a0\\Big( q(p) \\Big)\\) is cost - \\(c' \\Big( q(p) \\Big)\\) is the marginal cost</p> <p>$$ \\begin{aligned} \\dfrac{\\partial \\pi}{\\partial q} &amp;= \\dfrac{\\partial R}{\\partial q} - \\dfrac{\\partial C}{\\partial q}  \\ 0 &amp;= \\text{MR} - \\text{MC} \\ \\implies \\text{MR} &amp;= \\text{MC} \\end{aligned} $$ For perfectly-competitive market - \\(\\text{MR}(Q)\\) = \\(P(Q)\\) - Hence, at market equilibrium, \\(q\\) for which \\(\\text{MC}(Q) = P\\)</p> <p> </p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#average-profit","title":"Average Profit","text":"\\[ \\begin{aligned} \\text{AP} &amp;= \\dfrac{r}{q} - \\dfrac{c}{q} \\\\ &amp;= p - \\text{AC} \\end{aligned} \\]"},{"location":"Economics/Microeconomics/05_Production_Theory/#taxation","title":"Taxation","text":"Fixed Tax Per-Unit Tax Optimal Quantity No change Reduced Profit Reduced Reduced Curves No change"},{"location":"Economics/Microeconomics/05_Production_Theory/#shutdown-decision","title":"Shutdown Decision","text":"<p>Producer still part of the market, but does not produce anything</p> <p>Sometimes, producing something is better than nothing, as making low loss is better than extreme loss</p> <p>Short-run: Only shutdown if - revenue is lower than variable cost, as you have to pay fixed cost regardless - \\(Pq &lt; \\text{VC}\\) - ie, \\(P &lt; \\text{AVC}\\)</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#firm-vs-market-demand","title":"Firm vs Market Demand","text":"<p>$$ q(P) = Q(P) - S^0(P) $$ - \\(q(P)=\\) Firm demand - \\(Q(P)=\\) Market demand - \\(S^0(P) =\\) Residual demand = how much competition is selling</p> <p>Even with inelastic \\(Q\\), \\(q\\) can be elastic</p> \\[ \\begin{aligned} \\dfrac{dq}{dP} &amp;= \\dfrac{dQ}{dP} - \\dfrac{dS^0}{dP} \\\\ %% e_{di} &amp;= E_d - E_s \\end{aligned} \\] <p>\\(\\dfrac{dS^0}{dP} &gt; 0\\) as number of suppliers will inc with inc in selling price</p> <p>If there are \\(N\\) identical firms - \\(Q = Nq, S^0 = (N-1)q\\) - \\(e_{di} = N E_d - (N-1)E_s\\)     - \\(e_d =\\) Firm demand elasticity     - \\(E_d =\\) Market demand elasticity     - \\(E_d =\\) Market supply elasticity</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#firm-entryexit","title":"Firm Entry/Exit","text":"<p>Only in the long-run</p> <p>Happens when long-run profit &gt; Barrier of entry</p> Entry Exit"},{"location":"Economics/Microeconomics/05_Production_Theory/#outcome-of-competition","title":"Outcome of Competition","text":"<ul> <li>Forces each supplier to produce efficiently</li> <li>Forces entry and exit of suppliers until</li> </ul> <p>such that - Price = Marginal Cost = Min of Average Cost - Total profit of market = 0</p>"},{"location":"Economics/Microeconomics/05_Production_Theory/#different-firms","title":"Different Firms","text":""},{"location":"Economics/Microeconomics/06_Supply/","title":"Supply","text":"<p>is the optimal quantity which sellers are willing and able to sell at a given price, in a particular period</p>"},{"location":"Economics/Microeconomics/06_Supply/#law-of-supply","title":"Law of Supply","text":"<p>Assuming that factors are same, supply \\(\\propto\\) selling price of commodity</p>"},{"location":"Economics/Microeconomics/06_Supply/#contemporary-relation","title":"Contemporary Relation","text":"<p>\\(S = \\beta_1 + \\beta_2 P_{t}\\)</p> <ul> <li>land</li> <li>eggs</li> <li>milk</li> </ul>"},{"location":"Economics/Microeconomics/06_Supply/#lagged-relation","title":"Lagged Relation","text":"<p>\\(S = \\beta_1 + \\beta_2 P_{t-1}\\)</p> <p>For commodities with large gestation period, such as agricultural</p>"},{"location":"Economics/Microeconomics/06_Supply/#terms","title":"Terms","text":"<ul> <li>\\(\\beta_1 =\\) minimum selling price for which suppliers are willing to produce commodity</li> <li>\\(\\beta_2 =\\) sensitivity of supply wrt price</li> </ul>"},{"location":"Economics/Microeconomics/06_Supply/#graph","title":"Graph","text":"<ul> <li>y = P</li> <li>x = S</li> </ul> Shift Supply for the same price Outward Greater Inward Lower <p>All points on the supply curve show the optimal supplies Any point inside/outside the supply curve will not provide maximum profit</p>"},{"location":"Economics/Microeconomics/06_Supply/#individual-supply","title":"Individual Supply","text":"<p>Firm's Supply curve - relationship between market price and the amount that producer decides to produce - simply its MC curve</p> \\[ q = \\text{MC}(P) \\] <p>Every firm has different supply curve due to difference in cost structures</p> \\[ \\text{Cost} \\propto \\frac{1}{\\text{Scale}} \\quad (\\because \\text{Benefits of Scale}) \\] <p></p>"},{"location":"Economics/Microeconomics/06_Supply/#market-supply","title":"Market Supply","text":"<p>Total supply for a commodity in a market at a particular price</p> <p>Summation of supplies of commodity by different firms at particular prices</p> <p> </p> <p>In the long run - If any firm prices higher than the long run \\(P\\), they will not able to sell - If any firm prices lower than the long run \\(P\\), they will lose money</p> <p>Why don't firms want the entire market - Marginal cost is upward sloping</p> <p>Market supply curve is always more elastic that firm supply curve</p> <ol> <li>Get production function: \\(q = f(\\bar k, l, r_k, r_l)\\)</li> <li>Get cost function: \\(c=f(q)\\)</li> <li>Get quantity produced: \\(q=f(p)\\) from marginal cost</li> <li>Get market supply curve: \\(Q=Nq = N f(p)\\)</li> </ol>"},{"location":"Economics/Microeconomics/06_Supply/#factors-of-supply","title":"Factors of Supply","text":"\\[ S = \\beta_1 + \\beta_2 P + \\beta_3 F + \\beta_4 T + \\beta_5 E \\] Efficiency Technology Cost of Production input prices if cost inc, supply dec Expectations - if expected price/returns &gt; current price, then supply increases- else supply decreases Number of Sellers \\(S \\propto N\\)greater the no of sellers, greater the market supply Producer Sentiments mindset of producers - if it is positive, then supply increases- else supply decreases"},{"location":"Economics/Microeconomics/07_Elasticity/","title":"Elasticity","text":"<p>Partial derivatives are not a good way for comparing sensitivity, as unit of measurement is different and hence cannot be used</p> <ol> <li>for different commodities, or</li> <li>in different locations</li> </ol> <p>Elasticity is better than slope</p> <ol> <li>unit-free</li> <li>different goods</li> <li>different locations</li> </ol>"},{"location":"Economics/Microeconomics/07_Elasticity/#demand","title":"Demand","text":""},{"location":"Economics/Microeconomics/07_Elasticity/#price-elasticity-of-demand","title":"Price Elasticity of Demand","text":"<p>Proportional change in demand of commodity wrt proportional change in price of that commodity</p> <p>measure/responsives of the demand of a commodity to a given change in price, in terms of %</p> <p>\\(e\\) is generally negative (demand is generally negatively-related) but for giffen goods, \\(e\\) is positive</p> \\[ \\begin{aligned} e_x^p &amp;= \\frac{\\% \\Delta Q}{\\% \\Delta p} \\\\ &amp;= \\frac{\\color{orange} \\Delta Q/Q_0}{\\color{hotpink} \\Delta p/p_0} \\\\ &amp;= \\frac{\\color{orange} \\Delta Q}{\\color{hotpink} \\Delta p} \\frac{\\color{hotpink} p_0}{\\color{orange}{Q_0}} \\end{aligned} \\] <p>if price of commodity changes by some \\(k \\%\\), demand for it changes by \\(k \\times e \\%\\)</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#types","title":"Types","text":"<p>Note that the following shows the magnitude only</p> \\(\\vert e_x^p \\vert\\) Demand 0 perfectly inelastic(demand curve vertical - parallel to price axis) \\(0 &lt; \\vert e \\vert &lt; 1\\) inelastic (low sensitivity) 1 unitary elastic \\(1 &lt; \\vert e \\vert &lt; \\infty\\) elastic \\(\\infty\\) perfectly elastic(demand curve horizontal - parallel to demand axis)happens in perfectly-competitive market <p></p>"},{"location":"Economics/Microeconomics/07_Elasticity/#cases","title":"Cases","text":"<p>Consider profit functions \\(\\pi_1 = f_1(R, \\dots), \\pi_2 = f_2(R, \\dots),\\) where</p> <ul> <li>\\(\\pi =\\) profit of company</li> <li>R = revenue (incorporates pricing of both companies)</li> </ul> <p>Now - if \\(\\frac{\\delta \\pi_2}{\\delta \\pi_1} = 0,\\) perfectly competitive market   the profits of one company is independent of the profits of another company     - eg: agricultural farmers - else imperfect market     - eg: aviation industry</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#cross-price-elasticity-of-demand","title":"Cross Price Elasticity of Demand","text":"<p>Proportional change in demand of commodity wrt proportional change in price of another commodity</p> <p>proportional change may be % change</p> \\[ \\begin{aligned} e_{x_1}^{p_2} \\% &amp;= \\frac{\\% \\Delta x_1}{\\% \\Delta p_2} \\\\ &amp;= \\frac{\\color{orange} \\Delta x_1/x_1}{\\color{hotpink} \\Delta p_2/p_2} \\\\ &amp;= \\frac{\\color{orange} \\Delta x_1}{\\color{hotpink} \\Delta p_2} \\frac{\\color{hotpink} p_2}{\\color{orange}{x_1}} \\end{aligned} \\] <p>if price of another commodity changes by some \\(k \\%\\), demand of our main commodity changes by \\(k \\times e \\%\\)</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#sign","title":"Sign","text":"<ul> <li>-ve for complimentary goods</li> <li>0 for insensitive</li> <li>+ve for substitute goods</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#magnitude","title":"Magnitude","text":"<p>shows the degree of complimentarity/substitutability</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#determinants-of-elasticity-of-demand","title":"Determinants of Elasticity of Demand","text":"<p>i\u2019m using \\(|e|\\) to highlight only the magnitude</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#availability-of-substitute","title":"Availability of substitute","text":"\\[ |e| \\propto n_s \\] <ul> <li>more substitutes, more elastic<ul> <li>coke, pepsi</li> <li>rice, wheat</li> </ul> </li> <li>no substitutes, inelastic<ul> <li>petrol</li> <li>water</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#type-of-commodity","title":"Type of commodity","text":"<ul> <li>Luxury goods - elastic \\(|e| \\to \\infty\\)</li> <li>Necessities - inelastic \\(|e| \\to 0\\)</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#no-of-purposesuses-for-commodity","title":"No of purposes/uses for commodity","text":"\\[ |e| \\propto u \\] <p>more uses, more elastic</p> <ul> <li>eg: milk, steel</li> <li>if price increases, you will stop using for less important stuff</li> </ul> <p>fewer purposes, less elastic</p> <ul> <li>eg: petrol</li> <li>even if prices change, nothing really changes, you can only use petrol for car</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#proportion-of-income-spent-on-commodity","title":"Proportion of income spent on commodity","text":"\\[ |e| \\propto p \\] <p>more prop of income required, price elastic</p> <ul> <li>what you buy very frequently</li> <li>milk, petrol</li> </ul> <p>less prop of income required, price inelastic</p> <ul> <li>what you buy less frequently</li> <li>eg: flight tickets, junk food, noodles for me</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#time-period","title":"Time Period","text":"\\[ |e| \\propto T \\] <ul> <li>In the shortrun, demand is inelastic</li> <li>In the longrun, demand is elastic</li> </ul> <p>There is more time for consumers to reconsider their decision, to see if it is actually necessary to do so</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#addictiveness","title":"Addictiveness","text":"\\[ |e| \\propto \\frac 1 a \\] <ul> <li>More addictive product is inelastic</li> <li>less addictive product is elastic</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#total-revenue","title":"Total Revenue","text":"<p>basically finding the relationship b/w TR and demand</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#graph","title":"Graph","text":"<ul> <li>y = price</li> <li>x = Total Revenue</li> </ul> \\[ \\begin{aligned} TR &amp;= xp \\\\ \\frac{\\partial (TR)}{\\partial p} &amp;= x[e_x^{p} + 1] \\end{aligned} \\] <p>Changes in total revenue depends on</p> <ol> <li>quantity demand</li> <li>elasticity of demand</li> </ol> <p>The change is based on which factor is of greater magnitude</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#inelastic","title":"Inelastic","text":"\\[ |e| &lt; 1 \\] <p>For necessities, when price increases, total revenue increases</p> <p>reduction in price is pointless, and increase in price is good for profits</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#unitary-elastic","title":"Unitary Elastic","text":"\\[ |e| = 1 \\to \\frac{\\partial (xp)}{\\partial p} = 0 \\] <p>graph is vertical line parallel to price</p> <p>proportion of consumers\u2019 income spend does not change with change in price</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#elastic","title":"Elastic","text":"\\[ |e| &gt; 1 \\] <p>For luxury goods, when price increases, total revenue decreases</p> <p>discounts and offers is always a good policy, cuz the inc in profit due to inc in demand &gt; dec in profits due to dec in price</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#tr-using-graph","title":"TR using Graph","text":"<p>normal price-demand graph</p> <p>TR = quantity x price = area under graph</p> <p>with change in price</p> <ul> <li>For inelastic demand, the area of graph has minimal change</li> <li>For elastic demand, the area of graph has significant change</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#various-points-of-graph","title":"Various Points of Graph","text":"<p>draw geogebra graph</p> <ul> <li>At greater price, demand is elastic</li> <li>At center point, demand is unitary elastic</li> <li>At lower price, demand is inelastic</li> </ul> <p>Revenue is greatest at center point</p> <p></p> <p>This is due to Point Elasticity</p> <p>eg: if price of car goes from 100k to 50k, so many more people will buy but if price of car goes from 10k to 5k, not that many more people will buy</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#point-elasticity","title":"Point Elasticity","text":"<p>This wasn\u2019t taught in class, but I came across during Study Project research.</p> <p>Point elasticity is the elasticity at a point, duh.</p> <p>We know that elasticity is \\(e_x^p = \\dfrac{\\Delta x}{\\Delta p} \\dfrac{p}{{x}}\\). But for a single point, we do not have \\(\\Delta x\\) and \\(\\Delta p\\). So what we do is we take the slope of the graph instead.</p> <p>So the point elasticity of any point is</p> \\[ e_\\text{point} = \\frac{1}{\\text{Slope}} \\times \\frac{p}{{x}} \\]"},{"location":"Economics/Microeconomics/07_Elasticity/#income-elasticity","title":"Income Elasticity","text":"<p>Proportional change in demand of commodity wrt proportional change in income of consumers</p> <p>Shift in demand curve</p> \\[ \\begin{aligned} e_Q^I &amp;= \\frac{\\% \\Delta Q}{\\% \\Delta I} \\\\ &amp;= \\frac{\\color{orange} \\Delta Q/Q_0}{\\color{hotpink} \\Delta I/I_0} \\\\ &amp;= \\frac{\\color{orange} \\Delta Q}{\\color{hotpink} \\Delta I} \\frac{\\color{hotpink} I_0}{\\color{orange}{Q_0}} \\end{aligned} \\] <p>Engel Curve</p> <p></p> <p></p> Goods Elasticity Inferior \\(- \\infty &lt; e &lt; 0\\) Normal \\(0 &lt; e &lt; \\infty\\) Necessities \\(e \\to 0\\) luxury goods \\(e \\to \\infty\\)"},{"location":"Economics/Microeconomics/07_Elasticity/#relation-bw-income-elasticity-and-price-elasticity","title":"Relation bw Income Elasticity and Price Elasticity","text":"<p>\\(e^p \\propto e^m\\) High Income Elasticity \\(\\implies\\) High Price Elasticity</p> <p>This is because of</p> <ol> <li> <p>substitution effect</p> <ol> <li>when price decreases, you start buying more</li> <li>when price increases, you just don\u2019t buy this product and start buying alternatives</li> </ol> </li> <li> <p>income effect</p> <p>the real income gets changed</p> <ol> <li>when price decreases, you feel richer, cuz you can now buy more</li> <li>when price increases, you feel poorer, cuz you can now buy less</li> </ol> </li> </ol>"},{"location":"Economics/Microeconomics/07_Elasticity/#midpoint-formula-for-change","title":"Midpoint Formula for % change","text":"<p>Good as it gives the same answer regardless of direction of change</p> <p>helpful when we don\u2019t know what the initial value, ie we don\u2019t know what \\(\\frac p x\\) is</p> <p>let \\(v\\) be the value</p> \\[ \\begin{aligned} \\% \\text{ change} &amp;= \\frac{\\Delta v}{v_\\text{avg}} \\\\ v'&amp;= \\frac{|\\Delta v|}{(v_1 + v_2)/2} \\end{aligned} \\]"},{"location":"Economics/Microeconomics/07_Elasticity/#supply","title":"Supply","text":""},{"location":"Economics/Microeconomics/07_Elasticity/#elasticity-of-supply","title":"Elasticity of Supply","text":"<p>Proportional change in the supply of a commodity wrt proportional change of its price</p> <p>Always \\(0 &lt; e &lt; \\infty\\)</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#perfectly-inelastic","title":"perfectly inelastic","text":"<ul> <li> <p>\\(e \\propto T\\)</p> <ul> <li>sellers have small time to revise their decisions</li> <li>Real Estate in short run</li> </ul> </li> <li> <p>\\(e \\propto \\frac 1 G\\)</p> <ul> <li>or where gestation period is long(time taken to convert raw materials into final good)</li> <li>eg: agrigultural, large machinery</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#perfectly-elastic","title":"Perfectly elastic","text":"<p>perfectly competitive market</p> <p></p>"},{"location":"Economics/Microeconomics/07_Elasticity/#factors-of-elasticity-of-supply","title":"Factors of Elasticity of Supply","text":""},{"location":"Economics/Microeconomics/07_Elasticity/#nature-of-commodity","title":"Nature of Commodity","text":"<p>supply is elastic if it is possible to change the amount produced</p> <ul> <li>it is not possible for real estate</li> <li>it is possible for books, cars, manufactured goods</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#time","title":"Time","text":"<p>supply is more elastic if suppliers have time to respond</p> <p>supply is more elastic in long run, as there is time to find alternatives</p> <ul> <li>oil was nearly inelastic before cuz there were no other alternatives</li> <li>but now, suppliers have to make decision on production quantity based on how much they think the consumers will buy, as there are other alternatives</li> </ul>"},{"location":"Economics/Microeconomics/07_Elasticity/#interesting-question-on-farmer","title":"Interesting question on farmer","text":"<p>based on total revenue</p> <p>in slides</p> <ul> <li>the relation for eggs is lagged; the supplier wouldn\u2019t know the future price</li> <li>but for oil, they can do it instantly</li> </ul> <p>but the breaking eggs and reducing oil production only works in the short run, cuz consumers will find other alternatives</p> <p>for medicines, technological change is disliked by pharmaceutical companies</p> <p>but for luxury goods and computer manufacturing it is opposite, cuz demand for computers is elastic; so decrease in price would increase the total revenue </p>"},{"location":"Economics/Microeconomics/07_Elasticity/#applications","title":"Applications","text":""},{"location":"Economics/Microeconomics/07_Elasticity/#opec","title":"OPEC","text":"<p>(above)</p>"},{"location":"Economics/Microeconomics/07_Elasticity/#drugs","title":"Drugs","text":"<p>2 options to address</p> <ul> <li>Interdiction: cracking down on suppliers and restrict the supply for drugs</li> <li>Education: reduce the demand for drugs</li> </ul> <p>Keeping in mind that drugs are price-inelastic, education is more effective cuz</p> Interdiction Education supply dec same demand same dec price inc dec surviving cartels richer poorer addicts poorer better off crime inc dec"},{"location":"Economics/Microeconomics/07_Elasticity/#immigration","title":"Immigration","text":"<p>the increase in price for luxury housing will be greater than that for cars</p> supply demand luxury housing inelastic elastic cars elastic elastic"},{"location":"Economics/Microeconomics/08_Market_Equilibrium/","title":"Market Equilibrium","text":"<p>Market situation when price has reached the level where quantity supplied = quantity demand</p> <p>no tendency for change in price/decisions, as both producers and consumers are satisfied</p> <p>Auctions take place until equilibrium is reached</p>"},{"location":"Economics/Microeconomics/08_Market_Equilibrium/#idk","title":"IDK","text":""},{"location":"Economics/Microeconomics/08_Market_Equilibrium/#short-run","title":"Short-Run","text":""},{"location":"Economics/Microeconomics/08_Market_Equilibrium/#long-run","title":"Long-Run","text":"<ul> <li>Excess demand and supply tends to 0</li> <li>Total market profit = 0<ul> <li>Equilibrium forces an optimal no of parties</li> <li>If there was any possible profit, more parties will join</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/08_Market_Equilibrium/#obtaining-equilibrium","title":"Obtaining Equilibrium","text":"<ol> <li>Get \\(P\\) by equating market demand and market supply functions and solving them</li> <li>Get \\(Q\\) by substituting \\(P\\) in either function    (both gives the same answer)</li> </ol> <p>we can also draw a graph and obtain the point of interception of the supply and demand curves</p> <p></p>"},{"location":"Economics/Microeconomics/08_Market_Equilibrium/#dis-equilibrium","title":"Dis-equilibrium","text":"<p>Whenever there is a disequilibrium, the market automatically adjusts the price</p> Surplus Shortage Characteristic Excess Supply/Low Demand Excess Demand/Low Supply Buyers not willing to buy Sellers not willing to sell Price Actual &gt; Equilibrium Actual &lt; equilibrium AutomaticCorrection Actual price will reduce to equilibrium price automatically, as there is low demand actual price will increase to equilibrium price automatically, as there is low supply <p>Automatic market correction mechanism always occurs, given that</p> <ol> <li>Prices are flexible</li> <li>Market free from government intervention</li> <li>Both buyers and sellers are equally-informed about the market (internet has helped with making information symmetric); otherwise there will be one or more of the following</li> <li>sellers will manipulate buyers</li> <li>all the sellers will be selling bad products, as it more profitable to do so</li> <li>company recruiters will only get bad candidates as the salary they provide will be amazing for bad candidates, but too low for good candidates      so only the bad candidates will end up accepting the job</li> <li>buyers will be hesitant to pay higher price, even when the seller is justified to ask that much</li> </ol>"},{"location":"Economics/Microeconomics/08_Market_Equilibrium/#government","title":"Government","text":"<p>Whenever there is govt intervention in market dis-equilibrium, there will be always be a tendency for the existence of a parallel black market. Black market (not the illegal market one) is a market that sells commodity at price cheaper than govt-issued price.</p>"},{"location":"Economics/Microeconomics/08_Market_Equilibrium/#change-in-equilibrium","title":"Change in Equilibrium","text":"<p>Equilibrium Geogebra</p> Direction of Shift in Demand &amp; Supply Curve Cause Meaning Right/Left Change in constant Change in factors other than price Angular upward/downward Change in coefficient of price Change in price <p>Imagine an auction</p> Supply const Supply inc Supply dec demand const P sameQ same P \u2b07Q \u2b06 P \u2b06Q \u2b07 demand inc P \u2b06Q \u2b06 P ambiguousQ \u2b06 P \u2b06Q ambiguous demand dec P \u2b07Q \u2b07 P \u2b07Q ambiguous P ambiguousQ \u2b07 <p>Ambiguous \u2013&gt; it depends on the relative change b/w the supply and demand</p>"},{"location":"Economics/Microeconomics/09_Policies/","title":"Policies","text":"<p>Policy: Method to affect consumer behavior</p>"},{"location":"Economics/Microeconomics/09_Policies/#government","title":"Government","text":"<p>Government Intervention: - Sometimes, govt may not be satisfied with the market outcome - great where market is not perfectly competitive</p>"},{"location":"Economics/Microeconomics/09_Policies/#the-impossible-trinity","title":"The Impossible Trinity","text":"<pre><code>flowchart LR\nfer[Fixed Exchange Rate] &lt;--&gt; fcf[Free Capital Flow] &lt;--&gt; smp[Sovereign Money Policy] &lt;--&gt; fer</code></pre> <p>It is not possible to achieve all 3 simultaneously</p>"},{"location":"Economics/Microeconomics/09_Policies/#common-types","title":"Common Types","text":"<ol> <li>Price control</li> <li>Incentives: Many companies give lower prices for online booking, to reduce waiting times at queues; this is kinda like a subsidy. eg: in global village<ol> <li>Taxes</li> <li>Subsidies</li> </ol> </li> <li>Public provision</li> <li>Educational intervention: Persuasion &amp; information<ul> <li>Not very effective, as just providing information to humans does not guarantee that they will act on this information. According to classical economic assumption, this is perfect; refer Behavioral Economics</li> </ul> </li> <li>Laissez-faire (no intervention)</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#best-policies","title":"Best Policies","text":"<ul> <li>subsidies for basic necessities</li> <li>taxes for luxuries</li> </ul>"},{"location":"Economics/Microeconomics/09_Policies/#types-of-policies","title":"Types of Policies","text":"Policy Incorporates Monetary Central Bank Interest Rates Fiscal policy Ministry of Finance (Govt) Budget, Tax"},{"location":"Economics/Microeconomics/09_Policies/#price-control","title":"Price Control","text":"<p>when govt believes that market price is unfair to buyers/sellers</p> Price Ceiling Price Floor price limit legal maximum legal minimum govt believes price is high low to protect buyers sellers binding policy below equi price above equi price effects of binding 1. shortage2. non-price rationing3. creation of black market :(4. discrimination by sellers surplus sometimes, price ceiling may be 0 for illegal transactions such as prostitution, sale of organs if the surplus is not taken care of, the sellers will be unsatisfied1. this will cause a black market2. and consumers will buy from thereThe surplus is taken care of through non-price rationing by creating1. artificial demand   1. the govt purchases huge stock of agricultural produce and store in times of natural disasters2. limitation on production quantity - MSP for agriculture- minimum wage    - child labor dec    - income of workers inc    - cons    - causes unemployment    - students drop out cuz they get tempted by the salary    - on-job training reduces, as the companies are paying a lot, so cannot afford to waste time    - some benefit goes to teens from rich families"},{"location":"Economics/Microeconomics/09_Policies/#non-price-rationing","title":"Non-price rationing","text":"<p>restore equilibrium through imposing limits on buying</p> <p>help solve shortages</p> <p>eg:</p> <ol> <li>purchasing limit for gas cylinders</li> <li>issue tokens</li> <li>long wait times cause the buyers to rethink if they need to buy</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#rent-ceiling","title":"Rent Ceiling","text":"<ul> <li>in short run, it is fine</li> <li>in the long run, causes a huge shortage in houses</li> </ul> <p>\u201cthe best way to destroy a city, other than bombing\u201d \ud83d\udc80</p> <ol> <li>people pay lower rents</li> <li>both rich and poor tenants gain</li> <li>landlords lose</li> <li>maintenance worsens</li> <li>(more points)</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#alternative-to-rent-ceiling","title":"Alternative to Rent Ceiling","text":"<p>Housing subsidies</p> <p>effects</p> <ol> <li>no shortage</li> <li>equilibrium does not change</li> <li>helps only those in need</li> <li>however, the problem is funding the subsidies; which ends up increasing taxes</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#alternative-to-minimum-wage","title":"Alternative to minimum wage","text":"<p>wage subsidies for low earners</p> <p>the funding comes from taxing the rich</p> <p>but taxes de-incentives the rich, cuz they don\u2019t like it</p> <p>(i zoned out for this part \ud83d\ude1e)</p>"},{"location":"Economics/Microeconomics/09_Policies/#case-study-sugar","title":"Case Study: Sugar","text":"<p>US Sugar sellers faced a problem with repaying loans</p> <p>govt created a artificial demand for sugar</p> <p>purchased sugar at high price and sold to ethanol producers at lower price</p> <p>govt faced huge losses</p> <p>but helped farmers pay their loans</p>"},{"location":"Economics/Microeconomics/09_Policies/#taxes","title":"Taxes","text":"<p>compulsory payment citizens give the govt</p> <ol> <li>raise revenue/funds</li> <li>public projects, infrastucture, police</li> <li>discourage harmful activities</li> <li>(like sugary items)</li> <li>to make society less unfair and reduce income inequality</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#implementation","title":"Implementation","text":"<p>Taxes can be imposed on</p> <ul> <li>buyers</li> <li>sellers</li> <li>both</li> </ul> <p>in all 3 cases of taxation, the money buyers pay and sellers receive is the same</p> <p>Taxes = consumer payment - seller receiving</p> <p>\\(P_b = P_s + T\\)</p>"},{"location":"Economics/Microeconomics/09_Policies/#types-of-taxes","title":"Types of Taxes","text":""},{"location":"Economics/Microeconomics/09_Policies/#direct-tax","title":"Direct Tax","text":"<p>imposed on direct income of consumers</p> <p>eg: Wealth, Income Tax</p>"},{"location":"Economics/Microeconomics/09_Policies/#indirect-tax","title":"Indirect Tax","text":"<p>imposed on purchases/transactions</p>"},{"location":"Economics/Microeconomics/09_Policies/#specific-tax","title":"Specific Tax","text":"<p>imposed on quantity/volume of commodity</p> <p>eg: </p>"},{"location":"Economics/Microeconomics/09_Policies/#ad-volremsales-tax","title":"Ad volrem/Sales Tax","text":"<p>imposed on price of commodity</p> <p>eg: GST, VAT</p>"},{"location":"Economics/Microeconomics/09_Policies/#vat","title":"VAT","text":"<p>Tax imposed on the added value</p>"},{"location":"Economics/Microeconomics/09_Policies/#effects-of-taxes","title":"Effects of Taxes","text":"<ol> <li>quantity bought and sold reduces</li> <li>both buyers and sellers are affected adversely, regardless of who\u2019s taxed</li> <li>govt earns revenue</li> <li>price that buyers pay \\(\\ne\\) the amount the sellers get</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#effects-on-equi","title":"Effects on equi","text":"<p>equilibrium is maintained, but the equi quantity reduces \\(Q' &lt; Q\\)</p> <p>geogebra</p> <ol> <li>Find the quantity at which    demand-supply = tax (on the left side)</li> <li>Find new points on the supply and demand curve</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#tax-shifting","title":"Tax Shifting","text":"<p>the situation when burden of taxation is shifted from supplier to consumer, or vice-versa</p>"},{"location":"Economics/Microeconomics/09_Policies/#tax-burdenincidence","title":"Tax Burden/Incidence","text":"<p>burden \\(\\Delta P = |P' - P|\\)</p> <p>loss for supplier = \\(\\Delta Q \\times \\Delta P\\)</p> <p>\\(B \\propto \\frac 1 {|e|}\\)</p> <p>the relative burden depends on elasticity of supply and demand burden is heavier on inelastic side</p>"},{"location":"Economics/Microeconomics/09_Policies/#cases","title":"Cases","text":"Elasticity Elastic Inelastic Who\u2019s affected more \\(\\vert  e_d \\vert  = \\vert  e_s  \\vert\\) - - both equally \\(\\vert  e_d \\vert  &gt; \\vert  e_s  \\vert\\) demand supply sellers \\(\\vert  e_d \\vert  &lt; \\vert  e_s  \\vert\\) supply demand consumer <p>this is why basic necessities are not taxed, as</p> <ol> <li>demand is inelastic</li> <li>supply is elastic</li> <li>the burden of the taxes is borne by the farmers</li> <li>this would cause a shortage</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#case-study","title":"Case Study","text":"<p>in 1990, US imposed a new luxury tax, such as on yachts, with the objective of raising funds from the rich</p> <p>didn\u2019t work and repealed after a few years, because</p> <ol> <li>demand for yachts is elastic</li> <li>firstly, it is a luxury good</li> <li>there are many substitutes and \\(|e| \\propto n_s\\)</li> <li>supply for yachts is inelastic, or atleast in the short run</li> <li>hence, the producers felt the burden of the tax, rather than the rich consumers</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#subsidies","title":"Subsidies","text":"<p>compulsory payment citizens receive from the govt</p> <p>it is the exact opposite of tax</p> <p>uses</p> <ol> <li>help people in need</li> <li>+ve incentive, used to encourage certain actions</li> </ol> <p>Subsidies can be given to</p> <ol> <li>buyers</li> <li>sellers</li> <li>both</li> </ol> <p>price received by sellers = price paid by buyers + subsidies</p> <p>\\(P_s = P_b + S\\)</p>"},{"location":"Economics/Microeconomics/09_Policies/#effects","title":"Effects","text":"<ol> <li>Price received by \\(\\ne\\) Price paid by buyers</li> <li>Buyers pay less, sellers receive more</li> <li>Govt spending and investment increases</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#effects-on-equilibrium","title":"Effects on Equilibrium","text":"<p>equilibrium is maintained, but the equi quantity increases \\(Q' &gt; Q\\)</p> <p>Geogebra</p> <ol> <li>Find the quantity at which    supply-demand = tax (on the right side)</li> <li>Find new points on the supply and demand curve</li> </ol>"},{"location":"Economics/Microeconomics/09_Policies/#benefit","title":"Benefit","text":"<p>depends on the elasticity</p> <p>\\(B \\propto \\frac 1 {|e|}\\) (same like taxes)</p> <p>benefit is more for inelastic side</p> <p>\\(B_b + B_s = S\\)</p> <p>if both are inelastic, the benefits depends on the ratio of elasticity</p> <ul> <li>eg: For agricultural subsidies, it depends</li> <li>eg: For oil,</li> </ul>"},{"location":"Economics/Microeconomics/10_Welfare_Economics/","title":"Welfare Economics","text":"<p>Measure of well-being</p> <p>Normative (subjective) analysis</p>"},{"location":"Economics/Microeconomics/10_Welfare_Economics/#purpose","title":"Purpose","text":""},{"location":"Economics/Microeconomics/10_Welfare_Economics/#problem","title":"Problem","text":"<ul> <li>Unknown utility function</li> <li>Unknown satisfaction</li> </ul>"},{"location":"Economics/Microeconomics/10_Welfare_Economics/#solution","title":"Solution","text":"<ul> <li>Compensating variation<ul> <li>How much would one be willing to pay to increase their satisfaction</li> <li>How much would one be willing to pay not to be worse off</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/10_Welfare_Economics/#surplus","title":"Surplus","text":"Consumer Surplus Supplier Surplus Meaning Benefit that a consumer obtains beyond what they paid Benefit that a supplier obtains beyond what they\u00a0sold Formula Price as per Demand Function - Equilibrium Price= Willingness to Pay - Actual Payment Equilibrium Price - Price as per Supply Function= Actual Sale - Willingness to Sell= TR - Cost= Basically the profit Graphical \\(\\begin{aligned} &amp;= \\text{area below demand curve and above equilibrium price line} \\\\ &amp;= \\int \\limits_0^{Q} Q_d - \\int \\limits_0^{P} P_d \\end{aligned}\\) \\(\\begin{aligned} &amp;= \\text{area above supply curve and below price line} \\\\ \\\\ &amp;= \\int \\limits_0^{Q} Q_s - \\int \\limits_0^{P} P_s \\end{aligned}\\) Relationship with elasticity \\(\\text{CS} \\propto \\dfrac{1}{ \\vert e_d \\vert}\\) \\(\\text{PS} \\propto \\vert e_s \\vert\\) Relationship with equilibrium price \\(\\text{CS} \\propto \\dfrac 1 {P_{eq}}\\)Most affected: People who are inelasticLess affected:  People who are elastic \\(\\text{PS} \\propto P_{eq}\\) Individual Market"},{"location":"Economics/Microeconomics/10_Welfare_Economics/#total-benefit","title":"Total Benefit","text":"<p>Sum of producer and consumer surplus</p>"},{"location":"Economics/Microeconomics/11_Trade/","title":"Trade","text":"<p>We can live without trade, but the standard of living will be lower</p> <p>Trade happens only when it is cheaper to import than to produce it yourself</p> <p>we have already covered all this in principle of economics trade point</p> <p>When we trade, the total availability of goods and services increases, ie the post-trade PPC exceeds the pre-trade PPC</p> <p>Before trade, the production and consumption points will be the same After trade, the consumption point exceeds the production point</p>"},{"location":"Economics/Microeconomics/11_Trade/#factors-of-trade","title":"Factors of Trade","text":"<ol> <li>Preferences/Tastes</li> <li>Cost (what is the amount expected of the customer)</li> <li>Budget/Income (what is available to the customer)</li> <li>Threshold/Willingness to make the trade</li> </ol>"},{"location":"Economics/Microeconomics/11_Trade/#bases-for-trade","title":"Bases for Trade","text":"<p>shows what a country should import/export</p> <p>these minimize the opportunity costs</p> Theory Absolute Advantage A country must specialize in which it has absolute advantage, ie when it can- produce more at the same cost as others- produce same at a lower cost than others Comparative Advantage/Ricardian Model Countries should specialize in goods in which they have a higher relative advantage; ie goods where they have a lower opportunity cost relative to the trading partnerseems very obvious considering marginal net benefit for investment, and opportunity costendowment factors is the relative abundance/scarcity/productivity of labor and capital1. comp advantage in labor     - lower labor costs     - higher labor productivity2. comp advantage in capital goods     - more available capital (infrastructure, machinery)     - higher capital productivity <ol> <li>Calculate OC of all commodities in both countries \\(= \\frac{\\text{commodity production you  lose out on}}{\\text{what you chose to produce}}\\)</li> <li>Compare OC of each commodity b/w the countries</li> <li>The country with the lower OC for every commodity will produce that commodity</li> </ol>"},{"location":"Economics/Microeconomics/11_Trade/#empirical-tests-of-the-ricardian-model","title":"Empirical Tests of the Ricardian Model","text":"<p>cost \\(\\propto \\frac{1}{\\text{productivity}}\\)</p> <p>eg: AC ka efficiency</p>"},{"location":"Economics/Microeconomics/11_Trade/#us-vs-uk-productivity","title":"US vs UK productivity","text":"<p>Relative exports of 2 countries \\(\\propto\\) Relative output/productivity</p>"},{"location":"Economics/Microeconomics/11_Trade/#us-vs-japanese-costs","title":"US vs Japanese costs","text":"<p>Relative exports of 2 countries \\(\\propto \\frac{1}{\\text{Relative labor cost}}\\)</p>"},{"location":"Economics/Microeconomics/11_Trade/#international-trade","title":"International Trade","text":"<p>When you open for trade, the domestic price tends to the international price.</p> <p>country will</p> <ul> <li>export if domestic price &lt; international price</li> <li>import if domestic price &gt; international price</li> </ul> Export Import domestic price increases decreases supply in domestic market decreases increases domestic demand decreases increases Quantity Export = domestic supply - domestic demand Import = domestic demand - domestic supply Consumer Surplus decreases increases Producer Surplus increases decreases net benefit from trade (small triangle)"},{"location":"Economics/Microeconomics/11_Trade/#benefits-of-free-trade","title":"Benefits of Free Trade","text":"<ol> <li>increased variety of goods</li> <li>lower costs of production</li> <li>increased competition</li> <li>higher incentives</li> <li>better ideas</li> </ol> <p>The total surplus is always +ve in free trade, due to specialization and benefits of scale.</p>"},{"location":"Economics/Microeconomics/11_Trade/#tariffs","title":"Tariffs","text":"<p>Tax on imports</p> <p>it is economically bad, the losses of the consumers is not compensated but it is socially good</p> <p>Tariffs are better than quota, because it generates revenue for the govt Quota - govt restricts the quantity of commodity imported/exported</p>"},{"location":"Economics/Microeconomics/11_Trade/#effects","title":"Effects","text":"<p>Assuming that the country is small, such that tariffs does not affect world price</p> <ul> <li>imports and total surplus decreases (closer to no-trade equi), but</li> <li>consumer surplus dec</li> <li>producer surplus inc</li> <li>domestic price increases</li> <li>domestic suppliers are protected</li> <li>unemployment doesn\u2019t rise</li> <li>Govt earns tariff revenue = quantity imported x tariff rate</li> </ul> <p>the reduction in total surplus due to a govt policy is called deadweight loss of the policy</p>"},{"location":"Economics/Microeconomics/11_Trade/#why-tariffs","title":"Why Tariffs?","text":"<p>we need tariffs because</p> <p>without tariffs</p> <ol> <li>jobs are shipped abroad</li> <li>national security endangered</li> <li>highly dependent on another country</li> <li>this is why US is able to interfere in other countries policies, as other countries are dependent on them</li> <li>infant industries protected</li> <li>avoids unfair competition</li> <li>cheap labor</li> <li>environmental standards</li> <li>tariffs as a political tool</li> <li>reduces inequality</li> </ol>"},{"location":"Economics/Microeconomics/11_Trade/#few-caveats","title":"Few Caveats","text":"<ul> <li>Fairness: Few countries over-use their power<ul> <li>Exploitation of workers in developing nations</li> </ul> </li> </ul>"},{"location":"Economics/Microeconomics/11_Trade/#pareto-optimal-policy","title":"Pareto optimal policy","text":"<p>Any govt policy, where some people benefit and some lose out, is optimal if those who benefit can compensate for the people who lose out</p>"},{"location":"Economics/Public_Policy/","title":"Public Policy","text":""},{"location":"Economics/Public_Policy/#references","title":"References","text":"<ul> <li>Microeconomics for Public Policy | Andrew Heiss | Georgia State University</li> <li>Economy, Society, and Public Policy</li> <li>Public Finance in Canada | Yacucha Econ and Stats</li> </ul>"},{"location":"HSS_Electives/Foreign_Policy/","title":"Foreign Policy","text":""},{"location":"HSS_Electives/Foreign_Policy/#references","title":"References","text":"<ul> <li> Foreign Policy | Brian Urlacher</li> <li> </li> </ul>"},{"location":"HSS_Electives/IDS/","title":"Introduction of Development Studies","text":""},{"location":"HSS_Electives/IDS/#recommend-watching","title":"Recommend Watching","text":"<ul> <li> The Railway Men</li> <li> BP Oil Spill Documentary</li> <li> Matrabhumi</li> </ul>"},{"location":"HSS_Electives/IDS/01_Introduction/","title":"Introduction","text":""},{"location":"HSS_Electives/IDS/01_Introduction/#culture","title":"Culture","text":"<ul> <li>What should be adapted</li> <li>What should be preserved</li> </ul>"},{"location":"HSS_Electives/IDS/01_Introduction/#idk","title":"IDK","text":"<p>Swadeshi movement</p>"},{"location":"HSS_Electives/IDS/01_Introduction/#under-development-causes","title":"Under-development Causes","text":"<ul> <li>Lack of leadership</li> <li>Political instability</li> <li>Corruption</li> <li>Law of civic culture</li> <li>Cultural resistance</li> <li>Misues of foreign assistant</li> <li>Over-dependence on agriculture</li> <li>Lowe per capita incme</li> <li>Low literacy, Low skill, Lack of basic services</li> <li>Lack of natural resources</li> </ul>"},{"location":"HSS_Electives/IDS/01_Introduction/#reasons-for-japans-success","title":"Reasons for Japan\u2019s Success","text":"<ul> <li>Adapt to geographical situation despite natural disasters</li> <li>Highly-literate population</li> <li>Civic culture</li> <li>Early development of transport &amp; banking systems</li> <li>Niche technology development</li> <li>Strong cooperation between govt &amp; businesses</li> </ul>"},{"location":"HSS_Electives/IDS/01_Introduction/#indicators-of-development","title":"Indicators of Development","text":"<ul> <li>Economic development: GDP, GNP, PPP (Purchasing Power Parity)</li> <li>Occupational structure</li> <li>Energy consumption</li> <li>Transportation &amp; communication</li> <li>Consumption of manufactured metal per peron</li> <li>Literacy rate</li> <li>% of income spent on consumption of food</li> <li>Nutritional intake: Caloric, Proteins</li> <li>Per capita savings</li> <li>Infrastructure: Roads, Railways</li> <li>GNH</li> </ul> <p>These are not causes of development</p>"},{"location":"HSS_Electives/IDS/01_Introduction/#gnh-gross-national-happiness","title":"GNH - Gross National Happiness","text":"<ul> <li>Sustainable &amp; equitable socio-economic development</li> <li>Environmental conservation</li> <li>Preservation of identity &amp; culture</li> <li>Good governance</li> </ul> <p>Case study of Bhutan</p>"},{"location":"HSS_Electives/IDS/02_Modernization/","title":"Modernization Theory","text":"<p>Shift from traditional to \u201cmodern\u201d similar to developed countries</p> <ul> <li>Formal education</li> <li>Market-based economics</li> <li>Focus on economic growth as primary indicator of development</li> <li>Political systems</li> <li>Democratic</li> <li>Decentralized</li> <li>Secular <ul> <li>Religion should be unto individual choice</li> </ul> </li> </ul> <p>Claims that economic growth, cultural change, and political change go together</p> <p>Emphasize on dualism: </p>"},{"location":"HSS_Electives/IDS/02_Modernization/#walt-rostov-5-stages-to-development","title":"Walt Rostov 5 Stages to Development","text":"<ol> <li>Change from rigid traditional systems, and eliminate any resistance to them</li> <li>Preconditions for take-off</li> <li>Progressive leadership</li> <li>Greater flexibility</li> <li>Openness to new technology</li> <li>Greater diversity of products</li> <li>Take off</li> <li>Industrial growth</li> <li>Urbanization</li> <li>Drive to maturity</li> <li>Use of technology: Increase productivity and efficiency</li> <li>International trade: Bargaining power</li> <li>Emphasis on population<ul> <li>Demographic dividend/disaster</li> <li>Education &amp; Skill development</li> </ul> </li> <li>Final Stage</li> <li>Mass consumption</li> <li>High incomes</li> <li>Majority of workspace in service sector</li> <li>Move towards welfare state</li> </ol>"},{"location":"HSS_Electives/IDS/02_Modernization/#limitations","title":"Limitations","text":"<ul> <li>Euro-centric model and not easily applicable for other countries</li> <li>Assumes that all countries have the same resources and capability</li> <li>Does not account for problems that developing countries face</li> <li>Assumes that all countries can take such policies</li> <li>Focus on service sector causes scarcity in the agricultural and industrial sector, such as cleaning, etc</li> </ul>"},{"location":"HSS_Electives/IDS/02_Modernization/#criticism","title":"Criticism","text":"<ul> <li>Not Value neutral and promotes capitalism and western values</li> <li>May increase inequality within countries</li> <li>Exploits unlimited resources for industrial expansion at the cost of ecological issues</li> <li>Devalues traditional values and social institutions</li> </ul>"},{"location":"HSS_Electives/IDS/02_Modernization/#case-study-asian-tiger-economies","title":"Case Study: Asian Tiger Economies","text":"<p>Implemented modernization without ensuring decentralization</p>"},{"location":"HSS_Electives/IDS/02_Modernization/#idk","title":"IDK","text":"<ul> <li>Capitalism</li> <li>Socialism</li> <li>Communism</li> </ul>"},{"location":"HSS_Electives/IDS/03_IDK/","title":"Case Studies","text":""},{"location":"HSS_Electives/IDS/03_IDK/#_1","title":"Case Studies","text":""},{"location":"HSS_Electives/IDS/03_IDK/#ghana-chocolate","title":"Ghana Chocolate","text":""},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/","title":"Neo Liberalism Development Theory","text":"<p>Unregulated capitalist system with set of economic policies that limit restrictions on manufacturing and reduces barriers to commerce, reduce tariffs and free trade</p>"},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/#features","title":"Features","text":"<ul> <li>Rule of market, regardless of any social harm or market failure</li> <li>Deregulation: Limit govt regulation on anything that will reduce safety of jobs and profits</li> <li>Minimum Govt Intervention: \u201cMinimum Government, Max Governance\u201d</li> <li>Reduce subsidy on Goods and Services</li> <li>Encouraged Foreign Collaborations</li> <li> <p>New Industrial, Trade and Tax Policy</p> </li> <li> <p>Individual freedoms and responsibility: Meritocracy</p> </li> <li>Privatization</li> <li>Market Society, on top of Market Economy</li> <li>Import technology</li> </ul>"},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/#limitations","title":"Limitations","text":"<ul> <li>Misguided free market approach to public services</li> <li>Monopoly</li> <li>Increased financial instability</li> <li>Inequality</li> <li>New economic colonization: Debt Traps</li> </ul>"},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/#privatization","title":"Privatization","text":""},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/#advantages","title":"Advantages","text":"<ul> <li>Improved efficiency</li> <li>Sense of responsibliltiy</li> <li>Scientific management</li> <li>Reduction in political interference</li> <li>Encouragement of new innovations</li> </ul>"},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/#disadvantages","title":"Disadvantages","text":"<ul> <li>Lack of social welfare</li> <li>Class struggle</li> <li>Increased inequality</li> <li>Increased unemployment</li> <li>Exploitation of weaker section</li> </ul> <p>Due to the above, increased crime and/or violence</p>"},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/#what-is-good-governance","title":"What is good governance?","text":""},{"location":"HSS_Electives/IDS/04_Neo_Liberalism_Development_Theory/#case-studies","title":"Case Studies","text":"Market Failure Bhopal Gas Tragedy Coca-Cola Adoption in India Greece Govt Intervention BP Oil Spill Economic Colonization China Debt Trap on African countries, Pakistan, Sri Lanka"},{"location":"HSS_Electives/IDS/05_HDI/","title":"Human Development Index Model","text":"<ul> <li>Argues for holistic development</li> <li>Capability approach</li> </ul> <p>Freedom </p> <p>Economic growth should only be a means and not an end goal</p> <p>Focus on individual development, rather than market development</p> <ul> <li>Health</li> <li>Education</li> <li>Standard of living</li> </ul> <p>State should be a integral part of the system</p>"},{"location":"HSS_Electives/IDS/05_HDI/#hdi","title":"HDI","text":"<p>Human Development Index</p> Dimension Indicator Min Max Health Life expectancy at birth Education Expected years of schooling 15 Average years of schooling 15 Standard of living Gross National Income per capita"},{"location":"HSS_Electives/IDS/05_HDI/#encourages","title":"Encourages","text":"<ul> <li>Capability</li> <li>Beings: Conscience</li> <li>Productivity</li> <li>Empowerment</li> </ul>"},{"location":"HSS_Electives/IDS/05_HDI/#significance","title":"Significance","text":"<ul> <li>Helps control population</li> <li>Increase efficiency</li> <li>Other resources are better utilized</li> <li>Society becomes healthy and safe</li> <li>Conservation of environment</li> </ul>"},{"location":"HSS_Electives/IDS/05_HDI/#idk","title":"IDk","text":""},{"location":"HSS_Electives/IDS/05_HDI/#welfare-states","title":"Welfare States","text":"<ul> <li>Financial services</li> <li>Social services</li> <li>Non-cash benefits</li> </ul> <p>Modern welfare states: France, Finland, Belgium, Netherlands</p>"},{"location":"HSS_Electives/IDS/05_HDI/#idk_1","title":"IDK","text":"<ul> <li>Military expenditure</li> <li>Vicious cycle of offensive and defensive</li> <li>Govts don\u2019t keep education as a point in their agenda</li> <li>Life expectancy: Mental health is often forgotten </li> <li>Electricity consumption as an indicator of development is not ideal, as governments will be incentivized to increase consumption and hence increase CO2</li> <li>Creating more awareness about smoking</li> </ul>"},{"location":"HSS_Electives/IDS/05_HDI/#case-studies","title":"Case Studies","text":""},{"location":"HSS_Electives/IDS/05_HDI/#bihar-sithamali","title":"Bihar Sithamali","text":"<p>Open Defecation: Gives a chance to interact with each other</p>"},{"location":"HSS_Electives/IDS/05_HDI/#kerala-development-model","title":"Kerala Development Model","text":""},{"location":"HSS_Electives/IDS/05_HDI/#advantages","title":"Advantages","text":""},{"location":"HSS_Electives/IDS/05_HDI/#disadvantages","title":"Disadvantages","text":"<ul> <li>Agricultural stagnation</li> <li>Industrial stagnation</li> <li>Power deficiency</li> <li>Lack of good infrastructure</li> <li>Private sector declining</li> <li>Rising local unemployment in the state</li> <li>Poor investment in climate (2018, 2019, 2020 Floods)</li> <li>Headland workers: Harthal and Bandh</li> </ul>"},{"location":"HSS_Electives/IDS/05_HDI/#idk_2","title":"IDK","text":"<ul> <li>Remove table</li> <li>3<sup>rd</sup> person: This paper highlights/attempts</li> <li>1<sup>st</sup> person may cause bias</li> <li>Future/present-perfect study<ul> <li>Will analyze</li> <li>analyzes</li> </ul> </li> </ul>"},{"location":"HSS_Electives/IDS/05_HDI/#drawbacks","title":"Drawbacks","text":"<p>Measurement</p> <ul> <li>Civil war</li> <li>We are not considering other external factors such as</li> <li>Invasion</li> <li>Natural disasters</li> </ul>"},{"location":"HSS_Electives/IDS/05_HDI/#steps","title":"Steps","text":"<ul> <li>Objective</li> <li>Measurement</li> <li>Outcome</li> </ul>"},{"location":"HSS_Electives/IDS/06_Basic_Needs/","title":"Basic Needs Model","text":"<p>Everyone\u2019s talking about poverty, but no one has taken action</p>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/","title":"Right to Development","text":"<p>Development must be seen as a fundamental human right, regardless of whatever the type of government</p> <p>Rights are those claims and demands of an individual/group of individuals to live a good life which are accepted by the community/society and recognized by the State</p> <p>Human rights are generally defined as these rights, which are inherent in our nature, and without, which we cannot live as human being.</p> <p>Goal of development is enlargement of human choices</p>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#aspects-of-development","title":"Aspects of Development","text":"<ul> <li>Human security</li> <li>Economic freedom</li> <li>Political security</li> </ul>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#human-security","title":"Human Security","text":"<p>Protecting people from critical and pervasive threats and situations, building on their strengths and aspirations. It also means creating systems that give people the building blocks of survival, dignity and livelihood</p> <p>Lack of human security is costly for development, mainly through reduction in productivity</p> <p>Imbalanced development that involves horizontal inequalities is a major source of conflict, which leads to a vicious cycle.</p>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#traditional-vs-human-security","title":"Traditional vs Human Security","text":"Traditional Human Promote demands ascribed to the state protection of individuals Oriented State-centered People-centered Examples State boundariesPeopleInstitutionsValues Below Participants StateCentralized CommunityDecentralized"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#aspects-of-security","title":"Aspects of security","text":"Threats Economic UnemploymentEconomic inequality Food Health Infectious disease Environment Environmental pollution <ul> <li>Health</li> <li>Environmental</li> <li>Person</li> <li>Community</li> <li>Political</li> </ul>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#unemployment","title":"Unemployment","text":"<p>Data in India is not collected the right way</p> <p>Only those who report themselves as unemployed to state government are calculated as part of the </p>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#idk","title":"IDK","text":"<ul> <li>Rights-Holders</li> <li>entitled to rights</li> <li>entitled to claim rights</li> <li>entitled to hold duty-bearer accountable</li> <li>responsible to respect rights of others</li> <li>Duty-bearer</li> <li>Obligated to </li> </ul>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#principles-of-hrba","title":"Principles of HRBA","text":"<ul> <li>Direct links to human rights</li> <li>Common Participation</li> </ul>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#types-of-models","title":"Types of Models","text":"<ul> <li>Top-down</li> <li>Bottom-up: Better</li> </ul>"},{"location":"HSS_Electives/IDS/07_Right_To_Development/#case-studies","title":"Case Studies","text":""},{"location":"HSS_Electives/IDS/07_Right_To_Development/#amul","title":"Amul","text":""},{"location":"HSS_Electives/International_Relations/","title":"International Relations","text":""},{"location":"HSS_Electives/International_Relations/#overview","title":"Overview","text":"<p>How countries interact with each other</p> <ol> <li>History</li> <li>Theories of International Relations</li> <li>Issues of International Relations</li> </ol>"},{"location":"HSS_Electives/International_Relations/#theme-for-research-project","title":"Theme for research project","text":"<p>Suggest a proposal to UN about possible conflict, with sufficient reasons</p>"},{"location":"HSS_Electives/International_Relations/#watch","title":"Watch","text":"<ul> <li> how to become a tyrant</li> <li> Turning point</li> <li> The Mauritanian</li> <li> VICE movie on 2<sup>nd</sup> Gulf War</li> <li> Oslo</li> <li> BBC World Service - The Lazarus Heist</li> </ul>"},{"location":"HSS_Electives/International_Relations/#references","title":"References","text":"<ul> <li> International Relations | Dr. Devika Sharma | BITS Pilani Dubai Campus</li> <li> International Relations | Brian Urlacher</li> <li> International Security | Brian Urlacher</li> <li> The Story of \"Civilization\" | Predictive History Jiang Xueqin</li> <li> Geo-Strategy: Predicting the Future | Predictive History Jiang Xueqin</li> </ul>"},{"location":"HSS_Electives/International_Relations/01_Intro/","title":"01 Intro","text":""},{"location":"HSS_Electives/International_Relations/01_Intro/#international-relations","title":"International Relations","text":"<p>The study of what governs international peace and conflict</p> <p>International relations is not about morals, it's about survival.</p>"},{"location":"HSS_Electives/International_Relations/01_Intro/#why-learn-ir","title":"Why Learn IR","text":"<p>Why not just learn about internal affairs of a country? To see the global picture, we have to see the relations b/w countries</p>"},{"location":"HSS_Electives/International_Relations/01_Intro/#stages-of-political-relations","title":"Stages of Political Relations","text":"<p>For a country to have relations with another country</p> <ol> <li>recognize the other 'state'</li> <li>treaty</li> <li> <p>trade with them</p> <p>if you trade, then you don't go to war because </p> <ol> <li>you are dependent on each other</li> <li>help each other out</li> </ol> </li> </ol>"},{"location":"HSS_Electives/International_Relations/01_Intro/#unipolar-vs-bipolar-world","title":"Unipolar vs Bipolar world","text":"<p>Which is better? \ud83e\udd14</p> <p>Realists say that bipolar world is the most stable, and unipolar is least stable</p>"},{"location":"HSS_Electives/International_Relations/01_Intro/#afghanistan","title":"Afghanistan","text":"<p>Why is it important</p> <ol> <li>Geopolitical</li> <li>Resources</li> <li>Terrorism</li> <li>Instability of the State</li> <li>Global Power Balance</li> <li>Refugees</li> <li>Democracy/Liberacy/Women's Rights</li> </ol>"},{"location":"HSS_Electives/International_Relations/01_Intro/#us","title":"US","text":"<p>military</p> <p>economics</p>"},{"location":"HSS_Electives/International_Relations/01_Intro/#us-in-afghanistan","title":"US in Afghanistan","text":"<p>Afghanistan was initially dependent on the soviets. But US did not like that. Hence, it supported the Mujahidin guerillas to overthrow the govt. Then the govt was unstable and the values were against the US; then 9/11 happened. Then, the US went to intervene. I feel like US just went there to exploit the opium resources of Afghanistan</p>"},{"location":"HSS_Electives/International_Relations/01_Intro/#failure-in-afghanistan","title":"Failure in Afghanistan","text":"<p>it highlights America's decline</p> <p>Now, everyone's opinion of US will go down because they just spent 10-15yrs in a war (which wasn't even theirs), used up so much resources, failed and came back; and within a few weeks or so, the Taliban takes over.</p>"},{"location":"HSS_Electives/International_Relations/02_History/","title":"02 History","text":""},{"location":"HSS_Electives/International_Relations/02_History/#need-for-history","title":"Need for History","text":"<ol> <li>Give examples for theory</li> <li>Justifications for proposals and ideas</li> <li>To understand the present (Lot of conflicts in middle east are due to World War 1)</li> <li>Notice patterns</li> </ol>"},{"location":"HSS_Electives/International_Relations/02_History/#world-war-1","title":"World War 1","text":"<p>Started in Europe, mainly due high speed of industrialization; everyone believed that the best way to progress was through industrialization.</p>"},{"location":"HSS_Electives/International_Relations/02_History/#germany","title":"Germany","text":"<p>was dissatisfied and get surrounded by its enemies quickly</p>"},{"location":"HSS_Electives/International_Relations/02_History/#reason-for-dissatisfaction","title":"Reason for dissatisfaction","text":"<ol> <li>nationalism and wanted an empire</li> <li>Franz Ferdinand got assassinated</li> </ol> <p>The political objective of the assassination was to free Bosnia of Austria-Hungarian rule and established of a common South Slav (\"Yugoslav\") state. The assassination precipitated the July crisis which lead to Austria-Hungary declaring war on Serbia and the start of the First World War</p>"},{"location":"HSS_Electives/International_Relations/02_History/#parties","title":"Parties","text":"Allies (west) Alliance (germany) US (joined late) Germany france Austro-hungary russia Italy (switched sides from the allies) UK Ottoman empire China Japan <p>Italy switched sides cuz it felt like it didn't get much from the war, even though it did a lot</p>"},{"location":"HSS_Electives/International_Relations/02_History/#why-us-joined-ww1","title":"Why US joined WW1","text":"<p>Mostly financial</p> <ol> <li>To get european allies by supporting</li> <li>Maritime - Blockade of ships by Germany</li> </ol> <p>Germany sank many American merchant ships around the British Isles, using submarines, prompting the American entry into the war.</p>"},{"location":"HSS_Electives/International_Relations/02_History/#far-east","title":"Far East","text":"<p>China v Japan were having an ongoing conflict over territory</p> <p>Both Japan and China were with the Allies against germany and Austria-hungary</p>"},{"location":"HSS_Electives/International_Relations/02_History/#china","title":"China","text":"<p>basically china wanted to help the Allies in exchange for help with land disputes with japan</p>"},{"location":"HSS_Electives/International_Relations/02_History/#japan","title":"Japan","text":"<p>Japan already had a military alliance with Britain, but that did not obligate it to enter the war. It joined the Allies in order to make territorial gains: because they wanted to acquire the lands in Far East under German control</p>"},{"location":"HSS_Electives/International_Relations/02_History/#world-war-2","title":"World War 2","text":""},{"location":"HSS_Electives/International_Relations/02_History/#reasons","title":"Reasons","text":"<ol> <li>Treaty of Versailles was too unfair to Germany    At the end of WW1, the entire reparation costs and blame was put on Germany, even though they could not afford to do so</li> <li>The people felt very embarassed and angry and hence wanted to change    Hitler used this angst as fuel for his propaganda</li> <li>Hitler's occupations and torturing of jews and communists</li> </ol>"},{"location":"HSS_Electives/International_Relations/02_History/#parties_1","title":"Parties","text":"Allies Axis France Germany UK Italy US Japan Soviet China <p>US and Soviet were together?! \ud83d\ude32</p>"},{"location":"HSS_Electives/International_Relations/02_History/#why-did-japan-join-axis","title":"Why did Japan join axis","text":"<p>It wanted to become independent from the western world</p>"},{"location":"HSS_Electives/International_Relations/02_History/#end-of-ww2","title":"End of WW2","text":"<p>When Germany had already retreated, Japan was still trying to fight.</p> <p>Japan bombed pearl harbour; US bombed hiroshima and nagasaki using an atomic bomb.</p>"},{"location":"HSS_Electives/International_Relations/02_History/#why-did-us-actually-end-up-using-the-atomic-bomb","title":"Why did US actually end up using the atomic bomb","text":"<p>US claimed that it just wanted to get everything over with and this marked the end of the war.</p> <p>However, many experts say that US just wanted to try out the bomb to research further about it. This claim is supported by the fact that the first people to reach the site after the bombing were actually researchers like Richard Feynmann</p>"},{"location":"HSS_Electives/International_Relations/02_History/#us-and-soviet","title":"US and Soviet","text":"<p>Another theory about why US used the bomb is to show it's superiority, because the soviets were also developing nuclear weapons at the time. US didn't even tell soviets about the bombing, because they didn't want the soviets to get there first.</p> <p>After WW1 and WW2, naked expansion has been frowned upon. Previously, colonialism and expansion of territories was accepted</p>"},{"location":"HSS_Electives/International_Relations/02_History/#indian-wars","title":"Indian Wars","text":""},{"location":"HSS_Electives/International_Relations/02_History/#naxalitemaoist-insurgency","title":"Naxalite\u2013Maoist Insurgency","text":"<p>insurgency (violent, armed rebellion against authority)</p> <p>fought for improved land rights and more jobs for neglected agricultural laborer and the poor</p>"},{"location":"HSS_Electives/International_Relations/02_History/#siachen-glacier","title":"Siachen Glacier","text":"<p>gives India the \u201ctactical advantage of dominating height.\u201d Sitting at much lower altitudes, Pakistani soldiers are completely \u201cshut off from a view of the Siachen Glacier\u201d and are thus at a \u201csevere tactical disadvantage\u201d all along the AGPL. Demilitarizing the glacier would amount to India surrendering its advantage.</p>"},{"location":"HSS_Electives/International_Relations/02_History/#kargil-war","title":"Kargil War","text":"<p>Prior to 1984 neither India nor Pakistan had any permanent presence in the area. However, in 1984, India violated agreements and acquired the entire Siachen glacier. This provoked Pakistan to fight.</p>"},{"location":"HSS_Electives/International_Relations/02_History/#cold-war","title":"Cold War","text":""},{"location":"HSS_Electives/International_Relations/02_History/#communism","title":"Communism","text":"<p>Communism from Russian Revolution</p> <p>There are 2 class - haves / have-nots</p> <p>fight for</p> <ol> <li>resources</li> <li>power</li> <li>politics</li> </ol>"},{"location":"HSS_Electives/International_Relations/02_History/#reason-against-communism","title":"Reason against communism","text":"<p>have nots believed that the only way is by a violent uprising. the world govts got afraid</p> <p>they believed that there shouldn\u2019t be a \u2018state\u2019</p>"},{"location":"HSS_Electives/International_Relations/02_History/#reason-for-communism","title":"Reason for communism","text":"<p>because the people benefit</p>"},{"location":"HSS_Electives/International_Relations/02_History/#context","title":"Context","text":"<p>idealogical conflict - war of ideas - fight of who's way of life is better capitalism vs communism other wars were mostly about expanding territory/exploiting resources of a particular territory</p> <p>India tried being non-aligned because india was fed up of fighting others' wars; it just wanted to be independent from others; but actually comes closer to Soviet Union, because US was closer to Pakistan</p> <p>relatively non-violent</p> <ul> <li>nothing happened in europe, us, soviet</li> <li>violence happened in other countries through proxy wars</li> </ul>"},{"location":"HSS_Electives/International_Relations/02_History/#europe","title":"Europe","text":"<p>Iron Curtain was an idea/concept, not really a physical one; it represented the divide b/w the 2 ideologies</p> <p>Western Germany was controlled by 3 countries after WW2</p> <ol> <li>US</li> <li>UK</li> <li>France</li> </ol>"},{"location":"HSS_Electives/International_Relations/02_History/#berlin","title":"Berlin","text":"<p>Berlin was an enclave (a portion of territory surrounded by a larger territory whose inhabitants are culturally or ethnically distinct; like Musandam in UAE)</p> <p>itself was divided into east and west Berlin</p> <p>everybody wanted to move to the west Berlin side because 'western' was considered to be better</p>"},{"location":"HSS_Electives/International_Relations/02_History/#korea","title":"Korea","text":"<p>North freed by Soviet, South freed by US</p>"},{"location":"HSS_Electives/International_Relations/02_History/#south-east-asia","title":"South-East Asia","text":"<ul> <li>Vietnam<ul> <li>north - soviet</li> <li>south - US</li> </ul> </li> <li>Cambodia</li> <li>Laos</li> </ul>"},{"location":"HSS_Electives/International_Relations/02_History/#why-did-us-hold-on-to-vietnam-even-though-it-was-losing","title":"Why did US hold on to Vietnam, even though it was losing?","text":"<p>it felt that if it retreated, then soviet would expand itself into the south also; then, they would further expand themselves into Cambodia and Laos as well</p>"},{"location":"HSS_Electives/International_Relations/02_History/#cuban-missile-crisis","title":"Cuban Missile Crisis","text":"<p>Soviet places missile launch point in Cuba to attack US</p> <p>US places missile launch point Turkey to attack Soviet</p> <p>Nuclear deterrence nuclear weapons are intended to deter other states from attacking with their nuclear like 2 equally powerful drug cartels opting for cooperation instead of demolition</p>"},{"location":"HSS_Electives/International_Relations/02_History/#afghanistan","title":"Afghanistan","text":"<p>Soviet established a pro-Soviet govt.</p> <p>US supported the Mujahideen guerilla to fight against the Soviets.</p>"},{"location":"HSS_Electives/International_Relations/02_History/#collapse-of-soviet-union","title":"Collapse of Soviet Union","text":"<p>after the Chernobyl disaster, the govt opened up and everyone over-used the freedom they got and started asking for independence</p> <p>Similar thing happening in north korea if you give freedom, then people will take advantage</p>"},{"location":"HSS_Electives/International_Relations/02_History/#miscellaneous-points","title":"Miscellaneous Points","text":""},{"location":"HSS_Electives/International_Relations/02_History/#militiary-coup","title":"Militiary Coup","text":"<p>Militiary has the final power to protect the country</p>"},{"location":"HSS_Electives/International_Relations/02_History/#insurgence","title":"Insurgence","text":"<p>people who target govt expecting a change; they aren't exactly terrorists cuz they don't cause civil harm</p>"},{"location":"HSS_Electives/International_Relations/02_History/#diplomats","title":"Diplomats","text":"<p>you cannot attack diplomat in embassy; embassy are like enclaves</p> <ul> <li>Havana Syndrome</li> <li>Jamal Khashoggi</li> </ul>"},{"location":"HSS_Electives/International_Relations/02_History/#un-security-council","title":"UN Security council","text":"<p>Countries which volunteer its military services for global issues</p> <p>5 permanent members</p> <p>10 elected members</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/","title":"03 Current World","text":""},{"location":"HSS_Electives/International_Relations/03_Current_World/#chinas-rise","title":"China's rise","text":""},{"location":"HSS_Electives/International_Relations/03_Current_World/#reason-china-is-getting-better-so-quickly","title":"Reason china is getting better so quickly","text":"<p>Because they aren't wasting their money unnecessarily on military endeavors, like the US</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#why-isnt-india-rising-so-quickly","title":"Why isn't India rising so quickly","text":"<p>In india, the govt just focuses on implementing policies so as to gain enough popularity to win the next election. hence the policies are always short-sighted, because the ruling party knows that if it makes good long term policies instead of short term, they will lose the next elections and all the benefits of their policies will actually be enjoyed by their successors.</p> <p>meanwhile, in china, there is only one 'communist' party (which isn't exactly communist), which is always the ruling party; hence, it makes very long term policies</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#military","title":"Military","text":"<p>Not even close to US in terms of physical military</p> <p>Trying to attack digitally</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#but-why-does-us-still-spend-so-much-on-military","title":"But why does US still spend so much on military","text":"<p>because, that is the only superiority it has over countries. If it loses this advantage, then all the countries that are dependent on it for military purposes might go away</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#allies","title":"Allies","text":"<p>Not many allies compared to US</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#quad-vs-aukus","title":"Quad vs AUKUS","text":"<p>Both are groups of countries against China</p> Quad AUKUS US US Australia Australia Japan UK India Not much progress, as Japan and China do not want to invite animosity from China; if they join, then they'll get stuck with it Anti-China nuclear submarine alliance; gained more progress than the Quad <p>Terrorism is more a tactic of the weak, rather than of the strong.</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#how-regional-conflicts-affect-international-relations","title":"How regional conflicts affect international relations","text":""},{"location":"HSS_Electives/International_Relations/03_Current_World/#kurdish-turkish-conflict","title":"Kurdish-Turkish Conflict","text":"<p>The Kurdish\u2013Turkish conflict is an armed conflict between the Republic of Turkey and various Kurdish insurgent groups who have either demanded separation from Turkey to create an independent Kurdistan, or attempted to secure autonomy and greater political and cultural rights for Kurds inside the Republic of Turkey</p> <p>It is concerning for other countries as they are scared that the kurds in their own country would start asking for a state of their own</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#india-sri-lanka-conflict","title":"India-Sri Lanka Conflict","text":"<p>India interfered in the domestic aspects of Sri Lanka, and instigated a conflict, which ended up being an international conflict</p> <p>Fear in pakistan about nuclear weapons cuz of fear that it will fall under the wrong hands like terrorists</p> <ol> <li>Even in india and pak\u2019s case in war, india would always be limited in its strategic decisions. india doesn\u2019t want the wrong people to get hold of the ruins and the nuclear weapons</li> <li>pakistan could just take out the political sphere in order to knock india out, but it can\u2019t because it wants to avoid a new govt that is more against it, and to avoid a headless chicken in charge of the neighboring enemy</li> </ol>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#cooperation","title":"Cooperation","text":"<p>according to realists, cooperation takes place only as long as it benefits yourself; otherwise, the cooperation breaks off</p> <p>liberals say that once cooperation starts, laws and treaties are to be established to ensure it doesn\u2019t break</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#iaea","title":"IAEA","text":"<p>international atomic energy agency</p> <p>the treaty said that nuclear for energy is fine, but the thingies shouldn\u2019t be used for military</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#biological-weapons-convention-bwc","title":"Biological Weapons Convention (BWC)","text":"<p>it happens because it is not seen as a real military weapon</p>"},{"location":"HSS_Electives/International_Relations/03_Current_World/#indus-water-treaty","title":"Indus Water Treaty","text":"<p>even though they are at war, India and Pakistan realized that they shouldn\u2019t fight for water as it is a basic human requirement</p> <p>Liberals say that they is scope for cooperation even b/w countries at war</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/","title":"04 Theories of IR","text":""},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#realism","title":"Realism","text":"<p>This theory says that every country just cares about survival; everything a state does is for its security</p> <p>Realists say that rules are made by people in power to maintain their power China says why should we follow rules the west made</p> <p>Feminists say that if there are more women, then the state would be softer; realists say that doesn't matter</p> <p>Some realists believe that a most unstable world is a uni-polar world, and that the most stable is a bipolar world</p> <p>Alliances occur due to interests and convenience, not exactly due to trust; there are no points for loyalty</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#classical-realism","title":"Classical Realism","text":"<p>says that wars occur due to the dark side of human nature - desire for power</p> <p>Hans J. Morgenthau</p> <p>Eg: hitler</p> <p>it also says that we can predict the possibility of war from the nature of individuals in the govt</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#structural-realism","title":"Structural Realism","text":"<p>says that classical realism is not scientifically sound; states act in response to what is thrown at them; human nature doesn\u2019t matter</p> <p>Wars happen between states due to systemic anarchy: lack of a central authority (mostly during civil wars)</p> <p>autocratic countries do their own thing but at the same time, they're more nervous that people will rise up, because</p> <ol> <li>not democractic</li> <li>common people die serving a country that isn't even democratic</li> </ol> <p>We can predict how leaders would behave, as they are responsible for their own state's survival. Therefore, they will act very rational, as they wouldn't be in that position if they weren't rational</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#defensive-structural-realism","title":"Defensive structural realism","text":"<p>Kenneth Waltz</p> <p>just maximize defense</p> <p>just as much power you need to protect yourself from other self-seeking states</p> <p>Eg: Israel's iron dome</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#offensive-structural-realism","title":"Offensive structural realism","text":"<p>John Mearsheimer (longer name so defense and offense)</p> <p>maximize power (resources, military defense and offense), as much as you can</p> <p>Countries can be defensive and/or offensive at different times Eg: China was defensive realist during 1962 for the land dispute with India, but now it is on the offensive in the South China Sea</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#liberalism","title":"Liberalism","text":""},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#democratic-peace-theory","title":"Democratic Peace Theory","text":"<p>theory under liberalism</p> <p>says that democratic countries do not fight wars</p> <p>Newly-established democracies are more unstable and are hence more prone to fight wars</p> <p>But it contradicts the working of the US; US has been waging wars</p> <p>The main reason for conflict is due to lack of trust</p> <p>According to liberalists, security dilemma is due to absolute gains as well as relative gains</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#points-against-realism","title":"Points Against Realism","text":"<p>According to liberalists, realism can only explain conflicts but cannot explain peace</p> <p>Moreover, realism fails to explain why many of the treaties bw US and soviet was signed during the cold war</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#neo-liberalism","title":"Neo-liberalism","text":"<p>mix of realism and liberalism</p> <p>States are rational, and in an international anarchical system, but believe that the world is more peace-loving than realists</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#constructivism","title":"Constructivism","text":"<p>there is no reality other than what we give to it; it\u2019s ideas that matter</p> <p>how countries view each other</p> <p>Power resides where people believe it resides</p> <p>Power resides where men believe it resides Varys - Game of Thrones</p> <p>A state\u2019s identity is what threatens us</p> <p>anarchy isn\u2019t exactly objective reality, but it is the meaning people give it</p> <p>they don\u2019t think that anarchy is a factor for international relations</p> <p>value thingy - an example is paradox of value example</p> <p>better theory to explain change in relations</p> <p>they say that nuclear weapons provide a prestigue, identity and status for countries, as it\u2019s a small club</p> <p>they say that countries fight for ideology, not just power; US govt went after the communists within US also</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#us-and-uk","title":"US and UK","text":"<p>US doesn\u2019t think of UK\u2019s military improvement as a threat; so clearly constuctivism is a good theory</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#constructivists-view-of-hiroshima-bombing","title":"Constructivist\u2019s view of Hiroshima Bombing","text":"<p>because japanese were demonised in the minds of the US people through propaganda</p> <p>however, US didn\u2019t use atomic bomb in germany during ww2 cuz they were hitler and the germans are europeans; despite hitler using chemical and biological weapons in concentration camps (like the japanese) and other horrible stuff</p> <p>So constructivists say that this difference in perception is the reason the bombing took place</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#marxism","title":"Marxism","text":"<p>everything occurs only for economic reasons, but disguised by the haves as other stuff (like nationalism, religion, patriotism) etc\u2026</p> <p>says that wars occur because have-nots are fooled by haves</p> <p>game of thrones - the seven - lannisters didn\u2019t care about religion</p> <p>it says that the economy is a driving force/defining feature of the world (just like how structural realism considers systemic anarchy) that determines state behavior</p> <p>projected a better, prosperous and equal world</p> <p>explains why US came to Saudi for oil</p> <p>says that radicalization occurs if people aren\u2019t doing so well economically</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#classes","title":"Classes","text":"<ul> <li>capital class (haves) (bourgeoisie)</li> <li>working class (have-nots) (proletariats)</li> </ul> <p>marxists say that middle class is just fake; they just pretend to care for the working class, but hope to eventually be a part of the capital class</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#history","title":"History","text":"<p>every epoch(era) includes the haves exploiting the have-nots for their own benefit</p> <ol> <li>primitive communism (hunter gatherers)</li> <li>slavery</li> <li>feudalism</li> <li>capitalism</li> <li>socialism</li> <li>communism</li> </ol>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#marxism-vs-communism","title":"Marxism vs Communism","text":"<p>Communism is just marxism, but they also believed there should not be a state, as they believed that the State just represents the haves.</p> <ul> <li>social classes disappear</li> <li>everyone owns the means of production</li> <li>state belongs to the people and does not reflect the interests of the rich/haves</li> </ul> <p>communists believed in revolution/wars, as the haves wouldn\u2019t just let the have-nots</p> <p>therefore, this threat was the reason why the US made sure that it did not spread</p> <p>communism failed because we all care about personal glory and invidual gain; we don\u2019t really care about if others get money or not eg: universal basic income is highly argued against</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#explanation-for-conflicts","title":"Explanation for Conflicts","text":"<p>marxists say that conflicts are due to the class divide bw the haves and have nots</p> <p>in GBR, there was no revolution because the wealth that came from colonisation by GBR helped get money and better standard of living of the working class</p> <p>marxists say that due to colonisation, the class conflict becomes global</p> <ul> <li>Colonizers become the haves</li> <li>colonized become the have-nots</li> </ul>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#explanation-for-world-wars","title":"Explanation for World Wars","text":"<p>despite the motive being \u2018fighting for the country\u2019, the soldiers are just fighting for the sake of the haves</p> <p>marxists say that soldiers join the armies just for survival - to make a living</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#why-is-marxism-better","title":"Why is marxism better?","text":"<p>While other theories explain at a macroscopic level, marxism explains in microscopic level (soldiers)</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#why-isnt-it-liked","title":"Why isn\u2019t it liked?","text":"<p>because he says that religion and others stuff matter a lot to the people, but they are just an illusion; this triggered the whole world</p> <p>also, Marx has ignored the fact that there a lot of people who are genuinely religious, nationalist, etc\u2026 which seems pretty ignorant on his part</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#examples-of-war-from-the-marxist-perspective","title":"Examples of war from the Marxist Perspective","text":"<p>western countries trying to exploit the have-nots from the other countries</p> <p>capitalists disallow trade unions in order to maximize profits</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#us-guatemala","title":"US-Guatemala","text":"<p>United Fruit Banana</p> <p>(view slides)</p> <p>the decision to overthrow the Guatemala govt was purely to maintain the profits of the company, rather than just pure anti-communism</p> <p>Guatemala has never recovered from that</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#us-iran","title":"US-Iran","text":"<p>Iran cut off oil supply for UK, and the US overthrew that leader. The new leader was actually a previous Shah who was very corrupt.</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#2nd-gulf-war","title":"2<sup>nd</sup> Gulf War","text":"<p>reasons</p> <ol> <li>Iraq wasn\u2019t supposed to have weapons of mass destruction</li> <li>oil</li> </ol> <p>random definition: despot means autocrat</p> <p>Halliburton was an oil services and eng company it went from 22<sup>nd</sup> -&gt; 7<sup>th</sup> largest military contractor in just a few years</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#another-aspect-of-marxism","title":"Another aspect of Marxism","text":"<p>hegemony - kinda like domination</p> <p>In Marxist philosophy, cultural hegemony is the dominance of a culturally diverse society by the ruling class who manipulate the culture of that society\u2014the beliefs and explanations, perceptions, values, and mores\u2014so that the worldview of the ruling class becomes the accepted cultural norm Wikipedia</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#critical-theory","title":"Critical Theory","text":"<p>states that all theories are just projection of theorists\u2019 values</p> <p>it\u2019s not objective; it\u2019s subjective</p> <p>it says that there is no such thing as a grand theory</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#miscellaneous-points","title":"Miscellaneous Points","text":""},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#security-dilemma","title":"Security Dilemma","text":"<p>Let's just say a country has conflicts with another country.</p> <p>If the defensive structural realist country beefs up its security, then the offensive structural realist country will feel threatened; therefore, it will also improve its offense in response</p> <p>According to realists, this is due to focus on relative gains</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#how-did-eu-become-possible","title":"How did EU become possible","text":"<ol> <li>realization</li> <li>wars are too expensive</li> <li>benefits of scale and trade</li> <li>trust brought about through<ol> <li>laws</li> <li>treaties</li> </ol> </li> <li>common enemy against the soviets</li> <li>begins with the ECSC</li> </ol>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#game-theory","title":"Game theory","text":"<p>(i did not really understand properly)</p> <p>cooperation occurs as it is better than individual effort</p> <p>but then one individual just goes against the others and takes everything</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#ecsc","title":"ECSC","text":"<p>European Coal &amp; Steel Community</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#why-coal-steel","title":"Why coal &amp; steel?","text":"<p>because they were the most important resources at the time, and for which conflicts (like hitler\u2019s occupations) were waged</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#why-would-nuclear-cooperation-make-sense","title":"Why would nuclear cooperation make sense","text":"<ol> <li>countries will not longer fear each other</li> <li>Share information to avoid accidental action</li> <li>keep the other one in check</li> </ol>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#track-to-track-diplomacy","title":"Track to track diplomacy","text":"<p>cricket matches</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#pok","title":"POK","text":"<p>Pakistan-Occupied Kashmir</p>"},{"location":"HSS_Electives/International_Relations/04_Theories_of_IR/#escalation-order","title":"Escalation Order","text":"<p>the order of responses based on the circumstance</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/","title":"05 Issues of IR","text":""},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#issues-of-international-relations","title":"Issues of International Relations","text":""},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#history-of-nuclear-weapons","title":"History of nuclear weapons","text":"<p>Nuclear weapons are more of a political weapons, rather than an actual military weapon; cuz it\u2019s more about signaling/deterrence than actually using it</p> <p>Nuclear weapons were only used once - when the victim did not have any nuclear weapons to deter them; ie, US on Japan; no MAD (mutually assured deterrence)</p> <p>But the fact that it hasn\u2019t been used so far doesn\u2019t mean that it cannot happen now</p> <p>Western world was caught off guard when India started nuclear testing (according to the media, at least)</p> <p>Indian strategists were actually glad that Pakistan also got nuclear weapons, because Pakistan now became secure; an insecure Pakistan would try to attack India in other ways; now it\u2019s just about deterrence, rather than fighting</p> <p>This could be possible for Iran too, cuz it\u2019s been cornered by everyone; but if it becomes nuclear, then it will become secure and may reduce terrorism</p> <p>Terrorism is the weapon of the weak ; the strong do not do that</p> <p>all this is like gun laws for civilians</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#present","title":"Present","text":"<p>All countries are allowed to have civilian nuclear programs for power generation; but the countries must sign treaties to allow inspection to ensure that nothing is get diverted into the weapon development</p> <p>Iran is producing nuclear weapons to protect itself from Israel. Should we be worried? Yes, because (the below reason)</p> <p>Arguably, we should monitor which countries newly avail nuclear weapons, because we do not know how they would use them</p> <p>It is better if nuclear weapons are under a civilian government, rather than the military</p> <p>The permanent 5 of UN were somehow okay with India and Pakistan going nuclear, but then they are not okay with other countries cuz it changes the power balance</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#treaties","title":"Treaties","text":""},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#disarmament","title":"Disarmament","text":"<p>Japan has been educating countries to denuclearisation</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#non-proliferation-treaty","title":"Non-Proliferation Treaty","text":"<p>Stopped horizontal proliferation (no of countries)</p> <p>India criticized the treaty saying that the treaty did nothing about vertical proliferation (no of weapons, trials); India said that then they should ban testing</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#idk-treaties","title":"IDK Treaties","text":"<p>i don\u2019t agree with this, but this theory says that</p> <p>even the defensive missile weapons systems should be controlled so that the countries that have nuclear weapons do not feel insecure</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#elements-of-stable-nuclear-deterrence","title":"Elements of Stable Nuclear Deterrence","text":"<p>According to Scott Sagan</p> <ol> <li>disallow pre-emptive war when one side has a temporary advantage</li> <li>eg: 2<sup>nd</sup> Gulf War</li> <li>develop survivable second-strike forces</li> <li>to deter the enemy if they nullify the first attack</li> <li>avoid accidental nuclear war</li> <li>keep weapons away from terrorists</li> </ol>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#determinants-of-going-nuclear","title":"Determinants of going nuclear","text":"<ol> <li>to improve national security</li> <li>to improve prestige, national identity</li> <li>to improve political image</li> <li>Western world wants to affect the common people of countries, so that the people riot against the country</li> <li>But if the country makes nuclear weapons, then it appeases the people</li> <li>economic costs</li> </ol>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#more-vs-none","title":"More vs None","text":"<p>what is better? more or no nuclear weapons?</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#for-more","title":"For More","text":"<p>helps small countries feel secure which will stop them from doing other nonsense</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#nuclear-doctrinespostures","title":"Nuclear Doctrines/Postures","text":"<ol> <li>every country wants a minimum deterrence</li> <li>second strike/survivable weapons capability</li> <li>No First Use    eg: India and China</li> <li>assured and massive retaliation    eg: Cold war</li> <li>Nuclear strategy prefers counterforce</li> <li>Counterforce - attack military threats like missile launch points</li> <li>Countervalue - attack commercial places like malls, tourist destinations, wonders of the world</li> <li>Asymmetric escalation    not responding proportional</li> <li>Launch on Warning (LoW)    keep missiles and nuclear weapons separately to give the enemy some time to reconsider their current decision</li> <li>Nuclear strategies</li> <li>Nuclear ambiguity/opacity       eg: Israel</li> <li>latent nuclear capacity       eg: North Korea</li> <li>Extended nuclear deterrence/ nuclear umbrella       eg: US for the countries dependent on it</li> </ol>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#recent-developments","title":"Recent Developments","text":"<p>Countries are still keeping on increasing their nuclear weapons</p> <p>we are further away from nuclear-free than ever </p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#china","title":"China","text":"<p>has been accelerating its nuclear capability</p> <p>hypersonic missiles can evade the radars of the enemy</p> <p>Nuclear posture</p> <ol> <li>defensive</li> <li>clearly no use on nuclear-less countries</li> </ol>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#india","title":"India","text":"<p>india has always been no first use</p> <p>despite this being a great policy for a safer world, India has recently become more ambiguous about this, saying that they might consider using it for certain circumstances to signal others not to mess with them</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#terrorism","title":"Terrorism","text":"<p>United Nations has never been able to come up with a working definition. The definition changes with context.</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#terrorist","title":"Terrorist","text":"<p>The govt tends to label anybody against the state as a terrorist. Kinda messed up and unfair defintion, but yeah what to do.</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#klf","title":"KLF","text":"<p>Khalistan Liberation Front</p> <p>Pakistan funded the movement</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#kurdistan-worker-party","title":"Kurdistan Worker\u2019 Party","text":"<p>Kurds have wanted their own state for a long time</p> <ul> <li>Why was this a threat?</li> <li>cuz other groups will also start asking for their states</li> </ul> <p>But the UN did not interfere, cuz they cannot interfere in the internal affairs of a country</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#ira","title":"IRA","text":"<p>Irish Republican Army</p> <p>Northern Ireland wanted to separate </p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#eta","title":"ETA","text":"<p>Spain - Catalonya</p> <p>Basque separatists</p>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#why-do-terrorist-take-up-arms","title":"Why do terrorist take up arms?","text":"<ol> <li>other measures have not succeeded</li> <li>perceived/real victimhood</li> <li>minority persecution</li> <li>unfair govt</li> <li>misfits</li> <li>sociopaths</li> </ol>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#terrorists","title":"Terrorists","text":"<ul> <li>non-state actors</li> <li>they do not differentiate bw civillians vs the govt</li> <li>for them, the end justifies the means</li> <li>in reality they\u2019re weak</li> </ul>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#pathology-of-terrorism","title":"Pathology of Terrorism","text":"<p>many terrorist groups in countries is funded by other countries</p> <p>a lot of funding comes from diaspora and from illegal trades like fake clothing, merch, etc.</p> <p>a lot of govts consider NGOs a forefront for terrorism funding</p> <p>2 happenings of terrorism</p> <ol> <li>as a method to meddle in another country\u2019s affairs</li> <li>as an organisation</li> </ol>"},{"location":"HSS_Electives/International_Relations/05_Issues_of_IR/#tibet","title":"Tibet","text":"<p>China has done the following tricks in Tibet</p> <ol> <li>intermingle the population there</li> <li>connect the country with the rest of the country</li> </ol> <p>so the average tibetan doesn\u2019t want an independent country anymore, cuz they\u2019re anyways happy with what they\u2019re getting rn</p>"},{"location":"HSS_Electives/International_Relations/06_Softpower/","title":"06 Softpower","text":""},{"location":"HSS_Electives/International_Relations/06_Softpower/#soft-power","title":"Soft Power","text":"<ul> <li>trying to change the perception of the country, without using any force</li> <li>helps in diplomatic relations</li> <li>healthier than hard power??</li> </ul> <p>eg:</p> <ul> <li>US: hip hop</li> <li>Japan: anime</li> <li>Korea: KPop, KDrama</li> </ul>"},{"location":"HSS_Electives/International_Relations/06_Softpower/#japan","title":"Japan","text":"<ul> <li>japan is trying to stay close allies with the US</li> <li>but doesn't always get along with them, for eg<ul> <li>Paris Climate Agreement</li> <li>Recognition of Jerusalem as the capital of Israel</li> </ul> </li> <li>Japan sees China\u2019s soft power tactics as pure propaganda</li> <li>Japan is unnotoriously closed off to outsiders<ul> <li>they\u2019re afraid of diluting their culture</li> <li>however, now it\u2019s slowly changing cuz they\u2019re afraid of the aging population</li> </ul> </li> </ul>"},{"location":"HSS_Electives/International_Relations/06_Softpower/#us","title":"US","text":"<p>Softpower has gone down, especially after the storming of the White House in Jan 2021.</p>"},{"location":"HSS_Electives/International_Relations/06_Softpower/#india","title":"India","text":""},{"location":"HSS_Electives/International_Relations/07_Poverty/","title":"07 Poverty","text":""},{"location":"HSS_Electives/International_Relations/07_Poverty/#development-and-poverty-alleviation","title":"Development and Poverty Alleviation","text":"<p>Policies of one country for development has a high possibility of affecting the development of another country</p> <p>eg: </p> <ol> <li>dams (China - india)</li> <li>nuclear plant (uae-china)</li> </ol>"},{"location":"HSS_Electives/International_Relations/07_Poverty/#mainstream-view","title":"Mainstream View","text":"<p>maximize \u2018wealth\u2019 using a capitalist system</p> <p>obsessed with GDP</p>"},{"location":"HSS_Electives/International_Relations/07_Poverty/#critical-view","title":"Critical View","text":"<p>more about happiness and sustainability</p> <ol> <li>health</li> <li>education</li> <li>standard of living</li> <li>self-fulfillment</li> </ol>"},{"location":"HSS_Electives/International_Relations/07_Poverty/#india","title":"India","text":"<p>India liberalized its economy cuz it took funds from the IMF, which said that it is compulsory to adopt certain principles</p> <p>One of the concerns in the north east is that they look at natural resources as sacred, rather than just for human consumption</p>"},{"location":"HSS_Electives/International_Relations/07_Poverty/#gini-coefficient","title":"GINI Coefficient","text":"<p>is a measure of statistical dispersion intended to represent the income inequality or the wealth inequality within a nation or a social group.</p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/","title":"08 Role of Economics in IR","text":""},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#great-depression","title":"Great Depression","text":"<p>Countries did not perform trade, as exporting countries wanted to save resources</p> <p>So many unemployed people were there in Germany, while the Jews were pretty well off; this was the appeal that Hitler had</p> <p>The world realized that economics should never be a reason for wars again. If we are trading together, then there is more room for cooperation and less likeliness for wars (liberal view)</p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#international-organizations","title":"International Organizations","text":""},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#imf-world-bank","title":"IMF, World Bank","text":"<p>When a country is defaulting, IMF gives them loans for development</p> <p>eg: india in 1991, greece in 2010s</p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#wto","title":"WTO","text":"<p>established the liberal international trading system</p> <p>fairer than the UN, because it has no security council</p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#impact-of-liberal-trading-financial-system","title":"Impact of Liberal Trading &amp; Financial System","text":"<p>IMF Conditionalities require loan-taking countries to implement a liberal economy</p> <p>The short-term effects were actually bad, because the sudden changes cause instability</p> <p>EU took US to the WTO in 2018, because the US imposed tariffs on steel and aluminium imports from the EU</p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#bilateral-trade","title":"Bilateral Trade","text":""},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#russia-germany","title":"Russia-Germany","text":"<p>Russia provides raw materials like crude oil and natural gas, Germany gives final goods like machinery</p> <p>But in Dec 2021, Germany has threatened Russia to block the pipelines (and not import) if Russia does anything harmful to Ukraine</p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#china-taiwan","title":"China-Taiwan","text":""},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#us-china","title":"US-China","text":""},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#russia-saudi","title":"Russia-Saudi","text":"<p>Saudi wanted to reduce prices, but Russia did not want to. This shows that </p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#india-malaysia","title":"India-Malaysia","text":"<p>Malaysia said something against India about Kashmir, and India banned Malaysia</p>"},{"location":"HSS_Electives/International_Relations/08_Role_of_Economics_in_IR/#china-australia","title":"China-Australia","text":"<p>Australia said that Covid-19 is a bioweapon, and China imposed tariffs</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/","title":"09 Class Presentations","text":""},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#cyber-security","title":"Cyber Security","text":""},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#past","title":"Past","text":"<ol> <li>Russia attack on Ukraine</li> <li>Russia attack on German</li> <li>China attack on US</li> <li>Russia caused power outage in Ukraine</li> <li>allegdly Korean WannaCry ransomware</li> <li>NotPetya by Russia</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#present","title":"Present","text":"<p>the investment in cyber crime has been actively increasing</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#why-is-it-the-next-big-threat","title":"Why is it the next big threat","text":"<ol> <li>easy to do as</li> <li>it is cost-effective</li> <li>no bloodshed</li> <li>minimal losses</li> <li>limited repercussions</li> <li>lack of solid rules to regulate cyber crimes</li> <li>not under the attention of leaders</li> <li>world becoming more digital</li> <li>countries could lose large amounts</li> <li>viruses</li> <li>hard to detect</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#what-can-countries-do","title":"What can countries do","text":"<ol> <li>cyber warfare training for defence</li> <li>offensive cyber weapons development for deterrance</li> <li>defensive cyber security protocol</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#cryptocurrency","title":"Cryptocurrency","text":"<p>as cryptocurrencies are fast, secure, and de-centralized, terrorist organizations can easily get funding without any hinderance</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#cyberattacks","title":"Cyberattacks","text":"<p>china spear phishing</p> <p>Spear phishing is an email or electronic communications scam targeted towards a specific individual, organization or business. Although often intended to steal data for malicious purposes, cybercriminals may also intend to install malware on a targeted user\u2019s computer.</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#why-is-it-a-threat-in-international-level","title":"Why is it a threat in international level","text":"<p>as it is possible to disrupt the enemy\u2019s</p> <ol> <li>infrastructure</li> <li>production and GDP</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#data-ai","title":"Data &amp; AI","text":"<ol> <li>increase in unemployment</li> <li>lead to more conflicts</li> <li>more susceptible to radicalization</li> <li>more robots increase the civillians\u2019 fear of wars</li> <li>manipulate our decisions</li> <li>we won\u2019t be choosing our leaders</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#semiconductor","title":"Semiconductor","text":"<ol> <li>chip war is in favor of US</li> <li>US has the best</li> <li>china cannot solve the problem by throwing resources</li> <li>it\u2019s not easy to produce a completely new techology</li> <li>banning of chinese students in US would wipe out the ambition of Chinese tech domination</li> <li>China doesn\u2019t invade taiwan cuz TSMC is a Taiwanese company</li> <li>China is forced to cooperate with the US</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#refugees","title":"Refugees","text":""},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#why-is-it-important","title":"Why is it important","text":"<ol> <li>people are the foundation of a democracy</li> <li>internal issues</li> <li>recent refugee movements</li> <li>overpopulation</li> <li>exploitation</li> <li>criminal</li> <li> <p>where does the funding go?</p> </li> <li> <p>why refugees move for monetary reasons highlights marxism the failure of the political system </p> </li> <li>how countries deal with refugees highlights realism</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#how-do-they-come-up","title":"How do they come up","text":"<ol> <li>wars</li> <li>social/political issues</li> <li>sexual discrimination</li> <li>lack of access to basic needs</li> <li>environmental conditions (not thaaaat common)</li> <li>climate change</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#solutions","title":"Solutions","text":"<ol> <li>investigation of trafficking and criminal organizations</li> <li>more funding for host nations</li> <li>solve the inner stigma among people</li> <li>better conditions for refugees</li> <li>better organizations</li> </ol>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#resource-conflicts","title":"Resource Conflicts","text":"<p>opposition of ideas for the use of resources</p> <ol> <li>it can happen any time</li> <li>it can happen for a long time</li> <li>exploitation</li> <li>inequality</li> </ol> <p>debt traps lead to resource conflicts</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#zombie-apocalypse","title":"Zombie Apocalypse","text":"<p>Sai Krishna</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#north-korea","title":"North Korea","text":"<p>Is it more dangerous that North Korea has nuclear weapons compared to democratic countries like India??</p> <p>One more reason why China getting powerful is a threat is because it is threatening that a non-democratic country will be the one of - if not - the most powerful country.</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#indo-china","title":"Indo-China","text":"<p>india and china had a war in 1961</p> <p>China has had problems with India, because India has given asylum to the Dalai Lama.</p> <p>India is trying to keep it non-violent, because</p> <ol> <li>it is not capable to do so yet</li> <li>it cannot, as it might lose with Pakistan in Kashmir</li> <li>it cannot risk angering USA</li> </ol> <p>What\u2019s the point of democracy if India is censoring maps, but it\u2019s fine??</p> <p>Why do you say that a democracy better than a dictatorship?</p>"},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#graphs","title":"Graphs","text":""},{"location":"HSS_Electives/International_Relations/09_Class_Presentations/#iran","title":"Iran","text":"<p>Iran </p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/","title":"Report on 'The Uncontrolled Rise of China'","text":"<p>[toc]</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#introduction","title":"Introduction","text":""},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#objective","title":"Objective","text":"<p>This report takes a look at how China is getting too powerful with no one to keep them in check.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#pre-research-thoughts","title":"Pre-Research Thoughts","text":"<p>I believe that China is expanding its power in an uncontrolled manner that is dangerous to the rest of the world. However, despite the severe propaganda against China, I believe that the damage China causes is minimal compared to the atrocities by major superpowers in the last century or so.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#scope","title":"Scope","text":"<p>This report will cover</p> <ul> <li>rapid rise in China and the reasons behind it</li> <li>arguments against China</li> <li>arguments defending China</li> </ul>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#discussion","title":"Discussion","text":""},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#rapid-rise","title":"Rapid Rise","text":"<p>Prior to a few decades, China was a country that was weighed down by crippling poverty. It was very inefficient and isolated from the rest of the world.</p> <p>China set up various new policies that instigated rapid growth and pulled millions out of poverty. One such policy was the introduction of SEZs (Special Economic Zones) with tax and business incentives to attract foreign investments. China had a large inflow of capital, in exchange for providing cheap labor. This cheap labor factor is what significantly reduced unemployment. The government prioritizes the growth of the community more than the growth of individuals. This has ensured the development of the entire nation, rather than just the richest people.</p> <p>In India, the govt just focuses on implementing policies so as to gain enough popularity to win the next election. Hence the policies are always short-sighted, because the ruling party knows that if it makes good long term policies instead of short term, they will lose the next elections and all the benefits of their policies will actually be enjoyed by their successors. Meanwhile, in China, there is a one-party democratic system; the Chinese Communist Party always stays in power; hence, it makes strategic long term policies, without any fear of losing the next elections.</p> <p>Furthermore, China has spent more of its resources into its development instead of using it on military endeavors, like the US; thereby allowing all the other sectors to flourish and get millions of people out of poverty.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#arguments-against-china","title":"Arguments Against China","text":"<p>There are various aspects that make China\u2019s expansion a worrying concern. It is not being hindered in its efforts for rapid expansion of power despite the following:</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#human-rights-violations","title":"Human rights violations","text":"<p>The basic rights such as labor rights are violated. In particular, minorities (such as Uyghur Muslims) are being persecuted severely. They are forced to convert religions, stripped-off of their culture, and exploited for cheap labor. Furthermore, they are deprived of basic freedom to speech which contradicts the very essence of a democracy - highlighting the totalitarian nature of the government.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#hong-kong","title":"Hong Kong","text":"<p>The human part should tell us this is wrong</p> <p>The violation of human rights threatens the very essence of a civilization, and is obviously a concern for the rest of the world. </p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#censorship","title":"Censorship","text":"<p>Only Chinese apps and media are allowed, as a means of censoring all content that is against the Chinese government. Despite there being various apps with different features, once again, there is only an illusion of freedom of choice as everything is under the control of the state.</p> <p>Moreover, various Chinese apps have allegations/history of spying on their users, as a means of collecting data, with popular apps like Tiktok being one of them recently. This data gets sold to data mining companies, which then target the users with specialized advertisements for products.</p> <p>Even when the Covid-19 outbreak emerged, the media was prevented from announcing it to the world, for maintaining China\u2019s image; they ended up risking the lives of millions across the world by doing so.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#cyber-crimes","title":"Cyber Crimes","text":"<p>China has been involved in cyber crimes with large-scale implications, with many breaches being backed by the state. When looking at past occurrences, the US, the EU, NATO, the UK and other countries accused China of exploiting vulnerabilities in Microsoft Exchange Server (mail/calendar server)<sup>1</sup>. It affected around 250,000 organizations worldwide and allowed hackers to steal company emails and to breach a compromised Exchange server.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#international-waters","title":"International Waters","text":"<p>China builds artificial islands and sets up military bases there in order to claim disputed ocean waters. This obviously harms the biodiversity and sustainability of these natural environments, affecting both the flora and fauna (i.e. both plants and animal biospheres). China does this in order to extract the natural resources of those regions and to simultaneously prevent other countries from doing so. Moreover, they are able to avail more efficient trading routes.</p> <p>This can especially be seen at the South China Sea. There are many \u2018islands\u2019 that didn\u2019t even exist up until a few years ago. Satellite images show numerous ships pumping sand out of the sea. China has heavily militarized the cluster of islands in the region, and build its own naval bases, to keep other countries in check. China insists that its intentions are non-militaristic, but its actions say otherwise. <sup>2</sup></p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#biowarfare","title":"Biowarfare","text":"<p>There is research that suggests that Covid-19 was a bioweapon. It seems very suspicious that the origin of the virus was from Wuhan, the same place where there is a research center for virology(Wuhan Institute of Virology).<sup>3</sup> Moreover, the fact that China hid the news of the outbreak makes it seem even more obvious that this was intentional.</p> <p>One possibility is that China used the virus to cripple the rest of the world, as no country was even prepared for the possibility of a pandemic. Countries\u2019 economies, healthcare, education system, and other sectors were heavily tested; many countries were just not able to cope. For instance, Italy\u2019s health care was not ready and the death toll clearly showed that.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#debt-traps","title":"Debt traps","text":"<p>China has distributed large amounts of loans to low and middle income countries. It seems generous, until the clauses and contracts for these loans are analyzed. China intentionally gives out loans to countries that definitely cannot repay them, with the aim of using those countries for its benefit. Clearly, the Belt and Road Initiative (BRI) not only acts as a geopolitical influence, but also as a weapon - once the country gets crippled by these tempting loans, it becomes a puppet for China and its expansion, by the taking over the infrastructure of the borrower.</p> <p>In the case of the Sri Lankan port of Hambantota, China pushed Sri Lanka into borrowing money from Chinese banks to fund the project, despite the lack of large potential commercial gains.<sup>4</sup> However, Sri Lanka could not keep up with the loans, and China demanded the port as collateral, forcing the government to give away control to a Chinese company. In the case of Africa, China has been accused of spying. After \u2018gifting\u2019 the African Union building, China intentionally left a backdoor to the servers, to secretly access data. Moreover, microphones were found all over the building. <sup>5</sup></p> <p>Some of the known regions where China has invested in large amounts and hence under risk of these debt traps</p> <ul> <li>Indian subcontinent<ul> <li>Sri Lanka</li> <li>Pakistan</li> </ul> </li> <li>Indo-Pacific<ul> <li>Thailand</li> <li>Laos</li> <li>Cambodia</li> </ul> </li> <li>All of Africa except Swaziland</li> </ul>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#dependence-of-other-countries","title":"Dependence of other countries","text":"<p>A large majority of countries in the world are dependent on China for production, imports and exports of goods. This dependence has led to countries being helpless when they are against policies that they disagree with.</p> <p>Taking an example, Australia is extremely dependent on China for a huge fraction of its economy, with China being its largest trading partner. Around 40% of Australia\u2019s exports is with China.<sup>6</sup> This has caused fears in the country about China\u2019s growing influence, with many saying that this is of utmost concern. Australia has hence formed alliances with other countries such as the Quad and AUKUS, in order to address this.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#arguments-defending-china","title":"Arguments Defending China","text":"<p>However, despite the above, China isn\u2019t exactly the monster that it seems when compared to the other superpowers like the US and the Soviet Union from the last century.</p> <p>Regarding cyber crimes, China isn\u2019t the only country which is a culprit. Various other countries have also been involved in scandals and tampering incidents; Russia, for instance, has been accused of tampering in the 2016 US Presidential Elections. It seems unfair to put the blame solely on a single country - China.</p> <p>When it comes to the BRI, there is research<sup>7</sup> that suggest that Chinese lenders are willing to renegotiate the terms of loans<sup>4</sup>; there are various instances where Chinese investment has genuinely improved the standard of living in countries, especially in African ones like Lesotho. While other states use force to exploit resources of countries, China hardly harms the governments of these countries. It\u2019s just being smart, with non-violent strategies to bring more countries under its control. Despite extensive militarization, China limits its use of violence, which is in stark contrast to the US\u2019 expeditions for resources.</p> <p>Despite claims that Covid-19 was a bioweapon, it hasn\u2019t been confirmed yet and there is a possibility that it was genuinely just an accidental leak. Hence, unless it has been proved, China can\u2019t exactly be pronounced guilty.</p> <p>Finally, online resources are heavily backed by Western media; they show only the Westerners\u2019 side of the story. Hence, despite incomplete data and a lack of the full picture, China is portrayed and interpreted as a super villain.</p>"},{"location":"HSS_Electives/International_Relations/Project/Report_on_%27The_Uncontrolled_Rise_of_China%27/#conclusions","title":"Conclusions","text":"<p>The rapid and uncontrolled rise of China is indeed concerning; however, the points defending China highlight that it isn\u2019t the super villain it is portrayed to be; it is no different from any other emerging superpower throughout history. It is evident that further unbiased research must be performed.</p> <p>However, it is also evident that it is too dangerous to just let China continue its current efforts without any hinderance. This is clearly an international issue with worldwide consequences, and not just a regional one.</p> <p>The following measures may be taken to address the issue of China\u2019s rapid rise and growing dominance:</p> <ul> <li>Products made through exploited labor should be boycotted, to hinder the Government\u2019s efforts at exploiting workers. Even if a company does produce goods in China, it should ensure that employees and laborers avail good working conditions.</li> <li>As the digital world is still relatively recent, more ideation is required to address the issue of cyber crimes. New laws must be agreed upon to properly police cyber crimes, as it could have serious repercussions if left unhindered. A suggestion would be for the UN to issue heavy penalties for such crimes.</li> <li>The UN must come in and make stricter laws for governing international waters, to ensure that China doesn\u2019t just bully its neighbors.</li> <li>China\u2019s microbiology research must be monitored to ensure that their bioweapons are kept in check and other countries can be prepared in the case of an \u2018accidental\u2019 leak.</li> <li>Other countries should support countries that are under the BRI, in order to reduce China\u2019s dominance over them.</li> <li>International companies should find alternative countries to produce their goods. It may not be easy, but it is necessary to reduce the current dependence on China.</li> </ul> <ol> <li> <p>China accused of cyber-attack on Microsoft Exchange servers \u21a9</p> </li> <li> <p>Why China is building islands in the South China Sea \u21a9</p> </li> <li> <p>Was COVID Created in a Lab? Here's What We Know \u21a9</p> </li> <li> <p>There Is No Chinese \u2018Debt Trap\u2019 \u21a9\u21a9</p> </li> <li> <p>China's Rush Into Africa, Explained. \u21a9</p> </li> <li> <p>Australia monthly trade data \u21a9</p> </li> <li> <p>Debt Relief with Chinese Characteristics \u21a9</p> </li> <li> <p>How China Became So Powerful \u21a9</p> </li> </ol>"},{"location":"HSS_Electives/International_Relations/Project/presentation/","title":"Presentation","text":""},{"location":"HSS_Electives/International_Relations/Project/presentation/#focus-on","title":"Focus on","text":"<ol> <li>try to stick to only a few \u2018for\u2019 and \u2018against\u2019 arguments</li> <li>add graphs</li> <li>future</li> <li>theories of international relations</li> <li>economics</li> <li>feelings and the \u2018human\u2019 part</li> <li>add qr code for the report</li> </ol>"},{"location":"HSS_Electives/International_Relations/Project/presentation/#credits","title":"Credits","text":"Image Name Source Red Neon Signage Airam Dato-on Pexels World Map - Wikipedia Commons city Zhang Kaiyv Pexels hongKongProtests - Wikipedia Commons Security Pixabay Pexels Chicago Max Bender Pexels Honk Kong Dimitris.s12 Pexels Wall of China Paulo Marcelo Martins Pexels laborExploitation AP Video Guardian coalition - End Uyghur Forced Labour cyber graph - RFA humanRights Sora Shimazaki Pexels ocean Donald Tong Pexels timelapse Google Google Timelapse waters - Wikipedia Commons covid Markus Spiske Pexels wuhan - Wikipedia Commons mask August de Richelieu Pexels concentrationMaps Google BBC Article <p>Thanks to all of them</p>"},{"location":"HSS_Electives/Politics/","title":"Politics","text":""},{"location":"HSS_Electives/Politics/#references","title":"References","text":"<ul> <li> Civil War and Political Instability | Brian Urlacher</li> <li> Politics and Strategy | UCLA</li> </ul>"},{"location":"Management/Accounts/","title":"Fundamentals of Finance &amp; Accounts","text":"<p>This course mainly focuses on financial accounting.</p>"},{"location":"Management/Accounts/#accounting-spreadsheets","title":"Accounting Spreadsheets","text":"<p>Available in different formats</p> <ul> <li>HTML</li> <li>Google Sheets</li> <li>Excel</li> </ul>"},{"location":"Management/Accounts/#financial-statements-dashboard","title":"Financial Statements Dashboard","text":"<ul> <li>Dashboard</li> <li>GitHub Repository</li> </ul>"},{"location":"Management/Accounts/#references","title":"References","text":"<ul> <li> Fundamentals of Finance &amp; Accounting | Dr Asgar Ali | BITS Pilani Dubai Campus</li> <li> Introduction to Quantitative Decision | Allan Wesley</li> <li> Managerial Accounting | Edspira</li> </ul>"},{"location":"Management/Accounts/01_Introduction/","title":"01 Introduction","text":""},{"location":"Management/Accounts/01_Introduction/#accounts-vs-finance","title":"Accounts vs Finance","text":"Accounting Finance Past-Looking Future-Looking Aspect Reporting Planning Easy to automate \u2705 \u274c"},{"location":"Management/Accounts/01_Introduction/#accounting","title":"Accounting","text":"<ul> <li>Measure performance of organization</li> <li>Provides useful info for decision-making</li> </ul>"},{"location":"Management/Accounts/01_Introduction/#public-offerings","title":"Public Offerings","text":"<p>When a corporation wants to list itself in the stock market, there are offerings (for valuation of my company)</p> Meaning IPO Initial Public Offer FPO Follow-Up Public Offer"},{"location":"Management/Accounts/01_Introduction/#earnings-management","title":"Earnings Management","text":"<p>Situation when management tries to increase their earnings, by intentionally focusing on increasing stock valuation, and nothing else.</p>"},{"location":"Management/Accounts/01_Introduction/#brances-of-accounting","title":"Brances of Accounting","text":"Branch Alias Name Purpose External Financial Accounting Official records Internal Management Accounting(Revenue Optimization, Internal Audit) Decision process"},{"location":"Management/Accounts/01_Introduction/#financial-accounting","title":"Financial Accounting","text":"<p>Systematic procedure of recording, classifying, summarizing, analyzing, and reporting a business\u2019 monetary transactions</p>"},{"location":"Management/Accounts/01_Introduction/#advantages","title":"Advantages","text":"<p>The systematic record helps</p> <ul> <li>Protect property</li> <li>Communicate results to interested parties</li> <li>Comply with legalities</li> </ul>"},{"location":"Management/Accounts/01_Introduction/#disadvantages","title":"Disadvantages","text":"<ul> <li> <p>Records only monetary transactions</p> </li> <li> <p>Inflation not considered</p> </li> <li> <p>Historical in nature</p> </li> <li> <p>Costly</p> </li> <li> <p>Window-dressing</p> </li> </ul> <p>Fund manager sells stocks with large losses and purchases high-flying stocks near the end of the quarter or year</p>"},{"location":"Management/Accounts/01_Introduction/#interested-parties","title":"Interested Parties","text":"Party Why are they interested in accounts Investors If they will get return on their investment Creditors If they will get loan back Workers If a company closes, you will not get salary Customers If a company closes, you will not get maintanance/replacement Government Checking for Fraud"},{"location":"Management/Accounts/01_Introduction/#financial-management","title":"Financial Management","text":"<p>Decisions on</p> <ul> <li>Investment</li> <li>Financing</li> <li>Dividend</li> </ul>"},{"location":"Management/Accounts/01_Introduction/#goal-of-corporation","title":"Goal of Corporation","text":"<p>Maximizes current wealth, ie value of company; not maximize profit</p>"},{"location":"Management/Accounts/01_Introduction/#expenditure-vs-expenses","title":"Expenditure vs Expenses","text":"Expenditure Expenses Meaning Buying assets for long-run gain Payment for something you have already consumed Example InvestmentBuying laptop Giving SalaryDepreciation of assetsBuying chocolates"},{"location":"Management/Accounts/01_Introduction/#asset","title":"Asset","text":"<p>Anything that provides you right to use/gain renenue generated by that item</p> <p>eg: Prepaid Telephone Service, Accrued income (deferred income; revenue that's been earned, but has yet to be received)</p> Type Duration Nature changes Example Current Period of 12months Short \u2705 Inventory Non-current/Fixed Long \u274c Land, Buildings Fictitious deferred revenue expenditures with no resale value Set up costsCompany LogoGoodwill"},{"location":"Management/Accounts/01_Introduction/#types-of-assets","title":"Types of Assets","text":"Real Asset Financial Asset/Securities Something that can generate revenue Contracts that provide a right to gain income from real assetsOne party\u2019s financial assets are another party\u2019s liability Can be tangible/intangible \u2705 \u2705 Liquidity Low High Examples Tangible (Machinery, property)Intangible (Technical know-ho) SharesBondsThese can be tangible (hard-copy)/intangible Purpose Functioning of businessRepresents society\u2019s wealth Separation of ownership &amp; managementEfficient allocation of capitalEfficient allocation of risk <p>Securities are actually financial assets with collateral, but they are used interchangeably</p>"},{"location":"Management/Accounts/01_Introduction/#financial-assets","title":"Financial Assets","text":"Asset Income Ownership/Equity Claims(Equity Shares/Common Stocks) Variable Creditor Claims(Bonds) Fixed Hybrid Claims(Preferential Stocks) Hybrid Derivatives(Claims on other financial assets) Synthetic Indirect Financial Assets(Mutual funds, Hedge funds) Synthetic"},{"location":"Management/Accounts/01_Introduction/#bonds","title":"Bonds","text":"<p>Interest rate of bond depends on</p> <ul> <li>Credit rating of corporation</li> <li>Duration</li> <li>Short-term bond has low interest rate</li> <li>Long-term bond has high interest rate</li> </ul>"},{"location":"Management/Accounts/01_Introduction/#derivatives","title":"Derivatives","text":"<p>Synthetically-created instrument that obtains value from underlying set of assets</p> <ul> <li>Spot price</li> <li>Expiry</li> <li>Exercise price</li> </ul>"},{"location":"Management/Accounts/01_Introduction/#types","title":"Types","text":"Type Forward Future contract Call Option Right to buy an asset Put Option Right to sell an asset Swap- CDS (Credit Default Swap)"},{"location":"Management/Accounts/01_Introduction/#indirect-investing","title":"Indirect Investing","text":"<ul> <li>Hedge funds invest at a higher risk-return compared to Mutual funds</li> </ul>"},{"location":"Management/Accounts/01_Introduction/#liability","title":"Liability","text":"<p>Anything that has requirement for you to pay for it</p> <p>eg: Outstanding expenses, Unaccrued income (receiving advance payment, bank overdrafting)</p> Type Example Current Short Term(Period of 12months) Rent Non-Current Long Term Loans Contingent Conditional Guarantee/Warranty"},{"location":"Management/Accounts/01_Introduction/#keywords","title":"Keywords","text":"Underwriters Assurance that they will buy in case the value of a commodity reduceseg: Insurance Standards The standards we follow is INDAS (INDian Accounting Standards) Market Cap Valuation Free-Floating Ratio Ratio of stocks publicly available for purchase Liquidity Ratio of assets in cash BPL Below poverty line White Goods Household/domestic goods, such as fridge, dryers, etc"},{"location":"Management/Accounts/01_Introduction/#documents","title":"Documents","text":"Document Meaning Time Shows Journal Chronological record of transactions continuous Debit, Credit Ledger Classification of transactions into different accounts continuous Debit, Credit Trial Balance list of balances of the ledger accounts at a point of time Debit, Credit Balance Sheet Shows the assets and liabilities at particular instant Assets, Liabilities Profit-Loss/Income Statement Shows the revenue and expenses relevant to the core operations of company during period of time Assets, Liabilities Cashflow Statement Show the source and uses of cash during period of time"},{"location":"Management/Accounts/02_Principles_of_Accounting/","title":"02 Principles of Accounting","text":""},{"location":"Management/Accounts/02_Principles_of_Accounting/#accounting-concepts","title":"Accounting Concepts","text":"Money Measurement All transactions are recorded in terms of currency (monetary value)Only money transactions are recorded Business Entity A corporation is considered as a separate legal entity from its owners Dual Aspect Assets = Liabilities + Capital(Assets + Expenses = Liabilities + Equity + Revenue) Going Concern Assumption that business will continue to trade for the foreseable futureAllows cost of purchases to be distributed across time Historical Cost Assets are quantified by their cost &amp; not their market value Accounting Period Matching Cost When calculating net income, only relevant revenue and relevant expenses for the specific accounting period should be used Revenue Realisation Sale should be considered as complete only after complete exchange of ownership between both parties, for the goods/services"},{"location":"Management/Accounts/02_Principles_of_Accounting/#accounting-conventions","title":"Accounting Conventions","text":"Full Disclosure All information should be informed to users of statements Materiality Only those information should be stated that impacts the decision of the users of statement and unnecessary information should not be disclosed Conservatism Incorporate anticipated losses, but not anticipated profits Consistency Transactions/events are recorded in the same way, in every accounting period"},{"location":"Management/Accounts/02_Principles_of_Accounting/#derivation-of-accounting-equation","title":"Derivation of Accounting Equation","text":"\\[ \\begin{aligned} \\text{Assets} &amp;= \\underbrace{\\text{Liabilities + Capital}}_\\text{Total Liabilities} \\\\ \\text{Capital} &amp;= \\text{Equity+Net Margin} \\\\ \\text{Net Margin} &amp;= \\text{Revenue-Expenses} \\\\ \\implies \\text{Assets + Expenses} &amp;= \\text{Liabilities + Equity + Revenue} \\end{aligned} \\] <ul> <li>Capital: Soft Contract</li> <li>Liabilities: Hard Contract</li> </ul>"},{"location":"Management/Accounts/02_Principles_of_Accounting/#something","title":"Something","text":"<ul> <li>Debit: Indebted</li> <li> <p>Creditor: Gets credit for the transaction</p> </li> <li> <p>Capital is when owners invest funds</p> </li> <li>Drawings is when owners withdraw funds</li> </ul>"},{"location":"Management/Accounts/03_Process_of_Accounting/","title":"03 Process of Accounting","text":""},{"location":"Management/Accounts/03_Process_of_Accounting/#types-of-accounts","title":"Types of Accounts","text":"Account Debit Credit Personal Receiver Giver Real What comes in What goes out Nominal Expenses &amp; Losses Income &amp; Gains"},{"location":"Management/Accounts/03_Process_of_Accounting/#accounting-equation","title":"Accounting Equation","text":"Assets + Expenses Liabilities + Equity + Revenue Increases Dr. Cr. Decreases Cr. Dr."},{"location":"Management/Accounts/03_Process_of_Accounting/#accounting-cycle","title":"Accounting Cycle","text":"<pre><code>flowchart LR\nsd[Source&lt;br/&gt;Documents] --&gt;\n|Journalize| Journal --&gt;\n|Posting| Ledger --&gt;\ntb[Trial&lt;br/&gt;Balance]--&gt;\nfs\n\nsubgraph fs[Financial&lt;br/&gt;Statements]\n    direction LR\n    bs[Balance&lt;br/&gt;Sheet]\n    pl[Profit-Loss/&lt;br/&gt;Income]\n    cf[Cashflow]\nend</code></pre>"},{"location":"Management/Accounts/03_Process_of_Accounting/#journal","title":"Journal","text":"<p>Record of transactions, regardless of income, expenses, etc</p> Date Particulars Debit(Dhs) Credit(Dhs) 2022-01-01 Cash A/C Dr. 20,000 To Capital A/C 20,000 (Being commencement of business) <p>To means: Debitor(Dr.) is indebted to Creditor(Cr.)</p>"},{"location":"Management/Accounts/03_Process_of_Accounting/#purpose","title":"Purpose","text":"<ul> <li>provides permanent record</li> <li>provides information of debit and credit in an entry and an explanation</li> <li>reduces the possibility of error as both aspects of a business transaction are written side by side</li> </ul>"},{"location":"Management/Accounts/03_Process_of_Accounting/#compound-journal-entries","title":"Compound Journal Entries","text":"Date Particulars Debit (Dhs) Credit(Dhs) 2022-01-01 Cash A/C Dr. 20,000 To Electricity Company 10,000 To Water Company 10,000 (Expenditure on Utilities) <p>Transactions involving Discount A/C are always compound journal entries</p>"},{"location":"Management/Accounts/03_Process_of_Accounting/#ledger","title":"Ledger","text":"<p>Summary statement of all the transactions relating to a person, asset, expense or income which have taken place during a given period of time and shows their net effect</p> <ul> <li>Debit side = Receipts side</li> <li>Credit side = Payment side</li> </ul> <p>It is in a \u2018T\u2019 form</p> <p></p> Dr &lt; Account Name &gt; Cr. Date Particulars Amount Date Particulars Amount 2022-01-01 To Credit A/C 2022-01-01 By Debit A/C Total \\(d\\) Total \\(c\\)"},{"location":"Management/Accounts/03_Process_of_Accounting/#overage-balance","title":"Overage Balance","text":"<p>Overage = surplus of debit/credit</p> Symbol Meaning C/D Carried Down B/D Brought Down Case Dr Cr \\(d&gt;c\\) To Balance B/D By Balance C/D \\(d&lt;c\\) To Balance C/D By Balance B/D"},{"location":"Management/Accounts/03_Process_of_Accounting/#trial-balance","title":"Trial Balance","text":"<p>List of overages of the ledger accounts at a particular point of time</p> <p>The selected side (debit/credit) is the one having the amount brought down to next period.</p> <p>If everything is right, the trial balance should result in</p> \\[ \\sum \\text{Debit Overages} = \\sum \\text{Credit Overages} \\] S. No Name of A/C Debit (Dhs) Credit (Dhs) \\(a\\) \\(b\\) Total \\(k\\) \\(k\\)"},{"location":"Management/Accounts/04_Financial_Statements/","title":"04 Financial Statements","text":"<p>In our course, we will work on the simpler \u2018horizontal\u2019 version of each financial statement.</p>"},{"location":"Management/Accounts/04_Financial_Statements/#balance-sheet","title":"Balance Sheet","text":"Liabilities Amount Asset Amount"},{"location":"Management/Accounts/04_Financial_Statements/#types","title":"Types","text":"Contains Standalone Company Consolidated Company,"},{"location":"Management/Accounts/04_Financial_Statements/#cashflow-statement","title":"Cashflow Statement","text":"Particular Inflow Outflow Opening Balance $120,000 Operating Activities Sales $400,000 Supplies $9,000 Rent $60,000 Salaries $330,000 Investing Activities Additional Equipment $55,000 Financing Activities 0 Total Inflow $400,000 Total Outflow $454,000 Net Cashflow -$54,000 Closing Balance $66,000"},{"location":"Management/Accounts/04_Financial_Statements/#profitloss-statement","title":"Profit/Loss Statement","text":"<p>Also called as comprehensive Income Statement</p> Amount Sales Cost of Goods Sold Gross Margin XXX - Operational Costs (Office &amp; Selling Expenses) Operating Profits XXX + Non-Operating Income + Non-Operating Losses EBIT (Earnings before Interests and Tax) XXX - Interest - Other financing costs PBT (Profit before Tax) XXX Provision for Tax PAT (Profit after Tax)/Net Margin XXX <p>You only include the expenses used for the revenue generation.</p>"},{"location":"Management/Accounts/04_Financial_Statements/#change-in-equity-statement","title":"Change in Equity Statement","text":""},{"location":"Management/Accounts/04_Financial_Statements/#notes","title":"Notes","text":"<p>Explanation notes of system you followed to obtain the above statements</p>"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/","title":"05 Fixed Assets & Depreciation","text":""},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#fixed-assets","title":"Fixed Assets","text":"<p>Also called as non-current assets</p> <p>Long-term assets that can be</p> <ul> <li>Tangible (Land, Buildings)</li> <li>Intangible (Goodwill, Patent, Knowhow)</li> </ul>"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#importance-of-fixed-assets-identification","title":"Importance of fixed assets identification","text":"Financial Statement Understand Why important? Profit Loss Statement Expensed Less profit this yearLess Depreciation in Coming yearsLess assets in Balance Sheet Balance Sheet Capitalized More profit this yearMore depreciation in coming yearsMore assets in Balance Sheet"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#cost-of-fixed-asset","title":"Cost of Fixed Asset","text":"<p>All expenses necessary to make asset ready for intented use</p> <ul> <li>Purchase price [Net ie after making adjustment for taxes(excluded), rebates, etc]</li> <li>Cost of site preparation</li> <li>Delivery and handling cost</li> <li>Installation cost</li> <li>Training/Professional fee</li> <li>Cost of trial run</li> <li>Maintanance</li> </ul>"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#useful-life-of-an-asset","title":"Useful life of an asset","text":"\\[ \\text{Useful Life} \\le \\text{Physical Life} \\] <p>Estimated based on - Expected physical wear and tear - Obsolescence (not used anmyroe - Legal/limits on use assets</p> <p>Expressed in terms of time period/production units (hrs, km)</p>"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#depreciation","title":"Depreciation","text":"<p>Means of cost allocation</p> <p>Depreciation \\(\\ne\\) Valuation</p>"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#methods-of-depreciation","title":"Methods of Depreciation","text":"Straight-line Declining balance/Written-Down value DepreciationAmount \\(D\\) \\(\\frac{\\text{Original Asset Cost} - \\text{Estimated Scrap Value}}{\\text{Estimated Life of Asset}}\\) Value at time \\(t\\) \\(V_0 - tD\\) \\(V_0 (1-r)^t\\)where \\(r =\\) depreciation rate Conclusion Acceptable Better Salvage Amount 0 \\(\\ge 0\\)"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#accounting-treatment","title":"Accounting Treatment","text":"Date Particulars Amount 1. Entry for purchase of asset Asset A/C Dr. To Bank A/C Cr. 2. Entries for providing depreciation at the end of each year Depreciation A/C Dr. To Asset A/C Cr. 3. Entry for amount realized on sale of asset Bank A/C Dr. To Asset A/C Cr."},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#reasoning","title":"Reasoning","text":"<p>Refer to Accounting Equation</p> <ol> <li>Asset value inc; Bank (Asset) dec</li> <li>Depreciation (Expense) inc; Asset value dec</li> <li>Bank (Asset) inc; Asset value dec</li> </ol>"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#types-of-asset-values","title":"Types of Asset Values","text":"Value Meaning Salvage Estimated asset value at the end of its useful life Scrap Actual resale value at the end of its useful life Book Estimate asset value at any point in time <p>At the end of useful life</p> \\[ \\begin{aligned} \\text{Book Value} &amp;= \\text{Scrap Value} \\\\ \\text{Net margin for asset resale} &amp;= \\text{Scrap value} - \\text{Salvage value} \\end{aligned} \\]"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#law-of-marginal-utility","title":"Law of Marginal Utility","text":"\\[ \\text{Returns from consumption} \\propto \\frac{1}{\\text{Consumption Amount}} \\]"},{"location":"Management/Accounts/05_Fixed_Assets_%26_Depreciation/#sinking-fund","title":"Sinking Fund","text":"<p>\u201cA sinking fund is an account a corporation uses to set aside money earmarked to pay off the debt from a bond or other debt issue\u201d</p> <ul> <li>Long-term provision</li> <li>Short-term provision</li> </ul>"},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/","title":"06 Cost of Sales & Inventories","text":""},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/#inventory","title":"Inventory","text":"<p>Assets that are either</p> <ul> <li>products for sale</li> <li>supplies</li> </ul>"},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/#supplies","title":"Supplies","text":"<p>Tangible items that will be consumed in the course of normal operations, such as lubricants, repair parts</p>"},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/#types-of-companies","title":"Types of Companies","text":"Type Manufacturing Merchandising Service Meaning Converts raw materials into finished goods Sells goods in the same form as acquired Provides intangible services Example Trading businesses, Grocery stores Hotels, beauty parlors, plumbers, professional service firms (accountingfirms, legal firms) Inventory MaterialsWork-in-progressFinished goods Materials Inventory costs Acquisition costs(includes cost of goods sold)"},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/#inventory-costs","title":"Inventory Costs","text":"<p>Includes</p> <ul> <li>Cost of purchase</li> <li>Net of trade discount</li> <li>Includes duties and taxes, freight inward</li> <li>Cost of conversion</li> <li>Direct Labour</li> <li>Factory Overheads (Rent, Insurance, Electricity)</li> <li>Transport costs</li> <li>Set-up costs</li> <li>Other normal losses</li> </ul> <p>Does not include</p> <ul> <li>Abnormal losses</li> <li>Interest cost</li> <li>Selling and distribution overheads</li> </ul>"},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/#some-special-costs","title":"Some Special Costs","text":"Cost Meaning Example Intangible Inventory CostsJobs in-progress/unbilled costs Costs incurred for client but not yet billed Shortage Costs Costs incurred by an organization when it has no inventory in stock. Loss of business from customers who go elsewhere to make purchasesLoss of the margin on sales that were not completedOvernight shipping costs to acquire goods that are not in stock"},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/#calculation-of-cost-of-goods-sold","title":"Calculation of Cost of Goods Sold","text":"A. Cost of Goods Consumed Opening stock of raw material \\(a\\) + Purchase (including freights etc.) \\(b\\) - Closing Stock of raw material \\(c\\) \\(c\\) B. Cost of Goods Produced/Production: Opening Work-in-progress (WIP) \\(d\\) + Cost of raw material consumed \\(c\\) + Conversion Cost \\(e\\) + Factory Overheads \\(f\\) - Closing WIP \\(g\\) \\(g\\) C. Cost of Goods Sold Opening Stock of Finished Goods \\(h\\) + Cost of Goods Produced \\(g\\) - Closing Stock of Finished Goods \\(i\\) \\(i\\)"},{"location":"Management/Accounts/06_Cost_of_Sales_%26_Inventories/#inventory-cost-methods","title":"Inventory Cost Methods","text":"<p>Valuation of unsold inventory stock when preparing financial statements</p> Meaning Permittedin India? Formula FIFO(First In, First Out) Items bought first sold first \u2705 LIFO(Last In, First Out) Items bought last sold first \u274c WAC(Weighted Average Cost) \u2705 \\(\\dfrac{\\sum \\text{Count}_i \\times \\text{Rate}_i}{\\text{Total Count}}\\) <p></p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/","title":"07 Analysis of Financial Statements","text":""},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#types-of-analysis","title":"Types of Analysis","text":"Analysis Understand Values Formula Absolute Actual Values Horizontal/Dynamic Trend over the years All values compared to a base year \\(\\frac{V}{V_\\text{base}} \\times 100\\%\\) Vertical/Static Particular period All values compared to the total assets in the same period \\(\\frac{V}{\\text{Total Assets}}\\times 100\\%\\) (Balance Sheet)\\(\\frac{V}{\\text{Net Cashflow}}\\times 100\\%\\)(Cash Flow)\\(\\frac{V}{\\text{Total Revenue}}\\times 100\\%\\)(Income Statement) Ratio Take ratio to create a combination of values and infer something <p>All types of analysis is important, as they each may give different inferences.</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#balance-sheet","title":"Balance Sheet","text":"Variable Meaning SHAREHOLDER'S FUNDS Equity Share Capital Ownership stake(increases with Stock split) Total Share Capital Reserves and Surplus Retained earnings Total Reserves and Surplus Total Shareholders Funds Equity Share Application Money Hybrid/Debt/Other Securities NON-CURRENT LIABILITIES Pending after a year Long Term Borrowings Loans/Bonds Deferred Tax Liabilities [Net] Postponed taxes Other Long Term Liabilities Mortgages Long Term Provisions Conditional Guarantees/WarrantiesEmployment benefits, pensions Total Non-Current Liabilities CURRENT LIABILITIES Pending within a year Short Term Borrowings Trade Payables What you owe suppliersOther parties will only tolerate if you are dominant in the market Other Current Liabilities Current Portion of Long-Term Debt Short Term Provisions Provisions for immediate conditional compensations such as legal issues, etc Total Current Liabilities Total Capital And Liabilities ASSETS NON-CURRENT ASSETS Tangible Assets Physical Intangible Assets Non-Physical Capital Work-In-Progress Products in progress Intangible Assets Under Development R&amp;D Fixed Assets Non-Current Investments Long Term Loans And Advances Giving loans to subsidiaries, as the parent company get cheaper loansTax evasion Other Non-Current Assets Machinery, Equipment Total Non-Current Assets CURRENT ASSETS Current Investments Money market (loans between 7 &amp; 365 days) Inventories Trade Receivables Cash And Cash Equivalents Anything that can used as payment, such as Cash/Cheques/Credit slips Short Term Loans And Advances Other Current Assets Total Current Assets Total Assets <p>Trenches is when you securitize a loan that you lent, and then trade it to the public. 2008 financial crisis</p> <p>Sinking fund is the repayment of bond</p> <p>Generally, steel plants </p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#income-statement","title":"Income Statement","text":"Meaning INCOME Revenue From Operations [Gross] Less: Excise/Sevice Tax/Other Levies Revenue From Operations [Net] Other Operating Revenues Total Operating Revenues Other Income Total Revenue EXPENSES Cost Of Materials Consumed Purchase of Stock-In Trade Purchase of ready-made input for production Changes In Inventories Of FG,WIP And Stock-In Trade Employee Benefit Expenses Finance Costs Depreciation And Amortisation Expenses Other Expenses Less: Amounts Transfer To Capital Accounts Total Expenses Profit/Loss Before Exceptional, ExtraOrdinary Items And Tax Exceptional Items Profit/Loss Before Tax Tax Expenses-Continued Operations Current Tax Deferred Tax Total Tax Expenses Profit/Loss After Tax And Before ExtraOrdinary Items Profit/Loss From Continuing Operations Profit/Loss For The Period OTHER ADDITIONAL INFORMATION EARNINGS PER SHARE Basic EPS <p>If total shareholders funds increases over time, the company is very good, regardless if equity share capital dec.</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#cashflow-statement","title":"Cashflow Statement","text":"NET PROFIT/LOSS BEFORE EXTRAORDINARY ITEMS AND TAX Net CashFlow From Operating Activities Net Cash Used In Investing Activities Net Cash Used From Financing Activities Foreign Exchange Gains / Losses Adjustments On Amalgamation Merger Demerger Others NET INC/DEC IN CASH AND CASH EQUIVALENTS Cash And Cash Equivalents Begin of Year Cash And Cash Equivalents End Of Year"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#ratio-analysis","title":"Ratio Analysis","text":"Aspect Ratio Recommended Liquidity Current Ratio 2:1 Quick Ratio/Acid Test Cash Ratio Profitability Gross Profit Ratio Operating Profit Ratio Net Profit Ratio Solvency Ratio Debt-Equity Ratio Interest Coverage Ratio Turnover Ratio Fixed Asset Turnover Ratio Inventory Turnover Ratio Receivable Turnover Ratio Earning Ratio Profit-Earning Ratio Earning Per Share"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#misc","title":"Misc","text":""},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#types-of-investments","title":"Types of Investments","text":"Relationship Amount Subsidiary &gt; 50% Associate 20% &lt; A &lt; 50% Minority Interest &lt; 20%"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#shares","title":"Shares","text":"<p>\u2018Splitting\u2019 shares = fragmentation</p> <p>Base capital</p> Authorized capital Paid-up capital Equity shares <p>Reserve and Surplus involves</p> <ul> <li>Retained earnings</li> <li>Overage from premium surplus</li> </ul> Face Value Book/Intrinsic Value Market Value <p>Dividend of 200% means 200% of face value</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#stock-splits","title":"Stock Splits","text":"<p>Causes market noise</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#market-noise","title":"Market Noise","text":"<p>Unnecessary oscillation</p> <p>Herding behavior</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#re-investment-risk","title":"Re-Investment Risk","text":""},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#solvency","title":"Solvency","text":"<p>Ability of a company to cover its long-term financial obligations</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#insolvency","title":"Insolvency","text":""},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#financial-distress","title":"Financial Distress","text":"<p>When Current assets &lt; Hard Contracts</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#types-of-lease","title":"Types of Lease","text":"<p>An operating lease is a contract that permits the use of an asset without transferring the ownership rights of said asset. A finance lease is a contract that permits the use of an asset and transfers ownership after the lease period is complete, and the lessor meets all other contract obligations.</p>"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#ratio-analysis_1","title":"Ratio Analysis","text":"Represents NI Net Income TE Total Equity IDK \\(\\tau\\) Effective Tax Rate Current Tax/PBT Working Capital Current Assets - Current Liabilities Cash Expenses per Day Total Expenses/365 Overall Performance Ratio ROA/ROTA (Before Tax) EBIT/TA ROA/ROTA (After Tax) EBIT*(1-\\(\\tau\\))/TA ROE NI/Equity ROCE (Before Tax) EBIT/TA-CL ROCE (After Tax) EBIT(1-t)/TA-CL Profit Margin Ratios EBITDA Margin EBITDA/Sales EBIT Margin/OPM EBIT/Sales EBT Margin EBT/Sales Net Profit Margin NI/Sales Asset Turnover Ratio Sales/Total Assets Two Factor Dupont Analysis ROA EBIT margin * ATR Three Factor DuPont NPM NI/Sales ATR Sales/Total Assets Total Leverage Total Assets/Equity ROE NPM * ATR * TL Five Factor Dupont Tax Factor NI/EBT Interest Factor EBT/EBIT EBIT Margin EBIT/Sales ATR Sales/TA TL TA/Equity ROE TF * IF * EM * ATR * TL Turnover or Efficiency Ratios Non-Current Asset Turnover Ratio Sales/NCA PPE Utilisation Ratio/ Capital Intensity Ratio Sales/PPE Current Asset Turnover Ratio Sales/CA Equity Turnover Ratio Sales/Equity Working Capital Ratios Working Capital Turnover Ratio Sales/Working Capital Inventory Turnover Ratio (ITR) Sales/Inventory Days Inventory 365/ITR Debtors Turnover Ratio (DTR) Sales/Accounts Receivable Days receivable or Average Collection Period 365/DTR Days Cash Cash/ Cash Expenses per Day Creditor Turnover Ratio (CTR) Material Consumed/Accounts Payable Days Creditors/Average Payment Period 365/CTR Cash Conversion Cycle (Days) Days inventory + Days debtors + Days Cash - Days Payable Insolvency Ratio Debt All interest bearing liabilites are debt Debt/Equity Ratio Total Debt/ Equity Debt Ratio /Debt Capitalisation Ratio Debt/ (Debt + Equity) Equity Ratio/ Equity Capitalisation Ratio Equity/(Debt + Equity) Interest Coverage Ratio EBIT/ Interest Total Debt Service Ratio EBIT/ (Interest + Debt) Test of Dividend Policy Dividend Per Share Dividend Declared/ No. of share outstanding Earning Per Share NI/ No of share outstanding Dividend Yeild Ratio Dividend/ Current Market Price Dividend Payout Ratio (D/P Ratio) DPS/EPS = Dividend Declared/NI Retension Ratio 1 - D/P Ratio Liquidity Ratios Current Ratio Current Assets/ Current Liabilities Quick Ratio/ Acid Test Ratio (CA-Inventory)/ CL Valuation Ratios Book Value per Share Total Equity/ No. of Share Outstanding Market Value Per Share (on balance sheet date) market value of share Earning Per share NI/ No of share outstanding Price Earning Ratio (P/E) MPS/EPS Price to Book Value Ratio (P/B) MPS/BVPS"},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#margin-vs-markup","title":"Margin vs Markup","text":""},{"location":"Management/Accounts/07_Analysis_of_Financial_Statements/#return-vs-yield","title":"Return vs Yield","text":"Return Yield Calculated relative to Initial invested capital Current Market Price"},{"location":"Management/Accounts/Side_Quests/Current_Maturity/","title":"Current Maturity","text":""},{"location":"Management/Accounts/Side_Quests/Current_Maturity/#2-extra-credit-assignment","title":"\\(2 \\%\\) Extra-Credit Assignment","text":"<p>Will long-term borrowings will be reclassified into short-term borrowings?</p> <p>By: Ahmed Thahir, 2020A7PS0198U</p>"},{"location":"Management/Accounts/Side_Quests/Current_Maturity/#summary","title":"Summary","text":"<p>No, not exactly. However, long-term borrowings will be reclassified into current liabilities (not exactly short-term borrowings) upon a certain date, using the concepts of</p> <ul> <li>Current Maturity of Long-Term Debt</li> <li>Current Portion of Long-Term Debt</li> </ul>"},{"location":"Management/Accounts/Side_Quests/Current_Maturity/#explanation","title":"Explanation","text":"<p>The current maturity of a company\u2019s long-term debt refers to the stage when a long-term debt (or a portion of it) is due within the next 12 months.</p> <p>Current Portion of Long-Term Debt (CPLTD) refers to the portion of liabilities that have gone throught current maturity of long-term debt. It can be less than or equal to the Long-term Debt (LTD).</p> \\[ 0 \\le \\text{CPLTD} \\le \\text{LTD} \\] <p>This means that portion of long-term debt that is to be paid within a year is reclassified from a non-current liability to a current liability.</p>"},{"location":"Management/Accounts/Side_Quests/Current_Maturity/#why","title":"Why?","text":"<p>This is to accurately analyze the liquidity of a company, since CPLTD must be paid within the coming year; liquidity is a company's ability to convert assets to cash or acquire cash\u2014through a loan or money in the bank\u2014to pay its liabilities/obligations within the current year.</p> \\[ \\begin{aligned} \\text{Current Ratio} &amp;= \\frac{\\text{Current Assets}}{\\text{Current Liabilities}} \\\\ &amp;= \\frac{\\text{Current Assets}}{\\text{Short-Term Borrowings + \\textcolor{hotpink}{CPLTD}}} \\\\ \\text{Quick Ratio} &amp;= \\frac{\\text{Current Assets - Inventories}}{\\text{Current Liabilities}} \\\\ &amp;= \\frac{\\text{Current Assets - Inventories}}{\\text{Short-Term Borrowings + \\textcolor{hotpink}{CPLTD}}} \\\\ \\text{Cash Ratio} &amp;= \\frac{\\text{Cash \\&amp; Cash Equivalent + Short-Term Investments}}{\\text{Current Liabilities}} \\\\ &amp;= \\frac{\\text{Cash \\&amp; Cash Equivalent + Short-Term Investments}}{\\text{Short-Term Borrowings + \\textcolor{hotpink}{CPLTD}}} \\end{aligned} \\] <p>As you can see in all forms of liquidity analysis, we need to include CPLTD to ensure an accurate analysis.</p>"},{"location":"Management/Accounts/Side_Quests/Current_Maturity/#references","title":"References","text":"<p>[1] \u201cCurrent Maturity Definition,\u201d Investopedia. https://www.investopedia.com/terms/c/currentmaturity.asp (accessed Apr. 30, 2023).</p> <p>[2] \u201cWhat Is the Current Portion of Long-Term Debt (CPLTD)?,\u201d Investopedia. https://www.investopedia.com/terms/c/currentportionlongtermdebt.asp (accessed Apr. 30, 2023).</p>"},{"location":"Management/Accounts/Side_Quests/Insolvency/","title":"Insolvency","text":"<p>Insolvency and banruptcy 2016</p>"},{"location":"Management/Business_Analytics/","title":"Business Analytics","text":""},{"location":"Management/Business_Analytics/#references","title":"References","text":"<ul> <li> Market Research | IIT Madras</li> <li> Business Analytics | IIT Madras</li> <li> Business Data Management | IIT Madras</li> <li> Customer Lifetime Value | Edward Malthouse</li> </ul>"},{"location":"Management/Consulting/","title":"Consulting","text":""},{"location":"Management/Consulting/#references","title":"References","text":"<ul> <li> IIM Ahmedabad Consult Prep Book</li> <li> Case Interview Walkthroughs | Matt Huang</li> </ul>"},{"location":"Management/Consulting/01_Introduction/","title":"Consulting","text":""},{"location":"Management/Consulting/01_Introduction/#types","title":"Types","text":""},{"location":"Management/Consulting/01_Introduction/#why-consulting","title":"Why Consulting","text":"<ul> <li>Dynamic nature of work</li> <li>Boosted career progression</li> <li>High value professional network</li> <li>Great perks</li> <li>Lucrative exit opportunities</li> </ul>"},{"location":"Management/Consulting/01_Introduction/#roles","title":"Roles","text":"<ul> <li>Intern</li> <li>Analyst/Associate</li> <li>Senior Analyst/Associate</li> <li>Consultant</li> <li>Senior Consultant</li> <li>Manager</li> <li>Senior Manager</li> <li>Principal/Director</li> <li>Partner</li> </ul> <p>Shift from</p> <ul> <li>Analytical skills</li> <li>Project management, people management</li> <li>Business development, client relationships</li> </ul>"},{"location":"Management/Corporate_Finance/","title":"Corporate Finance","text":"<p>Also called Financial Management</p> <p>This course covers concepts relevant to managing finances of a corporation.</p>"},{"location":"Management/Corporate_Finance/#references","title":"References","text":"<ul> <li> Financial Management | Faisal Zargar | BITS Pilani Dubai Campus</li> <li> Corporate Finance | Aswath Damodaran | NYU Stern</li> <li> Valuation | Aswath Damodaran | NYU Stern</li> <li> Finance | Hvass Laboratories</li> <li> Project Evaluation and Emerging Markets Finance | Campbell Harvey</li> </ul>"},{"location":"Management/Corporate_Finance/01_Introduction/","title":"01 Introduction","text":""},{"location":"Management/Corporate_Finance/01_Introduction/#finance","title":"Finance","text":"<p>Finance is the field that deals with value; finance is not about money</p> <p>Financial system helps transfer money from savers to consumers.</p> <p>Finance is a child of Economics.</p> <p>Financial Management is a study of a corporation\u2019s finances. Hence, it is also called as Corporate Finance, Business Finance.</p> <p>2 variables involed are</p> <ul> <li>Time</li> <li>Risk</li> </ul>"},{"location":"Management/Corporate_Finance/01_Introduction/#goal","title":"Goal","text":"<p>Maximize value of company</p> <p>This is measure by the price of the stock</p>"},{"location":"Management/Corporate_Finance/01_Introduction/#financial-decisions-in-order-of-importance","title":"Financial Decisions (in order of importance)","text":"<ul> <li>Capital budgeting decisions (most important)</li> <li>Long term investments</li> <li>Purchase of real assets</li> <li>Captial structure decisions</li> <li>Financing decisiosn</li> <li>Sale of financial assets</li> <li>Working capital decisions</li> <li>Liquidity vs Profitability</li> <li>Dividend decisions (Residual of budgeting and structure - not very important)</li> <li>Pay/Retain</li> </ul>"},{"location":"Management/Corporate_Finance/01_Introduction/#risk-vs-uncertainity","title":"Risk vs Uncertainity","text":"<p>For risk, we have known probabilities. For eg, we can estimate inflation, etc</p> <p>Uncertainity means we have no information.</p> <p>Usually,</p> \\[ \\text{Trade Return} \\propto \\text{Risk} \\]"},{"location":"Management/Corporate_Finance/01_Introduction/#securities","title":"Securities","text":"<p>is a tradeable asset that gives you claim over something.</p> Risk-Free(Future cash flows guaranteed) Tradeable Loan \u2705 \u274c Bond \u2705 \u2705 Share \u274c \u2705"},{"location":"Management/Corporate_Finance/01_Introduction/#ownership-forms","title":"Ownership Forms","text":"Form Sole Proprietorship Partnership Company/Corporation/Limited Liability Company No of owners 1 \\(\\ge 2\\) \\(n\\)(includes shareholders) Ease of starting Easy Intermediate Difficult Regulations Low Low High Keeping profits All Part Partial Ease of Valuation Difficult Difficult Easy Life length life of owner life of owners Unlimited Equity capital Limited to owner\u2019s personal wealth Limited to owners\u2019 personal wealth Liability Unlimited Unlimited Limited to investment of investor Ease for transfer of ownership Difficult Difficult Easy Ownership separate from Management \u274c \u274c \u2705 Agency Problems \u274c \u274c \u2705 Taxation Single* Single* Double <p>*Taxed only once as personal income (corporate tax is higher than personal)</p>"},{"location":"Management/Corporate_Finance/01_Introduction/#agency-problems","title":"Agency Problems","text":"<p>Goals of managers different from owners</p> <p>The manager will be more short-term oriented, in order to boost their portfolio, so that they can move on to a better company</p>"},{"location":"Management/Corporate_Finance/02_Corporation/","title":"02 Corporation","text":""},{"location":"Management/Corporate_Finance/02_Corporation/#foundation","title":"Foundation","text":"<p>Founding starts by filing a charter with the state it wishes to incorporate</p>"},{"location":"Management/Corporate_Finance/02_Corporation/#ownership","title":"Ownership","text":"<p>There is no limit to number of shareholders, and thus amounts of funds is theortically </p> <p>Before they list themselves, </p> <ol> <li>Value the company</li> <li>They make \\(\\le 49 \\%\\) available, to avoid a \u2018hostile takeover\u2019</li> </ol> <p>Owner of stock can be called as:</p> <ul> <li>Shareholder</li> <li>Stockholder</li> </ul> <p>Owners can expect (not promised - not legal obligation)</p> <ul> <li> <p>capital gain</p> </li> <li> <p>dividend payments</p> </li> </ul> \\[ \\begin{aligned} \\text{Earnings per share} &amp;= \\frac{\\text{net profit}}{\\text{no of shares}} \\\\ \\text{Dividend payout rate} &amp;= \\text{} \\end{aligned} \\] <p>The board decides [in consultation with CEO] whether to give out dividends or to re-invest</p>"},{"location":"Management/Corporate_Finance/02_Corporation/#funds","title":"Funds","text":"\\[ \\text{Assets} = \\text{Liability} + \\text{Equity} \\] <p>The capital structure of a corporation</p> <ul> <li>Debt &amp; Bonds</li> <li>Equity = sum of all ownership value</li> </ul> <p>This is one of the things naive investors are not aware. Dividend should not be a factor when evaluating a stock. Dividends actually make the value of your stock lower, as the equity has reduced. (Similar to Law of Conservation of Energy). Distribution of profits should not occur during times of expansion. A company giving dividends is a sign that it has ran out of expansion.</p> <p>Double Taxation</p> <ul> <li>Dividend tax</li> <li>Capital gains tax</li> </ul> <p>Refer Clientele Effect</p>"},{"location":"Management/Corporate_Finance/02_Corporation/#claim-on-assets","title":"Claim on Assets","text":"<ol> <li>Debt (Interest)</li> <li>Preference Shares (Preference Dividends)</li> <li>Owners/Common Shares (Dividends)</li> </ol>"},{"location":"Management/Corporate_Finance/02_Corporation/#debt-bonds","title":"Debt &amp; Bonds","text":"<p>Lenders cannot be owners of the corporation. Payment of interest is a legal obligation.</p> <p>If company fails to pay interest, they have to file for bankruptcy. A legal authority comes in, and sells the company\u2019s assets to pay off the debt/bonds</p>"},{"location":"Management/Corporate_Finance/02_Corporation/#company-summary","title":"Company Summary","text":"Category Sign Sales Revenue + Direct Costs - Indirect Costs - EBIT (Earnings Before InTerest) Interest - Taxes - Net Margin \u00b1 <p>EBITDA (I was too shy to ask sir)</p>"},{"location":"Management/Corporate_Finance/02_Corporation/#clientele-effect","title":"Clientele Effect","text":""},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/","title":"Time Value of Money","text":"<p>You should never compare money across different time instants. We can only compare at the same instant.</p> When we take cashflow ___ in time Name forward compounding backward discounting <p>Return for every investment is a compensation</p> <ul> <li>Time</li> <li>Inflation</li> <li>Risk</li> </ul> <p>In a finance interview, if you\u2019re not sure of the answer, just say it\u2019s compounding \ud83d\ude2d\ud83d\ude02</p>"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#keywords","title":"Keywords","text":"Denotion Expressed as Value of something at Present Value PV Currency \\(t = 0\\) (not even \\(t \\approx 0\\)) Future Value FV Currency \\(t &gt; 0\\) Interest RateDiscount RateCompound RateOpportunity cost of capitalRequired return \\(r\\) % Exchange rate between present &amp; future value Number of Periods \\(n\\) or \\(t\\) Timeline Graphical reprsesentation of the timing of cash flows"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#singular-cashflow-formula","title":"Singular Cashflow Formula","text":"\\[ \\begin{aligned} \\text{FV} &amp;= \\text{PV} \\times \\underbrace{(1+r)^t}_{\\text{Compound Factor}} \\\\ \\implies \\text{PV} &amp;= \\text{FV} \\times \\underbrace{\\frac{1}{(1+r)^t}}_\\text{Discount Factor} \\end{aligned} \\]"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#multiple-cashflows","title":"Multiple Cashflows","text":"\\[ \\begin{aligned} \\text{FV} &amp;= \\sum_{t=0} c_t (1+r)^t \\\\ \\text{PV} &amp;= \\sum_{t=0} \\frac{c_t}{(1+r)^t} \\end{aligned} \\] <p>where \\(c_t\\) can be</p> Flow Type Inflow \\(c_t&gt;0\\) Outflow \\(c_t&lt;0\\)"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#types-of-interest","title":"Types of Interest","text":"<p>If \\(P =\\) original principal amount</p> Type FV Simple \\(P \\times (1+r) \\times t\\) Compound(Default) \\(P \\times (1+r)^t\\)"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#types-of-cashflows","title":"Types of Cashflows","text":"<p>Infinite series of cashflows which has</p> <p>eg: Preference share in a corporation</p> Perpetuity Annuity Finiteness Infinite Finite Term Forever Fixed Cashflow \u2705 \u2705 Occurs every time period \u2705 \u2705 Present Value \\(\\frac{c}{r}\\) \\(\\frac{c}{r} \\left[ 1-\\frac{1}{(1+r)^t} \\right]\\) Future Value N/A \\(\\frac{c}{r} \\left[ (1+r)^t - 1 \\right]\\)"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#conceptual-understanding-of-long-term-loan","title":"Conceptual understanding of long-term loan","text":"<p>Every [equal] installment is actually a combination of</p> <ul> <li>interest payment</li> <li>principal repayment</li> </ul> <p>As time goes on, your installment will be constituting: less of interest repayment &amp; more of principal repayment</p>"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#i-missed-a-few-classes","title":"I missed a few classes","text":""},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#interest-rates","title":"Interest Rates","text":""},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#apr","title":"APR","text":"<p>Annual Percentage Rate</p>"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#ear","title":"EAR","text":"<p>Effective Annual Rate</p> <p>The actual interest rate you are paying</p> \\[ \\text{EAR } = \\left( 1 + \\frac{\\text{APR}}{m} \\right)^m - 1 \\] <p>where \\(m =\\) interest compounding frequency</p> <p>This is the value of \\(r\\) we use when calculating present/future value</p>"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#compounding-frequency","title":"Compounding Frequency","text":"\\(m\\) Annual 1 Semi-Annual 2 Quarterly 4 Monthly 12 Daily 365 Hourly 365 * 24 Minutely 365 * 24 * 60 Second 365 * 24 * 60 * 60 <p>As we go from annual compounding towards more frequent compounding frequency, we are moving from discrete compounding to continuous compounding</p>"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#compounding-cycle","title":"Compounding Cycle","text":"<p>Frequency of compounding</p> <p>Let \\(m\\) be the compounding cycle, ie number of compounding per year $$ \\begin{aligned} \\text{FV} &amp;= \\text{PV} \\cdot (1+r)^t \\ &amp;= \\text{PV} \\left(1 + \\dfrac{r}{m} \\right)^{mt} &amp; \\text{(Discrete)} \\ &amp;= \\text{PV} \\times e^{rt} &amp; \\text{(Continuous)} \\end{aligned} $$</p>"},{"location":"Management/Corporate_Finance/03_Time_Value_of_Money/#idk","title":"IDK","text":"<p>If you are in the middle of time period, and certain cashflows have already been taken, $$ \\text{PV}' = \\text{PV} \\times \\dfrac{1}{(1+r)^{t_a/t_b}} $$</p> <ul> <li>\\(t_a=\\) Time elapsed in current time period</li> <li>\\(t_b=\\) Time Period</li> </ul>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/","title":"04 Capital Budgeting Decisions","text":"<p>Corporations face multiple decisions, but have to pick wisely due to limited capital.</p>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#capital-budgeting","title":"Capital Budgeting","text":"<p>Process of evaluating firm\u2019s long-term investment opportunities</p> <p>Large investments usually consist of smaller investment decisions.</p>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#framework","title":"Framework","text":"<ol> <li>Generation of investment idea</li> <li>Estimation of cash flows</li> <li>Select the appropriate opportunity cost of capital</li> <li>Selection of ideas based on acceptance criteria</li> <li>Re-evaluation</li> </ol>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#types-of-investments","title":"Types of Investments","text":"<ul> <li>Revenue-enhancement</li> <li>Cost-reduction</li> <li>Mandatory [government] investments to meet regulations</li> </ul>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#net-present-value-primary","title":"Net Present Value (Primary)","text":"<p>It is in currency</p> <p>One of </p> \\[ \\text{NPV} = \\text{PV(Inflows)} - \\text{PV(Outflows)} \\] NPV Meaning Decision \\(&gt;0\\) Actual returns &gt; Minimum required return Accept \\(&lt;0\\) Actual returns &lt; Minimum required return Reject \\(0\\) Actual returns = Minimum required return Doesn\u2019t matter"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#irr-primary","title":"IRR (Primary)","text":"<p>Internal Rate of Return</p> \\[ \\text{IRR} = \\text{Rate @ which NPV is 0} \\] <p>Actual return of your project</p> <p>We only know cashflows; no interest rates</p> <p>Calculating</p> <ol> <li>Derive an equation in terms of </li> </ol> \\[ \\text{NPV} = 0 \\\\ \\implies \\sum \\text{Discounted Cashflows} = 0 \\\\ \\] <ol> <li>Solve for \\(r\\)</li> </ol>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#disadvantages","title":"Disadvantages","text":"<ul> <li>multiple solutions can be found for the same project</li> <li>assumes that positive cash flows are reinvested at the IRR, which is considered impractical in practice</li> </ul>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#mirr","title":"MIRR","text":"<p>Modified Internal Rate of Return</p> <p>The modified internal rate of return (MIRR) is a measure of the profitability of a project or other investment.</p> <p>It assumes that positive cash flows are reinvested at the firm's cost of capital and that the initial outlays are financed at the firm's financing cost. The MIRR, therefore, more accurately reflects the cost and profitability of a project</p> <p>$$ \\begin{aligned} \\text{MIRR} &amp;= \\Bigg( \\dfrac{\\text{FV}(\\text{Positive cash flows} \\times \\text{Cost of capital})}{\\text{PV}(\\text{Initial outlays} \\times \\text{Financing cost})} \\Bigg) ^{1/n} - 1 \\ \\textbf{where }</p> <p>\\text{FVCF}\u00a9 &amp;= \\text{the future value of positive cash flows at the cost of capital} \\ \\text{PVCF}(fc) &amp;= \\text{the present value of negative cash flows at the financing cost} \\ n &amp;= \\text{number of periods} \\end{aligned} $$</p>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#profitability-index-secondary","title":"Profitability Index (Secondary)","text":"\\[ \\text{PI} = \\frac{ \\text{PV(Inflows)} }{ \\text{PV(Outflows)} } \\] <p>For every 1 unit of investment</p> \\[ \\begin{aligned} &amp;\\text{Additional value generated after taking minimum returns} \\\\ &amp;= (\\text{PI} - 1) \\times \\text{Original Investment} \\end{aligned} \\] NPV Meaning Decision \\(&gt;1\\) Actual returns &gt; Minimum required return Accept \\(&lt;1\\) Actual returns &lt; Minimum required return Reject \\(1\\) Actual returns = Minimum required return Doesn\u2019t matter"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#payback-period-secondary","title":"Payback Period (Secondary)","text":"<ul> <li>Simplest explanation</li> <li>If you have low DPP, that means the investement is less risky</li> </ul>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#discounted-payback-period-secondary","title":"Discounted Payback Period (Secondary)","text":"\\[ \\text{DPP} = \\]"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#disadvantages_1","title":"Disadvantages","text":"<ul> <li>Subjective payback period</li> <li>Only focusing on short-term gains</li> </ul>"},{"location":"Management/Corporate_Finance/04_Capital_Budgeting_Decisions/#required-rate-of-return","title":"Required Rate of Return","text":"\\[ \\text{RRR} = R_f + \\beta \\cdot \\text{RP} \\] <p>where</p> <ul> <li>\\(R_f=\\) Risk Free Return</li> <li>\\(\\text{RP} =\\)\u00a0Risk Premium</li> </ul>"},{"location":"Management/Corporate_Finance/05_Cost_of_Capital/","title":"Cost of Capital","text":"<p>Depends primarily on the use of funds, not the source, because every investment has a different risk associated with it.</p> <p>Debt is almost always the cheapest source of capital, but has some trouble associated with it. This will be covered in a future topic.</p> <p>It is always calculated as WACC (Weighted average cost of capital)</p> <p>Lower the WACC the better</p> Alias Name Perspective of Required return Investor Appropriate discount rate Firm Compound rate Calculations Opportunity cost of capital idk <ul> <li>Cost of equity</li> <li>Cost of debt/distress</li> </ul>"},{"location":"Management/Corporate_Finance/05_Cost_of_Capital/#uses","title":"Uses","text":"<ol> <li>WACC is used to value the entire firm</li> <li>Evaluate return for projects</li> <li>Evaluate performance of firm</li> </ol>"},{"location":"Management/Corporate_Finance/05_Cost_of_Capital/#some-notes","title":"Some Notes","text":"<ul> <li>Growing companies have high WACC, as they have risks associated with them</li> <li>It is better if WACC decreases over time</li> </ul>"},{"location":"Management/Corporate_Finance/05_Cost_of_Capital/#calculation","title":"Calculation","text":"\\[ \\begin{aligned} \\text{WACC} = \\quad &amp; w_l  \\times k_l (1-\\tau) \\\\ + &amp; w_b  \\times k_b (1-\\tau) \\\\ + &amp; w_p \\times k_p \\\\ + &amp; w_c \\times k_c \\end{aligned} \\] Term Meaning Formula \\(w_d\\) Proportion of debt \\(\\frac{n_d}{n_d + n_p + n_c}\\) \\(w_p\\) Proportion of preference shares \\(\\frac{n_p}{n_d + n_p + n_c}\\) \\(w_c\\) Proportion of common shares \\(\\frac{n_c}{n_d + n_p + n_c}\\) \\(k_l\\) Pre-Tax Cost of Loan (Interest Rate) \\(k_l (1-\\tau)\\) Post-Tax Cost of Loan \\(k_b\\) Pre-Tax Cost of Bond (Yield to Maturity) \\(k_b (1-\\tau)\\) Post-Tax Cost of Bond \\(k_p\\) Cost of preference shares \\(\\frac{D_p}{P_p}\\) \\(k_c\\) Cost of common shares \\(\\tau\\) Tax rate Available <p>Interest is tax-deductable, hence it gives \u2018tax shield\u2019</p>"},{"location":"Management/Corporate_Finance/05_Cost_of_Capital/#capm","title":"CAPM","text":"<p>Capital Asset Pricing Model</p> <p>Describes relation between systematic risk and expected rate of return of risky investments.</p> <p>Expected return on a risk investment depends on</p> <ul> <li>Risk-free rate (return rate of bond)</li> <li>Risk premium, depending on \\(\\beta\\), where \\(\\beta\\) is the sensitivity of the stock wrt the market</li> </ul> \\[ \\begin{aligned} k &amp;= r_\\text{min} \\\\ &amp;= r_f + \\beta \\Big[ R_m - r_f \\Big] \\end{aligned} \\] <p>where</p> <ul> <li>\\(r_\\text{min} =\\) Required return of investment</li> <li>\\(r_f =\\) Risk-Free rate</li> <li>\\(r_m =\\) Stock market return</li> <li>Take only recent data (say, 1 year or so)</li> </ul>"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/","title":"Valuation","text":""},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#debt","title":"Debt","text":"<p>It is the rate of return the firm\u2019s lenders demand when they loan money to the firm. </p>"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#forms-of-borrowing","title":"Forms of Borrowing","text":"Type Private Bank Loan Public Bond/Debenture"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#bond","title":"Bond","text":"<p>Certificate of </p> Term Fixed? Meaning Formula Unit Face/PAR/Book Value \u2705 Listing price of the security \\(\\text{PAR } = \\frac{\\text{Total Amount}}{\\text{No of bonds}}\\) Currency Coupon Rate \u2705 Interest rate % of face value Time to Maturity/Time to Expiry \u2705 Bounding time period by which face value will be repayed(at every payment instant, we only pay the coupon amount) Credit Rating Partially YTM(Yield-to-Maturity) IRR of the bondActual return for the buyer of the bond Bond Traded at Purchase Returns PAR Market Value = Face Value YTM = Coupon rate Premium Market Value &gt; Face Value YTM &lt; Coupon rate Discount Market Value &lt; Face Value YTM &gt; Coupon rate"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#bond-price","title":"Bond Price","text":"\\[ \\text{Bond Price} = \\sum_{t=1}^T \\frac{\\text{Coupon } t}{(1+\\text{YTM})^t} + \\frac{\\text{PAR}}{(1+\\text{YTM})^T} \\] \\[ \\text{Bond Price } \\propto \\frac{1}{\\text{Interest Rate}} \\] <p>This is because, if interest rate increases, lenders will go to loan market, and everyone will sell their bonds.</p>"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#misc","title":"Misc","text":""},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#run-on-the-bank","title":"Run-on-the-bank","text":"<p>Banks should have minimum liquidity, to ensure that</p> <ul> <li>If a private bank falls show on SLR, they can request from government, using Rapport</li> <li>If a govt bank falls show on SLR, they can request from government, using Reverse Rapport</li> </ul>"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#rapport","title":"Rapport","text":"<p>Repurchase agreement</p>"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#reverse-rapport","title":"Reverse Rapport","text":""},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#why-are-govt-bonds-risk-free","title":"Why are Govt Bonds Risk-Free?","text":"<p>Chance of default is lowest.</p>"},{"location":"Management/Corporate_Finance/06_Fixed_Income_Valuation/#preference-shares","title":"Preference Shares","text":"<ul> <li>Hybrid of debt and common shares</li> <li>Fixed dividends</li> <li>Deferrable dividends</li> <li>They don\u2019t have voting rights</li> <li>There is no expiration date</li> <li>It is the only real example of perpetuity</li> <li>Usually higher return than bonds</li> </ul> \\[ k_p = \\frac{d_p}{p_p} \\quad \\left(\\frac{c}{r} \\text{ from Perpetuity} \\right) \\]"},{"location":"Management/Corporate_Finance/07_Equity_Valuation/","title":"Equity Valuation","text":"<p>Common Shares</p> <p>Returns</p> <ul> <li>Dividends</li> <li>Capital Gains</li> </ul> <p>Difficult to estimate pricing, as there are so many variables in play</p> <ol> <li>Unsure cashflows</li> <li>Life of investment is infinite</li> <li>No way to calculate required rate of return</li> </ol> <p>It is frowned upon for a corporation to reduce dividends. Hence, if it increases dividends, it does so very carefully.</p>"},{"location":"Management/Corporate_Finance/07_Equity_Valuation/#book-value-method","title":"Book Value Method","text":"<p>Most appropriate for established companies $$ \\begin{aligned} \\text{Value} &amp;= \\dfrac{\\text{Net Worth}}{\\text{No of Shares}} \\ \\text{Net Worth} &amp;= \\text{Assets} - \\text{Liabilities} \\end{aligned} $$ Assumption: book values are representative of true worth of company</p>"},{"location":"Management/Corporate_Finance/07_Equity_Valuation/#dividend-capitalization-model","title":"Dividend Capitalization Model","text":"<p>Value of equity is the sum of discounted dividends $$ \\begin{aligned} P_t &amp;= \\sum_{t=1}^\\infty \\dfrac{D_t}{(1+k)^t} \\end{aligned} $$</p>"},{"location":"Management/Corporate_Finance/07_Equity_Valuation/#constant-growthgordon-model","title":"Constant Growth/Gordon Model","text":"\\[ \\begin{aligned} D_t &amp;= D_{t-p} \\times (1+g)^p \\\\ \\implies P_t &amp;= \\frac{D_{t+1}}{k_\\text{CS} - g} \\quad \\cancel{+ \\frac{P_\\infty}{(1+r)^\\infty}} \\\\ g &amp;= \\text{ROE} \\times \\text{Retention Rate} \\end{aligned} \\] <p>where</p> <ul> <li>\\(g =\\) dividend growth rate</li> <li>non-zero constant percentage change of dividend from one year to next. If non-constant, we take average \\(g\\) over a few years</li> <li>Retention rate = Plowback rate<ul> <li>\\(= 1-\\text{Payout Rate}\\)</li> </ul> </li> <li>\\(k=\\) market discount rate</li> </ul> Dividend Growth \\(g\\) No \\(0\\) Perpetuity Constant \\(\\ge 0\\)"},{"location":"Management/Corporate_Finance/07_Equity_Valuation/#pvgo","title":"PVGO","text":"<p>Present Value of Growth Opportunities</p> <p>Represents value in an equity from expected growth opportunities</p> \\[ \\begin{alignedat}{1} E[&amp;\\text{PVGO}] &amp;&amp;= E[\\text{Growth}] \\\\ &amp;&amp;&amp;= P_{\\text{Growth}} &amp;- P_{\\text{No Growth}} \\\\ &amp;\\text{PVGO}_\\text{Actual} &amp;&amp;= P_\\text{Actual} &amp;- P_{\\text{No Growth}} \\end{alignedat} \\]"},{"location":"Management/Corporate_Finance/07_Equity_Valuation/#earnings","title":"Earnings","text":"<p>Earnings Multiplier $$ P_t = (\\text{P/E})\\text{Industry} \\times \\text{EPS}\\text{Firm} $$</p> <p>Shouldn\u2019t \\((\\text{P/E})_\\text{Industry}\\) exclude the company we are analyzing?</p>"},{"location":"Management/Corporate_Finance/07_Equity_Valuation/#free-cash-flow-model","title":"Free Cash Flow Model","text":"<p>Principle: Free cash flows will be</p> <ul> <li>Distributed as dividend</li> <li>Reinvested leading to capital appreciation</li> </ul> \\[ \\begin{aligned} P_t = \\ &amp; \\dfrac{\\text{FCFE}}{k} \\\\ \\text{FCFE} = \\ &amp; \\text{Surplus of time period} \\\\ = \\ &amp; \\text{Net Income} + \\text{Non-Cash Exp} \\\\ + \\ &amp; \\text{Investments in Working Capital} \\\\ + \\ &amp;\\text{Net Investment} + \\text{Net Borrowing} \\end{aligned} \\] <p>Use the signs appropriately based on inflow/outflow</p> Net Income Inflow Depreciation and Amortization Inflow Investment in WC Outflow Net Investment Outflow Net Borrowing Outflow"},{"location":"Management/Corporate_Finance/08_Capital_Structure/","title":"08 Capital Structure","text":""},{"location":"Management/Corporate_Finance/08_Capital_Structure/#capital-re-structuring","title":"Capital Re-Structuring","text":"<p>Change in capital structure and leverage</p> <p>If we need to keep assets constant, then inc in debt should be accompanied with purchasing shares</p> <p>We can maximize shareholder wealth by decreasing WACC</p>"},{"location":"Management/Corporate_Finance/08_Capital_Structure/#leverage","title":"Leverage","text":"Operating Leverage Financial Leverage Asset for which firm has to pay a fixed cost Source of funds for which firm has to pay a fixed return Shows ability of firm to Use fixed costs magnify effects of change in sales on its EBIT Relationship between Sales &amp; EBIT Formula \\(\\frac{\\Delta \\% \\text{EBIT}}{\\Delta \\% \\text{Sales}}\\)\\(\\dfrac{\\text{Fixed Cost}}{\\text{Total Cost}}\\) We employ assets with fixed costs in the hope that volume will provide revenues sufficient to cover all fixed &amp; variable costs Interpretation If you believe that you can increase your sales by investing, go for investing in fixed costs Risk Operating risk EBIT &amp; EPS Preferred for Companies with steady expansion Liquidity\u00a0\\(\\propto \\frac{1}{\\text{Operating Leverage}}\\) <p>Fixed cost is a cost that does not change with no of units.</p>"},{"location":"Management/Corporate_Finance/08_Capital_Structure/#operating-risk","title":"Operating Risk","text":""},{"location":"Management/Financial_Forensics/","title":"Financial Forensics","text":""},{"location":"Management/Financial_Forensics/#references","title":"References","text":"<ul> <li> Finacial Forensics | IIT Madras</li> </ul>"},{"location":"Management/HR/","title":"Human Resources","text":""},{"location":"Management/HR/#references","title":"References","text":"<ul> <li> Industrial Organizational Psychology | Louis Montano</li> <li> Principles of Human Resource Management | IIT Kharagpur</li> <li> Human Resource Development | IIT</li> </ul>"},{"location":"Management/Lean/","title":"Lean","text":""},{"location":"Management/Lean/#references","title":"References","text":"<ul> <li>Introduction to Lean Six Sigma Methods | MIT</li> <li>Lean Six Sigma Green Belt | European Students of Industrial Engineering and Management</li> </ul>"},{"location":"Management/Lean/01_Introduction/","title":"Introduction","text":""},{"location":"Management/Lean/01_Introduction/#lean-production-system","title":"Lean Production System","text":"<p>Finishing good inventories through eliminating wastes from processes</p> <p>Continuous improvement - Reduces cost - Reduce time - Increases quality</p> <ul> <li>Jidoka: When there is a problem, stop production and stop producing defective products</li> <li>Just-in-time: Every atomic process produces only what is needed by the next process in a continuous flow</li> </ul>"},{"location":"Management/Lean/01_Introduction/#pre-requisities","title":"Pre-Requisities","text":"<ol> <li>Clear business requirements</li> <li>KPIs for performance management<ol> <li>Productivity</li> <li>Quality</li> <li>Costs</li> <li>Delivery</li> <li>Safety</li> </ol> </li> <li>Operation improvement</li> <li>People engagement<ol> <li>Learn</li> <li>Do</li> <li>Teach</li> </ol> </li> </ol>"},{"location":"Management/Lean/01_Introduction/#types-of-wastes","title":"Types of Wastes","text":"<ul> <li>Transportation</li> <li>Inactivity</li> <li>Motion</li> <li>Storage</li> <li>Over-processing: doing more than what is required</li> <li>Defects</li> <li>Over-production: producing more that what is required</li> </ul>"},{"location":"Management/Lean/01_Introduction/#value-streams","title":"Value Streams","text":"<p>All actions required for a product from order to delivery</p> <p>Works - Value-adding - Incidental - Pure waste</p>"},{"location":"Management/MBFM/","title":"Money, Banking &amp; Financial Markets","text":""},{"location":"Management/MBFM/#recommended-reading","title":"Recommended Reading","text":"<ul> <li> Trading and Exchanges: Market Microstructure for Practitioners</li> </ul>"},{"location":"Management/MBFM/#references","title":"References","text":"<ul> <li> Money, Banking &amp; Financial Markets | Dr. Asgar Ali | BITS Pilani Dubai Campus</li> <li> Introducting to Banking | University Leibzig </li> <li> Financial Markets | Yale</li> <li> Financial Theory | Yale</li> </ul>"},{"location":"Management/MBFM/01_Introduction/","title":"Introduction","text":""},{"location":"Management/MBFM/01_Introduction/#financial-system","title":"Financial System","text":""},{"location":"Management/MBFM/01_Introduction/#trade-types","title":"Trade Types","text":"Goal Related variables Hedging Already have exposureNot proactively adding risk to what you have Currency exchange rateInterest rate Market Making Earn from bid offer Proprietary Trading/Portfolio Management Maximize returns Directional: Long/ShortArbitrage: Find relationship between prices &amp; profit from mispricingValue/Relative ValueSystematic modellingFundamental analysis"},{"location":"Management/MBFM/01_Introduction/#parties-of-financial-markets","title":"Parties of Financial Markets","text":"Parties Individual/Retail Investors Dealers Trade with 1 one interested party when there is no market Take principal risks Brokers Intermediary between 2 trade parties Don\u2019t take principal risks Mutual Funds Manage public-investors\u2019 money in a long-only format Insurance Companies Pension Funds Asset Managers Sovereign Wealth Funds Hedge Funds Find opportunities from inefficient market positioning/pricing Private Equity Invest in companies Governments Policy MakersIntervene in certain cases Corporate Hedgers Liability Managers"},{"location":"Management/MBFM/01_Introduction/#financing-types","title":"Financing Types","text":"Advantages Disadvantages Direct - Information asymmetry- Risk Indirect - Information asymmetry alleviation- Risk alleviation"},{"location":"Management/MBFM/02_Financial_Markets/","title":"Financial Markets","text":"<p>Mechanism that facilitates trade of financial securities between - savers/investors/lenders (have money, need return)   and - borrowers (need money, have risks)</p> <p>Zero-sum game</p>"},{"location":"Management/MBFM/02_Financial_Markets/#functions","title":"Functions","text":"<ul> <li> <p>Provide liquidity (key function)</p> </li> <li> <p>Avoids need for coincidence of wants</p> </li> <li> <p>Price discovery</p> </li> <li> <p>Reduce total costs due to benefits of scale</p> </li> <li> <p>Base for capital formation</p> </li> <li> <p>Economic stability</p> </li> <li> <p>Innovation</p> </li> <li> <p>Helps in continuous flow of money</p> </li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#type","title":"Type","text":""},{"location":"Management/MBFM/02_Financial_Markets/#idk","title":"Idk","text":"Bond Market Stock Market Derivative Market Forex Market"},{"location":"Management/MBFM/02_Financial_Markets/#idk_1","title":"Idk","text":"Money Market Capital Market Maturity Duration Short-term(&lt; 1 yr) Long-term(&gt;= 1 yr) Volume High Low/High Regulator Central Bank Capital Market Regulator/SEC(except for Govt Bonds)Central bank (for cross-border transactions) Cost of capital Cheaper(lower risk) Expensive Participants Central bankLarge corporations Commercial BanksRetail investors/borrowers Purpose Borrowers: Working capitalLenders: Investing temporary overage Borrowers: ExpenditureLenders: Long-term investments Comment Interest-bearing instruments are usually zero-coupon bonds Comment Money doesn\u2019t actually flow, it\u2019s just recorded on financial statements <p>Why are bonds preferred over equity</p> <ul> <li>Retaining ownership &amp; control</li> <li>Equity may cause noise in valuation, due to large number of players</li> <li>Tax deductibility</li> </ul> <p>Call money</p>"},{"location":"Management/MBFM/02_Financial_Markets/#money-market-instruments","title":"Money Market Instruments","text":"Instrument Participant Comment Call &amp; Notice Commercial banks Central bank audits every 2 weeks to check for reserves, so commercial banks take short-term loans to maintain liquidity for the inspection Treasury Bill Central govtExercised by Central bank Short-term bondHelps maintain short-term liquidity Commercial bills 2 businesses Unpaid invoice that can be traded Commercial Paper 2 businesses Promissory note Money-Market Mutual Funds Public Synthetically-createdPool funds to take different positions in money market Repo/Reverse-Repo Central bankCommercial bank Short-term loanRe-purchase agreement"},{"location":"Management/MBFM/02_Financial_Markets/#idk_2","title":"IDK","text":""},{"location":"Management/MBFM/02_Financial_Markets/#sources-of-corporate-debt","title":"Sources of Corporate Debt","text":"<ul> <li>Sorted in order of least risky to more risky</li> <li>Also, Sorted in order of least return to highest return</li> </ul> Source Duration Market Treasury Bill(T-Bill) Short term Money Govt Bond Long term Corporate Bond (Zero Coupon)(More traded) Long-term Corporate Bond (Coupon) Long-term Commercial Paper Short-term CD (Certificate of Deposit) Rapport"},{"location":"Management/MBFM/02_Financial_Markets/#idk_3","title":"IDK","text":"Primary Market Secondary Market(Stock change) Investors trade with Company directly Each other"},{"location":"Management/MBFM/02_Financial_Markets/#primary-market","title":"Primary Market","text":"<ul> <li>Initial Public Offering</li> <li>Follow-up public offering</li> </ul> Instrument Participants Requirements Advantages Limitations Public Issue General public High transparencyProspectus (detailed document of company)Under-writer No filteringHigh costsLarge number of people to convincePotential under-subscription Private placement Selected subset of new investors Overcomes limitations of public issue Right issue Existing shareholders preferredThen only general public Prefer dedicated investors Bonus issue Existing shareholders Give instead of dividends Maintain share priceBroadening of shares through distributing bonus shares makes it harder for Hostile Takeover Base Rate Central bankCommercial Bank"},{"location":"Management/MBFM/02_Financial_Markets/#secondary-market-instruments","title":"Secondary Market Instruments","text":"<p>Exchanges may be order-driven and quote-driven</p> Order-Driven Quote-Driven Direct Indirect Party Buyer &amp; Seller Buyer-Dealer-Seller Settlement credited \\(t+1\\) basis Advantages Example NSE NASDAQ"},{"location":"Management/MBFM/02_Financial_Markets/#indian-stock-exchanges","title":"Indian Stock Exchanges","text":"<ul> <li>Volume of trades: 92.7%, 7.3% BSE</li> <li>Volume of trades market: 97.2% NSE, 1.8% BSE</li> </ul> <pre><code>---\ntitle: Stocks Trade Volume Share in India\n---\npie\n\"NSE\": 92.7\n\"BSE\":  7.3\n\"Others\": 0</code></pre> <pre><code>---\ntitle: Derivatives Trade Volume Share in India\n---\npie\n\"NSE\":      97.2\n\"BSE\":       1.8\n\"Others\":  1.0</code></pre>"},{"location":"Management/MBFM/02_Financial_Markets/#international","title":"International","text":"Value of Stocks(not volume)(Trillions) NYSE 26.64 NASDAQ 23.46 Shanghai 7.63 Euronext 7.33 Japan 6.79 Hong Kong 6.13 Shenzhen 5.74 London 4.05 BSE 3.96 NSE 3.77"},{"location":"Management/MBFM/02_Financial_Markets/#us-stock-market","title":"US Stock Market","text":"<ul> <li>Stock Exchanges</li> <li>New York Stock Exchange (Blue Chip Industrial Companies, 2800, hybrid-both broker and dealer market)</li> <li>Nasdaq (Technology-driven Companies, 3300, totally electronic, dealer market)</li> <li>Stock Indices</li> <li>Dow Jones Industrial Average (DJIA, Top 30 Comp from NYSE and Nasdaq, Price Weighted)</li> <li>S&amp;P 500 (Top 500 Comp headquartered in the US, Market Weighted)</li> <li>Nasdaq Composite (Top 2500 Comp of Nasdaq, be it headquartered in the US or Outside, Market Weighted)</li> <li>Russell 2000 (Small Cap Companies)</li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#advantages-of-us-market","title":"Advantages of US Market","text":"<ul> <li>Fractional investment: Mutual funds are basically from this idea</li> <li>Selection effect: The fact that these companies are on the US stock market means they have already been successful on their local domestic market</li> <li>Geographical diversification</li> <li>US and US-listed companies tend to have global operations</li> <li>US market has outperformed other markets</li> <li>Exposure to high tech companies</li> <li>Avoid currency depreciation wrt the global principal reserve currency (which is currently US Dollars)</li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#disadvantages-of-us-market","title":"Disadvantages of US Market","text":"<ul> <li>Set</li> <li>High charges</li> <li>Bank\u2019s fixed remittance charges     (1500 - 2000)</li> <li>GST</li> <li>Exchange Rates</li> <li>High brokerage and maintenance charges</li> <li>Tax Issues (DTAA)</li> <li>STCG within 24 months: 30%</li> <li>LTCG after 24 months: 20%.</li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#uae-stock-market","title":"UAE Stock Market","text":"<ul> <li>Abu Dhabi Securities Exchange (ADX) (2000)</li> <li>ADX General Index is a capitalization-weighted index which represents the performance of all the listed companies (92 securities) on the exchange (A base value of 1000 as of June 2001)</li> <li>Regulated by the Securities and Commodities Authority (SCA)</li> <li>Dubai Financial Market (DFM) (2000)</li> <li>Dubai Financial Market General Index (DFMGI) (119 securities)</li> <li>Modified capitalization-weighted index (maximum capitalization cap of 20%)</li> <li>NASDAQ Dubai (2005)</li> <li>Middle East's international financial exchange (70 securities)</li> <li>Dubai Financial Market holds two-thirds and Borse Dubai holds one-third of the shares in NASDAQ Dubai</li> <li>Regulated by Dubai Financial Services Authority (DFSA)</li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#sukuk","title":"Sukuk","text":"<p>\"sharia compliant\" bonds</p> <p>Sukuk is an Islamic instrument that provides the same commercial equivalent to a conventional bond, the difference being that it is structured in a sharia compliant manner and represents proportionate undivided ownership in the underlying asset or investment.</p> <p></p> <pre><code>sequenceDiagram\n\nparticipant i as Investor&lt;br/&gt;(Lender)\nparticipant s as SPV&lt;br/&gt;(Special Purpose Vehicle)\nparticipant b as Originator&lt;br/&gt;(Borrower)\n\ni -&gt;&gt; s: Investment\ns -&gt;&gt; b: Loan&lt;br/&gt;(Investment Proceeds)\nb -&gt;&gt; s: Sale of Asset(s)\nb -&gt;&gt; s: Lease &amp; Principal Payments\ns -&gt;&gt; i: Returns&lt;br/&gt;(Lease &amp; Principal Payments proceeds)\ns -&gt;&gt; b: Repurchase of assets</code></pre>"},{"location":"Management/MBFM/02_Financial_Markets/#trading-platforms","title":"Trading Platforms","text":"<ul> <li>IND</li> <li>Money</li> <li>Vested</li> <li>Groww</li> <li>Stockal</li> <li>Winvesta</li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#capital-market-participants","title":"Capital Market Participants","text":"Meaning Ownership in India Daily Trading Volume in India Daily Trading Volume in Developed Countries Retail Investors Individuals 18% 42-45% 18-20% Mutual Funds Institutional Investors Professional institutions whose career are investing (such as Investment Banks)Corporates that invest (Shark Tank) FIIs(Foreign Institution Investor) Hedge Funds"},{"location":"Management/MBFM/02_Financial_Markets/#retail-investment-in-developed-nations-in-india-but-trade-volume-is-lower","title":"Retail investment in Developed nations &gt; in India, but trade volume is lower","text":"<p>Indian stocks have lower return than risk-free returns, so Indian retail investors actually incur losses. India is still a developing country, and hence stock investing is being popular.</p> <p>In developed nations, they prefer investing indirectly through mutual funds.</p>"},{"location":"Management/MBFM/02_Financial_Markets/#participant-objectives","title":"Participant Objectives","text":"Run Duration Focus Look for Investors Long Business ValueCapital appreciation Under-Valued stocks Speculators Short Volatility Arbitrageurs Mis-pricing <p>Arbitrage is the \u2018invisible hand of market\u2019 that corrects the </p>"},{"location":"Management/MBFM/02_Financial_Markets/#bond-market","title":"Bond Market","text":"G-Secs Market Maturity: 1-30yrs PSU MarketPublic Sector Undertakings State Govt/Municipal Bonds Corporate Debentures/Bonds <p>Terms of the bond are called as \u2018bond indenture\u2019</p> <p>Thinking point: The share of corporate bonds in India in bond market is very low compared to other countries.</p>"},{"location":"Management/MBFM/02_Financial_Markets/#indian-stock-markets","title":"Indian Stock Markets","text":"Index BSE(Bombay Stock Exchange) Sensex NSE(National Stock Exchange) Nifty <p>LPG: Liberalization, Privatization, Globalized</p>"},{"location":"Management/MBFM/02_Financial_Markets/#ponzi-schemes","title":"Ponzi Schemes","text":"<p>Financial schemes </p>"},{"location":"Management/MBFM/02_Financial_Markets/#why-are-us-markets-institutions-the-best","title":"Why are US markets &amp; institutions the best","text":"<ul> <li>Entrepreneurial ambitions; no societal discouraging like in India</li> <li>Supportive financial system, such as supportive IBC</li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#ibc","title":"IBC","text":"<p>IBC: Insolvency &amp; Bankruptcy Code</p> <p>Defines the liberty for corporates</p> <p>If a company is insolvent and you are not able to repay loans, within a period of 90 days, the lenders can request for the company\u2019s liquidation.</p>"},{"location":"Management/MBFM/02_Financial_Markets/#stock-market-indices","title":"Stock Market Indices","text":"Types Preferred for Limitations Market Value-Weighted Company Performance Price-Weighted Price Performance Can be manipulated by changing number of stocks"},{"location":"Management/MBFM/02_Financial_Markets/#indian","title":"Indian","text":"Number Characteristic BSE Sensex 30 Largest and most-actively traded stocks NSE Nifty 50 Largest and most liquid <p>Both are Market Value-Weighted</p>"},{"location":"Management/MBFM/02_Financial_Markets/#trading-schedules","title":"Trading Schedules","text":"09:00-09:08 Request Bulk Trades 09:08-09:12 Clear Bulk Trades 09:12-09:15 Buffer 09:15-15:30 Trading Session"},{"location":"Management/MBFM/02_Financial_Markets/#transaction-process","title":"Transaction Process","text":"<ul> <li>Trading</li> <li>Post Trading Activities: Clearing &amp; Settlement</li> </ul> <p>Agencies</p> NSCCLNational Securities Clearing Corporation Ltd NSE ICCLIndian Clearing Corporation Ltd BSE"},{"location":"Management/MBFM/02_Financial_Markets/#orders","title":"Orders","text":"Bids Buy Offers Sell"},{"location":"Management/MBFM/02_Financial_Markets/#order-types","title":"Order Types","text":"Limit Orders Specifies price- Sell Limit Order- Buy Limit Order Market Orders Does not specify price Stop Orders - Sell\u2013stop order- Buy\u2013stop order"},{"location":"Management/MBFM/02_Financial_Markets/#depository","title":"Depository","text":"<ul> <li>Demat Account</li> <li>Depository Services</li> <li>NSDL: National Securities     Depository Ltd</li> <li>CDSL: Central Depository Services     (India) Ltd</li> </ul>"},{"location":"Management/MBFM/02_Financial_Markets/#bear-vs-bull","title":"Bear vs Bull","text":"Bull Bear Stock prices are rising falling Market Momentum Effect Stronger Weaker <p>The origin of these expressions is unclear, but one reason could be that bulls attack by bringing their horns upward, while bears attack by swiping their paws downward</p>"},{"location":"Management/MBFM/02_Financial_Markets/#broker-vs-dealer-market","title":"Broker vs Dealer Market","text":"Dealer(Over-the-counter) Broker Exchanges Counterparty for both buyers and sellers Finds a counterparty to both buyers and sellers Most automated Dealer sets bid and asks prices for the security in question, and will trade with any investor willing to accept those prices The advantage of the exchange is the provision of a central location for buyers and sellers to find their own counterparties Intermediary Ownership \u2705 \u274c Intermediary Risk \u2705 \u274c Barriers to entry High Low dealer provides liquidity in the market at the cost of a small premium often set bid prices lower than the market and ask prices higher"},{"location":"Management/MBFM/02_Financial_Markets/#idk_4","title":"IDK","text":"Example Adverse Selection Sub-optimal selection of borrower by lenders, which may lead to default Moral Hazard Incurred Satyam IT Debt collections?"},{"location":"Management/MBFM/02_Financial_Markets/#financial-year","title":"Financial Year","text":"<p>Why does financial year in India start in April: This is to follow the agricultural cycles</p>"},{"location":"Management/MBFM/03_Financial_Institutions/","title":"Financial Institutions","text":"<p>Non-individuals/organizations that</p> <ul> <li>Intermediary</li> <li>acts as mobilizers</li> <li>depositors of savings</li> <li> <p>dealers of credit/finance</p> </li> <li> <p>Non-Intermediary</p> </li> <li>Monitor</li> <li>Coordinate</li> <li>Protect rights</li> <li>Intervene (if required)</li> </ul>"},{"location":"Management/MBFM/03_Financial_Institutions/#types","title":"Types","text":"Type Regulated by Primary Function Secondary Function India US Intermediary Banking Financial institution licensed to accept deposits &amp; provide loans Central Bank Accept depositsLending loans Agency functionGeneral utility services Non-Banking Cannot accept \u2018loans\u2019 Forgot Non-Intermediary Banking Regulators RBI Insurance Regulators IRTA Securities Regulators SAVEE?SEBI SEC(Security Exchange Committee) <p>Universal bank that is involved in banking &amp; non-banking activities</p>"},{"location":"Management/MBFM/03_Financial_Institutions/#types-of-banks","title":"Types of Banks","text":"Type Owners Goal Size Commercial Private Profit Large Cooperative Community(Owners = Customers) Non-Profit Small Regional Rural Government (Finance Ministry) Non-ProfitProvide financing in communities where not available Small Investment Fixed IncomeEquityIBDCorporate FinanceAsset ManagementWealth Management"},{"location":"Management/MBFM/03_Financial_Institutions/#non-banking-institutions","title":"Non-Banking Institutions","text":"Purpose Non-Banking Financial Companies Bajaj Finance LtdMahindra Finance ServicesMuthoot FinanceCholamandalam Development Financial Institutions IFCI: Industrial Finance Corporation of IndiaICICI: Industrial Credit and Investment Corporation of IndiaIDBIIRCISIDBIHDFC Insurance Companies Protection against contingent/uncertain loss LICICICI Prudential Life Insurance CompanyGeneral Insurance CompanyThe New India Assurance Company Mutual Funds Pool funds of any amount invested by Asset Management Company with Custodians to inspect UTISBI Mutual FundAxis Bank Mutual Fund Index Funds Pooled investments that passively aim to replicate the returns of market indexes <p>Number of issues shares controls who can invest</p> <ul> <li>Stability: Decrease number of shares to increase share price, and exclude retail investors</li> <li>High Returns: Increase number of shares to decrease share price, and include retail investors</li> </ul>"},{"location":"Management/MBFM/04_Financial_Services/","title":"Financial Service","text":"<p>The process of holding shares in electronically is Dematerialisation</p>"},{"location":"Management/MBFM/04_Financial_Services/#factoring","title":"Factoring","text":"<p>Service for a business redeem its accounts receivable from a 3<sup>rd</sup> party at a discount, to improve current liquidity</p> <pre><code>flowchart LR\nCompany --&gt;\n|Sale of&lt;br/&gt;goods| Debtor --&gt;\n|Payment&lt;br/&gt;after expiry of credit period| Factor --&gt;\n|Payment&lt;br/&gt;at discount| Company\nCompany --&gt; |Receivables&lt;br/&gt;Transfer| Factor</code></pre>"},{"location":"Management/MBFM/04_Financial_Services/#types","title":"Types","text":"Risk Bearer Full-Recourse Factoring Company Non-Recourse Factoring Factor"},{"location":"Management/MBFM/04_Financial_Services/#foreign-exchange-services","title":"Foreign Exchange Services","text":"<ul> <li>Currency exchange</li> <li>Wire transfer</li> <li>Remittance</li> </ul>"},{"location":"Management/MBFM/05_Interest_Rate/","title":"Interest Rate","text":"Entity Interpretation of Interest Rat Lender Income from fixed-income securities Borrower Cost of borrowing Economist Base/Repo rate at which central banks lend to commercial banks Misc Discount Rate/Compounding Rate/Hurdle Rate <pre><code>flowchart LR\nCredit --&gt; Borrowing --&gt; Production --&gt; Employment --&gt; Income --&gt; pp[Purchasing Power] --&gt; Demand\nBorrowing --&gt; pp\n\nProduction -----&gt; Supply\n\nDemand &amp; Supply --&gt; Credit</code></pre>"},{"location":"Management/MBFM/05_Interest_Rate/#factors-that-affect-interest-rate","title":"Factors that affect interest Rate","text":"<ul> <li>Inflation</li> <li>Time</li> <li>Risk</li> </ul>"},{"location":"Management/MBFM/05_Interest_Rate/#interest-based-instruments","title":"Interest-Based Instruments","text":"<ul> <li>Simple loan</li> <li>Fully amortized loan: Fixed payment loan</li> <li>Coupon bond</li> <li>Discount bond: Zero-Coupon Bond</li> </ul>"},{"location":"Management/MBFM/05_Interest_Rate/#ytm","title":"YTM","text":"<p>Yield Till Maturity</p> <ul> <li>Coupon</li> <li>Capital Gains</li> <li>Reinvestment income</li> </ul> <p>Opportunity of </p>"},{"location":"Management/MBFM/05_Interest_Rate/#tvm","title":"TVM","text":"<p>Time Value of Money</p>"},{"location":"Management/MBFM/05_Interest_Rate/#determinants","title":"Determinants","text":"<p>Supply and change in bond market</p>"},{"location":"Management/MBFM/05_Interest_Rate/#change-in-equilibrium","title":"Change in equilibrium","text":"<ul> <li>Change in Price of bond: Movements along a demand/supply curve</li> <li>Change due to other factors: Shifts in a demand/supply curve</li> </ul>"},{"location":"Management/MBFM/05_Interest_Rate/#shift-in-demand","title":"Shift in Demand","text":"Increase in Shift in Demand Curve Bond Price Interest Rate Wealth/Purchasing Power Right Inc Dec Expected returns on bonds relative to alternative assets Right Inc Dec Risk of bonds relative to alternative assets Left Dec Inc Liquidity of bonds relative to alternative assets Right Inc Dec Expected Inflation Left Dec Inc"},{"location":"Management/MBFM/05_Interest_Rate/#shift-in-supply","title":"Shift in Supply","text":"Increase in Shift in Supply Curve Bond Price Interest Rate Wealth Left Inc Dec Profitability of project for which funds required Right(Higher cost of capital is tolerated) Dec Inc Expected Inflation Right Dec Inc Govt Budget"},{"location":"Management/MBFM/05_Interest_Rate/#fisher-effect","title":"Fisher Effect","text":"\\[ r = i - \\pi_e \\] <ul> <li>\\(r =\\) Real Interest Rate</li> <li>\\(i=\\) Nominal interest rate</li> <li>\\(\\pi_e =\\) Expected inflation rate</li> </ul>"},{"location":"Management/MBFM/05_Interest_Rate/#structure-of-interest","title":"Structure of Interest","text":"Interest rate of Risk Structure Different bonds at same time point Term Structure Same bond over time"},{"location":"Management/MBFM/05_Interest_Rate/#risk-structure","title":"Risk Structure","text":"Risk Type Shift in Demand Curve Bond Price Interest Rate of Bond Default Risk Bond Rating Left Dec Inc Liquidity Right Inc Dec Income tax exemption Right Inc Dec <p>High spread means </p> <p>Increase in interest rate of bond1 causes a decrease in another bond, due to its change in demand curve</p>"},{"location":"Management/MBFM/06_Yield/","title":"Yield Curve","text":"<p>Curve that shows the interest rate at different time horizons of holding a fixed-income security</p>"},{"location":"Management/MBFM/06_Yield/#purpose","title":"Purpose","text":"<ul> <li>Indicator of future yield levels, and help in setting the yield for all debt market instruments</li> <li>Measure and compare returns across maturity spectrum</li> <li>One more point</li> </ul>"},{"location":"Management/MBFM/06_Yield/#types","title":"Types","text":"Causes Upward Sloping Flat Humped Downward Sloping/Inverted Present Future interest rate &lt; Present Short-term interest ratePresent Future interest rate &lt; Future Short-term interest rate <ul> <li>Spot rate is the instantaneous rate</li> <li>Forward rate is the contract on a future rate</li> <li>Future rate is the spot rate in the future</li> </ul>"},{"location":"Management/MBFM/06_Yield/#theories-behind-yield-curves","title":"Theories behind Yield Curves","text":""},{"location":"Management/MBFM/06_Yield/#expectations-theory","title":"Expectations Theory","text":"<p>(photo in gallery)</p> <p>Risk Neutrality</p> <p>Consequence: Shape of yield curve will depend on the expected returns</p> Theory Assumption Advantages Limitation Expectations Investors are risk-neutral Incorrect to assume that bonds with different maturities do not have different expected return Bond-investors are risk-averse, not risk-neutral Liquidity-Premium Investors are risk-averseBonds are partial substitutes for each Investors demand risk premium for- Maturity Risk Premium Premium- Liquidity Premium Does not explain downward sloping/inverted curves Market Segmentation <p>Maturity Risk Premium: With maturity, risk increases</p> <p>Liquidity premium: </p>"},{"location":"Management/MBFM/07_Market_Efficiency/","title":"Efficient Market Hypothesis","text":"<ul> <li>Market corrects itself when new info becomes   available, through quick analysis and   necessary price adjustments</li> <li>Prices fully reflect all   available information</li> </ul>"},{"location":"Management/MBFM/07_Market_Efficiency/#market-efficiency","title":"Market Efficiency","text":"<p>Represents only information-processing efficiency</p> <p>No mis-pricings</p> <ul> <li>Good for investors</li> <li>Bad for speculators (Only mispricings will provide large gains. Just value investing provides nominal returns)</li> </ul>"},{"location":"Management/MBFM/07_Market_Efficiency/#reactions","title":"Reactions","text":"Type Under-reaction Delayed Efficient Over-reaction"},{"location":"Management/MBFM/07_Market_Efficiency/#forms-of-efficiency","title":"Forms of Efficiency","text":"<p>According to Fama, markets are neither purely inefficient nor purely efficient</p> Inefficient Weak Moderate Strong Market reflects __ info None historical historicalpublic historicalpublicprivate Action Type None Overreaction Pre-action Time Before/at the time of announcement Prices Characteristic Random Walk Implication No relation between past prices and future pricesNo trading rule that depends on past can predict futurePast prices do no provide any info to outperform the market Incorporates WFHIf an Technical Analysis Applicable? \u2705 \u274c \u274c \u274c Fundamental Analysis Applicable? \u2705 \u2705 \u274c Serial Correlation \u274c Momentum \u2705 Studies - Serial Correlation- Momentum/overreaction hypothesis - Dividend declaration- Stock splits- Earnings announcement- Announcement of half-yearly results- Acquisitions &amp; mergers- Announcements related to taxes - Studies of corporate insiders- Specialists in stock exchanges"},{"location":"Management/MBFM/07_Market_Efficiency/#causes-of-efficiency","title":"Causes of Efficiency","text":"<ul> <li>Sufficiently-large no of knowledgeable investors, who diffuse info</li> <li>Intense competition among investors</li> <li>Rapid transmission of information</li> <li>High speed of transactions</li> <li>Low cost of transactions</li> </ul>"},{"location":"Management/MBFM/07_Market_Efficiency/#causes-of-inefficiency","title":"Causes of Inefficiency","text":"<p>Probability of mispricings in asset market \\(\\propto\\)</p> <ul> <li>\\(\\dfrac{1}{\\text{Ease of trading}}\\)</li> <li>cost of information and transactions for exploiting inefficiency</li> </ul>"},{"location":"Management/MBFM/07_Market_Efficiency/#anomalies","title":"Anomalies","text":"<p>That prove that no market is purely efficient</p> Effect Size Small stocks tend to give higher returns January Stock prices are higher in January Small P/E Book Value to Market Value Ratio Reversal Market Momentum"},{"location":"Management/MBFM/08_Financial_Crises/","title":"Financial Crises","text":""},{"location":"Management/MBFM/08_Financial_Crises/#stage-1-buildup","title":"Stage 1: Buildup","text":""},{"location":"Management/MBFM/08_Financial_Crises/#credit-boom-bust","title":"Credit boom &amp; bust","text":"<ol> <li>Boom</li> <li>Financial liberalization: Reduced restrictions</li> <li>Financial innovation: New financial product</li> <li>Bust</li> <li>Lenders may lack expertise and/or incentives to manage risk appropriately</li> </ol>"},{"location":"Management/MBFM/08_Financial_Crises/#asset-price-boom-post","title":"Asset-price boom &amp; post","text":"<p>Herding</p>"},{"location":"Management/MBFM/08_Financial_Crises/#increased-uncertainty","title":"Increased uncertainty","text":"<ul> <li>Hard to obtain information</li> <li>Reduced lending</li> <li>Reduced economic activity</li> </ul>"},{"location":"Management/MBFM/08_Financial_Crises/#stage-2-banking-crisis","title":"Stage 2: Banking Crisis","text":""},{"location":"Management/MBFM/08_Financial_Crises/#stage-3-debt-deflation","title":"Stage 3: Debt Deflation","text":"<p>Underwater mortgage problem</p> <p>Deflationary spiral: Deflation increase defaults, and that causes more deflation</p>"},{"location":"Management/MBFM/08_Financial_Crises/#case-studies","title":"Case Studies","text":""},{"location":"Management/MBFM/08_Financial_Crises/#great-depression","title":"Great Depression","text":""},{"location":"Management/MBFM/08_Financial_Crises/#asian-tigers","title":"Asian Tigers","text":""},{"location":"Management/MBFM/08_Financial_Crises/#dot-com-bubble","title":"Dot-Com Bubble","text":"<p>Tech bubble/Internet bubble</p>"},{"location":"Management/MBFM/08_Financial_Crises/#2008-financial-bubble","title":"2008 Financial Bubble","text":"<ul> <li>Housing prices</li> <li>Stock prices</li> </ul> <p>Causes</p> <ul> <li>Failure for default prediction algorithms</li> <li>Used FICO (Fair Isaac Corporation) Score</li> <li>The models were trained on dataset where housing prices always increased</li> <li>Financial innovations</li> <li>Securitization: Process of building small loans (like mortgages) into standard debt securities</li> <li>CDO: Collateralized Debt Obligations</li> <li>CDS: Credit Default Swap</li> <li>Agency problems in mortgage markets</li> <li>Asymmetric information</li> <li>Credit-Rating Services</li> </ul>"},{"location":"Management/MBFM/08_Financial_Crises/#ai-bubble-coming-in-2030s","title":"AI Bubble coming in 2030s?","text":""},{"location":"Management/MBFM/09_Central_Bank/","title":"Central Bank","text":""},{"location":"Management/MBFM/09_Central_Bank/#monetary-policy","title":"Monetary Policy","text":"<p>What is the difference between SLR and CRR?  - Cash Reserve Ratio (CRR) is the percentage of money, which a bank has to keep with RBI in the form of cash. - Statutory Liquidity Ratio (SLR) is the proportion of liquid assets to time and demand liabilities.</p> <p>Central bank checks fortnightly</p> <p>Usually commercial banks have</p> <ul> <li>Short-term sources</li> <li>Long-term lending</li> </ul> <p>Balance of payment</p>"},{"location":"Management/MBFM/09_Central_Bank/#unsterilized-intervention","title":"Unsterilized Intervention","text":"<p>Intervention without worrying about side-effects</p> <p>Domestic currency is bought and foreign assets </p> <p>Outflow of foreign assets</p>"},{"location":"Management/MBFM/09_Central_Bank/#stock-market","title":"Stock Market","text":"<p>The main driver of stock market is monetary policy. This is primarily due to the resulting changes in the risk-free rate and hence, the opportunity cost.</p> <p>Hence when the employment index increases, the stock market goes down, anticipating a monetary policy</p>"},{"location":"Management/MBFM/10_Bond_Market/","title":"Bond Market","text":"<ul> <li>Government-dated securities</li> <li>Public sector bonds</li> <li>Corporate bonds</li> </ul>"},{"location":"Management/MBFM/10_Bond_Market/#govt-securities-market","title":"Govt Securities Market","text":"<p>Acts as benchmark for rest of market</p>"},{"location":"Management/MBFM/11_UAE/","title":"UAE Financial Markets","text":"<ul> <li>Comparatively new</li> <li>Doesn\u2019t have that \u2018depth\u2019?</li> <li>What does that mean?</li> </ul> <p>Money market is very small in UAE</p> <p>The Royal family of Abu Dhabi- Al Nahyan family\u2014 is known as the richest family in the world</p> <ul> <li>Central Bank: CBUAE</li> <li>SCA: Securities &amp; Commodities Authority</li> </ul>"},{"location":"Management/MBFM/11_UAE/#uae-stock-markets","title":"UAE Stock Markets","text":"<ul> <li>DFM: Dubai Financial Market</li> <li>ADX: Abu Dhabi Security Exchange</li> <li>NASDAQ Dubai </li> </ul> <p>Trading Time</p> <ul> <li>Monday-Friday</li> <li>9:30-3:00</li> </ul> DFM ADX NASDAQ Dubai Founded 2000-Mar-26 2000-Nov-15 2005-Sep-05 Market Cap AED 582 B AED 2.85 T Owned Govt of Dubai till 2006 Govt of Abu Dhabi 20% shares sold to public EquitiesSukukBondsFundsETFsREIT EquitiesDebt InstrumentsDerivativesETFs Settlement T+2 T+2"},{"location":"Management/MBFM/11_UAE/#market-indices","title":"Market Indices","text":"<p>DFMGI</p> <p>Dubai Financial Market General Index (30 DFM-listed equities)</p> <p>Secondary listed companies have a free float adjusted market cap &gt; AED 5 B</p> DFMGI ADX General Weightage Modified capitalization-weighted index (maximum cap of 20%) Capitalization-weighted Base Date 2003-12-31 Base Currency AED 1000 AED 1000 New listing are added"},{"location":"Management/MBFM/11_UAE/#how-to-invest-in-uae-markets","title":"How to invest in UAE Markets","text":"<ol> <li>Open trading account with licensed broker</li> <li>Apply for National Investor Number with SCA</li> <li>Perform trading</li> </ol>"},{"location":"Management/MBFM/11_UAE/#idk","title":"IDK","text":"<ul> <li>Full-service</li> <li>Discount-service</li> </ul>"},{"location":"Management/MBFM/11_UAE/#idk_1","title":"IDK","text":"<ul> <li>Onboarding fees</li> <li>Commissions: Borker chanrges + Market charges + VAT</li> </ul>"},{"location":"Management/MBFM/11_UAE/#tabadul","title":"Tabadul","text":"<p>Mutual market access model</p> <p>Enables trading between member exchanges</p> <ul> <li>Abu Dhabi</li> <li>Bahrain</li> <li>Muscat</li> </ul> <p>Traded in local currency of the exchange</p> <p>Service providers</p>"},{"location":"Management/MBFM/11_UAE/#-","title":"-","text":""},{"location":"Management/Management/","title":"Management","text":""},{"location":"Management/Management/#references","title":"References","text":"<ul> <li> Creating Video Games | MIT</li> <li> IIT Roorkee July 2018 | Project Management</li> <li> Agile Crash Course: Intro to Agile for Developers</li> <li> Onboarding your next engineer</li> <li> Software Engineer Onboarding Like A Pro</li> <li> How to Manage Data Science Projects</li> <li> Why Agile is Bad | Thriving Technologist</li> <li> Sports Management | IIT</li> <li> Sports Management | Ronnie Murrell</li> <li> Project Management | IIT</li> <li> Project Risk Management | Mike Clayton</li> <li> Knowledge Management | IIT</li> </ul>"},{"location":"Management/Management/#current-video","title":"Current Video","text":"<p>https://www.youtube.com/watch?v=MZSnYgdlV0A&amp;list=PLUl4u3cNGP61V4W6yRm1Am5zI94m33dXk&amp;index=8</p>"},{"location":"Management/Management/01_Team%20Management/","title":"Team Management","text":""},{"location":"Management/Management/01_Team%20Management/#main-pointers","title":"Main Pointers","text":"<ul> <li> Work face-to-face</li> <li> Rest well</li> <li> Motivate</li> </ul>"},{"location":"Management/Management/01_Team%20Management/#teams","title":"Teams","text":"<p>Modern software involves a cross-functional teams with the following skills</p> <ul> <li>Designers</li> <li>Programmers</li> <li>QA Testers</li> <li>Artists, Sound designers, Composers</li> <li>Community managers</li> <li>Business analysts</li> <li>Marketers</li> </ul>"},{"location":"Management/Management/01_Team%20Management/#onboarding","title":"Onboarding","text":"<ul> <li>Day -1</li> <li>Friendly follow up</li> <li>Dev setup</li> <li>Buddy assignment</li> <li>Week 1</li> <li>Day 1<ul> <li>Warm welcome by team</li> <li>2:1 with buddy and manager</li> <li>Business<ul> <li>Culture</li> </ul> </li> <li>Team<ul> <li>Vision</li> <li>Technology</li> <li>Culture</li> </ul> </li> <li>Preferences and competence</li> <li>Breathing room</li> </ul> </li> <li>Day 2-5<ul> <li>Tools and access</li> <li>Dev setup</li> <li>Code standards</li> <li>Training</li> </ul> </li> <li>Week 2</li> <li>Day 1<ul> <li>Assign first task</li> </ul> </li> <li>Day 5<ul> <li>Detailed code review</li> <li>Task planning</li> <li>Demo progress to others</li> </ul> </li> <li>After</li> <li>Clear expectations</li> <li>Designated team hour for doubts</li> <li>Coffee chat with each team member<ul> <li>See what they\u2019re working on</li> <li>Learn about different challenges</li> <li>Build rapport</li> </ul> </li> </ul>"},{"location":"Management/Management/01_Team%20Management/#standards","title":"Standards","text":"<ul> <li>Development guidelines</li> <li>Coding standards</li> <li>Testing requirements</li> <li>Tool/technologies used</li> </ul>"},{"location":"Management/Management/01_Team%20Management/#people","title":"People","text":"Dedicated Not Dedicated Capable - Acknowledge- Promote into leadership with mentorship - Give challenge to improve Not Capable - Give mentorship- If they don't reciprocate, they were just 'conveniently dedicated', remove them If they don't reciprocate, remove ## Recruiting <ul> <li>Objective<ul> <li>Estimate how well candidates perform on the job<ul> <li>Should evaluate how one is able to adapt to new unforeseen challenges. Most of the times, the solution is not Python, Machine Learning, or any of the the candidates' previous knowledge.</li> </ul> </li> </ul> </li> <li>Constraints<ul> <li>Limited time for recruiters</li> <li>Only limited intake of candidates</li> </ul> </li> </ul> Phase Action Online/In-Person Outcome Initial - CV- Cover Letter- Skills survey(no, yes, willing to learn)- Interview Online - Filter basic cutoff- Identify interested students Training Candidates should be given a basic version of the onboarding process and be evaluated on thatProvide training videos and resources to learn core skills Online - Identify students who are truly interested and not conveniently interested- Identify learning ability of candidate Final Individual Skills evaluation- Give everyone the same problem prompt- Simulate work-environment (allow access to notes, online tools)- Individual Presentation (whiteboard preferred; slideshow is fine) Depending on the role actual location - Problem-solving skills- Ability to utilize newly-learnt skills- Ability to handle unforeseen scenarios- Communication ability Group discussion Depending on the role actual location Check teamwork, politeness This is the logic behind Job Simulation portals such as - https://www.theforage.com/ - https://www.mckinsey.com/careers/mckinsey-digital-assessment"},{"location":"Management/Management/02_Project_Management/","title":"Project Management","text":"<p>Project Management is the planning, organization, securing, motivation and control of resources to successfully complete a project, while minimizing unproductive efforts</p> <ul> <li>The goal is to be 'agile'; 'agile' is an adjective, not a noun<ul> <li>Able to adapt to changing requirements</li> </ul> </li> <li>What to do<ul> <li>Find out where you are</li> <li>Take a small step towards the goal</li> <li>Adjust understanding based on what you learnt</li> <li>Repeat</li> </ul> </li> <li>How to do<ul> <li>When faced with 2/more alternatives that deliver similar value, choose the path that makes future change easier</li> </ul> </li> </ul>"},{"location":"Management/Management/02_Project_Management/#biggest-pitfall","title":"Biggest Pitfall","text":"<p>Avoid unnecessary Meetings</p>"},{"location":"Management/Management/02_Project_Management/#basics","title":"Basics","text":"<p>Every project should have the following</p> <ul> <li> Clear goal/vision/problem statement<ul> <li> Why</li> <li> Who: Stakeholder identification</li> <li> What<ul> <li> Scope</li> <li> Ideas</li> <li> Theme</li> </ul> </li> <li> How: Implementation</li> <li> Design doc not recommended<ul> <li> hard to maintain</li> <li> long; hard to refer to</li> </ul> </li> </ul> </li> <li> Stakeholder Management<ul> <li> Fields<ul> <li> Stakeholder</li> <li> Role</li> <li> Power</li> <li> Interest: What's in it for them</li> <li> Interest: Level</li> <li> Engagement: Frequency</li> <li> Engagement: Mode (presentation, call, email)</li> <li> Actions to take on-site</li> </ul> </li> <li> Rows<ul> <li> Project Sponsor</li> <li> Project Manager</li> <li> Data Engineer, IT, etc...</li> <li> End-Users: Clients, Company users</li> </ul> </li> <li> Plot<ul> <li> </li> </ul> </li> </ul> </li> <li> Valuation<ul> <li> IRR</li> <li> NPV</li> </ul> </li> <li> IDK<ul> <li> Define KPIs</li> <li> Set expectations for each person</li> <li> Security/Permissions</li> <li> Scenario-Planning for bad things that could go wrong<ul> <li> Over-budget</li> </ul> </li> </ul> </li> <li> Organizing<ul> <li> Processes<ul> <li> ISO/IEC DIS 42001 IT-AI-Management System</li> </ul> </li> <li> Documentation</li> <li> Tools<ul> <li> Version Control</li> </ul> </li> <li> Requirements<ul> <li> Data</li> <li> Model</li> <li> Access</li> </ul> </li> <li> Methods<ul> <li> Data Flow</li> </ul> </li> </ul> </li> <li> Relationships<ul> <li> Different stakeholders</li> <li> Communication</li> </ul> </li> <li> Usability<ul> <li> Interpretability</li> <li> Ease of setup</li> <li> Ease of modification</li> </ul> </li> <li> Testing<ul> <li> Prioritize, integrate and cut features early</li> <li> Plan backup procedures<ul> <li> Test data format</li> <li> Test plan</li> <li> Usage scenarios</li> </ul> </li> <li> Monitor<ul> <li> Model accuracy</li> </ul> </li> </ul> </li> <li> Life Cycle<ul> <li> Data drift</li> <li> Model drift</li> <li> Handling new requests<ul> <li> Scope creep<ul> <li> Have client prioritize</li> <li> Request additional resources</li> </ul> </li> <li> Nonsense requests<ul> <li> Understand why</li> </ul> </li> </ul> </li> </ul> </li> <li> Assessing<ul> <li> Perform regular assessments at a fix periodicity</li> </ul> </li> <li> Neatness</li> </ul>"},{"location":"Management/Management/02_Project_Management/#change-log","title":"Change Log","text":"<ul> <li>Datetime</li> <li>Change</li> <li>Reason</li> </ul>"},{"location":"Management/Management/02_Project_Management/#popular-project-management-models","title":"Popular Project Management Models","text":"Advantage Disadvantages Waterfall - Concept: Setting the goal- Design: Acquire the requirements, such as programmers- Pre-Production: Verify if the concept and design are feasible- Production- Testing  - Alpha  - Beta- Shipping- Maintenance Most of the actual feedback will occur at beta testing, which is too far ahead in the timeline, and hence it will be too late to respond. Classical Agile - Individuals and interactions &gt; processes and tools- Working software &gt; comprehensive documentation- Customer collaboration &gt; contract negotiation- Responding rather &gt; over following a plan Focus on features that consumers want Assumes interchangeable tasks &amp; team membersDepends on good communication Scrum 1. Transparency- Everyone on the team related to a decision is involved- Shared responsibility2. Inspection: Anyone on the team curious on why something is the way it is, can3. Adaptability"},{"location":"Management/Management/02_Project_Management/#scrum","title":"Scrum","text":"<p>Velocity tracking is flawed - Every sprint is different, as this isn't a repetitive assembly line - Velocity tracking does not help tech team - Only gives management a false sense of control</p>"},{"location":"Management/Management/02_Project_Management/#keywords","title":"Keywords","text":"Sprint Group of tasks to be completed by all teams concurrently Sprint Length Duration of sprintUsually 1 week Task Atomic chunk of work an individual can do independently that you can estimate duration forUsually \\(\\le 8 \\text{hrs}\\)Usually assigned to 1 person"},{"location":"Management/Management/02_Project_Management/#artifacts","title":"Artifacts","text":"Feature Requirement in User Story format:  \u201cAs the user/designer/artist, I want <code>something testable</code> so that <code>explain reason</code>\" Feature List List of features Backlog(Product/Project/Sprint) Prioritized list of functionality which a product should contain, or a project/sprint should achieveMaintained by Product Owner Tasklist Exhaustive list of tasks Scrumboard Task list visualized based on status like on Trello Target Goal\u201cHas to be done in 2days\u201d Estimation \u201cIt\u2019ll take about 2 days to do it\u201d Plan \u201cI\u2019ll need 2 days to do it\u201d Reality \u201cIt took 2 days to do it\u201d"},{"location":"Management/Management/02_Project_Management/#meetings","title":"Meetings","text":"Frequency Meeting Goal Details Timebox Weekly Sprint Planning Plan sprint backlog by converting project backlog into tasks 1hr Scrum/Standups Accountability &amp; Communication What did you do since last meetingWhat will you do until next meetingWhat is blocking you. Just note this down. Create a new meeting if someone wants to discuss this block 10min Sprint Review Review product Demonstrate working productReview &amp; evaluate productReview &amp; update product backlog 1hr Monthly Retrospective Meeting Review process Things to keep doingThings to stop doingNew things to try 30min Quarterly Stakeholder meeting"},{"location":"Management/Management/02_Project_Management/#people","title":"People","text":"Person Product Owner Has complete understanding of the productGuides the team Scrum Master AdministrativeRuns the meetingsFacilitatorMediator Team Member <p>Ideally Product Owner and Scrum master should always be different, as each of their roles is very tiring as is.</p>"},{"location":"Management/Management/02_Project_Management/#feature-size","title":"Feature Size","text":"<p>Categorize features as S, M, L</p> <p>IDK</p> <ul> <li>Discuss as an entire team whenever possible</li> <li>Each role should try to lend its perspective</li> <li>Listen &amp; try to make sense of what others are saying</li> <li>Offer alternate solutions &amp; point out problems</li> <li>Divide huge features into atomic features</li> <li>Everyone related to the decision should be there</li> <li>Everyone should agree on the feature size</li> <li>Don\u2019t average out the opinions if someone says S &amp; another person says L, don\u2019t conclude it\u2019s M</li> <li>Should not take too long. If you get stuck on a feature, put it aside &amp; come back to it</li> </ul>"},{"location":"Management/Management/02_Project_Management/#estimation","title":"Estimation","text":"<p>Get a clear view of project reality to make informed decisions to control project to hit targets. You need to identify what the team is capable of, not what you can/want to happen</p> <pre><code>---\ntitle: Estimation\n---\n\nflowchart LR\n\nsubgraph pb[Product Backlog]\n    direction LR\n    f1[Feature 1]\n    f2[Feature 2]\nend\n\nsubgraph sb[Sprint Backlog]\n    direction LR\n    t1[Task 1]\n    t2[Task 2]\nend\n\n\npb --&gt; Size --&gt; Effort --&gt; People --&gt; Time --&gt; sb</code></pre> <ul> <li>Don\u2019t estimate in \u201cideal work hours\u201d</li> <li>Include breaks, distractions &amp; meetings in the estimate</li> </ul> <p>Need to know the __ of your estimates</p> <ul> <li>Uncertainty</li> <li>Accuracy</li> <li>Precision</li> </ul> <p>You need to commit to a point estimate; don\u2019t use the average of a range.</p>"},{"location":"Management/Management/02_Project_Management/#estimation-ne-planning","title":"Estimation \\(\\ne\\) Planning","text":"Planning Estimation Goal Achieve a target Verify if plan is realistic Commitment occurs when Person accepts a task when estimation is accurate(not necessary person takes up the task) Nature Fixed VariableRe-estimate as you work on the task"},{"location":"Management/Management/02_Project_Management/#tracking-estimates","title":"Tracking Estimates","text":"Feature Task Original Estimate Elapsed Remaining Current Estimate <p>Get summary statistics of feature\u2019s resources</p> <p>Use this for better estimating in the future</p> <p>Compare against feature size</p>"},{"location":"Management/Management/02_Project_Management/#backlog-to-tasklist","title":"Backlog to Tasklist","text":"<p>By breaking up story into tasks, you can understand all dependencies &amp; potential overloading of individuals</p>"},{"location":"Management/Management/02_Project_Management/#scrum-board","title":"Scrum Board","text":"Doing Todo-This Sprint Todo-Long Term Discussion Testing Completed Cancelled"},{"location":"Management/Management/02_Project_Management/#software-engineering","title":"Software Engineering","text":""},{"location":"Management/Management/02_Project_Management/#aspects","title":"Aspects","text":"<ul> <li>Frontend</li> <li>UI</li> <li>UX</li> <li>Backend</li> <li>Database</li> <li>APIs</li> <li>Design/Spec/Customer</li> <li>Features</li> <li>Ease of use</li> </ul>"},{"location":"Management/Management/02_Project_Management/#write-less-code","title":"Write Less Code","text":"<ul> <li>Low Prototyping: Paper, Whiteboard, Digital Sketch</li> <li>Iterative Design</li> <li>Testing early</li> </ul>"},{"location":"Management/Management/02_Project_Management/#low-fidelity-prototyping","title":"Low Fidelity Prototyping","text":""},{"location":"Management/Management/02_Project_Management/#why-prototype","title":"Why prototype","text":"<ul> <li>Cheaper</li> <li>Visualize idea to others</li> <li>Get feedback earlier</li> <li>Experiment with alternatives</li> <li>Easier to change</li> <li>Easier to discard ideas</li> </ul>"},{"location":"Management/Management/02_Project_Management/#version-control","title":"Version Control","text":"<ul> <li>backup system</li> <li>way to share code</li> <li>history of project</li> <li>restore to checkpoint</li> <li>simultaneously work on the same files, without affecting others</li> <li>comment log</li> </ul> <p>Operations - Pull - Push - Check status - Lock files - Diff: compare - Merge changes and resolve conflict</p> <p>Note - Perfect copy on the main branch     - should always build and run     - with 0 errors     - with 0 warnings         - ignoring warnings can become troublesome when you actually have a problematic warning - Ignore unneeded files - Lock binary files</p>"},{"location":"Management/Management/02_Project_Management/#testingquality-assurance","title":"Testing/Quality Assurance","text":"<p>Systematic process of checking if product/service being developed meets requirements</p> <p>Types - Technical testing: looking for defects/logical errors - Playtesting: Dev team usage testing - User testing: Real end-user testing</p> <p>Aspects - Technical standards - Bug database - Build and test before check in - Daily builds, daily play throughs - Planned feature cuts - Code reviews/freezes - Asset freezes</p> <p>Bug reporting - Actual behavior - Expected behavior - How to reproduce - How common - Seriousness of bug - Supporting data (screenshots, numbers, etc)</p>"},{"location":"Management/Management/02_Project_Management/#stages","title":"Stages","text":"<ul> <li>Wireframe design</li> <li>Wireframe approval</li> <li>Mockup design</li> <li>Mockup approval</li> <li>Backend development</li> <li>Frontend development</li> <li>Integration</li> <li>Code review<ul> <li>Do not<ul> <li>nitpick on style guide: use a linter</li> <li>discuss large scale: should be discussed elsewhere and before</li> </ul> </li> <li>Do<ul> <li>Naming</li> <li>Forms of input</li> <li>Anticipating future needs</li> </ul> </li> </ul> </li> <li>Testing</li> <li>Functional testing</li> <li>User testing</li> <li>Deployment</li> <li>Maintenance</li> </ul>"},{"location":"Management/Management/03_Meetings/","title":"Meetings","text":""},{"location":"Management/Management/03_Meetings/#before-meeting","title":"Before Meeting","text":"<ul> <li> Is this meeting necessary?</li> <li> If yes, is this meeting productive? cost of meeting</li> <li> Meeting agenda: If you don\u2019t know why exactly you are having a meeting, you shouldn\u2019t be having it<ul> <li> Objective</li> <li> Context</li> <li> Topics</li> <li> Time-boxing: Every thing should be assigned a particular max-duration</li> </ul> </li> <li> Who all should be there? If someone does not need to be there, don\u2019t force them to attend</li> <li> Brief Creation<ol> <li>Presenting person should create a detailed document</li> <li>Forces presenter to deeply think and clearly present all information</li> <li>Forces participants to be aware of everything and avoid silly doubts</li> <li>Everyone should spend 5 minutes reading at start of meeting</li> <li>Saves participants time outside of meeting to read brief</li> <li>Technique used in Amazon</li> </ol> </li> </ul>"},{"location":"Management/Management/03_Meetings/#during-meeting","title":"During Meeting","text":"<ul> <li> Reading brief</li> <li> If time gets over, go ahead with the best solution possible rather than wasting more time trying to obtain the \u201cperfect\u201d solution</li> </ul>"},{"location":"Management/Management/03_Meetings/#after-meeting","title":"After Meeting","text":"<ul> <li> Meeting Summary: Action items for each person</li> </ul>"},{"location":"Management/Management/03_Meetings/#brainstorming","title":"Brainstorming","text":"<ol> <li>No criticism</li> <li>Negative feedback on ideas must be withheld until after the session</li> <li>Positive feedback is okay</li> <li>Free-wheeling</li> <li>Wilder the idea, the better</li> <li>Easier to limit an idea than think up</li> <li>Quantity: More the ideas, more likely to have useful ideas</li> <li>Build on ideas: Feel free to combine multiple ideas</li> </ol>"},{"location":"Management/Management/03_Meetings/#phases","title":"Phases","text":"<ol> <li>Before</li> <li>Casual spirit/atmosphere</li> <li>Designate<ol> <li>Facilitator: Session Lead<ol> <li>Understand and explain the problem and aim of session</li> <li>Facilitate session, encourage ideation, discourage criticism</li> <li>Ensure no voices lost during session</li> </ol> </li> <li>Secretary: Notetaker<ol> <li>Record every idea</li> <li>Monitor duration of session</li> <li>Not necessary to participate actively</li> </ol> </li> </ol> </li> <li>Explain process and principal question/problem statement at start of session<ol> <li>Problem statement should be simple<ol> <li>Divide complex problems into sub-problems for separate sessions</li> </ol> </li> <li>Problem statement should be clearly and simply articulated</li> </ol> </li> <li>Start with a \u201cbad\u201d/\u201cworthless\u201d idea</li> <li>During</li> <li>Think of possible solutions: You are not trying to solve a problem</li> <li>Don\u2019t interrupt anyone</li> <li>Note everything: don\u2019t just note the title of the idea, as you risk forgetting the details later</li> <li>After</li> <li>filter the feasible solutions</li> <li>pick the optimal solution</li> </ol>"},{"location":"Management/Marketing/","title":"Marketing","text":""},{"location":"Management/Marketing/#references","title":"References","text":"<ul> <li> Marketing Strategy Based on First Principles and Data Analytics | UW Foster School of Business</li> <li> Marketing Analytics</li> <li> Retail Marketing Strategy | IITR</li> <li> Strategic Marketing | IIT</li> <li> Marketing Strategy | Applied Marketing Strategy</li> </ul>"},{"location":"Management/New_Venture_Creation/","title":"New Venture Creation","text":"<p>How to plan and execute a new venture</p>"},{"location":"Management/New_Venture_Creation/#references","title":"References","text":"<ul> <li> Nuts and Bolts of Business Plans | MIT</li> <li> Innovation in Product Development</li> <li> Corporate Life Cycle | Aswath Damodaran | NYU Stern</li> <li> How to Start a Startup | YCombinator | Stanford</li> <li> Startup School | YCombinator</li> <li> 2018</li> <li> 2019</li> <li> 2023</li> <li> New Enterprises | MIT</li> <li> MIT Bootcamps</li> <li> Pitching Seed Stage Startup | YCombinator</li> <li> Lean Startup |  Startup Istanbul</li> <li> How to start a startup | YCombinator</li> <li> Harvard Innovation Labs<ul> <li> 2023</li> <li> 2012</li> <li> 2011</li> </ul> </li> <li> Fundamentals of Business - Marketing | CMU</li> <li> Marketing Research | CMU</li> <li> Essentials of SaaS</li> <li> Business Fundamentals | IITB</li> </ul>"},{"location":"Management/New_Venture_Creation/01_Introduction/","title":"Introduction","text":""},{"location":"Management/New_Venture_Creation/01_Introduction/#entrepreneurship-types","title":"Entrepreneurship Types","text":"SME IDE Meaning Small-Medium Entrepreneurship Innovation Driven Entrepreneurship Focus Market Local Global Risk Lower Higher Clustered(meaning??) \u274c \u2705 Usually Service-Based Annual cashflow with time Stable and then levels off"},{"location":"Management/New_Venture_Creation/01_Introduction/#innovation","title":"Innovation","text":"<p>Innovation \\(\\ne\\) Invention</p> <ul> <li>Innovation generates value</li> <li>Invention = any new idea</li> </ul> \\[ \\text{Innovation} = \\text{Invention} \\times \\text{Commercialization} \\]"},{"location":"Management/New_Venture_Creation/01_Introduction/#types","title":"Types","text":"<ul> <li>Technology</li> <li>Process</li> <li>Business Model</li> <li>Position</li> <li>Other</li> </ul>"},{"location":"Management/New_Venture_Creation/01_Introduction/#categories","title":"Categories","text":"<ul> <li>Core/Incremental</li> <li>Adjacent/Lateral</li> <li>Transformational/Disruptive</li> </ul>"},{"location":"Management/New_Venture_Creation/01_Introduction/#ways-to-start-a-company","title":"Ways to Start a Company","text":"Tech push Market Pull Passion Possess Technological advantage Problem Solution looking for a market Market looking for a solution Not enoughYou need to go to other 2"},{"location":"Management/New_Venture_Creation/01_Introduction/#myths-of-entrepreneurship","title":"Myths of Entrepreneurship","text":"Myth Truth Entrepreneurs are the most successful and highest achievers Usually good at only few things Entrepreneurs are individualist Good team is required Entrepreneurs are born Entrepreneurs are made Entrepreneurs love risk Entrepreneurs take calculated risk in advantageous areas Entrepreneurs are charismatic Entrepreneurs create change through leadership- Vision- Sense-making capability- Network/Relationships- Innovation engineering- Personal signature Entrepreneurs are undisciplined Entrepreneurs are disciplined- Explorative spirit of a pirate- Execution discipline of a Navy Seal Team Six"},{"location":"Management/New_Venture_Creation/01_Introduction/#idk","title":"IDK","text":"<ol> <li>Identify the problem</li> <li>5 whys</li> </ol>"},{"location":"Management/New_Venture_Creation/01_Introduction/#market-segmentation","title":"Market Segmentation","text":"<ol> <li> <p>Primary market research</p> </li> <li> <p>What problem</p> </li> <li> <p>What they think of idea</p> </li> <li> <p>Understand needs of customer</p> <ul> <li>Rational</li> <li>Emotional</li> <li>Social</li> </ul> </li> <li> <p>Limit to a few consumer segments</p> </li> <li> <p>Secondary research</p> </li> <li> <p>Select a Beachhead Market: market that can be captured easily, and also facilitates growth into other markets</p> </li> </ol> <p>Do not trust online, always do your own research</p>"},{"location":"Management/New_Venture_Creation/01_Introduction/#requirements-of-starting","title":"Requirements of Starting","text":"<ol> <li>Knowledge</li> <li>Capability/Skills</li> <li>Connections</li> <li>Financial Assets</li> <li>Name Recognition</li> <li>Credibility, from past work experience</li> <li>Passion</li> <li>Commitment</li> </ol>"},{"location":"Management/New_Venture_Creation/01_Introduction/#what-makes-a-business","title":"What makes a business","text":"<p>Until you have paying customers, you do not have a business</p>"},{"location":"Management/New_Venture_Creation/02_Idea/","title":"Refining and Presenting your Venture Idea","text":"<pre><code>---\ntitle: Success Rate of Startups\n---\npie\n\"Succeed\": 1\n\"Moderate\": 3\n\"Fail\": 6</code></pre> <ul> <li>1/10 startups succeed</li> <li>6/10 startups</li> </ul>"},{"location":"Management/New_Venture_Creation/02_Idea/#startup","title":"Startup","text":"<p>Long term plan: Exit Strategy</p> Going public Get acquired - In technology, this is not the right way to pitch.- It gives a message to investors that you are not interested in long-term growth. You\u2019re just interested in build, sell and run <p>Why would anyone want to acquire a company anyways?</p> <ul> <li>Startups are faster at innovating than large companies. </li> </ul> Startup Corporate Employees\u2019 Motivation Get rich by stocks Stable lifestyle Same goal \u2705 \u274c No internal competition \u2705 \u274cOther employees will try to make you look bad so that they can get ahead of you"},{"location":"Management/New_Venture_Creation/02_Idea/#elevator-pitch","title":"Elevator Pitch","text":"<p>For target customers who are dissatisfied with current solution, our product is a new product category that provides key problem solving opportunity. Unlike a competitive substitute, we have assembled key whole product features.</p> <ul> <li>It has to be spot-on since investors get thousands of pitches. They can easily determine if your pitch is valuable or not.</li> <li>Induce greed &amp; urgency in the investors</li> </ul>"},{"location":"Management/New_Venture_Creation/02_Idea/#the-pitch-kiss","title":"The Pitch: KISS","text":""},{"location":"Management/New_Venture_Creation/02_Idea/#structure","title":"Structure","text":"<ol> <li>Hook</li> <li>&lt; 7 seconds to engage audience </li> <li> <p>Phrases</p> <ol> <li>\u201cImagine \u2026 \u201d</li> <li>\u201cHave you ever felt \u2026\u201d</li> <li>\u201cDo you get \u201d</li> </ol> </li> <li> <p>Solution</p> </li> <li>Technology</li> <li>Business Model</li> <li>Marketing &amp; Sales</li> <li>Competition</li> <li>Management</li> <li>Financials</li> <li>Status &amp; Timeline</li> <li>The Offer</li> </ol>"},{"location":"Management/New_Venture_Creation/02_Idea/#characteristics","title":"Characteristics","text":"<ul> <li> <p>Focus should be on customer benefits, not on the technology</p> </li> <li> <p>Simple - No technical jargon</p> </li> <li> <p>Tailor the pitch for the Target Audience</p> </li> <li> <p>Lowest Common Denominator: Explain keeping in mind the least experienced/knowledgeable audience member</p> </li> <li> <p>Short (10/20/30): Audience questions will always take it to an hour, so prepare accordingly</p> </li> <li> <p>Pictures</p> </li> <li> <p>Answer details/curveballs quickly. 2 options:</p> </li> <li> <p>\u201cNo, that\u2019s not the case. From our research, this is why short reason. I\u2019ll get back to you in more detail later.\u201d</p> </li> <li> <p>\u201cThat\u2019s a very good point. We are not very familiar with. Let\u2019s discuss this in more detail later.\u201d</p> </li> </ul> <p>Make sure to shut off them quickly because you have an agenda to complete.</p> <ul> <li> <p>Presentation</p> </li> <li> <p>Passion and confidence</p> </li> <li>Engage the audience</li> <li>Slow and calm speech</li> <li>Get everyone nodding along with what you are saying</li> </ul>"},{"location":"Management/New_Venture_Creation/02_Idea/#style","title":"Style","text":"<ul> <li>Best presenter should be presenting</li> <li>Be/bring a highly knowledgeable teammate in the room</li> <li>Give firm answers</li> <li>Look at everyone in the room</li> <li>Do your research on your audience</li> <li>Pull questions</li> </ul>"},{"location":"Management/New_Venture_Creation/02_Idea/#when-to-raise-money","title":"When to Raise Money","text":"<ul> <li>Finish closing money at least 6 months before you need it</li> <li>Make pitches to investors simultaneously. This way investors are not influenced by other investors</li> <li>Be \u201cintroduced\u201d/use testimonials</li> <li>If you have 2 offers, prefer the quality of investor over the amount they\u2019re offering</li> </ul>"},{"location":"Management/New_Venture_Creation/02_Idea/#business-basics","title":"Business Basics","text":"<ul> <li>Profit &amp; Cash Flow</li> <li>Business PLan</li> <li>Be flexible (Lean Startup methodology)</li> <li>Initial vs Final Product/Service may not necessarily be the same</li> <li>Speed of progress is more important than Patents/Intellectual Property</li> <li>Mission</li> <li>The Team</li> <li>Chemistry</li> <li>Should be able to handle shocks</li> <li>Convey that you are</li> <li>Be willing to persist after failure</li> <li>Experienced to do a startup</li> <li>Speed of Execution</li> <li>Focused about your value proposition. Pivot; You don\u2019t always end up finishing with the idea you started with, but don\u2019t keep changing your project unnecessarily</li> </ul>"},{"location":"Management/New_Venture_Creation/03_Business_Models/","title":"Business Models","text":"<ul> <li>Value Creation</li> <li>Marketing</li> <li>Sales</li> <li>Value Delivery</li> <li>Finance</li> </ul> <p>Business model \\(\\ne\\) Business.</p> <p>Business model innovation is critical to develop a quality business, attack new markets and drive profitability</p>"},{"location":"Management/New_Venture_Creation/03_Business_Models/#components","title":"Components","text":"<ul> <li>Value Proposition</li> <li>Market Segment</li> <li>Value Chain Structure</li> <li>Position in the Value Network</li> <li>Revenue Generation and Margins</li> <li>High volume/Low margin</li> <li>Low volume/High margin</li> <li>Competitive Strategy</li> <li>Stage of Development</li> </ul>"},{"location":"Management/New_Venture_Creation/03_Business_Models/#business-model-canvas","title":"Business Model Canvas","text":"<ul> <li>Value proposition</li> <li>Customer segment</li> <li>Distribution channel</li> <li>Customer relationship: Feedback mechanism</li> <li>Key activities</li> <li>Key resources</li> <li>Key partnerships</li> <li>Cost structure</li> <li>Revenue stream</li> </ul>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/","title":"Business Plan","text":"<p>Dynamic &amp; shared vision with team on where we are, where we\u2019re going, how we\u2019re going there</p> <p></p>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#elements","title":"Elements","text":"<ol> <li>Executive Summary</li> <li>Opportunity and the Company &amp; its Services/Products</li> <li>Market Research/Analysis</li> <li>Economics of the Business</li> <li>Marketing Plan</li> <li>Design &amp; Development Plan</li> <li>Manufacturing &amp; Operations Plan</li> <li>Management Team</li> <li>Schedule</li> <li>Critical Risks, Problems &amp; Assumptions</li> <li>Financial Plan</li> <li>Assumptions</li> </ol> <p>Technology isn\u2019t a section, as it is a means to the end. The real point is the value produced.</p> <p>Cover Page</p> <ul> <li>Name of Venture</li> <li>Address, Contact Details</li> <li>Confidentiality Legend</li> <li>Securities Law Legend</li> <li>Control numbering of copies</li> </ul>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Put one in</li> <li>Include page numbers</li> </ol>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#executive-summary","title":"Executive Summary","text":"<p>Resume for the full plan</p> <p>Goal is to get the interview to give the pitch, and answer What do investors look for?</p>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#elements_1","title":"Elements","text":"<ol> <li>Description of Business Concept</li> <li>Opportunity &amp; Strategy</li> <li>Target Market &amp; Projections</li> <li>Competitive Advantages</li> <li>Economics, Profitability, Harvest Potential</li> <li>The Team</li> </ol>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#characteristics","title":"Characteristics","text":"<ul> <li>2 - 5 pages long</li> <li>Should be Logical, Clear, Interesting/Exciting</li> </ul>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#body","title":"Body","text":"<ol> <li>IDK Plan</li> <li>Marketing Strategy</li> <li>Pricing &amp; Distribution</li> <li>Sales Tactics</li> <li>Advertising &amp; Promotion</li> <li>Opportunity</li> <li>How big is it now?</li> <li>Trends</li> <li>Market Analysis</li> <li>Existing competitors</li> <li>Who loses if you win and what will be their response?</li> <li>Are customers interested?</li> <li>Development Plan</li> <li>Current Product Status</li> <li>Further steps (Time &amp; Resources) required</li> <li>Difficulty &amp; Risks</li> <li>Product Pipeline Plans</li> <li>Action Plan</li> <li>What will you do and when?</li> <li>Identification of \u2018Credibility Testers\u2019</li> <li>Sequencing to build value</li> <li>Eliminate/Reduce Dependencies</li> <li>Coordination of Schedule, Value Recognition Events, and Financing Requirements</li> <li>Appendix</li> </ol>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#business-plan-as-a-financing-document","title":"Business Plan as a Financing Document","text":""},{"location":"Management/New_Venture_Creation/04_Business_Plan/#first-reading-like-a-resume","title":"First reading: Like a resume","text":"<ol> <li>Excellent Idea</li> <li>Excellent financial promise</li> <li>Excellent team</li> <li>Action plan is credible and focused</li> <li>Details that give assurance of insight, commitment, and follow-through</li> </ol>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#why-some-plans-fail-here","title":"Why some plans fail here","text":"<ul> <li>Insufficient market</li> <li>Non-Credible technology</li> <li>Too large investment</li> <li>Failure to understand market</li> <li>Overly optimistic action plan</li> <li>Non-Credible team</li> <li>Poor business plan submission (misspellings, poor grammar)</li> </ul>"},{"location":"Management/New_Venture_Creation/04_Business_Plan/#second-reading-justify-the-investment","title":"Second reading: Justify the investment","text":""},{"location":"Management/New_Venture_Creation/04_Business_Plan/#third-reading-commit-to-a-plan","title":"Third reading: Commit to a plan","text":""},{"location":"Management/New_Venture_Creation/04_Business_Plan/#what-do-investors-look-for","title":"What do investors look for?","text":"<ol> <li>Why this? Why should I be interested?</li> <li>Why now?</li> <li>Why this team?</li> <li>Why will this succeed?</li> </ol>"},{"location":"Management/New_Venture_Creation/05_Marketing_Sales/","title":"Marketing &amp; Sales","text":""},{"location":"Management/New_Venture_Creation/05_Marketing_Sales/#2-success-strategies","title":"2 Success Strategies","text":"<ul> <li>Cost Leader: Aggressively cut costs</li> <li>Innovator</li> </ul>"},{"location":"Management/New_Venture_Creation/05_Marketing_Sales/#idk","title":"IDK","text":"<ul> <li>Identify your customers correctly</li> <li>\u201cProduct for everyone\u201d isn\u2019t for anyone</li> <li>Perform market segmentation</li> <li>Identify your segments of customers to target</li> <li>Some customers won\u2019t be interested even with the best of marketing</li> <li>Survey your customers</li> <li>Understand your consumer\u2019s behaviors</li> <li>Sell the benefits, not the product</li> <li>Leverage influencers (educators, doctors, etc)</li> <li>Use networking effect</li> </ul>"},{"location":"Management/New_Venture_Creation/05_Marketing_Sales/#lean-methodology","title":"Lean Methodology","text":"<ol> <li> <p>Develop Idea</p> </li> <li> <p>Identify unmet needs in market</p> </li> <li>Interview potential consumers, influencers, retailers</li> <li> <p>Focus on one unmet need</p> </li> <li> <p>MVP</p> </li> </ol> <p>Goal: Identify consumers for launch</p> <ol> <li>Efficacy first</li> <li>Minimal packaging</li> <li> <p>Minimal attention to fancy features</p> </li> <li> <p>Create customers</p> </li> <li> <p>Branding, packaging</p> </li> <li>Go to market</li> <li>Ramp up hiring &amp; spending</li> <li> <p>Confirm: re-orders</p> </li> <li> <p>Grow company</p> </li> <li> <p>Build staff</p> </li> <li>Become profitable &amp; self-sustaining</li> <li>Position for acquisition</li> </ol>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/","title":"Financial Projections","text":"<p>Failure to plan is planning to fail</p>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#startup-ceo-role","title":"Startup CEO Role","text":"<p>Even if you don't understand accounting/finance, you need to know</p> <ul> <li>Average Selling Price</li> <li>Gross margins</li> <li>Cost of R&amp;D</li> <li>Sales &amp; Marketing Strategy &amp; Expenses</li> <li>Start-up and/or Capital Expenses</li> </ul>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#venture-capitalist-wants","title":"Venture Capitalist Wants","text":"<ul> <li>3-5x absolute returns</li> <li>5-7yr investment horizon</li> <li>4x in 5yrs = 32% IRR</li> <li>Get a significant amount of $ invested</li> <li>Own a significant ownership % (50% +)</li> </ul> \\[ \\text{VC} \\% = \\dfrac{\\$ \\text{Invested}}{\\$ \\text{Invested} + \\text{Pre-VC Valuation}} \\]"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#tech-model","title":"Tech Model","text":"<ul> <li>COGS (Cost of Goods/Services): Unit costs + manufacturing O/H + Support</li> <li>R&amp;D should be 10-20%</li> <li>G&amp;A (General and administrative expensive) should be 5-15%</li> <li>Target operating profit of 15-20%</li> <li>Distribution strategy</li> </ul>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#idk","title":"IDK","text":"<ul> <li>Do not use business planning software</li> <li>Do not project best-case/worst-case</li> <li>Build sales projection from the bottom-up</li> </ul>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#tech-companies-rules-of-thumb","title":"Tech companies rules-of-thumb","text":"<ul> <li>Staffing drives departmental expenses</li> <li>Employee benefits add 15%</li> <li>Salaries wil be 60-70% of total expenses</li> <li>Remainder will be rent, utilities, travel</li> </ul>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#cashflow-projections","title":"Cashflow Projections","text":"<ul> <li>Burn rate</li> <li>Monthly operating loss + capital expenditures</li> <li>Cash flow projection</li> <li>Cumulative operating losses excluding depreciation</li> <li>Plus cumulative capital expenses</li> <li>Determining total cash required</li> <li>Cumulative operating loss + Cumulative capital expenses loss</li> <li>On the month you turn cash positive</li> </ul>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#presentation","title":"Presentation","text":"<p>Financial Summary</p> <ul> <li>Always show % next to absolute values</li> <li>Show pre-tax only</li> <li>Don\u2019t allocate G&amp;A</li> </ul> <p>Executive summmary</p> <ul> <li>Annual P&amp;L for 4-5yrs</li> <li>Data to justify revenue projectison</li> <li>Unit sales</li> <li>Average Selling Price (ASP)</li> <li>When will you be profitable</li> <li>Total cash requirement </li> </ul> <p>Full business plan</p> <ul> <li>Annual P&amp;L for 4years</li> <li>Quarterly P&amp;L for 4years</li> <li>Quarterly staffing plan for 4years</li> <li>Quarterly cash flow for 4years</li> </ul>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#equity-distribution","title":"Equity Distribution","text":"<p>Compensate for</p> <ul> <li>Ownership of IP</li> <li>Commitment</li> <li>Risk</li> <li>Sacrifice</li> <li>Past &amp; future contributions</li> </ul> <p>Work to be done &gt; Work already done. Incentivize people to do things in the future</p> <p>Everyone should vest</p> <p>You can always grant later</p>"},{"location":"Management/New_Venture_Creation/06_Financial_Projections/#common-ownership-breakdown","title":"Common ownership breakdown","text":"<ul> <li>CEO: 5%</li> <li>VP: 1-2.5%</li> <li>Sr Manager: 0.25%</li> <li> <p>Sr Ind Contributor: 0.1%</p> </li> <li> <p>Founding management gets 2x to 3x</p> </li> <li>Founding employees gets 5x to 10x</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/","title":"Legal Issues","text":""},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#lifecycle","title":"Lifecycle","text":""},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#idk","title":"IDK","text":"<ul> <li>IP</li> <li>Secrecy</li> <li>Speed</li> <li> <p>Become the industry-standard, lock-in customers, making it costly to switch</p> </li> <li> <p>You need to make sure you have correct owning rights. If you have an employed coder, you implicitly own the code; if you have an independent coder paid on a contract basis, you don\u2019t implicitly own it.</p> </li> <li>When you use open-source tools, make sure you\u2019re complying with its license</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#ip","title":"IP","text":"<p>Intellectual Property</p> <p>Valuable asset to raise capital</p>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#types","title":"Types","text":"Meaning Duration Example Cost Enhance value Protect expression Protect function Trademark Mark under which you sell goods and servicesDeveloping a name for yourselfDo not pick descriptive words/phrases such as \u201cStorage Technology, Analog Devices\u201dwww.uspto.gov Unlimited as long as continued renewal Apple, IBM, ThinkPad Cheap \u2705 \u274c \u274c Copyright Right to make copiesFederal registration helpsGood for music, not for software 75years \u2705 \u2705 \u274c Trade Secret Secrets to give yourself an advantage in the market Lasts as long as you can keep it secret with NDAs Formula for Coke \u274c \u2705 \u2705 Patent Limited time monopolyFederally-granted right to any system/method that is new, non-obvious and usefulOwnership \\(\\ne\\) Right to use 20years Expensive \u2705 \u2705 \u2705 Provisional Patent Requires meaningful description of invention (claims not required)FastNothing happens at the PTOWhatever not mentioned might not covered when filing patent) 1year Cheap(<code>$130</code> for small entity, <code>$65</code> for micro) University Licensing (Bayh-Dole Act) Sponsored researchShare royalties with inventors Combination"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#patent","title":"Patent","text":""},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#requirements-to-get-a-patent","title":"Requirements to get a patent","text":"<ul> <li>Novel</li> <li>Something new: Prior art must be cited</li> <li>Useful</li> <li>Patentable subject matter</li> <li>Not previously sold/publicly described</li> <li>Enabling disclosure</li> <li>1 year window in US only</li> <li>Not obvious \u201cto one of ordinary skill in the art\u201d</li> <li>Prior art \u201cteaches against\u201d</li> <li>Commercial success can show non-obviousness</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#obtaining-patent","title":"Obtaining Patent","text":"<ul> <li>Determine what to patent</li> <li>Determine when to patent</li> <li>Prepare one/more applications</li> <li>Prosecuting applications</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#when-to-file","title":"When to file","text":"<ul> <li>Before you lose rights</li> <li>Before a public disclosure</li> <li>Before an \u201con-sale\u201d bar</li> <li>First to file wins under AIA</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#parts","title":"Parts","text":"<ul> <li>Field of invention</li> <li>Background of invention</li> <li>\u201cPrior Art\u201d</li> <li>List of advantages compared to prior art</li> <li>Summary of invention</li> <li>Detailed description</li> <li>Examples of use</li> <li>Best mode: what is the best way to implement your invention</li> <li>Claims</li> <li>What exactly is your invention</li> </ul> <p>If you ever want to enforce the patent, claims is the part that matters. Hence this is where you should spend money for someone else to do, not the other parts.</p>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#typical-ip-terms","title":"Typical IP Terms","text":"W/o Equity W/ Equity Issue fees $ 50-150k $ 5-50k Maintenance fees ~50% of expected RR ~50% of expected RR Diligence Can\u2019t leave on shelf Can\u2019t leave on shelf Royalty as % of Sales 3-5% 2-4% Patent costs $ 25-200k $ 25-200k Research Sponsorship Not required Not required"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#corporation-registration","title":"Corporation Registration","text":"<ul> <li>Delaware, US is the best place to register a company</li> <li>Why do it soon?</li> <li>Avoid personal liability</li> <li>Avoid \u201cpartner\u201d liability</li> <li>Minimize personal taxes</li> <li>Section 83<ul> <li>Rule</li> <li>If you receive \u201cproperty in connection with providing services\u201d</li> <li>You have ordinary income (taxed unto 35%) equal to fair market value of property minus What you paid</li> <li>How to overcome</li> <li>Separate the time when stock is issued to you from the investment by others, ie incorporate earlier, issue stock &amp; make 83(b) election</li> </ul> </li> <li>S corporation is preferable over a regular corporation, to avoid double taxation</li> <li></li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#forms-of-equity-compensation","title":"Forms of Equity Compensation","text":"<ul> <li>Restricted stock</li> <li>Stock sold/granted outright</li> <li>Starts capital gains/SEC holding periods running</li> <li>Subject to vesting and buyback by company</li> <li>If 83(b) election timely:<ul> <li>modest/zero income at grant</li> <li>No further income unto stock sold, then capital gain</li> <li>No employer tax deduction for increase in value</li> </ul> </li> <li>ISOs (Incentive Stock Options) tax-qualified stock options</li> <li>Options compelling with tax requirements</li> <li>Only for employees of corporation</li> <li>Exercise price = FMV on date of grant</li> <li>Typical exercise vesting over time</li> <li>No tax on grant/vesting</li> <li>Possible alternative minimum tax on exercise</li> <li>Taxation upon stock sale - capital grain if holding period requirements met (&gt; 1yr from exercise and &gt;2yers from grant data); no employer deduction</li> <li>NQOs (Non-Qualified Stock Options)</li> <li>Complete tax freedom in design, but there may be accounting issues<ul> <li>Discounted options</li> <li>Repricing</li> <li>Performance vesting</li> </ul> </li> <li>No tax on grant/vesting</li> <li>Ordinary income (and employer deduction) upon exercise</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#vesting","title":"Vesting","text":"<p>Conditions on keeping what seems to have been awarded to you</p> <ul> <li>Time-based vesting</li> <li>3-5yrs</li> <li>Monthly, quarterly, annual</li> <li>Performance vesting</li> <li>Design issues</li> <li>Accounting issues</li> <li>Accelerated vesting on change in control? IPO?</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#forfeiture-expiration-of-vesting-rights","title":"Forfeiture &amp; Expiration of Vesting Rights","text":"<ul> <li>How long after employment ends may vested options be exercised (ISO rules generally limit to 90days)</li> <li>Forfeiture if \u201cbad boy\u201d provision violated</li> <li>Consequences of violation of non-competition, non-solicitation agreements</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#buyback-issues","title":"Buyback Issues","text":"<p>Can company repurchase vested equity for fair value?</p> <ul> <li>Always</li> <li>When employment ends?</li> <li>If covenants violated?</li> <li>Never?</li> </ul>"},{"location":"Management/New_Venture_Creation/07_Legal_Issues/#securities","title":"Securities","text":"<ul> <li>Don\u2019t offer to sell securities in a business plan</li> <li>Using the business plan to \u201csell securities\u201d presents problems beyonds VC\u2019s, corporate investors</li> <li>Properly paper all deals</li> <li>even friendly deals with friends/relatives to avoid misunderstandings</li> <li>Under federal law, all offers of securities must be registered with the SEC (very expensive), unless there is an exemption (eg: private placement)</li> <li>Avoid public pronouncements</li> <li>Blue sky (state securities) laws differ from state to state</li> <li>Non-compliance may trigger a recision offer, stop order, personal liability</li> </ul> <p>Private placements</p> <ul> <li>Use an experienced securities law attorney</li> <li>Avoid dealing with individual investors who are not \u201caccredited\u201d</li> <li>Include \u201crisk factors\u201d in disclosure materials</li> <li>Provide a capitalization table</li> <li>SEC 10b-5: don\u2019t make material misstatements of fact/omit to state material facts</li> <li>Legends/control number of documents</li> <li>Regulation D: Form D filing with SEC</li> </ul>"},{"location":"Management/New_Venture_Creation/idk/","title":"Idk","text":""},{"location":"Management/New_Venture_Creation/idk/#startup","title":"Startup","text":""},{"location":"Management/New_Venture_Creation/idk/#startup-learning-loop","title":"Startup Learning Loop","text":"<pre><code>---\ntitle: Minimize total time through loop\n---\nflowchart LR\ni[Ideas] --&gt;\n|Build| Product --&gt;\n|Measure| Data --&gt;\n|Learn &amp; Improve| i</code></pre>"},{"location":"Management/New_Venture_Creation/idk/#corporate-structure","title":"Corporate Structure","text":"<pre><code>flowchart TB\n\nbod[Board of Directors] --&gt;\nCEO --&gt;\nChiefs --&gt;\nPresident --&gt;\nSVP --&gt;\nVP --&gt;\nDirector --&gt;\nManager --&gt;\nExecutives\n\nsubgraph Chiefs\ndirection TB\nCTO[\"CTO&lt;br /&gt;Tech\"]\nCRDO[\"CMO&lt;br /&gt;Reseach &amp; Development\"]\nCOO[\"COO&lt;br /&gt;Operations\"]\nCMO[\"CMO&lt;br /&gt;Marketing\"]\nCFO[\"CFO&lt;br /&gt;Finance\"]\nCSO[\"CSO&lt;br /&gt;Security\"]\nCHRO[\"CMO&lt;br /&gt;Human Resources\"]\nCGO[\"CGO&lt;br /&gt;Green \"]\nend</code></pre>"},{"location":"Management/New_Venture_Creation/idk/#projects","title":"Projects","text":"Question Aspect Responsible Why Purpose &amp; Problem Director What Solution Manager How Implementation Team Lead"},{"location":"Management/Operations_and_Revenue_Optimization/","title":"Revenue Optimization","text":""},{"location":"Management/Operations_and_Revenue_Optimization/#references","title":"References","text":"<ul> <li> Operations Management | Allan Wesley</li> <li> Operations and Revenue Analytics | IIT Roorkee July 2018 </li> <li> Airline Planning &amp; Optimisation | TUD-AE4423</li> <li> E-Business (Digital Transformation) | IIT</li> <li> Supply Chain Digitization</li> </ul>"},{"location":"Management/Operations_and_Revenue_Optimization/01_Introduction/","title":"01 Introduction","text":""},{"location":"Management/Operations_and_Revenue_Optimization/01_Introduction/#goal","title":"Goal","text":"<ul> <li>Sell a minimum number of seats without selling every seat at discount prices, such that it is enough to cover fixed operating costs</li> <li>Sell remaining seats at higher rates to maximize revenue</li> </ul>"},{"location":"Management/Operations_and_Revenue_Optimization/01_Introduction/#profit","title":"Profit","text":"\\[ \\begin{aligned} \\text{Profit} &amp;= \\text{Income} - \\text{Expenses} \\\\ &amp;= \\text{Sale Price} \\times \\min(\\text{Demand}, \\text{Quantity}) - \\text{Cost} \\times \\text{Quantity} \\end{aligned} \\]"},{"location":"Management/Operations_and_Revenue_Optimization/01_Introduction/#passengers","title":"Passengers","text":"<p>Passengers have different valuations</p> Business people Others Keen on Flexibility \u2705 \u274c Booking Time Late Early Keen on refunds \u2705 \u274c Price Elasticity Low High Purchasing Power High Low"},{"location":"Management/Operations_and_Revenue_Optimization/01_Introduction/#selling-cases","title":"Selling Cases","text":"Sell too many discounted seats Not enough seats for high-paying passengers Sell too many discounted seats Empty seats at takeoff <p>Lost revenue in both scenarios</p>"},{"location":"Management/Operations_and_Revenue_Optimization/01_Introduction/#optimization","title":"Optimization","text":"<p>We can formulate using Optimization </p> <ul> <li>Objective Function: Maximize Total Revenue</li> <li>Constraints</li> <li>Seats sold \\(&gt;=\\) 0</li> <li>Seats sold \\(&lt;=\\) Capacity</li> <li>Seats sold \\(&lt;=\\) Demand</li> </ul>"},{"location":"Management/Operations_and_Revenue_Optimization/01_Introduction/#shadow-price","title":"Shadow Price","text":"<p>Marginal revenue for unit increase in demand of regular seats</p>"},{"location":"Management/Operations_and_Revenue_Optimization/02_Airline_Industry/","title":"Airline Industry","text":""},{"location":"Management/Operations_and_Revenue_Optimization/02_Airline_Industry/#types-of-optimization","title":"Types of Optimization","text":"Point-to-Point Network Entire trip"},{"location":"Management/Operations_and_Revenue_Optimization/02_Airline_Industry/#single-leg","title":"Single-Leg","text":""},{"location":"Management/Operations_and_Revenue_Optimization/02_Airline_Industry/#marketing-focus","title":"Marketing Focus","text":"<p>Marginal revenue analysis</p> Initial Increasing discounted fare demand through marketing Increasing regular fare demand through marketing <p></p>"},{"location":"Management/Operations_and_Revenue_Optimization/02_Airline_Industry/#capacity-allocation","title":"Capacity Allocation","text":"Initial Increasing capacity(assuming demand remains constant)"},{"location":"Management/Operations_and_Revenue_Optimization/02_Airline_Industry/#multi-leg","title":"Multi-Leg","text":"<p>Passengers on multiple legs must be considered for all the legs that they are a part of.</p>"},{"location":"Management/Risk_Management/","title":"Risk Management","text":""},{"location":"Management/Risk_Management/#references","title":"References","text":"<ul> <li> MIT 18.S096 Topics in Mathematics w Applications in Finance</li> <li> IIT Roorkee | Financial Derivatives and Risk Management</li> <li> Quantitative Risk Management | University Leipzig</li> <li> Financial Risk Management | ULFinance</li> <li> Financial Risk Management | Professor Carol Alexander</li> <li> FRM<ul> <li> Part 1 | Analyst Prep</li> <li> Part 2 Book 1 | Analyst Prep</li> <li> Part 2 Book 2 | Analyst Prep</li> <li> Part 2 Book 4 | Analyst Prep</li> </ul> </li> <li> Commodity Derivatives and Risk Management | IIT</li> <li> Risk Management in Finance | Gabor David</li> <li> Insurance<ul> <li> Insurance Loss Models | Katrien Antonio | University of Amsterdam</li> <li> Life Insurance Mathematics | Katrien Antonio | University of Amsterdam</li> <li> Non-life insurance | Katrien Antonio | University of Amsterdam</li> <li> Data science for insurance | Katrien Antonio | University of Amsterdam</li> <li> Advanced Life Insurance Mathematics | Katrien Antonio | University of Amsterdam</li> </ul> </li> <li> Consumer Risk Management Essentials | Risky World</li> <li> Consumer Credit Risk Management | Risky World</li> <li> Risk-Based Engineering | IIT</li> <li> FRM | FinRGB</li> </ul>"},{"location":"Management/Risk_Management/99_Risk_Neutral_Valuation/","title":"99 Risk Neutral Valuation","text":""},{"location":"Management/Risk_Management/99_Risk_Neutral_Valuation/#risk-neutral-valuation","title":"Risk Neutral Valuation","text":"<p>Suppose our economy includes stock \\(S\\), riskless money market account \\(B\\) with interest rate \\(r\\) and derivative claim \\(f\\)</p> <p>Assuming there\u2019s only 2 possible outcomes at time \\(dt\\)</p> <p></p>"},{"location":"Management/Risk_Management/99_Risk_Neutral_Valuation/#naive-approach","title":"Naive Approach","text":"<p>Current price of a derivative claim is determined by current price of portfolio which exactly replicates the payoff of the derivative at maturity</p> <p>Consider Forward contract with pays \\(S-K\\) at time \\(dt\\). One could think that its strike \\(K\\) should be defined by the \u201creal world\u201d transition probability \\(p\\) $$ p(S_1 - k) + (1-p) (S_2 - k) = p S_1 + (1-p) S_2 - k \\ p = \u00bd \\implies k_0 = (S_1 + S_2)/2 $$</p> <ol> <li>Borrow \\(S_0\\) to buy stock. Enter forward contract with strike \\(k_0\\)</li> <li> <p>In time \\(dt\\) deliver stock in exchange for \\(k_0\\) and repay \\(S_0 e^{r \\ dt}\\)</p> </li> <li> <p>If \\(k_0 &gt; S_0 e^{r \\ dt}\\), riskless profit</p> </li> <li>If \\(k_0 &lt; S_0 e^{r \\ dt}\\), definite loss</li> </ol> <p>Notes</p> <ul> <li>Given current price of the stock and assumptions on the dynamics of stock price, there is no uncertainty about the price of a derivative.</li> <li>Price is defined only by the price of the stock and not by the risk preferences of the market participants</li> <li>Mathematical apparatus allows us to compute current price of a derivative and its risks, given certain assumptions about the market</li> </ul>"},{"location":"Management/Risk_Management/99_Risk_Neutral_Valuation/#general-derivative-claim","title":"General derivative claim","text":"<p>For a claim \\(f\\),\u00a0find \\(a\\)\u00a0and \\(b\\) such that $$ \\begin{aligned} f_1 &amp;= a S_1 + b B_0 e^{r dt} \\ f_2 &amp;= a S_2 + b B_0 e^{r dt} \\ \\implies f_0 &amp;= a S_0 + b B_0 \\end{aligned} $$</p> \\[ \\begin{aligned} a &amp;= \\dfrac{f_1 - f_2}{S_1 - S_2} \\\\ b &amp;= \\dfrac{S_1 f_2 - S_2 f_1}{(S_1 - S_2) B_0 e^{r \\ dt}} \\end{aligned} \\] \\[ f_0 = e^{- r \\ dt} \\Big( f_1 q + f_2 (1-q) \\Big) \\\\ q = (S_0 e^{r \\ dt} - S_2)/(S_1 - S_2), &amp; q \\in (0, 1) \\\\ \\implies q S_1 + (1-q) S_2 = e^{r \\ dt} S_0 \\]"},{"location":"Management/Risk_Management/99_Risk_Neutral_Valuation/#black-scholes","title":"Black-Scholes","text":"<p>Assumes that stock has log-normal dynamics $$ dS = \\mu S dt + \\sigma S dw $$ where \\(W\\)\u00a0is a Brownian motion: \\(dW\\) is normally-distributed with mean 0 and standard deviation \\(\\sqrt{dt}\\) </p> <p>We want t find a replicating portfolio such that $$ df = a dS + b dB $$</p> \\[ (dS)^2 = \\sigma^2 S^2 dt \\] \\[ \\dfrac{\\partial f}{\\partial t} + \\dfrac{1}{2} \\dfrac{\\partial^2 f}{\\partial S^2} \\sigma^2 S^2 + \\dfrac{\\partial f}{\\partial S} r S - rf = 0 \\]"},{"location":"Management/Risk_and_Decision_Analysis/","title":"Risk &amp; Decision Analysis","text":""},{"location":"Management/Risk_and_Decision_Analysis/#references","title":"References","text":"<ul> <li> Risk and Decision Analysis | MIT</li> <li> Decision Analysis | Jef Karel Caers</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/01_Forecasts/","title":"Forecasts","text":"<p>Forecasts are never perfect.</p> <p>Forecasting is like steering a car using the rear view mirror.</p>"},{"location":"Management/Risk_and_Decision_Analysis/01_Forecasts/#flaw-of-averages","title":"Flaw of Averages","text":"<p>Fundamental problem in design and evaluation of projects on the \u2018average\u2019/\u2018most-likely\u2019 future forecasts</p> <p>Due to misunderstanding of probability and systems behavior</p>"},{"location":"Management/Risk_and_Decision_Analysis/01_Forecasts/#jensens-law","title":"Jensen\u2019s Law","text":"\\[ E[ \\ f(x) \\ ] \\ne f( \\ E[x] \\ ), \\\\ \\text{if } f(x) \\text{ is convex curve} \\] <p>where</p> <ul> <li>\\(E[ \\ f(x) \\ ]\\): Average of possible outcomes of \\(f(x)\\)</li> <li>\\(f( \\ E[x] \\ )\\): outcome calculated using average of \\(x\\)</li> <li>Convex function example: \\(x^2 + c\\)</li> </ul> <p>The equality holds true when \\(f(x)\\) is linear, but in reality, most systems are non-linear</p>"},{"location":"Management/Risk_and_Decision_Analysis/02_DCF/","title":"Discounted Cashflows","text":"<p>Always make sure that you compare value at the same time point.</p> <p>Learnt in Finance</p>"},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/","title":"Proactive Design","text":""},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/#stages-of-analysis","title":"Stages of Analysis","text":"Stage NPV Base case Consider base case design, for fixed objective (mission, specifications) Recognize reality of uncertainty - This may lead to different results due to system non-linearities- Capacity constraints systematically limit profit from good opportunities, while we suffer fully from risks- Error of forecasts- Distribution of possible outcomes of reality (volatility and uncertainty) Lowest Incorporate flexibility - Adjust project actual needs, based on how future develops, and intelligently develop system over time- Run a Monte Carlo simulation of all possibilities, and then identify what is the best initial case, and what flexibility is optimal Highest Multi-dimensional valuation Not just expected NPV, but also other summary statistics of the possible NPVs from the simulations Conclusion Don\u2019t accept consequences of  distribution of uncertainties- Avoid/reduce downside effects- Take advantage of opportunities- Reduce initial costs"},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/#example-mall-parking","title":"Example: Mall Parking","text":"<p>Requirement: Major garage serving mega-mall</p> <p>Actual demand uncertain, due to</p> <ul> <li>Population growth, demographics</li> <li>Mall success probability</li> <li>Competition</li> </ul> <p>Engineering design assumes a fixed forecast!</p>"},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/#optimizing-base-case","title":"Optimizing base case","text":"<p>Find highest value design, by looking at each major design alternative. No  </p> <p></p>"},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/#recognizing-uncertainty","title":"Recognizing uncertainty","text":"<p>Costs may be easy to estimate, as contracts will give fixed bids.</p> <p>However, demand is highly uncertain, especially as we proceed to the future</p> <p></p>"},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/#introducing-flexibility-into-design","title":"Introducing flexibility into design","text":""},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/#multi-dimensional-valuation","title":"Multi-Dimensional Valuation","text":""},{"location":"Management/Risk_and_Decision_Analysis/03_Proactive_Design/#conclusion","title":"Conclusion","text":"<p>Build the mall in a way that we start out only 4 floors, but make the foundation and etc in a way that we can expand to the initial number of floors as required, even though this is more expensive than just building foundation capable for 4 floors.</p>"},{"location":"Management/Risk_and_Decision_Analysis/04_Simulation/","title":"Simulation","text":"<p>Replicate outcomes of uncertain process</p> <p>Works with any distribution</p> <ul> <li>Regular/irregular</li> <li>Continuous/not</li> <li>Normal/not</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/04_Simulation/#requirements","title":"Requirements","text":"<p>Distributions for key parameters</p> <p>May be observed, estimated, assumed, or guessed</p>"},{"location":"Management/Risk_and_Decision_Analysis/04_Simulation/#steps","title":"Steps","text":"<ol> <li> <p>Create a valuation model</p> </li> <li> <p>Identify most significant uncertainties</p> </li> <li> <p>Tornado diagram</p> </li> <li> <p>Choose distributions for uncertainties</p> </li> <li> <p>Model distribution of outcomes</p> </li> <li> <p>Set up decision rules for exercising flexibility, to ensure that it is right decision to exercise flexibility</p> </li> </ol> <p>For eg: \u201cExpand if observed demand &gt; Capacity over 2 years. But don\u2019t expand towards the end of life\u201d</p>"},{"location":"Management/Risk_and_Decision_Analysis/04_Simulation/#flexibility-types","title":"Flexibility Types","text":"Flexibility \u201cin\u201d system Flexibility \u201con\u201d system Feature design to enable system to evolve easily Nothing to do with design Example Building foundation to support additional floors in future Abandon projectDelay project"},{"location":"Management/Risk_and_Decision_Analysis/05_Drivers_of_Flexibility/","title":"Drivers of Flexibility","text":""},{"location":"Management/Risk_and_Decision_Analysis/05_Drivers_of_Flexibility/#factors-affecting-flexible-design-vs-immediate-decision","title":"Factors affecting flexible design vs immediate decision","text":"Factor Comment Against Flexibility Comment For Flexibility Uncertainty Benefits of Scale Cheaper to produce at large quantity Benefits not attained when set-up is under-utilized, which is common when set-up is made for larger capacity than requirement Discount Rate Cancels out benefits of scaleFuture investments are better in terms of NPV Learning Efficiency improves with time &amp; experience Competitive Gaming"},{"location":"Management/Risk_and_Decision_Analysis/05_Drivers_of_Flexibility/#mannes-analysis","title":"Manne\u2019s Analysis","text":"<p>Analytic solution for simple case of constant linear growth</p> <p>Provides simple demonstration of issues, by giving useful insight into trade-offs</p> <p></p> <ul> <li>Optimal cycle time = most economical time between additions of capacity modules</li> <li>Cycle time defines model size (years * annual growth)</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/05_Drivers_of_Flexibility/#interpretation","title":"Interpretation","text":"<ol> <li>Higher discount rate \\(\\implies\\) small size of modules</li> <li>High discount rates reduce present value of future costs, which counteract benefits of scale</li> <li>Smaller \\(\\alpha\\) \\(\\implies\\) Larger benefits of scale</li> </ol>"},{"location":"Management/Risk_and_Decision_Analysis/05_Drivers_of_Flexibility/#results","title":"Results","text":"<p>Manne\u2019s present cost versus cycle time</p> <ol> <li>Steep for small cycle times</li> <li>Quite flat at bottom for large cycle times</li> </ol>"},{"location":"Management/Risk_and_Decision_Analysis/05_Drivers_of_Flexibility/#learning-effects","title":"Learning Effects","text":""},{"location":"Management/Risk_and_Decision_Analysis/06_Decision_Analysis/","title":"Decision Analysis","text":""},{"location":"Management/Risk_and_Decision_Analysis/06_Decision_Analysis/#decision-analysis-vs-flexibility-analysis","title":"Decision Analysis vs Flexibility Analysis","text":"<p>Due to this, flexibility analysis is preferred over decision analysis</p> <ul> <li> <p>Decision analysis</p> </li> <li> <p>assumes you can define choices to take at any stage</p> </li> <li> <p>Implies focus on a few distant choices</p> </li> <li> <p>Flexibility analysis</p> </li> <li> <p>encourages to explore</p> <ul> <li>What decisions to take</li> </ul> <p>and</p> <ul> <li>When to take them</li> </ul> </li> <li> <p>as granular as required</p> </li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/06_Decision_Analysis/#outcome","title":"Outcome","text":"<ol> <li> <p>Strategies for altering choices as future is revealed, not a unique \u201coptimal choice\u201d</p> </li> <li> <p>\u2018Second best\u2019 choices which offer</p> </li> <li> <p>Insurance against downside</p> </li> <li>Opportunity to exploit upside</li> </ol> <p>\u2018Second best\u2019 strategies are sub-optimal for each outcome, but preferable as they offer flexibility to do well in a range of outcomes. It is never the best, but never the worst</p> <ol> <li>Education of client about distribution, range of possible results (Value at Risk)</li> </ol>"},{"location":"Management/Risk_and_Decision_Analysis/06_Decision_Analysis/#motivation","title":"Motivation","text":"<p>People acting intuitively deal poorly with complex, uncertain situations. They</p> <ul> <li>Process probability info poorly</li> <li>Over-simplify complexity &amp; alter reality</li> <li>Focus on extremes</li> <li>Focus on end states, not whole process</li> </ul> <p>Decision analysis helps overcome this</p>"},{"location":"Management/Risk_and_Decision_Analysis/06_Decision_Analysis/#characteristics","title":"Characteristics","text":"<ul> <li>Assumes that every decision in the set of choices is discrete</li> <li>Looks over several time periods</li> <li>Deals with uncertainties</li> <li>Standard method</li> <li>Can include utility assessment (such as levels of consumer satisfaction)</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/06_Decision_Analysis/#decision-tree","title":"Decision Tree","text":"<ul> <li>Structure</li> <li>Decision points: Choices</li> <li>Chance points (possible outcomes) after each decision</li> <li>Data</li> <li>Value of each possible outcome</li> <li>Probability</li> <li>Uncertainties</li> </ul> <p>Goal: Maximize expected value of outcomes</p> <p>For each set of alternatives, calculate expected value. Then choose alternative with maximum EV</p>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/","title":"Value of Information","text":"<p>Decision to collect information is a decision to insert flexibility into development strategy, as the logic behind \u201ctest\u201d is so that you may change you decision once you have test results.</p> <p>Value of information = Value of this flexibility</p>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/#information-gathering","title":"Information Gathering","text":"<p>Inserting an test stage before decision problems as possible choice reduces uncertainty before commitment to a system design/roll-out</p> <pre><code>flowchart LR\nD --&gt; dp1[Decision Problem] &amp; Test\nTest --&gt; dp2[Decision Problem]</code></pre>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/#tests","title":"Tests","text":"<p>Any decision problem has initial uncertainties = \u201cprior probabilities\u201d, such as those concerning</p> <ul> <li>Cost of production</li> <li>Likelihood of sales</li> </ul> <p>Tests help get information on these issues, for eg</p> <ul> <li>Running a test plant</li> <li>Carrying out market analysis</li> </ul> <pre><code>flowchart LR\npp[Prior Probabilities] --&gt;|Test| ni[New Information] --&gt;|Revise| pp --&gt; new[New Expected Values for decision]</code></pre>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/#consequence","title":"Consequence","text":"<p>EV after test \\(\\ge\\) EV without test</p>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/#evsi","title":"EVSI","text":"<p>Expected value of Sample information</p> <p>Helps understand if test is significantly worth it? $$ \\begin{aligned} \\text{Expected value of Info} &amp;= EV_\\text{after test} - EV_\\text{without test} \\ &amp;= \\sum p_k \\cdot \\text{EV}(D_k^)   -  \\text{EV}(D^) \\end{aligned} $$</p> <ul> <li>\\(D^*\\) is the current best design</li> <li>\\(D_k^*\\) is the best design of test \\(k\\)</li> </ul> <p>Test results will not prove what will happen. They are samples, and hence false positives/negatives possible.</p> <p>Tests merely just update the prior estimates of probabilities using Bayes\u2019 Therom. Each test result implies a different value of project, each with a different probability. This EVSI is complicated</p> <p>Bayes\u2019 theorem is impractical for systems design, as elements of factor for updating the posterior probability are unavailable</p> <ol> <li>Full analysis is complicated process with many possible outcomes</li> <li>Involves many assumptions about what the probability of outcomes of the tests</li> <li>Analysis maybe incorrect even if math is correct</li> </ol>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/#evpi","title":"EVPI","text":"<p>Expected Value of Perfect information</p> <p>Even though it is hypothetical &amp; not perfect, it helps simplify analysis</p> <p>Establish upper bound on value of test</p> <p>Concept: Imagine a black box \u201cCassandra\u201d machine which predicts exactly which event test result \\(E_j\\)\u00a0occurs. Therefore, the \u201cbest\u201d possible decisions can be made. EV gain over the \u201cno test\u201d EV must be maximum possible, which is the desired upper limit on value of test</p>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/#characteristics","title":"Characteristics","text":"<ol> <li>Prior probability (occurrence of uncertain event) must equal probability (associated perfect test result)</li> <li>For \u201cperfect test\u201d, the posterior probabilities are either 0/1; no doubt remains</li> <li>Optimal choice generally obvious, once we \u201cknow\u201d what will happen</li> <li>EVPI can generally be written directly, without Bayes\u2019 Theorem</li> </ol>"},{"location":"Management/Risk_and_Decision_Analysis/07_Value_of_Information/#is-test-worthwhile","title":"Is Test Worthwhile?","text":"<ul> <li>If value is linear</li> <li>if EVPI &lt; cost of test -&gt; Reject test</li> <li>Pragmatic rule of thumb</li> <li>If cost &gt; 50% EVPI -&gt; Reject test</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/","title":"Project Evaluation","text":"<p>It is nearly impossible to derive the \u201cbest\u201d choice. Therefore, we try to find the \u201cpreferred solution\u201d</p>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#what-is-best","title":"What is \u201cbest\u201d?","text":"<p>Extreme (high/low) of all possibilities</p> <p>Either</p> <ol> <li>1 metric of performance</li> </ol> <p>or</p> <ol> <li>Metrics can be put on single scale</li> </ol> <p>However, both 1 and 2 are not realistic</p>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#valuepreferenceutility-function","title":"Value/Preference/Utility Function","text":"<p>\\(V(x)\\) is a means of ranking the relative preference of an individual for a bundle of consequences \\(x\\)</p>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#diminishing-marginal-utility-curve","title":"Diminishing marginal utility curve","text":""},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#exceptions-to-diminishing-marginal-utility","title":"Exceptions to Diminishing Marginal Utility","text":"<p>Very common in real life</p> <ul> <li>Critical mass: only valuable if you have enough</li> <li>Network/Connectivity: more connections \\(\\implies\\) more valuable</li> <li>Threshold/Competition: only valuable if</li> <li>Minimum reached (absolute graded exams)</li> <li>Matches/beats competition (relative grading exams)</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#conditions-for-a-value-function","title":"Conditions for a Value function","text":""},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#axioms","title":"Axioms","text":"<ol> <li>Completeness/Complete Pre-order: \\(V(x)\\) is defined \\(\\forall x_i\\)</li> <li>Transitivity: \\(V(a)&gt;V(b) \\ \\land \\ V(b)&gt;V(c) \\implies V(a)&gt;V(c)\\)</li> <li>General true for individuals</li> <li>Not necessarily true for groups; not all group members share the same preferences <ul> <li></li> </ul> </li> <li>Ellsberg Paradox: Under ambiguity, transitivity does not always hold, as people will want to choose the non-ambiguous option usually</li> <li>Allais Paradox: </li> <li>Monotonicity/Archimedean Principle</li> <li>\\(V(x)\\) is monotonically-increasing/decreasing</li> <li>\\(a &gt; b \\implies (V(a) &gt; V(b) \\quad \\forall a, b) \\lor (V(a) &lt; V(b) \\quad \\forall a, b)\\)</li> <li>This assumption does not hold for all utility functions<ul> <li>Inflation rate</li> <li>Audio volume</li> <li>Salt on food</li> <li>Problem can be re-formulated as \u201cSalt available on table\u201d</li> </ul> </li> </ol>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#consequences","title":"Consequences","text":"<ul> <li>Existence of \\(V(x)\\)</li> <li>Only ranking \\(x_1, x_2, \\dots\\) possible. We cannot quantify the distances between \\(V(x_1), V(x_2), \\dots\\)</li> <li>Strategic equivalence: Monotonic transformation of \\(V(x) \\equiv V(x)\\); \\(V(x_1, x_2) = {x_1}^2 x_2 \\equiv 2 \\log \\vert x_1 \\vert + \\log \\vert x_2 \\vert\\)</li> <li>Values not good basis for absolute value</li> <li>Arrow\u2019s Impossibility Theorem/Paradox</li> <li>No \u201cfair\u201d voting system, without a dictator, that satisfies everyone\u2019s preferences</li> <li>Hence, concept of \u201cbest\u201d is not meaningful in design of complex systems</li> <li>Therefore, we try to find the \u201cpreferred solution\u201d</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#outcomes","title":"Outcomes","text":"<p>Nature of Evaluation</p> <ul> <li>Many dimensions &amp; metrics of performance</li> <li>Uncertainty about metrics</li> <li>\u201cBest\u201d is undefined</li> <li>We can screen out dominated solutions</li> </ul> <p>Nature of Choice</p> <ul> <li>Any person must make tradeoffs</li> <li>Group inevitably have to negotiate deal</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#concept-of-dominance","title":"Concept of Dominance","text":"<p>One alternative better than others on all dimensions</p> <p>Dominated alternatives can be discarded</p> <p>Feasible region or \u201cTrade Space\u201d is area under &amp; left of the curve</p> <p></p>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#metrics","title":"Metrics","text":"<ul> <li>Expected Value: Useful, but insufficient, as it cannot describe range of effects</li> <li>Worst-case scenario with some notion of probability of loss: People are \u201crisk-averse\u201d; more sensitive to loss</li> <li>Best case scenario</li> <li>CapEx: Capital Expenditure = Investment</li> <li>Some measure of benefit-cost</li> <li>Value-Modelling</li> <li>VAR</li> <li>VAG</li> </ul>"},{"location":"Management/Risk_and_Decision_Analysis/08_Project_Evaluation/#robustness","title":"Robustness","text":"<p>Taguchi method</p> <p>Robust design is a product whose performance is minimally-sensitive to factors causing variability</p> <p>Robustness measured by standard deviation of distribution of outcomes</p> <p></p> <p>Preferred when we particular result</p> <ul> <li>Tuning into a signal</li> <li>Fitting parts together</li> </ul> <p>However, this is not necessarily value maximizing. We would prefer to</p> <ul> <li>limit downside</li> <li>maximize upside</li> </ul> <p></p>"},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/","title":"Summary","text":""},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/#deterministic-analysis","title":"Deterministic Analysis","text":""},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/#uncertainty-analysis","title":"Uncertainty Analysis","text":""},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/#characterization-of-enumeration-space-to-find-best-flexible-designs","title":"Characterization of enumeration space to find best flexible designs","text":""},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/#comparison-of-fixed-vs-flexible-design","title":"Comparison of fixed vs flexible design","text":""},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/#learning-rates","title":"Learning Rates","text":""},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/#multi-criteria-decision-table","title":"Multi-Criteria Decision Table","text":"<p>With \\(\\alpha=0.95, \\text{LR}=10\\%\\)</p> <p></p>"},{"location":"Management/Risk_and_Decision_Analysis/09_Summary/#value-of-flexibility-for-different-economies-of-scale-learning-rates","title":"Value of flexibility for different economies of scale &amp; learning rates","text":""},{"location":"Management/SAPM/","title":"Security Analysis &amp; Portfolio Management","text":"<p>Course will focus on investing, not on trading/speculationCourse is not going to give tips to earn super-normal profits</p>"},{"location":"Management/SAPM/#tools","title":"Tools","text":"<ul> <li>https://finance.yahoo.com/screener/</li> <li>https://wallmine.com/screener</li> <li>http://alphavantage.co/</li> <li>https://iexcloud.io/</li> <li>https://finnhub.io/</li> <li>https://alpaca.markets/</li> </ul>"},{"location":"Management/SAPM/#recommended-readings","title":"Recommended Readings","text":"<ul> <li> Investment Fables</li> <li> Stocks for the long run</li> <li> The Intelligent Investor (Value investing)</li> <li> Technical Analysis of Stock Trends</li> <li> Irrational Exuberance (Psychological aspects of investing)</li> <li> The Black Swan</li> <li> Fooled by Randomness</li> <li> Flash Boys</li> </ul>"},{"location":"Management/SAPM/#recommended-showsmovies","title":"Recommended Shows/Movies","text":"<ul> <li> Big Short</li> <li> Inside Job</li> <li> Trillion Dollar Bet</li> <li> Floored</li> <li> Wall Street</li> <li> Barbarians at the Gate</li> <li> Rogue Trader</li> <li> Margin Call</li> <li> Too Big to Fail</li> <li> Industry | HBO</li> </ul>"},{"location":"Management/SAPM/#references","title":"References","text":"<ul> <li> MIT 18.S096 Topics in Mathematics w Applications in Finance</li> <li> Aswath Damodaran | Investment Philosophies</li> <li> ML in Finance| Hudson &amp; Thames</li> <li> Marcos Lopez de Prado Talks</li> <li> IIT Roorkee | Quantitative Investment Management</li> <li> Security Analysis &amp; Portfolio Management | IIT Roorkee</li> <li> Mathematical Portfolio Theory | IIT Guwahati</li> <li> CFA<ul> <li> Level 1 | AnalystPrep</li> <li> Level 2 | AnalystPrep</li> <li> Level 3 | AnalystPrep</li> </ul> </li> <li> Portfolio Management | NEDL</li> <li> Quantitative Finance | IIT</li> <li> Quantitative Finance | Nathan Whitehead</li> <li> Wall Street Expert Reviews | Financial Edge Training</li> <li> Financial Data Science</li> <li> ML for Algotrading | Trade Mamba</li> <li> Pricing for Options | Caltech</li> <li> Advanced Algorithmic Trading and Portfolio Management</li> <li> Advanced Mathematical Finance | Mike, the Mathematician</li> <li> Investing for Laymen | Hvass Laboratories</li> <li> Global Asset Allocation and Stock Selection | Campbell Harvey</li> <li> Global Financial Management | Campbell Harvey</li> <li> Global Tactical Assset Allocation | Campbell Harvey</li> </ul>"},{"location":"Management/SAPM/01_Introduction/","title":"Introduction","text":""},{"location":"Management/SAPM/01_Introduction/#investment","title":"Investment","text":"<p>Sacrificing current resources with the expectation of future gains</p> <ul> <li>Sacrificing current resources is certain</li> <li>Future returns has risk &amp; uncertainty</li> </ul> <p>It is nearly impossible to \u201cbeat the market\u201d consistently</p>"},{"location":"Management/SAPM/01_Introduction/#investment-vs-speculation","title":"Investment vs Speculation","text":"Investment Speculation Buying undervalued, holding for a long time and selling high, hence making a largecapital gain Buying and selling of high-risk securities with anticipation of earning higher returns in the short-term Horizon Long Short"},{"location":"Management/SAPM/01_Introduction/#return","title":"Return","text":"<p>Total income an investor gets from their investment every year</p> <p>Compensation for</p> <ul> <li>Time</li> <li>Inflation</li> <li>Risk</li> <li>Opportunity cost (Compensation for postponing consumption)</li> </ul>"},{"location":"Management/SAPM/01_Introduction/#investment-amount-factors","title":"Investment Amount Factors","text":"<ul> <li>Income</li> <li>Expenses (Necessary/Optional)</li> <li>Time Horizon</li> <li>Expected Return</li> <li>Risk tolerance</li> </ul>"},{"location":"Management/SAPM/01_Introduction/#investment-steps","title":"Investment Steps","text":"<ol> <li>Set investment objectives (Factors)</li> <li>Major asset allocation</li> <li> <p>Portfolio generation</p> </li> <li> <p>Asset/Security selection</p> </li> <li> <p>Proportion</p> </li> <li> <p>Execution</p> </li> <li>Performance Review</li> <li>Portfolio Revision: Inclusion/exclusion of assets in an    existing portfolio or changing the ratio of funds invested</li> </ol> <p>Compare portfolio with benchmark returns and revise portfolio 7. Go to step 1</p>"},{"location":"Management/SAPM/01_Introduction/#investment-objectives","title":"Investment Objectives","text":"<ul> <li>Returns</li> <li>Regular Income<ul> <li>Stock Dividends</li> <li>Bond Coupon</li> <li>Zero-coupon bond maturity repayment should not be taken as capital appreciation; it is interest income</li> </ul> </li> <li>Capital Appreciation<ul> <li>Stock Value</li> <li>Bond Value increment due to change in market interest rate</li> </ul> </li> <li>Safety/Risk</li> <li>Liquidity</li> <li> <p>Tax factors: Govt security bonds are free from tax </p> </li> <li> <p>Ease of management</p> </li> <li>Legal &amp; regulatory factors</li> <li>Unique needs &amp; preferences</li> <li>Duration of investment</li> <li>Frequency of performance evaluation</li> </ul>"},{"location":"Management/SAPM/01_Introduction/#asset-allocation","title":"Asset Allocation","text":"Strategic Tactical Approach buy-and-hold Duration Long-term Short-term"},{"location":"Management/SAPM/01_Introduction/#security-selection","title":"Security Selection","text":"Value Stock Growth Stock Valuation Under-valued Overvalued Price to earnings Low High Volatility Low High Dividends High Low/No Source of Return Dividends Expected capital gain Cyclical Stock Defensive Stock Volatility High Low Sensitivity to market trends High Low Company usually deals with Luxury goods Necessities Comment Follow all cycles of economy: expansion, peak, and recession, recovery Outperform market during economic slowdown"},{"location":"Management/SAPM/01_Introduction/#security","title":"Security","text":"<p>Always invest in business, not stocks</p> <p>Stocks don\u2019t always \u2018win\u2019 in the long-run. Index funds are better, as they keep revising the portfolio. Easier to invest in index funds for passive income rather than evaluating yourself.</p> <p>Yield on bond market actually is more volatile than stock market, due to fluctuations in the interest rate</p>"},{"location":"Management/SAPM/01_Introduction/#taxes","title":"Taxes","text":""},{"location":"Management/SAPM/01_Introduction/#dividends","title":"Dividends","text":"<p>Fully-taxable regardless of the dividend amount</p> <p>Exception: if you are below the taxable income slab</p>"},{"location":"Management/SAPM/01_Introduction/#capital-gains","title":"Capital Gains","text":"Tax in India Taxable when STCGShort-Term Capital Gains 15% Any gain LTCGLong-Term Capital Gains 10% Only if gain &gt; 1 lakh"},{"location":"Management/SAPM/01_Introduction/#note","title":"Note","text":"<ul> <li>When comparing investments, remember about Survivorship Bias</li> </ul>"},{"location":"Management/SAPM/02_Risk_Returns/","title":"Risk and Returns","text":"<p>Note: Horizon need not always be \\(h=1\\)</p>"},{"location":"Management/SAPM/02_Risk_Returns/#return","title":"Return","text":"<p>\u201cReturn is backward-looking\u201d $$ r(t, h) = y_t - y_{t-h} $$</p>"},{"location":"Management/SAPM/02_Risk_Returns/#roi","title":"ROI","text":"<p>% change in series</p> <p>Return on investment is in percentage relative to original investment</p> ROI \\(R_t\\) Time Additive? Multi-Period Return is __ sum of individual returns Simple \\(\\dfrac{y_t - y_h}{y_h}\\) \u274c Geometric Continuous(Preferred) \\(\\ln \\left \\vert \\dfrac{y_t}{y_h} \\right \\vert = \\ln \\vert y_t \\vert - \\ln \\vert y_{t_h} \\vert\\) \u2705 Arithmetic \\[ \\text{CR} = \\ln \\vert 1 + \\text{SR} \\vert \\]"},{"location":"Management/SAPM/02_Risk_Returns/#re-investment-benefit","title":"Re-Investment Benefit","text":"\\[ \\text{Re-Investment Benefit} = \\text{IRR} - \\text{ROI} \\] <p>Benefit that could be obtained by investing all intermediate inflows at the same ROI</p>"},{"location":"Management/SAPM/02_Risk_Returns/#yield","title":"Yield","text":"<p>\u201cYield is forward-looking\u201d $$ Y_t = \\dfrac{y_t - y_h}{y_t} $$</p>"},{"location":"Management/SAPM/02_Risk_Returns/#dividends","title":"Dividends","text":"<p>Dividend rate are relative to face value, not your investment</p>"},{"location":"Management/SAPM/02_Risk_Returns/#dates","title":"Dates","text":"Dividend Declaration Date Ex-Dividend Date Record Date Payment Date"},{"location":"Management/SAPM/02_Risk_Returns/#return-series","title":"Return Series","text":"<p>Assumed to be a random walk</p>"},{"location":"Management/SAPM/02_Risk_Returns/#expected-returns","title":"Expected Returns","text":"\\[ E(R) = \\sum_i r_i \\cdot P(r_i) \\]"},{"location":"Management/SAPM/02_Risk_Returns/#risk","title":"Risk","text":"<p>Chance of actual return differing from expected return</p> <p>Statistically quantified through variance/standard deviation of returns\u2019 PDF</p>"},{"location":"Management/SAPM/02_Risk_Returns/#types-of-unknowns","title":"Types of Unknowns","text":"Systematic risk Unsystematic risk Uncertainty Meaning Sensitivity to market fluctuations Personal factors Unknown effects Type ExternalMacro InternalMicro External Minimizable \u274c \u2705through diversification (portfolio) \u274c Risk Compensation expected \u2705 \u2705 \u274c \\[ \\begin{aligned} \\text{Risk: } \\sigma^2 &amp;= \\text{SR} + \\text{UR} \\\\ \\text{SR} &amp;= \\beta^2 \\cdot \\sigma^2 (R_m) \\end{aligned} \\]"},{"location":"Management/SAPM/02_Risk_Returns/#risk-measures","title":"Risk Measures","text":"Standard Deviation \\(\\sigma (R_p)\\) Beta(Market sensitivity) \\(\\dfrac{\\text{cov} (R_p, R_m)}{\\sigma^2_{m}}\\) Semi Deviation \\(\\sigma (\\text{Loss}_p)\\)\\(\\text{Loss}_t = \\arg \\max(R_t, 0)\\) <p>where \\(p=\\) portfolio and \\(m=\\) market</p>"},{"location":"Management/SAPM/02_Risk_Returns/#risk-return-tradeoff","title":"Risk-Return Tradeoff","text":"<ul> <li>Investors are rational and risk-averse: prefer less risk investments</li> <li>Investors expect risk premium: Investors are ready to take risk only with the expectation of higher return</li> </ul> \\[ R_\\min = R_f + \\underbrace{\\left ( \\dfrac{R_m - R_f}{\\sigma_m} \\right )}_\\text{Market Price of Risk} \\sigma \\]"},{"location":"Management/SAPM/02_Risk_Returns/#jensens-inequality","title":"Jensen\u2019s Inequality","text":"<p>Using Jensen\u2019s Inequality $$ E[f(x)] \\ne f(E[x])  \\ \\implies E[u(R)] &gt; u(E[R]) $$ where</p> <ul> <li>\\(R\\) is the return obtained</li> <li>\\(u(R)\\) is the utility obtained from the return</li> </ul>"},{"location":"Management/SAPM/02_Risk_Returns/#effect-of-frequency-on-volatility","title":"Effect of Frequency on Volatility","text":"\\[ V \\propto \\nu \\]"},{"location":"Management/SAPM/02_Risk_Returns/#trading-days","title":"Trading Days","text":"Trading Days Fixed-Income 365.25 Variable-Income 252"},{"location":"Management/SAPM/02_Risk_Returns/#annualization","title":"Annualization","text":"\\[ \\begin{aligned} \\text{Annual } E(R) &amp;= 252 \\times E(R) \\\\ \\text{Annual } \\sigma(R) &amp;= \\sqrt{252} \\times \\sigma(R) \\end{aligned} \\] <p>There are 252 trading days in a year</p>"},{"location":"Management/SAPM/02_Risk_Returns/#idk","title":"IDK","text":"<p>Fixed-income securities are also very volatile</p>"},{"location":"Management/SAPM/02_Risk_Returns/#ytm","title":"YTM","text":"<p>Yield to Maturity = IRR of security if held until maturity</p>"},{"location":"Management/SAPM/03_Trading_Styles/","title":"Trading Styles","text":""},{"location":"Management/SAPM/03_Trading_Styles/#margin-trading","title":"Margin Trading","text":"<p>Allows investors to leverage positions</p> <p>A margin account provides you the resources to buy more quantities of a stock than you can afford at any point of time. For this purpose, the broker would lend the money to buy shares and keep them as collateral.</p> <p>You need to maintain</p> <ul> <li>Initial margin</li> <li>Maintenance margin</li> </ul> <p>Margin calls occur when an investor's equity falls below a certain threshold, and the broker requires the investor to deposit more funds into their account.</p>"},{"location":"Management/SAPM/03_Trading_Styles/#short-selling","title":"Short Selling","text":"<p>Trader borrows shares from a broker and immediately sells them with the expectation that the share price will fall shortly after. If it does, the trader can buy the shares back at the lower price, return them to the broker, and keep the difference, minus any loan interest, as profit</p> <p>Being short in an asset means investing in such a way that the investor will profit if the value of the asset falls. This is the opposite of a more conventional \"long\" position, where the investor will profit if the value of the asset rises</p> <p>It is riskier than going \u201clong\u201d</p> Profit Bound Loss Bound Long Unlimited Limited: Cost of stock Short Limited: Cost of stock Unlimited <p>Security Lending and Borrowing Scheme \u2013 1997 (SLB):</p> <ul> <li>SLB is a scheme that has been launched to enable the   settlement of securities sold short.</li> <li>SLB enables lending of idle securities by the investors   through the clearing corporation/clearing house of   stock exchanges to earn a return through the same.</li> <li>Securities in the F&amp;O segment are eligible for SLB</li> </ul>"},{"location":"Management/SAPM/03_Trading_Styles/#day-trading","title":"Day Trading","text":"<p>Practice of buying and selling financial instruments within the same trading day, such that all positions are usually closed before the market close for the trading day</p> <p>Square-off position intra-day</p> <p>Institutional traders are not permitted to do day trading in India</p>"},{"location":"Management/SAPM/04_Fundamental_Analysis/","title":"Fundamental Analysis","text":"<p>Examines various factors affecting supply and demand conditions, thereby influencing future income from and value of an investment</p> <p>Studies fundamental factors that determine earnings and risks associated with a share</p> <p>Suitable for</p> <ul> <li>Long-term investing: value of share that should prevail in capital market</li> <li>Determining intrinsic worth of share</li> <li>Explaining price-behavior of shares in terms of underlying fundamental factors</li> </ul>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#why-invest-in-assets-with-low-pe-ratio","title":"Why invest in assets with low P/E ratio?","text":"<ul> <li>Store of value</li> <li>Expected future earnings</li> </ul>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#geic-model","title":"GEIC Model","text":"<ul> <li>**G**lobal economy</li> <li>Domestic **e**conomy</li> <li>**I**ndustry</li> <li>**C**ompany</li> </ul> <pre><code>flowchart LR\n\nsubgraph ee[Economic&lt;br/&gt;Environment]\n    direction LR\n    ge[Global&lt;br/&gt;Economy]\n    e[Domestic&lt;br/&gt;Economy]\n    i[Industry] \nend\n\nee --&gt; Company --&gt; Performance --&gt; v[Value&lt;br/&gt;of share]</code></pre>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#global-economy","title":"Global Economy","text":"<ul> <li>Prospects for Exports</li> <li>Price competition</li> <li>Cost of foreign inputs</li> <li>Profits through foreign investments</li> <li>Exchange rate fluctuations</li> <li>Risk of changing political environment in world</li> <li>Increasing/decreasing peace in international scenario</li> </ul> <p>Stronger globalization and international collaboration, higher the importance of monitoring global economy. Eg: sub-prime crisis</p>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#economy","title":"Economy","text":"<p>Shocks: Change in macro-economic vars provide a force that goes against inertia inherent in the performance of firms, and hence the share prices</p> <p>Types of shocks</p> <ul> <li>Supply</li> <li>Demand</li> <li>Financial market</li> </ul> <p>Do a matrix of PESTEL Factors with SWOT</p>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#pestel","title":"PESTEL","text":"Dimension Factors Political Political stabilityTax PolicyEmployment lawsEnvironment regulationsTrade restrictions &amp; tariffs Economic Economic growthInterest ratesExchange ratesInflation rateUnemployment Social Health consciousnessPopulation growth rateAge distributionCareer attitudesEmphasis on safetyCultural dimensions of society Technological R&amp;D ActivityAutomationTechnological incentivesRate of technological change Environmental Legal"},{"location":"Management/SAPM/04_Fundamental_Analysis/#swot","title":"SWOT","text":"<p>Strengths, Weaknesses, Opportunities, Threats</p>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#industry","title":"Industry","text":"<p>An industry is set of companies that serves a particular niche of consumers</p>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#industry-phase","title":"Industry Phase","text":"<p>Identify which phase of the life cycle the industry belongs to</p> Phase Pioneering Trial phasePotential to be commercialized Expansion Starting to be commercialized Stabilized/Mature Fully commercialized Decay Being abandoned"},{"location":"Management/SAPM/04_Fundamental_Analysis/#structural-analysis","title":"Structural Analysis","text":"<p>Intensity of competition among firms in the same industry determines its profitability</p> <p>Porter\u2019s 5 Forces Model</p> <ul> <li>Competitive rivalry</li> <li>Threat of entry: New supplier</li> <li>Threat of substitution: New industry</li> <li>Bargaining powers of consumers</li> <li>Bargaining powers of suppliers</li> </ul>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#company","title":"Company","text":"<ul> <li>Quantitative: Financial</li> <li>Qualitative: Non-Financial</li> <li>Quality of mgmt</li> <li>Product portfolio/range</li> <li>Collaborations</li> <li>Shareholders pattern and listing</li> <li>R&amp;D, Innovation</li> <li>Diversification</li> <li>Does this company fall under strict Govt regulations</li> <li>Disputes &amp; contingent liabilities</li> <li>Availability of inputs</li> <li>Industrial relations</li> </ul>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#equity-valuation","title":"Equity Valuation","text":"<p>07_Equity_Valuation.md </p> <p>Check if stock is under-valued/over-valued</p>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#ratios","title":"Ratios","text":""},{"location":"Management/SAPM/04_Fundamental_Analysis/#pe-ratio","title":"P/E Ratio","text":"<p>Price that market is willing to pay for one unit of earning</p> <p>Lower is better; extreme P/E ratios are not desirable</p> <p>Provides a benchmark in determining the value of a share and hence the value of shareholders</p> <p>There is a strong connection between P/E, dividend discount models, and fundamentals $$ \\begin{aligned} \\text{P/E} &amp;= \\dfrac{P_\\text{Dividend Growth Model}}{\\text{Earnings}} \\ &amp;= \\dfrac{1}{\\text{Earnings}} \\times \\dfrac{D_{t+1}}{k-g} \\ &amp;= \\dfrac{1}{\\text{Earnings}} \\times \\dfrac{D_t (1+g)}{k-g} \\ &amp;= \\dfrac{D_t}{\\text{Earnings}} \\times \\dfrac{1+g}{k-g} \\ &amp;= \\text{Dividend Payout Ratio} \\times \\dfrac{1+g}{k-g}  \\end{aligned} $$ </p> <p>How to determine if P/E ratio is good</p> <ul> <li>Company growth rate</li> <li>How fast has company been growing in the past?</li> <li>Are these rates expected to increase in the future</li> <li>Industry</li> </ul>"},{"location":"Management/SAPM/04_Fundamental_Analysis/#peg-ratio","title":"PEG Ratio","text":"<p>Good way to decide if P/E ratio of company is high/low $$ \\text{PEG} = \\dfrac{\\text{P/E}}{\\text{Earnings Growth}} $$</p> PEG Ratio Interpretation Action \\((0, 0.50)\\) Undervalued Buy \\([0.50, 0.65)\\) Consider buying \\([0.65, 1.00)\\) Watch/Hold \\([1.00, 1.30)\\) Consider selling \\([1.30, 1.70)\\) Consider shorting \\([1.70, \\infty)\\) Overvalued Short"},{"location":"Management/SAPM/04_Fundamental_Analysis/#preferred-values","title":"Preferred Values","text":"Preferred PV of dividends High P/E Low P/Dividends Low P/Book Value Low P/Sales Low PEG Low Capitalization Low"},{"location":"Management/SAPM/04_Fundamental_Analysis/#idk","title":"IDK","text":"<ul> <li>Porter's Diamond</li> <li>Value chain analysis</li> <li>BCG Matrix</li> <li>Balanced Scorecard</li> </ul>"},{"location":"Management/SAPM/05_Technical_Analysis/","title":"Technical Analysis","text":"<ol> <li>Identify trend changes at early stage through predicting stock price patterns, using historical data (volume/price)</li> <li>Identify when to buy/sell</li> <li>Maintain investment position until evidence indicates that trend has reversed</li> </ol>"},{"location":"Management/SAPM/05_Technical_Analysis/#notes","title":"Notes","text":"<ol> <li>Probabilistic modelling; always uncertain, never deterministic</li> <li>Continued success is dependent on keeping successful strategies known only to a few</li> </ol>"},{"location":"Management/SAPM/05_Technical_Analysis/#premises","title":"Premises","text":"<p>Market action determines everything</p> <ol> <li>Everything will continue in state of rest/uniform motion unless compelled by external force</li> <li>Market price is solely dependent on forces of demand and supply</li> <li>Prices have a tendency to move in trends that persist for appreciable duration</li> <li>Reversals of trends are caused by shifts in demand &amp; supply</li> <li>There is a time gap b/w technicians perceiving a change and when investors assesses the change</li> </ol>"},{"location":"Management/SAPM/05_Technical_Analysis/#tools","title":"Tools","text":"<ul> <li>Typical</li> <li>Variables<ul> <li>Price</li> <li>Volume</li> <li>Rate of change</li> </ul> </li> <li>Charts &amp; graphs<ul> <li>Line charts</li> <li>Linear scale</li> <li>Log scale</li> <li>Bar charts: OHLC - Open High Low Close</li> <li>Candle chart: </li> <li>Point &amp; figure chart</li> </ul> </li> <li>Dow Theory Measures</li> <li>Moving averages</li> <li>Momentum and oscillators</li> <li>Breadth</li> <li>Market indicators</li> <li>Investors\u2019 sentiments</li> <li>Contrary opinion</li> <li>Professional investors\u2019 behavior</li> <li>Economic indicators</li> </ul>"},{"location":"Management/SAPM/05_Technical_Analysis/#typical","title":"Typical","text":"OHLC Candlestick chart Candle color:Red/black: close&gt;openGreen/Blue: close&gt;open"},{"location":"Management/SAPM/05_Technical_Analysis/#dow-theory","title":"Dow Theory","text":"<p>Assumes that most shares follow the trend of the market most of the time</p> <p>It intends to show the general trend/direction of the market as a whole and does not predict the direction of change in a particular security</p> <p>In order to measure the \u201cmarket\u201d, two indices are used</p> <ul> <li>Industrial average: combination of blue-chip shares from industry</li> <li>Transportation average: shares of transport companies</li> <li>To reinforce the conclusions obtained from Industrial Average</li> </ul>"},{"location":"Management/SAPM/05_Technical_Analysis/#trends","title":"Trends","text":"Primary Secondary Tertiary Overall trend- Business cycles- Intrinsic value Reactions that interrupt the progress of prices in primary trendMay give wrong signals &amp; confuse market Random movementsBuilding blocks to secondary trends Duration Few years Few months Day-to-day Direction - bullish: upward- bearish: downward Opposing primary trend: Technical reaction- Technical corrections: upward -&gt; downward- Technical rally: downward -&gt; upward Concerns Long-term investors Weak holdersTraders High-frequency traders"},{"location":"Management/SAPM/05_Technical_Analysis/#principle-of-confirmation","title":"Principle of Confirmation","text":"<p>Whatever trends emerge in Industrial average must be confirmed by Transportation average</p> <p>If trends in share prices are contradictory to industrial production/transportation of goods, then one should not design a trading strategy in shares and must wait until one gets confirmation of trends</p>"},{"location":"Management/SAPM/05_Technical_Analysis/#price-volume","title":"Price-Volume","text":"<p>Volume is the \u2018fuel\u2019 to move prices</p> <p>Usually, \\(\\text{Volume} \\propto \\text{Price}\\) , ie volume</p> <ul> <li>contracts on decline</li> <li>expands on rallies/advances</li> </ul> <p>If it is against this normal relationship, it is an indicator of an upcoming trend reversal. However, it should only be used as background information, since the actual reversals would be signaled by averages</p>"},{"location":"Management/SAPM/05_Technical_Analysis/#price-actions","title":"Price Actions","text":"<p>Price actions determine the trend</p> <ul> <li>Bullish indications: successive rallies penetrate peaks while the trough of an intervening decline is above the preceding trough</li> <li>Bearish indications: series of declining peaks and troughs</li> </ul>"},{"location":"Management/SAPM/05_Technical_Analysis/#averages","title":"Averages","text":"<p>Time Series Filters </p> <p>Usually uses the closing prices</p> <p>Convention is to use 2 averages</p> <ul> <li>Slower average: larger window</li> <li>Faster average: smaller window</li> </ul> <p>Notes</p> <ul> <li> <p>Normally, an average moves along with a trend; but a reversal in trend may be captured by a crossover of 2 averages</p> </li> <li> <p>Signals to buy/sell are generated when the</p> </li> <li> <p>price crosses the moving average</p> <p>or</p> </li> <li> <p>one MA crosses the another</p> </li> <li> <p>Doubtful about this</p> </li> <li> <p>Buy</p> <ul> <li>price &gt; moving average</li> <li>Faster average &gt; Slower average</li> </ul> </li> <li> <p>Sell</p> <ul> <li>price &lt; moving average</li> <li>Faster average &lt; Slower average</li> </ul> </li> <li> <p>MA is a lagging indicator \u2013&gt; crossover will usually signal a trend reversal well after new trend has begin and is used mainly for confirmation</p> </li> </ul>"},{"location":"Management/SAPM/05_Technical_Analysis/#trend-channels","title":"Trend Channels","text":"<p>Trends have to be bounded</p> <ul> <li>Trend channels</li> <li>When prices trend between 2 parallel lines, this is referred to a channel<ul> <li>It is created by drawing 2 parallel lines</li> <li>Line 1: Basic/main trendline</li> <li>Line 2: Return/channel line</li> </ul> </li> </ul> <p>Use-case</p> <ul> <li>Represents area of support/resistance depending on direction of underlying trend</li> <li>Helps identify potential trend acceleration/reversal</li> </ul> Bullish Bearish"},{"location":"Management/SAPM/05_Technical_Analysis/#envelops","title":"Envelops","text":"<p>2 symmetrical parallel lines to moving average</p> <p>This is based on principle that prices fluctuate around a given trend in cyclical movements</p> <p>Envelops consist of points of maximum and minimum divergence from some moving average</p>"},{"location":"Management/SAPM/05_Technical_Analysis/#bollinger-bands","title":"Bollinger Bands","text":"<ul> <li>Middle line: \\(\\text{MA(close, \\(w\\))}\\)</li> <li>Upper band: \\(\\text{MA} + z_{\\alpha/2} * \\sigma (\\text{close}, w)\\)</li> <li>Lower band: \\(\\text{MA} - z_{\\alpha/2} * \\sigma (\\text{close}, w)\\)</li> </ul> <p>Whenever bands narrow, a change in trend occurs: Whenever bands narrow, they have been stable for a while and it is followed by movement which is more volatile and in opposite direction</p>"},{"location":"Management/SAPM/05_Technical_Analysis/#patterns","title":"Patterns","text":""},{"location":"Management/SAPM/05_Technical_Analysis/#psychological-barriers","title":"Psychological barriers","text":"<p>Support &amp; resistance levels</p> <ul> <li>Bargain hunters \u201csupport\u201d the lower level upwards</li> <li> <p>Profit takers \u201cresist\u201d the upper level downwards</p> </li> <li> <p>Breakout: prices go outside the support/resistance level</p> </li> <li>Pullback: prices return within support/resistance level</li> </ul> <p></p>"},{"location":"Management/SAPM/05_Technical_Analysis/#patterns_1","title":"Patterns","text":"Pattern Trend Signal Head &amp; Shoulders Uptrend Bearish(reversal) Inverted head &amp; shoulders Downtrend Bullish(reversal) Symmetric triangle Uptrend Bullish Symmetric triangle Downtrend Bearish Ascending triangle Uptrend Bullish Rectangle Uptrend Bullish Rectangle Downtrend Bearish Flag Uptrend Bullish Flag Downtrend Bearish Pennant Uptrend Bullish Pennant Downtrend Bearish Cup &amp; Handle Bullish Inverted Cup &amp; Handle Bearish"},{"location":"Management/SAPM/05_Technical_Analysis/#momentumoscillator","title":"Momentum/Oscillator","text":"<p>Measures the velocity of price move</p> Indicates Formula MACDMoving Averages Convergence Divergence Trend-Deviation \\(\\dfrac{\\text{Faster EMA}}{\\text{Slower EMA}}\\)or\\(\\text{Faster EMA} - \\text{Slower EMA}\\) Signal EMA of MACD RSIRelative Strength Index Buying/selling ratio\\(\\text{RSI} &gt; 0.70 \\implies\\) Overbought\\(\\text{RSI} &lt; 0.30 \\implies\\) Oversold \\(\\dfrac{\\text{RS}}{1+\\text{RS}}\\)\\(\\text{RS} = \\dfrac{\\text{Avg(gains)}_w}{\\text{Avg(losses)}_w}\\)where \\(w=\\) window size"},{"location":"Management/SAPM/06_Portfolio/","title":"Portfolio","text":"<p>Pool of securities combined such that</p> <ul> <li>Maximizes expected returns</li> <li>Minimizes unsystematic risk</li> </ul> <p>Concept of hedging</p> <p>Try to diversify on all 4 pillars of GEIC</p>"},{"location":"Management/SAPM/06_Portfolio/#aspects","title":"Aspects","text":"<ul> <li>What set of securities to be selected</li> <li>What proportions</li> <li>Selection of optimum portfolio</li> </ul>"},{"location":"Management/SAPM/06_Portfolio/#characteristics","title":"Characteristics","text":"<p>Let \\(w_i\\) be the fraction of investment allocation to security \\(i\\)</p> <ul> <li>\\(w_i \\in [0, 1]\\)</li> <li>\\(\\sum_i w_i = 1\\)</li> <li>\\(w_i&lt;0 \\implies\\) Taking loan?</li> </ul> <p>Note: We assume Gaussian distribution of returns for all securities. If violated, then analyze accordingly $$ \\begin{aligned} E[R_p] &amp;= \\sum_i^n w_i R_i \\</p> <p>\\sigma^2_{R_p} &amp;= \\sum_i^n (w_i \\sigma_i)^2 + 2 \\sum_{i=1}^{\\lceil n/2 \\rceil} \\sum_{j&gt;i}^n w_i w_j \\sigma_i \\sigma_j \\rho_{ij} \\ \\beta_p &amp;= \\sum_i^n w_i \\beta_i \\end{aligned} $$</p> <p>where</p> <ul> <li>\\(\\rho_{ij} =\\) correlation between 2 securities \\(i\\) and \\(j\\)</li> <li>\\(\\beta_i =\\) \\(\\beta\\) of security \\(i\\)</li> <li>Given +ve portfolio weights on 2 shares, the lower the correlation between them, the lower the variance of the portfolio</li> </ul>"},{"location":"Management/SAPM/06_Portfolio/#minimum-variance-portfolio","title":"Minimum Variance Portfolio","text":"<p>A portfolio of group of shares that minimizes the return variance is the portfolio that has equal variance with every share return $$ w^* = \\arg \\min \\sigma^2_{R_p} \\ \\implies w^* = w   @   \\dfrac{d \\sigma^2_{R_p}}{dw} = 0 $$</p>"},{"location":"Management/SAPM/06_Portfolio/#2-securities","title":"2 Securities","text":"\\[ \\begin{aligned} w^* &amp;= (w_1^*, 1-w_1^*) \\\\ w_1^* &amp;= \\dfrac{\\sigma_2^2 - \\sigma_1 \\sigma_2 \\rho_{12}}{\\sigma_1^2 + \\sigma_2^2 - 2 \\sigma_1 \\sigma_2 \\rho_{12}} \\end{aligned} \\]"},{"location":"Management/SAPM/06_Portfolio/#types-of-portfolios","title":"Types of Portfolios","text":"Value-Weighted"},{"location":"Management/SAPM/06_Portfolio/#benchmark","title":"Benchmark","text":"<ul> <li>60% Equity, 40% Bonds</li> </ul>"},{"location":"Management/SAPM/06_Portfolio/#india","title":"India","text":"<p>Nifty50 makes a 12% average return, but actually, entire pool of Indian stock market makes a negative return</p> <p>Retail investors lose money due to single-stock investment</p> <p>Exane, Expose</p>"},{"location":"Management/SAPM/06_Portfolio/#structural-break","title":"Structural Break","text":"<p>When a crisis hits, most assets quickly tend to correlations close to 1</p>"},{"location":"Management/SAPM/07_Portfolio_Theory/","title":"Portfolio Theory","text":"<p>Shouldn't it be performed on forecasted time series?</p>"},{"location":"Management/SAPM/07_Portfolio_Theory/#markowitz-theory","title":"Markowitz Theory","text":"<p>Naive diversification of portfolio may/may not decrease risk</p> <p>Markowitz: Nature and degree of covariates between securities determine whether portfolio risk can be reduced</p> <p>Diversification pays when the securities have negative correlation</p>"},{"location":"Management/SAPM/07_Portfolio_Theory/#contributions","title":"Contributions","text":"<ol> <li>Quantification of risk &amp; return</li> <li>Efficient portfolio</li> </ol>"},{"location":"Management/SAPM/07_Portfolio_Theory/#efficient-set","title":"Efficient Set","text":"<p>A set of portfolios is called efficient set, if all the portfolios in it are non-dominated portfolios in terms of mean-variance dominance principle</p>"},{"location":"Management/SAPM/07_Portfolio_Theory/#mean-variance-dominance-principle","title":"Mean-Variance Dominance Principle","text":"<p>A portfolio A dominates portfolio B if</p> <ul> <li>For given risk, portfolio A has higher expected return</li> <li>For given expected return, portfolio A has same/lower risk</li> </ul>"},{"location":"Management/SAPM/07_Portfolio_Theory/#efficient-frontier","title":"Efficient Frontier","text":""},{"location":"Management/SAPM/07_Portfolio_Theory/#mean-variance-analysis","title":"Mean-Variance Analysis","text":"\\[ \\text{Obj}_\\max = E[R_p] - \\lambda \\sigma^2_{R_p} \\]"},{"location":"Management/SAPM/07_Portfolio_Theory/#limitations","title":"Limitations","text":"Limitation Solution Variance is not ideal risk measurement since it penalizes both unwanted high losses and desired low losses Semi-deviationVaR, CVaR Sensitive to estimated parameters \\(\\mu\\) and \\(\\sigma\\) Robust optimization"},{"location":"Management/SAPM/07_Portfolio_Theory/#diversification-reduction-of-dispersion","title":"Diversification &amp; Reduction of Dispersion","text":"<p>Shows how naive diversification reduces discretion of returns in a stock portfolio</p> \\(\\text{Risk} \\propto \\dfrac{1}{\\text{no of securities}}\\) \\(\\text{Marginal Risk Reduction} = -k\\) Diminishing reduction with no of securities 15-20 securities found to be the most appropriate"},{"location":"Management/SAPM/07_Portfolio_Theory/#sharpes-single-factorindex-model","title":"Sharpe\u2019s Single Factor/Index Model","text":"<p>Linear relation between return of a security and the market index, in the absence of risk-free asset $$ R_i = \\alpha + \\beta R_m + \\epsilon $$</p> <ul> <li>\\(\\beta=\\) systematic risk</li> <li>\\(\\alpha=\\) return independent of market</li> </ul>"},{"location":"Management/SAPM/07_Portfolio_Theory/#capital-market-line","title":"Capital Market Line","text":"<p>Upon introduction of Risk-Free Asset, Efficient frontier becomes a straight line rising from risk-free rate and tangential to Markowitz Efficient Frontier, called Capital Market Line</p> <p></p> <ul> <li>Lending portfolio: Portfolio where risk-averse investors in low risk assets</li> <li>Borrowing portfolio: Portfolio where risk-tolerant investors borrow at risk-free rate and invest in risky assets</li> </ul> <p>Consists of efficient portfolios constructed by combining risk-free security and market portfolio</p> <p>Represents equilibrium in the capital market. It does not show the relationship between expected rate of return of asset with individual risk</p> <p>All portfolios on CML are perfectly correlated with market portfolio and hence they are completely diversified, and hence possess no unsystematic risk; the portfolio that the investor should pick depends on the risk tolerance</p> <p>The slope of the CML gives the Sharpe Ratio of the market portfolio</p> \\[ E(R_p) = R_f + \\left[ \\dfrac{R_m-R_f}{\\sigma_m} \\right ] \\sigma_p \\]"},{"location":"Management/SAPM/07_Portfolio_Theory/#systematic-risk-principle","title":"Systematic Risk Principle","text":"<p>In an equilibrium situation, the market will price only systematic risk</p> <p>Hence, expected return on asset only depends on systematic risk</p>"},{"location":"Management/SAPM/07_Portfolio_Theory/#capital-asset-pricing-model","title":"Capital Asset Pricing Model","text":""},{"location":"Management/SAPM/07_Portfolio_Theory/#assumptions","title":"Assumptions","text":"<ul> <li>Investments judged only on associated risk and return</li> <li>Investors</li> <li>maximize expected utility determined on associated risk and return</li> <li>rational</li> <li>risk-averse</li> <li>Markowitz efficient</li> <li>have same holding time horizon as others</li> <li>can have unlimited borrowing and lending at risk-free rate</li> <li>Market</li> <li>perfectly-competitive</li> <li>frictionless<ul> <li>no transaction cost</li> <li>no information cost</li> </ul> </li> <li>Capital market is in equilibrium</li> <li>Capital assets are perfectly divisible</li> </ul>"},{"location":"Management/SAPM/07_Portfolio_Theory/#sml","title":"SML","text":"<p>Linear relationship between \\(E[R_i]\\) vs \\(\\beta_i\\) $$ E[R_i] = R_f + \\left[ \\dfrac{R_m-R_f}{\\beta_m} \\right ] \\beta_i $$</p> <p>Isn\u2019t always \\(\\beta_m = 1\\)</p> \\(R_i &gt; E[R_i]\\) underpriced \\(R_i &lt; E[R_i]\\) overpriced \\(\\beta_i &gt; 1\\) aggressive \\(\\beta_i &lt; 1\\) defensive <p>Slope is the Treynor Ratio</p> <p></p>"},{"location":"Management/SAPM/07_Portfolio_Theory/#arbitrage-pricing-theory","title":"Arbitrage Pricing Theory","text":"<p>Multi-factor pricing model, based on Arbitrage and Law of One Price</p> <p>Linear relationship between expected return of security and \\(\\beta\\)s of \\(k\\) factors</p> <p>Only sources of risk relevant in a security are systematic risk caused by \\(k\\) factors</p> <p>Breaks market risk into \\(k\\) components $$ E[R_i] = R_f + \\sum_{\\text{Factor: }j=1}^k \\Big( E[R_{j}] - R_f \\Big) \\beta_{ji} $$ These \\(k\\) factors could be</p> <ul> <li>Chen, Roll &amp; Ross</li> <li>Growth rate in industrial production</li> <li>Expected &amp; unexpected inflation rate</li> <li>Spread between long-term and short-term interest rates</li> <li>Spread between low-grade and high-grade bonds</li> <li>Fama &amp; French</li> <li>Firm size</li> <li>\\(\\dfrac{\\text{Book value}}{\\text{market value}}\\)</li> <li>Market portfolio</li> <li>Carhart: Fame &amp; French model + Momentum</li> </ul>"},{"location":"Management/SAPM/07_Portfolio_Theory/#arbitrage","title":"Arbitrage","text":"<p>Arbitrage opportunity arises when investor can earn risk-free profits without making net investment</p>"},{"location":"Management/SAPM/07_Portfolio_Theory/#law-of-one-price","title":"Law of One Price","text":"<p>If 2 assets are equivalent in all economically relevant aspects, they should have the same market price</p> <p>Enforced by arbitrageurs: if they observe any deviation, they engage in arbitrage and this will eliminate the opportunity</p>"},{"location":"Management/SAPM/07_Portfolio_Theory/#limitations_1","title":"Limitations","text":"<ul> <li>Does not suggest any optimum portfolio that is to be selected by investor</li> <li>Does not explain how investors decide investment portfolio</li> </ul>"},{"location":"Management/SAPM/07_Portfolio_Theory/#von-neumann-morgenstern-utility-theory","title":"Von Neumann-Morgenstern Utility Theory","text":"<ul> <li>Rational portfolio choice must apply preferences based on expected utility</li> <li> <p>Optimal portfolio solves the expected utility max problem</p> </li> <li> <p>Wealth after one period: \\(W = W_0 (1+R_p)\\)</p> </li> <li>Expected utility: \\(E[u(W)] = E[ \\ u \\Big( W_0(1+R_p) \\Big) \\ ]\\)</li> </ul>"},{"location":"Management/SAPM/07_Portfolio_Theory/#idk","title":"IDK","text":"<p>When diversifying, diversify for the worst-case (such as at the event of a crisis), not just in the best-case/average-case</p> <p>Idea - Minimize the correlation in the worst case     - returns should be uncorrelated/negatively correlated in worst-case - If we don't have data for the worst case     - Take a rolling correlation     - For every pair of security, the correlation is the highest correlation they ever had         - \\(r_{i,j} = \\max \\{ {r_{i, j}}_t \\vert t \\in [1, T] \\}\\)</p>"},{"location":"Management/SAPM/08_Portfolio_Evaluation/","title":"Portfolio Evaluation","text":"<ul> <li>Evaluation of portfolio as whole, without examining the individual securities.</li> <li>However, for portfolio revision, you need to examine the individual securities.</li> <li>Always perform evaluation using synthetic dataset (Gaussian Copula, Cholesky decomposition) to ensure portfolio will perform well in different possible scenarios</li> </ul>"},{"location":"Management/SAPM/08_Portfolio_Evaluation/#metrics","title":"Metrics","text":"Type Metric Comment Excess Inflation Adjusted Return \\(\\dfrac{1 + R_{P_{t_1, t_2}}}{1+\\pi_{t_1, t_2}} - 1\\)\\(\\pi_{t_1, t_2} = \\dfrac{\\text{CPI}_{t_2} - \\text{CPI}_{t_1}}{\\text{CPI}_{t_1}}\\) Return corrected for inflation Corrects for past, not necessarily indicative of future Jensen \\(\\alpha\\) \\(R_p - R_\\min\\) Excess return more than required Ratio Sharpe \\(\\dfrac{R_P - R_f}{\\sigma_p}\\) Price premium per unit risk Sortino \\(\\dfrac{R_P - R_f}{{\\sigma_\\text{semi}}_p}\\) Price premium per unit of downside risk Treynor \\(\\dfrac{R_P-R_f}{\\beta_P}\\) Price premium per unit \\(\\beta\\) Calmar \\(\\dfrac{R_p}{\\text{Max Drawdown}}\\) Sterling \\(\\dfrac{R_p}{\\text{Max Drawdown} - 10 \\%}\\) Omega \\(\\dfrac{P(\\text{gain}) \\times \\mu_\\text{gain}}{P(\\text{loss}) \\times \\mu_\\text{loss}}\\)\\(\\dfrac{R_p - R_f}{\\sum \\min \\{ w R_{pt} - R_f, 0 \\}}\\)"},{"location":"Management/SAPM/08_Portfolio_Evaluation/#drawdown","title":"Drawdown","text":"<p>Percentage peak-to-trough decline during a specific time period</p> <p>Measured once a new high is reached, because a minimum cannot be measured yet since the value could decrease further</p>"},{"location":"Management/SAPM/08_Portfolio_Evaluation/#sharpe-ratio","title":"Sharpe Ratio","text":""},{"location":"Management/SAPM/08_Portfolio_Evaluation/#limitations","title":"Limitations","text":"<p>Non-normality leads to under-estimating the variance in sharpe ratio estimate</p> <p></p> <p></p> <p>Selection bias of strategies results in false-positives regarding the success of a strategy</p> <p></p>"},{"location":"Management/SAPM/08_Portfolio_Evaluation/#non-normality-adjusted-sharpe-ratio","title":"Non-Normality Adjusted Sharpe Ratio","text":"\\[ \\hat \\sigma^2 (\\widehat {\\text{SR}}) = \\dfrac{1}{n-1} \\left( 1 - \\hat \\gamma_3 \\widehat {\\text{SR}} + \\dfrac{\\hat \\gamma_4 - 1}{4} \\widehat {\\text{SR}}^2 \\right) \\]"},{"location":"Management/SAPM/08_Portfolio_Evaluation/#deflated-sharpe-ratio","title":"Deflated Sharpe Ratio","text":"\\[ \\begin{aligned} \\text{DSR} &amp;= P(\\text{SR}^* \\le \\widehat {\\text{SR}} ) \\\\ &amp;= \\Phi \\left( \\dfrac{ \\text{SR}^* - \\widehat {\\text{SR}} }{\\hat \\sigma(\\widehat {\\text{SR}})} \\right) \\end{aligned} \\] <ul> <li>\\(\\text{SR}^* =\\) benchmark sharpe ratio</li> <li>\\(\\widehat{\\text{SR}} =\\) estimated sharpe ratio of portfolio</li> <li>\\(\\phi=\\) cdf of normal distribution</li> </ul> <p>Probability that SR is statistically-significant, after controlling for inflationary effect of</p> <ul> <li>No of independent trials with the strategy \\(k\\)</li> <li>List all the returns of all strategies</li> <li> <p>Find the independent series</p> </li> <li> <p>Data Dredging \\(V \\left[ \\widehat{\\text{SR}}_k \\right]\\)</p> </li> <li>Non-normality of returns: \\(\\hat y_3, \\hat y_4\\)</li> <li>Length of time series \\(T\\)</li> </ul> <p>Can help identify if the benefits is due to chance</p>"},{"location":"Management/SAPM/09_Fund_Management_Evaluation/","title":"Fund Management Evaluation","text":""},{"location":"Management/SAPM/09_Fund_Management_Evaluation/#metrics","title":"Metrics","text":"Metric Formula Meaning Net Selectivity Measure\\(R_r\\) \\(R_P - (R_f+R_S+R_U)\\) Excess return obtained solely through portfolio optimization Expense Ratio \\(\\dfrac{\\text{Total Expenses}}{\\text{Net Assets}}\\) Portfolio Turnover Ratio \\(\\dfrac{\\min(\\text{Purchases}, \\text{Sales})}{\\text{Assets}}\\) How quickly securities in fund are bought/sold by fund manager Tracking Error \\(\\sigma(R_P-R_B)\\) How well portfolio tracks the benchmark"},{"location":"Management/SAPM/09_Fund_Management_Evaluation/#famas-decomposition-of-total-return","title":"Fama\u2019s Decomposition of Total Return","text":"\\[ R_P = R_f + R_s + R_u + R_r \\] \\(R_s\\) Return from systematic risk \\((R_m-R_f) \\beta_P\\) \\(R_u\\) Return from unsystematic risk \\((R_m-R_f)  \\left(\\dfrac{\\sigma_P}{\\sigma_m} - \\beta_P \\right)\\) \\(R_r\\) Residual return/Net Selectivity Measure"},{"location":"Management/SAPM/09_Fund_Management_Evaluation/#expense-ratio","title":"Expense Ratio","text":"Type Typical \\(\\%\\) Active \\([0.50, 0.75]\\) Passive \\([0.02, 0.20]\\) <p>Fund with a smaller amount of assets has high expense ratio due to limited funds for covering costs</p> <p>International funds may have high operational expenses due to staffing in multiple countries</p>"},{"location":"Management/SAPM/09_Fund_Management_Evaluation/#portfolio-turnover-ratio","title":"Portfolio Turnover Ratio","text":"<p>Funds with high PTR will tend to have higher fees to reflect turnover costs</p> <p>However, high PTR tends to translate higher overall returns, thus mitigating the impact of additional fees</p>"},{"location":"Management/SAPM/09_Fund_Management_Evaluation/#goals-for-fund-manager","title":"Goals for Fund Manager","text":"<ul> <li>Minimize \\(\\beta\\)</li> <li>Maximize \\(\\alpha\\)</li> <li>Minimize \\(\\text{ER}\\)</li> <li>Maximize \\(R_r\\)</li> </ul>"},{"location":"Management/SAPM/99_IDK/","title":"Triple Barrier","text":""},{"location":"Management/SAPM/99_Portfolio_Optimization/","title":"Portfolio Optimization","text":""},{"location":"Management/SAPM/99_Portfolio_Optimization/#key-words","title":"Key Words","text":"Delta Relationship of whole book to underlying stock(1<sup>st</sup> derivative of something) Gamma Change of the portfolio(1<sup>st</sup> derivative of delta) Theta How trading book is carrying/bleeding away money, when nothing changes in market/position Vega/Kappa Book/Portfolio/Positions\u2019s sensitivity to volatility OTC Over The Counter"},{"location":"Management/SAPM/99_Portfolio_Optimization/#variables","title":"Variables","text":"Variable Meaning Interest rate sensitivity Equity exposure Commodity exposure Credit Distribution/Linearity of price behavior Regularity of cash flow/prepayment Correlation across sectors &amp; classes"},{"location":"Management/SAPM/99_Portfolio_Optimization/#variance-of-portfolio","title":"Variance of Portfolio","text":"<p>If the portfolio has one unit of each security whose prices are tracked in the Covariance matrix, the portfolio variance is the sum of the items in the covariance matrix.</p> <p>If set of positions \\(X=\\{ x_1, x_2, \\dots \\}\\), then the variance of the portfolio is given by \\(\\hat \\sigma_p^2 = X' \\text{Cov}_{XX}  X\\)</p>"},{"location":"Management/SAPM/99_Portfolio_Optimization/#index-trackingbenchmark-replication","title":"Index Tracking/Benchmark Replication","text":"<p>Portfolio compression strategy aimed at mimicking the risk/return profile of a financial instrument, by focusing on a reduced basket of representative assets</p> <p>Intuitively similar to L1 regularization $$ \\begin{aligned} \\text{Tracking error TE}(w) &amp;= {\\vert\\vert r_b - Xw \\vert\\vert}_2 \\ \\implies \\min \\text{TE}(w) &amp; + \\lambda {\\vert\\vert w \\vert\\vert}_0 \\end{aligned} $$ where</p> <ul> <li>\\(r_b \\in R^T\\) : returns of benchmark instrument in the past T days</li> <li>\\(X = [r_1, \\dots r_T]^T \\in R^{T \\times N}\\) : returns of \\(N\\) stocks in the past T days</li> </ul>"},{"location":"Management/SAPM/99_Portfolio_Optimization/#pairs-trading-portfolio","title":"Pairs Trading Portfolio","text":"<p>Spread \\(z_t = y_{1t} - \\gamma y_{2t}\\) with weights \\(w = \\begin{bmatrix} 1 \\\\ -\\gamma \\end{bmatrix}\\)</p> <p>Use VECM modelling of the universe of stocks</p> <p>From the parameter \\(\\beta\\) contained in the low-ranked matrix \\(\\Pi = \\alpha \\beta^T\\), one can simply use any/all column(s) of \\(\\beta\\)</p> <p>\\(\\beta\\) defines a co-integration subspace and we can then optimize the portfolio within that con integration subspace</p>"},{"location":"Management/SAPM/99_Portfolio_Optimization/#conversion-from-yield-to-price","title":"Conversion from Yield to Price","text":"<p>Fixed-income securities (such as bonds) trade as yield (ROI) $$ \\text{Price} = \\text{PV01} \\cdot \\text{Close} \\cdot 100 $$ \u201cPV01\u201d of a portfolio of assets is the sensitivity of the total scheme assets to a one basis point (or 0.01 per cent) change in interest rates</p>"},{"location":"Management/SAPM/99_Portfolio_Optimization/#duration-vs-dv01","title":"Duration vs DV01","text":"Duration DV01 Measures Measures the weighted average time to a security's cash flows, where the weighting is the cash flow. Signifies Also shows the % change in price per change in yield Shows the % change in price per 1million of face value Preferred for Equities Fixed-Income Securities <p>Either measure is fine, but be mindful of units</p>"},{"location":"Management/SAPM/99_Portfolio_Optimization/#spread-pv01","title":"Spread PV01","text":"<p>For credit-risky securities, we should distinguish b/w interest rate risk &amp; credit risk</p> <p>Credit spread takes default (and recovery) into consideration</p> <p>If recovery = 0, PV01 = CSPV01</p> <p>Different sources of spread</p> <ul> <li>Calculated</li> <li>CDS</li> <li>Asset Swap Spreads</li> </ul> <p></p> <p>Larger the credit spread, higher the probability of credit defaults</p>"},{"location":"Management/SAPM/99_Portfolio_Optimization/#game-theory","title":"Game Theory","text":"<p>When designing your portfolio, you need to incorporate external factors and others\u2019 ideas as well (kinda like Game Theory)</p>"},{"location":"Management/SAPM/99_Portfolio_Optimization/#kelly-criterion","title":"Kelly Criterion","text":""},{"location":"Management/SAPM/99_Portfolio_Optimization/#simulation-for-optimization","title":"Simulation for Optimization","text":"<ul> <li> <p>Simulate the validation prices series</p> </li> <li> <p>Even a simple AR(1) is fine</p> </li> <li> <p>Naive Benchmark</p> </li> <li> <p>Buy if expected log return &gt; \\(k \\sigma_0\\)</p> </li> <li>Sell if expected log return &lt; \\(-k \\sigma_0\\)</li> <li> <p>Flatten, otherwise</p> </li> <li> <p>Find trading parameters that</p> </li> <li> <p>maximizes the average Sharpe Ratio over all simulated price series</p> <ul> <li>\\(\\implies\\) Solving HJB Equation</li> </ul> </li> <li> <p>or</p> <p>maximizes the average Sharpe Ratio over all simulated series</p> <ul> <li>\\(\\implies\\) Solving MLE</li> </ul> </li> </ul> <p></p>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/","title":"Regularized Pricing &amp; Risk Models","text":"<p>https://www.youtube.com/watch?v=aga-Tak3c3M&amp;list=PLUl4u3cNGP63ctJIEC1UnZ0btsphnnoHR</p>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#bond-duration","title":"Bond Duration","text":"<p>Sensitivity of bond price \\((\\ln P)\\) to bond yield \\(y\\)</p> <ul> <li>Duration gives the \u201cweighted time\u201d</li> <li>Duration of zero coupon bond = maturity</li> <li>Duration of regular coupon bond &lt; maturity</li> <li>As there is only a fixed \\(y\\) for all payment dates, the duration is a sensitivity to \u201cparallel\u201d move</li> </ul> <p>Good measure for price changes for small variation in yield</p> <p>Second derivative required for large changes in yield</p> <p>$$ \\begin{aligned} P &amp;= \\sum \\limits_{i=1}^n e^{-y t_i} C_i \\ P_y &amp;= \\dfrac{\\partial P}{\\partial y}= - \\sum \\limits_{i=1}^n t_i e^{-y t_i} C_i \\ \\implies d &amp;= \\dfrac{P_y}{P} \\ c &amp;= \\dfrac{\\partial^2 P}{\\partial y^2} = \\sum \\limits_{i=1}^n t_i^2 e^{-y t_i} C_i \\ \\end{aligned} $$ where</p> <ul> <li>\\(d=\\) Bond Duration</li> <li>\\(c =\\) Bond convexity: Always positive</li> <li>\\(P=\\) price of bond</li> <li>\\(y=\\) yield of bond</li> <li>\\(C_i = i\\)th cashflow</li> </ul>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#swaps","title":"Swaps","text":"<p>Valuing fixed and float legs of the swap</p> <p>Swap can be hedged with bond $$ \\begin{aligned} \\text{PV}\\text{fixed} &amp;= \\sum_i C \\delta_i \\Alpha_i = C \\sum_i w_i \\ \\text{PV}\\text{float} &amp;= \\sum_i C r_i \\delta_i \\Alpha_i = \\sum_i r_i w_i \\ \\text{PV}\\text{fixed} &amp;= \\text{PV}\\text{float} \\ \\implies C &amp;= \\dfrac{\\sum_i r_i w_i}{\\sum_i w_i} \\end{aligned} $$ where</p> <ul> <li>\\(c =\\) swap rate (fixed leg coupon)</li> <li>Weighted sum of forward rates (assuming same frequency of payments of fixed &amp; floating legs)</li> <li>\\(\\Alpha_i =\\) discount factor for payment date \\(i\\)</li> <li>\\(\\delta_i =\\) day count fraction</li> <li>\\(r_i =\\) forward rate (floating rate of future payment)</li> </ul>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#yield-curve","title":"Yield Curve","text":"<ol> <li>Select input instruments</li> <li>Choose interpolation</li> <li>Interpolation space (daily forward rates, zero rates, etc)</li> <li>Spline (piece-wise constant, linear, tension spline, etc)</li> <li>Knot points and model parameters</li> <li>Calibrate</li> <li>Solve for spline parameters such that input instruments are re-priced at par</li> </ol>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#bond-spread","title":"Bond Spread","text":"\\[ P= \\sum_{i=1}^n e^{-s t_i} \\Alpha_i C_i \\] <p>where</p> <ul> <li>\\(\\Alpha_i =\\) discount factor for payment date \\(i\\) computed from curve</li> <li>\\(s=\\) bond spread</li> <li>\\(t_i =\\) future time of payment in years</li> <li>\\(C_i = i\\)th cashflow</li> </ul> <p>If the model is available for typical movements of the curve embedded in \\(\\Alpha_i\\) we can build more effective risk model for bond, rather than using single \u201cparallel\u201d shift mode (bond duration)</p>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#hedging","title":"Hedging","text":"\\[ x = \\arg \\min {\\left \\vert \\left \\vert F^T (r + Hx ) \\right \\vert \\right \\vert}^2 \\] <p>where</p> <ul> <li>\\(r =\\) portfolio risk</li> <li>\\(H =\\) hedging portfolio risks</li> <li>\\(x =\\) weights of hedging instruments</li> <li>\\(F =\\) market scenarios (factors)</li> </ul>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#pca","title":"PCA","text":"<p>Use SVD to decompose market movements data \\(D\\) into principal comments \\(P\\) and corresponding uncorrelated market dynamics \\(U\\) with weights \\(S\\) $$ D = U \\cdot S \\cdot P^T $$ Use few SVD components with largest singular values - low rank approximation of market data $$ P^T (r + Hx) = 0 $$</p>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#pca-risk-model","title":"PCA Risk Model","text":"<p>\u201cFormally\u201d tuned to historical data</p> <p>Hedge coefficients are unstable, especially if historical window is short</p> <p>Costly to re-hedge when PC factors change</p> <p>Instability is coming from PCs corresponding to small singular values</p> <p>Over-fitting to historical data</p> <p>NO assumptions of shape of yield curve</p>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#regularized-risk-models","title":"Regularized Risk Models","text":"<p>Assumption: Forward rates move smoothly $$ H^T R = I \\ {\\vert \\vert L \\cdot J \\cdot R \\vert \\vert}^2 \\to \\min \\ R \\sim \\Big(HH^T + \\lambda^2 (L \\cdot J)^T \\cdot L \\cdot J \\Big)^{-1} $$ where</p> <ul> <li>\\(J =\\) Jacobean matrix translating shifts of yield curve inputs to movements of forward rates</li> <li>\\(L=\\) Smoothness regularity matrix</li> <li>\\(\\lambda =\\) regularization parameter</li> </ul>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#pricing-model","title":"Pricing Model","text":""},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#hjm-heath-jarrow-morton-model","title":"HJM Heath-Jarrow-Morton Model","text":"<p>Evolution of forward rates $$ {df}{t, s} = \\mu^\\beta V(t, s) \\rho (t, s) \\cdot dB_t^Q $$ where} dt + f_{t, s</p> <ul> <li>\\(f =\\) forward rate</li> <li>\\(\\mu=\\) drift</li> <li>\\(\\beta=\\) model skew factor</li> <li>\\(\\rho=\\) Correlation/factor structure</li> <li>\\(V(t, s)=\\) parametric volatility surface</li> <li>\\(d B_t^Q =\\) Brownian motion</li> </ul>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#regularized-volatility-surface","title":"Regularized Volatility Surface","text":""},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#challenges","title":"Challenges","text":"<ul> <li>High dimensionality</li> <li>Need to calibrate many elements</li> <li>Large memory requirement to store matrix</li> <li>Relatively small number of calibration instruments</li> <li>Under-determined problem</li> <li>Sensitivity areas of calibration instruments overlap significantly</li> <li>Ill-posed inverse problem</li> <li>Unstable, noisy solution</li> <li>Need regularity conrtaints</li> <li>Has to be smooth to produce realistic prices for similar instruments</li> </ul>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#idk","title":"IDK","text":"<p>Represent volatility surface as linear combination of \\(n\\) basis functions $$ v = v_0 + \\beta x $$ where</p> <ul> <li>\\(v =\\) vector of volatility grid elements</li> <li>\\(\\beta=\\) matrix corresponding to basis functions</li> <li>\\(x=\\) vector of weights</li> </ul> <p>Make \\(n\\) equivalent to number of calibration instruments \\(M\\)</p> <p>\u201cFormally\u201d unambiguous</p> <p>Make basis functions piecewise constant matching sensitivity of calibration instruments, 0 otherwise</p>"},{"location":"Management/SAPM/99_Regularized_Pricing_and_Risk_Models/#sensitivities","title":"Sensitivities","text":"\\[ \\begin{aligned} J_{ij} &amp;= \\dfrac{\\partial q_i}{\\partial x_j} \\\\ q &amp;= J \\cdot x \\\\ &amp;= \\ln \\dfrac{q_{mdl}}{q_0} \\\\ q_\\text{in} &amp;= \\ln \\dfrac{q_\\text{market}}{q_0} \\end{aligned} \\] <p>where</p> <ul> <li>\\(q_{mdl} =\\)  model price</li> <li>\\(q_\\text{market} =\\)  market price</li> <li>\\(q_0 =\\) base price</li> <li>\\(x=\\) vector basis functions coefficients</li> </ul>"},{"location":"Management/Sales/","title":"Sales","text":""},{"location":"Management/Sales/#references","title":"References","text":"<ul> <li> Strategic Sales Management | IITR</li> </ul>"},{"location":"Management/Strategy/","title":"Strategy","text":""},{"location":"Management/Strategy/#references","title":"References","text":"<ul> <li> STRAT 422 - Advanced Strategy Analytics | BYU</li> <li> Strategic Management | Tim Blumentritt | Kennesaw State University</li> <li> Business Analysis for Engineers | IIT</li> <li> Strategic Management | IIT Roorkee</li> <li> Strategic Management | IIS Bengaluru</li> <li> Business Strategy | MeanThat</li> <li> Business Strategy Lecture | Ajarn Olli</li> <li> Corporate Strategy | Pontema</li> <li> Strategic Services Marketing | IIT Roorkee</li> <li> Series C Growthonomics | Aryng</li> <li> Strategic Planning | BSC Designer</li> <li> Business Strategy | Ajarn Olli</li> <li> Strategy | David Kryscynski</li> </ul>"},{"location":"Management/Strategy/01_Introduction/","title":"Introduction","text":""},{"location":"Management/Strategy/01_Introduction/#strategy","title":"Strategy","text":"<p>Actions required to get from current position to intended position</p>"},{"location":"Management/Strategy/01_Introduction/#tiers-of-planning","title":"Tiers of Planning","text":"Tier Scope &amp; Duration Level Meaning Military Analogy 1 Strategic Large Corporate/Political Why Business/Military When &amp; where Business Vertical 2 Operational Medium Campaign Series of battles Operational 3 Tactical Small Major Battle Minor Standards &amp; Procedures Engagement Technical Tools &amp; Techniques Armor, Cavalry <p>Strategy without tactics is the slowest way to win a war; Tactics without strategy is the noise before defeat.</p>"},{"location":"Management/Strategy/01_Introduction/#idk","title":"IDK","text":"<p>Shifting mental models</p> <ul> <li>Don't just think outside the box, doubt the box itself</li> <li>Pursue a range of inputs</li> <li>Frame the question effectively</li> <li>Outline binding constraints and criteria for success</li> <li>Allow sufficient time to select ideas</li> </ul> <p>Brainstorming</p> Before After Frame question clearly A good question for brainstorming will be narrow and concrete, so that people feel they know how to begin answering it How could we sell more outerwear this winter season? - What specific marketing strategies could we use to increase outerwear sales by 10% this winter?- How can we optimize our online store to make outerwear more appealing and accessible to customers during the winter season?- What new outerwear products or collaborations could we introduce to attract more customers and boost sales this winter? Create creativity conditions Reveal &amp; doubt boxes Relevant BoxesWhat boxes currently exist that are still relevant?1. Seasonal Demand for Outerwear: Winter is a peak time for outerwear sales, as customers actively seek warm, functional clothing2. Online Shopping Trends: Consumers increasingly prefer shopping online, especially during winter months when weather conditions may discourage in-store visits.3. Sustainability Appeal: Many customers value eco-friendly and sustainable outerwear options, making this a key selling point that remains relevant. Boxes to Doubted1. Traditional Retail Dominance: The assumption that brick-and-mortar stores are the primary sales channel may need to be reconsidered due to the rise of e-commerce.2. Heavy Reliance on Discounts: While discounts drive sales, relying solely on price cuts may erode brand value and profitability in the long term.3. Uniform Style Preferences: Assuming all customers prefer classic or traditional outerwear styles might overlook emerging trends like bold colors, unique designs, or tech-integrated apparel. Bring new boxes Sustainability and Circular Economy- Outerwear made from recycled materials- Buy-back programs for used outerwear- Repair and upcycling services for extending product lifeAssumptions- Environmental Consciousness: Consumers are increasingly prioritizing eco-friendly products and are willing to change their buying habits to support sustainable practices.- Value in Longevity: There's a growing appreciation for durable products that can be repaired or repurposed, challenging the \"fast fashion\" model.- Circular Economy Viability: The infrastructure and consumer mindset necessary for successful buy-back and recycling programs are developing rapidly. Brainstorm Follow up"},{"location":"Management/Systems_Engineering/","title":"Systems Engineering","text":"<p>Interdisciplinary field of engineering and engineering management that focuses on how to design, integrate, and manage complex systems over their life cycles</p>"},{"location":"Management/Systems_Engineering/#references","title":"References","text":"<ul> <li> Fundamentals of Systems Engineering | MIT</li> </ul>"},{"location":"Masters/GRE/","title":"GRE","text":"<ul> <li>https://www.dilipoakacademy.com</li> <li>https://ets.org/</li> <li>https://www.ets.org/gre/test-takers/general-test/prepare/powerprep.html</li> <li>https://www.gregmat.com</li> </ul>"},{"location":"Masters/GRE/#what-is-gre","title":"What is GRE?","text":"<p>Graduate Re Examination</p> <ul> <li>Math</li> <li>Verbal</li> <li>Writing</li> </ul>"},{"location":"Masters/GRE/#what-does-gre-test","title":"What does GRE test?","text":"<ul> <li>Critical thinking</li> <li>Accumulated knowledge</li> <li>Not IQ test</li> <li>Not inherent measure of intelligence</li> </ul>"},{"location":"Masters/GRE/#how-to-learn","title":"How to \u201clearn\u201d","text":"<ul> <li>Learning best approach</li> <li>Accurate prep material</li> <li>Practice</li> </ul>"},{"location":"Masters/GRE/#format","title":"Format","text":"Measure Section # of Qns Allotted Time(minutes) Analytical Writing 1 1(Analyze an Issue) 30 English 1 12 18 2 15 23 Math 1 12 21 2 15 26 Total 5 01:58 Math Problem-Solving Numeric EntryData InterpretationMCQsFive-Answer MCQ Quantitative Comparison English Text Completion One-BlankTwo-BlankThree-Blank Sentence Equivalence Reading Comprehension Paragraph Argument"},{"location":"Masters/GRE/#scoring","title":"Scoring","text":"Math 130-170 English 130-170 Essay 0-6"},{"location":"Masters/GRE/#adaptive","title":"Adaptive","text":"<ul> <li>Sections are adaptive</li> <li>Difficulty of second section adapts to performance on the first section</li> <li> <p>First section is always medium difficulty</p> </li> <li> <p>Questions are not adaptive</p> </li> </ul>"},{"location":"Masters/GRE/#practice","title":"Practice","text":"<ul> <li>https://ereg.ets.org/ereg/testPrep/viewEbooksSerives</li> </ul>"},{"location":"Masters/GRE/English/01_Vocabulary/","title":"Vocabulary","text":""},{"location":"Masters/GRE/English/01_Vocabulary/#types","title":"Types","text":"<ul> <li>Denotative: meaning</li> <li>Connotative: usage</li> </ul> <p>GRE requires connotative understanding</p>"},{"location":"Masters/GRE/English/01_Vocabulary/#tools","title":"Tools","text":"<ul> <li>wordnik.com</li> <li>nytimes.com</li> <li>dictionary.com</li> </ul>"},{"location":"Masters/GRE/English/01_Vocabulary/#idk","title":"IDK","text":"<ul> <li>Understand how words function</li> <li>Read &amp; study words as you learn</li> </ul>"},{"location":"Masters/GRE/English/01_Vocabulary/#tips","title":"Tips","text":"<ul> <li>Flashcards</li> <li>Don\u2019t use word lists: easy to memorize due to non-randomization</li> <li>Reading</li> <li>Active usage</li> <li>Grouping/association</li> <li>Vocabulary games</li> <li>Questions</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/","title":"Blanks","text":"<ol> <li>Read entire sentence</li> <li>Find clues/words/phrase in sentence</li> <li>Identify sentence type</li> <li>Look for keywords</li> <li>Come up with own words and match</li> <li>Eliminate options</li> <li>Do not be afraid to pick word you don\u2019t know</li> </ol> <p>Types</p> <ol> <li>Single</li> <li>Double</li> <li>Triple</li> </ol> <p>Types</p> <ul> <li>Single sentences</li> <li>Multiple sentences</li> <li>Dependent blanks</li> <li>Back-to-back blanks</li> <li>Other blank is the clue</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#no-shifts","title":"No Shifts","text":"<ul> <li>Likewise</li> <li>Infact</li> <li>indeed</li> <li>so</li> <li>Just as \u2026 so (too)</li> <li>Not only \u2026 but also</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#elaboration","title":"Elaboration","text":"<ul> <li>hyphen</li> <li>colon</li> <li>semi-colon</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#apposition","title":"Apposition","text":"<p>Two similar/related words (usually adjectives) follow one another</p> <p>Eg: \u201cpointed, even polemical\u201d</p>"},{"location":"Masters/GRE/English/02_Blanks/#cause-effect","title":"Cause-Effect","text":"<ul> <li>because</li> <li>given that</li> <li>as result of</li> <li>since</li> <li>therefore</li> <li>consequently</li> <li>thus</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#shifts","title":"Shifts","text":""},{"location":"Masters/GRE/English/02_Blanks/#reversal","title":"Reversal","text":"<ul> <li>Though</li> <li>Although</li> <li>Even though</li> <li>Despite</li> <li>Yet</li> <li>But</li> <li>However</li> <li>Notwithstanding</li> <li>Nonetheless</li> <li>Regardless</li> <li>Not without detractors</li> <li>Typically</li> </ul> <p>Types</p> <ul> <li>Single reversal</li> <li>Double reversal</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#time-shifts","title":"Time shifts","text":"<ul> <li>Once</li> <li>At first</li> <li>Then \u2026 now</li> <li>Initially</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#perception-shift","title":"Perception Shift","text":"<ul> <li>Since \u2026</li> <li>Only with</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#false-shift","title":"False shift","text":"<ul> <li>albeit</li> </ul>"},{"location":"Masters/GRE/English/02_Blanks/#sentence-equivalence","title":"Sentence Equivalence","text":"<p>2 answers </p> <p>Both will be synonyms</p>"},{"location":"Masters/GRE/English/03_Reading_Comprehension/","title":"Reading Comprehension","text":""},{"location":"Masters/GRE/English/03_Reading_Comprehension/#usual-topics","title":"Usual Topics","text":"<ul> <li>Social Sciences</li> <li>Sociology</li> <li>Psychology</li> <li>Business, Law, Government</li> <li>Hard Sciences</li> <li>Literature</li> <li>History</li> </ul>"},{"location":"Masters/GRE/English/03_Reading_Comprehension/#types-of-passages","title":"Types of passages","text":"Type Short Paragraph argument Short Critical reading Medium 20-40 lines Long 40+ lines"},{"location":"Masters/GRE/English/03_Reading_Comprehension/#types-of-questions","title":"Types of questions","text":"<ul> <li>Line summarizing the passage</li> <li>Meaning of certain word, in the context of the passage</li> <li>Replace the word with a blank and try to match it with the options</li> <li>Meaning of certain line, in the context of the passage</li> <li>Inference: Parallel reasoning</li> <li>Multiple correct answers (denoted with alphabet bulleted options)</li> <li>Select the sentence in the passage</li> <li>Which of the following options does the author imply?</li> </ul>"},{"location":"Masters/GRE/English/03_Reading_Comprehension/#tips","title":"Tips","text":"<ul> <li>Read actively</li> <li>Identify key words</li> <li>Read for general meaning</li> <li>Understand structure</li> <li>Eliminate wrong options</li> <li>Incorrect</li> <li>Out of scope</li> <li>Extreme</li> <li>Too many assumptions</li> <li>Rotten fruit: one/two words make the sensible part insensible</li> <li>Too broad/narrow</li> <li>True, but doesn\u2019t answer the question and hence is not relevant<ul> <li>True in the real world</li> <li>Pertains to another part of passage</li> </ul> </li> </ul>"},{"location":"Masters/GRE/English/03_Reading_Comprehension/#paragraph-argument","title":"Paragraph Argument","text":""},{"location":"Masters/GRE/English/03_Reading_Comprehension/#elements-of-argument","title":"Elements of argument","text":"<ul> <li>Premises = Facts</li> <li>Conclusion = Statement tying facts together</li> <li>Gap: Something that the conclusion does not take into account</li> </ul> <p>5 options</p>"},{"location":"Masters/GRE/English/03_Reading_Comprehension/#types-of-questions_1","title":"Types of questions","text":"<ul> <li>Weaken/casts the most doubt</li> <li>Strengthening</li> <li>Paradox argument</li> <li>Bold-faced</li> <li>Percentage vs Numbers: Likelihood</li> </ul>"},{"location":"Masters/GRE/English/03_Reading_Comprehension/#elimination-of-choices","title":"Elimination of choices","text":"<ul> <li>Irrelevant</li> <li>Opposite</li> </ul>"},{"location":"Masters/GRE/English/04_Writing/","title":"Writing","text":""},{"location":"Masters/GRE/English/04_Writing/#issue-task","title":"Issue Task","text":"<ul> <li>Directions</li> <li>Agree/Disagree</li> <li>Support your position</li> <li>Choose a side</li> <li>Concession point: Other side is also valid in some cases</li> </ul>"},{"location":"Masters/GRE/English/04_Writing/#topics","title":"Topics","text":"<ul> <li>Government &amp; Power</li> <li>Education</li> <li>Culture &amp; society</li> </ul>"},{"location":"Masters/GRE/English/04_Writing/#argument","title":"Argument","text":"<ul> <li>Introduction</li> <li>The argument is flawed for numerous reasons</li> <li>Body</li> <li>Focus on 3 logical fallacies</li> <li>Use a paragraph for each fallacy</li> <li>Strengthen argument<ul> <li>\u201cThe argument would have been stronger had it provided information regarding \u2026\u201d</li> </ul> </li> <li>Conclusion</li> </ul>"},{"location":"Masters/GRE/Math/Algebra/","title":"Algebra","text":"<ul> <li>Like terms: Terms with identical variables that can be added/subtracted</li> <li>Identities</li> <li>Factoring</li> <li>Quadratic formula</li> <li>\\(x = \\dfrac{-b \\pm \\sqrt{D}}{2a}, D=b^2 - 4ac\\)</li> <li>\\(D&lt;0 \\implies\\) no solution</li> <li>Simultaneous equations</li> <li>No soln: \\(0x+0y=k, k \\ne 0\\)</li> <li>Unique soln</li> <li>Infinitely-many solns: \\(0x+0y=0\\)</li> <li>Extraneous roots</li> <li>occur for<ul> <li>even exponents</li> <li>absolute value</li> </ul> </li> <li>Functions</li> <li>Defined in the question</li> <li>Custom operators</li> <li>Formula (area, volume, temp conversion)</li> <li>Inequalities</li> <li>Only adding inequalities always holds true<ul> <li>Hence, avoid sub, mul, div</li> </ul> </li> <li>Quadratic<ul> <li>Set expo to zero</li> <li>Find solutions</li> <li>Record on number line</li> <li>Test number on each region</li> <li>Solve inequality</li> </ul> </li> </ul> <p>Questions</p> <ul> <li>Age</li> <li>Distance</li> <li>Speed: Avg speed = total distance/total time</li> <li>Time</li> <li>Work</li> <li>Double matrix</li> <li>3 criteria Venn diagram</li> <li>Sequences</li> <li>Batch</li> <li>Recursive</li> <li>Sum of sequences</li> <li>Number of terms</li> <li>Exclusive: \\(x_2 - x_1\\)</li> <li>Inclusive: \\(x_2 - x_1+1\\)</li> <li>Growth/Decline</li> <li>Mixture</li> <li>Formula algebraic expressions</li> </ul>"},{"location":"Masters/GRE/Math/Arithmetic/","title":"Arithmetic","text":"<ul> <li>Real Numbers</li> <li>Integers</li> <li>Properties of</li> <li>Addition</li> <li>Subtraction</li> <li>Multiplication</li> <li>Division</li> <li>Operations with signed numbers</li> <li>PEDMAS</li> <li>Decimals</li> <li>10<sup>th</sup> Places</li> <li>Addition, Subtraction, Multiplication, Division</li> <li>Rounding up/down</li> <li>Fractions</li> </ul>"},{"location":"Masters/GRE/Math/Coordinate_Geometry/","title":"Coordinate Geometry","text":"<ul> <li>X-axis, Y-axis</li> <li>X coordinate, y coordinate</li> <li>Quadrants: 1, 2, 3, 4 in Anti-clockwise direction</li> <li>Distance between 2 points: Euclidean distance</li> <li>Lines</li> <li>Equation</li> <li>Slope</li> <li>Intercept</li> </ul>"},{"location":"Masters/GRE/Math/Counting/","title":"Counting","text":""},{"location":"Masters/GRE/Math/Counting/#fundamental-counting-principle","title":"Fundamental counting principle","text":"<p>No of ways \\(= n_1 \\times n_2 \\times \\dots\\)</p> <p>How many different \\(x\\) digit numbers can be created using \\(n\\) digits only: \\(y^x\\)</p>"},{"location":"Masters/GRE/Math/Counting/#factorial","title":"Factorial","text":"<p>\\(n\\) unique objects can be arranged in \\(n!\\) ways</p>"},{"location":"Masters/GRE/Math/Counting/#restrictions","title":"Restrictions","text":"<p>No of ways to follow rule = no of ways to ignore rule - no of ways to break rule</p>"},{"location":"Masters/GRE/Math/Counting/#duplicates","title":"Duplicates","text":"<p>When there are duplicate objects $$ \\begin{aligned} &amp;= \\dfrac{n!}{\\prod_i^k n_i!} \\end{aligned} $$ where </p> <ul> <li>\\(k=\\) no of unique groups</li> <li>\\(n_i =\\) no of objects in group \\(k\\)</li> <li>\\(\\sum_i^k n_i = n\\)</li> </ul>"},{"location":"Masters/GRE/Math/Counting/#permutation","title":"Permutation","text":""},{"location":"Masters/GRE/Math/Counting/#combination","title":"Combination","text":"<ul> <li>Order doesn\u2019t matter</li> <li>Outcomes of one stage are same as outcomes of other stages</li> </ul>"},{"location":"Masters/GRE/Math/Data_Interpretation/","title":"Data Interpretation","text":"<ul> <li>Graph</li> <li>Table</li> </ul> <p>Types of questions</p> <ul> <li>MCQ</li> <li>MCQ Multiselect</li> <li>Numeric entry</li> </ul> <p>Usually 1 set of data interpretation questions per quantitative section</p> <ul> <li>Grouped together</li> <li>All refer to same info source</li> </ul> <p>Topics</p> <ul> <li>Real-life math</li> <li>Statistics</li> <li>Percents</li> <li>Ratios</li> <li>Probability</li> <li>Interpretation</li> </ul> <p>Time allotment</p> Min Per question Quantitative comparison 1.25 MCQ 2 Numeric entry 2 Data interpretation 2"},{"location":"Masters/GRE/Math/Data_Interpretation/#strategy","title":"Strategy","text":"<ol> <li>Understand big picture</li> <li>Read any accompanying text</li> <li>Pay attention to units of measurement</li> <li>For graphics with axes<ol> <li>Read axis labels</li> <li>Check if axis starts at zero</li> <li>Check axis increment: linear/log</li> </ol> </li> <li>Identify trends/relationships<ol> <li>Spike/level out/cyclical</li> <li>One factor influences another</li> </ol> </li> <li>Read the question</li> <li>Check the units of question and units in data</li> <li>Check answer choices before performing calculations</li> <li>Indicate correct form of answer (fraction/decimal)</li> <li>Degree of accuracy</li> </ol>"},{"location":"Masters/GRE/Math/Data_Interpretation/#notes","title":"Notes","text":"<ul> <li>All visual graphics are drawn to scale</li> <li>Estimate whenever possible</li> <li>Do not confuse absolutes with rates/percents</li> </ul>"},{"location":"Masters/GRE/Math/Data_Interpretation/#diagrams","title":"Diagrams","text":"<ul> <li>Venn Diagram</li> <li>Scatter Plot: Correlation, Trend line</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/","title":"Geometry","text":"<ul> <li>Line</li> <li>Bisector: divide into 2</li> <li>Perpendicular bisector</li> <li>Transversal: passes through 2 || lines<ul> <li>All angles formed are equal due to VOA and AIA</li> </ul> </li> <li>Angle</li> <li>GRE only focuses on degrees<ul> <li>No need to learn radians</li> </ul> </li> <li>Vertically-opposite angles are equal</li> <li>Alternate interior angles are equal</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/#triangles","title":"Triangles","text":"<ul> <li>Vertices</li> <li>Angles add upto 180</li> <li>Edges</li> <li>Angles-Edges<ul> <li>Shortest edger oppo to smallest angle</li> <li>Longest edge oppo to largest angle</li> </ul> </li> <li>\\(\\vert a-b \\vert &lt; c &lt; (a+b)\\)</li> </ul> <p>Area = \\(\\dfrac{1}{2} bh\\)</p>"},{"location":"Masters/GRE/Math/Geometry/#isosceles","title":"Isosceles","text":"<ul> <li>2 equal angles</li> <li>2 equal edges</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/#equlaterial","title":"Equlaterial","text":"<ul> <li>3 equal angles: 60,60,60</li> <li>3 equal edges</li> </ul> <p>Area = \\(\\dfrac{\\sqrt{3}}{4} a^2\\)</p> <p>Altitudes of isosceles and equilateral triangles always bisect the base</p>"},{"location":"Masters/GRE/Math/Geometry/#right-triangle","title":"Right-Triangle","text":"<ul> <li>Pythagorean theorem: \\(a^2+b^2 = c^2\\)</li> <li> <p>Pythagorean triplet: Set of 3 integers that can be the sides of a right triangle</p> <ul> <li>Common</li> <li>3-4-5</li> <li>5-12-13</li> <li>8-15-17</li> <li>7-24-25</li> <li>Multiple of triples is also a triple</li> <li>2 corresponding sides are required for a triple</li> </ul> </li> <li> <p>45-45-90: \\(x, x, x \\sqrt{2}\\)</p> </li> <li>Hiding in squares</li> <li>30-60-90: \\(x, x\\sqrt{3}, 2x\\)</li> <li>Hiding in equilateral triangle</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/#similar-triangles","title":"Similar Triangles","text":"<p>All three angles are equal</p> <p>Ratio of any pair of corresponding sides is the same</p>"},{"location":"Masters/GRE/Math/Geometry/#quadrilaterals","title":"Quadrilaterals","text":"<p>4 edges</p> <p>Angles add upto 360 deg</p> <ul> <li>Parallelogram</li> <li>Opposite sides are parallel</li> <li>Opposite sides are equal</li> <li>Opposite angles are equal</li> <li>Rhombus</li> <li>Parallelogram with equal edges</li> <li>Diagonals are perpendicular bisectors</li> <li>\\(\\dfrac{1}{2} d_1 d_2\\)</li> <li>Rectangle</li> <li>Parallelogram with all angles 90</li> <li>Diagonals are equal length</li> <li>Square</li> <li>Rectangle with equal edges</li> <li>Diagonals are perpendicular bisectors</li> <li>Diagonals are equal length</li> <li>Trapezoid/Trapezium</li> <li>1 pair of parallel edges</li> <li>\\(\\dfrac{1}{2}h(a+b)\\)</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/#polygons","title":"Polygons","text":"<p>Sum of angles of polygon with \\(n\\) edges = \\(180(n-2)\\)</p> <p>Convex polygon: all interior angles &lt; 180</p> <ul> <li>Pentagon: angles add up to 540</li> <li>Hexagon: angles add up to 720</li> </ul> <p>Regular polygon: equal sides and equal angles</p>"},{"location":"Masters/GRE/Math/Geometry/#circles","title":"Circles","text":"<ul> <li>center</li> <li>radius</li> <li>Chord: line segment passing connecting 2 points of circumference</li> <li>diameter: chord passing through center</li> <li>Arc</li> <li>Minor arc</li> <li>Major arc</li> <li>Sector</li> <li>Circumference: \\(2 \\pi r\\)</li> <li>Area: \\(\\pi r^2\\)</li> </ul> <p>Properties</p> <ul> <li>Inscribed angles on the same side of a chord/arc held are equal</li> <li>Inscribed angles holding  chord/arc of equal lengths are equal</li> <li>Inscribed angles holding diameter is 90deg</li> <li>Central angle is 2 x inscribed angle holding the same chord/arc</li> <li>Radius \\(\\perp\\) tangent at the point of intersection</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/#volume","title":"Volume","text":"<ul> <li>Cube: \\(a^3\\)</li> <li>Cuboid: \\(lbh\\)</li> <li>Cylinder: \\(\\pi r^2 h\\)</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/#surface-area","title":"Surface Area","text":"<ul> <li>Cube: \\(6 a^2\\)</li> <li>Cuboid: \\(2(lb + bh + lh)\\)</li> <li>Cylinder: \\(2 \\pi r^2 + 2 \\pi r h\\)</li> </ul>"},{"location":"Masters/GRE/Math/Geometry/#units-of-measurement","title":"Units of Measurement","text":"<ul> <li>Metric: km, kg, L</li> <li>English/Imperial: miles, pounds, gallons</li> </ul> <p>All conversions will be given in GRE</p> <p>Only units of time are expected to be known</p>"},{"location":"Masters/GRE/Math/Geometry/#strategies","title":"Strategies","text":"<ul> <li>Redraw figures</li> <li>Add all given information</li> <li>Add all information that can be deduced</li> <li>Add/extend lines</li> <li>Assign vars and use algebra</li> <li>2/more triangles &amp; lengths required</li> <li>Look for similar triangles</li> <li>Right triangle</li> <li>Look out for triples</li> <li>Use pythagorean theorem</li> <li>Circles</li> <li>Look out for circle properties</li> <li>Look out for isosceles triangles</li> </ul>"},{"location":"Masters/GRE/Math/Integers/","title":"Integers","text":"<ul> <li>Divisibility: No remainder</li> <li>Divisor = Factor</li> <li>Multiple</li> <li>Rules<ul> <li>2: Number is even</li> <li>3: sum of digits is divisible by 3</li> <li>4: 2 trailing digits divisible by 4</li> <li>5: last digit is 0 or 5</li> <li>6: Number divisible by 2 and 3</li> <li>7:</li> <li>8:</li> <li>9: Sum of digits divisible by 9</li> <li>10: Last digit is 0</li> </ul> </li> <li>Prime numbers</li> <li>+ve integer with only 2 divisors: 1 and itself </li> <li>1 is neither prime nor composite</li> <li>2 is only even prime number</li> <li>Prime factorization</li> <li>Any integer &gt; 1 is either prime or can be expressed be expressed as product of prime numbers</li> <li>If \\(n= p^a q^b r^c \\cdots\\) where \\(p, q, r, \\dots\\) are prime factors of \\(n\\), then total number of positive divisors of \\(n\\) is \\((a+1)(b+1)(c+1) \\cdots\\)</li> <li>Squares of integers</li> <li>called perfect squares</li> <li>Prime factorization will always have even no of each prime</li> <li>Will always have odd numbers of +ve divisors</li> <li>GCD/HCF</li> <li>Names<ul> <li>Greatest Common Divisor</li> <li>Greatest Common Factor</li> <li>Highest Common Factor</li> </ul> </li> <li>Greatest +ve common divisor shared by 2/more numbers</li> <li>LCM</li> <li>Least common multiple</li> <li>Smallest positive integer that is a multiple of both numbers</li> <li>\\(\\text{HCF}(x, y) \\times \\text{LCM}(x, y) = x \\times y\\)</li> <li>Operations with odd/even integers</li> <li>Product of odd numbers is always odd<ul> <li>Add/sub</li> <li>Odd +- odd = even</li> <li>Odd +- even = odd</li> <li>Even +- even = even</li> <li>Mul</li> <li>Odd x odd = odd</li> <li>Odd x even = even</li> <li>even x even = even</li> <li>Div</li> <li>Even/Even can be anything</li> <li>Odd/even = non-integer</li> <li>Even/odd = non-integer or even integer</li> <li>Odd/odd: non-integer or odd integer</li> </ul> </li> <li>Consecutive integers</li> <li>Every \\(n\\)th number is divisible by \\(n\\)</li> <li>\\(n\\) consecutive integers \\(\\implies\\) 1 number must be divisible by \\(n\\)</li> <li>Remainders</li> <li>Remainder \\(\\in\\) [0, Divisor)</li> <li>Dividend = divisor x quotient  +  remainder</li> <li>If \\(n/D = Q \\text{ with } R\\), then possible values of \\(n\\) are \\(R + aD\\), where \\(a \\ge 0\\)</li> </ul>"},{"location":"Masters/GRE/Math/Percents_Ratios/","title":"Percents &amp; Ratios","text":"<ul> <li>Basics</li> <li>What is 40% of 90?</li> <li>15% of what number is 60?</li> <li>120 is what percent of 80?</li> <li>Find \\(x\\%\\) of \\(y\\)</li> <li>Percent change</li> <li>Increase</li> <li>Decrease</li> <li>Interest</li> <li>Simple Interest</li> <li>Compound Interest</li> <li>Ratios</li> <li>Equivalent ratios</li> <li>Portioning</li> <li>Combining ratios</li> </ul>"},{"location":"Masters/GRE/Math/Powers_and_Roots/","title":"Powers &amp; Roots","text":"<ul> <li>Base</li> <li>Exponent</li> <li>\\(x^n = \\prod \\limits_{i=1}^n x\\)</li> <li>Negative number raised to even power: positive</li> <li>Negative number raised to odd power: negative</li> <li>Power laws</li> <li>\\(a^m \\times a^n = a^{m+n}\\)</li> <li>\\(a^m \\times b^m = (a b)^{m}\\)</li> <li>\\(a^0 = 1\\)</li> <li>\\((a^m)^n = a^{mn}\\)</li> <li>\\(x^{-n}=\\dfrac{1}{x^n}\\)</li> <li>\\((a^m b^n)^o = (a^{mo} b^{no})\\)</li> <li>\\(\\sqrt[n]{x} = x^{1/n}\\)</li> <li>\\(x^{m/n} = (x^m)^{1/n} = (x^{1/n})^m\\)</li> <li>\\(x^m=x^n \\iff m=n \\quad (x \\not \\in\u00a0[-1, 0, 1])\\)</li> <li>Roots</li> <li>Odd root of negative number will be negative</li> <li>Odd root of positive number will be positive</li> <li>We cannot find even root of negative number</li> <li>Rationalizing</li> <li>Multiply numerator and denominator by conjugate of denominator</li> </ul>"},{"location":"Masters/GRE/Math/Powers_and_Roots/#units-digit","title":"Units Digit","text":"<ul> <li>Look for repeating pattern</li> <li>Figure out where pattern will be at desired power</li> <li>The units digit of any product will be influenced only by the units digits of the 2 factors</li> </ul> <p>Eg: What is the unit\u2019s digit of \\(57^{123}\\)</p>"},{"location":"Masters/GRE/Math/Probability/","title":"Probability","text":"<ul> <li>Basic formula</li> <li>Complement</li> <li>Useful for \u201cat least one\u201d questions</li> <li>Mutually-exclusive</li> <li>Independent events</li> </ul>"},{"location":"Masters/GRE/Math/Quantitative_Comparison/","title":"Quantitative Comparison","text":""},{"location":"Masters/GRE/Math/Quantitative_Comparison/#options","title":"Options","text":"<ul> <li>A &gt; B</li> <li>B &gt; A</li> <li>A = B</li> <li>Cannot be determined</li> </ul>"},{"location":"Masters/GRE/Math/Quantitative_Comparison/#notes","title":"Notes","text":"<ol> <li>Do not perform more calculations than necessary</li> <li>Do not select D if comparison does not contain unknown values</li> <li>Geometry figures are not necessarily drawn to scale, unless stated otherwise</li> <li>Pay attention to shared information</li> </ol>"},{"location":"Masters/GRE/Math/Quantitative_Comparison/#strategies","title":"Strategies","text":"<ol> <li>Approximation</li> <li>Matching operations: perform same operations on both quantities</li> <li>Add both sides</li> <li>Subtract both sides</li> <li>Multiply both sides by +ve constant</li> <li>Divide both sides by +ve constant<ol> <li>Variable can be positive/negative</li> </ol> </li> <li>Plugging in numbers</li> <li>Looking for equality</li> <li>Number sense</li> </ol>"},{"location":"Masters/GRE/Math/Statistics/","title":"Statistics","text":"<ul> <li>Average</li> <li>Mean<ul> <li>If a set is evenly spaced, the mean and median are equal; However, the converse may/may not hold true</li> </ul> </li> <li>Median</li> <li>Mode</li> <li>Weighted<ul> <li>p_a avg_a + p_b avg_b</li> </ul> </li> <li>Dispersion</li> <li>Range: max-min</li> <li>Variance</li> <li>Standard deviation</li> <li>Rank-based</li> <li>Quartiles</li> <li>Percentiles: Can never be 100<sup>th</sup> percentile</li> <li>Normal distribution</li> <li>Plots</li> <li>Histogram</li> <li>Box plot</li> </ul>"},{"location":"Masters/GRE/Math/Word_Problems/","title":"Word Problems","text":"<ol> <li>Understand question &amp; restrictions</li> <li>Eliminate impossible choices</li> <li>Consider testing answer choices</li> <li>Assign variables</li> <li>Create an equation</li> <li>Solve equation (if necessary)</li> <li>Reread question and confirm required value</li> </ol>"},{"location":"Masters/IELTS/","title":"IELTS Academic","text":""},{"location":"Math_Electives/Numerical_Analysis/","title":"Numerical Analysis","text":""},{"location":"Math_Electives/Numerical_Analysis/#references","title":"References","text":"<ul> <li> MIT 10.34 Numerical Methods Applied to Chemical Engineering</li> <li> StudySession | Numerical Analysis</li> <li> Numerical Methods for Computational Finance</li> </ul>"},{"location":"Math_Electives/Optimization/","title":"Optimization","text":"<p>Applied mathematics that deals with maximizing/minimizing an objective, with/without constraint(s). This has various applications, such as Revenue Maximization, Cost Minimization, etc</p>"},{"location":"Math_Electives/Optimization/#references","title":"References","text":"<ul> <li> Optimization | Dr. Maneesha | BITS Pilani Dubai Campus</li> <li> Public Transportation Systems | MIT</li> <li> Optimization | Michel Bierlaire</li> <li> Optimization &amp; Simulation | Michel Bierlaire</li> </ul>"},{"location":"Math_Electives/Optimization/01_Linear_Programming/","title":"01 Linear Programming","text":""},{"location":"Math_Electives/Optimization/01_Linear_Programming/#linear-programming","title":"Linear Programming","text":"<p>Objective/constraint will be in linear form</p>"},{"location":"Math_Electives/Optimization/01_Linear_Programming/#solution-properties","title":"Solution Properties","text":"Property Meaning How to obtain Feasibility All constraints satisfied Substitute var values in constraints Optimality Max/min value of obj() Substitute var values in obj()"},{"location":"Math_Electives/Optimization/01_Linear_Programming/#graphical-method","title":"Graphical Method","text":"<ol> <li>Define obj()</li> <li>Draw all constraints</li> <li>Draw line for LHS=RHS</li> <li>Draw appropriate arrows show the direction of inequality</li> <li>Find vertices of soln space (feasible region)</li> <li>Find the value of obj() at these vertices</li> <li>Pick the min/max value</li> </ol>"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/","title":"02 Primal Simplex","text":"<p>Vertices can be determined algebraically, when all constraints RHS and variables are non-negative.</p> <p>Always start a problem on the left-side sheet; else you\u2019ll waste time flipping pages</p>"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#optimality-feasibility","title":"Optimality &amp; Feasibility","text":"Max Prob Min Prob Feasibility All basic vars \\(\\ge 0\\) Same as \\(\\leftarrow\\) Optimality Coeff of all basic vars in obj() \\(\\ge 0\\) Coeff of all basic vars in obj() \\(\\le 0\\)"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#direct-simplex-method","title":"Direct Simplex Method","text":"<ol> <li>Make sure all RHS constraints are +ve. Else, multiply by -1 to change the sign</li> <li>Convert the constraints inequality into equality</li> </ol> Constraint LHS represents RHS represents Difference Example \\(\\le\\) usage of limited resources for activities limit on the availability of resources Slack (unused) amount of resources \\(4x + 3y \\le 240\\)\\(\\implies 4x + 3y \\textcolor{hotpink}{+ s_k} = 240\\) \\(\\ge\\) usage of limited resources for activities minimum requirement of resource utilization Surplus amount of resources \\(4x + 3y \\le 240\\)\\(\\implies 4x + 3y \\textcolor{hotpink}{- x_k} = 240\\) <ol> <li>Transpose obj()</li> </ol> <p>Example: \\(\\max Z = 70x+50y \\implies \\max Z - 70x-50y=0\\)</p> <ol> <li>Select Entering/Exiting vars</li> </ol> Type Entering var= Non-basic var with most ___ coefficient of obj() Exiting var= Basic var with  ___ ratio Maximization -ve(entering causes fastest increase in value of obj()) least Minimization -ve(entering causes fastest decrease in value of obj()) least <ol> <li>Calculate pivot row</li> <li>Check optimality is reached</li> <li>if obj() coeff \\(\\ge 0 \\forall\\) non-basic vars</li> <li>Verify feasibility</li> <li> <p>end here</p> </li> <li> <p>Else</p> </li> <li> <p>Calculate other rows</p> </li> <li> <p>Repeat steps 4-6</p> </li> </ol> Term Meaning/Formula Ratio \\(\\text{Ratio} = \\frac{\\text{Solution for basic variable}}{\\text{Constraint coeff for entering var}}\\)Denominator &gt; 0If constraint coeff \\(&lt; 0\\), ignore that case, and check other variables\u2019 ratio Pivot Element Intersection of entering and exiting var Pivot Row \\(\\text{Pivot Row} = \\frac{\\text{Leaving Row}}{\\text{Pivot Element}}\\) Other rows \\(\\text{New row} = \\text{Old row} - (\\text{Coeff of var in pivot column} \\times \\text{Pivot row})\\) <p>If \\(x_3, x_4, \\dots\\) come in one equation each, treat them as basic vars. Use row operations to ensure </p> Equation Coeff of \\(x_3, x_4\\) Constraint 1 obj() 0"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#artificial-starting-solution","title":"Artificial Starting Solution","text":"<ul> <li>Surplus var is not initially included in the list of basic vars</li> <li>If slack and artificial var are tied for leaving var, artificial var leaves</li> </ul> <p>Starting Steps</p> <ol> <li>If any constraints have negative RHS, multiply by -1</li> <li>Convert to equality</li> </ol> Constraint Sign Introduce \\(\\le\\) + Slack var \\(=\\) + Artificial var \\(R_1, R_2, \\dots\\) \\(\\ge\\) - Surplus var (subtraction)+ Artificial var \\(R_1, R_2, \\dots\\)"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#big-m-method","title":"Big-M Method","text":"Step Maximization Minmization Introduce artificial var to transposed obj()\\(M=\\) very large number, say a millionFor the sign (column on right), think of it as: making \\(R_1, R_2, \\dots\\) very anti-entering \\(+ MR_1 + M R_2 \\ \\dots\\) \\(- MR_1 - M R_2 \\ \\dots\\) Make the table as usual Perform row transformation to eliminate \\(R_1, R_2, \\dots\\) in obj() row(keeping basic rows the same) \\(Z - MR_1 - MR_2\\) \\(Z + MR_1 + MR_2\\) Solve as usual"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#two-phase-method","title":"Two-Phase Method","text":"Phase obj() Goal 1 \\(\\min R = \\sum R_i\\)(for both max/min problems) Force artificial vars to be 0 2 original LP\u2019s obj() Determine optimal soln"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#phase-1-steps","title":"Phase 1 Steps","text":"<ul> <li>Do transformation to make \\(R_i\\) as 0 in \\(R\\)\u2019s row; other rows unchanged</li> <li>Solve as usual</li> </ul>"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#phase-2-steps","title":"Phase 2 Steps","text":"Optimal value of\\(R = \\sum R_i\\) Artificial varsin basis \\(\\implies\\) Optimal Soln = Steps \\(&gt; 0\\) \u274c(infeasible soln) \\(=0\\) \\(0\\) Optimal soln of phase 2 LP - Drop columns in phase 1 table corr to artificial variables- Use original obj() with constraints from optimal phase 1 table (ignore initial constraints). This gives phase 2 obj()- Perform row transformation to eliminate phase 1 basic vars in phase 2 obj() row- Solve as usual \\(= 0\\) \\(&gt; 0\\) Optimal soln of original LP - Drop all\u00a0\u00a0- Non-basic artificial vars from optimal phase 1 table\u00a0\u00a0- Variables from original prob with -ve coeff in row of optimal phase 1 table- Solve as usual"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#special-cases","title":"Special Cases","text":"Cases Meaning Description Identification in simplex Degeneracy(Degenerate soln) \\(\\ge 1\\) redundant constraints Nothing alarmingMay lead to Cycling (Var enters &amp; exits basis repeatedly w/o reaching optimality)Can be temporary/permanent Solution for one basic var \\(= 0\\)Usually happens when there is a tie for the leaving variable AlternativeOptima obj() \\vert  \\vert binding constraint obj() will assume the same optimal value at more than one corner point, \\(\\implies \\exists\\) alternative soln Coeff of non-basic var \\(=0 \\implies\\) var enters basic vars &amp; obj() will not change UnboundedSoln Unbounded soln space in \\(\\ge 1\\) direction Values of some decision vars can be inc indefinitely, w/o violating constraint(s) - Entries for one/more non-basic var column \\(\\le 0 \\ \\forall\\) constraint rowsand- Entry for same non-basic var in obj() row\\(\\le 0\\) : max\\(\\ge 0\\) : min No feasibleSoln Inconsistent contraints Artificial var(s) exist(s) in basis even after optimality"},{"location":"Math_Electives/Optimization/02_Primal_Simplex/#summary-of-methods","title":"Summary of Methods","text":"Constraints Method to use All \\(=\\) Solve algebraically All \\(\\le\\) Direct Simplex Method All \\(\\ge\\) Big-M Method / 2 Phase Method Mixture of \\(\\le, =, \\ge\\) Big-M Method / 2 Phase Method"},{"location":"Math_Electives/Optimization/03_Duality/","title":"03 Duality","text":"<p>Dual problem is a linear programming prob derived from the primal (original) LP model. It is basically a transposed version of the primal problem. Optimal Soln of Primal Prob = Optimal Soln of Dual Prob</p> <p>Dual Form is preferred when no of constraints increases</p> Form Numerical work \\(\\propto\\) Preferred for Simplex No of constraints Fewer constraints/Many vars Dual No of vars Fewer vars/Many constraints"},{"location":"Math_Electives/Optimization/03_Duality/#conversion-of-primal-to-dual","title":"Conversion of Primal \\(\\to\\) Dual","text":""},{"location":"Math_Electives/Optimization/03_Duality/#initial-steps","title":"Initial Steps","text":"<ul> <li>All constraints RHS &amp; vars are \\(\\ge 0\\)</li> <li>Introduce slack and surplus vars (don\u2019t introduce artificial vars)</li> <li>Dual var is defined \\(\\forall\\) primal constraint</li> <li>Dual constraint is defined \\(\\forall\\) primal var (including slack and surplus vars)</li> </ul> Primal obj() \\(\\implies\\) Dual obj() Inequality of new Constraints max min \\(\\ge\\) min max \\(\\le\\) \\[ \\text{Dual Obj()} = \\sum \\text{RHS constraints} \\] \\[ \\begin{aligned} &amp;\\text{Dual constraint j} \\implies \\\\ &amp; \\small{\\sum \\text{Constraint coeff of } x_i \\text{ &lt;Inequality&gt; } \\text{Non-transposed Obj() coeff of } x_i} \\end{aligned} \\]"},{"location":"Math_Electives/Optimization/03_Duality/#computations","title":"Computations","text":"Formula [Primal constraints column in iteration \\(i\\)](Primal basic vars) [Inverse in iteration \\(i\\)] x [Primal constraints col] Primal obj() coeff of \\(x_j\\)(Primal non-basic vars) LHS of non-transposed dual constraint\\(_j\\) - RHS of non-transposed dual constraint\\(_j\\) [Dual vars in iteration \\(i\\)] [RHS of basic vars in non-transposed dual constraint] x [Inverse in iteration \\(i\\)] Inverse [Inverse] = [Columns in optimal primal table corr to vars not in obj()]"},{"location":"Math_Electives/Optimization/03_Duality/#checking-optimality-feasibility","title":"Checking Optimality &amp; Feasibility","text":"Max Prob Min Prob Feasibility All primal basic vars \\(\\ge 0\\) Same as \\(\\leftarrow\\) Optimality All primal non-basic vars \\(\\ge 0\\) All primal non-basic vars \\(\\le 0\\)"},{"location":"Math_Electives/Optimization/04_Dual_Simplex/","title":"04 Dual Simplex","text":"<p>This is not the same as duality</p> Problem starts at Successive iterations continue to be __ obtained in last iteration Primal Simplex basic feasible solution feasible optimality Dual Simplex infeasible solution, which is better than optimal optimal feasibility"},{"location":"Math_Electives/Optimization/04_Dual_Simplex/#steps","title":"Steps","text":"<p>Obj() must satisfy optimality condition of regular simplex method</p> <ol> <li>Change all equalities to \\(\\le\\)</li> </ol> Constraint Type Change \\(\\le\\) \\(\\ge\\) Multiply both sides by -1 \\(=\\) Convert into inequality of both types\\(x_1 + x_2 = 1 \\implies \\quad x_1 + x_2 \\le 1, \\quad -x_1 - x_2 \\le -1\\) <ol> <li>Add slack vars (there is no surplus/artificial vars for dual simplex)</li> <li>Transpose obj()</li> <li>Select Entering/Exiting vars</li> </ol> Exiting var= Basic var with most ___ value Entering var= Non-basic var with  ___ ratio Max/Min (same for both) -ve least <ol> <li>Calculate pivot row (same as primal)</li> <li>Check feasibility is reached</li> <li>If value of all basic vars \\(\\ge 0\\)</li> <li>Verify optimality (same as primal)</li> <li>end here</li> <li>Else</li> <li>Calculate other rows (same as primal)</li> <li>Repeat steps 4-6</li> </ol>"},{"location":"Math_Electives/Optimization/04_Dual_Simplex/#ratio","title":"Ratio","text":"\\[ \\text{Ratio } = \\left| \\frac{     \\text{Obj() coeffient} }{     \\text{Constraint coeff for exiting var} } \\right| \\qquad (\\text{only magnitude}) \\] <p>Denominator &lt; 0</p> <p>If constraint coeff \\(\\ge 0 \\ \\forall\\) non-basic \\(x_j\\), the problem has no feasible solution</p>"},{"location":"Math_Electives/Optimization/05_Post_Optimal_Analysis/","title":"05 Post Optimal Analysis","text":"<p>Deals with situation of finding new solution in efficient way when parameters are changed</p>"},{"location":"Math_Electives/Optimization/05_Post_Optimal_Analysis/#actions","title":"Actions","text":"Existing SolnFeasible? Existing SolnOptimal? \\(\\implies\\) Action \u2705 \u2705 No action \u2705 \u274c Use primal simplex \u274c \u2705 Use dual simplex \u274c \u274c Use generalized simplex method"},{"location":"Math_Electives/Optimization/05_Post_Optimal_Analysis/#change-in-feasibility","title":"Change in Feasibility","text":"Change Steps RHS of constraint equation changes 1. Check feasibility with inverse method2. Calc new obj(), with values from step 13. Update table4. Use dual simplex5. Calc obj() when feasibility is maintained/obtained Addition of new constraint(s) 1. Check feasibility by substituting existing values into new constraint2. Introduce slack/surplus into equation3. Introduce slack/surplus row &amp; column into table 4. Update introduced basic var row using below formula5. Use dual simplex6. Calc obj() when feasibility is maintained/obtained \\[ \\begin{aligned} &amp; \\text{Updated row of introduced basic var} \\\\ &amp; = \\text{Initial row of introduced basic var} - \\left( \\sum \\text{coeff}_i \\times x_i \\right) \\end{aligned} \\] <p>where</p> <ul> <li>\\(x_i =\\) basic variables in new constraint</li> <li>coeff\\(_i\\) = coeff of \\(x_i\\) in new constraint</li> </ul>"},{"location":"Math_Electives/Optimization/05_Post_Optimal_Analysis/#change-in-optimality","title":"Change in Optimality","text":"<p>Caused due to change in obj()</p> <p>Steps</p> <ol> <li>Find the dual var values, using new obj() coeff</li> <li>Check optimality</li> <li>If optimality is maintained, go to step 6</li> <li>Update obj() row using</li> <li>coeff found when checking optimality</li> <li>original obj() value, using above latest coeff</li> <li>Use primal simplex</li> <li>Calculate latest solution in new obj()</li> </ol>"},{"location":"Math_Electives/Optimization/05_Post_Optimal_Analysis/#new-constraint","title":"New Constraint","text":"Type Meaning Redundant A new constraint that does not affect feasibility of an existing optimum solution. Binding - A new constraint that affects feasibility of an existing optimum solution.- Simplex table after incorporating the constraint"},{"location":"Math_Electives/Optimization/06_Transportation_Model/","title":"Transportation Model","text":"<p>Special case of LP, which deals with shipping of commodities from \\(m\\) sources to \\(n\\) nodes</p> <p>The number of basic vars and independent constraints will be \\((m+n-1)\\)</p> <p>It will always be a minimization problem, since transporation model deals with the shipping cost of commodities</p> <p>To solve, we've to 1. Find initial BFS 2. Find optimal solution</p>"},{"location":"Math_Electives/Optimization/06_Transportation_Model/#matrix","title":"Matrix","text":"<p>\\(m \\times n\\)</p> <p>For every cell \\(v_{ij}\\), make sure that</p> \\[ \\begin{aligned} v_{ij} &amp;= \\text{argmin}(D_i, S_j) \\\\ \\sum v_i &amp;= D_i \\\\ \\sum v_j &amp;= S_j \\end{aligned} \\]"},{"location":"Math_Electives/Optimization/06_Transportation_Model/#balanced-transportation","title":"Balanced Transportation","text":"\\[ \\sum \\text{Supply} = \\sum \\text{Demand} \\]"},{"location":"Math_Electives/Optimization/06_Transportation_Model/#find-initial-bfs","title":"Find initial BFS","text":"<p>(Basic Feasible Soln)</p> <p>Any basic feasible solution will have \\((m+n-1)\\)</p> Basic vars \\(v &gt; 0\\) Non-basic vars \\(v=0\\) <ul> <li>If the problem is balanced, no issues</li> <li>Else add an extra row/column to compensate</li> <li>If no penalties, cell costs = 0</li> <li>If \\(\\exists\\) Penalties, cell costs = penalties</li> </ul> <p>Soln can be find using one of the following methods</p> Method Steps North-West Corner Traverse from top-left to bottom-right Least Cost Vogel\u2019s Approximation(VAM) 1. Calculate row-wise penalties \\(P_i = \\min_2(v_i) - \\min(v_i)\\)2. Calculate row-wise penalties \\(P_j = \\min_2(v_j) - \\min(v_j)\\)3. Pick the row/column with max penalty. Cross out the penalty (and hence entire row/column), if the row/column is completely utilized4. In that row/column, we select the cell with least cost5. Repeat, excluding the recently-allocated cell"},{"location":"Math_Electives/Optimization/06_Transportation_Model/#find-optimal-solution","title":"Find optimal solution","text":"<p>Method of multipliers. 2 conditions need to be satisfied</p> <ul> <li>Supply limits &amp; demand requirements remain satisfied</li> <li>Shipments through all routes must be \\(\\ge 0\\)</li> </ul> <p>Checking optimality</p> <ol> <li> <p>Set \\(u_1 = 0\\)</p> </li> <li> <p>Find \\(u_i, u_j\\) for cells with \\(u_i + v_j = c_{ij}\\)</p> </li> <li>Find BIJ for empty cells: \\(\\text{BIJ} = u_i + v_j-c_{ij}\\)</li> <li>If BIJ \\(\\le 0\\) for empty cells, solution is optimal (this is minimization problem)</li> <li>Else, non-optimal</li> </ol> <p>Optimizing</p> <ol> <li>Find the entering var as the empty cell with the most +ve BIJ</li> <li>Put \\(\\theta\\) there</li> <li>Make a square/rectangle, with corners as non-empty cells or \\(\\theta\\) cell</li> <li>Add</li> <li>\\(-\\theta\\) to corner cells in the same row/col as \\(\\theta\\) cell</li> <li>\\(+\\theta\\) to other corner cells</li> <li>\\(\\theta\\) = Max value that \\(\\theta\\) can assume, which is obtained using the cells in the same row/column of \\(\\theta\\) cell</li> <li>Evaluate all the cells</li> </ol> <p>If 0 appears in non-basic var, and there is no other potential entering var, it implies that optimality is already reached, and future iterations give Alternative Optima.</p>"},{"location":"Math_Electives/Optimization/06_Transportation_Model/#degenerate-bfs","title":"Degenerate BFS","text":"<p>If in a cell we find zero mentioned, it means that all corresponds to basic var that has assumed \\(v=0\\). It implies degenerate basic feasible solution.</p>"},{"location":"Math_Electives/Optimization/06_Transportation_Model/#maximization-problem","title":"Maximization Problem","text":"<p>For eg, if we want to maximize the distribution of foods (not worried about money, for eg during a natural disaster).</p> <p>The values of \\(c_{ij}\\) will be the +ve output. Since transportation problem is always minimization.</p> <ol> <li>\\(c_{ij} = -1 \\times c_{ij}\\)</li> <li>Solve as usual</li> <li>Total output = -1 x total cost</li> </ol>"},{"location":"Math_Electives/Optimization/07_Assignment_Model/","title":"07 Assignment Model","text":"<p>Special case of transportation model, where no of supply nodes always = no of demand nodes</p> <p>Input is a \\(n \\times n\\) matrix, where</p> <ul> <li>\\(n\\) workers are assigned to \\(n\\) jobs</li> <li>cells contain the value of cost associated with assignment</li> </ul>"},{"location":"Math_Electives/Optimization/07_Assignment_Model/#objectives","title":"Objectives","text":"<p>is one of the following</p> <ul> <li>minimize the total time to complete a set of jobs</li> <li>minimize cost of assignments</li> <li>maximize the skill ratings</li> <li>maximize total satisfaction of customers</li> </ul>"},{"location":"Math_Electives/Optimization/07_Assignment_Model/#assumptions","title":"Assumptions","text":"<ul> <li>Each machine/worker is assigned \\(\\le 1\\) job</li> <li>Each job is assigned to exactly 1 machine/worker</li> </ul>"},{"location":"Math_Electives/Optimization/07_Assignment_Model/#steps","title":"Steps","text":"<ol> <li> <p>Operations</p> </li> <li> <p>Row operation \\(R_i = R_i - \\text{min} (R_i)\\)</p> </li> <li> <p>Col operation \\(C_i = C_i - \\text{min} (C_i)\\)</p> <p>or </p> </li> <li> <p>Col operation \\(C_i = C_i - \\text{min} (C_i)\\)</p> </li> <li> <p>Row operation \\(R_i = R_i - \\text{min} (R_i)\\)</p> </li> <li> <p>Assign jobs to workers</p> </li> <li> <p>Only cells with value = 0 can be assigned</p> </li> <li> <p>Assignment of a cell must be unique</p> </li> <li> <p>Cost of completion = Initial values of the assigned cells</p> </li> </ol>"},{"location":"Math_Electives/Optimization/07_Assignment_Model/#special-cases","title":"Special Cases","text":"Case Method No Unique Solution found 1. Draw minimum number of horizontal/vertical lines in the last reduced matrix, passing through all 0s2. Select smallest uncovered element3. Subtract it from every uncovered element4. Add it to every element at the intersection5. If no feasible solution, go to step 16. Else, determine the optimal solution Unbalanced Assignment Add rows/columns as requiredFill empty rows/columns with 0s Maximization Assignment Problem Multiple all cells with -1 (only for first operation)Be careful of -ve signFinal value = -1 x Total Cost Disallowed Assignment If some cell is missing data, fill it in with\u00a0\\(M\\) (a very large number)"},{"location":"Math_Electives/Optimization/08_Project_Management/","title":"08 Project Management","text":"<p>These are network-based methods, designed to assist in planning, scheduling, and control of projects.</p>"},{"location":"Math_Electives/Optimization/08_Project_Management/#objective","title":"Objective","text":"<ol> <li>Determine the minimum possible completion time for the project.</li> <li>Determine a range of start and end time for each activity, so that the project can be completed in minimum time.</li> </ol>"},{"location":"Math_Electives/Optimization/08_Project_Management/#notations","title":"Notations","text":"\\(\\text{ES}_j = \\square_j\\) Earliest occurance time of event \\(j\\) \\(\\text{LC}_j = \\triangle_j\\) Latest completion time of event \\(j\\) \\(D_{ij}\\) Duration of activity between \\(i\\) and \\(j\\)"},{"location":"Math_Electives/Optimization/08_Project_Management/#activities","title":"Activities","text":"Critical Non-Critical Leeway in determining start time \u274c \u2705, within some limit Leeway in determining end time \u274c \u274c Conditions 1. \\(\\square_i = \\triangle_i\\)2. \\(\\square_j = \\triangle_j\\)3. \\(\\square_j - \\square_i = \\triangle_j - \\triangle_i = D_{ij}\\) <p>where \\(D_{ij}\\) =  given distance between 2 nodes</p>"},{"location":"Math_Electives/Optimization/08_Project_Management/#methods","title":"Methods","text":"CPM PERT Full Form Critical Path Method Project Evaluation Review Technique Assumption for activity deterministic durations probabilistic durations Duration of activity Fixed Determined based on- most optimistic time\u00a0\\(a\\)- most likely time\u00a0\\(m\\)- pessimistic time\u00a0\\(b\\) Procedure 2 passes1. Forward pass determines earliest occurance times; take path with max duration if \\(\\exists\\) multiple paths2. Backward pass determines latest completion times; take path with min duration if \\(\\exists\\) multiple paths3. Find critical paths4. Find the float for non-critical activities 1. Calculate distance and variance2. Solve like CPM3. Calculate cumulative E(D_i) and Var4. Calculate required probabilities using \\(z\\)\u00a0distributionIn case of ties, take the max variance path, thereby reflecting more uncertainty Average duration\u00a0\\(\\bar D = \\frac{a+4m+b}{6}\\)Variance\u00a0\\(= \\left(\\frac{b-a}{6}\\right)^2\\)"},{"location":"Math_Electives/Optimization/08_Project_Management/#float","title":"Float","text":"Free Float Total Float \\(\\square_j - \\square_i - D_{ij}\\) \\(\\triangle_j - \\square_i - D_{ij}\\) Case FF = 0 Any delay will cause delay in starting successive activities FF &lt; TF We have leeway in starting the project as FF unitsFor any excess delay (FF &lt; d &lt; T), starting successive activities will be delayed FF\u00a0= TF Activities may be scheduled anywhere between the earliest start time &amp; the latest completion time without delaying the project"},{"location":"Math_Electives/Optimization/09_Game_Theory/","title":"09 Game Theory","text":"<p>Deals with situations where there are conflict of interest between 2 opponents called \u2018players\u2019, who may have finite/infinite strategies or alternatives.</p> <p>These are 2 person zero-sum games, because of the gain of one player is equal to loss to the other</p> <p>Associated with each player is the payoff that one player pays to the other with respect to the each pair of strategies</p> <p>The game is summarized in terms of the payoff to one player.</p> <p>For 2 players with \\(m\\) and \\(n\\) strategies respectively, the payoff matrix will be \\(P_{m \\times n}\\)</p> <p>If \\(A\\) and \\(B\\) use strategy \\(i\\) and \\(j\\) respectively, then payoff to</p> <ul> <li>player A: \\(p_{ij}\\)</li> <li>player B: \\(-p_{ij}\\)</li> </ul>"},{"location":"Math_Electives/Optimization/09_Game_Theory/#examples","title":"Examples","text":"<ul> <li>advertising campaigns for competing products</li> <li>planning war strategies for opposing armies</li> </ul>"},{"location":"Math_Electives/Optimization/09_Game_Theory/#optimal-solution","title":"Optimal Solution","text":"<p>Due to presence of conflict of interest, optimal solution selects the strategies for each player such that any change in strategies will not improve the payoff for either of the players.</p>"},{"location":"Math_Electives/Optimization/09_Game_Theory/#simple-strategies","title":"Simple Strategies","text":"<p>Parties can only pick 1 strategy each.</p> <p>We are trying to find the best variation of the worst-case scenario for both parties</p> <ol> <li>Strategy of \\(A\\) is the strategy for which payoff = max(min) for A</li> <li>Find row-wise min</li> <li>Calculate the max of these</li> <li>Strategy of \\(B\\) is the strategy for which payoff = min(max) for B</li> <li>Find row-wise max</li> <li>Calculate the min of these</li> <li>Saddle point solution = \\((i, j)\\), where \\(i\\) and \\(j\\) are the strategies that </li> <li>if \\(i=j\\), neither \\(i, j\\) would be willing to change their strategy</li> <li>Value of game \\(= [\\text{Sol}_A, \\text{Sol}_B]\\)</li> </ol>"},{"location":"Math_Electives/Optimization/09_Game_Theory/#mixed-strategies","title":"Mixed Strategies","text":"<p>\\(\\not \\exist\\) Saddle point \\(\\implies\\) There is no single strategy for one/more players.</p> <ol> <li> <p>Consider strategies</p> </li> <li> <p>\\(A\\) selects strategies \\(i \\in [1, 2, \\dots]\\) w/ probability \\(x_i\\), such that \\(\\sum x_i = 1\\)</p> </li> <li> <p>\\(B\\) selects strategies \\(i \\in [1, 2, \\dots]\\) w/ probability \\(y_i\\), such that \\(\\sum y_i = 1\\)</p> </li> <li> <p>Draw table of B\u2019s picked strategy and A\u2019s expected payoff</p> </li> </ol> \\[ \\text{Expected Payoff}_A =  \\] B\u2019s Strategy A\u2019s expected payoff <ol> <li> <p>Draw graph</p> </li> <li> <p>idk</p> </li> <li> <p>Maxmin = highest point of lower intersection open area in the graph</p> </li> <li> <p>Minmax = lowest point of highest intersection open area in the graph</p> </li> <li> <p>Equate the expected pay-off of the lines that are involved in maxmin</p> </li> <li> <p>Value of game = value obtained by substituting \\(x_1\\) in the intersecting equations (intersecting equations will give the same value)</p> </li> <li> <p>Find the other person\u2019s </p> </li> </ol> \\[ \\text{Expected Payoff}_B =  \\] A\u2019s Strategy B\u2019s expected payoff"},{"location":"Math_Electives/Optimization/10_Integer_Programming/","title":"10 Integer Programming","text":""},{"location":"Math_Electives/Optimization/10_Integer_Programming/#integer-programming","title":"Integer Programming","text":"<ol> <li>Solve as usual</li> <li>Branch &amp; Bound</li> <li>Split with the variable with larger decimal value</li> </ol> \\[ \\begin{aligned} \\nabla f(x_0) &amp;= 0 \\\\ \\frac{\\partial f}{\\partial x_i} &amp;= 0, \\forall i \\end{aligned} \\]"},{"location":"Math_Electives/Optimization/10_Integer_Programming/#application-sports-scheduling","title":"Application: Sports Scheduling","text":"<ul> <li>Objective: Maximize team preferences</li> <li>Decisions: Which teams should play each other each week</li> <li>Decision variable can be binary or discrete</li> </ul> <p>Steps</p> <ul> <li>Define binary variable \\(x_{ijk}\\)</li> <li>team \\(i\\)</li> <li>team \\(j\\)</li> <li>week \\(K\\)</li> <li>If team \\(I\\) plays team \\(J\\) in week \\(K\\)</li> <li>\\(x_{IJK}=1\\)</li> <li>Else 0</li> <li>Constraints</li> <li>Play other teams in the same division twice<ul> <li>\\(\\sum x_{IJk} = 2, \\forall k\\),\u00a0where \\(I\\) and \\(J\\) are in same divisions</li> </ul> </li> <li>Place teams in other divisions once<ul> <li>\\(\\sum x_{IJk} = 1, \\forall k\\), where \\(I\\) and \\(J\\)\u00a0are in different divisions</li> </ul> </li> <li>Play exactly one team each week<ul> <li>\\(\\sum x_{IjK} = 1, \\forall j\\)</li> </ul> </li> </ul>"},{"location":"Math_Electives/Optimization/11_Goal_Programming/","title":"Goal Programming","text":"<p>This deals with situations with multiple objective functions.</p> <p>Sometimes, some goals will be more important than others</p>"},{"location":"Math_Electives/Optimization/11_Goal_Programming/#deviation-variables","title":"Deviation Variables","text":"<p>Represent the amount by which goal will be violated</p> Deviation ___ RHS of constraint \\(s_i^+\\) above \\(s_i^-\\) below <p>\\(s_i^+\\) and \\(s_i^-\\) are by definition dependent and hence cannot be taken as basic variables simultaneously. This means that in any simplex iteration, \\(\\le 1\\) one the 2 deviation variables can assume +ve values</p>"},{"location":"Math_Electives/Optimization/12_Dynamic_Programming/","title":"Dynamic Programming","text":"<ol> <li>Divide the problem into stages</li> <li>Find the solution stage-by-stage</li> <li>Combine all stages to find overall solution</li> </ol>"},{"location":"Math_Electives/Optimization/13_Non-Linear_Programming/","title":"Non-Linear Programming","text":"<p>Necessary condition</p>"},{"location":"Mech/FEA/","title":"Finite Element Analysis","text":"<p>Finite element analysis (FEA) is a computerized method for predicting how a product reacts to real-world forces, vibration, heat, fluid flow, and other physical effects.</p> <p>FEA helps identify if a product will break, wear out, or work the way it was designed.</p>"},{"location":"Mech/FEA/#steps","title":"Steps","text":"<ul> <li>Create model</li> <li>Create parts</li> <li>Create sets for boundary conditions and loads</li> <li>Merge parts to assembly</li> <li>Materials</li> <li>Create materials and sections</li> <li> <p>Assign materials to sections</p> </li> <li> <p>Create steps</p> </li> <li>Specify output requests</li> <li>Specify boundary conditions</li> <li>Specify loads</li> <li>Generate Mesh</li> <li>Create jobs</li> <li>Run jobs</li> </ul> <p>Job = Simulation</p>"},{"location":"Mech/FEA/#controls","title":"Controls","text":"Apply Calculate Force Control Force Displacement Displacement Control Displacement Force"},{"location":"Mech/FEA/01_Crack/","title":"Cracks","text":"<ul> <li>Advanced topic: Only covered after Bachelor\u2019s and Master\u2019s level courses</li> <li>Rare topic: Most FEA does not focus on cracks, since cracks are due to failure of the initial manufacturing stage and hence crack FEA is an after-thought</li> </ul>"},{"location":"Mech/FEA/01_Crack/#crack-properties","title":"Crack Properties","text":"Characteristic length Fracture energy Proportional to mesh sizeHow much energy required to break one finite element Displacement"},{"location":"Mech/FEA/01_Crack/#reading","title":"Reading","text":"<ul> <li> Research gate crack characteristic length vs fracture energy BUET</li> </ul>"},{"location":"Misc/Health/","title":"Diet","text":"<p>The following are made for Thahir. Consult a doctor for yourself.</p> <ul> <li>2200 calories per day</li> <li>Atleast 40% is protein<ul> <li>Nuts, paneer, ghee</li> <li>Lean meat: chicken breast, salmon, egg whites</li> </ul> </li> </ul> <p>Yoghurt, two cups</p> <p>Protein supplements: whey protein</p> <p>Nuts is the best, even shake </p> <p>30min to 1hr after sunrise , for about 30 minutes</p> <p>Teeth - Don't drink lemonade - may cause tooth decay - Gargle before bed     - Coconut oil: basic solution     - Salt     - Alternate between the above 2 every night</p>"},{"location":"Misc/Health/#supplements","title":"Supplements","text":"Multi-Vitamin Protein Whey \u00bd scoops per day Optimal NutritionLaperveApplied Nutrition"},{"location":"Misc/Health/#misc","title":"Misc","text":"<ul> <li>Sunglight</li> </ul>"},{"location":"Misc/Health/#exercises","title":"Exercises","text":"<ul> <li>Upper<ul> <li>Shoulder<ul> <li>angle pushup</li> <li>\u2060shoulder shrug</li> <li>\u2060t, y hold</li> </ul> </li> </ul> </li> <li>Lower<ul> <li>Core/Back/Glutes<ul> <li>leg stretch hold - front, left, right, back</li> <li>squats</li> <li>superman</li> </ul> </li> </ul> </li> </ul>"},{"location":"Misc/misc/","title":"Misc","text":""},{"location":"Misc/misc/#digital-business-card","title":"Digital Business Card","text":"<ol> <li>Generate vCard text: https://vcardmaker.com/</li> <li>Generate QR Code from text: https://www.the-qrcode-generator.com/</li> </ol> <p>Example vCard</p> <pre><code>BEGIN:VCARD\n\nVERSION:3.0\n\nFN:Ahmed Thahir\n\nN:Thahir;Ahmed;;;\n\nURL:https://LinkedIn.com/AhmedThahir\n\nEMAIL;TYPE=Work:ahmedthahir2002@gmail.com\n\nTEL;TYPE=WORK,VOICE:+971 55 123 4567\n\nADR;CHARSET=UTF-8;TYPE=WORK:;;;Dubai;;;United Arab Emirates\n\nEND:VCARD\n</code></pre>"},{"location":"Misc/misc/#communicationpresentation","title":"Communication/Presentation","text":"<ol> <li>Know your goal</li> <li>Know your Audience</li> <li>Structure<ol> <li>Introduction<ol> <li>Context: background of overall current situation</li> <li>Destination: Where we want to be </li> </ol> </li> <li>\u2060Discussion<ol> <li>Situation: Background of specific topic</li> <li>Conflict: Problem Context<ol> <li>What<ol> <li>What's the problem</li> <li>What's stopping us from going from current situation to destination</li> </ol> </li> <li>Why: Why does it matter?</li> </ol> </li> <li>Question: Problem Statement</li> <li>Solution<ol> <li>How to go from current situation to destination</li> </ol> </li> </ol> </li> <li>Conclusion</li> <li>Action Plan</li> <li>Recap</li> </ol> </li> </ol> <p>Misc - Always give analogies/examples whenever possible - For only presenting     - Show takeaways and actions/proposal in the beginning itself - For discussion presentations     - Show only takeaways in beginning, and show actions/proposal at the end to avoid limiting ideas</p> <p>Audience transformation framework</p> <p></p> <p>Presentation 1. Big picture before details 2. Problem 3. What's in it for you 4. Solution 5. What's in it for you 6. Give numbers for context</p> <p>Throughout - Eye contact - Open posture - Hand gestures</p>"},{"location":"Misc/misc/#review-presentation","title":"Review Presentation","text":""},{"location":"Misc/AI_Healthcare/","title":"AI for Healthcare","text":""},{"location":"Misc/AI_Healthcare/#references","title":"References","text":"<ul> <li> ML for Healthcare | MIT</li> <li> Survival Analysis | DataTab</li> <li> Survival Analysis | Meerkat Statistics</li> <li> Predictive Maintenance | Matlab</li> <li> CQE (Certified Quality Engineer) | institute of Quality and Reliability</li> <li> Time-based maintenance</li> </ul>"},{"location":"Misc/AI_Healthcare/#current-video","title":"Current Video","text":"<p>https://www.youtube.com/watch?v=PKCMH5KOcxQ&amp;list=PLUl4u3cNGP60B0PQXVQyGNdCyCTDU1Q5j&amp;index=12</p>"},{"location":"Misc/AI_Healthcare/01_Introduction/","title":"Introduction","text":""},{"location":"Misc/AI_Healthcare/01_Introduction/#problems","title":"Problems","text":"<ul> <li>Misdiagnosis</li> <li>Late diagnosis</li> <li>Inappropriate management after diagnosis</li> <li>Medical errors are pervasive</li> </ul>"},{"location":"Misc/AI_Healthcare/01_Introduction/#history","title":"History","text":"Limitations 1970s MYSIN expert system Identifying bacteria 1980s INTERNIST-1/Quick Medical Reference Internal medicine Bayesian network-like 1. Clinicians entered symptoms manually2. Difficult to maintain3. Difficult to generalize (prior probabilities will different across different parts of the world) RX Project 1990s ANN 1. Did not fit well into clinical workflow2. Hard to get enough training data3. Poor generalization to new places"},{"location":"Misc/AI_Healthcare/01_Introduction/#what-has-changed","title":"What has changed?","text":""},{"location":"Misc/AI_Healthcare/01_Introduction/#data-availability","title":"Data availability","text":"<ul> <li>Adoption of Electronics Records</li> <li>Lab tests</li> <li>Imaging</li> <li>Vital signs</li> <li>Genomics</li> <li>Wearable sensors</li> </ul> <p>### Standardization</p> <ul> <li>Reports</li> <li>Data storage</li> <li>APIs</li> </ul> <p>OMOP</p> <p></p>"},{"location":"Misc/AI_Healthcare/01_Introduction/#machine-learning","title":"Machine Learning","text":"<ul> <li>Learning with high-dimensional features</li> <li>Semi-supervised and unsupervised learning</li> <li>Deep learning</li> <li>Democratization of machine learning</li> <li>Open-source software</li> </ul>"},{"location":"Misc/AI_Healthcare/01_Introduction/#overview","title":"Overview","text":"<p>Emergency department</p> <ul> <li>Limited resources</li> <li>Time sensitive</li> <li>Critical decisions</li> </ul>"},{"location":"Misc/AI_Healthcare/01_Introduction/#applications","title":"Applications","text":"<ul> <li>Better triage</li> <li>Faster diagnosis</li> <li>Early detection of adverse events</li> <li>Prevent medical errors</li> <li>Recommend treatment pathway</li> <li>Anticipating clinicians needs</li> <li>Reducing needs for specialist consults</li> <li>Automated documentation &amp; billing</li> <li>Predicting patient\u2019s future disease progression</li> <li>Continuous monitoring</li> <li>Discovery of new disease subtypes</li> <li>Design of new drugs</li> <li>Better targeted clinical trials</li> </ul>"},{"location":"Misc/AI_Healthcare/01_Introduction/#what-makes-ml-in-healthcare-different","title":"What makes ML in healthcare different?","text":"<ul> <li>Life/death decisions, similar to Autonomous Driving</li> <li>Need robust algorithms</li> <li>Checks and balances required for ML deployment</li> <li>Need fair &amp; accountable algorithms</li> <li>Lot of scope for unsupervised learning</li> <li>Causal learning required: just prediction insufficient</li> <li>Very little labelled data: need to use semi-supervised algorithms</li> <li>Small sample size</li> <li>Data quality issues</li> <li>Varying time intervals</li> <li>Missing data</li> <li>Censored labels</li> <li>Data sensitivity</li> <li>Difficulty of de-identifying</li> <li>Difficulty of deploying ML</li> <li>Commercial electronic health record software is difficult to modify</li> <li>Different standards used</li> <li>Careful testing and iteration needed</li> </ul>"},{"location":"Misc/AI_Healthcare/02_Clinical_Care/","title":"Clinical Care","text":""},{"location":"Misc/AI_Healthcare/02_Clinical_Care/#goals-of-health-care","title":"Goals of Health Care","text":"<ul> <li>Cure Morbidity (sickness)</li> <li>Disability</li> <li>Delay Mortality</li> <li>Keep people healthy</li> </ul>"},{"location":"Misc/AI_Healthcare/02_Clinical_Care/#tasks-of-health-care","title":"Tasks of Health Care","text":"<ul> <li>Diagnosis</li> <li>Prognosis</li> <li>Treatment</li> <li>Prevent/Public Health</li> </ul>"},{"location":"Misc/AI_Healthcare/02_Clinical_Care/#medical-cycle","title":"Medical Cycle","text":""},{"location":"Misc/AI_Healthcare/02_Clinical_Care/#enterprise-level-clinical-process-automation","title":"Enterprise-level clinical process automation","text":""},{"location":"Misc/AI_Healthcare/02_Clinical_Care/#how-does-the-health-system-learn","title":"How does the Health System Learn","text":"<p>Randomized Clinical Trials</p>"},{"location":"Misc/AI_Healthcare/02_Clinical_Care/#limitations","title":"Limitations","text":"<ul> <li>Heterogeneity: most cases to which RCT results are applied to do not fit trial criteria</li> <li>Short follow-up</li> <li>Small samples</li> </ul>"},{"location":"Misc/AI_Healthcare/02_Clinical_Care/#paying-for-health-care","title":"Paying for Health Care","text":"<ul> <li>Companies spend lot on healthcare</li> <li>Increased demand</li> <li>Waste: Unnecessary procedures</li> </ul>"},{"location":"Misc/AI_Healthcare/03_Clinical_Data/","title":"Clinical Data","text":""},{"location":"Misc/AI_Healthcare/03_Clinical_Data/#basic-exploration","title":"Basic Exploration","text":"<p>Who are these 300 yr old people? According to law, you are not supposed to specify age of someone older than 90, as they will be easily identified due to small subpopulation size</p> <p>Why are some greater than 300? Their age is 300+time spent in hospital</p>"},{"location":"Misc/AI_Healthcare/03_Clinical_Data/#types-of-data","title":"Types of Data","text":"<ul> <li>Demographics</li> <li>Vital signs</li> <li>Medications</li> <li>Laboratory</li> <li>Pathology</li> <li>Microbiology</li> <li>Notes</li> <li>Discharge summary</li> <li>Attending/resident</li> <li>Nurse</li> <li>Specialist</li> <li>Consultant</li> <li>Referring physician</li> <li>Emergency room</li> <li>Imaging: XRay, CTScan, etc</li> <li>Quantified self</li> <li>Activity</li> <li>Vitals</li> <li>Diet</li> <li>Blood sugar</li> <li>Allergies</li> <li>Mindfulness</li> <li>Mood</li> <li>Sleep</li> <li>Pain</li> <li>Sexual activity</li> <li>Billing data</li> <li>Diagnoses</li> <li>Procedures</li> <li>Diagnose related groups</li> <li>Adminstrative</li> <li>Service</li> <li>Transfers</li> </ul>"},{"location":"Misc/AI_Healthcare/03_Clinical_Data/#issues","title":"Issues","text":"<ul> <li>Missing data</li> <li>Non-stationarity</li> <li>Change in definition of disease over time, resulting in number of people with disease change over time</li> <li> <p>Lab tests performed changes over times</p> </li> <li> <p>Discontinuation medication intake by patient not tracked</p> </li> <li>Standards are often lacking</li> </ul>"},{"location":"Misc/AI_Healthcare/03_Clinical_Data/#coding-systems","title":"Coding Systems","text":"<ul> <li>Medication</li> <li>NDC</li> <li>MedDRA</li> <li>HCPCS</li> <li>GSN</li> <li>CPT</li> <li>Procedure</li> <li>ICD9</li> <li>CPT</li> </ul> <p>CPT: owned by American College of Physicians; codes are copywrited \ud83d\ude33</p>"},{"location":"Misc/AI_Healthcare/03_Clinical_Data/#censors","title":"Censors","text":"<ul> <li>Left-sensored: Missing features</li> <li>Right-sensored: Missing label</li> </ul>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/","title":"Risk Stratification","text":"<p>Separating a patient population into high-risk and low-risk of having an outcome</p> <ul> <li>Predicting something in the future</li> <li>Goal is different from diagnosis, with distinct performance metrics</li> <li>Fuzzy classification</li> <li>Diverse data</li> </ul> <p>Risk stratification drives interventions that target high-risk patients</p> <p>Goal is to reduce cost and improve patient outcomes</p>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#applications","title":"Applications","text":"<ul> <li>Pre-mature infant\u2019s risk of severe morbidity</li> <li>Does this patient need to be admitted to coronary-care unit</li> <li>Likelihood of hospital readmission</li> </ul>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#types","title":"Types","text":"Traditional AI Use readily-available data and feed into model Pros Simple - Population-level- Automated: Fits more easily into workflow- Higher accuracy- Quicker to derive Limitations ManualSample-specificNot used as much as required due to high friction Example APGAR Scoring system AI"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#apgar-scoring-system","title":"APGAR Scoring system","text":""},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#framing-for-supervised-ml","title":"Framing for Supervised ML","text":"<p>Why are gaps important? To avoid label leakage</p> <p>Sparsity-encourage models</p> <ul> <li>Easier to interpret</li> <li>Helps deploy model to different clinics where they may not have access to all the data</li> </ul>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#how-to-get-labels","title":"How to get labels","text":"<ul> <li>Manual</li> <li>Label patients\u2019 data by \u201cchart review\u201d<ul> <li>Visualization of individual patient data time series</li> </ul> </li> <li>Automatic</li> <li>Rule-based<ul> <li>Labels may get revised regularly based on standards</li> <li>For eg</li> <li>2020: 200 units of sugar = diabetes</li> <li>2025: 100 units of sugar = diabetes</li> </ul> </li> <li>Machine learning to predict if the patient is \u201ccurrently\u201d diabetic</li> </ul> <p>Based on</p> <ul> <li>medications: may not have record of</li> <li>purchase</li> <li>intake</li> <li>lab data</li> </ul>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#metrics","title":"Metrics","text":"PPVPositive Predictive Value AUC-ROC Calibration"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#intervention-tainted-outcomes","title":"Intervention-Tainted Outcomes","text":"<p>Form of Self-Selection Bias</p> <p>Let</p> <ul> <li>Group A: Patients with Pneumonia with history of asthma</li> <li>Group B: Patients with Pneumonia without history of asthma</li> </ul> <p>Observation: Group A dies less often than group B</p>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#discussion","title":"Discussion","text":"<ol> <li>Reason group A dies less is due to more intensive care</li> <li>Long survival time may be due to treatment</li> </ol>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#conclusion","title":"Conclusion","text":"<ol> <li>Does this mean group A has lower risk? No</li> <li>Should we treat group A with less priority? No</li> </ol>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#hacks","title":"Hacks","text":"<ol> <li>Remove such features from the model; not feasible for high-dimensional data</li> <li>Redefine outcome by finding a pre-treatment surrogate (such as lactate levels)</li> <li>Consider treated patients as right-censored by treatment</li> </ol>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#solutions","title":"Solutions","text":"<ol> <li>Interpretable models are very important</li> <li>Causality modelling: Reframe question to \u201cWill admission to ICU lower likelihood of death for patient\u201d</li> </ol>"},{"location":"Misc/AI_Healthcare/04_Risk_Stratification/#deep-learning-for-risk-stratification","title":"Deep Learning for Risk Stratification","text":"<p>Not very big gains</p> <p></p> <p>Baseline is L1-regularized Logistic Regression, with good structural features</p> <p>Sequential data in medicine is very different from language modelling</p> <ul> <li>Many time scales</li> <li>Significant missing data</li> <li>Multi-variate observations</li> <li>Not enough data to learn subtle non-linear interactions</li> </ul>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/","title":"Survival Modelling","text":"<p>Variable studies is the time until an event occurs</p> <p>Predict when some event will happen</p> <p>Focus on right-censored data</p> <p></p> <p>Always finite time period: start &amp; end time period</p>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#cases","title":"Cases","text":"Treatment Event knowledge of true survival duration within time period within time period \u2705 within time period within time periodbut not noticed \u274c within time period not within time period \u274c within time period Discontinued study \u274c within time period Unexpected event \u274c"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#challenges-to-classification","title":"Challenges to classification","text":"<ul> <li>Less training data</li> <li>Pessimistic estimates due to choice of window</li> </ul>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#challenges-to-regression","title":"Challenges to regression","text":"<ul> <li>Non-gaussian: \\(T\\) is non-negative; may want long tails</li> <li>If we just naively remove censored events, model will be biased predict lower survival, since the people who got removed due to censoring did not get diabetes (ever/yet)</li> </ul>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#notation-formalization","title":"Notation &amp; Formalization","text":"<p>Let</p> <ul> <li>Data</li> <li>\\(X=\\) features</li> <li>\\(t=\\) time</li> <li>\\(b(t)=\\{ 0, 1 \\} =\\) binary indicator denoting whether time is of censoring/event occurrence</li> <li>\\(f(t)=P(t) =\\) probability of death at time \\(t\\)</li> <li>\\(S(t) =\\) probability of individual surviving beyond time \\(t\\)</li> <li>\\(T_d=\\) time of death</li> </ul> \\[ \\begin{aligned} s(t) &amp;= P(T_d&gt;t) &amp;&amp;= 1-P(T_d&lt;t) \\\\ &amp;= \\int_{t}^\\infty f(x) \\cdot dx &amp;&amp;= 1-\\int_{0}^t f(x) \\cdot dx \\end{aligned} \\] <p></p>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#methods","title":"Methods","text":""},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#kaplan-meier-estimator","title":"Kaplan-Meier Estimator","text":"<p>Graphical representation of survival function</p> <ul> <li>Non-parametric model</li> <li>Good for unconditional density estimation</li> </ul> <p></p> <ul> <li>\\(d(t)=\\) no of events at time \\(t\\)</li> <li>\\(n(t)=\\) no of individuals alive and uncensored at time \\(t\\)</li> </ul> \\[ \\hat s_{k-m}(t) = \\prod_{k: y(k) \\le t} \\left( 1-\\dfrac{d(k)}{n(k)} \\right) \\]"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#log-rank-test","title":"Log-Rank Test","text":"<p>Compares the time until and event occurs of 2/more independent samples</p> <p>\u201cIs there a significant difference between the 2 curves\u201d</p> <p>Hypothesis test</p> <ul> <li>\\(H_0:\\) identical distribution curves</li> <li>\\(H_1:\\) different distribution curves</li> </ul> <p>\\(p &lt; \\alpha \\implies\\) reject \\(H_0\\)</p>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#cox-proportional-hazards-model","title":"Cox Proportional Hazards Model","text":"<p>Identify if there are other parameters that affect the curve</p>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#evaluation","title":"Evaluation","text":""},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#c-statisticconcordance-index","title":"C-Statistic/Concordance-Index","text":"<p>Evaluate model\u2019s ability to predict relative survival times</p> <p>Equivalent to AUC for binary classification without censoring $$ \\hat c = \\dfrac{1}{n} \\sum_{i: b_i=0} \\sum_{j: y_i &lt; y_j} I \\Big[ S(\\hat y_j \\vert X_j) &gt; S(\\hat y_i \\vert X_i) \\Big] $$ </p>"},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#mean-squared-error-for-uncensored-individuals","title":"Mean-Squared Error for uncensored individuals","text":""},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#held-out-censored-likelihood","title":"Held-out censored likelihood","text":""},{"location":"Misc/AI_Healthcare/05_Survival_Modelling/#binary-classifier","title":"Binary Classifier","text":"<p>Derive binary classifier from learnt model and check calibration</p>"},{"location":"Misc/AI_Healthcare/06_Physiological_Time_Series/","title":"Physiological Time Series","text":""},{"location":"Misc/AI_Healthcare/06_Physiological_Time_Series/#problems","title":"Problems","text":"<ul> <li>Measurements confounded by</li> <li>Interventions</li> <li>Measurement errors</li> </ul>"},{"location":"Misc/AI_Healthcare/06_Physiological_Time_Series/#idk","title":"IDk","text":"<ul> <li>Once measurement issues identified, we must impute the missing data</li> <li>Can help mitigate alarm fatigue by not alerting the clinicians when unnecessary</li> </ul>"},{"location":"Misc/AI_Healthcare/06_Physiological_Time_Series/#switching-linear-dynamical-systems","title":"Switching linear dynamical systems","text":""},{"location":"Misc/AI_Healthcare/06_Physiological_Time_Series/#traditional-modelling","title":"Traditional Modelling","text":""},{"location":"Misc/AI_Healthcare/07_NLP/","title":"Natural Language Processing","text":""},{"location":"Misc/AI_Healthcare/07_NLP/#goals","title":"Goals","text":"<ul> <li>For any word/phrase, assign meaning from taxonomy/ontology/terminology</li> <li>For any word/phase, determine whether it represents protected health information</li> <li>Determine aspects of each entity: time, location, certainty</li> <li>Having identified 2 meaningful phrases in a sentence, determine the relationship between them</li> <li>In a larger document, identify sentences/fragments relevant to answering a specific medical question</li> <li>Summarization</li> </ul>"},{"location":"Misc/AI_Healthcare/07_NLP/#types","title":"Types","text":"<ul> <li>Every word</li> <li>De-identification</li> <li>Extraction of all<ul> <li>EntitiesTime</li> <li>Certainty</li> <li>Causation/association</li> </ul> </li> <li>Aggregate</li> <li>Identify \u201csmoking\u201d</li> <li>Cohort selection</li> </ul>"},{"location":"Misc/AI_Healthcare/07_NLP/#idk","title":"IDK","text":"<p>Billing codes are enforced based on the tests required to evaluate a patient, not the condition</p>"},{"location":"Misc/AI_Healthcare/08_Implementing/","title":"Deploying","text":""},{"location":"Misc/AI_Healthcare/08_Implementing/#hype-cycle","title":"Hype Cycle","text":"<p>Technology adoption cycle</p> <p></p> <p>Venture Capitalists know that 9/10 investments fail, but expect at least 1/10 makes enough money to compensate for the others</p>"},{"location":"Misc/AI_Healthcare/09_Imaging/","title":"Imaging","text":"<ul> <li>Can\u2019t just automate reading image scans because of</li> <li>high-risk</li> <li>Can\u2019t sue AI company</li> </ul> <p>Hence, AI is used to prioritize which scans are most urgent to look at</p> <p>This way the expert can still look at missed diagnoses eventually even if is low priority</p>"},{"location":"Misc/AI_Healthcare/09_Imaging/#problems-with-ai","title":"Problems with AI","text":"<ul> <li>Explainability</li> <li>Localization</li> <li>Patients and provides share in decisions: all parties need to be convinced of the validity of the conclusion</li> </ul>"},{"location":"Misc/AI_Healthcare/09_Imaging/#solution-semantic-segmentation","title":"Solution: Semantic Segmentation","text":"<p>Identifying anomalies in the scans</p>"},{"location":"Misc/AI_Healthcare/11_Differential_Diagnosis/","title":"Differential Diagnosis","text":"<ul> <li>Diagnosis: Identification of nature and cause of certain phenomenon</li> <li>Differential diagnosis: Distinguishing of particular disease/condition from others that present similar clinical features</li> </ul>"},{"location":"Misc/AI_Healthcare/11_Differential_Diagnosis/#models","title":"Models","text":"<ul> <li>Flowcharts</li> <li>Based on associations b/w diseases and {signs, symptoms}</li> <li>\u201cmanifestations\u201d covers all observables, including lab tests, bedside measurements</li> <li>Single disease vs multiple diseases</li> <li>Probabilistic vs categorical</li> <li>Utility theoretic</li> <li>Rule-based</li> <li>Pattern-matching</li> </ul> <p>Models?</p> <ul> <li>Bayesian network</li> </ul>"},{"location":"Misc/Design/","title":"Design","text":""},{"location":"Misc/Design/#references","title":"References","text":""},{"location":"Misc/Design/01_Introduction/","title":"Introduction","text":""},{"location":"Misc/Design/01_Introduction/#principles-of-design","title":"Principles of Design","text":"<p>CRAP - [ ] Minimalism     - [ ] Replace text with icons     - [ ] Few functional elements as possible     - [ ] Few visual elements (color, typography) as possible - [ ] Contrast     - [ ] Typography     - [ ] Colors - [ ] Repetition     - [ ] Typography     - [ ] Colors - [ ] Alignment     - [ ] Everything aligned to something else on page     - [ ] Share lines and repeat alignments where possible - [ ] Proximity: Group related items together     - [ ] White space     - [ ] Color     - [ ] Location     - [ ] Contrast     - [ ] Repetition     - [ ] Alignment     - [ ] Typography</p>"},{"location":"Misc/Design/01_Introduction/#typography","title":"Typography","text":"Family Serif Sans Serif Slab Serif Monospaced Script Weight Extra light Light Regular Semi bold Bold Black Style Regular Italic Underline Size Color ## Colors"},{"location":"Misc/Design/01_Introduction/#color-systems","title":"Color Systems","text":"System Purpose HSL Hue, Saturation, Luminance Human-Intuitive RGB Red, Green, Blue Screens CMYK Cyan, Magenta, Yellow, blacK Print <p>### Color Palette</p> Aspect Meaning Example Contrast Monochromatic All have the same hue Complementary Split Complementary Triad Usability &amp; Accessibility Perceptually-uniformity Values close to each other use similar colorsValues far away use different colors Bad: RainboxGood: Vivirdis, Inferno Colorblind-safety Colors should be distinguishable by people with common forms of colorblindness"},{"location":"Misc/Design/02_Asset%20Types/","title":"Asset Types","text":""},{"location":"Misc/Design/02_Asset%20Types/#formats","title":"Formats","text":"Type Format Use Lossless Bitmaps/Raster JPEG Photographs \u274c PNG Images with limited colors (&lt;256 colors)LosslessWeb \u2705 Webp Web Both GIF Short animations with limited colors (&lt;256 colors) \u274c Vector SVG Digital designsWeb \u2705 PDF Print Both EPS \u2705"},{"location":"Misc/Digital_Transformation_Best_Practices/","title":"Digital Transformation Best Practices","text":"<p>New digital transformations initiatives should always have a trial phase, with focus on learning what could go wrong and 0 expectations of utilizing insights</p> <p>Eg: data logger swapped</p>"},{"location":"Misc/DoE/","title":"Design of Experiments","text":""},{"location":"Misc/DoE/#references","title":"References","text":"<ul> <li> Modern Data Analysis for Economics</li> <li> From Data to Decisions: Measurement, Uncertainty, Analysis and Modeling | Chris Mack | University of Texas</li> <li> Design of Experiments (DoE) simply explained | DATAtab</li> <li> DoE vs Machine Learning | Paul Allen</li> <li> Designing, Running, and Analyzing Experiments | IxD Online: UCSD &amp; Coursera</li> <li> Design And Analysis Of Experiments | IITK</li> <li> Design of Experiments | The Open Educator</li> <li> Design of Experiments | Adam Kashlak</li> <li> Design of Experiments | Cache Lack Math &amp; Stats Lectures</li> </ul>"},{"location":"Misc/DoE/01_Introduction/","title":"Introduction","text":"<p>Planning experiment to promote good decision making, with minimum cost</p> <p>Counter-intuitive point: the best time to design experiment is after experiment is finished, especially the first time when you don\u2019t know the underlying data-generating response process</p>"},{"location":"Misc/DoE/01_Introduction/#experiment","title":"Experiment","text":"<p>Deliberate variation of one/more process variables while observing effect on one/more response variables</p>"},{"location":"Misc/DoE/01_Introduction/#experimental-design","title":"Experimental Design","text":"<ul> <li>Maximize information gain</li> <li>Minimize resources (time and cost)</li> </ul> <p>DOE is a procedure to plan experiments to efficiently provide valid conclusions</p> <p>Does the experiment have enough statistical power to answer research questions?</p>"},{"location":"Misc/DoE/01_Introduction/#process","title":"Process","text":"<ol> <li>Define objectives of experiment</li> <li>Define inputs to the process</li> </ol>"},{"location":"Misc/DoE/01_Introduction/#types-of-input-vars","title":"Types of Input Vars","text":"Dealing Controlled &amp; observed/Factors Direct control of experimenter Variation + repeats/replication experiments in a systematic way Uncontrolled &amp; observed/Nuisance vars Not controlled by experimenter, but measured - Blocking- Analysis of covariance Uncontrolled &amp; unobserved Unknown to experimenter, but affects output response Randomization: Impact of variable averages out to 0"},{"location":"Misc/DoE/01_Introduction/#uses","title":"Uses","text":"<ul> <li>Exploratory work</li> <li>Comparison: Choosing between alternatives</li> <li>Screening: Selecting key factors that affect a response</li> <li>Response surface modeling: Optimize given process</li> <li>Hitting and control target response with minimum variability</li> <li>Maximize/minimize response/goal</li> <li>Increase process robustness</li> <li>Prediction</li> </ul>"},{"location":"Misc/DoE/01_Introduction/#rsm","title":"RSM","text":"<p>Response Surface Methodology</p> <p>Looks for quadratic/higher order trends</p> <p>Assumes all variables significant</p> <p>Quadratic response always has a stationary point (min/max/saddle point)</p> <p>Can be used to optimize a process $$ y_i = \\beta_0 + \\sum_{i=1}^k \\beta_i x_i + \\sum_{i=1}^k \\beta_{ii} x_i^2 + \\sum_{i} \\sum_{j&gt;i} \\beta_{ij} x_i x_j + u_i $$ One at a time</p> <p></p> <p></p>"},{"location":"Misc/DoE/01_Introduction/#properties","title":"Properties","text":"Orthogonality No collinearity/multi-collinearity of factors Rotatability Variance of response at \\(x\\) depends only on distance of \\(x\\) from design center point, and not direction (ie, \\(x_j\\))- All first-order orthogonal designs are rotatable- Composite face-center design is not rotatable Uniformity Control no of center points to achieve uniform precision, until \\(\\sigma^2_{y, \\text{center}} = \\sigma^2_{y, \\text{extreme}}\\) Efficiency No of required experimental runs"},{"location":"Misc/DoE/01_Introduction/#notes","title":"Notes","text":"<ul> <li>Beware of extrapolation</li> <li>Multiple responses</li> <li>Overlapping response contour plots</li> <li>Combined cost function</li> </ul>"},{"location":"Misc/DoE/01_Introduction/#pitfalls-of-doe-rsm","title":"Pitfalls of DOE &amp; RSM","text":"<ul> <li>Optimization of process without understanding the process</li> <li>Design assumes a model, so there is no way to test model error as the model always fits</li> <li>A quadric model will always show you an optimum point, but its accuracy depends on the accuracy of the model</li> <li>Exponential data fir with a quadratic model will show an optimum that does not exist</li> </ul>"},{"location":"Misc/DoE/01_Introduction/#doe-for-prediction","title":"DOE for Prediction","text":"<p>Goal: equalize the leverage of every point</p>"},{"location":"Misc/DoE/01_Introduction/#optimal-design","title":"Optimal design","text":"<p>Algorithmic approach to searching the design space and pick values of input vars in experiment to produce desired statistical properties</p> <ul> <li>Smallest SE of model parameters and of predictions, for a given \\(n\\)</li> <li>Smallest \\(n\\), for a given SE of model parameters &amp; predictions</li> </ul>"},{"location":"Misc/DoE/01_Introduction/#limitations","title":"Limitations","text":"<ul> <li>Model must be specified ahead of time</li> <li>Range of each input var must be specified ahead of time</li> <li>With multiple input vars, there can be tradeoffs b/w parameter variances</li> </ul>"},{"location":"Misc/DoE/01_Introduction/#types","title":"Types","text":"Design Use when Advantage Disadvantage \\(\\text{SE}(b_1)\\)For SLR Space-Filling Evenly spaced out \\(x\\) or \\(y\\) check whether the model is correct IntuitiveCan verify model Wasted opportunity cost of SE \\(\\sqrt{3 \\times \\dfrac{n-1}{n+1}} \\times \\dfrac{\\text{RMSE}}{\\sqrt{n} \\left( \\dfrac{x_\\max - x_\\min}{2}  \\right)}\\) Dumbbell - half data points at the lowest \\(x\\) value- half data points at the highest \\(x\\) value structural model already known Lowest SE of parameters Cannot verify structural model \\(1 \\times \\dfrac{\\text{RMSE}}{\\sqrt{n} \\left( \\dfrac{x_\\max - x_\\min}{2}  \\right)}\\) Equal-Thirds - \u2153 highest- \u2153 middle- \u2153 lowest Compromise between space-filling and dumbbell \\(\\sqrt{\\dfrac{3}{2}} \\times \\dfrac{\\text{RMSE}}{\\sqrt{n} \\left( \\dfrac{x_\\max - x_\\min}{2}  \\right)}\\)"},{"location":"Misc/DoE/01_Introduction/#principles","title":"Principles","text":"<ol> <li>Capacity for primary model</li> <li>Capacity for alternate model</li> <li>Minimum variance of estimated model parameters or predict values</li> <li>Except for simple cases, must search for optimal design</li> <li>Sample where the variation is</li> <li>For non-constant variance, \\(n_i \\propto \\sigma_{yi}^2\\)</li> <li>For curves, sample more in steep regions: Think about evenly-space \\(y\\) values rather than evenly-space \\(x\\) values</li> <li>Repeats and replication: To compute a model-independent estimate of process standard deviation</li> <li>Randomization and blocking</li> <li>allows detection of drift</li> <li>reduces influence of effect modifiers</li> </ol>"},{"location":"Misc/DoE/01_Introduction/#what-to-optimize","title":"What to optimize","text":"Optimality Objective Uncorrelated ObsLinear Model Uncorrelated ObsQuadratic Model Correlated Obs (autoregressive)Linear Model Correlated Obs  (autoregressive)Quadratic Model A(Average) Min average variance of estimates of model parameters (trace of covariance matrix) C(Combination) Min variance of predetermined linear combination of model parameters (selected subset of important parameters) D(Determinant) Min determinant of covariance matrixMax determinant of information matrix Dumbbell Equal-Thirds \\(\\approx\\) equally-spaced \\(x\\) \\(\\approx\\) equally-spaced \\(y\\) E(Eigenvalue) Max the minimum eigenvalue of information matrixMin multi-collinearity T Max trace of information matrix G Min the maximum \\(h_{ii}\\)Min maximum prediction variance I(Integrated) Min average prediction variance over design space VVariance Min average prediction variance for \\(m\\) specific points <p>Information matrix \\(= X^T X\\) </p>"},{"location":"Misc/DoE/01_Introduction/#idk","title":"IDK","text":"Repetition Replication Duplication of experiment on some data with same experimental run Repeated experimental runs where entire procedure is repeated independently at a different time Each replicate is subject to same variability, but independently(ie complete block) Include all sources of variation \u274c \u2705 Example Repeat generation of one data point through five \u201creadings\u201d to independently assess variability"},{"location":"Misc/DoE/02_Types_of_Experiments/","title":"Types of Experiments","text":"Type Free from Self-Selection External Validity Example LATE RCT(Randomized Control Trials) \u2705 \u26a0\ufe0f Only for compliers Natural/Quasi A situation where the researcher does not assign treatment to individualsTreatment is \u201cas if\u201d random, as implicit randomization occurs \u274c \u2705 Regression Discontinuity Design Discrete treatment status determined by an underlying continuous variable, which is used for quasi experimentsAssumption: People right before and after threshold are identicalRunning/forcing variable: Index/measure that determines eligibilityCutoff/cutpoint: threshold that formally assigns access to programLimitations- Requires lots of data in the neighborhood of the threshold- Poor generalizability: The validity of the results is usually restricted to this region- Throws away the lot of information in the non-random parts- Doesn\u2019t allow building structural causal model Uni admission cutoff provides a natural experiment on uni education. Students just above/below are likely to be very similar. For these students, uni education is \u201cas if\u201d random. Comparing these students (ones that went to uni/not) produces an estimate of the causal effect of college education. People in the bandwidth Differences-in-Differences 2 time-series process \\(y_1\\) and \\(y_2\\) have the factors affecting them Instrumental Variables IV technique helps work around simultaneous causal relationships- Education -&gt; Earnings -&gt; Education -&gt; ...- Supply \u2192 Demand \u2192 Supply \u2192 ... Only for compliers"},{"location":"Misc/DoE/02_Types_of_Experiments/#compliance","title":"Compliance","text":"Type What they do when assigned to control group \\(T=0\\) What they do when assigned to treatment group \\(T=1\\) Compliers \\(T=0\\) \\(T=1\\) Always takers \\(T=1\\) \\(T=1\\) Never takers \\(T=1\\) \\(T=1\\) Defiers \\(T=0\\) \\(T=1\\)"},{"location":"Misc/DoE/02_Types_of_Experiments/#differences-in-differences","title":"Differences-in-Differences","text":"<p>Let</p> <ul> <li>Control: \\(y_0\\) be the time series with \\(x=0\\)</li> <li>Treated: \\(y_1\\) be the time series with \\(x=1\\)</li> <li>\\(D_t\\) be the difference of the 2 series</li> </ul> \\[ \\begin{aligned} y_{0t} &amp;= f(t) + \\beta_1 (T=0) \\\\ &amp;= f(t) \\\\ y_{1t} &amp;= f(t) + \\beta_1 (T=1) \\\\ D_t &amp;= (y_1 - y_0)_t \\end{aligned} \\]"},{"location":"Misc/DoE/02_Types_of_Experiments/#assumptions","title":"Assumptions","text":"<ul> <li>Parallel trends: \\(f_1(t) = f_0(t)\\)<ul> <li>confirmed by evaluating regions without the treatment</li> </ul> </li> <li>No differential timing: Check Goodman-Bacon decomposition</li> <li>Absence treatment: no other variables</li> <li>Difference between the treatment &amp; the control group is time-invariant<ul> <li>any difference in their difference must be due to the treatment effect.</li> </ul> </li> </ul>"},{"location":"Misc/DoE/02_Types_of_Experiments/#why-not-other-way","title":"Why not other way?","text":"<ul> <li>Wrong ways: Impossible to know if change happened because of treatment or naturally<ul> <li>Only comparing treatment group before/after</li> <li>Only comparing treatment/control group at a particular time</li> </ul> </li> </ul>"},{"location":"Misc/DoE/02_Types_of_Experiments/#rdd","title":"RDD","text":""},{"location":"Misc/DoE/02_Types_of_Experiments/#threats","title":"Threats","text":""},{"location":"Misc/DoE/02_Types_of_Experiments/#manipulation","title":"Manipulation","text":"<p>People may change behavior when they know of the cutoff</p> <p>Discontinuity exists in the running variable even without any treatment</p> <p> </p> <p>Check with McCrary Density Plot</p> <p></p>"},{"location":"Misc/DoE/02_Types_of_Experiments/#non-compliance","title":"Non-Compliance","text":"<p>People on the margin of the cutoff may/may not get treatment, by misrepresenting the running variable - Some people may not want treatment even though they crossed the cutoff - Others may request access to the above discarded treatment spots</p> <p>This is different from manipulation, where the actual running variable comes out different</p> <p>For eg: Misreporting income</p> <p></p>"},{"location":"Misc/DoE/02_Types_of_Experiments/#types","title":"Types","text":"\\(T\\) Sharp \\(\\begin{cases} 1, &amp; z \\ge z_0\\\\ 0, &amp; \\text{o.w}\\end{cases}\\) Fuzzy \\(\\begin{cases} , &amp; z \\ge z_0\\\\ , &amp; \\text{o.w}\\end{cases}\\) Doubly-local effect: CACE only around cutoffUseful when there is non-complianceUse above/below threshold as instrument"},{"location":"Misc/DoE/02_Types_of_Experiments/#what-to-choose","title":"What to Choose","text":""},{"location":"Misc/DoE/03_Nuisance/","title":"Nuisance Removal","text":""},{"location":"Misc/DoE/03_Nuisance/#blocking-vs-randomization","title":"Blocking vs Randomization","text":"<p>Block what you can, randomize what you cannot</p> Blocking Covariate analysis Randomization Group experiments into blocks, each having a fixed value of the variable Put measured uncontrolled inputs into the modelIgnore them when modeling is complete Increase \\(\\text{cov}(T_1, T_2)\\) to decrease \\(\\sigma^2(T_1-T_2)\\) Model impact of variable, and then subtract it out Prevent unknown effect from biasing results Error that is same for \\(T_1\\) and \\(T_2\\) will cancel out Turn systematic errors into random errors which average out to zero Effective for Measured uncontrolled inputs Unmeasured uncontrolled inputs Application Understanding treatment effects Allows for time-series analysis to detect drift Example Randomly assign each person to- one new shoe- one old shoe(randomly assigned to left/right foot) Randomly assign- half of participants w/ new shoes- half of participants w/ old shoes \\[ \\begin{aligned} \\sigma^2(\\text{ATE}) &amp;= \\sigma^2(T_1-T_2) \\\\ &amp;= \\sigma^2_{T_1} + \\sigma^2_{T_2} - 2 \\text{ cov}(T_1, T_2) \\end{aligned} \\] <p>For measured uncontrolled inputs, use blocking or covariate analysis to remove effect of nuisance factors, and reduce known variability</p> <ul> <li>Different measurement tools, prices batches</li> <li>Spatial/temporal variations</li> </ul>"},{"location":"Misc/DoE/03_Nuisance/#random-treatment-assignment","title":"Random Treatment Assignment","text":"<p>Used for removing sources of variation due to nuisance factors</p>"},{"location":"Misc/DoE/03_Nuisance/#blockingrandomized-complete-block-design-rcbd","title":"Blocking/Randomized Complete Block Design (RCBD)","text":"<ul> <li>Complete experiment is performed for each block</li> <li>Each block sees each treatment exactly onec</li> <li>With each block, testing order is randomized</li> <li>Examples of blocks</li> <li>Raw material batches</li> <li>People (operators)</li> <li>Process/measurement tools</li> <li>Time</li> </ul> \\(\\alpha_1\\) \\(\\alpha_2\\) \\(\\alpha_3\\) \\(\\alpha_4\\) \\(T_2\\) \\(T_1\\) \\(T_1\\) \\(T_3\\) \\(T_1\\) \\(T_3\\) \\(T_2\\) \\(T_2\\) \\(T_3\\) \\(T_2\\) \\(T_3\\) \\(T_1\\) \\[ T \\in \\{ T_1, T_2, T_3 \\} \\\\ s \\in \\{ \\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4 \\} \\] <p>Note: The term \u2018blocking\u2019 originated  from agriculture, where a block is typically a set of homogeneous (contiguous) plots of land with similar fertility, moisture, and weather, which are typical nuisance factors in agricultural studies $$ y_{ij} = f(T_i) + \\text{Block}j + u $$</p>"},{"location":"Misc/DoE/03_Nuisance/#balanced-incomplete-block-design","title":"Balanced Incomplete Block Design","text":""},{"location":"Misc/DoE/03_Nuisance/#latin-square-design-lsd","title":"Latin Square Design (LSD)","text":"\\(\\alpha_1\\) \\(\\alpha_2\\) \\(\\alpha_3\\) \\(\\beta_1\\) \\(T_1\\) \\(T_2\\) \\(T_3\\) \\(\\beta_2\\) \\(T_2\\) \\(T_3\\) \\(T_1\\) \\(\\beta_3\\) \\(T_3\\) \\(T_1\\) \\(T_2\\) \\[ \\begin{aligned} T &amp;\\in \\{ T_1, T_2, T_3 \\} \\\\ s_1 &amp;\\in \\{ \\alpha_1, \\alpha_2, \\alpha_3 \\} \\\\ s_2 &amp;\\in \\{ \\beta_1, \\beta_2, \\beta_3 \\} \\end{aligned} \\] <p>A Latin square of order \\(n\\) is an \\(n \\times n\\) array of cells in which \\(n\\) treatments are placed, one per cell, such that each treatment only occurs</p> <ul> <li>once in each row</li> <li>once in each column</li> </ul> <p>Requirements</p> <ul> <li>Number of levels of each blocking var must equal number of levels of primary var</li> <li>No interactions between input vars, especially b/w nuisance vars</li> </ul> <p>Outcome</p> <ul> <li>Not complete block</li> <li>Model is orthogonal, if no interactions</li> </ul> \\[ y_{ijk} = f(T_i) + R_j + C_k + u_{ijk} \\] <p>Example: Test effect of amount of gasoline additive on emissions</p> <p></p>"},{"location":"Misc/DoE/04_Factorial/","title":"Factorial Design","text":""},{"location":"Misc/DoE/04_Factorial/#circular","title":"Circular","text":"<p>Experimental design that sets</p> <ul> <li>which predictor vars to vary</li> <li>Over what range</li> <li>Sampling plan: With what distribution of values</li> </ul> <p>Given nature of model, we can easily decide how to sample</p> Design Limitation No of measurements One at a time Cannot help investigate interactions Full factorial design \\(r \\prod \\limits_{i=1}^F l_i\\)"},{"location":"Misc/DoE/04_Factorial/#full-factorial-design","title":"Full Factorial Design","text":"<ol> <li>Use \\(l_i\\) levels for factor \\(F_i\\)</li> <li>It is common to normalize each factor to \\([-1, 1]\\): coded vars</li> <li>Perform \\(r\\) complete replicates of experiment</li> <li>Replicates are required to estimate error</li> </ol> <p>Adding center point</p> <ul> <li>Center point is often the POR (plan of record) and significant data may already exist about its response</li> <li>For LR</li> <li>Center points do not affect orthogonality of design</li> <li>Center points do not change any model parameter except the intercept</li> <li>Repeated center point can be used to check linear model validity: is non-linear term required?</li> </ul>"},{"location":"Misc/DoE/04_Factorial/#2-level-factorial-design","title":"2-level factorial design","text":"<p>For each factor, run every combination at 2 levels: high and low labelled as \\(-1, +1\\)</p> <p>For \\(F\\) factors there will be \\(r \\times 2^F\\) experimental runs for full factorial design</p> <p>With this, we can detect</p> <ul> <li>linear variations only</li> <li>interactions</li> </ul> <p>We cannot detect</p> <ul> <li>Non-linear variations</li> </ul> <p>This design is completely orthogonal</p>"},{"location":"Misc/DoE/04_Factorial/#fractional-factorial-design","title":"Fractional Factorial Design","text":"<p>Many higher order interactions may be negligible (sparsity-of-effects) principle, and hence redundant</p> <ul> <li>We can reduce number of runs by eliminating higher-order model interactions, especially the ones that are not relevant to us</li> </ul> <p>Choosing subset of full factorial design</p> <ul> <li>Balanced: all combinations have same number of obs</li> <li>Orthogonal design: effects of any factor sum to zero across effects of other factors</li> </ul>"},{"location":"Misc/DoE/04_Factorial/#half-factorial-design","title":"Half-Factorial design","text":"<p>Limitation</p> <ul> <li>Aliasing: some terms may get confounded by 2-factor interactions</li> <li>Not all terms can be distinguished in 8 runs</li> </ul> <p></p> <p>\\((x_1 x_2 = x_3 x_4), (x_1 x_3 = x_2 x_4) \\implies\\) collinearity</p>"},{"location":"Misc/DoE/04_Factorial/#projections","title":"Projections","text":"<p>If one of the factors proves to have no effect on the response, the \\(F\\) factor half-factorial design collapses to a \\(k-1\\) factor full-factorial design</p> <p></p>"},{"location":"Misc/DoE/04_Factorial/#ccd","title":"CCD","text":"<p>Central Composite Design</p> <ol> <li>Take 2-level factorial design</li> <li>Add center point with repeats: middle point b/w all factors</li> <li>Add axial (star) points: center point except w/ one var changed to be at \u00b1 an extreme value. Do this for all vars</li> </ol> <p>\\(n\\) level CCD more efficient than \\((n+1)\\) level factorial design $$ n = r(2^F + 2F + 1) $$</p>"},{"location":"Misc/DoE/04_Factorial/#types","title":"Types","text":"Type Rotatable Circumscribed Every factor data point on radiusequidistant from center: \\(2^{F/4}\\) Face-Centered Every factor data point on the line segments connecting all the initial factors \u274c"},{"location":"Misc/DoE/04_Factorial/#examples","title":"Examples","text":"Level Type 2 Circumscribed 2 Face-Centered 3"},{"location":"Misc/DoE/04_Factorial/#box-behnken-design","title":"Box-Behnken Design","text":"<ol> <li>Put a data point in the center</li> <li>Put a data point at midpoint each edge of process space</li> </ol>"},{"location":"Misc/DoE/04_Factorial/#disadvantages","title":"Disadvantages","text":"<ul> <li>Does not contain embedded factorial design: hence, cannot do pre-survey and add more points</li> <li>No corner (extreme points)</li> </ul>"},{"location":"Misc/DoE/04_Factorial/#repeated-center-points","title":"Repeated Center Points","text":"<ul> <li>Repeated center points are not randomized</li> <li>They are run as the first and last data points</li> <li> <p>Every spread through rest of data collection</p> </li> <li> <p>Help check against process instability</p> </li> <li>All other points should have randomized order</li> </ul> <p>The number of repeated center points can be set to create \u201cuniform precision\u201d, as \\(\\sigma^2_{y \\text{ center}} = \\sigma^2_{y \\text{ corner}}\\)</p>"},{"location":"Misc/DoE/04_Factorial/#sequential-doe","title":"Sequential DOE","text":"<p>Steepest Ascent/Descent</p> <p></p> <ol> <li>Start with factorial design (linear model) about current process (POR: Plan of Record)</li> <li>In scaled coordinates, \\((0, 0, \\dots, 0)\\)\u00a0represents center point</li> <li>Move in direction of steepest ascent/descent</li> <li>Find factor \\(j\\) with max \\(\\vert \\beta_j \\vert\\)</li> <li>Move a distance of the \\(j\\)th factor: \\(\\Delta x_j \\approx 1\\)\u00a0(higher/lower based on judgment)</li> <li>For every other factor, move a distance of \\(\\Delta x_{j'} = \\dfrac{\\Delta x_j \\beta_{j'}}{\\beta_j}\\)</li> <li>Measure response at this new point</li> <li>Keep moving until response goes down</li> </ol>"},{"location":"Misc/DoE/04_Factorial/#idk","title":"IDK","text":"<ol> <li>Start with 2-level full factorial design with repeated center points</li> <li>Extend to central composite design if quadratic model needed</li> </ol> <p>Results in 2 blocks: control number center repeated to ensure uniformity and rotatability</p> No of Factors Factorial Center Repeats Added star center repeats 2 \\(r\\) \\(r\\) 3 \\(1.4 r + 0.5\\) \\(r\\) 4 \\(2r\\) \\(r\\) 6 \\(4 (r-4)\\) \\(r\\)"},{"location":"Misc/DoE/04_Factorial/#mixtures","title":"Mixtures","text":"<p>Factors with constraints</p> <p>Consider</p> <ul> <li>\\(x_j \\in [0, 1] \\quad \\forall j \\in F\\)</li> <li>\\(\\sum_{j}^F x_j = 1\\)</li> </ul>"},{"location":"Misc/DoE/04_Factorial/#simplex-design","title":"Simplex Design","text":"<p>Applicable for Mixtures</p> <p>Each factor taking \\((m+1)\\) evenly space values $$ x_j = { v/m } \\ v \\in [0, m] \\ \\forall j \\in F $$ </p>"},{"location":"Misc/DoE/04_Factorial/#taguchi-methods","title":"Taguchi Methods","text":"<p>Statistical methods for improving manufacturing quality</p> <ol> <li>Optimization involves use of loss function</li> <li>Quality begins with designing a process with inherently high quality</li> <li>Use DOE</li> </ol>"},{"location":"Misc/DoE/04_Factorial/#loss-function","title":"Loss Function","text":"Goal Loss Function Eg More the better Monotonic Production output Less the better Monotonic Pollution emissions Hitting target with min variation Quadratic"},{"location":"Misc/DoE/04_Randomization/","title":"Randomization","text":""},{"location":"Misc/DoE/05_IDK/","title":"Experimental Design","text":"<p>Important goal: equalize leverage of every point during multiple regression $$ h_{ii} = \\dfrac{k}{n}, \\forall i $$</p>"},{"location":"Misc/DoE/05_IDK/#known-functional-form","title":"Known Functional Form","text":"<p>Non-dimensionalization</p>"},{"location":"Misc/DoE/05_IDK/#actions","title":"Actions","text":"<ul> <li>Simplify differential equations</li> <li>Rescale variables to unitless form</li> <li>Get rid of unnecessary parameters</li> <li>Reduce number of experiments needed to test hypothesis</li> </ul>"},{"location":"Misc/DoE/05_IDK/#rules","title":"Rules","text":"<ol> <li>Identify differential equation</li> <li>Identify independent &amp; dependent vars</li> <li>Replace each of them with a quantity scaled relative to characteristic unit of measure to be determined</li> <li>Divided through by the coefficient of the highest order polynomial/derivative term</li> <li>Scale boundary conditions</li> <li>Choose the definition of the characteristic unit for each var so that the coefficients of as many terms as possible become 1</li> <li>Rewrite system of equations in terms of new dimensionless quantities</li> </ol>"},{"location":"Misc/DoE/05_IDK/#example","title":"Example","text":"\\[ \\begin{aligned} c_t = c_0 e^{-kt} &amp;\\implies (c_t/c_0) = e^{-kt} \\\\ 3 \\text{ var} &amp; \\implies 2 \\text{ var} \\end{aligned} \\]"},{"location":"Misc/DoE/05_IDK/#unknown-functional-form","title":"Unknown Functional Form","text":"<p>Buckingham Pi Theorem</p>"},{"location":"Misc/DoE/09_idk/","title":"IDK","text":""},{"location":"Misc/DoE/09_idk/#pre-surveyexploratory-designs","title":"Pre-Survey/Exploratory Designs","text":"<p>Sequential approach: simple screening pre-survey experiment first (such as 2-level factorial design), followed by through investigation</p> <p>Use \\(\\le 25\\%\\) of total available data for collection into screening</p> <p>We want to know: what vars are the most important and over what ranges</p> <p>Do low-cost pre-survey DOE that focuses on high-priority</p> <p>Based on this outcome, perform full experiment</p>"},{"location":"Misc/DoE/09_idk/#experiment-pointers","title":"Experiment Pointers","text":"<ul> <li> <p>Always perform experiment with both trial &amp; control samples</p> </li> <li> <p>Always get the raw data; processing should be done by analyst, not data providers</p> </li> <li> <p>Every data point should have central tendency &amp; uncertainty associated</p> </li> <li>Incorporate all potential uncertainty associated with collecting the data &amp; use Uncertainty Propagation</li> <li>Observation: Use robust summary statistics: Median</li> <li>Spread/Uncertainty of estimate<ul> <li>Standard error, not standard deviation</li> <li>Use non-robust summary statistics</li> </ul> </li> <li>Every data point fed to model should be iid observation</li> </ul> <p></p>"},{"location":"Misc/DoE/09_idk/#data-template","title":"Data Template","text":""},{"location":"Misc/DoE/09_idk/#for-collection","title":"For Collection","text":"Type Category_ID Subcategory_ID Reading_ID Value Control Product A Sample 1 1 x Control Product A Sample 1 2 x Control Product A Sample 1 3 x Control Product A Sample 2 1 x Control Product A Sample 2 2 x Control Product A Sample 2 3 x Control Product B Sample 1 1 x Control Product B Sample 1 2 x Control Product B Sample 1 3 x Control Product B Sample 2 1 x Control Product B Sample 2 2 x Control Product B Sample 2 3 x Trial \u2026 \u2026 \u2026 \u2026"},{"location":"Misc/DoE/09_idk/#for-modelling","title":"For Modelling","text":"<p>We cannot use the collection data directly for modelling as each row is not iid observation. Hence aggregation is required to obtain the central tendency &amp; uncertainty for each iid observation.</p> Type Category_ID Subcategory_ID Central Tendency(Median) Uncertainty(IQR) Control Product A Sample 1 x x Control Product A Sample 2 x x Control Product B Sample 1 x x Control Product B Sample 2 x x Trial \u2026 \u2026 \u2026 \u2026"},{"location":"Misc/Driving/","title":"Driving","text":""},{"location":"Misc/Driving/#theory","title":"Theory","text":""},{"location":"Misc/Driving/#practicals","title":"Practicals","text":"<ul> <li>Vehicle controls</li> <li>Driving in 2-way streets</li> <li>Driving in multi-way streets</li> <li>Special maneuvers</li> <li>Parking</li> <li>60deg parking</li> <li>Garage reverse parking</li> <li>Parallel reverse parking</li> <li>Road</li> <li>Moving off in an incline</li> <li>Emergency brake</li> </ul>"},{"location":"Misc/Driving/01_Introduction/","title":"Introduction","text":""},{"location":"Misc/Driving/01_Introduction/#skills-required","title":"Skills Required","text":"<ul> <li>Car control</li> <li>Visual scanning</li> <li>Identifying and weighing risk</li> <li>Thinking &amp; responding</li> <li>Making decisions</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#road-user","title":"Road User","text":"<p>Anyone using the road</p> <ul> <li>People</li> <li>Pedestrians</li> <li>Children</li> <li>Cyclists/Motorcyclists</li> <li>People of determination</li> <li>Emergency vehicles</li> <li>Official vehicles</li> <li>Police</li> <li>Ambulance</li> <li>Fire Engine</li> <li> <p>Military vehicles</p> </li> <li> <p>Vehicles</p> </li> <li>Cars</li> <li>Trucks</li> <li>Trams</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#attitude-in-driving","title":"Attitude in Driving","text":"<p>Difficult in UAE due to people of different nations, making it hard to predict their move</p> <p>Responsibility to be positive and ensure everyone\u2019s safety</p> <ul> <li>Most traffic violations like beating the red light is usually caused by bad attitude of the driver</li> <li>Flashing headlights to intimidate others increases risk of crash</li> <li>Proper use of indicator provides allows other drivers to react appropriately</li> <li>Driving too fast for the situation is an unacceptable driving behavior</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#always-give-way","title":"Always give way","text":"<ul> <li> <p>Pedestrians</p> </li> <li> <p>Emergency vehicles</p> </li> <li> They will use Highways Fast lane Congested highways Emergency yellow area Internal roads Between vehicles Junction Between vehicles Junction with red light Move to the side without crossing the signal Roundabouts Do not enterIf you are already inside, keep moving and move to the right lane once exited </li> <li> <p>Tram</p> </li> </ul> <p>IDK</p> <ul> <li>Do not follow emergency vehicles</li> <li>Do not use emergency yellow area (road shoulders)</li> <li>People walking along or crossing the roads should be considered as among the many hazards on the road</li> <li>When dealing with pedestrian, drivers must give way, always</li> <li>When approaching a pedestrian crossing where pedestrians are present, drivers must stop and give way to pedestrians</li> <li>You are causing an obstruction to the tram and can attract fines if Stopping or parking near the tram track, and/or   Littering or fixing any hoarding at the tram track.</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#watch-out","title":"Watch out","text":"<ul> <li>Children: Do unexpected things</li> <li>People of determination vehicles</li> <li>School busses: Slow down, stop and wait till the bus starts moving</li> <li>Busses and taxi lanes</li> <li>Motorcyclist and cyclist: When drivers making right turns should watch out for cyclists</li> <li>Animals: unpredictable; Camels</li> <li>Do not horn as they cause them to run</li> </ul> <p>Areas</p> <ul> <li>Residential areas</li> <li>Mosques</li> <li>Playgrounds</li> <li>Shops</li> <li>Shopping malls</li> <li>Parks</li> <li>School areas</li> </ul> <p>Guideline (SSS)</p> <ul> <li>Space: 1.5m</li> <li>Speed: Slow down</li> <li>Sound: Lightly sound horn</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#weird-areas","title":"Weird Areas","text":"<p>Slip lane: free-right separated from main road by a traffic island</p> <p>\u2018Bicycle Shared Starting\u2019 Marking\u2019</p> <p></p> <p>\u2018Bicycle Shared Ending Marking\u2019</p> <p></p>"},{"location":"Misc/Driving/01_Introduction/#insurance","title":"Insurance","text":""},{"location":"Misc/Driving/01_Introduction/#parties","title":"Parties","text":"<ol> <li>Insurer</li> <li>Owner of vehicle and insurance policy</li> <li>Other vehicle involved in car accident</li> </ol>"},{"location":"Misc/Driving/01_Introduction/#policies","title":"Policies","text":"<ul> <li>Comprehensive/Full: All damage cost covered by insurance for both second and third party</li> <li>TPL (Third Party Liability): Will only cover damage cost for third party; second party will be responsible for bearing their own costs</li> </ul> <p>Conditions where insurance does not cover</p> <ul> <li>Driver under influence of alcohol/sedative medicine</li> <li>When driving different vehicle category without license</li> <li>When driving vehicle in a country where insurance does not cover</li> <li>When driver is driving without specs for whom it is mandatory as mentioned in license</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#consequences-of-accidents","title":"Consequences of accidents","text":"<ul> <li>Fatalities</li> <li>Serious injuries</li> <li>Vehicle damage</li> <li>Property damage</li> <li>Vehicle reparation</li> <li>Problems from vehicle insurance</li> <li>Fines</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#vehicle-safety-features","title":"Vehicle Safety Features","text":"<ul> <li>Seat belt</li> <li>Child restraint system add-on</li> <li>Baby seats<ul> <li>Rear-facing</li> <li>It provides more protection to baby head because neck is not fully developed and it is more vulnerable to the forces during brake or collision</li> <li>&lt;1 yr</li> <li>&lt;13 kg</li> <li>&lt;65 cm</li> <li>Integral harness</li> </ul> </li> <li>Child seat<ul> <li>Forward-facing</li> <li>1&gt;4 yrs</li> <li>9-18 kg</li> <li>65-95 cm</li> <li>Internal harness</li> </ul> </li> <li>Booster Seat<ul> <li>4-6 yrs</li> <li>15-25 kg</li> <li>95-125 cm</li> </ul> </li> <li>Booster cushion<ul> <li>6-11 yrs</li> <li>22-36 kg</li> <li>125-140 cm</li> </ul> </li> <li>Airbags: Designed to protect adults; children must be kept away</li> <li>SRS (Supplement Restraint System)</li> <li>Only effective when used with seat belts</li> <li>Distance between face and steering wheel should be &gt;25 cm</li> <li>Head restraint: Prevents whiplash injury</li> <li>Distance between head and restraint should be &lt;10cm</li> <li>Crumble zone</li> </ul>"},{"location":"Misc/Driving/01_Introduction/#driver-assistance-systems","title":"Driver Assistance Systems","text":"<ul> <li>Conventional Cruise Control</li> <li>Adaptive Cruise Control</li> <li>Intelligent Speed Assistance</li> <li>Lane Support Systems: &gt; 50 km/h</li> <li>Lane Departure Warning</li> <li>Lane Keep Assist</li> <li>Lane Centering Assist</li> <li>Blind Spot Monitoring</li> <li>Forward Collision Mitigation</li> <li>Forward COlloysion Warning</li> <li>Autonomous Emergency Braking</li> <li>Parking Assistance</li> <li>Anti-Lock Braking System</li> <li>Electronic Stability Programme</li> </ul>"},{"location":"Misc/Driving/02_Traffic_Signs/","title":"Traffic Signs","text":"Class Subclass Type Sign Image Road Signinformations, warnings, order Regulatorycontrol users must/must not do ControlAssign right-of-way priority/direction of travel Stop(even if there are no vehicles) Give way/YieldSlow down Give way to pedestrians Give way to cyclists Entry forbidden Go this way Mandatory Go this way Roundabout Tram Only Maximum Speed Limit Minimum Speed Limit Police Reduce Speed(Temporary) ProhibitoryActions that must not be taken No left/right No U-Turn No overtaking No goods (heavy) vehicles No hazardous material No pedestrians allowed No cyclists No horn Give priority oncoming traffic(Temporary) Cannot exceed speed limit Maximum height limit Maximum width limit Maximum weight limits Qualification PlateSupplementary to other signs, such as exceptions Parking Controlwhen and where you can/cannot park Paid Parking with time restrictions Parking with time restrictions Parking for people of determination drivers Paid Parking zone Reserved for RTA Taxis only Reserved for RTA Busses only Loading and unloading only Paid parking for loading and unloading of commercial vehicles No stopping/parking No stopping/parking during mentions timing No waiting(only pickup &amp; drop-off of passengers allowed) Freeway Controlwhich roads are classified as freeway Beginning of freeway End of freeway Warning Advance Warning(Triangular, red border, white background) Traffic Signal ahead Stop Sign ahead Give way sign ahead Roundabout ahead T-intersection ahead Side road ahead Intersection ahead Staggered junction ahead Other traffic merging You will merge to main road 2-way road 2-way road ahead(crosses one-way road) Dual carriageway ends(2 lanes join) Curve ahead Right lane ends ahead Road narrows on the side Lane closed ahead Diversion to opposite carriageway ahead No through road(Dead end) U-Turn ahead Steep hill ahead Pedestrian crossing ahead Children potentially ahead Bicycle crossing ahead Animals potentially ahead Road works ahead Maximum headroom at hazard ahead Tunnel ahead Low flying aircraft ahead(do not get distracted) Opening bridge ahead Quay side/river bank ahead Risk of falling rocks High voltage overhead ahead Humps ahead Uneven road Other dangers ahead Loose chippings Slippery road Beware edge way soft Tram crossing ahead Tram/Railway crossing to the right/left Hazard MarkerIdentify physical hazardsReflective to light Hazard PlateBridge structure, guard rails Hazard Marker Single ChevronIndicates road curve Multiple chevronSharp deviation T-Junction Chevron Single Tram/Railway line crossing over road 2 or more Tram/Railway line crossing over road2 lanes turning right and 1 lane making a u turn? Diagrammatic Warning- triangular advance warning sign does not have sufficient space for a picture- triangular advance warning sign not big enough to draw attention- mainly used in high-speed roads Right lane closure ahead Additional lane added Five lanes merging to fourMiddle lanes must be careful as both have equal priority Lane use control directional restriction: Heavy vehicles cannot use first lane Lane use control directional restriction: First lane Turn left only Beginning/end of median End of median Joining lane Sharp curve lanes ahead Tram route in single direction Tram route in both directions GuideDirection: Route #, Street Names, Destinations BlueNational routes, UAE emblem Emirates Route Emblem GreenMajor routes inside cities Dubai Route Emblem WhiteLocal RedHyperlocal TrailblazingRoute-finding signsRecognizable symbols/numbers to guide drivers to correct road Airport City Center National Route City Route Freeway Landmark/Tourist Destination Advance Exit One Lane Drop Two Lane Drop Other No through roadDead end ahead Priority for you more than vehicles from opposite direction Parking Hospital Countdown markers- Used in conjunction with other signs- Each bar represents 100m No turning for lorriesUsually for U-Turns Supplementary information sign Parking for country diplomats\u2019 cars onlyUsually near embassies, consulates Diversion of traffic route- Temporary- Usually at construction areas Other Reflective marker posts- Indicate edge of carriageway- Usually at curves, bends, diversions Lane use signals- Usually at tunnels, basement parkings Reduce Speed Now Road Clear- Usually after passing roadworks Do not enter junction until exit is clear- Usually at busy traffic intersections, tram area Penalty for Violation Keep off tramway(Pedestrians) VMS (Variable Message Sign)Messages take priority over other signs Toll- Salik uses RFID Road Markings- help position vehicle on the road- Yellow/White Regulatory- Tell drivers what they can/cannot do No passing/crossingexcept emergencyusually found on 2-way roads Stop Give wayUsually accompanied with give way sign Pedestrian crossing Pedestrian crossing with Zig-zag lineNo lane changing Box junctionsDrivers should not enter junction until exit is clear, even if signal is green Tram line pedestrian crossing Zig-zag zoneDrivers should not- park- stop, except to give way- reverse- change lane- overtake Tram box junction Warningused to warn drivers of approaching hazard Rumble strips Speed humps Upcoming tram crossing GuidanceHelp drivers understand paths they should follow at intersections/roundabouts Lines in center of road Short intermittent- Along carriageway- Used where there is no side road, junction, exits- Safe to change lane/overtake after checks Long intermittent- Along carriageway- Used where there is a side road, junction, exits- Potentially dangerous to change lane/overtake; drivers can do so, but must look out for vehicles joining their path Solid/Continuous- Near curves, hills, other danger zones- Drivers cannot overtake/change lanes unless emergency Broken yellow line- Along carriageway- 2 way/single carriageway roads- Be careful Broken white lines- Along carriageway- One way/dual carriageway roads Solid lines (single/double)- Along carriageway- Hazardous/unclear view (sharp bends)- Do not cross line Double yellow linesSolid on one size, broken on the other- Along carriageway- Drivers can only overtake/change lanes if broken line is on their side- Usually found in steep roads with bends End of carriageway Traffic lane Traffic lane arrows Traffic lane markings IDK Keep Entrance Clear Traffic Control Signalshelp control traffic flow Traffic light Red Yellow/Amber Green Directional light U Turn Left Intermittent lightFlashing yellow Pedestrian lights Red Green"},{"location":"Misc/Driving/02_Traffic_Signs/#traffic-signal-law","title":"Traffic Signal Law","text":"<p>If there is no traffic signal or police officer, the priority of crossing must be given to</p> <ul> <li>Joining road: Vehicle coming from main road</li> <li>Roundabout: Vehicle coming from left</li> </ul>"},{"location":"Misc/Driving/03_Risk/","title":"Risk","text":""},{"location":"Misc/Driving/03_Risk/#speed-limits-convention","title":"Speed Limits Convention","text":"Area Speed Limit(km/h) Parking 25 Service Road 25 Urban Single Carriageway 40 Urban Dual Carriageway 60/80 Rural Roads 100 Freeways 12060 (min) ## Moving Off Moving from stationary/low speed to match traffic speed <p>Slow moving off can disturb others</p> <ul> <li>Prepare</li> <li>Observe</li> <li>Move</li> </ul>"},{"location":"Misc/Driving/03_Risk/#controlled-intersections","title":"Controlled Intersections","text":"<ul> <li>T-Intersection<ul> <li>Continuing road</li> <li>Terminating road</li> </ul> </li> <li> <p>Junction</p> <ul> <li>Traffic light intersection</li> <li>No traffic light<ul> <li>Priority to vehicle that does not have stop sign/line</li> <li>If both have stop sign/line, Priority to vehicle that enters junction first</li> <li>If both arrive at the same time, priority to vehicle arriving from the left</li> </ul> </li> </ul> </li> <li> <p>Mirrors</p> </li> <li>Signals</li> <li>Position</li> <li>Speed</li> <li>Look around</li> </ul>"},{"location":"Misc/Driving/03_Risk/#turning","title":"Turning","text":"<p>MSPLS</p> <p>Right on Multi-lane road - Last lane to last lane - 2<sup>nd</sup> Last lane to any lane other than last lane</p>"},{"location":"Misc/Driving/03_Risk/#u-turn","title":"U-Turn","text":"<p>Should always be made from the first lane to the last lane</p> <p>Types - Open: Opposite to another road     -  - Closed:      -  - Three point u-turn     -  - Intersection u-turn</p>"},{"location":"Misc/Driving/03_Risk/#lane-discipline","title":"Lane Discipline","text":"<p>Changing lanes - Mirror center - Signal - Side mirror - Shoulder: Headcheck     - Do not look away from front for more than a second - Mirror center</p> <p>Overtaking - only allowed from the left side - be extremely careful overtaking a heavy vehicle due to their large blind spot - if someone is overtaking you, you must slow down</p>"},{"location":"Misc/Driving/03_Risk/#roundabouts","title":"Roundabouts","text":"<ul> <li>Keep left indicator on</li> <li>When exiting, turn right indicator on</li> </ul> <p>Types - Single lane - Two lane     - U-Turn: First lane         - Exit the left hand lane     - Left: First-Lane         - Exit the left hand lane     - Straight: 2<sup>nd</sup> lane         - Exit the right hand lane     - Right: 2<sup>nd</sup> lane         - Exit the right hand lane - Three lane     - U-Turn: First lane         - Exit the left hand lane     - Left: First-Lane         - Exit the left hand lane     - Straight: 2<sup>nd</sup> lane         - Exit the right hand lane     - Right: Use free-right if available, else 3<sup>rd</sup> lane         - Exit the right hand lane</p> Type Right Straight Left U-Turn 1 LaneEnter 1 1 1 1 2 LaneEnter 2 2 1 1 3 LaneEnter Free-right3, o.w 3: if free-right, parking required, need to turn right soon2, ow 1 1 1 LaneExit 1 1 1 1 2 LaneExit 2 2 1 1 3 LaneExit 3 3: if free-right, parking required, need to turn right soon2, ow 1 1 ## Parking <ul> <li>Parallel parking<ul> <li>Enter<ul> <li>Go ahead</li> <li>Headcheck</li> <li>Reverse</li> <li>Signal</li> <li>Go forward to fit</li> </ul> </li> <li>Exit<ul> <li>Reverse</li> <li>Headcheck</li> <li>Signal</li> <li>Forward</li> </ul> </li> </ul> </li> <li>60deg angle parking</li> <li>90deg angle parking<ul> <li>Forward</li> <li>Reverse: preferred as easier to exit</li> </ul> </li> </ul>"},{"location":"Misc/Driving/04_Focus/","title":"Focus","text":""},{"location":"Misc/Driving/04_Focus/#medication-fatigue-alcohol","title":"Medication, Fatigue, Alcohol","text":"<ul> <li>Be careful</li> <li>Alcohol tolerance level: 0</li> </ul>"},{"location":"Misc/Driving/04_Focus/#emotions","title":"Emotions","text":""},{"location":"Misc/Driving/04_Focus/#personality-traits","title":"Personality Traits","text":"<ul> <li>Actions</li> <li>Attitude</li> <li>Behavior</li> </ul>"},{"location":"Misc/Driving/04_Focus/#distractions","title":"Distractions","text":"<p>Mainly don't use phone</p>"},{"location":"Misc/Driving/04_Focus/#vision","title":"Vision","text":"<p>Visual field dec with inc speed</p> <p>Braking - Reaction distance     - Perception time     - Reaction time - Braking distance</p>"},{"location":"Misc/Driving/04_Focus/#space-management","title":"Space Management","text":"<p>Gates</p> <p></p> <p>Always have 2 gates open for emergency</p> <p>Forward - 2 sec rule when driving light vehicle - 3 sec rule when driving motorcycle - 4 sec rule when driving heavy vehicle</p> <p>Double the distance at night, or when the conditions are poor</p>"},{"location":"Misc/Driving/05_Environment/","title":"Environment","text":""},{"location":"Misc/Driving/05_Environment/#night-driving","title":"Night Driving","text":"<ul> <li>Much harder at night, than day</li> <li>Eye adaptation: Close eyes for a few seconds before starting to drive to speed up eyes to adjust to low light</li> <li>Avoid interior lights, dim dashboard lights</li> <li>Use low beam whenever, and use high beam only when required as it may dazzle other drivers</li> </ul>"},{"location":"Misc/Driving/05_Environment/#fog","title":"Fog","text":"<ul> <li>Use low beam headlights and fog lights; high beam will reflect</li> <li>Use defrost for front glass</li> <li>Don't overtake</li> </ul>"},{"location":"Misc/Driving/05_Environment/#sandstorm","title":"Sandstorm","text":""},{"location":"Misc/Driving/05_Environment/#slippery-and-sandy-roads","title":"Slippery and Sandy Roads","text":""},{"location":"Misc/Driving/05_Environment/#rain","title":"Rain","text":"<ul> <li>Initial rain drops is more dangerous, since they loosen the grease and dirt</li> <li>Poor visibility</li> <li>Poor tyre traction</li> <li>Aquaplaning/Hydroplaning<ul> <li>Buildup of Layer of water between wheels and road</li> <li>At low speeds, good tyre designs can dissipate water buildup; this is hard at high speeds</li> </ul> </li> <li>Large braking distance<ul> <li>Double the safe distance</li> </ul> </li> </ul>"},{"location":"Misc/Driving/05_Environment/#times-of-the-day","title":"Times of the day","text":"<ul> <li>Sunrise/Sunset: Glares can cause issues</li> <li>Peak traffic hours</li> </ul>"},{"location":"Misc/Driving/05_Environment/#natural-forces","title":"Natural Forces","text":""},{"location":"Misc/Driving/06_Rules/","title":"Rules","text":""},{"location":"Misc/Driving/06_Rules/#freeway","title":"Freeway","text":""},{"location":"Misc/Driving/06_Rules/#interchanges","title":"Interchanges","text":"<ul> <li>Cloverleaf<ul> <li></li> </ul> </li> <li>Arterial</li> </ul>"},{"location":"Misc/Driving/06_Rules/#common-traffic-offences-accidents","title":"Common traffic offences &amp; accidents","text":"<ul> <li>Speeding</li> <li>Sudden swerving</li> <li>Abrupt lane changing</li> <li>Lack of lane discipline</li> <li>Not maintaining safe distance</li> <li>Illegal overtaking</li> <li>Not wearing seatbelt</li> <li>Using phone while driving</li> <li>Illegal parking</li> </ul>"},{"location":"Misc/Driving/06_Rules/#vehicle-seizure","title":"Vehicle Seizure","text":"<ul> <li>Unauthorized road races</li> <li>Recreational motorcycle on paved roads</li> <li>Illegal vehicle modifications</li> <li>Reckless driving</li> <li>Escaping from police</li> <li>Running red light</li> <li>Driving without registration plate</li> <li>Illegal tint level</li> <li>Using fake/concealed number plate</li> <li>Intentionally colliding/Damaging police vehicle</li> <li>Allowing person under 18 to operate vehicle</li> </ul>"},{"location":"Misc/Driving/07_Hazards_Emergencies/","title":"Hazards &amp; Emergencies","text":""},{"location":"Misc/Driving/07_Hazards_Emergencies/#hazard-perception","title":"Hazard Perception","text":"<ul> <li>Hazard<ul> <li>Types<ul> <li>Actual</li> <li>Potential</li> </ul> </li> <li>Kinds<ul> <li>Static</li> <li>Dynamic</li> <li>Environmental</li> </ul> </li> </ul> </li> <li>Cause of hazard</li> <li>Perception</li> </ul>"},{"location":"Misc/Driving/07_Hazards_Emergencies/#emergencies","title":"Emergencies","text":"<ul> <li>Emergency gear<ul> <li>First aid kit</li> <li>Portable fire extinguisher</li> <li>Owner's manual</li> <li>High visibility safety vest (\\(\\ge 2\\))</li> <li>Reflective triangle</li> <li>Flashlight</li> <li>Jump cables</li> <li>Spare tyre</li> <li>Tyre jack</li> <li>Lug wrench</li> <li>Brick/wedge</li> <li>Tyre pressure gauge</li> <li>Gloves</li> <li>Engine oil</li> <li>Brake oil</li> <li>Coolant</li> </ul> </li> <li>Mechanical knowledge<ul> <li>Stuck vehicle in sand<ul> <li>Reduce tyre pressure</li> <li>Keep using quick bursts of low rpm acceleration</li> </ul> </li> <li>Engine overheating<ul> <li>Open hood</li> <li>Replenish coolant without turning off engine; be careful of radiator cap as it will be extremely hot</li> <li>If not going away, turn off engine</li> </ul> </li> <li>Flat tyre<ul> <li></li> </ul> </li> <li>Dead battery<ul> <li>Turn off both engines</li> <li>Connect like terminals</li> <li>Start on the good engine</li> <li>Be careful when removing wires</li> </ul> </li> <li>Breakdown</li> </ul> </li> </ul>"},{"location":"Misc/Driving/07_Hazards_Emergencies/#accidents","title":"Accidents","text":"<ul> <li>Minor crash<ul> <li>Pull over</li> <li>Go to Dubai Police app</li> <li>File a report<ul> <li>Take photo of car from afar</li> </ul> </li> </ul> </li> <li>Major crash</li> <li>Fire</li> </ul>"},{"location":"Misc/Driving/08_Your_Vehicle/","title":"Your Vehicle","text":""},{"location":"Misc/Driving/08_Your_Vehicle/#accidents","title":"Accidents","text":"<ul> <li>Road accidents<ul> <li>Pedestrians</li> <li>Vehicles in front</li> <li>Vehicles behind</li> <li>Vehicles at junction</li> <li>While going straight/left turn</li> <li>Passing vehicles</li> <li>Oncoming vehicles</li> <li>Single vehicle</li> </ul> </li> </ul>"},{"location":"Misc/Driving/08_Your_Vehicle/#avoiding-accidents","title":"Avoiding accidents","text":""},{"location":"Misc/Driving/08_Your_Vehicle/#maintenance","title":"Maintenance","text":"<p>POWER - Petrol - Oil/Lubricants     - Engine oil     - Power steering oil     - Brake fluid     - Automatic         - transmission oil     - Manual         - Gear oil         - Clutch fluid     - Differential oil - Water/Fluids     - Coolant         - Radiator             - Never open cap directly as it can be extremely hot         - Reservoir tank     - Windscreen washer fluid - Electric     - Battery         - Wet cell/flooded/rechargeable         - Maintenance-free - Rubber     - Tyres         - Tyre type         - Tyre condition             - Age             - Depth             - Tread wear indicator             - Visual inspection         - Wheel alignment         - Pressure     - Hoses &amp; pipes         - Radiator hoses         - Hydraulic hose         - Fuel hose         - Vacuum hose     - Belts         - Serpentine belt         - Timing belt     - Wiper blades</p>"},{"location":"Misc/Driving/08_Your_Vehicle/#dashboard","title":"Dashboard","text":"<ul> <li>Red: Important</li> <li>Yellow: Warning</li> <li>Green: System is on</li> </ul>"},{"location":"Misc/Energy/","title":"Energy","text":""},{"location":"Misc/Energy/#recommend-readings","title":"Recommend Readings","text":"<ul> <li> Sustainable Energy without the Hot Air | David JC MacKay</li> <li>Only focus on physical &amp; technological issues</li> <li>Not on economics/politics</li> </ul>"},{"location":"Misc/Energy/#references","title":"References","text":"<ul> <li> Renewables in electricity markets | DTU</li> <li> Energy Trading, Portfolio and Risk Management | Brandenburg University</li> <li> Foundations for Energy Data Analytics | Duke University</li> <li> Energy Economics | Virtual University of Pakistan</li> <li> Data-Driven Analytics and Optimization for Energy Systems | DTU</li> <li> Energy and the Environment</li> <li> MIT 11.165 Urban Energy Systems and Policy, Fall 2022</li> <li> The Energy Academy | Modo Energy</li> <li> MIT 15.031J Energy Decisions, Markets, Policies, Spring 2012</li> <li> Intelligent and Integrated Energy Systems Part 1| TUD</li> <li> Intelligent and Integrated Energy Systems Part 2 | TUD</li> <li> Decision Making on Future Energy Systems | TUD</li> <li> Business of Future Energy Systems | TUD</li> <li> Digitalization of Intelligent and Integrated Energy Systems | TUD</li> <li> Energy Systems Analysis | Gang He</li> <li> Energy Transition | TU Delft</li> <li> Renewable Energy | Swiss Learning Exchange</li> <li> Solar Energy | TU Delft</li> <li> Wind Energy | TU Denmark</li> <li> Renewables in Energy Markets | Jalal Kazenpour | TU Denmark</li> <li> Advanced Optimization and Game Theory for Energy Markets | Jalal Kazenpour | TU Denmark</li> </ul>"},{"location":"Misc/Energy/01_Introduction/","title":"Introduction","text":""},{"location":"Misc/Energy/01_Introduction/#why-is-energy-special","title":"Why is energy special?","text":"<ul> <li>There should be equilibrium between power generation and consumption</li> <li>Transportation and distribution performed on power network, with specific physical rules</li> <li>Storage is uneconomical</li> <li>Large part of energy demand is of critical nature (hospitals, residencies)</li> <li>Consumers should not differentiate origin, quality and nature of production</li> </ul>"},{"location":"Misc/Energy/01_Introduction/#deregulation","title":"Deregulation","text":"Regulated De-regulated Prices determined by Regularity body \u201cInvisible hand\u201d of market Structure Vertical integration Horizontal restructuring Supplier Fixed Multiple- Competition <p>Chile &gt; UK &gt; Scandinavia &gt; California (crisis, shortage, Enron)</p>"},{"location":"Misc/Energy/01_Introduction/#participants","title":"Participants","text":"Grid Operators TSO (Transmission System Operator) Operates transmissions assetsResponsible for power balance on transmission system DisCo (Distribution Company)DSO (Distribution System Operator) Operates distribution gridOften acts as retailer (not preferable) Producers GenCo (Generating Company)/IPP (Independent Power Producer) Owns production assetsGeneration is offered through energy market Intermediary Retailer Buys energy from wholesale electricity marketSales to end-consumers Consumers Household (small)/Industrial (large) Use energy for various purposesLarge consumers may be allowed to directly participate in whole electricity market Regulator Market designRulesMonitoringCurb misbehavior (collusion, power abuse) Operator Organizes and operates energy marketDefinition of bid products &amp; formsSet up &amp; maintenance of trading platformDaily matching of supply and demand offers"},{"location":"Misc/Energy/01_Introduction/#models","title":"Models","text":"Monopoly Purchasing Agent Wholesale Market Retail Market Consumer-Centric Peer-Peer ModelMicro-Grids Supplier-Centric Consumer-Centric Characteristic Hierarchical Decentralized \u201cProsumers\u201d"},{"location":"Misc/Energy/01_Introduction/#markets","title":"Markets","text":""},{"location":"Misc/Energy/01_Introduction/#types","title":"Types","text":"Capacity For system operator to ensure that sufficient generation capacity is present for reliable system operation in future year and at competitive prices Energy Central place for optimal scheduling and settlement of energy exchanges Ancillary Service Any type of service that supports power system operations, directly bought by system operator- Primary reserves- Secondary reserves- Tertiary receivers (manual)- Black-start capability, short-circuit power, reactive reserves, voltage control"},{"location":"Misc/Energy/01_Introduction/#financial","title":"Financial","text":"Market Meaning Futures Financial contracts with time horizons unto 6 yearsUsed for price hedging and risk management Day-ahead/Spot Central instrument for everyday matching of electricity supply and demand Balancing Close to real-time operator for system operator to ensure power system balance Intra-day Continuous trading platform between day-ahead and balancingAllows to correct original schedules (when plant outages/changes in wind power generation)"},{"location":"Misc/Energy/01_Introduction/#challenges","title":"Challenges","text":"Variable energy demand\u201cDuck Curve\u201d Renewable energy generation is variable and non-dispatchable Renewable energy generation is hard to forecast"},{"location":"Misc/Energy/01_Introduction/#economic-impact-of-renewable-energy","title":"Economic impact of renewable energy","text":"<p>Wind and solar energy induces a downward pressure on market prices</p>"},{"location":"Misc/Energy/01_Introduction/#quest-for-flexibility","title":"Quest for Flexibility","text":"<p>Flexibility is seen as ability to adapt to variable and unforeseen changes in operating conditions</p> <ul> <li>Generation units</li> <li>Power system</li> <li>Demand side</li> <li>Integrated energy systems view (heat and gas energy systems)</li> </ul>"},{"location":"Misc/Energy/01_Introduction/#traditional-vs-renewable","title":"Traditional vs Renewable","text":"Traditional Renewable Producers Fossil fuels WindSolar Fixed Production \u2705 \u274c Fixed Demand \u274c \u274c Cost distribution Demand DemandSupply <p>Probabilistic matching rather than regular price matching</p>"},{"location":"Misc/Energy/02_Spot_Markets/","title":"Spot Markets","text":""},{"location":"Misc/Energy/02_Spot_Markets/#bilateral-contracts","title":"Bilateral Contracts","text":"<pre><code>flowchart LR\nb[Buyer]\nbr[Broker]\ns[Seller]\n\nb &lt;--&gt; br &lt;--&gt; s\nb &lt;--&gt; s</code></pre> <p>Direct exchange of energy between buyer and seller in a decentralized fashion</p> <p>System operator is informed about trades that occur</p>"},{"location":"Misc/Energy/02_Spot_Markets/#types","title":"Types","text":"Customized long-term contracts OTC (Over the counter) Electronic Trading Consistently matches supply and offer bids Flexible \u2705 \u274c Private transactions \u2705 \u274c Transaction costs High(due to Broker) Low \\(\\approx 0\\) Speed Fast(allows for trading \u201cuntil last second\u201d) Trade volume Large Small Duration Long Small"},{"location":"Misc/Energy/02_Spot_Markets/#auctions-in-energy-pool","title":"Auctions in Energy Pool","text":"<ul> <li>All generation bids and consumption offers are placed at same time</li> <li>No one knows about others\u2019 bids and offers</li> <li>Centralized market clearing decides bids and offers that are retained</li> <li>Eventually, the system operator is informed about the trades that occurred</li> </ul>"},{"location":"Misc/Energy/02_Spot_Markets/#merit-order","title":"Merit Order","text":"<ul> <li>Consumption orders are ranked in dec price order</li> <li>Supply bids are ranked in inc price order</li> </ul>"},{"location":"Misc/Energy/02_Spot_Markets/#social-welfare","title":"Social Welfare","text":"<p>Area between consumption and generation</p> <p>Equilibrium point is that which allows to maximize social welfare</p> <ul> <li>Any buyer is to pay almost what they were ready to pay</li> <li>Any seller will get at least what they were ready to sell for</li> </ul> <p></p>"},{"location":"Misc/Energy/02_Spot_Markets/#market-clearing","title":"Market Clearing","text":"<p>Goal</p> <ul> <li>Schedule for all supply and demand offers</li> <li>Price at which market is cleared</li> </ul> <p>Inputs</p> <ul> <li>All offers in the market are formulated in terms of quantity \\(Q\\) and price \\(P\\)</li> <li>Supply side</li> <li>Set of offers</li> <li>Maximum quantity for offer</li> <li>Price for offer</li> <li>Demand side</li> <li>Set of offers</li> <li>Maximum quantity for offer</li> <li>Price for offer</li> </ul> <p>Decision variables</p> <ul> <li>Generation schedule</li> <li>Consumption schedule</li> </ul> <p>Objective: Maximize social welfare</p> <p>Constraints</p> <ul> <li>Non-negativity of supply and demand</li> <li>Balance of generation and consumption</li> <li>Generation and consumption within limits</li> </ul>"},{"location":"Misc/Energy/02_Spot_Markets/#settlement-process","title":"Settlement Process","text":"<ul> <li>Who should pay what?</li> <li>Who should get paid what amount?</li> </ul>"},{"location":"Misc/Energy/02_Spot_Markets/#approaches","title":"Approaches","text":"Pay-as-bid Uniform Every party pays/receives whatever they bid the same equilibrium amount Advantages Overcomes limitations of pay-as-bidYields budget balance: sum of revenues equal to sum of payments Disadvantages Supplier may receive 0 revenue, which won\u2019t cover their fixed costsConsumers incentivized to lower bids; suppliers incentivized to increase bids <p>Both approaches guarantee</p> <ul> <li>individual rationality: consumers will pay at most what they were ready to pay, and producers will receive at least what they were ready to receive</li> <li>Revenue adequacy: Sum of revenues \\(\\ge\\) Sum of payments</li> </ul>"},{"location":"Misc/Energy/02_Spot_Markets/#geographic-prices","title":"Geographic Prices","text":"<p>Prices vary across various locations, as power has to flow through network involved</p> <p>Exchanges capacity limitations</p> <ul> <li>There is a maximum amount of energy that can be exchanged from one location to another</li> <li>When this limit is reached, there is congestion and prices for connected areas will different</li> <li>Exchange capacity limitations are directly related to network constraints and operational practice</li> </ul>"},{"location":"Misc/Energy/02_Spot_Markets/#approaches-to-handle-exchange-capacity-limitations","title":"Approaches to handle exchange capacity limitations","text":"Zonal Nodal System Operator TSO ISO Market Operator Ind. Market Operator ISO Offers Market Products Unit Capabilities Clearing Supply-demand equilibrium UCED Problem Network representation Simplified Detailed Prices Zonal Nodal Used in Europe US <p>Market is not-budget balanced anymore, as the sum of consumer payments &gt; sum of supplier revenues; difference defines congestion rent to be collected by system operator(s)</p>"},{"location":"Misc/Energy/02_Spot_Markets/#approach-1-split","title":"Approach 1: Split","text":"<p>Due to transmission constraints, the market has to be split and be treated as individual sub-markets</p> <ul> <li>Submarkets have their own supply-demand equilibrium</li> <li>Transmission-related offers: Extra (price-independent) consumption/generation offers representing the transmission from one zone to the next to be added</li> </ul> <p></p>"},{"location":"Misc/Energy/02_Spot_Markets/#approach-2-flow-based-coupling","title":"Approach 2: Flow-based coupling","text":"<p>Instead of boldly splitting market, one could instead acknowledge how power flows</p> <p>This allows clearing a single market with geographically-differentiated prices</p> <p></p>"},{"location":"Misc/Energy/02_Spot_Markets/#regulation-support-schemes","title":"Regulation &amp; Support Schemes","text":"<p>Grid parity = scenario when it is profitable to produce energy, ie Levelized Cost of Energy (cost of energy production) &lt; market price</p> <p>New energy generation tech may need support in order to reach grid parity</p> <ul> <li>Regulation is an instrument for policy makers to support their integration in the market</li> <li>Support schemes consist in financial support to make them competitive in the market</li> </ul> <p>These have impact on participant revenues, offering strategies, market outcomes</p> <p>Types</p> FIT FIP CFT Meaning Feed-in-tariff Fixed Feed-in-Premium Contract for difference/ Sliding Premium Implication Guaranteed price Fixed support regardless of market revenue Compensation of difference between guaranteed price and market revenue Blue: Support revenueGreen: Market Revenue Implication for producer Just ensure you get scheduledBid as low as possible <p>Safe policy to guarantee non-negative equilibrium prices: FIP or CfD at 0</p>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/","title":"Intra-Day &amp; Balancing Markets","text":"<p>Convergence towards real-time operations relies on</p> <ul> <li>BRP</li> <li>Adjustment Market: Intra-day market mechanism</li> <li>Balancing Market: (near) realtime market</li> </ul> <p>If a deviation from the original schedule occurs (for producer/consumer)</p> <ul> <li>Re-dispatch of own units: Compensate with other generation/consumption means within their own portfolio</li> <li>Intra-day/adjustment market: Find ways to adjust through agreements with other players between day-ahed market clearing and actual operation</li> <li>Balancing market: Let system operator put system back to balance</li> </ul>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/#day-ahead-market","title":"Day-Ahead Market","text":"<p>Day-Ahead market is a financial market with</p> <ul> <li>Pool based on auction mechanism</li> <li>Only transactions</li> <li>No generation/consumption</li> <li>Market participants and system operator are informed about market clearing outcomes (price &amp; volumes for each market time unit)</li> <li>In European set-up, the market participants will then self-dispatch, ie determine themselves how they will generate/consume depend on volumes &amp; prices</li> <li>Fairly long time before actual operation [12, 36] hours</li> </ul>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/#brp","title":"BRP","text":"<p>Balance Responsible Parties</p> <p>Companies that can and may handle the balance responsibility for production and consumption units and/or trades actual electricity.</p>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/#intra-day-market","title":"Intra-Day Market","text":"<p>Intra-Day Market is based on bilateral contracts, even though handled through central platform</p> <p>Purpose: Need for corrective actions may highly vary  depending upon how new information disclosure occurs between day-ahead market clearing and actual operation</p> <p>Features</p> <ul> <li>Fewer players</li> <li>Lesser liquidity</li> <li>Low trade volume</li> </ul> <p>Organization: leaning towards electronic reading</p> <p>Flexibility summarizes the impact of operational constraints (ie, minimum up and downtime, ramping, minimum operating point, etc)</p> <p>You need not only buy alone or sell alone; you can do both to exploit any market inefficiencies</p> <p>It may be difficult to foresee the actual imbalance that would need to be fixed eventually</p> <p>Decision-making in such adjustment markets can be complex &amp; stressful</p>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/#balancing-market","title":"Balancing Market","text":"<ul> <li>Regulation market: Participants that offer to buy/sell, prior to hour of operations</li> <li>Balancing market: Participants cover the cost of their contribution to place the system off-balance</li> </ul>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/#cases","title":"Cases","text":"<ul> <li>Positive: Supply &gt; Demand: downward regulation required</li> <li>Negative: Supply &lt; Demand: upward regulation required</li> <li>Balanced: Supply \\(\\approx\\) Demand: no regulation required</li> </ul>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/#payment-settlement","title":"Payment Settlement","text":"<ul> <li>One-price: Total payment/revenue of day-ahead market participants for deviations from schedule equals revenue/payment of balancing generators</li> <li>If one\u2019s own deviation leads to off-balancing system, it leads to a loss</li> <li>If one\u2019s own deviation helps in balancing system, it leads to a profit</li> <li>Two-price</li> <li>Those off-balancing system penalized</li> <li>Those supporting system (unintentionally) will not get extra rewards</li> </ul>"},{"location":"Misc/Energy/03_Intra_Day_and_Balancing_Markets/#causes-of-imbalance","title":"Causes of Imbalance","text":"<ul> <li>Electric load is greater/less than forecasted at the time of market-clearing</li> <li>Renewable energy generation is greater/less than forecasted at the time of market-clearing</li> <li>Outages/operational difficulties of production units</li> <li>Outages/operational difficulties of transmission equipments</li> <li>Internal congestion (within market/balancing zone)</li> </ul>"},{"location":"Misc/Energy/04_Ancillary_Services/","title":"Ancillary Services","text":"<p>Services required by transmission/distribution system operator to enable them to maintain the integrity and stability of transmission/distribution system as well as power quality</p>"},{"location":"Misc/Energy/04_Ancillary_Services/#types","title":"Types","text":""},{"location":"Misc/Energy/04_Ancillary_Services/#reserve-types","title":"Reserve Types","text":"Reserve Primary Shared among all system operatorsDaily day-ahead auctionsInflexible demandNeeds upward &amp; downward capacityEnergy not considered (energy-neutral service ) Secondary Relieve primary reserve which has ben activatedRestore any imbalance on interconnectionsCapacity purchases on monthly basisCombines symmetric upward &amp; downward productsBased on bilateral contracts (negotiated; non-public)Negative revenue in downward regulation case consists in buying back energy that is already sold through day-ahead market Tertiary Daily day-ahead auctionsVarying demandNeed upward &amp; downward capacityEnergy paid for at balancing price"},{"location":"Misc/Energy/04_Ancillary_Services/#activation-approaches","title":"Activation Approaches","text":"Reactive Corrective Proactive Preventive"},{"location":"Misc/Energy/04_Ancillary_Services/#quantify-need-for-ancillary-services","title":"Quantify need for ancillary services","text":"<p>Depends on total uncertainty which is based on</p> <ul> <li>Supply-side uncertainty</li> <li>Demand-side uncertainty</li> </ul>"},{"location":"Misc/Energy/05_Impact_of_Renewables/","title":"Impact of Renewables","text":""},{"location":"Misc/Energy/05_Impact_of_Renewables/#electricity-cost-structure","title":"Electricity Cost Structure","text":"<ul> <li>Electricity Generation</li> <li>Electricity Transport/Transmission</li> <li>Taxes</li> </ul>"},{"location":"Misc/Energy/05_Impact_of_Renewables/#idk","title":"IDK","text":"<p>The forecasts of renewable energy generation is what drives the prices, not the actual generation</p> <p>Wind acts as a stochastic driver since having the lowest short-run marginal cost, with quantiles based on forecasts (13-37 hrs ahead)</p> <p>Higher (forecasted) production of renewable energy \\(\\implies\\)\u00a0lower energy price</p>"},{"location":"Misc/Energy/06_Participation_of_Renewables/","title":"Participation of Renewables","text":""},{"location":"Misc/Energy/06_Participation_of_Renewables/#market-participants","title":"Market Participants","text":"<ul> <li>Price taker: Decisions and resulting offers (buying/selling) does not affect market outcomes</li> <li>Price maker: Decisions and resulting offers (buying/selling) affects market outcomes</li> </ul>"},{"location":"Misc/Energy/06_Participation_of_Renewables/#market-participation-strategy","title":"Market Participation Strategy","text":"<ol> <li>Increase your offer</li> </ol> \\(E_i\\) Limitations Trust the forecastDirectly take forecasts and make offers \\(\\hat E_i\\) Susceptible to balancing costs from under-producing Increase your offer \\(\\tau \\hat E_i\\)\\(\\tau &gt; 1\\) Be bold and just max out generation Unrealistic (Requires knowledge of future balancing prices)"},{"location":"Misc/Energy/06_Participation_of_Renewables/#revenue-analysis","title":"Revenue Analysis","text":"<p>Performance Ratio $$ \\begin{aligned} \\gamma &amp;= (R_\\text{DA} + R_B)/R^*_\\text{DA} \\ \\gamma &amp; \\in (0, 1) \\end{aligned} $$ where</p> <ul> <li>\\(R_\\text{DA} =\\) revenue from day-ahead</li> <li>\\(R_\\text{DA} =\\) revenue from balancing market</li> <li>\\(R_\\text{DA} =\\) Optimal revenue</li> </ul>"},{"location":"Misc/Energy/06_Participation_of_Renewables/#news-vendor-problem","title":"News vendor problem","text":"<p>How much should news vendor buy from printing store to maximize expected revenue</p> <p>Bank cashflow problem: how much a bank should keep in reserves to satisfy request for withdrawal</p>"},{"location":"Misc/Energy/06_Participation_of_Renewables/#requirements","title":"Requirements","text":"<ul> <li>One shot opportunity to decide on quantity of interest</li> <li>Uncertain outcome</li> <li>Known marginal revenue, profit, loss</li> <li>Objective: maximize expected revenue</li> </ul>"},{"location":"Misc/Energy/06_Participation_of_Renewables/#solution","title":"Solution","text":"<p>Optimal number \\(n^*\\) such that $$ \\begin{aligned} \\alpha^* &amp;= \\dfrac{\\pi<sup>+}{\\pi</sup>+ + \\pi^-} \\ n^* &amp;= F<sup>{-1}(\\alpha</sup>*) \\end{aligned} $$ where</p> <ul> <li>\\(\\pi^+ = \\lambda^R - \\lambda^P =\\) unit cost of buying less than needed</li> <li>\\(\\pi^- = \\lambda^P - \\lambda^T =\\) unit cost of buying more than needed</li> <li>\\(\\alpha^* =\\) Normal level of original CDF F</li> </ul>"},{"location":"Misc/Energy/06_Participation_of_Renewables/#uncertainty","title":"Uncertainty","text":"\\[ n^* = \\hat F^{-1}(\\hat \\alpha^*) \\\\ \\implies n_t^* = \\hat F_t^{-1}(\\hat \\alpha_t^*) \\]"},{"location":"Misc/Energy/06_Participation_of_Renewables/#notes","title":"Notes","text":"<p>The optimal strategy can change over time</p>"},{"location":"Misc/Energy/07_Analytics/","title":"Renewable Energy Analytics","text":"<p>Forecasting helps make decisions</p>"},{"location":"Misc/Energy/07_Analytics/#what-to-forecast","title":"What to forecast","text":"<p>Different participants have different needs</p> <ul> <li>Electric load</li> <li>Day-ahead prices</li> <li>Potential imbalance sign</li> <li>Regulation prices/penalties</li> <li>Potential congestion on interconnectors</li> <li>Generation from renewable sources</li> </ul> <p>All these are driven by weather and climate</p>"},{"location":"Misc/Energy/07_Analytics/#use-cases","title":"Use cases","text":"<ul> <li>Definition of reserve requirements</li> <li>Unit commitment and economic dispath</li> <li>Coordination of renewables with storage</li> <li>Design of optimal trading strategies</li> <li>Electricity market clearing</li> <li>Optimal maintenance planning (especially for offshore wind farms)</li> </ul> <p>Inputs to these methods are</p> <ul> <li>deterministic forecasts</li> <li>probabilistic forecasts such as quantiles intervals and predictive distributions</li> <li>probabilistic forecasts in the form of trajectory or scenarios</li> <li>Risk indices</li> </ul>"},{"location":"Misc/Energy/07_Analytics/#features-for-forecasting","title":"Features for forecasting","text":"<ul> <li>Recent power generation measurements</li> <li>Weather forecasts for upcoming future</li> <li> <p>Other: Off-sit measurements, radar image, etc</p> </li> <li> <p>Short-term (&lt;6hrs): power generation measurements are more important</p> </li> <li>Medium-term (6-96hrs): weather forecasts are more important</li> <li>Long-term (&gt;96hrs): weather forecasts become less important, as long-term weather forecasts are not reliable</li> </ul> <p></p>"},{"location":"Misc/Energy/07_Analytics/#power-curve","title":"Power Curve","text":"<p>Power curve shapes the distribution of prediction errors</p> Ideal Actual"},{"location":"Misc/Energy/07_Analytics/#uncertainty","title":"Uncertainty","text":""},{"location":"Misc/Energy/07_Analytics/#causes-of-non-stationarity","title":"Causes of Non-Stationarity","text":"<ul> <li>Seasonality</li> <li>Equipment condition</li> <li>Wind Blades cleanliness</li> <li>Solar panel cleanliness</li> </ul>"},{"location":"Misc/Energy/99_Cities/","title":"Cities","text":""},{"location":"Misc/Energy/99_Cities/#why-cities","title":"Why Cities?","text":"<p>Intersection of Tech, Policies, Markets</p> <p>Urban population has the major concentration of populations, and it is continuously increasing</p> <p></p> <p></p>"},{"location":"Misc/Energy/99_Cities/#the-balance-sheet","title":"\u2018The Balance Sheet\u2019","text":"<p>Energy Consumption vs Sustainable Energy Production</p>"},{"location":"Misc/Energy/99_Cities/#key-sources-of-consumption","title":"Key Sources of Consumption","text":"<ul> <li>Transport</li> <li>Cars</li> <li>Planes</li> <li>Freight</li> <li>AC</li> <li>Heating</li> <li>Cooling</li> <li>Lighting</li> <li>Electronics</li> <li>Food</li> <li>Production</li> <li>Transporting</li> <li>Maintaining</li> <li>Manufacturing</li> </ul>"},{"location":"Misc/Energy/99_Cities/#key-sources-of-sustainable-production","title":"Key sources of sustainable production","text":"<ul> <li>Wind</li> <li>Solar</li> <li>photovoltaics</li> <li>thermal</li> <li>Biomass</li> <li>Hydroelectric</li> <li>Wave</li> <li>Tide</li> <li>Geothermal</li> <li>Nuclear (unclear whether nuclear counts as sustainable)</li> </ul>"},{"location":"Misc/Energy/99_Cities/#key-concepts","title":"Key Concepts","text":""},{"location":"Misc/Energy/99_Cities/#energy","title":"Energy","text":"<ul> <li>Quantitative property of doing work</li> <li>Conserved: can neither be created/destroyed</li> <li>Transformation: Light, heat, mass; \\(E=mc^2\\)</li> <li>Forms: Kinetic, Chemical, potential, mechanical (elastic), biological</li> <li>Units: kWh, Joules, calories, terms</li> <li>Fossil fuels: Barrels, short tons, cubic feet</li> </ul>"},{"location":"Misc/Energy/99_Cities/#power","title":"Power","text":"<ul> <li>Quantitative rate of doing work</li> <li>Energy per time</li> <li>Units: Watts, ergs, horsepower, lumen*</li> </ul>"},{"location":"Misc/Energy/99_Cities/#emissions-intensity","title":"Emissions Intensity","text":"<ul> <li>Unit: mtcde: metric-ton carbon-dioxide equivalent</li> <li>There are many forms of greenhouse gases, so we usually use CO2 equivalent</li> <li>by gas, per unit of energy, per activity, per GDP, by region</li> </ul>"},{"location":"Misc/Energy/99_Cities/#energy-consumption","title":"Energy Consumption","text":"<p>Usually shown using Sankey diagrams</p> <p></p> <p>Rejected energy is the by-product of energy generation that is not used (energy lost due to heat loss, air resistance, etc)</p>"},{"location":"Misc/Energy/99_Cities/#deep-decarbonization","title":"Deep Decarbonization","text":"<p>Goal of getting to net-zero emissions by 2050</p> <p></p>"},{"location":"Misc/Energy/99_Cities/#aspects-of-urban-energy-planning","title":"Aspects of Urban Energy Planning","text":"<ul> <li>Technological Implementation</li> <li>Geography</li> <li>Politics</li> <li>Land use &amp; built environment</li> </ul>"},{"location":"Misc/Energy/99_Cities/#key-issues-with-monitoring","title":"Key Issues with Monitoring","text":"<ul> <li>City, urban definitions</li> <li>Types of emissions: upstream (import), downstream (exports &amp; waste), goods &amp; services</li> <li>Measurement of affluence: Wealth vs Income</li> </ul>"},{"location":"Misc/Energy/99_Cities/#just-energy-transition","title":"Just Energy Transition","text":"<p>Environmental equity: reducing risk for all communities; distribution and effects os environmental problems and policies and processes to reduce differences in who bears environmental risks</p> <p>Climate Justice</p> <ul> <li>Historical responsibility</li> <li>Inter-generational equity</li> <li>Disproportionate causes and burdens</li> <li>Grassroots movements</li> <li>Legal actions on climate change</li> </ul> <p>Transformative justice</p> <ul> <li>Practices designed to create change in social systems</li> </ul> <p>Energy justice</p> <ul> <li>Disproportionate access, harms, burdens</li> <li>Unions &amp; worker</li> <li>Fossil-fuel dominated communities<ul> <li>Create a lot of jobs</li> </ul> </li> <li>Frontline/EJ communities </li> </ul> Distributional equitable distribution of burdens &amp; benefits of energy and environmental decisions Procedural Right to fair process for different stakeholders to take part equitably in decision-making process Restorative Repair harm done to individuals, instead of focusing upon punishing the offender Recognition Recognizing that parts of society might suffer as result of energy &amp; environmental decisions, and identifying individuals and groups who might be impacted by such decisions Cosmopolitan Reinforces all of the above, but states that \u201cabove forms of justice must apply universally to al human beings\u201d"},{"location":"Misc/Energy/99_Cities/#just-framework","title":"Just Framework","text":""},{"location":"Misc/Energy/99_Cities/#importance-of-land-uses-and-land-cover","title":"Importance of land uses and land cover","text":"<ul> <li>Total sequestration potential is uncertain</li> <li>Natural/existing ecosystems are more efficient than restored ones</li> <li>Policy mechanisms may be wildly different for different ecosystems</li> <li>Farm preservation vs biodiversity protections</li> <li>Carbon storage may fit into different regimes</li> </ul> <p>Controlling the spatial expansion of cities is crucial</p> <p>https://www.youtube.com/watch?v=EWFGkZ64ng4&amp;list=PLUl4u3cNGP63SEOB1q95TFs0hwyf1d7BG&amp;index=5</p>"},{"location":"Misc/Reproducible_Research/00/","title":"00","text":"<p>John Hopkins University</p> <p>Coursera</p>"},{"location":"Misc/Reproducible_Research/01/","title":"01","text":"<p>The fundamental problem of data analysis is that \\(\\not \\exists\\) notation system for communicating results of data analysis.</p>"},{"location":"Misc/Reproducible_Research/01/#replication","title":"Replication","text":"<p>The standard for strengthening scientific evidence is replication of findings and conducting studies with independent investigators, data, analytical methods, laboratories, instruments</p> <p>However, replication is not always possible, as it is expensive, time-consuming, unique</p> <p>Hence, we aim for reproducibility, which is a compromise between replication and doing nothing</p>"},{"location":"Misc/Reproducible_Research/01/#reproducibility","title":"Reproducibility","text":""},{"location":"Misc/Reproducible_Research/01/#requirements","title":"Requirements","text":"<ul> <li>Analytic data</li> <li>Analytic code</li> <li>Documentation of code and data</li> <li>Standard means of distribution</li> </ul>"},{"location":"Misc/Reproducible_Research/01/#what-we-get","title":"What we get","text":"<ul> <li>Transparency</li> <li>Availability of data, software, methods</li> <li>Improved transfer of knowledge</li> </ul> <p>However, it does not necessarily ensure correctness of analysis. Reproducible analysis may still be wrong</p>"},{"location":"Misc/Reproducible_Research/01/#problems","title":"Problems","text":"<p>so some of the problems I have with reproducibility </p> <p>are, so the premise of reproducible research is that, </p> <p>you know, with all the data and all the </p> <p>code available to people, people can check each other. </p> <p>You can kind of validate someone else's analysis, and the whole </p> <p>system would kind of be self correcting in the long run. </p> <p>Alright. </p> <p>So one problem which I don't see here is </p> <p>that the long run sometimes is too long and then </p> <p>in terms of the context of the problems that </p> <p>you're dealing with I think reproducibility addresses what I call </p> <p>most, the kind of downstream aspects of scientific dissemination. </p> <p>Now, I'll be more specific about what I mean by that. </p> <p>Meaning that it kind of only happens post publication [INAUDIBLE]. </p> <p>And another key thing which is important in my area, maybe. </p> <p>I mean, particularly in my area, is that, [COUGH] </p> <p>the ideas of reproducibility kind of assume that everyone </p> <p>plays by the same rules, and everyone wants to </p> <p>achieve the same goals, which is definitely not tru</p>"},{"location":"Misc/Reproducible_Research/01/#challenges","title":"Challenges","text":"<ul> <li>Authors must take effort to publish results on the web (resources such as web servers may not be available)</li> <li>Readers must download the data and results individually and combine everything on their own</li> <li>Readers may not have the same resource as authors</li> </ul>"},{"location":"Misc/Reproducible_Research/01/#replication-vs-reproducibility","title":"Replication vs Reproducibility","text":"Replication Reproducibility Ensures validity of Scientific claim Data analysis"},{"location":"Misc/Reproducible_Research/01/#research-pipeline","title":"Research Pipeline","text":""},{"location":"Misc/Reproducible_Research/01/#literate-statistical-programming","title":"Literate (Statistical) Programming","text":"<p>An article is a stream of text and code</p> <p>Analysis code is divided into text and \u2018code chunks\u2019</p> <p>Code chunks load data and computes results</p> <p>Presentation code formats results</p> <p>Literate program is</p> <ul> <li>weaved to human-readable documents</li> <li>tangled to machine-readable documents</li> </ul> <p>Notes</p> <ul> <li>Do not affect the raw data - ever</li> <li>Do not save output and import them as images</li> <li>Save data in non-proprietary formats (csv, sqlite)</li> </ul>"},{"location":"Misc/Reproducible_Research/01/#requires","title":"Requires","text":"<ul> <li>Documentation lang (human readable)   for eg: latex, markdown</li> <li>Programming lang (machine readable)   for eg: python, r</li> </ul> <p><code>knitr</code> incorporates both of these through Rmarkdown </p>"},{"location":"Misc/Reproducible_Research/01/#pros","title":"Pros","text":"<ul> <li>Text and code in one place, logical order</li> <li>Data and results update automatically to external changes</li> </ul>"},{"location":"Misc/Reproducible_Research/01/#cons","title":"Cons","text":"<ul> <li>Hard for author to work, as everything is one place</li> <li>Can slow down processing of documents</li> </ul>"},{"location":"Misc/Reproducible_Research/01/#steps-in-data-analysis","title":"Steps in data analysis","text":"<ol> <li>Define question in the most simple, atomic, concrete manner</li> <li>Define ideal dataset</li> <li>Determine data access</li> <li>Obtain data</li> <li>Data Cleaning</li> <li>EDA</li> <li>Statistical Prediction/Modelling</li> <li>Interpreting results</li> <li>Challenge results</li> <li>Synthesize results</li> <li>Create reproducible code</li> </ol>"},{"location":"Misc/Reproducible_Research/02/","title":"Coding Standards","text":"<ul> <li>Always write code in human-readable text files, this ensures everyone will be access your code</li> <li>Indent code</li> <li>Limit width of code to 80 char</li> <li>Limit length of individual functions to performing one particular task</li> </ul>"},{"location":"Misc/Reproducible_Research/02/#markdown","title":"Markdown","text":""},{"location":"Misc/Reproducible_Research/02/#rmarkdown","title":"RMarkdown","text":""},{"location":"Misc/Reproducible_Research/02/#library-to-pretty-print-tables","title":"Library to pretty print tables","text":"<pre><code>library(xtrable)\nxt &lt;- xtable(summary(fit))\nprint(xt, type=\"html\")\n</code></pre>"},{"location":"Misc/Reproducible_Research/02/#default-settings","title":"Default Settings","text":"<pre><code>```{r setoptions, echo=FALSE}\n# do not display this default settings block\nopts_chunk$set(\n  echo=FALSE, # hide code of all code chunks\n  results=\"hide\", # hide outputs of all code chunks\n)\n```\n</code></pre>"},{"location":"Misc/Reproducible_Research/02/#caching","title":"Caching","text":"<pre><code>```{r setoptions, cache = TRUE}\nmy code blah blah()\n```\n</code></pre>"},{"location":"Misc/Reproducible_Research/02/#knitr","title":"<code>knitr</code>","text":"<pre><code>flowchart LR\nrmd --&gt; md --&gt; html &amp; pdf</code></pre>"},{"location":"Misc/Reproducible_Research/03/","title":"Communicating Results","text":"<p>People are busy, hence yo ushould breakdown results into different levels of detail</p>"},{"location":"Misc/Reproducible_Research/03/#research-paper","title":"Research Paper","text":"<ul> <li>Title</li> <li>Author list</li> <li>Abstract</li> <li>Body</li> <li>Results</li> <li>Supplementary Materials (details)</li> <li>Code/Data (more details)</li> </ul>"},{"location":"Misc/Reproducible_Research/03/#email","title":"Email","text":"<ul> <li>Subject</li> <li>Summarize findings in one sentence</li> <li>Email body</li> <li>Brief description of problem</li> <li>Recall what was proposed</li> <li>Recall what was executed</li> <li>Summary findings in 1-2 paragraphs</li> <li>If you want to suggest future actions, make them concrete</li> <li>If you have questions for them to address, make them yes/no</li> <li>Attachments</li> <li>Literate Programming File</li> <li>Links to supplementary materials</li> <li>Code/Software/Data</li> <li>Github Repo/Project Website</li> </ul>"},{"location":"Misc/Reproducible_Research/03/#rpubs","title":"RPubs","text":"<p>Free site to publish work</p>"},{"location":"Misc/Reproducible_Research/03/#reproducible-research-checklist","title":"Reproducible Research Checklist","text":"<p>\u2705 Start with good science</p> <ul> <li>Garbage in, Garbage out</li> <li>Coherent, focused question</li> <li>working with good collaborators</li> <li>Something that\u2019s interesting to you</li> </ul> <p>\u274c Don\u2019t use GUI softwares for analysis, as it is hard to reproduce</p> <p>\u274c Don\u2019t do things by hand</p> <ul> <li>Using spreadsheets to perform operations</li> <li>Editing tables/figures manually</li> </ul> <p>\u2705 Document unavoidable manual operations (not as easy at is it sounds)</p> <ul> <li>Downloading data from a website</li> <li>Moving data to outside project folder</li> <li>Splitting/reformatting data files</li> </ul> <p>\u2705 Teach a computer to do tasks</p> <ul> <li>Downloading data</li> </ul> <pre><code>download.file(\"somelink/file.csv\", \"local_location/file.csv\")\n</code></pre> <ul> <li>Web scraping</li> </ul> <p>\u2705 Use version control (such as Git)</p> <ul> <li>Helps slow down and perform tasks step by step</li> <li>Add changes in small chunks</li> </ul> <p>\u2705 Keep track of software environment</p> <ul> <li>Write cross-platform code</li> <li>For eg, in python be careful when working with paths. Use <code>os.path.join(folder, file)</code> instead of <code>folder + \"/\" + file</code></li> <li>Computer Architecture</li> <li>CPU, GPU specs</li> <li>Operating System</li> <li>Software toolchain</li> <li>Compilers/Interpreter</li> <li>Programming languages</li> <li>Command shell</li> <li>Database backends</li> <li>Data analysis softwares</li> <li>Supporting software</li> <li>Libraries</li> <li>Packages</li> <li>Dependencies</li> <li>External dependencies</li> <li>Websites</li> <li>Data/Software repositories</li> <li>Remote databases</li> <li>Version Numbers</li> </ul> <p>\u274c Don\u2019t save output independent of code</p> <p>\u2705 Set your seed for random number generator</p>"},{"location":"Misc/Sports/","title":"Sports Analytics","text":""},{"location":"Misc/Sports/#references","title":"References","text":"<ul> <li> Sports Performance Analytics Specialization | University of Michigan</li> <li> Mathematical modelling of football</li> </ul>"},{"location":"School/Computer_Science/","title":"Computer Science","text":"<p>I had the best ever school teachers: Malini ma\u2019am &amp; Viji ma\u2019am.</p> <p>I even used her notes when studying for university courses. The PDF to that scanned document can be found below: </p> <ul> <li> <p>Part - 1 -  History of C, Tokens, Strucuture of a Program, Data-Types, Escape Sequences, Characters .vs. Strings, Operators &amp; Expressions, Increment &amp; Decrement Operators, Hierarchy of Math Operators, Short Hand Expressions, Literals, Type-Casting, Flow of Control, If-Elif-Else, Loops - While, Do-While &amp; For, Jump, Break</p> </li> <li> <p>Part - 2 - Arrays, Linear Search, Binary Search, Bubble Sort, Insertion Sort, Selection Sort. </p> </li> </ul>"},{"location":"School/Linux_Fundamentals/","title":"Computer Science","text":"<p>Notes have been compiled from Network Chuck's \"Linux For Hackers\" Series and HackerRank Bash Scripting Section. </p>"},{"location":"School/Linux_Fundamentals/bash/","title":"Bash","text":"<ol> <li> <p>Read - Takes Input, '$' sign for variables.     <pre><code>read name\necho (\"Welcome $name\")\n</code></pre></p> </li> <li> <p>For Loops: Have two braces for Math Ops (())     <pre><code>for ((i = 1; i &lt;= 100; i+=2))\ndo\n    $i\ndone\n</code></pre></p> </li> <li> <p>While Loop Structure - do, (stuff), done</p> </li> <li> <p>We use \" | bc\" for math operations.      <pre><code>echo(\"5+3\") | bc\n</code></pre></p> </li> <li> <p>Conditionals : if, elif, else, fi</p> <pre><code>read input\n\nif [ $input == \"y\" ] || [ $input == \"Y\" ]; then \n    echo \"YES\"\nelse \n    echo \"NO\"\nfi\n</code></pre> </li> <li> <p>grep : Will search and print matching. </p> <p><pre><code>grep -iwE \"the|that|then|those\" \n\n# i - To search case-insensitive. \n# w - To ignore case. \n# E - To compare as an extended regex, to allow use of \"|\"\n\ngrep -v \"that\" \n# v - Will show invert of what you're searching.\n</code></pre> 7. sed : To replace. </p> <pre><code>sed 's/the /this /1'\n#Space to avoid words like \"therefore\"\n\nsed -e 's/thy/your/ig' -e 's/Thy/Your/ig' -e 's/tHy/YouR/ig'\n#To replace mutliple words with one\n# -e is for editing\n\nsed -e 's/thy/{&amp;}/gi'\n#Make it highlight in curly braces. \n\nsed -e 's/([0-9]+) ([0-9]+) ([0-9]+) ([0-9]+)/\\4 \\3 \\2 \\1/' \n#Back-Refrencing. \n#E - for extended regular expression \n</code></pre> </li> <li> <p>awk - For comparision and parsing.     <pre><code>awk '{ if ($4 == \"\") print \"Not all scores are available for \"$1}'\nVariable out of the \"\". \n\nawk '{ if (($2 &gt;= 50) &amp;&amp; ($3 &gt;= 50) &amp;&amp; ($4 &gt;=50)) {print $1\" : Pass\"} else {print $1\" : Fail\"}}'\n\n\nawk '{\ntotal = ($2 + $3 + $4)/3\nif (total &gt;= 50 &amp;&amp; total&lt; 60)\n    print $1,$2,$3,$4, \": C\"\nelse if (total &gt;= 60 &amp;&amp; total &lt; 80)\n    print $1,$2,$3,$4, \": B\"\nelse if (total &gt;= 80)\n    print $1,$2,$3,$4, \": A\" \nelse \n    print $1,$2,$3,$4, \": FAIL\" }'\n\n\nawk '\n    BEGIN {count=0}\n\n    {\n        printf \"%s %d %d %d\", $1, $2, $3, $4\n        count++;\n        if (count%2 == 0)\n            printf \"\\n\"  \n        else\n            printf \";\"\n    }\n'\n</code></pre></p> </li> <li> <p>Arrays: </p> <pre><code>while read country\ndo\n    countries=(\"${countries[@]}\" \"$country\")\ndone\necho \"${countries[@]}\"\n# First one is array, second one is element being added to array. \n\n\nwhile read country\ndo \n    countries+=($country)\ndone\necho \"${countries[@]:3:5}\"\n#Sliced\n\nwhile read country\ndo \n    if [[ \"$country\" != *a* &amp;&amp; \"$country\" != *A* ]]; then\n        countries+=(\"$country\")\n    fi\ndone\necho \"${countries[@]}\"\n# Filterting on the basis of letter. \n\nwhile read line\ndo\n    elements+=(i)\ndone \necho ${#elements[@]}\n# counts - \"#\"\n</code></pre> </li> <li> <p>Cut</p> <pre><code>while read lines\ndo\n    echo \"$lines\" | cut -c3\ndone\n# Cut a specifc character. \n\nwhile read lines\ndo\n    echo \"$lines\" | cut -c 2,7\ndone\n# Cut multiple characters. \n\nwhile read lines\ndo\n    echo \"$lines\" | cut -c 2-7\ndone\n# Cut a range of charavters. \n\nwhile read lines \ndo \n    echo \"$lines\" | cut -d $'\\t' -f 1-3\ndone\n# -d : only takes one character so use 'X'\n\nwhile read lines \ndo \n    echo $lines | cut -c 13-\ndone\n# Print from X character to the end. \n\nwhile read line\ndo\n    echo \"${line}\" | cut -d ' ' -f 4\ndone\n# 4th Word, delimeter is ' '.\n</code></pre> </li> <li> <p>Head and Tail: </p> <pre><code>head -n 20 \n# For first 20 lines of text. \n\nhead -c 20 \n# For first 20 characters of text. \n\nhead -n 22 | tail -n +12\n# First 22 characters &amp;&amp; Prints from 12th to last (22nd Character)\n</code></pre> </li> <li> <p>tr and sort : tr replaces, sort sorts (lol)</p> <pre><code>tail -n 20\n# Last 20 lines.\n\ntr '()' '[]'\n# Replace. \n\ntr -d \"(a-z)\"\n# Delete all lower-case characters. \n\ntr -s ' '\n# Squeezes spaces.\n\nsort -f\n# Sorts in alphabetical order, -f ignore case. \n\nsort -r\n# Sorts in reverse alphabetical order. \n\nsort -n \n# Sorts in numerically ascending order. \n\nsort -n -r\n# Sorts in numerically descending order. \n\nsort -r -n -k 2 -t $'\\t'\n# -r : For reverse order \n# -n : numerical sort \n# -k: column ordering \n# -t : tab separted indicator\n</code></pre> </li> <li> <p>Uniq:      <pre><code>    uniq\n    # Eliminates repetitions. \n\n    uniq -c \n    # Counts the repitions. \n</code></pre></p> </li> <li>Paste:     <pre><code>paste -d'\\t' -s\n# '-s' tells the command to write everything sequentially in one line. \n\npaste -s -d ';'\n# Pastes with a delimeter specified. \n</code></pre></li> </ol>"},{"location":"School/Math/","title":"Math","text":"<p>These are just a few of the major math notes from grade 12.</p> <p>Still haven't added all of the notes, however.</p>"},{"location":"School/Math/01_Trignometric/","title":"01 Trignometric","text":"Rule Product \\(2 \\sin x \\cos y\\) \\(\\sin(x+y) + \\sin(x-y)\\) \\(2 \\cos x \\sin y\\) \\(\\sin(x+y) - \\sin(x-y)\\) \\(2 \\cos x \\cos y\\) \\(\\cos(x+y) + \\cos(x-y)\\) \\(2 \\sin x \\sin y\\) \\(\\cos(x-y) - \\cos(x+y)\\) Sum \\(\\sin C + \\sin D\\) \\(2 \\sin \\left( \\frac{C+D}{2} \\right) \\cos \\left( \\frac{C-D}{2} \\right)\\) \\(\\sin C - \\sin D\\) \\(2 \\cos \\left( \\frac{C+D}{2} \\right) \\sin \\left( \\frac{C-D}{2} \\right)\\) \\(\\cos C + \\cos D\\) \\(2 \\cos \\left( \\frac{C+D}{2} \\right) \\cos \\left( \\frac{C-D}{2} \\right)\\) \\(\\cos C - \\cos D\\) \\(-2 \\sin \\left( \\frac{C+D}{2} \\right) \\sin \\left( \\frac{C-D}{2} \\right)\\) \\(\\tan(x+y)\\) \\(\\frac{\\tan x + \\tan y}{1 - \\tan x \\tan y}\\) \\(\\tan(x-y)\\) \\(\\frac{\\tan x - \\tan y}{1 + \\tan x \\tan y}\\) Double \\(\\sin 2x\\) \\(2 \\sin x \\cos x\\) \\(\\frac{2 \\tan x}{1 + \\tan^2 x}\\) \\(\\cos 2x\\) \\(\\cos^2 x - \\sin^2 x\\)\\(2\\cos^2 x - 1\\)\\(1 - 2 \\sin^2 x\\) \\(\\frac{1-\\tan^2 x}{1 + \\tan^2 x}\\) \\(\\tan 2x\\) \\(\\frac{2 \\tan x}{1 - \\tan^2 x}\\) \\(\\cot 2x\\) \\(\\frac{\\cot^2 x - 1}{2 \\cot x}\\) Triple \\(\\sin 3x\\) \\(3 \\sin x - 4\\sin^3 x\\) \\(\\cos 3x\\) \\(4\\cos^3 x - 3\\cos x\\) \\(\\tan 3x\\) \\(\\frac{3\\tan x - \\tan^3 x}{1 - 3 \\tan^2 x}\\) \\(\\cot 3x\\) \\(\\frac{3 \\cot x - \\cot^3 x}{1 - 3 \\cot^2 x}\\) Half \\(\\tan \\frac{x}{2}\\) \\(\\text{cosec }x - \\cot x\\) \\(\\sqrt{\\frac{1-\\cos x}{1+\\cos x}}\\) \\(\\cot \\frac{x}{2}\\) \\(\\text{cosec }x + \\cot x\\) \\(\\sqrt{\\frac{1+\\cos x}{1-\\cos x}}\\)"},{"location":"School/Math/02_Integration/","title":"02 Integration","text":"<p>For simplicy, I\u2019ve excluded</p> <ul> <li>\\(dx\\) for pre-integration</li> <li>\\(+ c\\) for post-integration</li> </ul> Pre-Integration Post-Integration Basic \\(x^n, n \\ne -1\\) \\(\\frac{x^{n+1}}{n+1}\\) \\(\\frac{1}{x}\\) \\(\\log x\\) \\(e^x\\) \\(e^x\\) \\(a^x\\) \\(\\frac{a^x}{\\log a}\\) Coefficient \\(f(ax+b)\\) \\(\\frac{F(ax + b)}{a}\\) Trignometric \\(\\sin x\\) \\(- \\cos x\\) \\(\\cos x\\) \\(\\sin x\\) \\(\\tan x\\) \\(\\log \\vert \\sec x\\vert\\) \\(-\\log\\vert \\cos x \\vert\\) \\(\\cot x\\) \\(\\log \\vert \\sin x\\vert\\) \\(-\\log\\vert \\text{cosec } x \\vert\\) \\(\\sec x\\) \\(\\log\\vert \\sec x + \\tan x\\vert\\) \\(-\\log\\vert \\sec x - \\tan x \\vert\\) \\(\\text{cosec }x\\) \\(\\log\\vert \\text{cosec } x - \\cot x\\vert\\) \\(-\\log\\vert \\text{cosec } x + \\cot x \\vert\\) \\(\\sec x \\tan x\\) \\(\\sec x\\) \\(\\text{cosec }x \\cot x\\) \\(-\\text{cosec } x\\) \\(\\sec^2 x\\) \\(\\tan x\\) \\(\\text{cosec}^2 x\\) \\(- \\cot x\\) IDK \\(\\frac{1}{\\sqrt{1-x^2}}\\) \\(\\sin^{-1} x\\) \\(-\\cos^{-1} x\\) \\(\\frac{1}{\\sqrt{1+x^2}}\\) \\(\\tan^{-1} x\\) \\(-\\cot^{-1} x\\) \\(\\frac{1}{x \\sqrt{x^2 - 1}}\\) \\(\\sec^{-1} x\\) \\(- \\text{ cosec}^{-1} x\\) Squares \\(\\frac{1}{a^2 + x^2}\\) \\(\\frac{1}{a} \\tan^{-1} \\left( \\frac{x}{a} \\right)\\) \\(\\frac{1}{x^2 - a^2}\\) \\(\\frac{1}{2a} \\log\\left\\vert \\frac{x-a}{x+a}\\right \\vert\\) \\(\\frac{1}{a^2 - x^2}\\) \\(\\frac{1}{2a} \\log\\left\\vert \\frac{a+x}{a-x}\\right \\vert\\) Den Roots \\(\\frac{1}{\\sqrt{a^2 - x^2}}\\) \\(\\sin^{-1} \\left( \\frac{x}{a} \\right)\\) \\(\\frac{1}{\\sqrt{x^2 + a^2}}\\) \\(\\log\\left\\vert  x + \\sqrt{x^2 + a^2} \\right \\vert\\) \\(\\frac{1}{x \\sqrt{x^2 - a^2}}\\) \\(\\frac{1}{a} \\sec^{-1} \\left(\\frac{x}{a}\\right)\\) Num Roots \\(\\sqrt{a^2 - x^2}\\) \\(\\frac{x}{2} \\sqrt{a^2 - x^2} + \\frac{a^2}{2} \\sin^{-1}\\left(\\frac{x}{a}\\right)\\) \\(\\sqrt{a^2 + x^2}\\) \\(\\frac{x}{2} \\sqrt{a^2 + x^2} + \\frac{a^2}{2} \\log \\vert x + \\sqrt{a^2 + x^2}  \\vert\\) \\(\\sqrt{x^2 - a^2}\\) \\(\\frac{x}{2} \\sqrt{x^2 - a^2} - \\frac{a^2}{2} \\log \\vert x + \\sqrt{x^2 - a^2} \\vert\\) IDK \\(e^x \\Big(f(x) + f'(x) \\Big)\\) \\(e^x f(x)\\) \\(x \\Big(f(x) + f'(x) \\Big)\\) \\(x f(x)\\) Parts/ILATE \\(\\int (uv) dx\\) \\(u \\int vdx + \\int \\left(u' {\\small \\int} vdx \\right)\\)"},{"location":"School/Math/02_Integration/#partial-fractions","title":"Partial Fractions","text":"Function Partial Fraction \\(\\frac{px+q}{(x-a)(x-b)}\\) \\(\\frac{A}{(x-a)} + \\frac{B}{(x-b)}\\) \\(\\frac{px^2 + qx + r}{(x-a)(x-b)(x-c)}\\) \\(\\frac{A}{(x-a)} + \\frac{B}{(x-b)} + \\frac{C}{(x-c)}\\) \\(\\frac{px+q}{(x-a)^3}\\) \\(\\frac{A}{(x-a)} + \\frac{B}{(x-a)^2} + \\frac{C}{(x-a)^3}\\) \\(\\frac{px^2 + qx + r}{(x-a)^2 (x-b)}\\) \\(\\frac{A}{(x-a)} + \\frac{B}{(x-a)^2} + \\frac{C}{(x-b)}\\) \\(\\frac{px^2 + qx + r}{(x-a) (x^2 + bx + c)}\\) \\(\\frac{A}{(x-a)} + \\frac{Bx + C}{(x^2 + bx + c)}\\)"},{"location":"School/Math/02_Integration/#properties","title":"Properties","text":"\\(\\left(\\int f(x) \\cdot dx \\right)'\\) \\(f(x)\\) \\(\\int f'(x) dx\\) \\(f(x) + c\\) \\(\\int k \\cdot f(x) dx\\) \\(k \\int f(x) dx\\) \\(\\int \\Big(f(x) \\pm g(x) \\Big) \\ dx\\) \\(\\int f(x) \\ dx \\pm \\int g(x) \\ dx\\)"},{"location":"Tools/","title":"Tools","text":""},{"location":"Tools/#references","title":"References","text":"<ul> <li> Missing Semester 2020 | MIT</li> <li> Missing Semester 2019 | MIT</li> </ul>"},{"location":"Tools/Windows/","title":"Windows","text":""},{"location":"Tools/Windows/#run-program-without-admin-privileges","title":"Run program without admin privileges","text":"<p>Be careful; this does not eliminate the need for authorization. Never run any programs without authorization.</p> <p>Useful to run run program with low privileges</p>"},{"location":"Tools/Windows/#run_program_namebat","title":"<code>run_{program_name}.bat</code>","text":"<pre><code>Set __COMPAT_LAYER=RunAsInvoker\nStart program_name.exe\n</code></pre>"},{"location":"Tools/misc/","title":"Misc","text":""},{"location":"Tools/misc/#mirror-a-website","title":"Mirror a website","text":"<pre><code>wget --no-parent -r -l 2 -P . \"https://otexts.com/fpp3\"\n</code></pre>"},{"location":"Tools/misc/#scraping","title":"Scraping","text":"<p>Use wayback machine for verifying past scraping, for eg number of listings, etc</p>"},{"location":"Tools/AI%20%26%20Data/Model_Specification/","title":"Model Specification","text":""},{"location":"Tools/AI%20%26%20Data/Model_Specification/#base","title":"Base","text":"<pre><code>class Math:\n    def __str__(self):\n        return self.latex()\n    def __repr__(self):\n        return str(self)\n    def equation(self):\n        return \"\"\n    def latex(self):\n        return \"\"\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Model_Specification/#cost-functions","title":"Cost Functions","text":"<pre><code>class LogCosh(math.Math):\n    def cost(self, true, pred, sample_weight, delta=None):\n        error = pred - true\n\n        loss = np.log(np.cosh(error))\n        cost = np.mean(\n            sample_weight * loss\n        )\n        return cost\n\n    def latex(self):\n        return r\"\"\"\n        $$\n        \\Large\n        \\text{Mean Log Cosh}: \\text{mean} \\Big\\{ \\log \\left \\vert \\ \\cosh (u_i) \\ \\right \\vert \\Big \\} \\\\\n        \\text{where } u_i = \\text{ Prediction - True}\n        $$\n        \"\"\"\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Model_Specification/#models","title":"Models","text":"<pre><code>from utils.math import *\n\nfrom inspect import getfullargspec, getsource\nfrom string import Template\n</code></pre> <pre><code>class Model(Math):\n    def __init__(self, to_be_grouped=False):\n        name = (\n            self.__class__.__name__\n            .replace(\"_\", \" \")\n            .replace(\"Model\", \"\")\n            .strip()\n        )\n        self.__class__.__name__ = name\n        self.__name__ = name\n\n        args = getfullargspec(self.equation).args\n        self.args = tuple([arg for arg in args if arg not in [\"self\", \"x\"]])\n        self.k = len(self.args)\n\n        self.defaults = list(getfullargspec(self.equation).defaults)\n\n        self.param_initial_guess = [\n            x[0]\n            for x\n            in self.defaults\n        ]\n\n        self.param_initial_guess = (\n            [0 for arg in self.args]\n            if (self.param_initial_guess is None) or (self.k != len(self.param_initial_guess))\n            else self.param_initial_guess\n        )\n\n        self.param_bounds = [\n            x[1]\n            for x\n            in self.defaults\n        ]\n\n        self.param_bounds = (\n            [(None, None) for arg in self.args]\n            if (self.param_bounds is None) or (self.k != len(self.param_bounds))\n            else self.param_bounds\n        )\n\n        if \"constraints\" not in dir(self):\n            self.constraints = []\n\n        self.fitted_coeff_ = None\n        self.fitted_coeff_formatted_ = None\n        self.to_be_grouped = to_be_grouped\n\n    def set_fitted_coeff(self, *fitted_coeff):\n        self.fitted_coeff_ = fitted_coeff\n    def set_fitted_coeff_formatted(self, *fitted_coeff_formatted):\n        self.fitted_coeff_formatted_ = fitted_coeff_formatted\n    def __str__(self):\n        fillers = (\n            self.args\n            if self.fitted_coeff_formatted_ is None\n            else self.fitted_coeff_formatted_\n        )\n\n        fillers = dict()\n\n        if self.fitted_coeff_formatted_ is None:\n            a, b = self.args, self.args\n        else:\n            a, b = self.args, self.fitted_coeff_formatted_\n\n        for key, value in zip(a, b):\n            fillers[key] = value\n\n        equation = Template(self.latex()).substitute(fillers).replace(\"$\", \"$$\")\n        # st.code(string)\n\n        return rf\"\"\"\n        $$\n        \\text{{ {self.__class__.__name__} }}\n        $$\n\n        {equation}\n        \"\"\"\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Model_Specification/#example","title":"Example","text":"<pre><code>class Zero_Order(Model):\n    def __init__(self):\n        super().__init__(to_be_grouped=True)\n    # @jax.jit\n    def equation(\n        self, x,\n        k = [0, (0, None)]\n    ):  # hypothesis\n        ca = x[\"Previous_Reading\"]\n        # ta = x[\"Time_Point_Diff\"]\n        # tb = x[\"Time_Point\"]\n        t = x[\"Time_Point_Diff\"]\n        return np.clip(\n            (\n                ca - k * t\n            ),\n            0,\n            ca # np.inf\n        )\n    def quantile(self, X_test, X_train, y_train, link_distribution_dof, link_distribution_q):\n        ca_train = X_train[\"Previous_Reading\"]\n        t_train = X_train[\"Time_Point_Diff\"]\n\n        ct_train_true = y_train\n        k_train_true = -(1/t_train) * (ct_train_true - ca_train)\n\n        ct_train_hat = ( # chat_t\n            self.equation(X_train, *self.fitted_coeff_)\n        )\n        k_train_hat = -(1/t_train) * (ct_train_hat - ca_train)\n\n        u = k_train_hat - k_train_true # np.log(k_train_hat/k_train_true) # -(1/t_train) * np.log(ct_train_hat / ct_train_true) \n\n        X_train[\"u\"] = u\n        u_grouped = X_train.groupby(\"Temperature\")[\"u\"].agg([\"mean\", \"std\", \"count\"])\n        u_grouped = u_grouped.reset_index()\n        n = u_grouped[\"count\"]\n        u_grouped[\"se\"] = u_grouped[\"std\"] * np.sqrt(\n            1 + 1/n\n            # +\n            # ((u_grouped[\"Temperature\"] - u_grouped[\"Temperature\"].mean())**2)/((n-1)*u_grouped[\"Temperature\"].var()) # does not work for single temperature\n        )\n        u_grouped[\"u_quantile\"] = scipy.stats.t.ppf(loc=0, scale=u_grouped[\"se\"], df=link_distribution_dof, q = link_distribution_q)\n\n        ca_test = X_test[\"Previous_Reading\"]\n        t_test = X_test[\"Time_Point_Diff\"]\n\n        grouped_last_time_point = X_train.groupby(\"Temperature\")[\"Time_Point_Diff\"].max().rename(\"Time_Point_Latest\")\n\n        ct_test_hat = ( # chat_t\n            self.equation(X_test, *self.fitted_coeff_)\n        )\n        X_test[\"k_test_hat\"] = -(1/t_test) * (ct_test_hat - ca_test)\n\n        X_test = X_test.merge(u_grouped[[\"Temperature\", \"u_quantile\"]], how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n        # X_test[\"k_test_quantile\"] = np.exp(\n        #     np.log(X_test[\"k_test_hat\"]) - X_test[\"u_quantile\"]\n        # )\n        X_test[\"k_test_quantile\"] = X_test[\"k_test_hat\"] - X_test[\"u_quantile\"]\n        X_test = X_test.merge(grouped_last_time_point, how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n\n        X_test[\"horizon\"] = X_test[\"Time_Point_Diff\"] - X_test[\"Time_Point_Latest\"].max()\n        X_test[\"horizon\"] = np.clip(\n            X_test[\"horizon\"],\n            0,\n            np.inf\n        )\n        # - for correction\n\n        response_quantile_pred_test = ca_test - (X_test[\"k_test_quantile\"] * t_test)\n\n        response_quantile_pred_test = np.clip(\n            response_quantile_pred_test,\n            0,\n            np.inf\n        )\n\n        return response_quantile_pred_test\n\n    def latex(self):\n        return r\"\"\"\n        $$\n        \\begin{aligned}\n        {\\huge c_t} &amp;\n        {\\huge = c_0 - \\textcolor{hotpink}{$k} t} \\\\\n        \\\\\n        c_t &amp;= \\text{Concentration} \\\\\n        c_0 &amp;= \\text{Initial Concentration} \\\\\n        t &amp;= \\text{Time (weeks)}\n        \\end{aligned}\n        $$\n        \"\"\"\n\nclass First_Order(Model):\n    def __init__(self):\n        super().__init__(to_be_grouped=True)\n    # @jax.jit\n    def equation(\n        self, x,\n        k = [0, (0, None)]\n    ):  # hypothesis\n\n        ca = x[\"Previous_Reading\"]\n        # ta = x[\"Time_Point_Diff\"]\n        # tb = x[\"Time_Point\"]\n        t = x[\"Time_Point_Diff\"]\n        return (\n            ca\n            *\n            np.exp(\n                -k\n                *\n                t # (tb-ta)\n            )\n        )\n    def quantile(self, X_test, X_train, y_train, link_distribution_dof, link_distribution_q):\n        ca_train = X_train[\"Previous_Reading\"]\n        t_train = X_train[\"Time_Point_Diff\"]\n\n        ct_train_true = y_train\n        k_train_true = -(1/t_train) * np.log(ct_train_true / ca_train)\n\n        ct_train_hat = ( # chat_t\n            self.equation(X_train, *self.fitted_coeff_)\n        )\n        k_train_hat = -(1/t_train) * np.log(ct_train_hat / ca_train)\n\n        u = np.log(k_train_hat/k_train_true) # -(1/t_train) * np.log(ct_train_hat / ct_train_true) \n\n        X_train[\"u\"] = u\n        u_grouped = X_train.groupby(\"Temperature\")[\"u\"].agg([\"mean\", \"std\", \"count\"])\n        u_grouped = u_grouped.reset_index()\n        n = u_grouped[\"count\"]\n        u_grouped[\"se\"] = u_grouped[\"std\"] * np.sqrt(\n            1 + 1/n\n            # +\n            # ((u_grouped[\"Temperature\"] - u_grouped[\"Temperature\"].mean())**2)/((n-1)*u_grouped[\"Temperature\"].var()) # does not work for single temperature\n        )\n        u_grouped[\"u_quantile\"] = scipy.stats.t.ppf(loc=u_grouped[\"mean\"], scale=u_grouped[\"se\"], df=link_distribution_dof, q = link_distribution_q)\n\n        ca_test = X_test[\"Previous_Reading\"]\n        t_test = X_test[\"Time_Point_Diff\"]\n\n        grouped_last_time_point = X_train.groupby(\"Temperature\")[\"Time_Point_Diff\"].max().rename(\"Time_Point_Latest\")\n\n        ct_hat = ( # chat_t\n            self.equation(X_test, *self.fitted_coeff_)\n        )\n        X_test[\"k_test_hat\"] = -(1/t_test) * np.log(ct_hat / ca_test)\n\n        X_test = X_test.merge(u_grouped[[\"Temperature\", \"u_quantile\"]], how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n        # X_test[\"k_test_quantile\"] = np.exp(\n        #     np.log(X_test[\"k_test_hat\"]) - X_test[\"u_quantile\"]\n        # )\n        X_test[\"k_test_quantile\"] = X_test[\"k_test_hat\"] / np.exp(X_test[\"u_quantile\"])\n        X_test = X_test.merge(grouped_last_time_point, how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n\n        X_test[\"horizon\"] = X_test[\"Time_Point_Diff\"] - X_test[\"Time_Point_Latest\"].max()\n\n        X_test[\"horizon\"] = np.clip(\n            X_test[\"horizon\"],\n            0,\n            np.inf\n        )\n\n        # - for correction\n        response_quantile_pred_test = ca_test * np.exp(-(X_test[\"k_test_quantile\"] * t_test))\n\n        response_quantile_pred_test = np.where(\n            response_quantile_pred_test.round(2) == 0.0,\n            response_quantile_pred_test + link_distribution_q,\n            response_quantile_pred_test\n        )\n        # st.write(response_quantile_pred_test)\n\n        return response_quantile_pred_test\n\n    def latex(self):\n        return r\"\"\"\n        $$\n        \\begin{aligned}\n        {\\huge c_t} &amp;\n        {\\huge = c_0 \\cdot\n        \\exp \\{\n            \\overbrace{- \\textcolor{hotpink}{$k}}^{\\small \\mathclap{\\small \\mathclap{\\text{Rate const}}}} t\n        \\} } \\\\\n        \\\\\n        c_t &amp;= \\text{Concentration} \\\\\n        c_0 &amp;= \\text{Initial Concentration} \\\\\n        t &amp;= \\text{Time (weeks)}\n        \\end{aligned}\n        $$\n        \"\"\"\n\nclass Combined_Arrhenius(Model):\n    # @jax.jit\n    def equation(\n        self, x,\n        A=[0, (0, None)],\n        E_a=[10_000, (0, None)],\n        n=[1, (0.8, 1.2)],\n    ):\n        ca = x[\"Previous_Reading\"]\n        # ta = x[\"Time_Point_Diff\"]\n        # tb = x[\"Time_Point\"]\n        t = x[\"Time_Point_Diff\"]\n        T = x[\"Temperature\"] + 273.15\n        # Conversion to Kelvin is required: Kelvin is a ratio attribute, while Celcius and Farenheit are not\n        # Please read https://uni-notes.netlify.app/CS_Electives/Data_Mining/02_Data/#types-of-attributes for more details\n        R = 8.3144598\n\n        k = (\n            A\n            *\n            np.exp(\n                -E_a\n                /\n                (R*T).values\n            )\n        )\n\n        return (\n            ca\n            *\n            np.exp(\n                -k * (t**n) # (tb-ta)\n            )\n        )\n\n    def quantile(self, X_test, X_train, y_train, link_distribution_dof, link_distribution_q):\n        ca_train = X_train[\"Previous_Reading\"]\n        t_train = X_train[\"Time_Point_Diff\"]\n\n        ct_train_true = y_train\n        k_train_true = -(1/t_train) * np.log(ct_train_true / ca_train)\n\n        ct_train_hat = ( # chat_t\n            self.equation(X_train, *self.fitted_coeff_)\n        )\n        k_train_hat = -(1/t_train) * np.log(ct_train_hat / ca_train)\n\n        u = np.log(k_train_hat/k_train_true) # -(1/t_train) * np.log(ct_train_hat / ct_train_true) \n\n        X_train[\"u\"] = u\n        u_grouped = X_train.groupby(\"Temperature\")[\"u\"].agg([\"mean\", \"std\", \"count\"])\n        u_grouped = u_grouped.reset_index()\n        n = u_grouped[\"count\"]\n        u_grouped[\"se\"] = u_grouped[\"std\"] * np.sqrt(\n            1 + 1/n\n            # +\n            # ((u_grouped[\"Temperature\"] - u_grouped[\"Temperature\"].mean())**2)/((n-1)*u_grouped[\"Temperature\"].var()) # does not work for single temperature\n        )\n        u_grouped[\"u_quantile\"] = scipy.stats.t.ppf(loc=u_grouped[\"mean\"], scale=u_grouped[\"se\"], df=link_distribution_dof, q = link_distribution_q)\n\n        ca_test = X_test[\"Previous_Reading\"]\n        t_test = X_test[\"Time_Point_Diff\"]\n\n        grouped_last_time_point = X_train.groupby(\"Temperature\")[\"Time_Point_Diff\"].max().rename(\"Time_Point_Latest\")\n\n        ct_hat = ( # chat_t\n            self.equation(X_test, *self.fitted_coeff_)\n        )\n        X_test[\"k_test_hat\"] = -(1/t_test) * np.log(ct_hat / ca_test)\n\n        X_test = X_test.merge(u_grouped[[\"Temperature\", \"u_quantile\"]], how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n        # X_test[\"k_test_quantile\"] = np.exp(\n        #     np.log(X_test[\"k_test_hat\"]) - X_test[\"u_quantile\"]\n        # )\n        X_test[\"k_test_quantile\"] = X_test[\"k_test_hat\"] / np.exp(X_test[\"u_quantile\"])\n        X_test = X_test.merge(grouped_last_time_point, how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n\n        X_test[\"horizon\"] = X_test[\"Time_Point_Diff\"] - X_test[\"Time_Point_Latest\"].max()\n        X_test[\"horizon\"] = np.clip(\n            X_test[\"horizon\"],\n            0,\n            np.inf\n        )\n\n        # - for correction\n\n        response_quantile_pred_test = ca_test * np.exp(-(X_test[\"k_test_quantile\"] * t_test))\n\n        response_quantile_pred_test = np.where(\n            response_quantile_pred_test.round(2) == 0.0,\n            response_quantile_pred_test + link_distribution_q,\n            response_quantile_pred_test\n        )\n\n        return response_quantile_pred_test\n\n    def latex(self):\n        return r\"\"\"\n        $$\n        \\begin{aligned}\n        {\\huge c_t} &amp;\n        {\\huge = c_0 \\cdot \\exp \\Bigg \\{\n            -\n            \\overset{\n                \\mathclap{\n                \\substack{ {\\small \\text{Rate const}} \\qquad \\\\  {\\tiny \\nwarrow} \\qquad \\\\ }\n                }\n            }{\n                k\n            }\n\n            t^ {\n                \\overset{\n                \\mathclap{\\qquad\n                {\\tiny \\nearrow} \\substack{ {\\small \\text{Order}} \\\\ \\\\ \\\\ }\n                }\n                }{\n                \\textcolor{hotpink}{$n}\n                }\n            }\n        \\Bigg \\} } \\\\\n        {\\large k} &amp;=\n        {\n            \\large \\textcolor{hotpink}{$A}\n            \\exp \\left\\{\n            {\n                \\dfrac{\n                    -\\textcolor{hotpink}{$E_a}\n                }{\n                    RT\n                }\n            }\n            \\right\\}\n        } \\\\\n        \\\\\n        c_t &amp;= \\text{Concentration} \\\\\n        c_0 &amp;= \\text{Initial Concentration} \\\\\n        T &amp;= \\text{Temperature (Kelvin)} \\\\\n        R &amp;= \\text{Gas Constant} \\\\\n        t &amp;= \\text{Time (weeks)}\n        \\end{aligned}\n        $$\n        \"\"\"\n\nclass Rate_Law(Model):\n    # def __init__(self):\n    #     super().__init__()\n    #     self.constraints = (\n    #         {'type': 'ineq', 'fun': lambda x:  x[-1] != 0}, # n!=0\n    #     )\n    #     #Nelder-Mead doesn't support constraints\n\n    # @jax.jit\n    def equation(\n        self, x,\n        A=[1, (0, None)],\n        E_a=[10_000, (0, None)],\n        n=[1, (0.8, 1.2)],\n    ):\n        ca = x[\"Previous_Reading\"]\n        # ta = x[\"Time_Point_Diff\"]\n        # tb = x[\"Time_Point\"]\n        t = x[\"Time_Point_Diff\"]\n        T = x[\"Temperature\"] + 273.15\n        # Conversion to Kelvin is required: Kelvin is a ratio attribute, while Celcius and Farenheit are not\n        # Please read https://uni-notes.netlify.app/CS_Electives/Data_Mining/02_Data/#types-of-attributes for more details\n        R = 8.3144598\n\n        k = (\n            A\n            *\n            np.exp(\n                -E_a\n                /\n                (R*T)\n            )\n        )\n\n        return np.power(\n            ca**(1-n) - k*t*(1-n), # (tb-ta)\n            1/(1-n)\n        )\n\n    def quantile(self, X_test, X_train, y_train, link_distribution_dof, link_distribution_q):\n        ca_train = X_train[\"Previous_Reading\"]\n        t_train = X_train[\"Time_Point_Diff\"]\n\n        ct_train_true = y_train\n        k_train_true = -(1/t_train) * np.log(ct_train_true / ca_train)\n\n        ct_train_hat = ( # chat_t\n            self.equation(X_train, *self.fitted_coeff_)\n        )\n        k_train_hat = -(1/t_train) * np.log(ct_train_hat / ca_train)\n\n        u = np.log(k_train_hat/k_train_true) # -(1/t_train) * np.log(ct_train_hat / ct_train_true) \n\n        X_train[\"u\"] = u\n        u_grouped = X_train.groupby(\"Temperature\")[\"u\"].agg([\"mean\", \"std\", \"count\"])\n        u_grouped = u_grouped.reset_index()\n        n = u_grouped[\"count\"]\n        u_grouped[\"se\"] = u_grouped[\"std\"] * np.sqrt(\n            1 + 1/n\n            # +\n            # ((u_grouped[\"Temperature\"] - u_grouped[\"Temperature\"].mean())**2)/((n-1)*u_grouped[\"Temperature\"].var()) # does not work for single temperature\n        )\n        u_grouped[\"u_quantile\"] = scipy.stats.t.ppf(loc=u_grouped[\"mean\"], scale=u_grouped[\"se\"], df=link_distribution_dof, q = link_distribution_q)\n\n        ca_test = X_test[\"Previous_Reading\"]\n        t_test = X_test[\"Time_Point_Diff\"]\n\n        grouped_last_time_point = X_train.groupby(\"Temperature\")[\"Time_Point_Diff\"].max().rename(\"Time_Point_Latest\")\n\n        ct_hat = ( # chat_t\n            self.equation(X_test, *self.fitted_coeff_)\n        )\n        X_test[\"k_test_hat\"] = -(1/t_test) * np.log(ct_hat / ca_test)\n\n        X_test = X_test.merge(u_grouped[[\"Temperature\", \"u_quantile\"]], how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n        # X_test[\"k_test_quantile\"] = np.exp(\n        #     np.log(X_test[\"k_test_hat\"]) - X_test[\"u_quantile\"]\n        # )\n        X_test[\"k_test_quantile\"] = X_test[\"k_test_hat\"] / np.exp(X_test[\"u_quantile\"])\n        X_test = X_test.merge(grouped_last_time_point, how=\"left\", left_on=\"Temperature\", right_on=\"Temperature\")\n\n        X_test[\"horizon\"] = X_test[\"Time_Point_Diff\"] - X_test[\"Time_Point_Latest\"].max()\n        X_test[\"horizon\"] = np.clip(\n            X_test[\"horizon\"],\n            0,\n            np.inf\n        )\n\n        # - for correction\n\n        response_quantile_pred_test = ca_test * np.exp(-(X_test[\"k_test_quantile\"] * t_test))\n\n        response_quantile_pred_test = np.where(\n            response_quantile_pred_test.round(2) == 0.0,\n            response_quantile_pred_test + link_distribution_q,\n            response_quantile_pred_test\n        )\n\n        return response_quantile_pred_test\n\n    def latex(self):\n        # {\\huge c_t} &amp; {\\huge = c_0 \\cdot e^{\n        return r\"\"\"\n        $$\n        \\begin{aligned}\n        {\\large c_t^{1-\\textcolor{hotpink}{$n}}}\n        &amp;=\n        {\n            \\Large\n            c_0^{1-\\textcolor{hotpink}{$n}}\n            - k t\n            ( {1 - \\textcolor{hotpink}{$n}} )\n        } \\\\\n        {\\large k} &amp;=\n        {\n            \\large \\textcolor{hotpink}{$A}\n            \\exp \\left\\{\n            {\n                \\dfrac{\n                    -\\textcolor{hotpink}{$E_a}\n                }{\n                    RT\n                }\n            }\n            \\right\\}\n        } \\\\\n        \\\\\n        c_t &amp;= \\text{Concentration} \\\\\n        c_0 &amp;= \\text{Initial Concentration} \\\\\n        T &amp;= \\text{Temperature (Kelvin)} \\\\\n        R &amp;= \\text{Gas Constant} \\\\\n        t &amp;= \\text{Time (weeks)}\n        \\end{aligned}\n        $$\n        \"\"\"\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Facebook_Prophet/","title":"Facebook Prophet","text":""},{"location":"Tools/AI%20%26%20Data/Facebook_Prophet/#limitations","title":"Limitations","text":"<ul> <li>Basically glorified curve-fitting to time variable</li> <li>Tends to overfit</li> <li>Does not extrapolate well</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Facebook_Prophet/#improve-fit","title":"Improve <code>.fit()</code>","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport time\nimport datetime\nfrom prophet import Prophet\nimport matplotlib.pyplot as plt\nfrom scipy.stats import pearsonr\n\nfrom batch_elastic_net import BatchElasticNetRegression\n\n\ndef make_sine_wave(length: int, n_cycles: int):\n    \"\"\"\n    Makes a sine wave given some length and the number of cycles it should go through in that period\n    \"\"\"\n    samples = np.linspace(0, length, length)\n    return np.sin(2 * np.pi * n_cycles * samples)\n\n\ndef generate_dataset(n_items):\n    \"\"\"\n    Generates a time series dataset with weekly frequency for two years. Randomly assigns the yearly, monthly and\n    trend values for each item\n    \"\"\"\n    year_in_weeks = 104\n    yealy_s = make_sine_wave(year_in_weeks, 2)\n    monthly_s = make_sine_wave(year_in_weeks, year_in_weeks / 24)\n    trend = np.arange(year_in_weeks) / year_in_weeks\n    all_ys = []\n    for i in range(n_items):\n        d = (np.stack([yealy_s, monthly_s, trend], axis=1) * np.random.rand(3)).sum(axis=1) + np.random.rand(year_in_weeks)\n        all_ys.append(d + (np.random.rand(len(d))-0.45).cumsum())\n    return pd.DataFrame(zip(*all_ys), index = pd.date_range(datetime.datetime(2020, 1, 1), freq='w', periods=len(d)))\n\n\ndef get_changepoint_idx(length, n_changepoints, changepoint_range=0.8):\n    \"\"\"\n    Finds the indices of slope change-points using Prophet's logic: assign them uniformly of the first changepoint_range\n    percentage of the data\n    \"\"\"\n    hist_size = int(np.floor(length * changepoint_range))\n    return np.linspace(0, hist_size - 1, n_changepoints+1).round().astype(int)[1:]\n\n\ndef make_changepoint_features(n, changes_idx):\n    \"\"\"\n    Creates initial slope and slope change-points features given a length of data and locations of indices.\n    The features are 0s for the first elements until their idx is reached, and then they move linearly upwards.\n    These features can be used to model a time series with an initial slope and the deltas of change-points.\n    \"\"\"\n    linear = np.arange(n).reshape(-1,1)\n    feats = [linear]\n    for i in changes_idx:\n        slope_feat = np.zeros(n)\n        slope_feat[i:] = np.arange(0, n-i)\n        slope_feat = slope_feat.reshape(-1,1)\n        feats.append(slope_feat)\n    feat = np.concatenate(feats, axis=1)\n    return feat\n\n\ndef run_prophet():\n    t = time.time()\n    all_prophets_datasets_forecasts = {}\n    for name, dataset in data_sets.items():\n        all_p_forecast = []\n        for i in range(dataset.shape[1]):\n            ds = dataset.iloc[:, i].reset_index()\n            ds.columns = ['ds', 'y']\n            # if uncertainty samples is not None it will take way more time\n            m = Prophet(n_changepoints=n_changepoints, changepoint_prior_scale=change_prior, growth='linear',\n                        uncertainty_samples=None,\n                        yearly_seasonality=True, weekly_seasonality=False, seasonality_prior_scale=seasonality_prior)\n            m.fit(ds)\n            forecast = m.predict(ds)\n            all_p_forecast.append(forecast.yhat)\n        all_prophets_datasets_forecasts[name] = pd.DataFrame(zip(*all_p_forecast), index=ds.ds)\n\n    return all_prophets_datasets_forecasts, time.time() - t\n\n\ndef run_batch_linear():\n    big_num = 20.  # used as std of prior when it should be uninformative\n    p = Prophet()\n    t = time.time()\n    all_BatchLinear_datasets_forecasts = {}\n    for name, dataset in data_sets.items():\n        dates = pd.Series(dataset.index)\n        dataset_length = len(dataset)\n        idx = get_changepoint_idx(dataset_length, n_changepoints)\n\n        seasonal_feat = p.make_seasonality_features(dates, 365.25, 10, 'yearly_sine')\n        changepoint_feat = make_changepoint_features(dataset_length, idx) / dataset_length\n        feat = np.concatenate([changepoint_feat, seasonal_feat], axis=1)\n\n        n_changepoint_feat = changepoint_feat.shape[1] - 1\n        # laplace prior only on changepoints (seasonals get big_num, to avoid l1 regularization on it)\n        l1_priors = np.array([big_num] + [change_prior] * n_changepoint_feat + [big_num] * seasonal_feat.shape[1])\n        # normal prior on initial slope and on seasonals, and a big_num on changepoints to avoid l2 regularization\n        l2_priors = np.array([5] + [big_num] * n_changepoint_feat + [seasonality_prior] * seasonal_feat.shape[\n            1])  # normal prior only on seasonal\n\n        # this is how Prophet scales the data before fitting - divide by max of each item\n        scale = dataset.max()\n        scaled_y = dataset / scale\n\n        blr = BatchElasticNetRegression()\n        blr.fit(feat, scaled_y, l1_reg_params=l1_priors, l2_reg_params=l2_priors, as_bayesian_prior=True, verbose=True,\n                iterations=1500)\n\n        # get the predictions for the train\n        all_BatchLinear_datasets_forecasts[name] = pd.DataFrame(blr.predict(feat) * scale.values, index=dates)\n\n    return all_BatchLinear_datasets_forecasts, time.time() - t\n\n\nif __name__ == '__main__':\n    data_files_names = ['d1', 'd2', 'M5_sample']\n    data_sets = {name: pd.read_csv(f'data_files/{name}.csv', index_col=0, parse_dates=True) for name in data_files_names}\n    data_sets['randomly_generated'] = generate_dataset(500)\n\n    # can play with these params for both predictors\n    change_prior = 0.5\n    # the seasonality_prior is an uninformative prior (hardly any regularization), which is the default for Prophet and usually does not require changing\n    seasonality_prior = 10\n    n_changepoints = 15\n\n    all_prophets_datasets_forecasts, prophet_time = run_prophet()\n    all_BatchLinear_datasets_forecasts, batch_time = run_batch_linear()\n\n    print(f'total number of items: {sum([x.shape[1] for x in data_sets.values()])}')\n    print(f'Prophet time: {round(prophet_time, 2)}; batch time: {round(batch_time, 2)}')\n\n    # plot examples from datasets (copy to notebook and repeat for different items and datasets)\n    name = 'd1'\n    batch_preds = all_BatchLinear_datasets_forecasts[name]\n    prophet_preds = all_prophets_datasets_forecasts[name]\n    orig_data = data_sets[name]\n\n    i = np.random.randint(0, orig_data.shape[1])\n    orig_data.iloc[:, i].plot(label='target')\n    batch_pred = batch_preds.iloc[:, i]\n    prophet_pred = prophet_preds.iloc[:, i]\n    prophet_pred.plot(label='prophet')\n    batch_pred.plot(label='my_batch')\n    plt.title(f'Pearson {round(pearsonr(batch_pred, prophet_pred)[0], 3)}')\n    plt.legend()\n    plt.show()\n\n    # mean pearson\n    all_corrs = {}\n    for name in data_sets.keys():\n        batch_preds = all_BatchLinear_datasets_forecasts[name]\n        prophet_preds = all_prophets_datasets_forecasts[name]\n        corrs = []\n        for i in range(prophet_preds.shape[1]):\n            corrs.append(pearsonr(batch_preds.iloc[:, i], prophet_preds.iloc[:, i])[0])\n        all_corrs[name] = np.mean(corrs)\n    print(all_corrs)\n</code></pre> <p>IDK</p> <pre><code>import numpy as np\nimport torch\nimport torch.optim as optim\nfrom typing import Optional, Union\n\nBIG_STD = 20.  # used as std of prior when it should be uninformative (when we do not wish to regularize at all)\n\n\ndef to_tensor(x):\n    return torch.from_numpy(np.array(x)).float()\n\n\nclass BatchElasticNetRegression(object):\n    \"\"\"\n    Elastic net for the case where we have multiple targets (y), all to be fitted with the same features (X).\n    Learning all items in parallel, in a single \"network\" is more efficient then iteratively fitting a regression for\n    each target.\n    Allows to set different l1 and l2 regularization params for each of the features.\n    Can also be used to estimate the MAP of a Bayesian regression with Laplace or Normal priors instead of L1 and L2.\n    \"\"\"\n    def __init__(self):\n        self.coefs = None\n        self.intercepts = None\n\n    def fit(self,\n            X, y,\n            l1_reg_params: Optional[Union[np.array, float]] = None,\n            l2_reg_params: Optional[Union[np.array, float]] = None,\n            as_bayesian_prior=False, iterations=500, verbose=True, lr_rate=0.1):\n        \"\"\"\n        Fits multiple regressions. Both X and y are 2d matrices, where X is the common features for all the targets,\n        and y contains all the concatenated targets.\n        If as_bayesian_prior==False then the l1 and l2 reg params are regularization params\n        If as_bayesian_prior==True then l1 is treated as the std of the laplace prior and l2 as the std for the normal\n        prior.\n        The reg params / std of priors can either be a single value for all features, or set a different regularization\n        or prior for each feature separately. e.g. if we have 3 features, l1_reg_params can be [0.5, 1.2, 0] to set\n        regularization for each.\n\n        TODO:\n        Add normalization before fitting\n        Requires more work on the optimizer to be faster\n        \"\"\"\n        n_items = y.shape[1]\n        k_features = X.shape[1]\n        n_samples = X.shape[0]\n\n        # TODO: if l1_reg_params is None just don't calculate this part of the loss, instead of multiplying by 0\n        if l1_reg_params is None:\n            l1_reg_params = BIG_STD if as_bayesian_prior else 0.\n        if type(l1_reg_params) == float:\n            l1_reg_params = [l1_reg_params] * k_features\n        if l2_reg_params is None:\n            l2_reg_params = BIG_STD if as_bayesian_prior else 0.\n        if type(l2_reg_params) == float:\n            l2_reg_params = [l2_reg_params] * k_features\n\n        assert len(l1_reg_params) == len(l2_reg_params) == k_features, 'Regularization values must match X.shape[1]'\n        if as_bayesian_prior:\n            assert 0 not in l1_reg_params and 0 not in l2_reg_params, 'Cannot have 0 prior'\n\n        # convert to tensors and set initial params\n        t_features = to_tensor(X)\n        t_target = to_tensor(y)\n        learned_coefs = torch.rand(k_features, n_items, requires_grad=True)\n        learned_intercepts = torch.rand(n_items, requires_grad=True)\n        # TODO: or auto-estimate initial sigma based on data std?\n        est_sigma = torch.ones(n_items)\n        if as_bayesian_prior:\n            # If the params are priors then they must become a matrix, not a simple vector - because the conversion\n            # depends on the sigma of errors for each target y. The actual regularization params will be different\n            # for each item based on its sigma.\n            t_l1_reg_params = to_tensor(np.stack([l1_reg_params] * n_items, axis=1))\n            l1_alpha = self.calc_l1_alpha_from_prior(est_sigma, t_l1_reg_params, n_samples)\n            t_l2_reg_params = to_tensor(np.stack([l2_reg_params] * n_items, axis=1))\n            l2_alpha = self.calc_l2_alpha_from_prior(est_sigma, t_l2_reg_params, n_samples)\n        else:\n            l1_alpha = to_tensor(l1_reg_params)\n            l2_alpha = to_tensor(l2_reg_params)\n\n        # TODO: add scheduler for learning rate\n        optimizer = optim.Adam([learned_coefs, learned_intercepts], lr_rate)\n\n        for i in range(iterations):\n            optimizer.zero_grad(set_to_none=True)\n            res = torch.matmul(t_features, learned_coefs) + learned_intercepts\n            diff_loss = (1 / (2 * n_samples)) * ((res - t_target) ** 2).sum(axis=0)\n\n            if as_bayesian_prior:\n                reg_loss = (l1_alpha * learned_coefs.abs()).sum(axis=0) + (l2_alpha * learned_coefs ** 2).sum(axis=0)\n            else:\n                reg_loss = torch.matmul(l1_alpha, learned_coefs.abs()) + torch.matmul(l2_alpha, learned_coefs ** 2)\n\n            loss = (diff_loss + reg_loss).sum()\n\n            loss.backward()\n            optimizer.step()\n            if as_bayesian_prior and i % 50 == 0:\n                # if the params are the priors - we must convert them to the equivalent l1/l2 loss params.\n                # This conversion depends on the final sigma of errors of the forecast, which is unknown until we\n                # have a forecast using those same params... We iteratively improve our estimate of sigma and\n                # re-compute the corresponding regularization params based on those sigmas.\n                # The sigma is per target in y, therefore the l1/l2 params are per item.\n                est_sigma = (res - t_target).std(axis=0).detach()\n                l1_alpha = self.calc_l1_alpha_from_prior(est_sigma, t_l1_reg_params, n_samples)\n                l2_alpha = self.calc_l2_alpha_from_prior(est_sigma, t_l2_reg_params, n_samples)\n\n            if i % 50 == 0 and verbose:\n                print(loss)\n            # TODO: early stopping if converges\n\n        self.coefs = learned_coefs.detach().numpy()\n        self.intercepts = learned_intercepts.detach().numpy()\n\n    def predict(self, X):\n        return X @ self.coefs + self.intercepts\n\n    @staticmethod\n    def calc_l1_alpha_from_prior(est_sigma, b_prior, n_samples):\n        \"\"\"\n        Converts from the std of a Laplace prior to the equivalent L1 regularization param.\n        The conversion formula is divided by 2*n_samples since we divided the diff_loss by 2*n_samples as well,\n        to match sklearn's implementation of Lasso.\n        \"\"\"\n        return est_sigma ** 2 / (b_prior * n_samples)\n\n    @staticmethod\n    def calc_l2_alpha_from_prior(est_sigma, b_prior, n_samples):\n        return est_sigma ** 2 / (b_prior ** 2 * 2 * n_samples)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Facebook_Prophet/#improve-predict","title":"Improve <code>.predict()</code>","text":"<p>01/25/23 edit: FB engineers integrated the solution in this post into the package in version release 1.1.2. Due to some implementation differences it is still slightly slower than the solution in the end of this post, but not significantly.</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom fbprophet import Prophet\n\n\ndef _make_historical_mat_time(deltas, changepoints_t, t_time, n_row=1):\n    \"\"\"\n    Creates a matrix of slope-deltas where these changes occured in training data according to the trained prophet obj\n    \"\"\"\n    diff = np.diff(t_time).mean()\n    prev_time = np.arange(0, 1 + diff, diff)\n    idxs = []\n    for changepoint in changepoints_t:\n        idxs.append(np.where(prev_time &gt; changepoint)[0][0])\n    prev_deltas = np.zeros(len(prev_time))\n    prev_deltas[idxs] = deltas\n    prev_deltas = np.repeat(prev_deltas.reshape(1, -1), n_row, axis=0)\n    return prev_deltas, prev_time\n\n\ndef prophet_logistic_uncertainty(\n    mat: np.ndarray,\n    deltas: np.ndarray,\n    prophet_obj: Prophet,\n    cap_scaled: np.ndarray,\n    t_time: np.ndarray,\n):\n    \"\"\"\n    Vectorizes prophet's logistic growth uncertainty by creating a matrix of future possible trends.\n    \"\"\"\n\n    def ffill(arr):\n        mask = arr == 0\n        idx = np.where(~mask, np.arange(mask.shape[1]), 0)\n        np.maximum.accumulate(idx, axis=1, out=idx)\n        return arr[np.arange(idx.shape[0])[:, None], idx]\n\n    k = prophet_obj.params[\"k\"][0]\n    m = prophet_obj.params[\"m\"][0]\n    n_length = len(t_time)\n    #  for logistic growth we need to evaluate the trend all the way from the start of the train item\n    historical_mat, historical_time = _make_historical_mat_time(deltas, prophet_obj.changepoints_t, t_time, len(mat))\n    mat = np.concatenate([historical_mat, mat], axis=1)\n    full_t_time = np.concatenate([historical_time, t_time])\n\n    #  apply logistic growth logic on the slope changes\n    k_cum = np.concatenate((np.ones((mat.shape[0], 1)) * k, np.where(mat, np.cumsum(mat, axis=1) + k, 0)), axis=1)\n    k_cum_b = ffill(k_cum)\n    gammas = np.zeros_like(mat)\n    for i in range(mat.shape[1]):\n        x = full_t_time[i] - m - np.sum(gammas[:, :i], axis=1)\n        ks = 1 - k_cum_b[:, i] / k_cum_b[:, i + 1]\n        gammas[:, i] = x * ks\n    # the data before the -n_length is the historical values, which are not needed, so cut the last n_length\n    k_t = (mat.cumsum(axis=1) + k)[:, -n_length:]\n    m_t = (gammas.cumsum(axis=1) + m)[:, -n_length:]\n    sample_trends = cap_scaled / (1 + np.exp(-k_t * (t_time - m_t)))\n    # remove the mean because we only need width of the uncertainty centered around 0\n    # we will add the width to the main forecast - yhat (which is the mean) - later\n    sample_trends = sample_trends - sample_trends.mean(axis=0)\n    return sample_trends\n\n\ndef _make_trend_shift_matrix(mean_delta: float, likelihood: float, future_length: float, k: int = 10000) -&gt; np.ndarray:\n    \"\"\"\n    Creates a matrix of random trend shifts based on historical likelihood and size of shifts.\n    Can be used for either linear or logistic trend shifts.\n    Each row represents a different sample of a possible future, and each column is a time step into the future.\n    \"\"\"\n    # create a bool matrix of where these trend shifts should go\n    bool_slope_change = np.random.uniform(size=(k, future_length)) &lt; likelihood\n    shift_values = np.random.laplace(0, mean_delta, size=bool_slope_change.shape)\n    mat = shift_values * bool_slope_change\n    n_mat = np.hstack([np.zeros((len(mat), 1)), mat])[:, :-1]\n    mat = (n_mat + mat) / 2\n    return mat\n\n\ndef add_prophet_uncertainty(\n    prophet_obj: Prophet,\n    forecast_df: pd.DataFrame,\n    using_train_df: bool = False,\n):\n    \"\"\"\n    Adds yhat_upper and yhat_lower to the forecast_df used by fbprophet, based on the params of a trained prophet_obj\n    and the interval_width.\n    Use using_train_df=True if the forecast_df is not for a future time but for the training data.\n    \"\"\"\n    assert prophet_obj.history is not None, \"Model has not been fit\"\n    assert \"yhat\" in forecast_df.columns, \"Must have the mean yhat forecast to build uncertainty on\"\n    interval_width = prophet_obj.interval_width\n\n    if using_train_df:  # there is no trend-based uncertainty if we're only looking on the past where trend is known\n        sample_trends = np.zeros(10000, len(forecast_df))\n    else:  # create samples of possible future trends\n        future_time_series = ((forecast_df[\"ds\"] - prophet_obj.start) / prophet_obj.t_scale).values\n        single_diff = np.diff(future_time_series).mean()\n        change_likelihood = len(prophet_obj.changepoints_t) * single_diff\n        deltas = prophet_obj.params[\"delta\"][0]\n        n_length = len(forecast_df)\n        mean_delta = np.mean(np.abs(deltas)) + 1e-8\n        if prophet_obj.growth == \"linear\":\n            mat = _make_trend_shift_matrix(mean_delta, change_likelihood, n_length, k=10000)\n            sample_trends = mat.cumsum(axis=1).cumsum(axis=1)  # from slope changes to actual values\n            sample_trends = sample_trends * single_diff  # scaled by the actual meaning of the slope\n        elif prophet_obj.growth == \"logistic\":\n            mat = _make_trend_shift_matrix(mean_delta, change_likelihood, n_length, k=1000)\n            cap_scaled = (forecast_df[\"cap\"] / prophet_obj.y_scale).values\n            sample_trends = prophet_logistic_uncertainty(mat, deltas, prophet_obj, cap_scaled, future_time_series)\n        else:\n            raise NotImplementedError\n\n    # add gaussian noise based on historical levels\n    sigma = prophet_obj.params[\"sigma_obs\"][0]\n    historical_variance = np.random.normal(scale=sigma, size=sample_trends.shape)\n    full_samples = sample_trends + historical_variance\n    # get quantiles and scale back (prophet scales the data before fitting, so sigma and deltas are scaled)\n    width_split = (1 - interval_width) / 2\n    quantiles = np.array([width_split, 1 - width_split]) * 100  # get quantiles from width\n    quantiles = np.percentile(full_samples, quantiles, axis=0)\n    # Prophet scales all the data before fitting and predicting, y_scale re-scales it to original values\n    quantiles = quantiles * prophet_obj.y_scale\n\n    forecast_df[\"yhat_lower\"] = forecast_df.yhat + quantiles[0]\n    forecast_df[\"yhat_upper\"] = forecast_df.yhat + quantiles[1]\n</code></pre> <pre><code>p = Prophet(uncertainty_samples=None) # tell Prophet not to create the interval by itself\np = p.fit(training_df)\n\n# set to your number of periods and freq\nforecast_df = p.make_future_dataframe(periods=10, freq='W', include_history=False)\ntraining_df = p.predict(training_df)\nforecast_df = p.predict(forecast_df)\nadd_prophet_uncertainty(p, training_df, using_train_df=True)\nadd_prophet_uncertainty(p, forecast_df)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/IBIS/","title":"IBIS","text":"<p>Ibis is the portable Python dataframe library:</p> <ul> <li>Fast local dataframes (via DuckDB by default)</li> <li>Lazy dataframe expressions</li> <li>Interactive mode for iterative data exploration</li> <li>Compose Python dataframe and SQL code</li> <li>Use the same dataframe API for 20+ backends</li> <li>Iterate locally and deploy remotely by changing a single line of code</li> </ul>"},{"location":"Tools/AI%20%26%20Data/IBIS/#backends","title":"Backends","text":"<p>Ibis supports 20+ backends:</p> <ul> <li>Apache Arrow DataFusion</li> <li>Apache Druid</li> <li>Apache Flink</li> <li>Apache Impala</li> <li>Apache PySpark</li> <li>BigQuery</li> <li>ClickHouse</li> <li>Dask</li> <li>DuckDB</li> <li>Exasol</li> <li>MySQL</li> <li>Oracle</li> <li>pandas</li> <li>Polars</li> <li>PostgreSQL</li> <li>RisingWave</li> <li>SQL Server</li> <li>SQLite</li> <li>Snowflake</li> <li>Trino</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Lux/","title":"Lux","text":"<p>Python library that facilitate fast and easy data exploration by automating the visualization and data analysis process. By simply printing out a dataframe in a Jupyter notebook, Lux recommends a set of visualizations highlighting interesting trends and patterns in the dataset. Visualizations are displayed via an interactive widget that enables users to quickly browse through large collections of visualizations and make sense of their data.</p> <p>Demo </p>"},{"location":"Tools/AI%20%26%20Data/MLFlow/","title":"MLFlow","text":""},{"location":"Tools/AI%20%26%20Data/MLFlow/#references","title":"References","text":"<ul> <li> MLFlow | Databricks</li> <li> MLFlow | Manuel Gil</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Marimo/","title":"Marimo","text":""},{"location":"Tools/AI%20%26%20Data/Marimo/#references","title":"References","text":"<ul> <li> Marimo Notebooks - Rethinking interactive code blocks | Vincent Warmerdam | Probabl</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Numpy/","title":"Numpy","text":""},{"location":"Tools/AI%20%26%20Data/Numpy/#references","title":"References","text":"<ul> <li> https://www.youtube.com/watch?v=GKsCWivmlHg</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/","title":"01","text":""},{"location":"Tools/AI%20%26%20Data/Numpy/01/#import","title":"Import","text":"<pre><code>import numpy as np\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#basics","title":"Basics","text":"<pre><code>np.array([1, 2, 3, 4, 5])\nnp.arange(1, 100, 10) ## start, step, step\nnp.linspace(1, 100, 10) ## start, step, no of values\n\n## idk\nnp.zeros(10)\nnp.ones(10)\n\n## random\nnp.random.random(10)\nnp.random.randn(10)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#array-operations","title":"Array Operations","text":"<pre><code>## Element-wise\na+3\n1/a\n\n## Boolean\na &gt; 4\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#indexing","title":"Indexing","text":"<pre><code>a[2]\n\na[2:]\na[-10:]\n\na[:10]\na[:-10]\n\na[::2] ## even rows\na[1::2] ## odd rows\n\n\n## Masking\na[a &gt; 4]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#npvectorize","title":"np.vectorize","text":"<p>Kinda like a for loop</p> <pre><code>names = [\"Thahir\", \"Azhar\"]\nfirst_letter = np.vectorize(lambda x: x[0])(names) \n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#stats","title":"Stats","text":"<pre><code>np.mean(a)\nnp.median(a)\nnp.std(a)\nnp.quantile(a, 0.90)\nnp.percenile(a, 90)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#calculus","title":"Calculus","text":"<pre><code>## analytic calculus (for symbolic, use sympy)\ndydx = np.gradient(y, x )\ny_int = np.cumsum(y) * (x[1]-x[0])\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#multi-dimensional","title":"Multi-Dimensional","text":"<pre><code>a = np.array([\n  [1, 2, 3],\n  [4, 5, 6]\n])\na = np.random.randn(3, 3)\n\na.ravel() ## returns a 1d array\n\na[0] ## first row\na[:,0] ## first column\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#mesh-grid","title":"Mesh Grid","text":"<pre><code>xv, yv = np.meshgrid(x, y)\nzv = xv**2 + yv**2\nplt.contourf(xv, yv, zv, levels=100)\nplt.colorbar()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#linear-algebra","title":"Linear Algebra","text":""},{"location":"Tools/AI%20%26%20Data/Numpy/01/#matrix","title":"Matrix","text":"<pre><code>  a.T\n  a*b ## element-wise operator\n  a@b ## matrix multiplication\n  a.dot(b)\n  a.cross(b)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#solve-systems-of-equations","title":"Solve systems of equations","text":"<pre><code>  a = np.array([\n    [3, 2, 1],\n    [5, -5, 4],\n    [6, 0, 1]\n  ])\n  b = np.array([\n    4,\n    3,\n    0\n  ])\n\n  x = np.linalg.solve(a, b) ## ax = b\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#eigenvalues","title":"Eigenvalues","text":"<pre><code>  temp = np.linalg.eig(A)\n  eigen_values = temp[0]\n  eigen_vector = temp[1][:, 0]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#find-replace","title":"Find-Replace","text":"<p><code>if</code></p> <pre><code>  prediction['Rating'] = np.where(\n    prediction['Rating'].to_numpy() &gt; 100,\n    100,\n    prediction['Rating'].to_numpy()\n  )\n</code></pre> <p><code>if-else</code></p> <pre><code>  prediction['Rating'] = np.where(\n    prediction['Rating'].to_numpy() &gt; 100,\n    100,\n    0\n  )\n</code></pre> <p><code>if-elseif-else</code></p> <pre><code>  conditions = [\n    prediction['Rating'].to_numpy() &gt; 100,\n    prediction['Rating'].to_numpy() &gt; 50,\n    prediction['Rating'].to_numpy() &gt; 20\n  ]\n\n  values = [\n    100,\n    50,\n    20  \n  ]\n\n  default = 0\n\n  prediction['Rating'] = np.select(\n    conditions,\n    values,\n    default = default\n  )\n</code></pre> <p>nested</p> <pre><code>  conditions = [\n    (prediction['Rating'].to_numpy() &gt; 100 &amp; prediction['Rating'].to_numpy() % 2 == 0),\n    (prediction['Rating'].to_numpy() &gt; 100 &amp; prediction['Rating'].to_numpy() % 3 == 0),\n    (prediction['Rating'].to_numpy() &gt; 100 &amp; prediction['Rating'].to_numpy() % 4 == 0),\n\n    prediction['Rating'].to_numpy() &gt; 50,\n    prediction['Rating'].to_numpy() &gt; 20\n  ]\n\n  values = [\n    102,\n    103,\n    104,\n\n    50,\n    20  \n  ]\n\n  default = 0\n\n  prediction['Rating'] = np.select(\n    conditions,\n    values,\n    default = default\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#rounding","title":"Rounding","text":""},{"location":"Tools/AI%20%26%20Data/Numpy/01/#round-to-integer","title":"Round to Integer","text":"<pre><code>  np.around(prediction)\n\n  ## instead of\n  ## prediction = ( round(element) for element in prediction )\n</code></pre> <p>Round to \\(n\\) places</p> <pre><code>  np.around(prediction, n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#read-data","title":"Read data","text":"<pre><code>data = np.loadtxt(\n  \"./data.csv\",\n  dtype = \"object\",\n  delimiter = \",\",\n  unpack = True,\n  skiprows = 1 \n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#save","title":"Save","text":"<pre><code>np.savetxt(\n    filename + \".csv\",\n  data,\n  delimiter = \",\",\n  fmt = \"%d\",\n  header = \"Col1, Col2\"\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#cartesian","title":"Cartesian","text":""},{"location":"Tools/AI%20%26%20Data/Numpy/01/#indexing_1","title":"Indexing","text":"<p>High space complexity</p> <pre><code>import numpy as np\n\ndef cartesian(arrays, out=None):\n    \"\"\"\n    Generate a Cartesian product of input arrays.\n\n    Parameters\n    ----------\n    arrays : list of array-like\n        1-D arrays to form the Cartesian product of.\n    out : ndarray\n        Array to place the Cartesian product in.\n\n    Returns\n    -------\n    out : ndarray\n        2-D array of shape (M, len(arrays)) containing Cartesian products\n        formed of input arrays.\n\n    Examples\n    --------\n    &gt;&gt;&gt; cartesian(([1, 2, 3], [4, 5], [6, 7]))\n    array([[1, 4, 6],\n           [1, 4, 7],\n           [1, 5, 6],\n           [1, 5, 7],\n           [2, 4, 6],\n           [2, 4, 7],\n           [2, 5, 6],\n           [2, 5, 7],\n           [3, 4, 6],\n           [3, 4, 7],\n           [3, 5, 6],\n           [3, 5, 7]])\n\n    \"\"\"\n\n    arrays = [np.asarray(x) for x in arrays]\n    dtype = arrays[0].dtype\n\n    n = np.prod([x.size for x in arrays])\n    if out is None:\n        out = np.zeros([n, len(arrays)], dtype=dtype)\n\n    #m = n / arrays[0].size\n    m = int(n / arrays[0].size)\n    out[:,0] = np.repeat(arrays[0], m)\n    if arrays[1:]:\n        cartesian(arrays[1:], out=out[0:m, 1:])\n        for j in range(1, arrays[0].size):\n        #for j in xrange(1, arrays[0].size):\n            out[j*m:(j+1)*m, 1:] = out[0:m, 1:]\n    return out\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#crps","title":"CRPS","text":"<pre><code># Adapted to numpy from pyro.ops.stats.crps_empirical\n# Copyright (c) 2017-2019 Uber Technologies, Inc.\n# SPDX-License-Identifier: Apache-2.0\n\nimport numpy as np\ndef crps(y_true, y_pred, sample_weight=None):\n    num_samples = y_pred.shape[0]\n    absolute_error = np.mean(np.abs(y_pred - y_true), axis=0)\n\n    if num_samples == 1:\n        return np.average(absolute_error, weights=sample_weight)\n\n    y_pred = np.sort(y_pred, axis=0)\n    diff = y_pred[1:] - y_pred[:-1]\n    weight = np.arange(1, num_samples) * np.arange(num_samples - 1, 0, -1)\n    weight = np.expand_dims(weight, -1)\n\n    per_obs_crps = absolute_error - np.sum(diff * weight, axis=0) / num_samples**2\n    return np.average(per_obs_crps, weights=sample_weight)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Numpy/01/#linear-regression","title":"Linear Regression","text":"<pre><code>class WLS(RegressorMixin):\n    \"\"\"\n    - Uses element-wise multiplication () for weighted regression to avoid the more cumbersome .dot and .diag\n    - np.linalg.lstsq is the most stable method, others are\n        - np.linalg.solve\n        - np.linalg.pinv\n        - np.linalg.inv\n    - Add 1s if intercept required\n    \"\"\"\n    def __init__(self, fit_intercept=True, alpha=0, penalize_intercept=False, **init_params):\n        self.fit_intercept = fit_intercept\n        self.alpha = lam\n        self.penalize_intercept = penalize_intercept\n\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        self.n_features = X.shape[1]  # Exclude intercept\n\n        # Augment matrix and target vector\n        penalty = np.sqrt(self.alpha) * np.eye(self.n_features)\n\n        if sample_weight is None:\n            sample_weight = np.ones(X.shape[0])\n\n        if self.fit_intercept:\n            X = np.c_[np.ones(x.shape[0]), X]\n\n        w = np.sqrt(sample_weight)\n\n        X_aug = np.vstack([X * w.reshape(X.shape[0], 1), np.hstack([penalty, np.zeros((n_features, 1))])])\n        y_aug = np.concatenate([y * w, np.zeros(n_features)])\n\n        self.coef, residuals, rank, singular_values = np.linalg.lstsq(X_aug, y_aug, rcond=None)\n\n        return self\n\n    def predict(self, X, y=None):\n        return np.dot([1, X], self.coef)\n</code></pre> <p>Mini-Batch</p> <pre><code>class MiniBatchWLS(RegressorMixin):\n    \"\"\"\n    - Uses element-wise multiplication () for weighted regression to avoid the more cumbersome .dot and .diag\n    - np.linalg.lstsq is the most stable method, others are\n        - np.linalg.solve\n        - np.linalg.pinv\n        - np.linalg.inv\n    - Add 1s if intercept required\n    \"\"\"\n    def __init__(self, fit_intercept=True, alpha=0, penalize_intercept=False, n_splits=4, n_jobs=1, **init_params):\n        self.fit_intercept = fit_intercept\n        self.alpha = lam\n        self.penalize_intercept = penalize_intercept\n        self.n_splits = n_splits\n        self.n_jobs = n_jobs\n\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        self.n_samples, self.n_features = X.shape  # Exclude intercept\n\n        self.split_size = self.n_samples // self.n_splits\n\n        # Augment matrix and target vector\n        penalty = np.sqrt(self.alpha) * np.eye(self.n_features)\n\n        if sample_weight is None:\n            sample_weight = np.ones(X.shape[0])\n\n        if self.fit_intercept:\n            X = np.c_[np.ones(x.shape[0]), X]\n\n        w = np.sqrt(sample_weight)\n\n\n        # parallelize this\n        for split in range(self.n_splits):\n            idx_start = split * self.split_size\n            idx_end = (split+1) * self.split_size\n\n            Xg = X[start_idx:end_idx, :]\n            yg = y[start_idx:end_idx, :]\n\n            XtX += Xg.T @ Xg\n            Xty += Xg.T @ yg\n\n\n        X_aug = np.vstack([Xtx * w.reshape(self.n_samples, 1), np.hstack([penalty, np.zeros((self.n_features, 1))])])\n        y_aug = np.concatenate([Xty * w, np.zeros(self.n_features)])\n\n        self.coef, residuals, rank, singular_values = np.linalg.lstsq(X_aug, y_aug, rcond=None)\n\n        return self\n\n    def predict(self, X, y=None):\n        return np.dot([1, X], self.coef)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/ONNX/","title":"ONNX","text":"<p>Open Neural Network eXchange</p>"},{"location":"Tools/AI%20%26%20Data/ONNX/#pytorch-to-tflite","title":"PyTorch to TFLite","text":"<pre><code>import sys\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport onnx\nfrom collections import OrderedDict\nimport tensorflow as tf\nfrom torch.autograd import Variable\nfrom onnx_tf.backend import prepare\n\n# Load the trained model from file\ntrained_dict = torch.load(\n    sys.argv[1],\n    map_location={'cuda:0': 'cpu'}\n)\n\ntrained_model = MLP(784, [256, 256], 10)\ntrained_model.load_state_dict(trained_dict)\n\nif not os.path.exists(\"%s\" % sys.argv[2]):\n    os.makedirs(\"%s\" % sys.argv[2])\n\n# Export the trained model to ONNX\ndummy_input = Variable(torch.randn(1, 1, 28, 28)) # one black and white 28 x 28 picture will be the input to the model\ntorch.onnx.export(trained_model, dummy_input, \"%s/mnist.onnx\" % sys.argv[2])\n\n# Load the ONNX file\nmodel = onnx.load(\"%s/mnist.onnx\" % sys.argv[2])\n\n# Import the ONNX model to Tensorflow\ntf_rep = prepare(model)\ntf_rep.export_graph(\"%s/mnist.pb\" % sys.argv[2])\n\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(\n        \"%s/mnist.pb\" % sys.argv[2], tf_rep.inputs, tf_rep.outputs)\ntflite_model = converter.convert()\n\nwith open(\"%s/mnist.tflite\" % sys.argv[2], \"wb\") as f:\n    f.write(tflite_model)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/OpenCV/","title":"OpenCV","text":"<pre><code>import cv2 as cv\nimprot numpy as np\nimport matplotlib.pyplot as plt\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/OpenCV/#read-image","title":"Read Image","text":"<pre><code>img = cv.imread(\n  \"/fruits.jpg\",\n  cv.IMREAD_GRAYSCALE # COLOR, GRAYSCALE, UNCHANGED\n) # numpy array\n</code></pre> <pre><code># x, y, channel\nimg[:, :, 0] # particular channel only\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/OpenCV/#show","title":"Show","text":"<pre><code>plt.axis(\"off\")\nplt.imshow(img)\nplt.show()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/OpenCV/#filters","title":"Filters","text":"<pre><code>img = cv.cvtColor(\n  img,\n  cv.COLOR_BGR2RGB\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/OpenCV/#export","title":"Export","text":"<pre><code>cv.imwrite(\n    \"output.png\",\n  img\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/","title":"Pandas","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/#references","title":"References","text":"<ul> <li> Python in Data Science for Beginners - Pandas | learndataa</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/","title":"IDK","text":"<p>Try using numpy for operations whenever possible</p> <p>Use <code>to_numpy()</code> instead of <code>.values</code></p>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#importing","title":"Importing","text":"<pre><code>import pandas as pd\npd.set_option('max_columns', 200)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#creating-dataframe","title":"Creating Dataframe","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/01/#dataset","title":"Dataset","text":"<pre><code>  df = pd.read_csv(\"dataset.csv\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#manual","title":"Manual","text":"<pre><code>  perf = pd.DataFrame(\n      columns = ['Season', 'Appearances', 'Goals', 'Assists'],\n      data = [\n          [\"2021/2022\", 39, 24, 3],\n          [\"2020/2021\", 44, 36, 4],\n          [\"2019/2020\", 46, 37, 7]\n      ]\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#filtering","title":"Filtering","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/01/#query-and-eval","title":"<code>query</code> and <code>eval</code>","text":"<pre><code>  ## query - better than boolean masking\n  df = df.query(\"\"\"\n  @date_start &lt;= Date &lt;= @date_end and \\\n  Type in @event_type\n  \"\"\")\n\n  mask = df.eval(\"something\") ## gives the boolean mask corresponding to this\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#boolean-masking","title":"Boolean Masking","text":"<pre><code>  df = df[\n    (df[\"Date\"] &gt;= date_start) &amp;\n    (df[\"Date\"] &lt;= date_end) &amp;\n    (df[\"Type\"].isin(event_type))\n  ]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#editing-values","title":"Editing Values","text":"<pre><code>(\n  prediction\n  .assign(\n    Rating = prediction.Rating.to_numpy() * 100,\n    Value = prediction.Value.to_numpy() * 50,\n  )\n)\n\nprediction[['Rating', 'Value']] = prediction[['Rating', 'Value']].to_numpy() * 100\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#readwrite","title":"Read/Write","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/01/#single-file","title":"Single File","text":"<pre><code>  df = pd.read_csv(\n    file,\n    engine=\"pyarrow\", backend_dtypes=\"pyarrow\"\n  )\n\n  dfs = pd.read_excel('GDSC.xlsx', sheet_name=\"Something\") ## gives all\n  dfs = pd.read_excel('GDSC.xlsx', sheet_name=None) ## gives all\n  for table, df in dfs.items():\n      print(table, df)\n</code></pre> <pre><code>  file_name = file[:-4] + \".csv\"\n  df.to_csv(\n    os.getcwd() + \"\\\\\" + rel + file_name,\n    index = False\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#multiple-files","title":"Multiple Files","text":"<pre><code>  raw_formula_student = pd.DataFrame()\n  for file in files:\n      if( \".csv\" == file[-4:] ):\n          raw_formula_student = pd.concat(\n              [raw_formula_student, read_file(file)]\n          )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#read-google-sheets","title":"Read Google Sheets","text":"<p>Best method</p> <pre><code>    import gspread\n    gc = gspread.service_account(\"key.json\")\n\n    from gspread_dataframe import get_as_dataframe as get_gsheet, set_with_dataframe as set_gsheet\n\n    from functools import lru_cache\n\n    def gsheet_to_csv(spreadsheet_id, sheet_id=None, sheet_name=None):\n      ## make sure the spreadsheet is publicly viewable\n      if sheet_id is not None:\n        link = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/gviz/tq?tqx=out:csv&amp;gid={sheet_id}\"\n      elif sheet_name is not None:\n        link = f\"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/gviz/tq?tqx=out:csv&amp;sheet={sheet_name}\"\n      else:\n        return None\n\n        df = pd.read_csv(\n          link,\n            engine = \"pyarrow\",\n          backend_dtypes = \"pyarrow\"\n        )\n        return df\n\n    def gsheet_by_api(spreadsheet_id, sheet_id=None, sheet_name=None):\n          gsheet = gc.open_by_key(spreadsheet_id)\n      if sheet_id is not None:\n        sheet = gsheet.get_worksheet_by_id(sheet_id)\n      elif sheet_name is not None:\n        sheet = getattr(gsheet, sheet_name)\n      else:\n        return None\n\n      df = get_gsheet(sheet, evaluate_formulas=True)\n        return df\n\n    @lru_cache(maxsize = 128) ## or st.cache_data(ttl=ttl_long)\n    def read_gsheet(spreadsheet_id, sheet_id=None, sheet_name=None, parse_dates=None, csv=True):\n        if csv is True:\n          df = gsheet_to_csv(spreadsheet_id, sheet_id, sheet_name)\n        else:\n          df = gsheet_by_api(spreadsheet_id, sheet_id, sheet_name)\n\n      df = df.dropna(how= \"all\", axis=\"index\")\n      df = df.dropna(how= \"all\", axis=\"columns\")\n\n      for col_name in df.columns:\n        if \"date\" in col_name.lower() or \"time\".lower() in col_name:\n          df[col_name] = pd.to_datetime(df[col_name])\n\n      return df\n</code></pre> <p>Old method (Not working)</p> <pre><code>    gsheetkey = \"1kax9m1FKah7cWPwylxhdJSyqF5eVALjgRbxyPuPg7g0\"\n    sheet_name = 'Social_Media_Analysis'\n    url= f'[\u0644\u0645 \u064a\u062a\u0645 \u0627\u0644\u0639\u062b\u0648\u0631 \u0639\u0644\u0649 \u0627\u0644\u0635\u0641\u062d\u0629](https://docs.google.com/spreadsheet/ccc?key={gsheetkey}&amp;output=xlsx')\n\n    sheet = pd.read_excel(url, sheet_name = sheet_name)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#useful-functions","title":"Useful Functions","text":"<pre><code>df.head()\ndf.tail()\n\ndf.describe()\ndf.dropna()\n\ndf.select_dtypes(int)\n\ndf.memory_usage(deep=True).sum()/1_000_000 ## in MBs \n</code></pre> <pre><code>df = df.set_index(\n    \"Season\",\n    \"Player Name\"\n)\n</code></pre> <pre><code>df.unique()\ndf.value_counts()\n100 * df['col'].value_counts() / df['col'].shape[0]\n</code></pre> <pre><code>df['Age'].avg()\n</code></pre> Function Function Application <code>pipe()</code> Table-wise <code>assign()</code> <code>apply()</code> Row/column-wise (not good to use) <code>applymap()</code> Element-wise (not good to use) <pre><code>df.iloc[:, 2:11] = (\n  df.iloc[:, 2:11]\n  .apply(lambda x: x.str.replace(',', '.'))\n  .to_numpy()\n  .astype(float)\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#view-null-values","title":"View null values","text":"<pre><code>  formula_student[\n      formula_student.isna().any(axis=1)\n  ]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#correlation","title":"Correlation","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/01/#correlation-matrix","title":"Correlation Matrix","text":"<pre><code>  (\n    formula_student\n    [['Cost', 'Design', 'Overall Scores']]\n    .corr()\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#correlation-ranking","title":"Correlation Ranking","text":"<pre><code>  (\n      formula_student\n      .iloc[:, 1:11]\n      .corr(\"Overall Scores\")\n      .sort_values(\"Correlation\", ascending=False)\n      .iloc[1:, :] ## remove the obvious overall scores = 1.00\n  )\n</code></pre> <pre><code>  ## this is unnecessarily complicated way i used before\n  (\n      formula_student\n      .iloc[:, 1:11]\n      .corr()\n      .rename(columns={\"Overall Scores\":\"Correlation\"})\n      [[\"Correlation\"]]\n      .sort_values(\"Correlation\", ascending=False)\n      .iloc[1:, :] ## remove the obvious overall scores = 1.00\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#deleting","title":"Deleting","text":"<p>Drop first \\(n\\) records</p> <pre><code>  df = df.iloc[n: , : ]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#sorting","title":"Sorting","text":"<pre><code>(\n  perf\n  .sort_values(\"Season\")\n  .reset_index(drop=True)\n)\n</code></pre> <pre><code>(\n  perf\n  .sort_values([\n    \"Season\",\n    \"Rating\",\n    \"Value\"\n  ], ascending=[\n    True,\n    True,\n    False\n  ])\n  .reset_index(drop=True)\n)\n</code></pre> <p>Different approach</p> <pre><code>  (\n    formula_student[[\"Cost\", \"Overall Placing\"]]\n    .sort_values(\"Cost\", ascending = False)\n    .head(10)\n    .sort_values(\"Overall Placing\")\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#groupingaggregation","title":"Grouping/Aggregation","text":"<p>Make sure to use <code>observed = True</code> always, especially when using categorical columns</p> <pre><code>meanCols = {\n    \"Value\": \"MeanValue\",\n    \"Overall\": \"MeanOverall\",\n    \"CPIValue\": \"MeanCPIValue\"\n}\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#single-aggregation-function","title":"Single Aggregation Function","text":"<pre><code>df.values.mean()\n# don't do df.mean().mean()\n\nnp.nanmean(df.values)\nnp.nanstd(df.values)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#all-columns","title":"All Columns","text":"<pre><code>    (\n      merged\n      .groupby(\n        [\"Year\"],\n        observed = True,\n        as_index = False, # if Year should not become index of dataframe\n      )\n      .mean()\n      .rename(columns={\n        \"Value\": \"MeanValue\",\n        \"Overall\": \"MeanOverall\",\n        \"CPIValue\": \"MeanCPIValue\"\n      })\n    )\n    ## or mean = merged.groupby([\"Year\"]).mean().reset_index()\n</code></pre> <p>Renaming is for obvious reasons</p>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#particular-columns","title":"Particular Columns","text":"<pre><code>    mean = merged[[\"Year\",\"Value\"]].groupby(\n      [\"Year\"],\n      as_index=False\n    ).mean().rename(columns=meanCols)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#multiple-aggregation-function","title":"Multiple Aggregation Function","text":"<pre><code>  summary_df = (\n      df[[\"latitude\", \"longitude\", \"emission\"]]\n      .groupby([\"latitude\", \"longitude\"], as_index=False)\n      .agg({\n          \"emission\": [\"median\",\"std\", \"mean\", \"min\", \"max\"]\n      })\n  )\n  summary_df.columns = summary_df.columns.map('_'.join)\n\n  df = df.merge(summary_df, how=\"inner\")\n</code></pre> <pre><code>  (\n    merged\n    .groupby(\n      [\"Year\"],\n      as_index=False\n    )\n    .agg(\n      ['mean', 'sum']\n    )\n  )\n</code></pre> <p>Round-off all results</p> <pre><code>    formula_student[[\"Car\", \"Overall Scores\"]]\n        .groupby(\n            [\"Competition\"]\n        )\n        .agg({\n            'Car' : [\"count\"],\n            'Overall Scores' : [\"mean\", \"min\", \"max\"]\n        })\n        .round(1)\n</code></pre> <p>Round-off specific results</p> <pre><code>    def mean_func(x):\n        return round(x.mean(), 1)\n\n    formula_student[[\"Car\", \"Overall Scores\"]]\n        .groupby(\n            [\"Competition\"]\n        )\n        .agg({\n            'Car' : [\"count\"],\n            'Overall Scores' : [mean_func, \"min\", \"max\"]\n        })\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#idk_1","title":"IDK","text":"<p>The count of each value until it changes to another value</p> <pre><code>  index  value\n      0     10\n      1     10\n      2     23\n      3     23\n      4      9\n      5      9\n      6      9\n      7     10\n      8     10\n      9     10\n     10     10\n     11     12\n\n  ---\n\n  index count\n     10     2\n     23     2\n      9     3\n     10     4\n     12     1\n</code></pre> <pre><code>  col = 'col_name'\n\n  df = (\n    df\n    .groupby(\n      df[col]\n      .ne( ## not equal to previous value; ie change occured\n        df[col]\n        .shift()\n      )\n      .cumsum()\n    )\n    [col]\n    .value_counts()\n    .reset_index(level=0, drop=True)\n  )\n</code></pre> <p>Explanation</p> <pre><code>      ## This is the intermediate dataframe produced\n      ## We then group by cumsum\n\n      index  value  shifted  not_equal  cumsum\n          0     10      NaN       True       1\n          1     10     10.0      False       1\n          2     23     10.0       True       2\n          3     23     23.0      False       2\n          4      9     23.0       True       3\n          5      9      9.0      False       3\n          6      9      9.0      False       3\n          7     10      9.0       True       4\n          8     10     10.0      False       4\n          9     10     10.0      False       4\n         10     10     10.0      False       4\n         11     12     10.0       True       5\n</code></pre> <pre><code>  col = 'col_name'\n\n  changes = (\n    df[col]\n    .diff()\n    .ne(0)\n    .cumsum()\n  )\n\n  df = (\n    df\n    .groupby([changes,col])\n    .size()\n    .reset_index(level=0, drop=True)\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#joinmerge","title":"Join/Merge","text":"<pre><code>merged = pd.merge(\n    ratings[ratings[\"Value\"] &gt;= 10000],\n    cpi\n).sort_values(\"Value\").reset_index(drop=True)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#plotting","title":"Plotting","text":"<pre><code>merged.plot(\n  x=\"Season\",\n  ylabel=\"Feature\",\n  title=\"Features over Time\"\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#plotting-backend","title":"Plotting Backend","text":"<pre><code>  pd.options.plotting.backend = 'plotly'\n  df.plot(backend='plotly')\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#type-casting","title":"Type Casting","text":"<pre><code>df['Fee'] = df['Fee'].to_numpy().astype(float)\n## df['Fee'] = df['Fee'].astype(float)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#lagged-value","title":"Lagged Value","text":"<p>alias::shift lag <pre><code>nba[\"wpc_lag\"] = (\n  nba\n  .groupby(\"Team\")\n  [\"wpc\"]\n  .shift(1)\n)\n</code></pre></p>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#performance-optimization","title":"Performance Optimization","text":"<p>https://pythonspeed.com/datascience</p>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#selectively-load-columns","title":"Selectively-load columns","text":"<pre><code>  df = pd.read_csv(\n    \"dataset.csv\",\n    usecols = [\n      \"First Name\",\n      \"Last Name\"\n    ]\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#selectively-load-rows","title":"Selectively-load rows","text":"<pre><code>  df = pd.read_csv(\n    \"dataset.csv\",\n    nrows = 10\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#reducing-variables-in-functions","title":"Reducing variables in functions","text":"<pre><code>  def process_data():\n      return modify2(modify1(load_1GB_of_data()))\n</code></pre> <p>instead of <pre><code>  def process_data():\n      data = load_1GB_of_data() ## \u2190 `data` var lives too long\n      return modify2(modify1(data))\n</code></pre></p>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#use-correct-dtypes","title":"Use correct <code>dtypes</code>","text":"<pre><code>  df = pd.read_csv(\n    \"dataset.csv\",\n    dtype = {\n      \"Age\": \"uint8\",\n      \"Year\": \"uint16\",\n      \"Time\": \"datetime\"\n      \"Salary\": \"ufloat32\",\n      \"Gender\": \"category\",\n      \"Name\": \"string[pyarrow]\"\n    }\n  )\n</code></pre> <p>Dynamically cleaning up after reading based on datatype; but i would recommend above</p> <pre><code>    def get_optimal_numeric_type(c_min: float, c_max: float, col_type: str) -&gt; str:\n        \"\"\"\n        Determines the optimal numeric data type for a given range of values.\n\n        Parameters\n        ----------\n        c_min : float\n            The minimum value of the data.\n        c_max : float\n            The maximum value of the data.\n        col_type : str\n            The current data type of the column ('int' or 'float').\n\n        Returns\n        -------\n        optimal_type : str\n            The optimal data type for the given range of values.\n        \"\"\"\n        type_info = np.iinfo if col_type == 'int' else np.finfo\n        for dtype in [np.int8, np.int16, np.int32, np.int64, np.float16, np.float32, np.float64]:\n            if col_type in str(dtype):\n                if c_min &gt; type_info(dtype).min and c_max &lt; type_info(dtype).max:\n                    return dtype\n        return None\n\n    \"\"\" Based on the data type and the range of values, the function determines the smallest possible data type that can accommodate the data without losing information. For example, if the data type is an integer and the range of values fits within the bounds of an int8 data type, the function converts the column data type to int8: \"\"\"\n\n    def reduce_memory_usage(df: pd.DataFrame) -&gt; pd.DataFrame:\n        \"\"\"\n        Reduces memory usage of a pandas DataFrame by converting its columns to the most memory-efficient data types\n        without losing information.\n\n        Parameters\n        ----------\n        df : pd.DataFrame\n            The input pandas DataFrame that needs memory optimization.\n\n        Returns\n        -------\n        df : pd.DataFrame\n            The optimized pandas DataFrame with reduced memory usage.\n        \"\"\"\n\n        ## Iterate through each column in the DataFrame\n        df_copy = df.copy()\n        for col in df_copy.columns:\n            col_type = df_copy[col].dtype\n\n            ## Check if the data type is not an object (i.e., numeric type)\n            if col_type != object:\n                c_min, c_max = df_copy[col].min(), df_copy[col].max()\n                col_type_str = 'int' if 'int' in str(col_type) else 'float'\n                optimal_type = get_optimal_numeric_type(c_min, c_max, col_type_str)\n                if optimal_type:\n                    df_copy[col] = df_copy[col].astype(optimal_type)\n            ## If the data type is an object, convert the column to a 'category' data type\n            else:\n                df_copy[col] = df_copy[col].astype('category')\n\n        ## Return the optimized DataFrame with reduced memory usage\n        return df_copy\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#use-pyarrow-engine","title":"Use <code>[[pyarrow]]</code> engine","text":"<pre><code>  df = pd.read_csv(\n    \"dataset.csv\",\n    engine = \"pyarrow\"\n  )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#use-modin","title":"Use Modin","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/01/#clipping","title":"Clipping","text":"<pre><code>## using pandas\ndf = df.clip(\n  lower = df['Column'].quantile(.25, interpolation=\"midpoint\"),           \n  upper = df['Column'].quantile(.75, interpolation=\"midpoint\")\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#chaining","title":"Chaining","text":"<pre><code>(\n  df\n  .pipe(function)\n  .assign(\n    ensnetns = nesntens\n  )\n  .astype({\"highway\": np.int8})\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#sql","title":"SQL","text":"<pre><code>df = pd.read_sql(query, engine)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#exporting-to-html","title":"Exporting to HTML","text":"<pre><code>html = \"\"\"\n&lt;head&gt;\n  &lt;link rel=\"stylesheet\" href=\"../../../backend/plugins/bootstrap/bootstrap.min.css\"&gt;\n  &lt;script src=\"../../../backend/plugins/bootstrap/bootstrap.min.js\"&gt;&lt;/script&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\"\"\"\n&lt;body&gt;\nhtml += blah_df.head.to_html(classes='table table-stripped')\nhtml += \"&lt;/body&gt;\"\n\nexporter = open(\"blah_df.html\", 'w')\nexporter.write(html)\nexporter.close()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#get","title":"Get","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/01/#get-last-letter-of-every-row","title":"Get last letter of every row","text":"<pre><code>  spf_unrate[\"PERIOD\"].str.get(-1)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#first-name","title":"First Name","text":"<pre><code>  df[\"Name\"] = df[\"Name\"].str.split().str.get(0)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#yearmonthdate","title":"Year/Month/Date","text":"<pre><code>  fred[\"YEAR\"] = pd.DatetimeIndex(fred['DATE']).year\n  fred = fred.drop(\"DATE\", axis=1)\n  fred\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#time-series","title":"Time Series","text":"<pre><code>df.shift(10)\ndf.diff(10)\n\n## window functions\ndf.rolling(10).mean()\ndf.rolling(10, center=True).mean()\n\ndf.expanding(10).mean()\ndf.expanding(10, center=True).mean()\n\n## exponential weighted window\ndf.ewm(10).mean()\ndf.ewm(10, center=True).mean()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#faster-windows-using-numpy","title":"Faster windows using numpy","text":"<pre><code>def rolling_window(a, window):\n    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n    strides = a.strides + (a.strides[-1],)\n    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n\nnp.mean(rolling_window(s, 2), axis=1)\nnp.median(rolling_window(s, 2), axis=1)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#missing-values","title":"Missing Values","text":"<pre><code>def check(data):\n  print(data.isnull().values.any())\n\nsheet.apply(check)          ## check if col has missing value\nsheet.apply(check, axis=1)  ## check if row has missing value\nsheet.pipe(check)           ## check if dataframe has missing value\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/01/#my-cleaning","title":"My Cleaning","text":"<pre><code>def clean_df(data):\n  df = data.copy()\n\n  for column in df.columns:\n    if \"date\" in column:\n      df[column] = pd.to_datetime(sheet[column])\n\n  df = df.apply(lambda col: col.str.strip() if col.dtype == \"object\" else col)\n\n  return df\n\nsheet.pipe(clean_df)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/02/","title":"02","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/02/#monotonicity","title":"Monotonicity","text":""},{"location":"Tools/AI%20%26%20Data/Pandas/02/#decreasing","title":"Decreasing","text":"<pre><code>df[\"Reading\"] = (\n  df\n  .sort_values(\"Time_Point\", ascending=True) # this is the time column, so always ascending\n  .groupby(\"Temperature\")\n  [\"Reading\"]\n  .cummin()\n)\n# or \ndf_train[\"Reading_Time_Point_Cummin\"] = (\n  df_train\n  .sort_values(\"Time_Point\", ascending=True) # this is the time column, so always ascending\n  .groupby(\"Temperature\")\n  [\"Reading\"]\n  .cummin()\n)\ndf_train = df_train.query(\"Reading &lt;= Reading_Time_Point_Cummin\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/02/#increasing","title":"Increasing","text":"<pre><code>df[\"Reading\"] = (\n  df\n  .sort_values(\"Time_Point\", ascending=True) # this is the time column, so always ascending\n  .groupby(\"Temperature\")\n  [\"Reading\"]\n  .cummax()\n)\n\ndf_train[\"Reading_Time_Point_Cummax\"] = (\n  df_train\n  .sort_values(\"Time_Point\", ascending=True) # this is the time column, so always ascending\n  .groupby(\"Temperature\")\n  [\"Reading\"]\n  .cummax()\n)\ndf_train = df_train.query(\"Reading &gt;= Reading_Time_Point_Cummin\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/02/#sampling","title":"Sampling","text":"<pre><code># if n=frac, then percentage of dataset\ndf.sample(\n  0.10\n)\n\n# if n=int, then count of dataset\ndf.sample(\n  1_000\n)\n\n# sampling with prob weights\ndf.sample(\n  1_000,\n  weights = \"Weight_Column\"\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/02/#multi-index","title":"Multi-Index","text":"<pre><code>df.columns = list(map('_'.join, df.columns.values))\ndf = df.reset_index()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Pandas/02/#objectname","title":"ObjectName","text":"<pre><code>class Class:\n  pass\n\nmodel = Class()\nmodel_name = type(model).__name__\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Polars/","title":"Polars","text":""},{"location":"Tools/AI%20%26%20Data/Polars/01/","title":"Introduction","text":""},{"location":"Tools/AI%20%26%20Data/Polars/01/#method-chaining","title":"Method Chaining","text":"<p>Equivalent to <code>.pipe()</code> in Pandas</p> <pre><code>df = (\n  df\n  .with_columns(f) # single function\n  .with_columns([g1, g2]) # multiple functions concurrently\n)\n\ndef f() -&gt; pl.Expr:\n    \"\"\"\n    Get first word of column\n    \"Chicago\" -&gt; \"C\"\n    \"\"\"\n    cols = [\"City\", \"Country\"]\n    return pl.col(cols).str.get(0)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/","title":"PyTorch","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/#references","title":"References","text":"<ul> <li> Learn PyTorch for deep learning in a day | Daniel Bourke</li> <li> Skorch</li> <li> PyTorch | Aladdin Persson</li> <li> PyTorch Lightning | Lightning AI</li> <li> PyTorch Lightning | Aladdin Persson</li> </ul>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/","title":"Introduction","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#imports","title":"Imports","text":"<pre><code>import torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nimport timm\n\nimport matplotlib.pyplot as plt ## For data viz\nimport pandas as pd\nimport numpy as np\n\nimport sys\nfrom tqdm.notebook import tqdm\n\nprint('System Version:', sys.version)\nprint('PyTorch version', torch.__version__)\nprint('Torchvision version', torchvision.__version__)\nprint('Numpy version', np.__version__)\nprint('Pandas version', pd.__version__)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#init","title":"Init","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#device","title":"Device","text":"<pre><code>device = (\n  \"mps\" if torch.backends.mps.is_available() and torch.backends.mps.is_built()\n  else\n  \"cuda\" if torch.cuda().is_available()\n  else\n  \"cpu\"\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#seed","title":"Seed","text":"<p>Disable these after debugging <pre><code>seed = 42\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\n\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False # hit on performance\n</code></pre></p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#tensors","title":"Tensors","text":"<pre><code>torch.mean(image_data, axis=0) ## column-wise mean\n\nluminance_approx = torch.mean(image_array, axis=-1) ## color_channel-wise mean\n\nvalues, indices = torch.max(data, axis=-1)\n</code></pre> <ul> <li><code>int8</code> is an integer type, it can be used for any operation which needs integers</li> <li><code>qint8</code> is a quantized tensor type which represents a compressed floating point tensor, it has an underlying int8 data layer, a scale, a zero_point and a qscheme</li> </ul>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#creating-tensors","title":"Creating Tensors","text":"<pre><code># \u274c\ntensor.tensor([2, 2]).cuda()\ntensor.rand(2, 2).cuda()\n\n# \u2705\ntensor.tensor([2, 2], device=device)\ntensor.rand(2, 2, device=device)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#conversion-to-tensor","title":"Conversion To Tensor","text":"<pre><code># \u274c creates a copy\ntensor = torch.tensor(array, device=device)\n\n# \u2705 avoids copying\ntensor = torch.as_tensor(array, device=device)\ntensor = torch.from_numpy(array, device=device)\n# however, changing array will also affect tensor\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#conversion-from-tensor","title":"Conversion From Tensor","text":"<pre><code># \u274c\ntensor.cpu()\ntensor.numpy()\ntensor.item() # causes synchronization\n\n# \u2705\ntensor.detach()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#api","title":"API","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#model-mode","title":"Model Mode","text":"<pre><code>model.train()\n\nmodel.eval()\nwith torch.inference_mode(): # turn off history tracking\n    pass\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#sequential","title":"Sequential","text":"<pre><code>nn.Sequential(\n    nn.LazyLinear(100),\n  nn.ReLU()\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#lazy-layers","title":"Lazy Layers","text":"<p>automatically detect the input size</p> <p>Only specify output size</p> <pre><code>nn.Sequential(\n  nn.LazyLinear(1000),\n  nn.LazyLinear(10),\n  nn.LazyLinear(100)\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#saveload-model","title":"Save/Load Model","text":"<pre><code># Method 1 - official recommended\ntorch.save(model.state_dict(), 'model-parameters.pt')\n\nmodel = NN(*args, **kwargs)\nthe_model.load_state_dict(torch.load('model-parameters.pt'))\n\n# Method 2\ntorch.save(model, 'model.pt')\nmodel = torch.load('model.pt')\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#view-parameters","title":"View Parameters","text":"<pre><code>for param in model.parameters():\n  print(name)\n\nfor name, param in model.named_parameters():\n    if param.requires_grad:\n        print(name, param.data)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#custom-loss-function","title":"Custom Loss Function","text":"<pre><code>class loss(nn.module):\n  def forward(self, pred, y):\n    error = pred-y\n    return torch.mean(\n      torch.abs(error)\n    )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#idk","title":"IDK","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#time-series","title":"Time-Series","text":"<pre><code>class TimeseriesDataset(torch.utils.data.Dataset):   \n    def __init__(self, X, y, seq_len=1):\n        self.X = X\n        self.y = y\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return self.X.__len__() - (self.seq_len-1)\n\n    def __getitem__(self, index):\n        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len-1])\n</code></pre> <pre><code>train_dataset = TimeseriesDataset(X_lstm, y_lstm, seq_len=4)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 3, shuffle = False)\n\nfor i, d in enumerate(train_loader):\n    print(i, d[0].shape, d[1].shape)\n\n&gt;&gt;&gt;\n# shape: tuple((batch_size, seq_len, n_features), (batch_size))\n0 torch.Size([3, 4, 2]) torch.Size([3])\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/01_Introduction/#torchserve","title":"TorchServe","text":"<p>[!WARNING] Torchserve Shelltorch exploit</p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/","title":"Basic Model","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#steps","title":"Steps","text":"<ul> <li>Define model using <code>nn.module</code></li> <li>Cost function</li> <li>Optimizer</li> <li>Epochs</li> <li>Train data</li> <li>Predict</li> </ul>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#device","title":"Device","text":"<pre><code>if torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\nelse:\n    device = torch.device(\"cpu\")\n\nprint(f\"Using {device}\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#data","title":"Data","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#dataset","title":"Dataset","text":"<pre><code>class CTDataset(Dataset):\n    def __init__(self, filepath, device):\n        self.x, self.y = torch.load(filepath, map_location=device)\n        self.x = self.x / 255.0\n        self.y = nn.functional.one_hot(self.y, num_classes=10).to(float)\n\n    def __len__(self):\n        return self.x.shape[0]\n\n    def __getitem__(self, ix):\n        return self.x[ix], self.y[ix]\n</code></pre> <pre><code># https://www.di.ens.fr/~lelarge/MNIST.tar.gz\ntrain_ds = CTDataset(\"./MNIST/training.pt\", device)\n# test_ds = CTDataset('./MNIST/test.pt', device)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#dataloader","title":"Dataloader","text":"<pre><code>train, dev, valid = random_split(train_ds, [0.6, 0.2, 0.2])\n</code></pre> <pre><code>train_size = min(8, len(train)) # Check if model overfits on small data, to ensure DNN actually is effective\ndev_size = min(8, len(dev))\n\nmin_training_batches = 4\ntrain_batch_size = min(32, max(1, train_size // min_training_batches))\n\nevaluation_batch_size = min(1_024, dev_size)\n</code></pre> <pre><code>train_random_sampler = RandomSampler(train, num_samples=train_size)\ndev_random_sampler = RandomSampler(dev, num_samples=dev_size)\n\ntrain_dl = DataLoader(\n    train, sampler=train_random_sampler, batch_size=train_batch_size, drop_last=True\n)\n\ndev_dl = DataLoader(\n    dev, sampler=dev_random_sampler, batch_size=evaluation_batch_size, drop_last=True\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#model","title":"Model","text":"<pre><code># architecture\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#train","title":"Train","text":"<pre><code>def get_max_len(arrays):\n    return max(\n        [\n            len(array)\n            for array\n            in arrays\n        ]\n    )\n\ndef pad(array, max_len):\n    return list(np.pad(\n        array,\n        pad_width = (0, max_len-len(array)),\n        constant_values = np.nan\n    ))\n\ndef get_all_nodes(model):\n    network_nodes = []\n\n    layers = model.named_children()\n    for i, layer in enumerate(layers):\n        layer_nodes_formatted = []\n\n        sub_layer = layer[-1]\n        for sub_layer_node in sub_layer:\n            layer_nodes_formatted.append(sub_layer_node)\n\n        network_nodes.append(layer_nodes_formatted)\n\n    return network_nodes\n\ndef get_summary_agg(df, agg=[\"mean\"], precision=2):\n    df = (\n        df\n        .groupby([\"Epoch\", \"Train_Time\", \"Subset\"])\n        .agg({\n            \"Loss\": agg,\n            \"Accuracy\": [\"mean\"]\n        })\n        .round(precision)\n    )\n    df.columns = list(map('_'.join, df.columns.values))\n    df = (\n        df\n        .reset_index()\n        .pivot(\n            index=[\"Epoch\", \"Train_Time\"],\n            columns=\"Subset\",\n            # values = \"Accuracy\"\n        )\n    )\n    df.columns = list(map('_'.join, df.columns.values))\n\n    # should not be part of data collection\n    # df[\"Generalization_Gap\"] = df[\"Loss_mean_Dev\"] - df[\"Loss_mean_Train\"]\n\n    df = df.reset_index()\n\n    return df\n</code></pre> <pre><code># @torch.compile(mode=\"reduce-overhead\")\ndef train_batch(model, optimizer, loss, x, y, train_dl_len, batch_idx, device, accum_iter=1, k_frac=None):\n    x = x.half()\n    y = y.half()\n    # x = x\n    # y = y\n\n    model.train()\n    # with torch.set_grad_enabled(True): # turn on history tracking\n    # forward pass\n    proba = model(x)\n    loss_array = loss(proba, y)\n\n    loss_scalar = loss_array.mean()\n\n    # backward pass\n    optimizer.zero_grad(set_to_none=True) # clear accumulated gradients from backpropagation\n    loss_scalar.backward()\n\n    # weights update\n    # if accum_iter != 1 -&gt; gradient accumulation\n    batch_num = batch_idx + 1\n\n    if (\n        (batch_num % accum_iter == 0)\n        or\n        (batch_num == len(train_dl_len))\n    ):\n        optimizer.step()\n\n# @torch.compile(mode=\"reduce-overhead\")\ndef train_epoch(dl, model, optimizer, loss, train_dl_len, device, eval=False, k_frac=None):\n\n    # epoch_accuracies = []\n    epoch_losses = []\n    epoch_accuracies = []\n\n    for batch_idx, (x, y) in enumerate(dl):\n        train_batch(model, optimizer, loss, x, y, train_dl_len, batch_idx, device, accum_iter=1, k_frac=k_frac)\n\n        # epoch_accuracies += eval_batch(model, x, y)\n        if eval:\n            temp = eval_batch(model, x, y, loss, device)\n            epoch_losses += temp[0]\n            epoch_accuracies += temp[1]\n\n    return epoch_losses, epoch_accuracies\n\n# @torch.compile(mode=\"reduce-overhead\")\ndef eval_batch(model, x, y, loss, device):\n    x = x.half()\n    y = y.half()\n\n    # x = x\n    # y = y\n\n    model.eval()\n    with torch.inference_mode(): # turn off history tracking\n        # forward pass\n        proba = model(x)\n\n        loss_value = loss(proba, y)\n        epoch_loss_array = loss_value.detach() # loss_value.item() # batch loss\n\n        true = model.predict_from_proba(y)\n        pred = model.predict_from_proba(proba)\n        epoch_accuracy_array = (pred == true) # torch.sum()\n\n        return epoch_loss_array, epoch_accuracy_array\n\n# @torch.compile(mode=\"reduce-overhead\")\ndef eval_epoch(dl, model, loss, device):\n    epoch_accuracies = []\n    epoch_losses = []\n    for batch_idx, (x, y) in enumerate(dl):\n        temp = eval_batch(model, x, y, loss, device)\n        epoch_losses += temp[0]\n        epoch_accuracies += temp[1]\n\n    return epoch_losses, epoch_accuracies\n\n\ndef train_model(train_dl, dev_dl, model, loss, optimizer, n_epochs, device, train_eval_every=10, dev_eval_every=10, agg=None, k_frac=None, log=False):\n    print(rf\"\"\"\n    \\n\n    Training with {train_dl, dev_dl, model, loss, optimizer, n_epochs, device, train_eval_every, dev_eval_every, agg, k_frac, log}\n    \"\"\")\n\n    model = model.to(device).half()\n\n    model.train()\n\n    summary_list = []\n\n    train_dl_len = len(train_dl)\n\n    print_epoch_every = dev_eval_every\n\n    train_time = 0\n    for epoch in range(1, n_epochs + 1):\n        print_epoch = False\n        eval_train = False\n        eval_dev = False\n\n        if epoch == 1 or epoch == n_epochs:\n            eval_train = True\n            eval_dev = True\n            if log:\n                print_epoch = True\n        if epoch % train_eval_every == 0:\n            eval_train = True\n        if epoch % dev_eval_every == 0:\n            eval_dev = True\n        if epoch % print_epoch_every == 0:\n            print_epoch = True\n\n        if print_epoch:\n            print(f\"Epoch {epoch}/{n_epochs} started\", end=\"\")\n\n        start_time = time.time()\n        epoch_train_losses, epoch_train_accuracies = train_epoch(train_dl, model, optimizer, loss, train_dl_len, device, eval=eval_train, k_frac=k_frac)\n        end_time = time.time()\n        duration = end_time-start_time\n        train_time += duration\n\n        if eval_dev:\n            epoch_dev_losses, epoch_dev_accuracies = eval_epoch(dev_dl, model, loss, device)\n        else:\n            epoch_dev_losses, epoch_dev_accuracies = [], []\n\n        for e, a in zip(epoch_train_losses, epoch_train_accuracies):\n            summary_list.append(\n                [epoch, train_time,  \"Train\", float(e), float(a)]\n            )\n        for e, a in zip(epoch_dev_losses, epoch_dev_accuracies):\n            summary_list.append(\n                [epoch, train_time, \"Dev\", float(e), float(a)]\n            )\n\n        if print_epoch:\n            print(f\", completed\")\n\n    model.eval()\n\n    summary = (\n         pd.DataFrame(\n            columns = [\"Epoch\", \"Train_Time\", \"Subset\", \"Loss\", \"Accuracy\"],\n            data = summary_list\n        )\n    )\n\n    if agg is not None:\n        summary = summary.pipe(get_summary_agg, agg)\n\n    return summary\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#idea","title":"Idea","text":"<p>I was watching https://youtu.be/VMj-3S1tku0 and got an idea. I\u2019ve put the same here: https://github.com/karpathy/micrograd/issues/78</p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#context","title":"Context","text":"<p>This is in reference to the step of clearing accumulated gradients at: https://github.com/karpathy/micrograd/blob/c911406e5ace8742e5841a7e0df113ecb5d54685/demo.ipynb#L265</p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#problem","title":"Problem","text":"<p>People tend to forget to clear the gradients wrt the loss function backward pass.</p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#idea_1","title":"Idea","text":"<p>Create a way to bind the loss function to the network once, and then automatically clear accumulated gradients automatically when performing the backward pass.</p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#advantage","title":"Advantage","text":"<p>We can perform backward pass whenever, wherever, and as many times as we want without worrying about accumulated gradient.</p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#pseudocode","title":"Pseudocode","text":"<pre><code>class Loss(Value):\n  def __init__(self, bound_network):\n    self.bound_network = bound_network\n\n  def __call__(self, batch_size=None):\n    # loss function definition\n    self.data = data_loss + reg_loss\n\n  def backward():\n    # clear gradients of bound network\n    bound_network.zero_grad()\n    super().backward()    \n\ntotal_loss = Loss(\n  bound_network = model\n)\n\nfor k in range(100):\n  # ...\n\n  # model.zero_grad() # since total_loss is bound to network, it should automatically perform model.zero_grad() before doing the backward\n  total_loss.backward()\n\n  # ...\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#questions","title":"Questions","text":"<ol> <li>Is my understanding of the problem correct?</li> <li>Is this change value-adding?</li> <li>Is the above pseudocode logically correct?</li> <li>If the answer to all the above are yes, I could work on a PR with your guidance.</li> </ol>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#loss-curve","title":"Loss Curve","text":"<pre><code>def plot_summary(df, x, y):\n    df = df.copy()\n    c = \"Optimizer\"\n\n    if \"Accuracy\" in y and \"Generalization\" not in y:\n        sub_title = f\"Higher is better\"\n        percentage = True\n    else:\n        sub_title = f\"Lower is better\"\n        percentage = False\n\n    if percentage:\n        df[y] *= 100\n\n    if \"Accuracy\" in y and \"Generalization\" not in y:\n        range_y = [\n            0,\n            100\n        ]\n    else:\n        range_y = [\n            0,\n            df[\n                df[y] &gt; 0\n            ][y].quantile(0.90)*1.1\n        ]\n\n    # if \"loss\" in y.lower():\n    #   range_y = [0, df[y].quantile(0.90)*1.1]\n    # else:\n    #   range_y = None\n    # if y == \"Generalization_Gap\":\n    #   sub_title = f\"Lower is better\"\n    #   range_y = None\n    # else:\n    #   range_y = [0, 100 if percentage else 1]\n    #   sub_title = f\"Higher is better\"\n\n    title = f'{y.replace(\"_\", \" \")}'\n\n    title += f\"&lt;br&gt;&lt;sup&gt;{sub_title}&lt;/sup&gt;\"\n\n    facet_row = \"Train_Batch_Size\"\n\n    fig = px.line(\n        data_frame=df,\n        x=x,\n        y=y,\n        facet_col=\"Learning_Rate\",\n        facet_row=\"Train_Batch_Size\",\n        facet_row_spacing = 0.1,\n        color = c,\n        title = title,\n        range_x = [df[x].values.min(), df[x].values.max()],\n        range_y = range_y, # df[y].values.min() * 0.95\n        markers=True,\n    )\n\n    n_rows = df[facet_row].unique().shape[0]\n    fig.update_layout(height=300*n_rows)\n    fig.update_traces(\n        patch={\n            \"marker\": {\"size\": 5},\n            \"line\": {\n                \"width\": 1,\n                # \"dash\": \"dot\"\n            },\n        }\n    )\n    fig.update_traces(connectgaps=True) # required for connecting dev accuracies\n    st.plotly_chart(fig, use_container_width=True)\n\n    return fig\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/02_Basic_Model/#multiple-models","title":"Multiple Models","text":"<pre><code>import inspect\n\ndef train_models(loss, model, n_epochs, optimizer_names, learning_rates, train_batch_sizes, device, agg=[\"mean\"], train_eval_every=10, dev_eval_every=10, log=False, output_path = \"summary.csv\"):\n    # summaries = pd.DataFrame()\n    # i=0\n    train_size = min(2_048, len(train)) # Check if model overfits on small data, to ensure DNN actually is effective\n    dev_size = min(2_048, len(dev))\n    train_random_sampler = RandomSampler(train, num_samples=train_size)\n    dev_random_sampler = RandomSampler(dev, num_samples=dev_size)\n\n    evaluation_batch_size = 2_048\n\n    if evaluation_batch_size &gt; dev_size:\n        raise Exception(\"Evaluation batch size &gt; dev size\")\n\n    for train_batch_size in train_batch_sizes:\n        if evaluation_batch_size &gt; train_size:\n            raise Exception(\"Evaluation batch size &gt; dev size\")\n\n        train_dl = DataLoader(\n            train, sampler=train_random_sampler, batch_size=train_batch_size, drop_last=True,\n            # num_workers = 1 # 0\n        )\n\n        dev_dl = DataLoader(\n            dev, sampler=dev_random_sampler, batch_size=evaluation_batch_size, drop_last=True,\n            # num_workers = 1 # 0\n        )\n\n        for learning_rate in learning_rates:\n            if learning_rate &gt; 0.0100:\n                raise Exception(\"Very high learning rate\")\n            for optimizer_name in optimizer_names:\n                model_copy = copy.deepcopy(model)\n                optimizer = getattr(optim_class, optimizer_name)\n                optimizer_kwargs = dict(\n                    params = model_copy.parameters(),\n                    lr=learning_rate\n                )\n                if \"eps\" in list(inspect.getfullargspec(optimizer.__init__)[0]):\n                    optimizer_kwargs.update(eps=1e-4)\n                optimizer = optimizer(**optimizer_kwargs)\n\n                for state in optimizer.state.values():\n                    for k, v in state.items():\n                        if isinstance(v, torch.Tensor):\n                            state[k] = torch.as_tensor(v, device=device).half()\n\n                summary = train_model(\n                    train_dl,\n                    dev_dl,\n                    model_copy,\n                    loss,\n                    optimizer,\n                    n_epochs,\n                    device = device,\n                    train_eval_every=train_eval_every,\n                    dev_eval_every=dev_eval_every,\n                    log=log,\n                    agg = agg\n                )\n                summary[\"Model\"] = str(get_all_nodes(model_copy))\n                summary[\"Optimizer\"] = optimizer_name\n                summary[\"Learning_Rate\"] = learning_rate\n                summary[\"Train_Batch_Size\"] = train_batch_size\n\n                # disabled due too high space complexity\n                # summaries = pd.concat([\n                #   summaries,\n                #   summary\n                # ])\n                summary.to_csv(\n                    output_path,\n                    index = False,\n                    mode = \"a\",\n                    header = not os.path.exists(output_path)\n                )\n                gc.collect(0)\n\n                # i += 1\n                # if i==1:\n                #   break\n\n    return None\n</code></pre> <pre><code>model = NeuralNet(\n    init_data = train,\n    hidden_layers = [\n        nn.Flatten(),\n        nn.LazyLinear(10),\n        nn.ReLU(),\n        # nn.LazyLinear(10),\n        # nn.ReLU()\n        # nn.Sigmoid() # not required\n    ]\n)\n</code></pre> <pre><code>def percentile(p):\n    def percentile_(x):\n        return np.percentile(x, p)\n    percentile_.__name__ = f'Percentile_{p}'#.format(n*100)\n    return percentile_\n</code></pre> <pre><code>optimizer_names = [\n    # 'ASGD',\n    # 'Adadelta',\n    # 'Adagrad',\n    'Adam',\n    # 'AdamW',\n    # 'Adamax',\n    # # 'LBFGS',\n    # 'NAdam',\n    # 'RAdam',\n    # 'RMSprop',\n    # 'Rprop',\n    'SGD',\n    # 'SparseAdam'\n]\n</code></pre> <pre><code>gc.collect()\ngc.set_threshold(0)\nsummaries = train_models(\n  loss = nn.CrossEntropyLoss(reduction=\"none\"),\n    model = model,\n    n_epochs = 20, # 3\n    optimizer_names = optimizer_names,\n    learning_rates = [\n      1e-4, 1e-3, 1e-2\n    ],\n    train_batch_sizes = [\n        16, 32, 64\n    ],\n    device = device,\n    agg = [\n        \"mean\",\n        # \"std\",\n        # \"median\",\n        percentile(2.5),\n        percentile(97.5)\n    ],\n    train_eval_every=3,\n    dev_eval_every=3,\n    log = True\n)\ngc.collect()\ngc.set_threshold(g0, g1, g2)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/03_Architectures/","title":"Architectures","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/03_Architectures/#common","title":"Common","text":"<pre><code>class NeuralNet(nn.Module):\n    def __init__(self, init_data, hidden_layers):\n        # init network architecture\n        pass\n    def forward(self, x):\n        return self.network(self.reshape(x)).squeeze()\n\n    # Helper Functions\n    def predict_logits(self, X):\n        return self.forward(X)\n    def predict_proba(self, X):\n        return torch.softmax(self.predict_logits(X), dim=0)\n    def predict_from_proba(self, proba)\n        return proba.argmax(axis=1)\n    def predict(self, X):\n        return self.predict_from_proba(self.predict_proba(X))\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/03_Architectures/#one-vs-rest-classifier","title":"One-vs-Rest Classifier","text":"<pre><code>class NeuralNet(nn.Module):\n    def __init__(self, init_data, hidden_layers):\n        super().__init__()\n\n        for x, y in DataLoader(init_data):\n            self.input_size = x.shape[-1]\n            self.output_size = y.shape[-1]\n            break\n\n        output_layer = nn.LazyLinear(self.output_size) # output layer\n\n        layers = (\n            # [input_layer] +\n            hidden_layers +\n            [output_layer]\n        )\n\n        self.network = nn.Sequential(\n            *layers\n        )\n\n        # init lazy layers\n        self.forward(x)\n\n    def reshape(self, x):\n        # batch_size, no_of_channels, width, height\n        return x.view(x.shape[0], 1, x.shape[1], x.shape[2])\n\n    def forward(self, x):\n        return self.network(self.reshape(x)).squeeze()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/03_Architectures/#one-vs-rest-with-k-1-classifiers","title":"One vs Rest with \\(k-1\\) Classifiers","text":"<ul> <li>Advantage: Will save compute if lots of neurons in pre-output layer, which are connected to output layer</li> <li>Disadvantage: Looks confusing</li> </ul> <pre><code>class NeuralNet(nn.Module):\n    def __init__(self, init_data, hidden_layers):\n        super().__init__()\n\n        for x, y in DataLoader(init_data):\n            self.input_size = x.shape[-1]\n            self.output_size = y.shape[-1]\n            break\n\n        output_layer = nn.LazyLinear(self.output_size - 1) # output layer\n\n        layers = (\n            # [input_layer] +\n            hidden_layers +\n            [output_layer]\n        )\n\n        self.network = nn.Sequential(\n            *layers\n        )\n\n        # init lazy layers\n        self.forward(x)\n\n    def reshape(self, x):\n        # batch_size, no_of_channels, width, height\n        return x.view(x.shape[0], 1, x.shape[1], x.shape[2])\n\n    def forward(self, x):\n        logits_except_last = self.network(self.reshape(x)).squeeze()\n        logit_last = torch.log(1 - torch.exp(logits_except_last).sum())\n\n        logits = (logits_except_last, logit_last.view(-1))\n        return logits\n</code></pre> <p>Testing logic</p> <pre><code># Given logits for the first two classes\nprobs_except_last = torch.tensor([0.1, 0.2])\nlogits_except_last = probs_except_last.log()\n\n# Compute the logit for the last class\nlogit_last = torch.log(1 - torch.exp(logits_except_last).sum())\n\n# Combine all logits\nlogits = torch.cat((logits_except_last, logit_last.view(-1)))\n\n# Compute softmax probabilities\nprobabilities = torch.softmax(logits, dim=0)\n\n# Verify that probabilities sum to 1\nprint(f\"{probs_except_last = }\")\nprint(f\"{logits_except_last = }\")\nprint()\nprint(f\"{probabilities = }\")\nprint(f\"{logits = }\")\n</code></pre> <pre><code>probs_except_last = tensor([0.1000, 0.2000])\nlogits_except_last = tensor([-2.3026, -1.6094])\n\nprobabilities = tensor([0.1000, 0.2000, 0.7000])\nlogits = tensor([-2.3026, -1.6094, -0.3567])\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/","title":"Advanced","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#uncertainty","title":"Uncertainty","text":"<pre><code>import numpy as np\nimport torch, torchvision\nfrom torch.autograd import Variable, grad\nimport torch.distributions as td\nimport math\nfrom torch.optim import Adam\nimport scipy.stats\n\n\nx_data = torch.randn(100)+0.0 ## observed data (here sampled under H0)\n\nN = x_data.shape[0] ## number of observations\n\nmu_null = torch.zeros(1)\nsigma_null_hat = Variable(torch.ones(1), requires_grad=True)\n\ndef log_lik(mu, sigma):\n  return td.Normal(loc=mu, scale=sigma).log_prob(x_data).sum()\n\n## Find theta_null_hat by some gradient descent algorithm (in this case an closed-form expression would be trivial to obtain (see below)):\nopt = Adam([sigma_null_hat], lr=0.01)\nfor epoch in range(2000):\n    opt.zero_grad() ## reset gradient accumulator or optimizer\n    loss = - log_lik(mu_null, sigma_null_hat) ## compute log likelihood with current value of sigma_null_hat  (= Forward pass)\n    loss.backward() ## compute gradients (= Backward pass)\n    opt.step()      ## update sigma_null_hat\n\nprint(f'parameter fitted under null: sigma: {sigma_null_hat}, expected: {torch.sqrt((x_data**2).mean())}')\n#&gt; parameter fitted under null: sigma: tensor([0.9260], requires_grad=True), expected: 0.9259940385818481\n\ntheta_null_hat = (mu_null, sigma_null_hat)\n\nU = torch.tensor(torch.autograd.functional.jacobian(log_lik, theta_null_hat)) ## Jacobian (= vector of partial derivatives of log likelihood w.r.t. the parameters (of the full/alternative model)) = score\nI = -torch.tensor(torch.autograd.functional.hessian(log_lik, theta_null_hat)) / N ## estimate of the Fisher information matrix\nS = torch.t(U) @ torch.inverse(I) @ U / N ## test statistic, often named \"LM\" (as in Lagrange multiplier), would be zero at the maximum likelihood estimate\n\npval_score_test = 1 - scipy.stats.chi2(df = 1).cdf(S) ## S asymptocially follows a chi^2 distribution with degrees of freedom equal to the number of parameters fixed under H0\nprint(f'p-value Chi^2-based score test: {pval_score_test}')\n#&gt; p-value Chi^2-based score test: 0.9203232752568568\n\n## comparison with Student's t-test:\npval_t_test = scipy.stats.ttest_1samp(x_data, popmean = 0).pvalue\nprint(f'p-value Student\\'s t-test: {pval_t_test}')\n#&gt; p-value Student's t-test: 0.9209265268946605\n</code></pre> <pre><code>## another example\n\nenv_loss = loss_fn(env_outputs, env_targets)\ntotal_loss += env_loss\nenv_grads = torch.autograd.grad(env_loss, params, retain_graph=True, create_graph=True)\n\nprint(env_grads[0])\nhess_params = torch.zeros_like(env_grads[0])\nfor i in range(env_grads[0].size(0)):\n    for j in range(env_grads[0].size(1)):\n        hess_params[i, j] = torch.autograd.grad(env_grads[0][i][j], params, retain_graph=True)[0][i, j] ##  &lt;--- error here\nprint(hess_params)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#early-stopping","title":"Early-Stopping","text":"<p>Class</p> <pre><code>  import copy\n\n\n  class EarlyStopping:\n      def __init__(self, patience=5, min_delta=0, restore_best_weights=True):\n          self.patience = patience\n          self.min_delta = min_delta\n          self.restore_best_weights = restore_best_weights\n          self.best_model = None\n          self.best_loss = None\n          self.counter = 0\n          self.status = \"\"\n\n      def __call__(self, model, val_loss):\n          if self.best_loss is None:\n              self.best_loss = val_loss\n              self.best_model = copy.deepcopy(model.state_dict())\n          elif self.best_loss - val_loss &gt;= self.min_delta:\n              self.best_model = copy.deepcopy(model.state_dict())\n              self.best_loss = val_loss\n              self.counter = 0\n              self.status = f\"Improvement found, counter reset to {self.counter}\"\n          else:\n              self.counter += 1\n              self.status = f\"No improvement in the last {self.counter} epochs\"\n              if self.counter &gt;= self.patience:\n                  self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n                  if self.restore_best_weights:\n                      model.load_state_dict(self.best_model)\n                  return True\n          return False\n</code></pre> <p>Classification</p> <pre><code>  import time\n\n  import numpy as np\n  import pandas as pd\n  import torch\n  import tqdm\n  from sklearn.metrics import accuracy_score\n  from sklearn.model_selection import train_test_split\n  from sklearn.preprocessing import LabelEncoder, StandardScaler\n  from torch import nn\n  from torch.autograd import Variable\n  from torch.utils.data import DataLoader, TensorDataset\n\n  ## Set random seed for reproducibility\n  np.random.seed(42)\n  torch.manual_seed(42)\n\n  def load_data():\n      df = pd.read_csv(\n          \"https://data.heatonresearch.com/data/t81-558/iris.csv\", na_values=[\"NA\", \"?\"]\n      )\n\n      le = LabelEncoder()\n\n      x = df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n      y = le.fit_transform(df[\"species\"])\n      species = le.classes_\n\n      ## Split into validation and training sets\n      x_train, x_test, y_train, y_test = train_test_split(\n          x, y, test_size=0.25, random_state=42\n      )\n\n      scaler = StandardScaler()\n      x_train = scaler.fit_transform(x_train)\n      x_test = scaler.transform(x_test)\n\n      ## Numpy to Torch Tensor\n      x_train = torch.tensor(x_train, device=device, dtype=torch.float32)\n      y_train = torch.tensor(y_train, device=device, dtype=torch.long)\n\n      x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n      y_test = torch.tensor(y_test, device=device, dtype=torch.long)\n\n      return x_train, x_test, y_train, y_test, species\n\n\n  x_train, x_test, y_train, y_test, species = load_data()\n\n  ## Create datasets\n  BATCH_SIZE = 16\n\n  dataset_train = TensorDataset(x_train, y_train)\n  dataloader_train = DataLoader(\n      dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n\n  dataset_test = TensorDataset(x_test, y_test)\n  dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n\n  ## Create model using nn.Sequential\n  model = nn.Sequential(\n      nn.Linear(x_train.shape[1], 50),\n      nn.ReLU(),\n      nn.Linear(50, 25),\n      nn.ReLU(),\n      nn.Linear(25, len(species)),\n      nn.LogSoftmax(dim=1),\n  )\n\n  model = torch.compile(model,backend=\"aot_eager\").to(device)\n\n  loss_fn = nn.CrossEntropyLoss()  ## cross entropy loss\n\n  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n  es = EarlyStopping()\n\n  epoch = 0\n  done = False\n  while epoch &lt; 1000 and not done:\n      epoch += 1\n      steps = list(enumerate(dataloader_train))\n      pbar = tqdm.tqdm(steps)\n      model.train()\n      for i, (x_batch, y_batch) in pbar:\n          y_batch_pred = model(x_batch.to(device))\n          loss = loss_fn(y_batch_pred, y_batch.to(device))\n          optimizer.zero_grad(set_to_none=True)\n          loss.backward()\n          optimizer.step()\n\n          loss, current = loss.detatch(), (i + 1) * len(x_batch)\n          if i == len(steps) - 1:\n              model.eval()\n              with torch.inference_mode(): # turn off history tracking\n                  pred = model(x_test)\n                  vloss = loss_fn(pred, y_test)\n              if es(model, vloss):\n                  done = True\n              pbar.set_description(\n                  f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:&gt;7f}, {es.status}\"\n              )\n          else:\n              pbar.set_description(f\"Epoch: {epoch}, tloss {loss:}\")\n</code></pre> <p>Regression</p> <pre><code>  import time\n\n  import numpy as np\n  import pandas as pd\n  import torch.nn as nn\n  import torch.nn.functional as F\n  import tqdm\n  from sklearn import preprocessing\n  from sklearn.metrics import accuracy_score\n  from sklearn.model_selection import train_test_split\n  from torch.autograd import Variable\n  from torch.utils.data import DataLoader, TensorDataset\n\n  ## Read the MPG dataset.\n  df = pd.read_csv(\n      \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", na_values=[\"NA\", \"?\"]\n  )\n\n  cars = df[\"name\"]\n\n  ## Handle missing value\n  df[\"horsepower\"] = df[\"horsepower\"].fillna(df[\"horsepower\"].median())\n\n  ## Pandas to Numpy\n  x = df[\n      [\n          \"cylinders\",\n          \"displacement\",\n          \"horsepower\",\n          \"weight\",\n          \"acceleration\",\n          \"year\",\n          \"origin\",\n      ]\n  ].values\n  y = df[\"mpg\"].values  ## regression\n\n  ## Split into validation and training sets\n  x_train, x_test, y_train, y_test = train_test_split(\n      x, y, test_size=0.25, random_state=42\n  )\n\n  ## Numpy to Torch Tensor\n  x_train = torch.tensor(x_train, device=device, dtype=torch.float32)\n  y_train = torch.tensor(y_train, device=device, dtype=torch.float32)\n\n  x_test = torch.tensor(x_test, device=device, dtype=torch.float32)\n  y_test = torch.tensor(y_test, device=device, dtype=torch.float32)\n\n\n  ## Create datasets\n  BATCH_SIZE = 16\n\n  dataset_train = TensorDataset(x_train, y_train)\n  dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n\n  dataset_test = TensorDataset(x_test, y_test)\n  dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n\n\n  ## Create model\n\n  model = nn.Sequential(\n      nn.Linear(x_train.shape[1], 50), \n      nn.ReLU(), \n      nn.Linear(50, 25), \n      nn.ReLU(), \n      nn.Linear(25, 1)\n  )\n\n  model = torch.compile(model, backend=\"aot_eager\").to(device)\n\n  ## Define the loss function for regression\n  loss_fn = nn.MSELoss()\n\n  ## Define the optimizer\n  optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n\n  es = EarlyStopping()\n\n  epoch = 0\n  done = False\n  while epoch &lt; 1000 and not done:\n      epoch += 1\n      steps = list(enumerate(dataloader_train))\n      pbar = tqdm.tqdm(steps)\n      model.train()\n      for i, (x_batch, y_batch) in pbar:\n          y_batch_pred = model(x_batch).flatten()  #\n          loss = loss_fn(y_batch_pred, y_batch)\n          optimizer.zero_grad(set_to_none=True)\n          loss.backward()\n          optimizer.step()\n\n          loss, current = loss.detatch(), (i + 1) * len(x_batch)\n          if i == len(steps) - 1:\n              model.eval()\n\n              with torch.inference_mode(): # turn off history tracking\n                  pred = model(x_test).flatten()\n                  vloss = loss_fn(pred, y_test)\n              if es(model, vloss):\n                  done = True\n              pbar.set_description(\n                  f\"Epoch: {epoch}, tloss: {loss}, vloss: {vloss:&gt;7f}, EStop:[{es.status}]\"\n              )\n          else:\n              pbar.set_description(f\"Epoch: {epoch}, tloss {loss:}\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#dropout","title":"Dropout","text":"<pre><code>## p = p_drop; NOT p_keep like Tensorflow\nmodel = nn.Sequential(\n  nn.Dropout(p=0.2),\n  ## ...,\n  nn.Dropout(p=0.2),\n  ## ...,\n)\n\n## make sure to specify model.train() and model.eval(), as dropout processing is only required for \"building\" the network. no need to processing for evaluation\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#quantization","title":"Quantization","text":"<pre><code>## direct precision reduction\nmodel = model.half() ## changes everything from float32 to float16\n\n## dynamic precision reduction\nmodel = torch.quantization.quantize_dynamic(\n  model,\n  {torch.nn.Linear},\n  dtype=torch.qint8\n)\n\n## static precision reduction\n## very complicated ngl\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#constrained-optimization","title":"Constrained Optimization","text":"<p>Warning: this clamping is not communicated to the optimizer, and in particular destroys the gradients. So the optimizer falsely believes that it has moved the parameter in a certain direction, when in fact it is clamped to the same value as before.</p> <pre><code>opt = optim.SGD(model.parameters(), lr=0.1)\nfor i in range(1000):\n    out = model(inputs)\n    loss = loss_fn(out, labels)\n    print(i, loss.detatch())\n    opt.zero_grad()\n    loss.backward()\n    opt.step()\n\n    # enforce the constraint that the weights fall in the range (-1, 1)\n    with torch.no_grad():\n        for param in model.parameters():\n            param.clamp_(-1, 1)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#ensembling","title":"Ensembling","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#approach-1","title":"Approach 1","text":"<pre><code>class MyEnsemble(nn.Module):\n    def __init__(self, modelA, modelB, nb_classes=10):\n        super(MyEnsemble, self).__init__()\n        self.modelA = modelA\n        self.modelB = modelB\n        # Remove last linear layer\n        self.modelA.fc = nn.Identity()\n        self.modelB.fc = nn.Identity()\n\n        # Create new classifier\n        self.classifier = nn.Linear(2048+512, nb_classes)\n\n    def forward(self, x):\n        x1 = self.modelA(x.clone())  # clone to make sure x is not changed by inplace methods\n        x1 = x1.view(x1.size(0), -1)\n        x2 = self.modelB(x)\n        x2 = x2.view(x2.size(0), -1)\n        x = torch.cat((x1, x2), dim=1)\n\n        x = self.classifier(F.relu(x))\n        return x\n\n# Train your separate models\n# ...\n# We use pretrained torchvision models here\nmodelA = models.resnet50(pretrained=True)\nmodelB = models.resnet18(pretrained=True)\n\n# Freeze these models\nfor param in modelA.parameters():\n    param.requires_grad_(False)\n\nfor param in modelB.parameters():\n    param.requires_grad_(False)\n\n# Create ensemble model\nmodel = MyEnsemble(modelA, modelB)\nx = torch.randn(1, 3, 224, 224)\noutput = model(x)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#approach-2","title":"Approach 2","text":"<p>When you create an ensemble in PyTorch, it's better to use the <code>nn.ModuleList()</code> class from PyTorch. The <code>nn.ModuleList()</code> has the same functions as a normal Python list like <code>append()</code>. When you create an Ensemble Model like this, you can directly call the <code>backward</code> operations and the gradient descent will occur through the model.</p> <p>Below is an ensemble Neural Network (<code>EnsembleNet</code>) that uses the <code>NeuralNet</code> as individual NN instances for the ensemble.</p> <p>To use bagging, simply create an X_input_list where the different elements of the list are Tensors that have been sampled with replacement from your training data. (Your X_input_list and the num_ensemble must be of the same size)</p> <p>You can modify the <code>EnsembleNet</code> initialization code to take a list of different neural networks as well.</p> <pre><code>class NeuralNet(nn.Module):\n  def __init__(self):\n    super(NeuralNet, self).__init__()\n    self.fc1 = nn.Linear(in_dim, out_dim)\n    self.fc2 = nn.Linear(out_dim, 1)\n\n\n  def forward(self, X):\n    \"\"\" X must be of shape [-1, in_dim]\"\"\"\n    X = self.fc1(X)\n    return torch.sigmoid(self.fc2(X))\n\n\nclass EnsembleNet(nn.Module):\n  def __init__(self, net = NeuralNet, num_ensemble=5, seed_val=SEED):\n      super(EnsembleNet, self).__init__()\n      self.ensembles = nn.ModuleList()\n\n      for i in range(num_ensemble):\n          torch.manual_seed(seed_val*i+1)\n          if torch.cuda.is_available(): # To randomize init of NNs for Ensembles\n              torch.cuda.manual_seed(seed_val*i+1)\n          self.ensembles.append(net)\n\n      self.final = nn.Linear(num_ensemble, 1)\n\n  def forward(self, X_in_list):\n      pred = torch.cat([net(X_in_list[i]) for i,net in enumerate(self.ensembles)])\n      pred = pred.reshape(-1, len(self.ensembles))\n      return torch.sigmoid(self.final(pred))\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#sklearn-integration","title":"Sklearn Integration","text":"<pre><code>from skorch import *\n\nmodel = NeuralNetRegressor(\n  Network,\n  max_epochs=100,\n  lr=0.001,\n  verbose=1\n)\n\nmodel = NeuralNetClassifier(\n  Network,\n  max_epochs=10,\n  lr=0.1,\n  # Shuffle training data on each epoch\n  iterator_train__shuffle=True,\n)\n</code></pre> <pre><code>model.fit(X, y)\npred = model.predict(X)\npred_proba = model.predict_proba(X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<pre><code>from sklearn.model_selection import GridSearchCV\n\nparams = {\n    'lr': [0.001,0.005, 0.01, 0.05, 0.1, 0.2, 0.3],\n    'max_epochs': list(range(500,5500, 500))\n}\n\ngs = GridSearchCV(model, params, refit=False, scoring='r2', verbose=1, cv=10)\n\ngs.fit(X_trf, y_trf)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#batch-normalization","title":"Batch Normalization","text":"<p>Flawed</p> <ul> <li>Training: No bessel correction for variance</li> <li>Inference: bessel correction for variance</li> </ul>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#gradient-regularization","title":"Gradient Regularization","text":"<pre><code>grads = torch.autograd.grad(\n    loss,\n    model.parameters(),\n    retain_graph=True,\n    create_graph=True\n)\ngrads_norm_penalty = (\n    torch.concat(\n        [g.view(-1) for g in grads]\n    )\n    .norm(p=2)\n)\n\nlam = alpha = 1e-4\ncost = loss + (lam * regularization) + (alpha * grads_norm_penalty)\ncost.backward()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#smooth-f1-loss","title":"Smooth F1 Loss","text":"<pre><code>import torch\n\nclass F1Loss:\n    def __init__(self, padding = 1e-7):\n        self.padding = padding\n\n    def __call__(self, y_true, y_pred):\n        tp = torch.sum((y_true * y_pred).float(), dim=0)\n        tn = torch.sum(((1 - y_true) * (1 - y_pred)).float(), dim=0)\n        fp = torch.sum(((1 - y_true) * y_pred).float(), dim=0)\n        fn = torch.sum((y_true * (1 - y_pred)).float(), dim=0)\n\n        p = tp / (tp + fp + self.padding)\n        r = tp / (tp + fn + self.padding)\n\n        s = tn / (tn + fp + self.padding)\n        n = tn / (tn + fn + self.padding)\n\n        #f1 = 2 * (p * r) / (p + r + 1e-7)\n        #f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)\n        custom_f1 = 4 * (p * r * s * n) / (p + r + s + n + self.padding)\n        f1 = torch.where(torch.isnan(f1), torch.zeros_like(f1), f1)\n\n        return 1 - torch.mean(f1)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#logcosh","title":"LogCosh","text":"<pre><code>class LogCoshLoss(torch.nn.Module):\n    def _log_cosh(x: torch.Tensor) -&gt; torch.Tensor:\n        return x + torch.nn.functional.softplus(-2. * x) - math.log(2.0) # math.log will be faster for a single number\n    def log_cosh_loss(y_pred: torch.Tensor, y_true: torch.Tensor) -&gt; torch.Tensor:\n        return torch.mean(_log_cosh(y_pred - y_true))\n\n    def forward(\n        self, y_pred: torch.Tensor, y_true: torch.Tensor\n    ) -&gt; torch.Tensor:\n        return self.log_cosh_loss(y_pred, y_true)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#tobit-regression","title":"Tobit Regression","text":"<pre><code>def loglike(y, sigma, y_, up_ind, down_ind):\n    \"\"\"Calculate logarithm of likelihood for censored tobit model.\n    Args:\n        Model parameters:\n            y: model output\n            sigma: variance of random error (estimated during learning)\n        True data:\n            y_: observed data\n            up_ind: boolean indication of right censoring\n            down_ind: boolean indication of left censoring\n    Returns:\n        Logharithm of likelihood\n    \"\"\"\n\n    normaldist = torch.distributions.Normal(\n        zero_tensor, sigma)\n\n    # model outputs normal distribution with center at y and std at sigma\n\n    # probability function of normal distribution at point y_\n    not_censored_log = normaldist.log_prob(y_ - y)\n    # probability of point random variable being more than y_\n    up_censored_log_argument = (1 - normaldist.cdf(y_ - y))\n    # probability of random variable being less than y_\n    down_censored_log_argument = normaldist.cdf(y_ - y)\n\n    up_censored_log_argument = torch.clip(\n        up_censored_log_argument, 0.00001, 0.99999)\n    down_censored_log_argument = torch.clip(\n        down_censored_log_argument, 0.00001, 0.99999)\n\n    # logarithm of likelihood\n    loglike = not_censored_log * (1 - up_ind) * (1 - down_ind)\n    loglike += torch.log(up_censored_log_argument) * up_ind\n    loglike += torch.log(down_censored_log_argument) * down_ind\n\n    loglike2 = torch.sum(loglike)\n    # we want to maximize likelihood, but optimizer minimizes by default\n    loss = -loglike2\n    return loss\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/04_Advanced/#getting-the-mode-of-log-normal-distribution","title":"Getting the Mode of Log-Normal Distribution","text":"<pre><code>import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define a simple neural network to predict the parameters (mu and sigma) of the Log-Normal distribution\nclass LogNormalModeModel(nn.Module):\n    def __init__(self):\n        super(LogNormalModeModel, self).__init__()\n        self.fc_mu = nn.Linear(1, 1)  # Predict mu\n        self.fc_sigma = nn.Linear(1, 1)  # Predict sigma\n\n    def forward(self, x):\n        mu = self.fc_mu(x)\n        sigma = torch.exp(self.fc_sigma(x))  # Ensure sigma is positive\n        return mu, sigma\n\n\n# Define the loss function as Negative Log-Likelihood for a Log-Normal distribution\ndef negative_log_likelihood_lognormal(y_true, mu, sigma):\n    # Log-Normal log-likelihood: \n    # log(p(y)) = -0.5 * log(2 * pi) - log(sigma) - ((log(y) - mu) ** 2) / (2 * sigma^2)\n    log_y = torch.log(y_true)\n    nll = torch.mean(0.5 * torch.log(2 * torch.pi) + torch.log(sigma) + ((log_y - mu) ** 2) / (2 * sigma**2))\n    return nll\n\noptimizer = optim.AdamW(model.parameters(), lr=1e-9) # Define optimizer\nmodel = LogNormalModeModel() # Instantiate the model\n\n# Training loop\nnum_epochs = 500\nfor epoch in range(num_epochs):\n    model.train()\n\n    # Forward pass: predict mu and sigma\n    mu, sigma = model(x)\n\n    # Compute the negative log-likelihood\n    loss = negative_log_likelihood_lognormal(y_true, mu, sigma)\n\n    # Backward pass and optimization\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 50 == 0:\n        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# After training, the model will predict mu and sigma\nmodel.eval()\nwith torch.no_grad():\n    mu_pred, sigma_pred = model(x)\n    # Calculate the mode for each predicted (mu, sigma) pair\n    mode_pred = torch.exp(mu_pred - sigma_pred**2)\n    ```\n\n## Differentiable MAD\n\n```python\nimport torch\n\ndef soft_median(x, alpha=1.0):\n    \"\"\"\n    Compute the differentiable soft median (approximation of median).\n\n    Parameters:\n        x (Tensor): Input tensor of shape (N,) or (batch_size, N).\n        alpha (float): Controls the \"softness\" of the median, higher alpha makes it closer to the true median.\n\n    Returns:\n        Tensor: Soft median of the input tensor.\n    \"\"\"\n    sorted_x, _ = torch.sort(x, dim=-1)\n    n = x.size(-1)\n\n    # SoftMedian is the weighted average based on the sorted tensor\n    indices = torch.arange(n, dtype=torch.float32, device=x.device).unsqueeze(0)  # (1, N)\n    weights = torch.exp(-alpha * torch.abs(indices - (n - 1) / 2.0))  # weight decays based on distance from center\n    weights = weights / weights.sum(-1, keepdim=True)  # Normalize weights\n\n    soft_median = torch.sum(sorted_x * weights, dim=-1)\n    return soft_median\n\ndef soft_mad(x, alpha=1.0):\n    \"\"\"\n    Compute the SoftMedian Absolute Deviation (SoftMAD) using SoftMedian.\n\n    Parameters:\n        x (Tensor): Input tensor of shape (N,) or (batch_size, N).\n        alpha (float): Softness factor for the soft median.\n\n    Returns:\n        Tensor: SoftMedian Absolute Deviation of the input tensor.\n    \"\"\"\n    median = soft_median(x, alpha)\n    deviation = torch.abs(x - median)\n    mad = soft_median(deviation, alpha)\n    return mad\n\n# Example usage:\nx = torch.randn(10)  # Random tensor of shape (10,)\nsoft_mad_value = soft_mad(x, alpha=1.0)\nprint(\"Soft Median Absolute Deviation:\", soft_mad_value)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/","title":"Performance Optimization","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#pre-load-into-ram","title":"Pre-Load into RAM","text":"<pre><code>class Sentinel2Dataset(Dataset):\n    def __init__(self, file_paths, labels, transform=None):\n        self.file_paths = file_paths\n        self.images = []\n        for file_path in tqdm(self.file_paths):\n            image = load_and_convert_tiff(file_path)\n            self.images.append(image)\n\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.file_paths[idx]\n        image = self.images[idx]\n        if self.transform is not None:\n            image = self.transform(image)\n        label = self.labels[idx]\n        return image, label\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#compile","title":"Compile","text":"Type Control FlowSupported? <code>torch.jit.trace</code> Static \u274c <code>torch.jit.script</code> Static \u2705 <code>torch.compile</code> Dynamic \u2705"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#model","title":"Model","text":"<pre><code>model = NeuralNet()\noptimized_model = torch.compile(\n    model,\n    mode = \"reduce-overhead\", # \"default\", \"reduce-overhead\", \"max-autotune\"\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#optimizer","title":"Optimizer","text":"<pre><code>if torch.cuda.get_device_capability() &lt; (7, 0):\n    print(\"torch.compile is not supported on this device.\")\n\n@torch.compile(fullgraph=False)\ndef step(opt):\n    opt.step()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#fuse-layers","title":"Fuse Layers","text":"<pre><code>model = torch.quantization.fuse_modules(\n    model,\n    [['conv', 'bn', 'relu']],\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#fuse-operators","title":"Fuse Operators","text":"<pre><code>@torch.jit.trace # or torch.jit.script or torch.compile\ndef gelu(x):\n    return (\n        x * 0.5 *\n        (1.0 + torch.erf(x / 1.41421))\n    )\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#mobile","title":"Mobile","text":"<pre><code>from torch.utils.mobile_optimizer import optimize_for_mobile\n\ntorchscript_model = torch.jit.script(model)\n\ntorchscript_model_optimized = optimize_for_mobile(torchscript_model)\ntorchscript_model_optimized.save(\"model.pt\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk","title":"IDK","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#gpu","title":"GPU","text":"<pre><code>if torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\nelse:\n    device = torch.device(\"cpu\")\n\nprint(f\"Using {device}\")\n</code></pre> <pre><code># tensors\ninput = input.to(device).half()\noutput = output.to(device).half()\n\n# model\nmodel = NeuralNet().to(device)\nmodel.half()\n\n# Optimizer\noptimizer = SGD(model.parameters(), lr=learning_rate)\nfor state in optimizer.state.values():\n  for k, v in state.items():\n    if isinstance(v, torch.Tensor):\n      state[k] = v.to(device).half()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk_1","title":"IDK","text":"<pre><code>torch.set_num_threads(int) # number of threads used for intraop parallelism\ntorch.set_num_interop_threads(int) # interop parallelism (e.g. in the JIT interpreter) on the CPU\n</code></pre> <p>If you have 4 cores and need to do, say, 8 matrix multiplications (with separate data) you could use 4 cores to do each matrix multiplication (intra-op-parallelism). Or you could use a single core for each op and run 4 of them in parallel (inter-op-parallelism). In training, you also might want to have some cores for the dataloader, for inference, the JIT can parallelize things (I think). The configuration is documented here, but without much explanation: https://pytorch.org/docs/stable/torch.html#parallelism 1.4k</p>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk_2","title":"IDK","text":"<pre><code>import torch.distributed as dist\ndist.init_process_group(backend=\"gloo\")\n</code></pre> <pre><code>local_rank = int(os.environ[\"LOCAL_RANK\"])\nmodel = torch.nn.parallel.DistributedDataParallel(\n    model,\n    device_ids=[local_rank],\n    output_device=local_rank,\n)\n</code></pre> <pre><code>train_sampler = DistributedSampler(train_data)\ntrain_loader = DataLoader(\n    ...\n    train_data,\n    shuffle=False, # train_sampler will shuffle for you.\n    sampler=train_sampler,\n)\nfor e in range(1, epochs + 1):\n    train_sampler.set_epoch(e) # This makes sure that every epoch the data is distributed to processes differently.\n    train(train_loader)\n</code></pre> <pre><code># to see which process throws what error\nfrom torch.distributed.elastic.multiprocessing.errors import record\n\n@record\ndef main():\n    # do train\n    pass\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#quantization","title":"Quantization","text":""},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#precision","title":"Precision","text":"<pre><code>torch.set_float32_matmul_precision(\"high\") # \"highest\", \"high\", \"medium\"\n</code></pre> <pre><code>model.half()\ntensor = tensor.half()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#amp","title":"AMP","text":"<p>Automatic Mixed Precision</p> <pre><code>dtype = torch.bfloat16\n\nscaler = (\n    torch.GradScaler()\n    if (dtype == torch.float16) # Only necessary for FP16\n    else None\n)\n\n# Train Network\nfor epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # Get data to cuda if possible\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n\n        # forward\n        with torch.autocast(device_type = device, dtype=torch.bfloat16):\n            scores = model(data)\n            loss = criterion(scores, targets)\n\n        # backward\n        optimizer.zero_grad(set_to_none=True)\n\n        if scaler is None:\n            loss.backward()\n            optimizer.step()\n        else:\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk_3","title":"IDK","text":"<pre><code>model.qconfig = torch.quantization.get_default_qconfig('qnnpack')\ntorch.quantization.prepare(model, inplace=True)\n# Calibrate your model\ndef calibrate(model, calibration_data):\n    # Your calibration code here\n    return model\nmodel = calibrate(model, [])\ntorch.quantization.convert(model, inplace=True)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk_4","title":"IDK","text":"<pre><code>class VerySimpleNet(nn.Module):\n    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n        super(VerySimpleNet,self).__init__()\n        self.quant = torch.quantization.QuantStub()\n        self.linear1 = nn.Linear(28*28, hidden_size_1) \n        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2) \n        self.linear3 = nn.Linear(hidden_size_2, 10)\n        self.relu = nn.ReLU()\n        self.dequant = torch.quantization.DeQuantStub()\n\n    def forward(self, img):\n        x = img.view(-1, 28*28)\n        x = self.quant(x)\n        x = self.relu(self.linear1(x))\n        x = self.relu(self.linear2(x))\n        x = self.linear3(x)\n        x = self.dequant(x)\n        return x\n</code></pre> <pre><code>net = VerySimpleNet().to(device)\nnet.qconfig = torch.ao.quantization.default_qconfig\nnet.train()\n\n# Insert observers\nnet_quantized = torch.ao.quantization.prepare_qat(net)\n</code></pre> <pre><code>def print_size_of_model(model):\n    torch.save(model.state_dict(), \"temp_delme.p\")\n    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n    os.remove('temp_delme.p')\n\ntrain_model(model, train_dl, net_quantized, epochs=1)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#quantize-the-model-using-the-statistics-collected","title":"Quantize the model using the statistics collected","text":"<pre><code>net_quantized.eval()\nnet_quantized = torch.ao.quantization.convert(net_quantized)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk_5","title":"IDK","text":"<p>Instead of feeding PyTorch sparse tensor directly into the dataloader, I wrote a custom Dataset class which only accept scipy coo_matrix or equivalent. Then, I wrote a custom collate function for the dataloader which to transform scipy coo_matrix to pytorch sparse tensor during data loading.</p> <p>~ https://discuss.pytorch.org/t/dataloader-loads-data-very-slow-on-sparse-tensor/117391</p> <pre><code>from typing import Union\n\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom scipy.sparse import (random, \n                          coo_matrix,\n                          csr_matrix, \n                          vstack)\nfrom tqdm import tqdm\n</code></pre> <pre><code>class SparseDataset2():\n    \"\"\"\n    Custom Dataset class for scipy sparse matrix\n    \"\"\"\n    def __init__(self, data:Union[np.ndarray, coo_matrix, csr_matrix], \n                 targets:Union[np.ndarray, coo_matrix, csr_matrix], \n                 transform:bool = None):\n\n        # Transform data coo_matrix to csr_matrix for indexing\n        if type(data) == coo_matrix:\n            self.data = data.tocsr()\n        else:\n            self.data = data\n\n        # Transform targets coo_matrix to csr_matrix for indexing\n        if type(targets) == coo_matrix:\n            self.targets = targets.tocsr()\n        else:\n            self.targets = targets\n\n        self.transform = transform # Can be removed\n\n    def __getitem__(self, index):\n        return self.data[index], self.targets[index]\n\n    def __len__(self):\n        return self.data.shape[0]\n\ndef sparse_coo_to_tensor(coo:coo_matrix):\n    \"\"\"\n    Transform scipy coo matrix to pytorch sparse tensor\n    \"\"\"\n    values = coo.data\n    indices = np.vstack((coo.row, coo.col))\n    shape = coo.shape\n\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    i = torch.LongTensor(indices).to(DEVICE)\n    v = torch.FloatTensor(values).to(DEVICE)\n    s = torch.Size(shape)\n\n    return torch.sparse.FloatTensor(i, v, s).to(DEVICE)\n\ndef sparse_batch_collate2(batch): \n    \"\"\"\n    Collate function which to transform scipy coo matrix to pytorch sparse tensor\n    \"\"\"\n    # batch[0] since it is returned as a one element list\n    data_batch, targets_batch = batch[0]\n\n    if type(data_batch[0]) == csr_matrix:\n        data_batch = data_batch.tocoo() # removed vstack\n        data_batch = sparse_coo_to_tensor2(data_batch)\n    else:\n        data_batch = torch.DoubleTensor(data_batch)\n\n    if type(targets_batch[0]) == csr_matrix:\n        targets_batch = targets_batch.tocoo() # removed vstack\n        targets_batch = sparse_coo_to_tensor2(targets_batch)\n    else:\n        targets_batch = torch.DoubleTensor(targets_batch)\n    return data_batch, targets_batch\n</code></pre> <pre><code>X = random(800000, 300, density=0.25)\ny = np.arange(800000)\nds = SparseDataset(X, y)\nsampler = torch.utils.data.sampler.BatchSampler(\n    torch.utils.data.sampler.RandomSampler(ds,\n                      generator=torch.Generator(device='cuda')),\n    batch_size=1024,\n    drop_last=False)\ndl = DataLoader(ds, \n                      batch_size = 1, \n                      collate_fn = sparse_batch_collate2,\n                      generator=torch.Generator(device='cuda'),\n          sampler = sampler)\n\nfor x, y in tqdm(iter(dl)):\n  pass\n\n# 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 782/782 [00:11&lt;00:00, 71.03it/s]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk_6","title":"IDK","text":"<ol> <li> <p>use Numpy Memmap to load array and say goodbye to HDF5.</p> <p>I used to relay on HDF5 to read/write data, especially when loading only sub-part of all data. Yet that was before I realized how fast and charming Numpy Memmapfile is. In short, Memmapfile does not load in the whole array at open, and only later \"lazily\" load in the parts that are required for real operations.</p> <p>Sometimes I may want to copy the full array to memory at once, as it makes later operations faster. Using Memmapfile is still much faster than HDF5. Just do\u00a0<code>array = numpy.array(memmap_file)</code>. It reduces the several minutes with HDF5 to several seconds. Pretty impressive, isn't it!</p> <p>A usefully tool to check out is\u00a0sharearray. It hides for you the verbose details of creating memmap file.</p> <p>If you want to create memmap array that is too large to reside in your memory, use\u00a0<code>numpy.memmap()</code>.</p> </li> <li> <p><code>torch.from_numpy()</code>\u00a0to avoid extra copy.</p> <p>While\u00a0<code>torch.Tensor</code>\u00a0make a copy of the passing-in numpy array.\u00a0<code>torch.from_numpy()</code>\u00a0use the same storage as the numpy array.</p> </li> <li> <p><code>torch.utils.data.DataLoader</code>\u00a0for multithread loading.</p> <p>I think most people are aware of it. With DataLoader, a optional argument\u00a0<code>num_workers</code>\u00a0can be passed in to set how many threads to create for loading data.</p> </li> <li> <p>A simple trick to overlap data-copy time and GPU Time.</p> <p>Copying data to GPU can be relatively slow, you would want to overlap I/O and GPU time to hide the latency. Unfortunatly, PyTorch does not provide a handy tools to do it. Here is a simple snippet to hack around it with\u00a0<code>DataLoader</code>,\u00a0<code>pin_memory</code>\u00a0and\u00a0<code>.cuda(async=True)</code>.</p> </li> </ol> <pre><code>from torch.utils.data import DataLoader\n\n# some code\n\nloader = DataLoader(your_dataset, ..., pin_memory=True)\ndata_iter = iter(loader)\n\nnext_batch = data_iter.next() # start loading the first batch\nnext_batch = [ _.cuda(non_blocking=True) for _ in next_batch ]  # with pin_memory=True and non_blocking=True, this will copy data to GPU non blockingly\n\nfor i in range(len(loader)):\n    batch = next_batch \n    if i + 2 != len(loader): \n        # start copying data of next batch\n        next_batch = data_iter.next()\n        next_batch = [ _.cuda(async=True) for _ in next_batch]\n\n    # training code\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/PyTorch/05_Performance_Optimization/#idk_7","title":"IDK","text":"<p>https://www.thekerneltrip.com/deep-learning/optimize-pytorch-code/</p> <p>https://gist.github.com/ZijiaLewisLu/eabdca955110833c0ce984d34eb7ff39</p> <p>https://www.linkedin.com/pulse/revolutionize-your-pytorch-workflow-how-speed-up-deep-jozsef-szalma</p> <p>https://towardsdatascience.com/better-data-loading-20x-pytorch-speed-up-for-tabular-data-e264b9e34352</p> <p>https://github.com/hcarlens/pytorch-tabular/blob/master/fast_tensor_data_loader.py</p> <p>https://discuss.pytorch.org/t/use-case-for-loading-the-entire-dataset-into-ram/165070/5</p> <p>https://github.com/AhmedThahir/stochastic-caching</p> <p>https://discuss.pytorch.org/t/dataloader-resets-dataset-state/27960/4 (move caching to get item so that dataloader will cache with multiple workers)</p> <p>Do operations as much as possible - in bulk - on gpu</p> <p>Solution:</p> <p>move to GPU asap Perform all operations in bulk</p> <p>Solution - loaf entire dataset into GPU directly (dataset) - load entire batch in GPU directly (dataloader) - load entire dataset into CPU directly (dataset) - load entire batch into CPU (dataloader)</p> <p>Based on folder sizes: os.path.size Based on available ram</p>"},{"location":"Tools/AI%20%26%20Data/Scipy/","title":"Scipy","text":"<p>Check out: https://github.com/OpenSourceEconomics/estimagic</p>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/","title":"01","text":""},{"location":"Tools/AI%20%26%20Data/Scipy/01/#optimization","title":"Optimization","text":"<pre><code>def func(x, m, c):\nreturn m*x + c\n\ndef jacobian(x, m, c):\nreturn ## first derivative\n\ndef hessian(x, m, c):\nreturn ## second derivative\n\nconstraints = (\n## equality constraint\n## fun = 0\ndict(\n  type = 'eq', ## = 0\nfun = lambda x: x.sum() - 1.0,\njac = lambda x: np.ones_like(x) ## optional, but recommended\n),\n## inequality constraint\n## fun &gt;= 0\ndict(\n  type = 'ineq', ## = 0\nfun = lambda x: x.sum() + 1.0,\njac = lambda x: np.ones_like(x) ## optional, but recommended\n),\n)\n\nbounds = (\n(0, None),\n(0, None)\n)\n\nres = minimize(\nfunc=func,\nx0 = [0, 0], ## initial_guess\nmethod = 'SLSQP',\njac = jacobian,\n## hes = hessian,\nbounds = bounds,\nconstraints = constraints\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#interpolation","title":"Interpolation","text":"<pre><code>from scipy.interpolate import interp1d\n\nf = interp1d(\nx,\ny,\nkind=\"linear\" ## \"cubic\"\n)\ninterpolated_values = f(x_dash)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#curve-fitting","title":"Curve Fitting","text":"<pre><code>from scipy.optimize import curve_fit\n\ndef func(x, a, b):\nreturn (a * x**2) + b\n\npopt, pcov = curve_fit(\nfunc,\nx_data,\ny_data,\np0 = (1, 1)\n) \n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#pcov","title":"PCov","text":"<pre><code>pcov = (\n  np.sqrt(self.optimization.fun) * np.sqrt(np.diag(\n    self\n    .optimization\n    .hess_inv\n    .todense()\n  ))\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#custom-curve-fit-with-regularization","title":"Custom Curve Fit with Regularization","text":""},{"location":"Tools/AI%20%26%20Data/Scipy/01/#custom-solvers","title":"Custom Solvers","text":""},{"location":"Tools/AI%20%26%20Data/Scipy/01/#solver","title":"Solver","text":"<pre><code>  import numpy as np\n  from scipy.optimize import OptimizeResult\n</code></pre> <p>The below implementations always return <code>success=True</code></p> <p>Shouldn't we check it is actually successful?</p>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#bgd","title":"BGD","text":"<pre><code>    def bgd(\n        fun,\n        x0,\n        jac,\n        args=(),\n        learning_rate=0.001,\n        mass=0.9,\n        startiter=0,\n        maxiter=1000,\n        callback=None,\n        **kwargs\n    ):\n        \"\"\"``scipy.optimize.minimize`` compatible implementation of batch\n        gradient descent with momentum.\n\n        Adapted from ``autograd/misc/optimizers.py``.\n        \"\"\"\n        x = x0\n        velocity = np.zeros_like(x)\n\n        for i in range(startiter, startiter + maxiter):\n            g = jac(x)\n\n            if callback and callback(x):\n                break\n\n            velocity = mass * velocity - (1.0 - mass) * g\n            x = x + learning_rate * velocity\n\n        i += 1\n        return OptimizeResult(x=x, fun=fun(x), jac=g, nit=i, nfev=i, success=True)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#rmsprop","title":"RMSProp","text":"<pre><code>    def rmsprop(\n        fun,\n        x0,\n        jac,\n        args=(),\n        learning_rate=0.1,\n        gamma=0.9,\n        eps=1e-8,\n        startiter=0,\n        maxiter=1000,\n        callback=None,\n        **kwargs\n    ):\n        \"\"\"``scipy.optimize.minimize`` compatible implementation of root mean\n        squared prop: See Adagrad paper for details.\n\n        Adapted from ``autograd/misc/optimizers.py``.\n        \"\"\"\n        x = x0\n        avg_sq_grad = np.ones_like(x)\n\n        for i in range(startiter, startiter + maxiter):\n            g = jac(x)\n\n            if callback and callback(x):\n                break\n\n            avg_sq_grad = avg_sq_grad * gamma + g**2 * (1 - gamma)\n            x = x - learning_rate * g / (np.sqrt(avg_sq_grad) + eps)\n\n        i += 1\n        return OptimizeResult(x=x, fun=fun(x), jac=g, nit=i, nfev=i, success=True)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#adam","title":"Adam","text":"<pre><code>    def adam(\n        fun,\n        x0,\n        jac,\n        args=(),\n        learning_rate=0.001,\n        beta1=0.9,\n        beta2=0.999,\n        eps=1e-8,\n        startiter=0,\n        maxiter=1000,\n        callback=None,\n        **kwargs\n    ):\n        \"\"\"``scipy.optimize.minimize`` compatible implementation of ADAM -\n        [http://arxiv.org/pdf/1412.6980.pdf].\n\n        Adapted from ``autograd/misc/optimizers.py``.\n        \"\"\"\n        x = x0\n        m = np.zeros_like(x)\n        v = np.zeros_like(x)\n\n        for i in range(startiter, startiter + maxiter):\n            g = jac(x)\n\n            if callback and callback(x):\n                break\n\n            m = (1 - beta1) * g + beta1 * m  ## first  moment estimate.\n            v = (1 - beta2) * (g**2) + beta2 * v  ## second moment estimate.\n            mhat = m / (1 - beta1**(i + 1))  ## bias correction.\n            vhat = v / (1 - beta2**(i + 1))\n            x = x - learning_rate * mhat / (np.sqrt(vhat) + eps)\n\n        i += 1\n        return OptimizeResult(x=x, fun=fun(x), jac=g, nit=i, nfev=i, success=True)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#usage","title":"Usage","text":"<pre><code>  from scipy.optimize import minimize\n\n  res = minimize(..., method = func) ## func = sgd, rmsprop, or adam\n  print(res.x)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#calculus","title":"Calculus","text":""},{"location":"Tools/AI%20%26%20Data/Scipy/01/#differentiation","title":"Differentiation","text":"<p>Analytical</p> <pre><code>  from scipy.misc import derivative as d\n\n  def f(x):\n    return x**2\n\n  d(f, x, dx=1e-6)\n</code></pre> <pre><code>  def pd(func, var=0, point=[]):\n      ## partial derivative\n      args = point[:]\n      def wraps(x):\n          args[var] = x\n          return func(*args)\n      return derivative(wraps, point[var], dx = 1e-6)\n\n  pd(foo, 0, [3,1]) ## 6.0000000008386678\n  pd(foo, 1, [3,1]) ## 2.9999999995311555\n</code></pre> <p>Integration</p> <pre><code>from scipy.integrate import quad\n\ndef func(x):\n  return x**2\n\nintegral, integral_error = quad(func, 0, 1)\n</code></pre> <pre><code>from scipy.integrate import dbquad\n\ndef func(x):\n  return x**2 + y**2\n\nintegral, integral_error = dblquad(func, 0, 1, 0, 1)\n</code></pre> <pre><code>from scipy.integrate import nquad\n</code></pre> <p>Differential Equations</p> <pre><code>from scipy.integrate import odeint\n\ndef dvdt(v, t):\n  return 3 * v**2 - 5\n\nv0 = 0\n\nt = np.linspace(0, 1, 100)\nsol = odeint(dvdt, v0, t)\n</code></pre> <pre><code>## coupled\n\ndef dSdx(S, x):\n  y1, y2 = S\n  return [\n    y1 + y2**2 + 3*x,\n    3*y1 + y2**3 - np.cos(x)\n  ]\n\ny1_0 = 0\ny2_0 = 0\nS_0 = (y1_0, y2_0)\n\nx = np.linspace(0, 1, 100)\nsol = odeint(dSdx, S_0, x)\n\ny1 = sol.T[0]\ny2 = sol.T[1]\n</code></pre> <pre><code>## second-order DE must be transformed into 2 coupled first order DE\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#fourier-transforms","title":"Fourier Transforms","text":""},{"location":"Tools/AI%20%26%20Data/Scipy/01/#numeric","title":"Numeric","text":""},{"location":"Tools/AI%20%26%20Data/Scipy/01/#continuous-time-frequency","title":"Continuous Time &amp; Frequency","text":"<pre><code>from scipy.integrate import quad\n\ndef x(t, k):\n  return np.exp(-k * t**2) * np.sin(k*t) * t**4\n\ndef get_x_ft(x, f, k):\n  x_FT_integrand_real = lambda t: np.real(x(t, k) * np.exp( -2*np.pi*1j*f*t) )\n  x_FT_integrand_complex = lambda t: np.imag(x(t, k) * np.exp( -2*np.pi*1j*f*t) )\n\n  x_FT_real = quad(x_FT_integrand_real, -np.inf, np.inf)[0]\n  x_FT_comp = quad(x_FT_integrand_comp, -np.inf, np.inf)[0]\n\n  return x_FT_real + 1j*x_FT_comp\n</code></pre> <pre><code>f = np.linspace(-4, 4, 100)\nx_FT = np.vectorize(get_x_FT)(x, f, k=2)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#continuous-time-discrete-frequency","title":"Continuous Time &amp; Discrete Frequency","text":"<pre><code>from scipy.integrate import quad\n\ndef x(t, k):\n  return np.exp(-k * t**2) * np.sin(k*t) /t\n\ndef get_x_ft(x, f, k, T):\n  x_FT_integrand_real = lambda t: np.real(x(t, k) * np.exp( -2*np.pi*1j*(n/T)*t) )\n  x_FT_integrand_complex = lambda t: np.imag(x(t, k) * np.exp( -2*np.pi*1j*(n/T)*t) )\n\n  x_FT_real = quad(x_FT_integrand_real, 0, T)[0]\n  x_FT_comp = quad(x_FT_integrand_comp, 0, T)[0]\n\n  return x_FT_real + 1j*x_FT_comp\n</code></pre> <pre><code>ns = np.arange(0, 20, 1)\nx_FT = np.vectorize(get_x_FT)(x, ns, k=2, T=4)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#fft","title":"FFT","text":"<p>Discrete Time &amp; Frequency</p> <pre><code># 1D\nfrom scipy.fft import fft, fftfreq\n\ny = fft(x)\nf = fftfreq(len(x), np.diff(t)[0])\n</code></pre> <pre><code># 2D\nfrom scipy.fft import fft2, fftfreq2\n\nimg_FT =_fft2(img)\nfy = fftfreq(img.shape[0], d=10) # suppose the spacing between pixels is 10mm\nfx = fftfreq(img.shape[1], d=10)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#linear-algebra","title":"Linear Algebra","text":"<p>Not very applicable to me</p>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#stats","title":"Stats","text":"<pre><code>dist.pmf() ## probability mass function\ndist.cdf() ## cumulative dist function\ndist.ppf() ## inverse of cdf\ndist.rvs() ## generate random variable sample\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#proportion","title":"Proportion","text":"<pre><code>p = 0.2 # probability of failure\nn = 1_000\nalpha = 0.95\nsig = (1-alpha)/2\n\n# method 1: Slow but exact\nk = int(p*n) # no of failures proportional to p and n\nlow, high = stats.binomtest(k, n, p).proportion_ci(confidence_level=alpha, method=\"exact\")\n\n# method 2: Fast but approximate\ndist = stats.binom(n, p)\nlow, high = dist.ppf(sig)/n, dist.ppf(1-sig)/n\n</code></pre> <p>beta</p> <pre><code>from scipy.stats import beta\na, b = 2.5, 3.1\n\nmean, var, skew, kurt = beta.stats(a, b, moments=\"mvsk\")\n</code></pre> <p>normal</p> <pre><code>norm.ppf(0.025, mu, sigma)\nnorm.ppf(0.975, mu, sigma)\n</code></pre> <p>skewnorm</p> <pre><code>from scipy.stats import skewnorm\n\n## skewness_factor\na = 5 ## +ve skew\na = -5 ## -ve skew\n\nmean, var, skew, kurt = skewnorm.stats(a, moments='mvsk')\ngenerated_values = skewnorm.rvs(a, size=1000)\n</code></pre> <p>custom</p> <pre><code>import scipy.stats as st\n\nclass my_dist(st.rv_continuous):\n  def _pdf(self, x, a1, a2, b1, b2):\n    return np.sin(x)\n\n  ## def _cdf(self, )\n\n  ## def _rvs(self, )\n\nmy_rv = my_dist(a = 0, b=np.inf)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#jac","title":"Jac","text":"<p>Need not be the final </p>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#finding-mode","title":"Finding Mode","text":"<pre><code>import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Define the parameters for the underlying normal distribution\nmu, sigma = 0, 1  # Mean and standard deviation of the normal distribution\n# Theoretical mode based on the formula for a log-normal distribution\ntheoretical_mode = np.exp(mu - sigma**2)\n\nlognorm_dist = stats.lognorm(sigma, scale=np.exp(mu))\n\nx = np.linspace(mu, mu+sigma, 1_000) # Create an array of x values to evaluate the PDF\ny = lognorm_dist.pdf(x) # Get the PDF values for each x\n\n# Find the mode (maximum of the PDF)\nmode = x[np.argmax(y)]  # The x value corresponding to the maximum PDF\n\nprint(f\"Numerical Mode of the log-normal distribution: {mode}\")\nprint(f\"Theoretical Mode of the log-normal distribution: {theoretical_mode}\")\nprint(f\"Diff: {np.abs(theoretical_mode-mode).round(4)}\")\n\n# Plot\nplt.plot(x, y, label='Log-Normal Distribution')\nplt.axvline(mode, color='red', linestyle='--', label=f'Numerical Mode: {mode}')\nplt.axvline(theoretical_mode, color='green', linestyle='--', label=f'Theoretical Mode: {theoretical_mode}')\nplt.legend()\nplt.show()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/01/#using-pytorch","title":"Using PyTorch","text":"<pre><code>import numpy\nimport scipy, scipy.optimize\nimport torch\n\n\ndef minim(obs, f, p0):\n    \"\"\"Fit function f to observations \"obs\" starting at p0\"\"\"\n\n    def fitfn(pars):\n        # NB the require_grad parameter specifying we want to\n        # differentiate wrt to the parameters\n        pars=torch.tensor(pars,\n                          requires_grad=True)\n        y=f(pars)\n        # Simple least-squares fitting\n        res=((obs-y)**2).sum()\n        res.backward()\n        # Note that gradient is taken from the \"pars\" variable\n        return res.data.cpu().numpy(), pars.grad.data.cpu().numpy()\n\n    res=scipy.optimize.minimize(fitfn,\n                                p0,\n                                method=\"BFGS\",\n                                jac=True) # NB: we will compute the jacobian\n    return res\n\n# Points on which observations are made\nX=torch.arange(100)\n\ndef exfn(p):\n    y=torch.sin(p[0]*X)+torch.cos(p[1]*X)\n    return y\n\n# Sample observations\nyp=exfn(torch.tensor([0.3, 0]) )\n\n# Sample run\nminim(yp, exfn, numpy.array([0.34, 0.01]))\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/02_Regression/","title":"Regression","text":"<pre><code>import scipy.optimize as so\nimport sympy as sp\n</code></pre> <pre><code>def linearModelLossRSS(b, X, y):\n    # Make predictions\n    predY = linearModelPredict(b, X)\n    # Compute residuals\n    res = y - predY\n    # Compute the residual sum of squares\n    residual_sum_of_squares = sum(res**2)\n    # Compute the gradient of the loss\n    gradient = -2 * np.dot(res, X)\n    return (residual_sum_of_squares, gradient)\n</code></pre> <pre><code>def linearModelFit(X, y, lossfcn):\n    nrows, ncols = X.shape\n    betas = np.zeros((ncols, 1))\n    # Optimize the loss\n    RES = so.minimize(\n      lossfcn,\n      betas,\n      args=(X, y),\n      jac=True,\n      # hess = 2 # isn't it just 2\n    )\n    # Obtain estimates from the optimizer\n    estimated_betas = RES.x\n    # Compute goodness of fit\n    res = y - np.mean(y)\n    TSS = sum(res**2)\n    RSS, deriv = linearModelLossRSS(estimated_betas, X, y)  # L2 loss and RSS are the same thing\n    R2 = 1 - RSS / TSS\n    return (estimated_betas, R2)\n</code></pre> <pre><code>X = np.array([[1, 0], [1, -1], [1, 2]])\ny = np.array([0, 0.4, 2]) \n\nbeta, R2 = linearModelFit(X, y, linearModelLossRSS)\n\nprint(\"Betas are\", beta)\nprint(\"R2:\\n\", R2)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/02_Regression/#obtaining-jac-and-hessian","title":"Obtaining Jac and Hessian","text":"<pre><code>## Basic Linear Regression\nx = sp.Symbol('x', constant=True, real=True)\ny = sp.Symbol('y', constant=True, real=True)\nm = sp.Symbol('m', real=True)\nc = sp.Symbol('c', real=True)\n\n\nyhat = m * x + c\nl = (yhat - y)**2\n\n\nvars = [m, b]\n\n\n## First-Order Reaction\n\n\nc0 = sp.Symbol('c_0', constant=True, real=True)\nt = sp.Symbol('t', constant=True, real=True)\nct = sp.Symbol('c_t', constant=True, real=True)\n\n\nk = sp.Symbol('k', real=True)\n\n\nchat = c0 * sp.exp(-k*t)\nl = (chat - ct)**2\n\n\nvars = [k]\n</code></pre> <pre><code>## Printing\n\nprint(\"Function\")\ndisplay(yhat)\n\n\nprint(\"\\nLoss\")\ndisplay(l)\n\n\nprint(\"\\nJac\")\nfor var in vars:\n display(l.diff(var).factor())\n\n\nprint(\"\\nHess\")\nfor var in vars:\n for var_inner in vars:\n   display(l.diff(var).diff(var).factor())\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/02_Regression/#idk","title":"IDK","text":"<pre><code>from scipy.optimize import minimize\nimport numpy as np\n\n# x = np.array([139, ...])\n# y = np.array([151, ...])\n\n# Define the Model\ndef f(x, a, b): return a * x + b\n\n# The objective Function to minimize (least-squares regression)\ndef obj(x, y, a, b): return np.sum((y - f(x, a, b))**2)\n\n# define the bounds -infty &lt; a &lt; infty,  b &lt;= 0\nbounds = [(None, None), (None, 0)]\n\nres = minimize(lambda coeffs: obj(x, y, *coeffs), x0=np.zeros(2), bounds=bounds)\n# res.x contains your coefficients\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Scipy/03_Jax/","title":"Jax","text":"<pre><code># from scipy.optimize import minimize\n\nfrom jax.scipy.optimize import minimize\nimport jax.numpy as np\n</code></pre> <p>Gradients of fun are calculated automatically using JAX\u2019s autodiff support when required.</p>"},{"location":"Tools/AI%20%26%20Data/Scipy/03_Jax/#speed-up-existing-implementation","title":"Speed Up Existing Implementation","text":"<pre><code>import jax.numpy as np\nfrom jax import jit, value_and_grad\n\ndef costFunction(weights):\n   # reshapes flattened weights into 2d matrix\n   weights = np.reshape(weights, newshape=(100, 75))\n\n   # weighted row-wise sum\n   weighted = np.sum(x * weights, axis=1)\n\n   # squared residuals\n   residualsSquared = (y - weighted) ** 2\n\n   return np.sum(residualsSquared)\n\n# create the derivatives\nobj_and_grad = jit(value_and_grad(costFunction))\n\nminimize(obj_and_grad, x0=startingWeights.flatten(), jac=True)\n</code></pre> <p>Or take the diff using <code>jax.diff</code></p> <ul> <li>Provide the jac &amp; hessian to the minimize function</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Scipy/03_Jax/#use-jaxscipy","title":"Use <code>jax.scipy</code>","text":"<pre><code>import \no.minimize(fun, x0, args=(), *, method, tol=None, options=None)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/","title":"Sklearn","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/#references","title":"References","text":"<ul> <li> Python in Data Science for Intermediate - Machine Learning with Sklearn | learndataa</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/","title":"01 IDK","text":"<p>Always set <code>n_jobs</code> and <code>random_state</code> explicitly</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#output-format","title":"Output Format","text":"<pre><code>transformer.set_output(transform=\"polars\") # \"pandas\"\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#basics","title":"Basics","text":"<pre><code>model = model()\n\nif \"n_jobs\" in dir(model):\n    kwargs[\"n_jobs\"]= -1\nif \"probability\" in dir(model):\n    kwargs[\"probability\"]= True\n\nmodel.set_params(**kwargs)\n\nmodel.fit(X_train, y_train)\nmodel.predict(X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#pca","title":"PCA","text":"<pre><code>from sklearn.decomposition import PCA\n\ndf = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))\n\npca = PCA(n_components=5)\npca.fit(df)\n\npca.components_\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#stratified-sampling","title":"Stratified Sampling","text":"<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, \n  test_size = 0.5,\n  random_state = 0,\n  stratify = y\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#save-load-model","title":"Save &amp; Load Model","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#pickle","title":"Pickle","text":"<p>[!WARNING] Pickling is unsafe</p> <pre><code>import pickle\nfile_name = \"model.pkl\"\n\n## save\nwith open(file_name, \"wb\") as f:\n    pickle.dump(model, f)\n\n#load\nwith open(file_name, \"rb\") as f:\n  model = pickle.load(f)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#json","title":"Json","text":"<pre><code>## save\nmodel.save_model(\"model.json\")\n\n## load\nmodel_new = xgb.XGBRegressor()\nmodel_new.load_model(\"model.json\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#pipelines","title":"Pipelines","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#what","title":"What?","text":"<p>Systematic organization of required operations</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#parts","title":"Parts","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#transformer","title":"Transformer","text":"<p>filter and/or modify data <code>fit()</code> and <code>transform()</code></p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#estimator","title":"Estimator","text":"<p>Learn from data <code>fit()</code> and <code>predict()</code></p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#implementation","title":"Implementation","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#libraries","title":"Libraries","text":"<pre><code>from sklearn.pipeline import make_pipeline\n##  just `Pipeline` involves naming each step\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#pipeline-used-here","title":"Pipeline Used Here","text":"<p>Data Preprocessing by using Standard Scaler Reduce Dimension using PCA Apply Classifier</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#initializing-pipelines","title":"Initializing Pipelines","text":"<p><pre><code>pipeline_lr = make_pipeline(\n  StandardScaler(),\n  LogisticRegression()\n)\n\n## more controlled way\npipeline_dt = Pipeline([\n  ('scaler',StandardScaler()),\n  ('classifier',DecisionTreeClassifier())\n])\n</code></pre> <pre><code>pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]\n\n## Dictionary of pipelines and classifier types for ease of reference\npipe_dict = {\n  0: 'Logistic Regression',\n  1: 'Decision Tree'\n}\n\nbest_accuracy = 0.0\nbest_classifier = 0\nbest_pipeline=\"\"\n</code></pre></p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#pipeline-parameters","title":"Pipeline Parameters","text":"<pre><code>pipe.get_params()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#trainingfitting","title":"Training/Fitting","text":"<pre><code>## Fit the pipelines\nfor pipe in pipelines:\n  pipe.fit(X_train, y_train)\n    ## pipe.fit(X_train, y_train, classifier__sample_weight=1)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#results","title":"Results","text":"<p><pre><code>for i,model in enumerate(pipelines):\n    print(\n      pipe_dict[i], \"Test Accuracy:\", model.score(X_test,y_test)\n    )\n</code></pre> <pre><code>for i,model in enumerate(pipelines):\n    if model.score(X_test,y_test)&gt;best_accuracy:\n        best_accuracy=model.score(X_test,y_test)\n        best_classifier=i\n        best_pipeline=model\n\nprint('Classifier with best accuracy:{}'.format(pipe_dict[best_classifier]))\n</code></pre></p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#change-loss_cost-function","title":"Change Loss_Cost Function","text":"<pre><code>def custom_loss(y_true, y_pred):\n    fn_penalty = 5 ## penalty for false negatives\n    fp_penalty = 1 ## penalty for false positives\n\n    ## calculate true positives, false positives, and false negatives\n    tp = ((y_true == 1) &amp; (y_pred == 1)).sum()\n    fp = ((y_true == 0) &amp; (y_pred == 1)).sum()\n    fn = ((y_true == 1) &amp; (y_pred == 0)).sum()\n\n    ## calculate loss\n    loss = fp_penalty * fp + fn_penalty * fn\n\n    return loss\n\nfrom sklearn.linear_model import LogisticRegression\nmodel = LogisticRegression(loss=custom_loss)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#custom-ensembling","title":"Custom Ensembling","text":"<p>Voting Stacking</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#linear-regression-statistical-inference","title":"Linear Regression statistical inference","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#parameter-standard-errors","title":"Parameter standard errors","text":"<pre><code>N = len(X)\np = len(X.columns) + 1  ## plus one because LinearRegression adds an intercept term\n\nX_with_intercept = np.empty(shape=(N, p), dtype=np.float)\nX_with_intercept[:, 0] = 1\nX_with_intercept[:, 1:p] = X.values\n\nbeta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) @ X_with_intercept.T @ y.values\nprint(beta_hat)\n\ny_hat = model.predict(X)\nresiduals = y.values - y_hat\nresidual_sum_of_squares = residuals.T @ residuals\nsigma_squared_hat = residual_sum_of_squares[0, 0] / (N - p)\nvar_beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) * sigma_squared_hat\nfor p_ in range(p):\n    standard_error = var_beta_hat[p_, p_] ** 0.5\n    print(f\"SE(beta_hat[{p_}]): {standard_error}\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#parameter-confidence-intervals","title":"Parameter confidence intervals","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom sklearn.linear_model import LinearRegression\n\n\ndef get_conf_int(X, y, model, alpha=0.05):\n\n    \"\"\"\n    ## alpha = 0.05 for 95% confidence interval; 0.01 for 99%-CI\n\n    Returns (1-alpha) 2-sided confidence intervals\n    for sklearn.LinearRegression coefficients\n    as a pandas DataFrame\n    \"\"\"\n\n    coefs = np.r_[[lr.intercept_], lr.coef_]\n    X_aux = X.copy()\n    X_aux.insert(0, 'const', 1)\n    dof = -np.diff(X_aux.shape)[0]\n    mse = np.sum((y - model.predict(X)) ** 2) / dof\n    var_params = np.diag(np.linalg.inv(X_aux.T.dot(X_aux)))\n    t_val = stats.t.isf(alpha/2, dof)\n    gap = t_val * np.sqrt(mse * var_params)\n\n    return pd.DataFrame({\n        'lower': coefs - gap, 'upper': coefs + gap\n    }, index=X_aux.columns)\n\n\nmodel = LinearRegression().fit(X_train, Y_train)\nget_conf_int(X_train, y_train, model, alpha = 0.05)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#mean-response-confidence-intervals","title":"Mean response confidence intervals","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom scipy import stats\n\nX = np.array([\n  [0, 10],\n  [5, 5],\n  [10, 2]\n])\n\nX_centered = X - X.mean()\n\nx_pred = np.array(\n  [[5, 10]]\n)\nx_pred_centered = x_pred-X.mean()\n\nn = X.shape[0]\nk = X.shape[1]\n\nidk = (\n    #(1/n) +\n    np.diag(\n      x_pred_centered.T\n      .dot(\n          np.linalg.inv(\n              X_centered.T\n              .dot(X_centered)\n          )\n      )\n      .dot(x_pred_centered)\n    )\n)\n\nse_confidence = (\n    X.std()\n    *\n    np.sqrt(\n      idk\n  )\n)\nse_prediction = (\n    X.std()\n    *\n    np.sqrt(\n      1 + idk\n  )\n)\n\nalpha = 0.05\ndof = n - k\nt_val = stats.t.isf(alpha/2, dof)\n\ngap_confidence = t_val * se_confidence\ngap_prediction = t_val * se_prediction\n\nprint(gap_confidence)\n#print(gap_prediction)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#custom-scorer","title":"Custom Scorer","text":"<pre><code>from sklearn.metrics import make_scorer\nfrom sklearn.model_selection import cross_val_score\n\ndef mean_error(y, y_pred):\n    return np.mean(y_pred - y)\ndef std_error(y, y_pred):\n    return np.std(y_pred - y)\n\nmean_error_scorer = make_scorer(mean_error, greater_is_better=False)\nstd_error_scorer = make_scorer(mean_error, greater_is_better=False)\n\nmodel = LinearRegression()\ncross_val_score(model, X, y, scoring=mean_error_scorer)\ncross_val_score(model, X, y, scoring=std_error_scorer)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#scaling","title":"Scaling","text":"<pre><code>## demonstrate data normalization with sklearn\nfrom sklearn.preprocessing import MinMaxScaler\n## load data\ndata = ...\n## create scaler\nscaler = MinMaxScaler()\n## fit and transform in one step\nnormalized = scaler.fit_transform(data)\n## inverse transform\ninverse = scaler.inverse_transform(normalized)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#time-series-split","title":"Time-Series Split","text":"<pre><code>|X||V|O|O|O|\n|O|X||V|O|O|\n|O|O|X||V|O|\n|O|O|O|X||V|\n</code></pre> <p>X / V are the training / validation sets. \"||\" indicates a gap (parameter n_gap: int&gt;0) truncated at the beginning of the validation set, in order to prevent leakage effects.</p> <pre><code>class StratifiedWalkForward(object):\n\n    def __init__(self,n_splits,n_gap):\n        self.n_splits = n_splits\n        self.n_gap = n_gap\n        self._cv = StratifiedKFold(n_splits=self.n_splits+1,shuffle=False)\n        return\n\n    def split(self,X,y,groups=None):\n        splits = self._cv.split(X,y)\n        _ixs = []\n        for ix in splits: \n            _ixs.append(ix[1])\n        for i in range(1,len(_ixs)): \n            yield tuple((_ixs[i-1],_ixs[i][_ixs[i]&gt;_ixs[i-1][-1]+self.n_gap]))\n\n    def get_n_splits(self,X,y,groups=None):\n        return self.n_splits\n</code></pre> <p>Note that the datasets may not be perfectly stratified afterwards, cause of the truncation with n_gap.</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#regression-with-custom-loss-function","title":"Regression with Custom Loss Function","text":"<p>using scipy </p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#decision-boundary","title":"Decision Boundary","text":"<pre><code>x_min, x_max = X[:, 0].min(), X[:,0].max()\ny_min, y_max = X[:, 1].min(), X[:, 1].max()\nresolution = 100\n\nx = np.linspace(x_min - 0.1, x_max + 0.1, resolution)\ny = np.linspace(y_min - 0.1, y_max + 0.1, resolution)\n</code></pre> <pre><code>xx, yy = np.meshgrid(x, y)\n</code></pre> <pre><code>x_in = np.c_[xx.ravel(), yy.ravel()]\ny_pred = model.predict(x_in).reshape(xx.shape)\n</code></pre> <pre><code>plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7 )\nplt.scatter(X[:,0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\nplt.xlim(xx.min(), xx.max())\nplt.ylim(yy.min(), yy.max())\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#svm","title":"SVM","text":"<ul> <li>LinearSVC: Primal</li> <li>SVC: Dual</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#boosted-hybrid-model","title":"Boosted Hybrid Model","text":"<p>Multi-Level Model</p> <pre><code>from sklearn.base import RegressorMixin, TransformerMixin\nfrom sklearn.utils.validation import check_is_fitted, check_array, check_X_y\n\nclass HybridBoostingRegressor(RegressorMixin, TransformerMixin):\n    def __init__(self, kwargs):\n        self.names = []\n        self.models = []\n        self.features_list = []\n        self.targets = []\n\n        for name, model, features, target in kwargs:\n            self.names.append(name)\n            self.models.append(model)\n            self.features_list.append(features)\n\n            if len(target) == 1:\n              self.targets.append(target[0])\n            else:\n              self.targets.append(target)\n\n    def filter_X(self, X, features):\n        if len(features) &gt; 0:\n          X = X[features]\n        return X\n\n    def get_y(self, y, y_intermediate, target):\n        if len(target) == 0:\n          y = y\n        else:\n          y = y_intermediate[target]\n\n        return y\n\n    def fit(self, X, y, y_intermediate = None, **fit_params):\n        if y_intermediate is None or y_intermediate.shape[0] == 0:\n          for target in self.targets:\n            if len(target) &gt; 0:\n              return Exception(f\"y_intermediate not found for {target}\")\n\n        y_res = y.copy()\n        y_intermediate_res = y_intermediate.copy()\n\n        self.fitted_models_ = []\n        for model, features, target in zip(self.models, self.features_list, self.targets):\n\n            X = self.filter_X(X.copy(), features)\n            y = self.get_y(y_res, y_intermediate_res, target)\n\n            # Check that X and y have correct shape\n            X, y = check_X_y(X, y)\n\n            model.fit(X, y, **fit_params)\n\n            self.fitted_models_.append(model)\n\n            if len(target) == 0:\n              pred = model.predict(X)\n            else:\n              pred = model.predict(X)\n\n            # residual\n            if len(target) != 0:\n              y_intermediate_res[target] = self.accumulate(y_intermediate_res[target], pred)\n            y_res = self.get_residual(y_res, pred)\n\n        return self\n\n    def predict(self, X):\n        check_is_fitted(self, \"fitted_models_\")\n\n        pred = self.pred_init\n        for fitted_model, features, target in zip(self.fitted_models_, self.features_list, self.targets):\n            X = self.filter_X(X.copy(), features)\n\n            # Input validation\n            X = check_array(X)\n\n            pred = self.accumulate(pred, fitted_model.predict(X))\n\n        return pred\n\nclass AdditiveHybridBoostingRegressor(HybridBoostingRegressor):\n    \"\"\"\n    y_hat = f_1(x_1) + f_1(x_2) + ...\n    \"\"\"\n    def __init__(self, kwargs):\n      super().__init__(kwargs)\n      self.pred_init = 0\n    def get_residual(self, y, pred):\n      return y-pred\n    def accumulate(self, y, pred):\n      return y+pred\n\nclass MultiplicativeHybridBoostingRegressor(HybridBoostingRegressor):\n    \"\"\"\n    y_hat = f_1(x_1) * f_1(x_2) * ...\n    \"\"\"\n    def __init__(self, kwargs):\n      super().__init__(kwargs)\n      self.pred_init = 1\n    def get_residual(self, y, pred):\n      return y/pred\n    def accumulate(self, y, pred):\n      return y*pred\n</code></pre> <pre><code>x = np.arange(1, 1000, 1)\nX = pd.DataFrame().assign(\n  x1 = x,\n  x2 = x**2\n)\ny_intermediate = pd.DataFrame().assign(\n  trend = 10000*X[\"x1\"] + X[\"x2\"],\n  seasonality = np.sin(X[\"x1\"]) + np.sin(X[\"x1\"])\n)\n\ny = y_intermediate[\"trend\"] + y_intermediate[\"seasonality\"]\n</code></pre> <pre><code>from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\n\nmodel = AdditiveHybridBoostingRegressor(\n    [\n        ('lr', LinearRegression(), [], [\"trend\"]),\n        ('rf', RandomForestRegressor(n_estimators=10, random_state=42, n_jobs=-1), [], [\"seasonality\"])\n    ]\n)\nmodel.fit(X, y, y_intermediate)\nmodel.predict(X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#bootstrap","title":"Bootstrap","text":"<pre><code>from sklearn.utils import resample\nX_test_bootstrap, y_test_bootstrap = resample(\n    X_test,\n    y_test,\n    replace = True,\n    n_samples = 1_000,\n    random_state = 0\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#variable-size-rolling-statistics","title":"Variable Size Rolling Statistics","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom pandas.api.indexers import BaseIndexer\n\nclass VariableWindowIndexer(BaseIndexer):\n    def __init__(self, window_size, max_periods=None):\n        super().__init__()\n        self.window_size = window_size.values\n        self.max_periods = max_periods\n\n    def get_window_bounds(self, num_values, min_periods, center, closed, step):\n        temp = np.arange(0, num_values, 1)\n\n        if self.max_periods is not None:\n          self.window_size = np.where(\n              self.window_size &lt;= self.max_periods,\n              self.window_size,\n              self.max_periods\n          )\n\n        window_end = temp + 1\n        window_start = window_end - self.window_size\n        return window_start, window_end\n</code></pre> <pre><code>horizon = 1\nlag = df[\"y\"].shift(horizon)\nwindow_size = df.index + 1\n\nrolling = lag.rolling(\n    VariableWindowIndexer(window_size=window_size, max_periods=None),\n    min_periods=1,\n    center=False\n)\n\ndf[[\"y_rolling_mean\", \"y_rolling_std\"]] = rolling.agg([\"mean\", \"std\"])\n</code></pre> t y lag y_rolling_mean y_rolling_std 0 1 1 NaN NaN NaN 1 2 2 1.0 1.0 NaN 2 3 3 2.0 1.5 0.707107 3 4 4 3.0 2.0 1.000000 4 5 5 4.0 2.5 1.290994 5 6 6 5.0 3.0 1.581139 6 7 7 6.0 3.5 1.870829 7 8 8 7.0 4.0 2.160247 8 9 9 8.0 4.5 2.449490 9 10 10 9.0 5.0 2.738613 10 11 11 10.0 5.5 3.027650 11 12 12 11.0 6.0 3.316625 12 13 13 12.0 6.5 3.605551 13 14 14 13.0 7.0 3.894440"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#bias-variance-decomposition","title":"Bias-Variance Decomposition","text":"<pre><code>from mlxtend.evaluate import bias_variance_decomp\n\n# Regression\navg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n        reg,\n        X_train, y_train,\n        X_test, y_test, \n        loss='mse',\n        random_seed=123\n)\n\n# Classification\navg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n        clf,\n        X_train, y_train,\n        X_test, y_test, \n        loss='0-1_loss',\n        random_seed=123\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#paired-t-test","title":"Paired T Test","text":"<pre><code>from mlxtend.evaluate import paired_ttest_5x2cv\n\n\nt, p = paired_ttest_5x2cv(\n    estimator1 = model1,\n    estimator2 = model2,\n    X=X, y=y,\n    random_seed=1\n)\n\nprint('t statistic: %.3f' % t)\nprint('p value: %.3f' % p)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#feature-agglomeration","title":"Feature Agglomeration","text":"<pre><code>import numpy as np\nfrom matplotlib import pyplot as plt\nfrom scipy.cluster.hierarchy import dendrogram\n\nfrom sklearn.cluster import FeatureAgglomeration\n\ndef plot_dendrogram(feature_clustering, names=None, title=None, **dendogram_params):\n    # Create linkage matriX and then plot the dendrogram\n\n    # create the counts of samples under each node\n    counts = np.zeros(feature_clustering.children_.shape[0])\n    n_samples = len(feature_clustering.labels_)\n    for i, merge in enumerate(feature_clustering.children_):\n        current_count = 0\n        for child_idX in merge:\n            if child_idX &lt; n_samples:\n                current_count += 1  # leaf node\n            else:\n                current_count += counts[child_idX - n_samples]\n        counts[i] = current_count\n\n    linkage_matrix = np.column_stack(\n        [feature_clustering.children_, feature_clustering.distances_, counts]\n    ).astype(float)\n\n    if names is None:\n        cols = None\n    else:\n        cols = lambda col_index: names[col_index]\n\n    dendrogram(linkage_matrix, leaf_label_func=cols, **dendogram_params)\n\n    if title is not None:\n      plt.title(title)\n    # plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n    plt.show()\n</code></pre> <pre><code>matrix_similarity = mutual_information # df.corr() or df.corr().abs()\nmatrix_distance = np.sqrt(2*(1 - matrix_similarity)) # matrix_similarity.abs()\n\nfeature_clustering = FeatureAgglomeration(distance_threshold=0, n_clusters=None, metric=\"precomputed\", linkage=\"average\")\nfeature_clustering.fit(matrix_distance)\n</code></pre> <pre><code># plot the top three levels of the dendrogram\nplot_dendrogram(feature_clustering, matrix_distance.columns, title=\"Mutual Information\", orientation = \"right\", truncate_mode=\"level\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#r2","title":"\\(R^2\\)","text":"<pre><code>y_baseline = np.mean(y_train)\nr2 = 1 - np.mean((y_pred - y_test) ** 2) / np.mean((y_baseline - y_test) ** 2)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#multiple-quantiles-wrapper","title":"Multiple quantiles wrapper","text":"<ul> <li>Meta estimator for Regressor </li> <li>Parallel using joblib</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#bias-correction","title":"Bias Correction","text":"<pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.compose import TransformedTargetRegressor\n\nclass TransformedTargetRegressorBC():\n    def __init__(self, **init_params):\n        self.estimator = TransformedTargetRegressor(**init_params)\n        pass\n\n    def bias_correction(y, lam, sig):\n        \"\"\"Back transform Box-Cox with Bias correction.\n        See https://robjhyndman.com/hyndsight/backtransforming\n        \"\"\"\n        if lam == 0:\n            return np.exp(y) * (1 + 0.5 * sig**2)\n        else:\n            res = np.power(lam*y + 1., 1/lam)\n            res *= (1 + 0.5 * sig**2 * (1 - lam) / (lam*y + 1.)**2)\n            return res\n\n    def fit(self, X, y, **fit_params):\n        self.estimator_ = clone(self.estimator)\n        self.estimator_.fit(X, y)\n\n        self.lam_ = model_trans.transformer_.lambdas_[0]\n\n        # standard deviation of transformed target\n        z_train = model_trans.transformer_.transform(y_train[:, np.newaxis]).ravel()\n        z_predict = model_trans.regressor_.predict(X_train)\n\n        sig = np.sum((z_train - z_predict)**2)\n        self.sig_ = np.sqrt(sig / (len(y_train) - len(model_trans.regressor_.coef_) - 1))\n\n        return self\n\n    def predict(self, X):\n        return self.bias_correction(\n            self.estimator_.predict(X),\n            self.lam_,\n            self.sig_\n        )\n\nmodel = TransformedTargetRegressor(\n    regressor = LinearRegression(),\n    transformer = PowerTransformer(method='box-cox', standardize=False)\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#ridge-one-hot","title":"Ridge One-Hot","text":"<pre><code>class RidgeOneHotEncoder(BaseEstimator, TransformerMixin):\n    def __init__(self, **init_params):\n        self.ohe = OneHotEncoder(**init_params)\n        self.ridge = Ridge(fit_intercept = False)\n\n    def transform_one_hot(self, X):\n        X = X * self.ridge_.coef_\n        return X\n\n    def fit(self, X, y, **fit_params):\n        self.ohe_ = clone(self.ohe)\n        self.ohe.fit(X, y, **fit_params)\n\n        self.ridge_ = clone(self.ridge)\n        self.ridge_.fit(X, y)\n\n        return self\n\n    def transform(self, X, y=None):\n        return self.transform_one_hot(X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_IDK/#irwls","title":"IRWLS","text":"<pre><code>class IRWLS(BaseEstimator, RegressorMixin):\n    def __init__(self, estimator, get_residual_, max_iter_irwls=10, delta=1e-3, coef_delta_tol=1e-3, loss_delta_tol=1e-3, loss_reduction=None, **init_params):\n        self.estimator = estimator(**init_params)\n        self.get_residual_ = get_residual_ if get_residual_ is not None else self.get_residual_l1_\n        self.max_iter_irwls = max_iter_irwls\n        self.delta = delta\n        self.coef_delta_tol = coef_delta_tol\n        self.loss_delta_tol = loss_delta_tol\n        self.loss_reduction = loss_reduction if loss_reduction is not None else np.median\n        self.trace = []\n\n    def get_residual_l1_(self, y_true, y_pred):\n        return np.abs(y_true - y_pred)\n\n    def get_sample_weight_(self, X, y, estimator):\n        return 1 / np.maximum(\n            self.delta, # ensures that weight does not explode\n            self.get_residual_(y, estimator.predict(X))\n        )\n\n    def get_delta_(self, old, new):\n        return np.median(np.abs(new - old))\n\n    def fit(self, X, y, sample_weight=None, **fit_params):\n        self.estimator_ = clone(self.estimator)\n        sample_weight_new = sample_weight if sample_weight is not None else np.ones(X.shape[0])\n\n        for iteration in range(0, self.max_iter_irwls, 1):\n            if i &gt; 0:\n                coef_old = coef_new\n                sample_weight_old = sample_weight_new\n                loss_old = loss_new\n\n            self.estimator_.fit(X, y, sample_weight_new, **fit_params)\n            coef_new = self.estimator_.coef_\n            sample_weight_new = self.get_sample_weight_(X, y, self.estimator_)\n            loss_new = self.loss_reduction(self.get_residual_(y, self.estimator_.predict(X)))\n            self.trace.append({\n                'iteration': iteration,\n                \"loss\": loss_new\n            })\n\n            if i &gt; 0:\n                coef_delta = self.get_delta_(coef_old, coef_new)\n                loss_delta = loss_new - loss_old\n\n                if (\n                    (coef_delta &lt; self.coef_delta_tol)\n                    or\n                    (loss_delta &lt; self.loss_delta_tol)\n                ):\n                    break\n\n    def predict(self, X, y=None):\n        return self.estimator_.predict(X)\n\nirwls = IRWLS(Ridge)\nirwls.fit(X, y)\nirwls.predict(X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/","title":"01 Performance Optimization","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/#performance-optimization","title":"Performance Optimization","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/#n_jobs-1","title":"<code>n_jobs=-1</code>","text":"<p>Multi-threading</p> <pre><code>## !pip install scikit-learn-intelex\nfrom sklearnex import patch_sklearn\npatch_sklearn()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/#config","title":"Config","text":"<pre><code>with sklearn.config_context(\n  assume_finite = True\n):\n  # reduce validation overhead: will not throw a ValueError if X contains NaN or infinity.\n\n  pass # do learning/prediction here with reduced validation\n</code></pre> <pre><code>with sklearn.config_context(\n    working_memory = 128 # MB\n):\n\n  pass # do chunked work here\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/#model-compression","title":"Model Compression","text":"<p>Linear models</p> <pre><code>model = SGDRegressor(penalty='elasticnet', l1_ratio=0.25)\nmodel.fit(X_train, y_train)\nmodel.sparsify()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/#warm-start","title":"Warm Start","text":"<p>Useful for re-using previous training as initial values</p> <p>Useful for hyper-parameter tuning</p> <pre><code>max_estimators = 100\n\nrf = RandomForestClassifier(\n  warm_start=True\n)\n\nn_estimators = 1\nwhile n_estimators &lt;= max_estimators:\n  rf.n_estimators = n_estimators\n    rf.fit(X_train, y_train)\n\n  n_estimators *= 2\n</code></pre> <p>The advantage here is that the estimators would already be fit with the previous parameter setting, and with each subsequent call to fit, the model will be starting from the previous parameters, and we're just analyzing if adding new estimators would benefit the model.</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/#mini-batchonline-learning","title":"Mini-Batch/Online Learning","text":"<pre><code>model = LinearRegression()\n\nmodel.partial_fit(data_1)\nmodel.partial_fit(data_2)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/01_Performance_Optimization/#config_1","title":"Config","text":"<pre><code>with sklearn.config_context(\n    assume_finite = True,\n    skip_parameter_validation = True\n):\n    pass\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/","title":"Custom","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/#regression-with-custom-loss-function","title":"Regression with Custom Loss Function","text":"<pre><code>import utils\n\nfrom sklearn.base import BaseEstimator\n#from sklearn.utils.estimator_checks import check_estimator\nfrom sklearn.utils.validation import check_X_y, check_array, check_is_fitted\nfrom sklearn.metrics import (\n    mean_absolute_percentage_error as mape,\n    # mean_squared_error as mse,\n    root_mean_squared_error as rmse,\n    mean_absolute_error as mae,\n    r2_score as r2\n)\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import optimize as o, stats\n\nfrom inspect import getfullargspec, getsource\n# import copy\n</code></pre> <pre><code>class CustomRegression(BaseEstimator):\n    \"\"\"\n    All variables inside the Class should end with underscore\n    \"\"\"\n    def __init__(self, model, method=\"Nelder-Mead\", cost = None, alpha=0, l1_ratio=0.5, maxiter = 500, maxfev = 1_000):\n        self.model = model\n        self.method = method\n        self.cost = cost if cost is not None else self.mse\n        self.alpha = alpha\n        self.l1_ratio = l1_ratio\n        self.maxiter = maxiter\n        self.maxfev = maxfev\n\n    def __str__(self):\n        return str(self.model_)\n    def __repr__(self):\n        return str(self)\n\n    def mse(self, pred, true, sample_weight):\n        error = pred - true\n\n        cost = error**2\n\n        cost = (\n            np.mean( # median is robust to outliers than mean\n                sample_weight * cost\n            )\n        )\n\n        return cost\n\n    def l1(self, params):\n        return np.sum(np.abs(params-self.model_.param_initial_guess))\n    def l2(self, params):\n        return np.sum((params-self.model_.param_initial_guess) ** 2)\n    def l3(self, params, l1_ratio=0.5):\n        return (\n            l1_ratio * self.l1(params) +\n            (1 - l1_ratio) * self.l2(params)\n        )\n\n    def regularization_cost(self, params, alpha, penalty_type=\"l3\"):\n        \"\"\"\n        Regularization requires standardised parameters\n        \"\"\"\n        penalty = get_attr(self, penalty_type)(params, self.l1_ratio)\n\n        return (alpha * penalty)/self.sample_size_\n\n    def cost_total(self, params, X, y):\n        pred = self.model_.equation(X, *params)\n        cost = self.cost(y, pred, self.sample_weight)\n\n        if self.alpha == 0:\n            pass\n        else:\n            cost += self.regularization_cost(params, self.alpha)\n        return cost\n\n    def check_enough_samples(self):\n        return self.enough_samples_\n\n    def fit(self, X, y, sample_weight=None):\n        check_X_y(X, y) # Using self.X,self.y = check_X_y(self.X,self.y) removes column names\n\n        self.X, self.y = X, y\n\n        self.n_features_in_ = self.X.shape[1]\n\n        self.sample_size_ = self.X.shape[0]\n\n        self.sample_weight = (\n            sample_weight\n            if sample_weight is not None\n            else np.full(self.sample_size_, 1) # set Sample_Weight as 1 by default\n        )\n\n        self.sample_size_ = self.sample_weight[self.sample_weight &gt; 0].shape[0]\n\n        self.model_ = copy.deepcopy(self.model)\n\n        self.dof_ = self.sample_size_ - self.model_.k # - 1 # n-k-1\n        if self.dof_ &lt;= 0:\n            self.success_ = False\n            self.enough_samples_ = False\n            # raise Exception(\"Not enough samples\")\n            return self\n        else:\n            self.enough_samples_ = True\n\n        params_all = getfullargspec(self.model_.equation).args        \n        params = [param for param in params_all if param not in ['self', \"x\"]]\n\n        self.optimization_ = o.minimize(\n            self.cost_total,\n            x0 = self.model_.param_initial_guess,\n            args = (self.X, self.y),\n            method = self.method, # \"L-BFGS-B\", \"Nelder-Mead\", \"SLSQP\",\n            constraints = self.model_.constraints,\n            bounds = self.model_.param_bounds,\n            # [\n            #     (-1, None) for param in params # variables must be positive\n            # ]\n            options = dict(\n                maxiter = self.maxiter,\n                maxfev = self.maxfev,\n                # xatol=1e-4,\n                # fatol=1e-4,\n                # adaptive=False,\n            )\n        )\n        self.success_ = self.optimization_.success\n\n        self.fitted_coeff_ = (\n            self.optimization_.x\n        )\n\n        self.fitted_coeff_formatted_ = [\n            f\"\"\"{{ {utils.round_f(popt, 4)} }}\"\"\" for popt in self.fitted_coeff_\n        ]\n\n        self.model_.set_fitted_coeff(*self.fitted_coeff_)\n        self.model_.set_fitted_coeff_formatted(*self.fitted_coeff_formatted_)\n\n        self.rmse_response = root_mean_squared_error(\n            y,\n            self.output(X),\n        )\n        self.rmse_link = root_mean_squared_error(\n            y,\n            self.output(X),\n        )\n\n        return self\n\n    def output(self, X):\n        return np.array(\n            self.model_\n            .equation(X, *self.fitted_coeff_)\n        )\n\n    def get_pred_se(self, X):\n        return self.rmse_response\n\n    def predict(self, X):\n        check_is_fitted(self, \"fitted_coeff_\") # Check to verify if .fit() has been called\n        check_array(X) #X = check_array(X) # removes column names\n\n        pred = (\n            self.output(X)\n            .astype(np.float32)\n        )\n\n        return pred\n\n    def predict_quantile(self, X, q):\n        return self.model_.quantile(X, self.X, self.y, link_distribution_dof=self.dof_, link_distribution_q=q)\n\n\nclass CustomRegressionGrouped(CustomRegression):\n    def __str__(self):\n        x = \"\"\n        for key, value in self.get_params().items():\n            x += f\"{str(key)}: {str([utils.round_f(v, 4) for v in list(value)])} \\n\\n\"\n\n        return str(x)\n    def __init__(self, model, cost, method=\"Nelder-Mead\", group=None):\n        super().__init__(model=model, cost=cost, method=method)\n        self.group = group\n        self.model = model\n        self.method = method\n        self.cost = cost\n\n        self.optimization_ = dict()\n        self.model_ = dict()\n        self.enough_samples_ = dict()\n\n        self.dof_ = 0\n        self.sample_size_ = 0\n\n    def get_params(self, how=\"dict\"):\n        params = dict()\n        for key, value in self.model_.items():\n            popt = \"fitted_coeff_\"\n            if popt in dir(value):\n                params[key] = getattr(value, popt)\n            else:\n                params[key] = None\n\n        if how == \"df\":\n            params = pd.DataFrame(params).T\n        return params\n\n    def model_group(self, X, y, model, method, error, sample_weight):\n        return (\n            CustomRegression(\n                model = self.model,\n                cost = self.cost,\n                method = self.method,\n            )\n            .fit(\n                X,\n                y,\n                sample_weight\n            )\n        )\n\n    def check_enough_samples(self, how=\"all\"):\n        if how == \"all\":\n            enough_samples = True\n            for e in self.enough_samples_.values():\n                if not e:\n                    enough_samples = False\n        elif how == \"any\":\n            enough_samples = self.enough_samples_\n        else:\n            pass\n\n        return enough_samples\n\n    def apply_model_multiple_group(self, X, y, group, model, method, cost, sample_weight):\n        for g in X[self.group].unique():\n            mask = X.eval(f\"{self.group} == {g}\")\n\n            m = self.model_group(\n                X[mask],\n                y[mask],\n                model,\n                method,\n                cost,\n                sample_weight[mask] if sample_weight is not None else sample_weight\n            )\n\n            if m.success_:\n                self.model_[g] = m\n                self.enough_samples_[g] = m.enough_samples_\n                self.optimization_[g] = m.optimization_\n                self.sample_size_ += m.sample_size_\n\n        success = True\n        for o in self.optimization_.values():\n            if not o.success:\n                success = False\n\n        self.success_ = success\n\n    def fit(self, X, y, sample_weight=None):\n        self.model_ = dict()\n\n        self.apply_model_multiple_group(X, y, self.group, self.model, self.method, self.cost, sample_weight)\n    def predict(self, X):\n        Xs = []\n        preds = pd.DataFrame()\n\n        for g in X[self.group].unique():\n            if g not in self.model_.keys():\n                return\n            else:\n                Xg = X.query(f\"{self.group} == {g}\")\n                index = Xg.index\n\n                pred = self.model_[g].predict(\n                    X = Xg.copy().reset_index(drop=True),\n                )\n\n                preds = pd.concat([\n                    preds, pd.Series(pred, index=index)\n                ])\n        return preds.sort_index()\n\n    def predict_quantile(self, X, q):\n        Xs = []\n        preds = pd.DataFrame()\n\n        for g in X[self.group].unique():\n            if g not in self.model_.keys():\n                return Exception(f\"Model not trained for {g}\")\n            else:\n                Xg = X.query(f\"{self.group} == {g}\")\n                index = Xg.index\n\n                pred = self.model_[g].predict_quantile(\n                    X = Xg.copy().reset_index(drop=True),\n                    q = q\n                )\n\n                preds = pd.concat([\n                    preds, pd.Series(pred, index=index)\n                ])\n\n        return preds.sort_index()\n</code></pre> <pre><code>curve_fit = CustomRegression(\n    model = model_selected,\n    cost = regression.LogCosh().cost,\n    method = solver\n)\nprint(curve_fit) ## prints latex\n\ncurve_fit.fit(\n    X_train,\n    y_train,\n    sample_weight=df_train[\"Sample_Weight\"],\n)\n\nprint(curve_fit) ## prints latex with coefficent values\n\npred = curve_fit.predict(X_test)\nll = curve_fit.predict_quantile(X_test, q=0.025)\nul = curve_fit.predict_quantile(X_test, q=0.975)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/#holt-winters","title":"Holt-Winters","text":"<pre><code>class HoltWinters(BaseEstimator):\n    \"\"\"Scikit-learn like interface for Holt-Winters method.\"\"\"\n\n    def __init__(self, season_len=24, alpha=0.5, beta=0.5, gamma=0.5):\n        self.beta = beta\n        self.alpha = alpha\n        self.gamma = gamma\n        self.season_len = season_len\n\n    def fit(self, series):\n        # note that unlike scikit-learn's fit method, it doesn't learn\n        # the optimal model paramters, alpha, beta, gamma instead it takes\n        # whatever the value the user specified the produces the predicted time\n        # series, this of course can be changed.\n        beta = self.beta\n        alpha = self.alpha\n        gamma = self.gamma\n        season_len = self.season_len\n        seasonals = self._initial_seasonal(series)\n\n        # initial values\n        predictions = []\n        smooth = series[0]\n        trend = self._initial_trend(series)\n        predictions.append(smooth)\n\n        for i in range(1, len(series)):\n            value = series[i]\n            previous_smooth = smooth\n            seasonal = seasonals[i % season_len]\n            smooth = alpha * (value - seasonal) + (1 - alpha) * (previous_smooth + trend)\n            trend = beta * (smooth - previous_smooth) + (1 - beta) * trend\n            seasonals[i % season_len] = gamma * (value - smooth) + (1 - gamma) * seasonal\n            predictions.append(smooth + trend + seasonals[i % season_len])\n\n        self.trend_ = trend\n        self.smooth_ = smooth\n        self.seasonals_ = seasonals\n        self.predictions_ = predictions\n        return self\n\n    def _initial_trend(self, series):\n        season_len = self.season_len\n        total = 0.0\n        for i in range(season_len):\n            total += (series[i + season_len] - series[i]) / season_len\n\n        trend = total / season_len\n        return trend\n\n    def _initial_seasonal(self, series):\n        season_len = self.season_len\n        n_seasons = len(series) // season_len\n\n        season_averages = np.zeros(n_seasons)\n        for j in range(n_seasons):\n            start_index = season_len * j\n            end_index = start_index + season_len\n            season_average = np.sum(series[start_index:end_index]) / season_len\n            season_averages[j] = season_average\n\n        seasonals = np.zeros(season_len)\n        seasons = np.arange(n_seasons)\n        index = seasons * season_len\n        for i in range(season_len):\n            seasonal = np.sum(series[index + i] - season_averages) / n_seasons\n            seasonals[i] = seasonal\n\n        return seasonals\n\n    def predict(self, n_preds=10):\n        \"\"\"\n        Parameters\n        ----------\n        n_preds: int, default 10\n            Predictions horizon. e.g. If the original input time series to the .fit\n            method has a length of 50, then specifying n_preds = 10, will generate\n            predictions for the next 10 steps. Resulting in a prediction length of 60.\n        \"\"\"\n        predictions = self.predictions_\n        original_series_len = len(predictions)\n        for i in range(original_series_len, original_series_len + n_preds):\n            m = i - original_series_len + 1\n            prediction = self.smooth_ + m * self.trend_ + self.seasonals_[i % self.season_len]\n            predictions.append(prediction)\n\n        return predictions\n</code></pre> <pre><code>def timeseries_cv_score(params, series, loss_function, season_len=24, n_splits=3):\n    \"\"\"\n    Iterating over folds, train model on each fold's training set,\n    forecast and calculate error on each fold's test set.\n    \"\"\"\n    errors = []    \n    alpha, beta, gamma = params\n    time_series_split = TimeSeriesSplit(n_splits=n_splits) \n\n    for train, test in time_series_split.split(series):\n        model = HoltWinters(season_len, alpha, beta, gamma)\n        model.fit(series[train])\n\n        # evaluate the prediction on the test set only\n        predictions = model.predict(n_preds=len(test))\n        test_predictions = predictions[-len(test):]\n        test_actual = series[test]\n        error = loss_function(test_actual, test_predictions)\n        errors.append(error)\n\n    return np.mean(errors)\n</code></pre> <pre><code>x = [0, 0, 0]\ntest_size = 20\ndata = series.values[:-test_size]\nopt = minimize(\n  timeseries_cv_score,\n  x0=x, \n  args=(data, mean_squared_log_error),\n  method='TNC',\n  bounds=((0, 1), (0, 1), (0, 1))\n)\n</code></pre> <pre><code>alpha_final, beta_final, gamma_final = opt.x\n\nmodel = HoltWinters(season_len, alpha_final, beta_final, gamma_final)\nmodel.fit(data)\npredictions = model.predict(n_preds=50)\n\nprint('original series length: ', len(series))\nprint('prediction length: ', len(predictions))\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/#soft-labelslabel-smoothing","title":"Soft Labels/Label Smoothing","text":"<pre><code>from sklearn.base import BaseEstimator, ClassifierMixin\nfrom sklearn.utils.validation import check_array\nfrom scipy.special import softmax\nimport numpy as np\n\ndef _log_odds_ratio_scale(X):\n    X = np.clip(X, 1e-8, 1 - 1e-8)   # numerical stability\n    X = np.log(X / (1 - X))  # transform to log-odds-ratio space\n    return X\n\nclass FuzzyTargetClassifier(ClassifierMixin, BaseEstimator):\n\n    def __init__(self, regressor):\n        '''\n        Fits regressor in the log odds ratio space (inverse crossentropy) of target variable.\n        during transform, rescales back to probability space with softmax function\n\n        Parameters\n        ---------\n        regressor: Sklearn Regressor\n            base regressor to fit log odds ratio space. Any valid sklearn regressor can be used here.\n\n        '''\n\n        self.regressor = regressor\n        return\n\n    def fit(self, X, y=None, **kwargs):\n        #ensure passed y is onehotencoded-like\n        y = check_array(y, accept_sparse=True, dtype = 'numeric', ensure_min_features=1)\n        self.regressors_ = [clone(self.regressor) for _ in range(y.shape[1])]\n        for i in range(y.shape[1]):\n            self._fit_single_regressor(self.regressors_[i], X, y[:,i], **kwargs)\n\n        return self\n\n    def _fit_single_regressor(self, regressor, X, ysub, **kwargs):\n        ysub = _log_odds_ratio_scale(ysub)        \n        regressor.fit(X, ysub, **kwargs)\n        return regressor    \n\n    def decision_function(self,X):\n        all_results = []\n        for reg in self.regressors_:\n            results = reg.predict(X)\n            if results.ndim &lt; 2:\n                results = results.reshape(-1,1)\n            all_results.append(results)\n\n        results = np.hstack(all_results)                \n        return results\n\n    def predict_proba(self, X):\n        results = self.decision_function(X)\n        results = softmax(results, axis = 1)\n        return results\n\n    def predict(self, X):\n        results = self.decision_function(X)\n        results = results.argmax(1)\n        return results\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/#tree-based-proximity","title":"Tree-Based Proximity","text":"<p>Random Forest Proximity</p> <pre><code>class TreeBasedProximity(): # BaseEstimator, TransformerMixin\n  \"\"\"\n  Create Proximity matrix\n\n  normalization_type = column_wise  : Normalize columns to sum to 1\n  normalization_type = n_trees      : pm / n_trees\n  \"\"\"\n\n  def __init__(self, estimator, **init_params):\n    self.estimator = estimator\n\n    self.supported_types = {\n      \"RandomForest\": \"a\",\n      \"XGBoost\": \"a\",\n      \"GradientBoosting\": \"b\"\n    }\n\n    for m, t in self.supported_types.items():\n      if m in self.estimator.__class__.__name__:\n        self.estimator_type = t\n        break\n    else:\n        return Exception(\"Unsupported estimator\")\n\n    self.n_trees = len(self.estimator.estimators_)\n\n  def fit(self, X, y=None, **fit_params):\n    # Get leaf_indices indices with shape = (x.shape[0], n_trees)\n    if self.estimator_type == \"a\":\n      leaf_indices = self.estimator.apply(X)\n    elif self.estimator_type == \"b\":\n      leaf_indices = np.array([tree[0].apply(X) for tree in self.estimator.estimators_]).T\n\n    self.pm_ = (\n        (leaf_indices[:, None, :] == leaf_indices[None, :, :])\n        .sum(axis=-1)\n    )\n    #np.fill_diagonal(self.pm_, 0)\n    return self\n\n  def normalize_(self, pm, normalization=\"n_trees\", ):\n    if normalization == \"n_trees\":\n        divisor = self.n_trees\n    elif normalization == \"col_wise\":\n        divisor = pm.sum(axis=0, keepdims=True)\n    else:\n        return Exception(\"Invalid normalization type\")\n    return pm / divisor\n\n  def transform(self, X=None, y=None, metric=\"similarity\", normalization=\"n_trees\", ):\n    pm = self.normalize_(\n        self.pm_,\n        normalization\n    )\n    np.fill_diagonal(pm, 1)\n\n    if metric==\"distance\":\n      pm = 1-pm\n\n    return pm\n</code></pre> <pre><code>model = RandomForestClassifier( # or Regressor\n    n_estimators=100,\n    max_depth=5, # make sure not too deep\n    n_jobs=-1,\n)\nmodel.fit(X, y)\n\nrfp = TreeBasedProximity(model) # randomforest model\nrfp.fit(X)\nrfp.transform(metric=\"similarity\", normalization=\"n_trees\")\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/#pairwise-mutual-information-matrix","title":"Pairwise Mutual Information Matrix","text":"<pre><code>from joblib import Parallel, delayed\n\nclass PairwiseMutualInformation():\n  def __init__(self, normalized=True, n_bins=None, sample=None, random_state=None, n_jobs=None, ):\n    self.n_bins = n_bins\n    self.sample = sample\n    self.normalized = normalized\n    self.random_state = random_state\n    self.n_jobs = n_jobs if n_jobs is not None else 1\n\n  def compute_histogram2d(self, i, j, X, n_bins):\n        return np.histogram2d(X[:, i], X[:, j], bins=n_bins)[0]\n\n  def joint_entropies(self, X):\n    histograms2d = np.empty((self.n_variables, self.n_variables, self.n_bins, self.n_bins))\n\n    results = (\n        Parallel(n_jobs=self.n_jobs)\n        (\n            delayed(self.compute_histogram2d)\n            (i, j, X, self.n_bins)\n            for i in range(self.n_variables)\n            for j in range(self.n_variables)\n        )\n    )\n\n    index = 0\n    for i in range(self.n_variables):\n        for j in range(self.n_variables):\n            histograms2d[i, j] = results[index]\n            index += 1\n\n    probs = histograms2d / len(X) + 1e-100\n    joint_entropies = -(probs * np.log2(probs)).sum((2,3))\n    return joint_entropies\n\n  def get_mutual_info_matrix(self, X):\n    j_entropies = self.joint_entropies(X)\n    entropies = j_entropies.diagonal()\n    entropies_tile = np.tile(entropies, (self.n_variables, 1))\n    sum_entropies = entropies_tile + entropies_tile.T\n\n    mi_matrix = sum_entropies - j_entropies\n    if self.normalized:\n        mi_matrix = mi_matrix * 2 / sum_entropies\n    return mi_matrix\n\n  def fit(self, X, y=None):\n    self.columns_ = X.columns\n\n    if self.sample is not None:\n      if type(self.sample) == int:\n        X = df.sample(n=self.sample, random_state=self.random_state)\n      elif type(self.sample) == float:\n        X = df.sample(frac=self.sample, random_state=self.random_state)\n      else:\n        pass\n\n    X = X.to_numpy()\n\n    self.n_variables = X.shape[-1]\n    self.n_samples = X.shape[0]\n\n    if self.n_bins == None:\n        self.n_bins = int((self.n_samples/5)**.5)\n\n    self.mi_matrix_ = self.get_mutual_info_matrix(X)\n    return self\n\n  def transform(self, X, y=None):\n    return pd.DataFrame(self.mi_matrix_, index=self.columns_, columns=self.columns_)\n\n  def fit_transform(self, X, y=None):\n    return self.fit(X, y).transform(X, y)\n</code></pre> <pre><code>matrix_similarity = PairwiseMutualInformation(normalized=True, n_jobs=-1, sample=0.10, random_state=0).fit_transform(df)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/#gradient-regularization","title":"Gradient Regularization","text":"<pre><code>import numpy as np\n\ndef linear_regression_with_gradient_regularization(X, y, lambda_ridge, lambda_second_gradient):\n    \"\"\"\n    Perform linear regression with gradient regularization.\n\n    Parameters:\n    X (np.array): Design matrix of shape (n_samples, n_features)\n    y (np.array): Target vector of shape (n_samples,)\n    lambda_ridge (float): Regularization parameter\n    lambda_second_gradient (float): Regularization parameter\n\n    Returns:\n    beta (np.array): Coefficient vector\n    loss (float): Total loss including regularization\n    \"\"\"\n\n    # Compute X^T X\n    XTX = X.T @ X\n\n    # Compute (X^T X)^2\n    XTX_squared = XTX @ XTX\n\n    # Compute the regularized matrix\n    reg_ridge = lambda_ridge * np.eye(n_features)\n    reg_second_gradient = 4 * lambda_second_gradient * XTX_squared\n    regularized_matrix = XTX + reg_ridge + reg_second_gradient\n\n    # Compute X^T y\n    XTy = X.T @ y\n\n    # Compute the closed-form solution\n    beta = np.linalg.solve(regularized_matrix, XTy)\n\n    # Compute the loss\n    residuals = y - X @ beta\n    mse = np.mean(residuals**2)\n    reg_term = lambda_ridge * np.sum(beta**2) + lambda_second_gradient * np.sum(XTX**2)\n    total_loss = mse + reg_term\n\n    return beta, total_loss\n\n# Example usage\nnp.random.seed(42)\nn_samples, n_features = 100, 5\nX = np.random.randn(n_samples, n_features)\ntrue_beta = np.array([1, 2, 3, 4, 5])\ny = X @ true_beta + np.random.randn(n_samples) * 0.1\n\nbeta_hat, loss = linear_regression_with_gradient_regularization(X, y, lambda_ridge=1, lambda_second_gradient=1e-4)\n\nprint(\"Estimated coefficients:\", beta_hat)\nprint(\"Total loss:\", loss)\n\n# Compare with OLS\nbeta_ols = np.linalg.solve(X.T @ X, X.T @ y)\nprint(\"\\nOLS coefficients:\", beta_ols)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/02_Custom/#non-linear-confidence-intervals","title":"Non-Linear Confidence Intervals","text":"<pre><code>def nlpredict(X, y, model, loss, popt, xnew, alpha=0.05, ub=1e-5, ef=1.05):\n    \"\"\"Prediction error for a nonlinear fit.\n\n    Parameters\n    ----------\n    model : model function with signature model(x, ...)\n    loss : loss function the model was fitted with loss(...)\n    popt : the optimized paramters\n    xnew : x-values to predict at\n    alpha : confidence level, 95% = 0.05\n    ub : upper bound for smallest allowed Hessian eigenvalue\n    ef : eigenvalue factor for scaling Hessian\n\n    This function uses numdifftools for the Hessian and Jacobian.\n\n    Returns\n    -------\n    y, yint, se\n\n    y : predicted values\n    yint : prediction interval at alpha confidence interval\n    se : standard error of prediction\n    \"\"\"\n    ypred = model(xnew, *popt)\n\n    hessp = nd.Hessian(lambda p: loss(*p))(popt)\n    # for making the Hessian better conditioned.\n    eps = max(ub, ef * np.linalg.eigvals(hessp).min())\n\n    sse = loss(*popt)\n    n = len(y)\n    mse = sse / n\n    I_fisher = np.linalg.pinv(hessp + np.eye(len(popt)) * eps)\n\n    gprime = nd.Jacobian(lambda p: model(xnew, *p))(popt)\n\n    temp = np.diag(gprime @ I_fisher @ gprime.T)\n    if interval_type == \"confidence\":\n        pass\n    elif interval_type == \"prediction\":\n        # 1 + comes for the prediction interval, not for confidence interval\n        # https://online.stat.psu.edu/stat501/lesson/7/7.2\n        temp += 1\n\n    sigmas = np.sqrt(\n        mse *\n        (1 + temp)\n    )\n\n    tval = t.ppf(1 - alpha / 2, len(y) - len(popt))\n\n    return [\n        ypred,\n        np.array(\n            [\n                ypred + tval * sigmas,\n                ypred - tval * sigmas,\n            ]\n        ).T,\n        sigmas,\n    ]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/05_KNN/","title":"KNN","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/05_KNN/#knn-ridge","title":"KNN Ridge","text":"<p>Useful for one-hot encoded input</p> <pre><code>class RidgeKNNRegressor(BaseEstimator, RegressorMixin):\n    def __init__(self, one_hot_columns, **init_params):\n        self.one_hot_columns = one_hot_columns\n        self.knn = KNeighborsRegressor(**init_params)\n        self.ridge = Ridge(fit_intercept = False)\n\n    def transform_one_hot(self, X):\n        X[self.one_hot_columns_idx] = X[self.one_hot_columns_idx] * self.ridge_.coef_[self.one_hot_columns_idx]\n        return X\n\n    def fit(self, X, y, **fit_params):\n        self.one_hot_columns_idx = X.columns.get_indexer(self.one_hot_columns)\n\n        self.ridge_ = clone(self.ridge)\n        self.ridge_.fit(X, y)\n\n        X = self.transform_one_hot(X)\n\n        self.knn_ = clone(self.knn)\n        self.knn_.fit(X, y, **fit_params)\n\n        return self\n\n    def predict(self, X, y=None):\n        X = self.transform_one_hot(X)\n        return self.knn_.predict(X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/05_KNN/#knn-median","title":"KNN Median","text":"<pre><code>from sklearn.neighbors.regression import KNeighborsRegressor, check_array, _get_weights\n\nclass MedianKNNRegressor(KNeighborsRegressor):\n    def predict(self, X):\n        X = check_array(X, accept_sparse='csr')\n\n        neigh_dist, neigh_ind = self.kneighbors(X)\n\n        weights = _get_weights(neigh_dist, self.weights)\n\n        _y = self._y\n        if _y.ndim == 1:\n            _y = _y.reshape((-1, 1))\n\n        ######## Begin modification\n        if weights is None:\n            y_pred = np.median(_y[neigh_ind], axis=1)\n        else:\n            # y_pred = weighted_median(_y[neigh_ind], weights, axis=1)\n            raise NotImplementedError(\"weighted median\")\n        ######### End modification\n\n        if self._y.ndim == 1:\n            y_pred = y_pred.ravel()\n\n        return y_pred    \n\nX = np.random.rand(100, 1)\ny = 20 * X.ravel() + np.random.rand(100)\nclf = MedianKNNRegressor().fit(X, y)\nprint(clf.predict(X[:5]))\n# [  2.38172861  13.3871126    9.6737255    2.77561858  17.07392584]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/05_KNN/#knn-cv","title":"KNN CV","text":"<pre><code># Authors: The scikit-learn developers\n# SPDX-License-Identifier: BSD-3-Clause\n\nfrom tempfile import TemporaryDirectory\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsTransformer\nfrom sklearn.pipeline import Pipeline\n\nX, y = load_digits(return_X_y=True)\nn_neighbors_list = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nclass KNeighborsEstimatorCV(BaseEstimator):\n    def __init__(self, estimator, cv_estimator, n_jobs=-1, **init_params):\n        self.estimator = estimator\n        self.cv_estimator = cv_estimator\n        self.init_params = init_params\n\n    def fit(self, X, y, **fit_params):\n        self.pipeline = Pipeline(\n            steps=[\n                (\"graph\", KNeighborsTransformer(n_neighbors=max(kwargs[\"n_neighbors\"]))),\n                (\"estimator\", self.cv_estimator(self.estimator(metric=\"precomputed\"), **self.init_params, n_jobs=self.n_jobs)\n                )\n            ],\n            memory=\"knncv\" if \"Grid\" in self.cv_estimator_.__class__.__name__ else None\n        )\n\n        self.pipeline.fit(self., y, **fit_params)\n\n    def predict(self, X, y=None):\n        return self.pipeline.predict(X, y)\n\nclass KNeighborsRegressorCV(BaseEstimator, RegressorMixin, KNeighborsEstimatorCV):\n    def __init__(self, cv_estimator, n_jobs=-1, **init_params):\n        return super().__init__(KNeighborsRegressor, cv_estimator, n_jobs=-1, **init_params)\n\nclass KNeighborsClassifierCV(BaseEstimator, RegressorMixin, KNeighborsEstimatorCV):\n    def __init__(self, cv_estimator, n_jobs=-1, **init_params):\n        return super().__init__(KNeighborsClassifier, cv_estimator, n_jobs=-1, **init_params)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/05_Persistence/","title":"Persistence","text":"<p>Pickle is not safe</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/05_Persistence/#onnx","title":"ONNX","text":"<pre><code>from skl2onnx import to_onnx\nonx = to_onnx(clf, X[:1].astype(numpy.float32), target_opset=12)\nwith open(\"filename.onnx\", \"wb\") as f:\n    f.write(onx.SerializeToString())\n\nfrom onnxruntime import InferenceSession\nwith open(\"filename.onnx\", \"rb\") as f:\n    onx = f.read()\nsess = InferenceSession(onx, providers=[\"CPUExecutionProvider\"])\npred_ort = sess.run(None, {\"X\": X_test.astype(numpy.float32)})[0]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/05_Persistence/#skops","title":"Skops","text":"<pre><code>import skops.io as sio\n</code></pre> <pre><code># from file\nsio.dump(model, \"model.skops\")\n\n# compression\nfrom zipfile import ZIP_DEFLATED\nsio.dump(model, \"model.skops\", compression=ZIP_DEFLATED, compresslevel=9)\n\n# in-memory\nserialized = sio.dumps(model)\n</code></pre> <pre><code># from file\nunknown_types = get_untrusted_types(file=\"model.skops\")\nmodel = sio.load(\"model.skops\", trusted=unknown_types)\n\n# in-memory\nunknown_types = get_untrusted_types(serialized)\nmodel = sio.loads(serialized, trusted=unknown_types)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/06_Clustering/","title":"Clustering","text":"<pre><code>from sklearn.base import BaseEstimator, ClusterMixin\nfrom sklearn.cluster import KMeans\nimport numpy as np\n\nclass WarmStartKMeans(BaseEstimator, ClusterMixin):\n    def __init__(self, n_clusters_list, **init_params):\n        \"\"\"\n        Custom KMeans estimator with warm start for a list of n_clusters.\n\n        Parameters:\n        - n_clusters_list: List of integers specifying the number of clusters to try.\n        - max_iter: Maximum number of iterations for k-means.\n        - tol: Tolerance for convergence.\n        - random_state: Random seed for reproducibility.\n        \"\"\"\n        self.n_clusters_list = n_clusters_list\n        self.init_params = init_params\n        self.results_ = {}\n\n    def fit(self, X, y=None, **fit_params):\n        \"\"\"\n        Fit the k-means model using warm start for multiple n_clusters values.\n\n        Parameters:\n        - X: Input data (array-like or sparse matrix).\n        - y: Ignored (not used in clustering).\n\n        Returns:\n        - self: Fitted estimator.\n        \"\"\"\n        previous_centroids = None\n\n        for i, n_clusters in enumerate(self.n_clusters_list):\n            if i == 0:\n                # First run: use default 'k-means++' initialization\n                kmeans = KMeans(\n                    n_clusters=n_clusters,\n                    **init_params\n                )\n            else:\n                # Subsequent runs: use centroids from the previous model as initialization\n                additional_centroids = np.random.rand(n_clusters - len(previous_centroids), X.shape[1])\n                init_centroids = np.vstack([previous_centroids, additional_centroids])\n                kmeans = KMeans(\n                    n_clusters=n_clusters,\n                    init=init_centroids,\n                    n_init=1,\n                    **init_params\n                )\n\n            # Fit the model and store results\n            kmeans.fit(X)\n            self.results_[n_clusters] = {\n                \"model\": kmeans,\n                \"labels\": kmeans.labels_,\n                \"centroids\": kmeans.cluster_centers_,\n                \"inertia\": kmeans.inertia_,\n            }\n\n            # Update previous centroids for warm start\n            previous_centroids = kmeans.cluster_centers_\n\n        return self\n\n    def predict(self, X):\n        \"\"\"\n        Predict cluster labels using the last fitted model.\n\n        Parameters:\n        - X: Input data (array-like or sparse matrix).\n\n        Returns:\n        - labels: Cluster labels predicted by the model.\n        \"\"\"\n        if not self.results_:\n            raise ValueError(\"The model has not been fitted yet.\")\n\n        # Use the last fitted model for prediction\n        last_model = list(self.results_.values())[-1][\"model\"]\n        return last_model.predict(X)\n\n    def get_results(self):\n        \"\"\"\n        Retrieve clustering results for all n_clusters values.\n\n        Returns:\n        - Dictionary containing models, labels, centroids, and inertia for each n_clusters value.\n        \"\"\"\n        return self.results_\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Boosted_Trees/","title":"Boosted Trees","text":"<p>XgBoost, LightGBM, CatBoost</p> <pre><code>model = XGBRegressor(\n    objective = custom_loss_grad_hess,\n)\n# fit model\nmodel.fit(X_train, y_train)\n# make predictions\npred = model.predict(X_test)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Boosted_Trees/#custom-loss-function","title":"Custom Loss Function","text":"<p>Need a function that returns - <code>grad</code>: \\(\\dfrac{dL}{d \\hat y}\\) - <code>hess</code>: \\(\\dfrac{d^2 L}{d {\\hat y}^2}\\)</p> <pre><code># define cost and eval functions\ndef custom_loss(y_pred, y_true):\n    residual = (y_true - y_pred)\n    loss = np.where(\n        residual &lt; 0,\n        (residual ** 2) ,\n        (residual ** 2) * 2\n    )\n    return np.mean(loss)\n\ndef custom_loss_grad_hess(y_pred, y_true):\n    residual = (y_true - y_pred)\n    grad = np.where(\n        residual &lt; 0,\n        (-2 * residual),\n        (-2 * residual) * 2\n    )\n    hess = np.where(\n        residual &lt; 0,\n        2,\n        2 * 2\n    )\n    return grad, hess\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Boosted_Trees/#undefined-hessian","title":"Undefined Hessian","text":"<p>MAE and MAPE don't work as the second derivative is 0, and no learning happens</p>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Boosted_Trees/#option-1-set-hessian-to-1","title":"Option 1: Set hessian to 1","text":"<pre><code># define cost and eval functions\ndef mae(y_pred, y_true):\n    residual = (y_true - y_pred)\n    loss = np.abs(residual)\n    return np.mean(loss)\n\ndef mae_grad_hess(y_pred, y_true):\n    #residual = (y_true - y_pred)\n    grad = np.ones(y_pred.shape) * -2\n    hess = np.ones(y_pred.shape)\n    return grad, hess\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Boosted_Trees/#option-2-randomized-version","title":"Option 2: Randomized version","text":"<pre><code>def quantile_loss(y_true,y_pred,alpha,delta,threshold,var):\n    x = y_true - y_pred\n\n    grad = (x&lt;(alpha-1.0)*delta)*(1.0-alpha)-  ((x&gt;=(alpha-1.0)*delta)&amp; (x&lt;alpha*delta) )*x/delta-alpha*(x&gt;alpha*delta)\n    hess = ((x&gt;=(alpha-1.0)*delta)&amp; (x&lt;alpha*delta) )/delta \n\n    grad = (np.abs(x)&lt;threshold )*grad - (np.abs(x)&gt;=threshold )*(2*np.random.randint(2, size=len(y_true)) -1.0)*var\n    hess = (np.abs(x)&lt;threshold )*hess + (np.abs(x)&gt;=threshold )\n\n    return grad, hess\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Boosted_Trees/#using-sympy","title":"Using sympy","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/Boosted_Trees/#using-autograd","title":"Using autograd","text":"<pre><code>custom_loss_grad_hess = partial(torch_autodiff_grad_hess, custom_loss)\n\n# create model instance\nfrom functools import partial\n\n# custom_loss = torch.nn.MSELoss(reduction=\"sum\") # sum is required; mean does not work\ndef custom_loss(y_pred, y_true):\n  return (\n      (\n          (y_pred-y_true) /\n          y_true\n      ) **2\n      .sum() # sum is required; mean does not work\n  )\n\ndef torch_autodiff_grad_hess(\n    loss,\n    y_true: np.ndarray,\n    y_pred: np.ndarray\n):\n    \"\"\"Perform automatic differentiation to get the\n    Gradient and the Hessian of `loss_function`.\n    \"\"\"\n\n    y_true = torch.from_numpy(y_true)\n    y_pred = torch.from_numpy(y_pred)\n    y_pred.requires_grad_()\n\n    loss_lambda = lambda y_pred: loss(y_pred, y_true)\n\n    grad = torch.autograd.functional.jacobian(\n        loss_lambda,\n        y_pred,\n        vectorize = True,\n    )\n\n    hess_matrix = torch.autograd.functional.hessian(\n        loss_lambda,\n        y_pred,\n        vectorize=True,\n    )\n    hess = torch.diagonal(hess_matrix)\n\n    return grad.numpy(), hess.numpy()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Feature%20Selection/","title":"Feature Selection","text":""},{"location":"Tools/AI%20%26%20Data/Sklearn/Feature%20Selection/#mda","title":"MDA","text":"<pre><code>from sklearn.cross_validation import ShuffleSplit\nfrom sklearn.metrics import r2_score\nfrom collections import defaultdict\n\nX = boston[\"data\"]\nY = boston[\"target\"]\n\nrf = RandomForestRegressor()\nscores = defaultdict(list)\n</code></pre> <pre><code>from joblib import Parallel, delayed\n\nclass FeaturePermutationMetric():\n    def __init__(self, estimator, scoring, scoring_lower_is_better, feature_names=None, random_feature_baseline=None, cv=None, random_state=None, n_repeats_fit = 3, n_repeats_feature_permute = 100, n_jobs=None):\n        self.estimator = estimator\n        self.scoring = scoring\n        self.diff_lower_is_better = not scoring_lower_is_better\n        self.random_feature_baseline = random_feature_baseline if random_feature_baseline is not None else np.random.normal(loc=0, scale=1, size=X.shape[0])\n        self.n_repeats_fit = n_repeats_fit\n        self.n_repeats_feature_permute = n_repeats_feature_permute\n        self.random_state = random_state\n        self.cv = cv if cv is not None else KFold(n_splits=5, random_state=self.random_state)\n        self.feature_names = feature_names\n\n        self.n_jobs = n_jobs if n_jobs is not None else 1\n\n        self.comparison_metric = \"scoring_diff_after_permuting\"\n\n    def get_score_after_permute_(self, X, y, train_idx, test_idx):\n        score_after_permute_list = []\n\n        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n\n        for random_state_fit_i in range(0, self.n_repeats_fit, 1):\n            random_state_fit = self.random_state + random_state_fit_i\n\n            self.estimator_ = clone(self.estimator)\n\n            self.estimator_.set_params(random_state=random_state_fit)\n            self.estimator_.fit(X_train, y_train)\n\n            score_before_permuting = self.scoring(y_test, self.estimator_.predict(X_test))\n\n            for random_state_feature_permuted_i in range(0, self.n_repeats_feature_permute, 1):\n                random_state_feature_permuted = self.random_state + random_state_feature_permuted_i\n                permutation = np.random.default_rng(random_state_feature_permuted).permutation\n\n                for feature_permuted in range(X_train.shape[1]):\n                    X_test_permuted = X_test.copy()\n                    X_test_permuted[:, feature_permuted] = permutation(X_test_permuted[:, feature_permuted])\n\n                    score_after_permuting = self.scoring(y_test, self.estimator_.predict(X_test_permuted))\n                    score_diff_after_permuting = (score_before_permuting - score_after_permuting)\n                    score_diff_perc_after_permuting = score_diff_after_permuting / score_before_permuting\n\n                    score_after_permute_list.append(\n                        [fold, random_state, feature_names[feature_permuted], score_diff_after_permuting, score_diff_perc_after_permuting]\n                    )\n        return score_after_permute_list\n\n    def fit(self, X, y):\n        if self.feature_names is None:\n            try:\n                self.feature_names = X.columns\n            except:\n                raise Exception(\"No feature names passed\")\n                pass\n        if self.random_feature_baseline:\n            self.random_feature_baseline_col_name = \"random_feature_baseline\"\n            feature_names = np.append(feature_names, [random_feature_baseline_col_name])\n            X[random_feature_baseline_col_name] = self.random_feature_baseline\n\n        with sklearn.config_context(\n            assume_finite = True,\n            skip_parameter_validation = True\n        ):\n            cv_results_full = (\n                Parallel(n_jobs = self.n_jobs)\n                (\n                    delayed( get_score_after_permute_ )(X, y, train_idx, test_idx)\n                    for fold, (train_idx, test_idx) in enumerate(self.cv.split(X, y))\n                )\n            )\n        self.cv_results_full_ = pd.DataFrame(\n            columns = [\"fold\", \"random_state\", \"feature_name\", \"score_diff_after_permuting\", \"score_diff_perc_after_permuting\"]\n            data = cv_results_full\n        )\n\n        cv_results_ = (\n            self.cv_results_full_\n            .groupby(\"feature_name\")\n            [\"score_diff_after_permuting\", \"score_diff_perc_after_permuting\"]\n            .agg([\"median\", \"std\", \"min\", \"max\"])\n            .sort(self.comparison_metric, ascending=not self.diff_lower_is_better)\n        )\n\n        self.important_features_ = self.get_important_features_()\n\n        return self\n\n    def get_important_features_(self):\n        variables_diff = self.cv_results_.query(f\"feature_name != {self.random_feature_baseline_col_name}\")[self.comparison_metric][\"median\"]\n        random_baseline_diff = self.cv_results_.query(f\"feature_name = {self.random_feature_baseline_col_name}\")[self.comparison_metric]\n\n        random_baseline_diff_best = (\n            random_baseline_diff\n            [\n                \"max\"\n                if not self.diff_lower_is_better\n                else \"min\"\n            ]\n            .iloc[0]\n        )\n\n        important_features_mask = (\n            variables_diff &gt; random_baseline_best_score\n            if not self.diff_lower_is_better\n            else variables_diff &lt; random_baseline_best_score\n        )\n\n        return self.cv_results_.eval(important_features_mask)\n\n    def transform(self, X, y):\n        check_is_fitted(self, \"important_features_\")\n        return X[self.important_features_], y\n\n    def fit_transform(self, X, y):\n        return self.fit(X, y).transform(X, y)\n</code></pre> <pre><code>fpm = FeaturePermutationMetric(\n    RandomForest(n_estimators=10, max_depth=5, n_jobs=-1),\n    scoring = root_mean_squared_error,\n    scoring_lower_is_better = True,\n    n_repeats_fit = 3,\n    n_repeats_feature_permute = 100,\n    n_jobs = -1,\n    random_state = 0\n)\nfpm.fit_transform(X, y)\nfpm.cv_results_\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Feature%20Selection/#permutation-feature-similarity","title":"Permutation Feature Similarity","text":"<pre><code>def permutation_feature_similarity(X, y, n_estimators=100, random_state=42):\n    # Split the data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n\n    # Train the random forest model\n    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n    rf.fit(X_train, y_train)\n\n    # Calculate baseline accuracy\n    baseline_accuracy = accuracy_score(y_test, rf.predict(X_test))\n\n    n_features = X.shape[1]\n    similarity_matrix = np.zeros((n_features, n_features))\n\n    # Permute each feature and measure impact\n    for i in range(n_features):\n        X_test_permuted = X_test.copy()\n        X_test_permuted[:, i] = np.random.permutation(X_test_permuted[:, i])\n        permuted_accuracy = accuracy_score(y_test, rf.predict(X_test_permuted))\n        accuracy_drop = baseline_accuracy - permuted_accuracy\n\n        # Calculate impact on other features\n        for j in range(n_features):\n            if i != j:\n                X_test_double_permuted = X_test_permuted.copy()\n                X_test_double_permuted[:, j] = np.random.permutation(X_test_double_permuted[:, j])\n                double_permuted_accuracy = accuracy_score(y_test, rf.predict(X_test_double_permuted))\n\n                # Similarity is inversely proportional to additional accuracy drop\n                additional_drop = permuted_accuracy - double_permuted_accuracy\n                similarity = 1 - (additional_drop / accuracy_drop) if accuracy_drop &gt; 0 else 0\n\n                similarity_matrix[i, j] = similarity\n                similarity_matrix[j, i] = similarity  # Symmetric matrix\n\n    return similarity_matrix\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Model%20Selection/","title":"Model Selection","text":"<p>Trick: Treat Model Class as hyperparameter to tune</p> <pre><code>from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n</code></pre> <pre><code>from sklearn.model_selection import RepeatedKFold\n\ninner_cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n</code></pre> <pre><code>from sklearn.pipeline import Pipeline\n\npipe = Pipeline(\n  [\n      (\"preprocessor\", preprocessing_pipeline),\n      ('model', None) # Set None as placeholder\n  ], \n  memory = \"cache_name\" # cache results, especially useful for grid-search\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Model%20Selection/#hyperparameter-tuning","title":"Hyperparameter Tuning","text":"<pre><code>hyperparameter_tuning_params = [\n  dict(\n    preprocessor__vectorizer__ngram_range = [(1, 1), (1, 2)],\n    model = [LinearRegression()],\n    model__penalty = ['l1', 'l2'],\n  ),\n  dict(\n    preprocessor__vectorizer__ngram_range = [(1, 1), (1, 2)],\n    model = [RandomForestRegressor()],\n    model__n_estimators = [1, 2],\n  )\n]\n</code></pre> <pre><code>hyperparameter_tuning_search = RandomizedSearchCV(\n  pipe,\n  param_distributions = hyperparameter_tuning_params,\n  n_iter = 10, # only for random search\n  cv = inner_cv, # RepeatedKFold\n  refit = False, # True forces to refit best model for the entire dataset at the end; pointless if you only want cv results\n  n_jobs = -1,\n  # memory = \"hyperparameter_tuning\" # caching; do not use for RandomSearch\n)\n\nhyperparameter_tuning_search.fit(X_train_inner_val, y_train_inner_val)\n</code></pre> <pre><code>results = pd.DataFrame(hyperparameter_tuning_search.cv_results_)\n</code></pre> <p>Note: Cross-validation estimators are faster than using the model inside CrossValidation, mainly - RidgeCV - LassoCV - LogisticRegressionCV</p> <pre><code>alphas = np.logspace(-2, 2, num=10, base=10)\n\n# as fast as Ridge for a single alpha\nmodel = RidgeCV(\n    alphas = alphas,\n)\n\n# you could nest RidgeCV inside GridSearchCV, using list of alphas as single list item\nmodel = GridSearchCV(\n    RidgeCV(),\n    params = dict(\n        alphas = [alphas],\n    ),\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Model%20Selection/#repeatedsearchcv","title":"RepeatedSearchCV","text":"<p>Should also repeat the gridsearch/randomsearch with different random seed. not required as it is only applicable for randomsearch and will end up giving different estimators, which is not goal of model evaluation</p> <pre><code>class RepeatedSearchCV():\n    def __init__(self, search, randomized_steps=None, n_repeats=3, random_state=None):\n        self.search = search\n        self.randomized_steps = randomized_steps\n        self.random_state = random_state\n        self.n_repeats = n_repeats\n\n        search_params = self.search.get_params()\n        previous_params = search_params[param for param in search_params.keys() if \"param\" in param] # param_grid or param_distribution\n        if randomized_steps is None:\n            estimators = [search_parms[\"estimator\"]]\n            updated_params = previous_params\n            updated_params[\"random_state\"] = [self.random_state + i for i in range(0, n_repeats, 1)]\n        else:\n            estimators = [\n                step_estimator\n                for step_id, step_estimator in search_parms[\"estimator\"].steps\n                if step_id in self.randomized_steps\n                and \"random_state\" in dir(step_estimator)\n            ]\n\n            updated_params = []\n            for previous_param in previous_params:\n                for i in range(0, n_repeats, 1):\n                    temp = previous_param\n                    temp[\"random_state\"] = self.random_state + i\n                    updated_params.append(temp)\n        self.updated_params = updated_params\n\n    def fit(self, X, y):\n        self.search_ = clone(self.search)\n\n        updated_kwargs = {}\n\n        for key, value in self.search_.__dir__.keys():\n          if key in [\"param_grid\", \"param_distribution\"]:\n              updated_kwargs[key] = self.updated_params\n\n          if key == \"n_iter\":\n              updated_kwargs[key] *= self.n_repeats x len(self.randomized_steps)\n\n        self.search_.set_params(**updated_kwargs)\n        self.search_.fit(X, y)\n\n        for key, value in self.search_.__dict__.items():\n           if key.endswith('_'):\n               setattr(self, key, value)\n\n\n    def predict(self, X, y):\n        pass\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sklearn/Model%20Selection/#nestedcv","title":"NestedCV","text":"<pre><code>import time\nfrom sklearn.utils.validation import check_is_fitted, check_array, check_X_y\n\nclass NestedCV():\n  def __init__(self, pipeline, params, inner_cv, outer_cv, n_repeats_fit, scoring, hyperparameter_tuning_niter, min_inner_size=None, random_state=0, refit=True):\n    self.pipeline = pipeline\n    self.params = params\n    self.inner_cv = inner_cv\n    self.outer_cv = outer_cv\n    self.n_repeats_fit = n_repeats_fit\n    self.scoring = scoring\n    self.hyperparameter_tuning_niter = hyperparameter_tuning_niter\n    self.refit = refit\n    self.random_state = random_state\n    self.min_inner_size = min_inner_size\n\n  def fit(self, X, y):\n    check_X_y(X, y)\n\n    best_hyperparameters = []\n    validation_metrics = []\n    train_metrics = []\n    outer_fold = []\n    model_classes = []\n    tested_params = []\n\n    train_durations = []\n    inference_durations = []\n\n    for i, (outer_train_idx, outer_valid_idx) in enumerate(self.outer_cv.split(X, y)):\n\n      for param in self.params:\n\n          for i, (inner_train_idx, inner_valid_idx) in enumerate(self.outer_cv.split(X, y)):\n            if self.min_inner_size is not None and inner_valid_idx.shape[0] &lt; self.min_inner_size:\n              return Exception(\"Not enough samples\")\n\n          # inner\n          hyperparameter_tuning_search = RepeatedSearchCV(\n                RandomizedSearchCV(\n                    self.pipeline,\n                    param_distributions = param,\n                    n_iter = self.hyperparameter_tuning_niter, # only for random search\n                    cv = self.inner_cv, # will split into (inner_train_idx, inner_val_idx)\n                    refit = True, # True forces to refit best model for the entire dataset at the end; required for nested CV; pointless if you only want cv results\n                    n_jobs = -1,\n                    scoring = self.scoring,\n                    random_state = self.random_state + i,\n                ),\n                n_repeats = 3,\n                random_state = 0\n          )\n          hyperparameter_tuning_search.fit(X[outer_train_idx], y[outer_train_idx])\n\n          # outer\n          outer_fold.append(i+1)\n          best_hyperparameter = hyperparameter_tuning_search.best_estimator_\n          best_hyperparameters.append(best_hyperparameter)\n\n          tested_params.append(param)\n\n          model_class = best_hyperparameter.steps[-1][1].__class__.__name__\n          model_classes.append(model_class)\n\n          train_duration = hyperparameter_tuning_search.refit_time_ / outer_train_idx.shape[0]\n          train_durations.append(train_duration)\n\n          train_metric = hyperparameter_tuning_search.score(X[outer_train_idx], y[outer_train_idx])\n          train_metrics.append(train_metric)\n\n          inference_start_time = time.time()\n          validation_metric = hyperparameter_tuning_search.score(X[outer_valid_idx], y[outer_valid_idx])\n          inference_end_time = time.time()\n\n          validation_metrics.append(validation_metric)\n\n          inference_duration = (inference_end_time - inference_start_time) / outer_valid_idx.shape[0]\n          inference_durations.append(inference_duration)\n\n    df = (\n        pd.DataFrame()\n        .assign(\n          outer_fold = outer_fold,\n          model_class = model_classes,\n          model = best_hyperparameters,\n          tested_params = tested_params,\n          train_metrics = train_metrics,\n          validation_metrics = validation_metrics,\n          train_duration_per_row = train_durations,\n          inference_duration_per_row = inference_durations\n        )\n    )\n\n    def my_func(x, statistics=[\"mean\", \"std\"]):\n      temp = x.agg(statistics)\n      return temp.iloc[0].round(4).astype(str) + \" \u00b1 \" + temp.iloc[1].round(4).astype(str)\n\n    summary = (\n        df\n        .groupby(\"model_class\")\n        [[\"train_metrics\", \"validation_metrics\", \"train_duration_per_row\", \"inference_duration_per_row\"]]\n        .agg(my_func)\n    )\n\n    self.cv_results_ = summary.to_dict()\n\n    if self.refit:\n\n      best_model_class = (\n          df\n          .groupby(\"model_class\")\n          [\"validation_metrics\"]\n          .mean()\n          .idxmax()\n      )\n\n      best_row = (\n          df[\n              df[\"model_class\"] == best_model_class\n          ]\n          .iloc[0]\n      )\n\n      best_model = best_row[\"model\"]\n      best_params_search = best_row[\"tested_params\"]\n\n      best_model_hyperparameter_search_ = RandomizedSearchCV(\n          best_model,\n          param_distributions = best_params_search,\n          n_iter = self.hyperparameter_tuning_niter, # only for random search\n          cv = self.inner_cv, # will split into (inner_train_idx, inner_val_idx)\n          refit = True, # True forces to refit best model for the entire dataset at the end; required for nested CV; pointless if you only want cv results\n          n_jobs = -1,\n          scoring = self.scoring,\n          random_state = self.random_state,\n          # memory = \"hyperparameter_tuning\" # caching; do not use for RandomSearch\n      )\n      best_model_hyperparameter_search_.fit(X, y)\n\n      for key, value in best_model_hyperparameter_search_.__dict__.items():\n           if key.endswith('_'):\n               setattr(self, key, value)\n      # self.best_params_ = best_model_hyperparameter_search_.best_params_\n      # self.best_estimator_ = best_model_hyperparameter_search_.best_estimator_\n      # self.score = best_model_hyperparameter_search_.score\n\n    return self\n</code></pre> <pre><code>pipeline = Pipeline(\n  [\n    ('model', None) # Set None as placeholder\n  ],\n#  memory = \"cache_name\" # cache results, especially useful for grid-search\n)\n\nparams = [\n  dict(\n    model = [RandomForestClassifier()],\n    model__n_estimators = np.arange(2, 10),\n  ),\n  dict(\n    model = [HistGradientBoostingClassifier()],\n    model__max_iter = np.arange(2, 10),\n  )\n]\n</code></pre> <pre><code>nestedcv = NestedCV(\n    pipeline = pipeline,\n    params = params,\n    inner_cv = RepeatedKFold(n_splits=2, n_repeats=1, random_state=0),\n    outer_cv = RepeatedKFold(n_splits=2, n_repeats=1, random_state=0),\n    inner_search_cv = ,\n    outer_search_cv = ,\n    final_search_cv = ,\n    n_repeats_fit = 3,\n    hyperparameter_tuning_niter = 1,\n    scoring = \"f1\",\n    random_state = 0,\n    refit = True,\n)\n</code></pre> <pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y)\n</code></pre> <pre><code>nestedcv.fit(X_train, y_train)\npd.DataFrame(nestedcv.cv_results_)\n\nprint(nestedcv.score(X_train, y_train))\nprint(nestedcv.score(X_test, y_test))\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sktime/","title":"Index","text":""},{"location":"Tools/AI%20%26%20Data/Sktime/#references","title":"References","text":"<ul> <li> Abhishek Murthy - Backtesting Time Series Forecasting Algorithms in SKTime and SKForecast</li> <li> Sktime | PyData Global 2023</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Sktime/01_Introduction/","title":"Introduction","text":"<pre><code># define model\nregressor = RandomForestRegressor()\n\n# transform to tabular form\nfeatures_no_of_lags = 3 # {1, 2, 3}\nforecaster = make_reduction(\n    regressor,\n    window_length = features_no_of_lags,\n    strategy = \"recursive\"\n)\n</code></pre> <pre><code>forecast_horizon = np.arange(1, 5)\n\ncv_expanding = ExpandingWindowSplitter(\n    initial_window = 24*10,\n    step_length = 24,\n    fh = forecast_horizon,\n)\n\ncv_expanding = SlidingWindowSplitter(\n    window_length = 24*10,\n    step_length = 24,\n    fh = forecast_horizon,\n)\n</code></pre> <pre><code>results = evaluate(\n    forecaster = forecaster,\n    y = y_train,\n    cv = cv,\n    return_data = True,\n    strategy = \"refit\" # [\"refit\", \"update\"]\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/","title":"StatsModels","text":""},{"location":"Tools/AI%20%26%20Data/StatsModels/#references","title":"References","text":"<ul> <li> Statsmodels | Data Science for Everyone</li> </ul>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/","title":"Introduction","text":""},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#imports","title":"Imports","text":"<pre><code>from statsmodels import api as sm\nfrom statsmodels.formula import api as smf\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#transformation","title":"Transformation","text":"<pre><code>X = sm.add_constant(X) # add intercept\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#train","title":"Train","text":""},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#equation","title":"Equation","text":"<pre><code>equation = \"y ~ x\"\nequation = \"y ~ x - 1\" # remove intercept\n\n# multi-variate\nequation = \"y ~ x + x^2\"\nequation = \"y ~ x_1 + x_2\"\n\n# non-linear\nequation = \"np.log(y) ~ t - 1\"\n\n# embedding external function - i don't like this\nequation = \"y ~ x_1 + np.log(x_2)\"\nequation = \"y ~ x_1 + custom_function(x_2)\"\n\n# categorical\nequation = \"y ~ x_1 + C(x_categorical)\"\n\n# interactions\nequation = \"y ~ x_1 * x_2\" # x_1 + x_2 + x_1:x_2\nequation = \"y ~ x_1:x_2\" # only x_1:x_2\n</code></pre> <pre><code>model = smf.ols(equation, data = df)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#regular-method","title":"Regular Method","text":"<pre><code>model = sm.OLS(y, X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#regular-method-with-equation","title":"Regular Method with Equation","text":"<pre><code>import patsy\ny, X = patsy.dmatrices(\n    equation,\n    data = df,\n    return_type = \"dataframe\"\n)\n# regular method\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#print-results","title":"Print Results","text":"<pre><code>result = model.fit(exog = X, endog = y)\n\nalpha = 0.05\nsig = alpha/X.shape[0] # bonferroni-correction\nres.summary(alpha = sig)\n\nres.predict(X_test) # sf\nres.predict(df_test) # smf\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#confidence-intervals","title":"Confidence Intervals","text":"<pre><code>from statsmodels.sandbox.regression import predstd\n\nstd, upper, lower = predstd.wls_prediction_std(model)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/StatsModels/01_Introduction/#sklearn-wrapper","title":"Sklearn Wrapper","text":"<pre><code>from sklearn.base import BaseEstimator, RegressorMixin, ClassifierMixin\nfrom sklearn.utils.validation import check_is_fitted, check_array, check_X_y\n\nclass SMWrapper(BaseEstimator):\n    \"\"\"\n    A universal sklearn-style wrapper for statsmodels regressors\n    \"\"\"\n\n    def __init__(self, estimator, fit_intercept=True, **init_params):\n        self.estimator = estimator\n        self.fit_intercept = fit_intercept\n        self.init_params = init_params\n\n    def fit(self, X, y, **fit_params):\n\n        if self.fit_intercept:\n            X = sm.add_constant(X)\n\n        # Check that X and y have correct shape\n        X, y = check_X_y(X, y)\n\n        self.estimator_ = self.estimator(\n            exog = X,\n            endog = y,\n            **self.fit_params\n        )\n        self.results_ = self.estimator_.fit()\n\n        return self\n\n    def predict(self, X):\n        # Check is fit had been called\n        check_is_fitted(self, 'estimator_')\n\n        # Input validation\n        X = check_array(X)\n\n        if self.fit_intercept:\n            X = sm.add_constant(X)\n\n        return self.results_.predict(X)\n\n    def summary(self, **summary_params):\n        return self.results_.summary(**summary_params)\n\nclass SMRegressor(RegressorMixin, SMWrapper):\n    def __init__(self, estimator, fit_intercept=True, **init_params):\n        super().__init__(estimator, fit_intercept, **init_params)\n\nclass SMClassifier(ClassifierMixin, SMWrapper):\n    def __init__(self, estimator, fit_intercept=True, **init_params):\n        super().__init__(estimator, fit_intercept, **init_params)\n</code></pre> <pre><code># Model Definition\nmodel = SMRegressor(sm.OLS)\n# model = SMRegressor(sm.GLS, sigma = sigma)\n\n# Training\nmodel.fit(X, y)\n\nalpha = 0.05\nsig = alpha/X.shape[1] # bonferroni-correction\nprint(model.summary(alpha=sig))\n\n# Inference\nmodel.predict(X)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/","title":"Sympy","text":""},{"location":"Tools/AI%20%26%20Data/Sympy/#import","title":"Import","text":"<pre><code>import sympy as smp\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#basics","title":"Basics","text":"<p>Declaring symbols</p> <pre><code>x = smp.symbols(\"x\")\nx = smp.symbols(\"x\", real=True, positive=True)\n\nx, y, z = smp.symbols(\"x y z\")\n</code></pre> <p>Declaring functions</p> <pre><code>f = smp.symbols(\"f\", cls=smp.Function)\n</code></pre> <p>Numbers</p> <pre><code>x = smp.Rational(5, 1)\nfrac = smp.Rational(1, 2)\n</code></pre> <p>Useful Functions</p> <pre><code>y = smp.sin(x)\nz = x**2 + y**2\n</code></pre> <pre><code>z.factor()\nz.expand()\nz.simplify()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#solve","title":"Solve","text":"<pre><code>smp.solve(z, x) ## find value of x that makes z(x) = 0 \nsmp.solve(z, y)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#convert-to-numerical","title":"Convert to Numerical","text":"<p>Lambdify</p> <pre><code>expr = smp.sin(x) + smp.sin(y)\nexpr_f = smp.lambdify([x, y], expr)\n</code></pre> <p>Substitute</p> <pre><code>expr = smp.sin(x) + smp.sin(y)\nexpr.subs([\n    (x, 10)\n])\nexpr.subs([\n  (x, 10),\n  (y, 5)\n])\nexpr.subs([\n  (x, 10),\n  (y, smp.sin(x))\n])\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#calculus","title":"Calculus","text":""},{"location":"Tools/AI%20%26%20Data/Sympy/#differentiation","title":"Differentiation","text":"<pre><code>dfdx = smp.diff(f) ## f = function symbol, which is a function of  \ndfdx_sub = dfdx.sub([\n    (g, smp.sin(x))\n])\n\ndfdx_sub_value = dfdx_sub.doit()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#integration","title":"Integration","text":"<p>Indefinite</p> <pre><code>## does not give +c\nsmp.integrate(\n  expr,\n  x\n)\n</code></pre> <p>Definite</p> <pre><code>smp.integrate(\n  expr,\n  (x, 0, smp.log(4))\n)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#vectors","title":"Vectors","text":"<pre><code>u1, u2, u3 = smp.symbols(\"u1 u2 u3\")\nu = smp.Matrix([u1, u2, u3])\n\nv1, v2, v3 = smp.symbols(\"v1 v2 v3\")\nv = smp.Matrix([v1, v2, v3])\n</code></pre> <pre><code>2*u + v\nu.norm()\n\nu.dot(v)\nu.cross(v)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#fourier-transform-analytic","title":"Fourier Transform (Analytic)","text":""},{"location":"Tools/AI%20%26%20Data/Sympy/#continuous-time-frequency","title":"Continuous Time &amp; Frequency","text":"<pre><code># symbols need to be defined with correct characteristics\n\nt, f = smp.symbols(\"t, f\", real=True)\nk = smp.symbols(\"k\", real=True, positive=True)\nx = smp.exp(-k * t**2) * k * t\nx\n</code></pre> <pre><code>from sympy.integrals.transforms import fourier_transform as ft\nx_FT = ft(x, t, f)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Sympy/#continuous-time-discrete-frequency","title":"Continuous Time &amp; Discrete Frequency","text":"<pre><code>t = smp.symbols(\"t\", real=True)\nk, n, T = smp.symbols(\"k, n, T\", real=True, positive=True)\nfn = n/T\nx = smp.exp(-k * t)\n</code></pre> <pre><code>x_FT = smp.integrate(\n  1/T * x * smp.exp(-2*smp.pi*smp.I*fn*t),\n  (t, 0, T)\n).simplify()\n</code></pre> <pre><code>get_FT = smp.lambdify([k, T, n], x_FT)\nns = np.arange(0, 20, 1)\nxFT = get_FT(k=1, T=4, n=ns)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/","title":"TensorFlow","text":"TensorFlow TensorFlow Lite TensorFlow Lite Micro TensorFlow.js TensorFlowServing Usage Model development Deployment to Microprocessors (laptops, mobile phones, RaspberryPi) Deployment to Microcontrollers Deployment to Web Cloud, On-Prem Optimized for X86TPUGPU X86ARM Cortex A ARM Cortex MDSPMCU Browser &amp; Node User ML researcher Application developer Supports training \u2705 \u274c \u274c \u274c \u274c Supports inference \u2705(inefficient) \u2705 \u2705 \u2705 \u2705 No of ops supported ~1400 ~130 ~50 Native quantization support \u274c \u2705 \u2705 OS-independent(No OS required) \u274c \u274c \u2705 Memory mapping of models \u274c \u2705 \u2705 Delegation to accelerators \u2705 \u2705 \u274c Distributed compute Needed Not needed Not needed Binary size &gt; 3MB 100KB ~10KB Base memory footprint ~ 5MB 300KB 20KB Weights Variable Fixed TopologyNeuron connections Variable Fixed"},{"location":"Tools/AI%20%26%20Data/Tensorflow/#references","title":"References","text":"<ul> <li> Learn TensorFlow and Deep Learning (beginner friendly code) | Daniel Bourke</li> <li> Python in Data Science for Advanced - Deep Learning with Keras &amp; TensorFlow | LearnDataa</li> <li> Zero to Deployment - Deep Learning | Aladdin Persson</li> </ul>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/01_TF/","title":"TensorFlow","text":""},{"location":"Tools/AI%20%26%20Data/Tensorflow/01_TF/#basics","title":"Basics","text":"<pre><code>from tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score\n</code></pre> <pre><code>model = Sequential()\nmodel.add(Dense(units=32, activation='relu', input_dim=len(X_train.columns)))\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(units=1, activation='sigmoid'))\n</code></pre> <pre><code>model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')\n</code></pre> <pre><code>model.fit(X_train, y_train, epochs=200, batch_size=32)\n</code></pre> <pre><code>pred = model.predict(X_test)\npred = np.where(\n  pred &gt; 0.5,\n  1,\n  0\n)\n</code></pre> <pre><code>model.save('tfmodel')\ndel model\nmodel = load_model('tfmodel')\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/02_TFL/","title":"TensorFlow Lite","text":""},{"location":"Tools/AI%20%26%20Data/Tensorflow/02_TFL/#quantization-aware-training","title":"Quantization-Aware Training","text":"<pre><code>from tensorflow_model_optimization.quantization.keras import quantize_model\n\nq_aware_model = quantize_model(model) # untrained model\n\nq_aware_model.compile(\n    # ...\n)\n\nq_aware_model.fit()\nq_aware_model.evaluate()\nq_aware_model.predict()\n\n# perform post-training optimization\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/02_TFL/#post-training-optimization","title":"Post-Training Optimization","text":"<pre><code>tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n\n# ... optimization\n\ntflite_model = tf_lite_converter.convert()\n\nwith open(\"model.tflite\", \"wb\") as f:\n    f.write(tflite_model)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/02_TFL/#quantization","title":"Quantization","text":"<pre><code>tf_lite_converter.target_spec.supported_types = [\n    tf.int8\n]\ntf_lite_converter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS_INT8\n]\ntf_lite_converter.optimizations = [\n    # tf.lite.Optimize.DEFAULT,\n    tf.lite.Optimize.OPTIMIZE_FOR_SIZE,\n    # tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n]\n\ndef representative_data_gen():\n    for input_value, _ in test_batches.take(100):\n        yield [input_value]\n\ntf_lite_converter.representative_dataset = representative_data_gen\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/02_TFL/#evaluating-model","title":"Evaluating model","text":"<p>Testing the model without edge device</p> <pre><code>interpreter = tf.lite.Interpreter(model_content = tflite_model)\ninterpreter.allocate_tensors()\n\ninput_details = interpreter.get_input_details()\noutput_details = interpreter.get_output_details()\n\nprint(input_details)\nprint(output_details)\n</code></pre> <pre><code>x_new = np.array(\n    [\n        [10.0, 5.0],\n        [5.0, 5.0],\n    ],\n    dtype=np.float32\n)\n\ninterpreter.set_tensor(\n    input_details[0][\"index\"],\n    x_new\n)\n\ninterpreter.invoke()\n\ntflite_results = interpreter.get_tensor(output_details[0][\"index\"])\nprint(tflite_results)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/03_TFLM/","title":"TensorFlow Lite Micro","text":"<p>Built to fit ML on embedded systems</p> <ul> <li>Very small binary footprint</li> <li>No dynamic memory allocation</li> <li>No dependencies on complex parts of the standard C/C++ libraries</li> <li>No operating system dependencies, can run on bare metal</li> <li>Designed to be portable across a wide variety of systems</li> </ul> <p></p>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/03_TFLM/#components","title":"Components","text":"<ul> <li>Core functionality (&lt; 20 KB)<ul> <li>Model loading</li> <li>Error reporting</li> <li>Memory planner</li> <li>...</li> </ul> </li> <li>Model operators: select which operators required<ul> <li>conv2D</li> <li>conv3D</li> <li>tanh</li> <li>sigmoid</li> <li>...</li> </ul> </li> </ul>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/03_TFLM/#steps","title":"Steps","text":"<pre><code>flowchart LR\nOpResolver --&gt;\nInterpreter --&gt;\nid[Input Data] --&gt;\nInvoke --&gt;\nod[Output Data] --&gt;\nAction --&gt;\nid</code></pre> <p>Initialization 1. Declare variables 2. Load model 3. Resolve operators 4. Initialize interpreter 5. Allocate arena 6. Define model inputs 7. Set up main loop</p>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/03_TFLM/#interpreter","title":"Interpreter","text":"<p>Store the model as data and loop through its ops at runtime - Interpreter overhead is very low due to complex instructions of the ML part; hence, no advantage in using compiler</p> <p>Advantages - Change the model without recompiling code - Same operator code can be used across multiple different models in the system - Same portable model serialization format can be used across a lot of systems</p>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/03_TFLM/#model-format","title":"Model Format","text":"<p><code>g_model</code> - Array of bytes   - Acts as equivalent of a file on disk   - Flatbuffer format - Holds all info about   - model   - operators   - connections   - trained weights</p>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/03_TFLM/#how-tfl-micro-solves-tinyml-challenges","title":"How TFL micro solves TinyML challenges","text":"<ul> <li>Ask developers to supply a contiguous array of memory \"arena\" to interpreter<ul> <li>The framework avoids any other memory allocations</li> </ul> </li> <li>Framework guarantees that it won\u2019t allocate from this \u201carena\u201d after initialization, so long-running applications won\u2019t fail due to to fragmentation</li> <li>Ensures<ul> <li>clear budget for the memory used by ML</li> <li>framework has no dependency on OS facilities needed by <code>malloc</code> or <code>new</code></li> </ul> </li> </ul> <p>Size of tensor arena - Operator variables - Interpreter state - Operator I/O</p> <p>Finding ideal size of arena</p> <ul> <li>Trial and error</li> <li>Create as large an arena as possible</li> <li>Use <code>arena_used_bytes()</code> to find actual size used</li> <li>Resize arena to this length and rebuild</li> <li>Best to do this for every deployment platform, since different op implementations may need varying scratch buffer sizes</li> </ul> <p>Ops specification</p> <p></p>"},{"location":"Tools/AI%20%26%20Data/Tensorflow/03_TFLM/#idk","title":"IDK","text":""},{"location":"Tools/AI%20%26%20Data/httpx/","title":"httpx","text":"<pre><code># requirements\nhttpx[http2]\naiolimiter\n</code></pre> <pre><code>async def get_data(client, limiter, series):\n  async with limiter:\n    response = await client.get(\n        URL_BASE + ENDPOINT + series,\n        params = params\n    )\n\n  return response.json()\n\n\nasync with httpx.AsyncClient(http2=True) as client:\n  limiter = AsyncLimiter(\n    10,     # asynchronous requests\n    1       # delay in s\n  )\n\n  tasks = []\n\n  for series in series_list:\n      tasks.append(asyncio.create_task(\n          get_data(client, limiter, series)\n      ))\n\n  data = await asyncio.gather(*tasks)\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/pywav/","title":"PyWavelets","text":"<pre><code>pip install pywavelets\n</code></pre> <pre><code>import pywt\nimport numpy as np\n</code></pre> <pre><code># wavelet decomposition\ncoeffs = pywt.wavedec(y, 'sym5', mode='symmetric')\n\ny_rec = pywt.waverec(coeffs, 'sym5', mode='symmetric')[1:]\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/pywav/#smoothing","title":"Smoothing","text":"<pre><code>def smooth_with_wavelets(y):\n    \"\"\"\n    FUNCTION TO SMOOTH SIGNAL VIA WAVELET DECOMPOSITION\n\n    INPUTS:\n    - y = array-like signal to smooth\n\n    OUTPUTS:\n    - y_rec = smoothed version of input signal\n\n    DEPENDENCIES:\n    - PyWavelets 1.3.0\n    - numpy 1.21.5\n\n    CODE AUTHORED BY: SHAWHIN TALEBI\n    \"\"\"\n\n\n    # wavelet decomposition\n    coeffs = pywt.wavedec(y, 'sym5', mode='symmetric')\n\n    # zero out last 5 detail coefficents\n    for i in range(5):\n        coeffs[i+5] = np.zeros(coeffs[i+5].shape)\n\n    # wavelet recomposition\n    y_rec = pywt.waverec(coeffs, 'sym5', mode='symmetric')[1:]\n\n    return y_rec\n</code></pre> <pre><code>y_smoothed = smooth_with_wavelets(y)\n</code></pre> <pre><code># plot result\nplt.figure(figsize=(24,8))\nplt.rcParams.update({'font.size': 16})\nplt.plot(x, y, x, y_smoothed, linewidth=2)\nplt.legend(['original', 'smoothed'])\nplt.savefig('smoothed_signal_plot.png', facecolor='white')\nplt.show()\n</code></pre>"},{"location":"Tools/AI%20%26%20Data/pywav/#references","title":"References","text":"<ul> <li> https://www.youtube.com/watch?v=gd6oUg608FI</li> <li> https://medium.com/@shouke.wei/how-to-plot-filter-bank-of-a-disctete-wavelet-in-python-42fbb6eb418d</li> <li> https://www.kaggle.com/code/asauve/a-gentle-introduction-to-wavelet-for-data-analysis</li> </ul>"},{"location":"Tools/API/FastAPI/","title":"FastAPI","text":"<p>Python package to create REST APIs </p> <ul> <li>Easy to learn &amp; use</li> <li>Fast development</li> <li>Async -&gt; High performance</li> <li>Automatic Documentation</li> </ul>"},{"location":"Tools/API/FastAPI/#installation","title":"Installation","text":"<pre><code>pip install fastapi uvicorn\n</code></pre>"},{"location":"Tools/API/FastAPI/#execution","title":"Execution","text":"<pre><code>uvicorn main:app --reload\n</code></pre>"},{"location":"Tools/API/FastAPI/#docs","title":"Docs","text":"<p>Go to</p> <ul> <li><code>http://127.0.0.1/8000/docs</code></li> </ul> <p>or</p> <ul> <li><code>http://127.0.0.1/8000/redoc</code></li> </ul> <p>or</p> <ul> <li><code>http://127.0.0.1/8000/openapi.json</code></li> </ul>"},{"location":"Tools/API/FastAPI/#imports","title":"Imports","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\n</code></pre>"},{"location":"Tools/API/FastAPI/#basic-app","title":"Basic App","text":"<pre><code>app = FastAPI()\n\n\nclass Item(BaseModel):\n    text: str = None\n    is_done: bool = False\n\n\nitems = []\n\n\n@app.get(\"/\")\ndef root():\n    return {\"Hello\": \"World\"}\n\n\n@app.post(\"/items\")\ndef create_item(item: Item):\n    items.append(item)\n    return items\n\n\n@app.get(\"/items\", response_model=list[Item])\ndef list_items(limit: int = 10):\n    return items[0:limit]\n\n\n@app.get(\"/items/{item_id}\", response_model=Item)\ndef get_item(item_id: int) -&gt; Item:\n    if item_id &lt; len(items):\n        return items[item_id]\n    else:\n        raise HTTPException(status_code=404, detail=f\"Item {item_id} not found\")\n</code></pre>"},{"location":"Tools/API/FastAPI/#return-files","title":"Return Files","text":"<pre><code>import os\n\nfrom fastapi import FastAPI \nfrom fastapi.responses import FileResponse\n\napp = FastAPI()\n\npath = \"/home/anthony/fastapifileexample\"\n\n@app.get(\"/\")\ndef index():\n    return {\"Hello\": \"World\"}\n\n@app.get(\"/cat\", responses={200: {\"description\": \"A picture of a cat.\", \"content\" : {\"image/jpeg\" : {\"example\" : \"No example available. Just imagine a picture of a cat.\"}}}})\ndef cat():\n    file_path = os.path.join(path, \"files/cat.jpg\")\n    if os.path.exists(file_path):\n        return FileResponse(file_path, media_type=\"image/jpeg\", filename=\"mycat.jpg\")\n    return {\"error\" : \"File not found!\"}\n</code></pre>"},{"location":"Tools/API/Flask/","title":"Flask","text":"<pre><code>from flask import (\n    Flask,\n    request,\n    send_file\n)\n\napp = Flask(__name__)\n\n@app.route('/badge-going')\ndef return_badge_going():\n    # badge_type = request.args.get('badge_type')\n    file_name = \"badge_going.jpg\"\n    try:\n        return send_file(\n            f\"./{file_name}\",\n            # attachment_filename = file_name\n        )\n    except Exception as e:\n        return str(e)\n</code></pre>"},{"location":"Tools/API/Robyn/","title":"RobynAPI","text":"<p>Similar to FastAPI but written in Rust</p>"},{"location":"Tools/API/Robyn/#workers-flag","title":"Workers Flag","text":"<pre><code>python app.py --workers=5\n</code></pre> <p><code>--workers</code> flag allows Robyn to serve a higher throughput. Default 1 is set for prototyping/development</p>"},{"location":"Tools/App_Dev/Streamlit/","title":"Streamlit","text":""},{"location":"Tools/App_Dev/Streamlit/01_Introduction/","title":"Introduction","text":""},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#structure","title":"Structure","text":"<pre><code>.\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 app\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 components.py\n\u2502   \u251c\u2500\u2500 p0.py\n\u2502   \u251c\u2500\u2500 p1.py\n\u2502   \u251c\u2500\u2500 p2.py\n\u2502   \u2514\u2500\u2500 p3.py\n\u251c\u2500\u2500 assets\n\u2502   \u2514\u2500\u2500 doe.svg\n\u251c\u2500\u2500 data\n\u2502   \u251c\u2500\u2500 foo.xlsx\n\u2502   \u2514\u2500\u2500 bar.xlsx\n\u251c\u2500\u2500 main.py\n\u251c\u2500\u2500 requirements.txt\n\u251c\u2500\u2500 styles.css\n\u2514\u2500\u2500 utils\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 custom_regression.py\n    \u251c\u2500\u2500 data.py\n    \u251c\u2500\u2500 math.py\n    \u251c\u2500\u2500 model.py\n    \u251c\u2500\u2500 models.py\n    \u251c\u2500\u2500 plots.py\n    \u2514\u2500\u2500 regression.py\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#files","title":"Files","text":""},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#mainpy","title":"<code>main.py</code>","text":"<pre><code>import app\n\nimport utils\nfrom utils import regression, models, custom_regression, plots\n# Not the best way to import, but it's convenient. Please make this nicer\n\nimport gc\nimport glob\n\nimport streamlit as st\n\ndef main():\n    st.set_page_config(\n        layout=\"wide\",\n        page_title=app.TITLE,\n    )\n\n    st.markdown(f\"\"\"\n    &lt;style&gt;\n    {utils.get_styles()}\n    &lt;/style&gt;\n    \"\"\", unsafe_allow_html=True)\n\n    gc.set_threshold(0) # disable garbage collection\n    app.main()\n    gc.collect() # collect manually after every execution, to avoid memory issues\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#stylescss","title":"<code>styles.css</code>","text":"<pre><code>.block-container {\n    padding-top: 1rem;\n    padding-bottom: 1rem;\n    padding-left: 1.5rem;\n    padding-right: 1.5rem;\n}\n[data-testid=\"stHeader\"]\n{\n    display: none !important\n}\n[data-testid=\"stSidebarHeader\"] {\n    position: absolute;\n    top: 0;\n    right: 0;\n    z-index: 10;\n}\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#utils__init__py","title":"<code>utils/__init__.py</code>","text":"<pre><code>@st.cache_data(ttl=60*60)\ndef get_styles():\n    with open(\"styles.css\", \"r\") as f:\n        styles = f.read()\n    return styles\n\n\ndef get_page_title(menu_selected_external, menu_selected_internal):\n    header = (\n        menu_selected_external +\n        (\": \" + menu_selected_internal if menu_selected_internal is not None else \"\")\n    )\n    st.subheader(header)\n\n\ndef internal_navigation(menu_selected_external, menu_options_external):\n    # with st.sidebar:\n    #     st.divider()\n\n    menu_options_internal_mappings = {\n        0: [\n\n        ],\n        1: [\n            \"Foo\",\n            \"Bar\"\n        ],\n    }\n    menu_options_internal = (\n        menu_options_internal_mappings\n        .get(menu_options_external.index(menu_selected_external), [])\n    )\n    # menu_selected_internal = st.radio(\n    #     label=\"Sub Menu\",\n    #     label_visibility = \"visible\",\n    #     options=menu_options_internal\n    # )\n\n    menu_selected_internal = option_menu( # st.radio\n        menu_title = None, # \"Menu\",\n        options = menu_options_internal,\n        orientation = \"horizontal\",\n        styles = {\n            \"container\": {\"margin\": \"0 !important\", \"padding\": \"0 !important\"}, # , \"background\": \"none\"\n            \"nav\": {\"font-size\": \"0.75em\"},\n            \"icon\": {\"display\": \"none\"},\n            \"nav-link\": {\"margin\":\"0\", \"padding\": \"0.5ex 1.5ex\"},\n        },\n    )\n\n    return menu_selected_internal, menu_options_internal\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#app__init__py","title":"<code>app/__init__.py</code>","text":"<pre><code>import utils\nfrom utils import data, regression, custom_regression, models, plots\n\nfrom app import (\n    components,\n    p0,\n    p1,\n    p2,\n    p3\n)\n\nimport streamlit as st\nfrom streamlit_option_menu import option_menu\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nfrom sklearn.metrics import (\n    mean_absolute_percentage_error as mape,\n    # mean_squared_error as mse,\n    root_mean_squared_error as rmse,\n    mean_absolute_error as mae,\n    r2_score as r2\n)\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nTITLE = \"Chemical Kinetics Modelling\"\n\ndef main():\n    data = utils.data # why???\n\n    menu_options_external = [\n        \"Home\",\n          \"Foo\",\n        \"Bar\",\n    ]\n\n    with st.sidebar:\n        st.title(TITLE)\n        # menu_selected_external = st.radio(\n        #     \"Menu\",\n        #     menu_options_external,\n        #     label_visibility = \"collapsed\"\n        # )\n    menu_selected_external = option_menu( # st.radio\n        menu_title = None, # \"Menu\",\n        options = menu_options_external,\n        orientation = \"horizontal\",\n        styles = {\n            \"container\": {\"margin\": \"0 !important\", \"padding\": \"0 !important\",},  # \"background\": \"none\"\n            \"nav\": {\"font-size\": \"0.75em\"},\n            \"icon\": {\"display\": \"none\"},\n            \"nav-link\": {\"margin\":\"0\", \"padding\": \"0.5ex 1.5ex\"},\n        }\n        # label_visibility = \"collapsed\"\n    )\n\n    if menu_selected_external == menu_options_external[0]:\n        p0.main()\n\n    menu_selected_internal, menu_options_internal = utils.internal_navigation(menu_selected_external, menu_options_external)\n\n    utils.get_page_title(menu_selected_external, menu_selected_internal)\n\n    if menu_selected_external == menu_options_external[1]:\n        p1.main(menu_selected_internal, menu_options_internal)\n\n    if menu_selected_external == menu_options_external[2]:\n        p2.main(menu_selected_internal, menu_options_internal, df)\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#p1py","title":"<code>p1.py</code>","text":"<pre><code>from utils import data\nimport streamlit as st\n\ndef main(menu_selected_internal, menu_options_internal):\n    if menu_selected_internal == menu_options_internal[0]:\n        st.dataframe(\n            data.get_details().collect(),\n            use_container_width=True,\n            hide_index=True\n        )\n    elif menu_selected_internal == menu_options_internal[1]:\n        st.dataframe(\n            data.get_readings().collect(),\n            use_container_width=True,\n            hide_index=True\n        )\n    st.stop()\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/01_Introduction/#appcomponentspy","title":"<code>app/components.py</code>","text":"<pre><code>import streamlit as st\nimport utils\n\ndef input_filters(df, menu_selected_external, menu_options_external, menu_selected_internal, menu_options_internal):\n    with st.sidebar:\n        # st.divider()\n        st.subheader(\"Data Input Filters\")\n\n        filter_cols = [\"Study_Identifier\", \"Temperature\"] # , \"Sample_Identifier\"\n        filters_selected = {}\n\n        n_cols = 3\n        cols = st.columns([2, 1])\n        current_col = 0\n        for col in filter_cols:\n            comparison_page == (menu_selected_external==menu_options_external[3] and menu_selected_internal==menu_options_external[2])\n\n            with cols[current_col]:\n                if (\n                    (col == filter_cols[0] and not comparison_page)\n                    or\n                    (col == filter_cols[1] and comparison_page)\n                ):\n                    single_only = True\n                else:\n                    single_only = False\n\n                filters_selected.update({\n                    col: generate_filter(df, col, single_only)\n                })\n                current_col = (current_col+1)%n_cols\n\n    keys = list(filters_selected.keys())\n    values = list(filters_selected.values())\n\n    return keys, values\n\ndef generate_filter(df, col, single_only=False):\n    \"\"\"\n    returns list for modularity and ease\n    \"\"\"\n\n    options = generate_options(df, col)\n\n    if single_only:\n        selected = [st.selectbox(\n            label = col.split(\"_\")[0],\n            options = options\n        )]\n    else:\n        selected = st.multiselect(\n            label = col.split(\"_\")[0],\n            options = options\n        )\n    if len(selected) == 0:\n        selected = options\n\n    return selected\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/02_Standalone/","title":"Standalone","text":""},{"location":"Tools/App_Dev/Streamlit/02_Standalone/#prerequisites","title":"Prerequisites","text":"<p>Before we get started, make sure you have the following libraries:</p> <pre><code>pip install cx_Freeze  \npip install streamlit\n</code></pre> <p>cx_Freeze\u00a0creates standalone executables from Python scripts, with the same performance, is cross-platform and should work on any platform that Python itself works on.</p>"},{"location":"Tools/App_Dev/Streamlit/02_Standalone/#creating-a-wrapper-code","title":"Creating a wrapper code","text":"<p>The first step is to create a wrapper code to run your main application. Besides all the code shown below, be aware to import all the libraries that your app needs to run on this file, so that all of them will be compiled by cx_freeze.</p> <p>For this tutorial, let\u2019s call this wrapper\u00a0run.py\u00a0and your Streamlit app script file\u00a0main.py.\u00a0This code was offered by\u00a0ploomber.io, check them out.</p> <pre><code>\u2500\u2500 your_app_folder/  \n\u2502 \u251c\u2500\u2500run.py  \n\u2502 \u251c\u2500\u2500main.py\n</code></pre> <pre><code>import streamlit  \n\nimport streamlit.web.cli as stcli  \nimport os, sys  \n\n# Import the other libraries you need here  \n\ndef resolve_path(path):  \n    resolved_path = os.path.abspath(os.path.join(os.getcwd(), path))  \n    return resolved_path  \n\nif __name__ == \"__main__\":  \n    sys.argv = [  \n        \"streamlit\",  \n        \"run\",  \n        resolve_path(\"main.py\"),  \n        \"--global.developmentMode=false\",  \n    ]  \n    sys.exit(stcli.main())\n</code></pre> <p>Now, we can use <code>cx_freeze</code> to create the executable file. Run the following command in the terminal.</p> <pre><code>cxfreeze -c run.py\n</code></pre> <p>Once the wrapper will run our interface, keep in mind that this solution requires\u00a0main.py\u00a0inside the cx_freeze regenerated folder.</p> <pre><code>\u2500\u2500 cx_freeze_generated_folder/  \n\u2502 \u251c\u2500\u2500lib  \n\u2502 \u251c\u2500\u2500share  \n\u2502 \u251c\u2500\u2500app.exe  \n\u2502 \u251c\u2500\u2500**main.py**  \n\u2502 \u251c\u2500\u2500other_files(images,streamlit .py pages, etc..)\n</code></pre> <p>The advantage of this approach is that, if no library is added during your code reviews,\u00a0you can edit your interface without the need to compile the wrapper again.</p>"},{"location":"Tools/App_Dev/Streamlit/02_Standalone/#covering-all-the-bases","title":"Covering all the bases","text":"<p>In some cases, cxfreeze might face some problems to deliver pyc to one or more libraries in your dependency import. Pyc files are compiled bytecode files that are generated by the Python interpreter when a Python script is imported or executed.</p> <p>Let's suppose cxfreeze could not generate a pyc file in the boto3 library. To get trough this issue, make sure you follow these steps:</p> <p>Find the missing pyc in your python interpreter files. If you\u2019re using an env in conda, you can find it here:</p> <pre><code>C:\\Users\\&lt;user&gt;\\Miniconda3\\envs\\&lt;your_env_name&gt;\\Lib\\site-packages\\boto3\n</code></pre> <p>After you find where the pyc files are located, copy them to the cxfreeze generated files, following the subfolder where they were located:</p> <pre><code>\u2500\u2500 cx_freeze_generated_folder/  \n\u2502 \u251c\u2500\u2500lib  \n\u2502 \u2502  \u251c\u2500\u2500 boto3  \n\u2502 \u2502    \u251c\u2500\u2500**sub_folder/**  \n\u2502 \u251c\u2500\u2500share  \n\u2502 \u251c\u2500\u2500app.exe  \n\u2502 \u251c\u2500\u2500main.py  \n\u2502 \u251c\u2500\u2500other_files(images,streamlit .py pages, etc..)\n</code></pre> <p>In other scenarios, cx_freeze might fail with different file types\u00a0or even not deliver a whole library folder. To resolve this issue, find the lib folder in your conda and\u00a0copy it to the cxfreeze folder we\u2019ve just build.</p> <pre><code>\u2500\u2500 cx_freeze_generated_folder/  \n\u2502 \u251c\u2500\u2500lib  \n\u2502 \u2502  \u251c\u2500\u2500 \"**copy lib files here\"**  \n\u2502 \u251c\u2500\u2500share  \n\u2502 \u251c\u2500\u2500app.exe  \n\u2502 \u251c\u2500\u2500main.py  \n\u2502 \u251c\u2500\u2500other_files(images,streamlit .py pages, etc..)\n</code></pre>"},{"location":"Tools/App_Dev/Streamlit/02_Standalone/#additional-tips","title":"Additional Tips","text":"<ul> <li>If your Streamlit app relies on external data files or assets, make sure to include them in the same directory as the executable or specify their paths correctly in your code.</li> <li>Keep in mind that creating a standalone executable can result in a larger file size compared to running the app directly through Streamlit.</li> <li>Test your standalone executable on different platforms to ensure it works as expected.</li> <li>You can start customizing your executable with Resource Hacker, like changing its icon to a more exclusive experience.</li> </ul>"},{"location":"Tools/App_Dev/nicegui/","title":"References","text":"<ul> <li> NiceGUI | R3ap3rPy</li> <li> NiceGUI | Turtle Code</li> </ul>"},{"location":"Tools/Apps/logseq/","title":"Plugins","text":"<ol> <li>Bear Theme</li> <li>Focus Mode</li> <li>Tabs</li> </ol>"},{"location":"Tools/Apps/logseq/#export","title":"Export","text":"<p>You can export the entire logseq database as a standalone website, with every feature except editing. \ud83d\ude32</p> <ol> <li>Make sure you go to settings and set All pages public when publishing as True.</li> <li>Then export the graph</li> </ol>"},{"location":"Tools/Apps/typora/","title":"Mermaidjs update","text":"<p><code>/Applications/Typora.app/Contents/Resources/TypeMark/lib/diagram/diagram.min.js</code></p> <ol> <li>Make a copy of the existing one</li> <li>Replace current library with latest version of mermaidjs</li> </ol>"},{"location":"Tools/Apps/typora/#shortcuts","title":"shortcuts","text":"Shorcut Function Ctrl p (so that everything is on left hand) quick open Ctrl d toggle side bar ctrl t insert table ctrl enter add row"},{"location":"Tools/Blender/","title":"Blender","text":""},{"location":"Tools/Blender/#references","title":"References","text":"<ul> <li> Blender for architects | ETHZ CAAD</li> </ul>"},{"location":"Tools/Causal_Discovery/GCastle/","title":"GCastle","text":""},{"location":"Tools/Causal_Discovery/GCastle/#references","title":"References","text":""},{"location":"Tools/Causal_Discovery/GCastle/01_Introduction/","title":"Introduction","text":""},{"location":"Tools/Causal_Discovery/GCastle/01_Introduction/#custom-test","title":"Custom Test","text":"<p>Mutual information</p> <pre><code>def mutual_information_fisherz_test(data, x, y, z):\n        \"\"\"Fisher's z-transform for conditional independence test, *using Mutual Information* instead of correlation\n\n        Parameters\n        ----------\n        data : ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set different\n            from x and y. This is the separating set that (potentially)\n            makes x and y independent.\n\n        Returns\n        -------\n        _: None\n        _: None\n        p: float\n            the p-value of conditional independence.\n\n        Examples\n        --------\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; import pandas as pd\n        &gt;&gt;&gt; np.random.seed(23)\n        &gt;&gt;&gt; data = np.random.rand(2500, 4)\n\n        &gt;&gt;&gt; p_value = CITest.fisherz_test(data, 0, 1, [])\n        &gt;&gt;&gt; print(p_value)\n        0.011609430716781555\n\n        &gt;&gt;&gt; p_value = CITest.fisherz_test(data, 0, 1, [3])\n        &gt;&gt;&gt; print(p_value)\n        0.01137523908727811\n\n        &gt;&gt;&gt; p_value = CITest.fisherz_test(data, 0, 1, [2, 3])\n        &gt;&gt;&gt; print(p_value)\n        0.011448214156529746\n        \"\"\"\n\n        n = data.shape[0]\n        k = len(z)\n        if k == 0:\n            # change this\n            # r = np.corrcoef(data[:, [x, y]].T)[0][1] \n            pass\n        else:\n            sub_index = [x, y]\n            sub_index.extend(z)\n\n            # change this\n            # sub_corr = np.corrcoef(data[:, sub_index].T)\n            pass\n\n            # inverse matrix\n            try:\n                PM = np.linalg.inv(sub_corr)\n            except np.linalg.LinAlgError:\n                PM = np.linalg.pinv(sub_corr)\n            r = -1 * PM[0, 1] / math.sqrt(abs(PM[0, 0] * PM[1, 1]))\n        cut_at = 0.99999\n        r = min(cut_at, max(-1 * cut_at, r))  # make r between -1 and 1\n\n        # Fisher\u2019s z-transform\n        res = math.sqrt(n - k - 3) * .5 * math.log1p((2 * r) / (1 - r))\n        p_value = 2 * (1 - stats.norm.cdf(abs(res)))\n\n        return None, None, p_value\n\npc = PC(alpha=0.05, ci_test=test)\n</code></pre>"},{"location":"Tools/Data_Visualization/Matplotlib/01/","title":"01","text":""},{"location":"Tools/Data_Visualization/Matplotlib/01/#initialization","title":"Initialization","text":"<pre><code>from matplotlib import pyplot as plt\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\nplt.figure(figsize=(16, 9), dpi=1920/16)\n</code></pre> <pre><code>plt.figure(\n  figsize=(6, 6),\n  dpi=80\n)\n</code></pre>"},{"location":"Tools/Data_Visualization/Matplotlib/01/#example","title":"Example","text":"<pre><code>df = df.sort_values(x).reset_index(drop=True)\nplt.plot(\n  df[x],\n  df[y],\n  'o'\n)\nplt.xlabel(x), plt.ylabel(y)\n\n#add linear regression line to scatterplot\nm, b = np.polyfit(df[x], df[y], 1)\nplt.plot(df[x], m*df[x] + b)\n\nplt.show()\n</code></pre>"},{"location":"Tools/Data_Visualization/Matplotlib/01/#regression-line","title":"Regression Line","text":"<pre><code>m, b = np.polyfit(x, y, 1)\nplt.plot(x, m*x + b)\n</code></pre>"},{"location":"Tools/Data_Visualization/Matplotlib/01/#handrawn-style","title":"Handrawn Style","text":"<pre><code>with plt.xkcd():\n    plt.show()\n</code></pre>"},{"location":"Tools/Data_Visualization/Matplotlib/01/#animation","title":"Animation","text":"<pre><code>import numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib_inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n\nfrom matplotlib.animation import FuncAnimation, writers, PillowWriter, FFMpegWriter\n\nimport seaborn as sns\nsns.set_theme() ## affects all matplotlib and seaborn plots\nplt.style.use('ggplot')\n</code></pre> <pre><code>## hyperparameters\nx_values = [1, 2, 3]\ny_values = [1, 2, 3]\nduration = 3 ## seconds\npause_duration = 2 ## seconds\nres_w, res_h = 1920, 1080 ## video_resolution\naspect_w, aspect_h = (16, 9) ## aspect_ratio\n</code></pre> <pre><code>## plot\nactual_no_of_frames = len(y_values)\nfig = plt.figure(\n    figsize = (aspect_w, aspect_h), ## inches\n    dpi = res_w/16 ## \n)\nplt.tight_layout()\nax = plt.gca()  ## Get current axes\nax.set_title(\"Title\")\nax.set_xlim(xmin=0, xmax=(len(y_values)-1)*1.05)\nax.set_ylim(ymin=0, ymax=max(y_values)*1.05)\nax.set_xticks(x_values, [\"\"] + list(x_ticks))\nax.grid(False, axis=\"x\")\nline, = ax.plot(0, 0, linewidth=3)\n\ndef animation_frame(i):\n  ## avoid changing axes, titles, etc in updates: low fps issue\n  ## ax.set_title(y_values[i])\n  if i not in [0, 1] and i &lt;= actual_no_of_frames:\n    ax.text(x=i-1, y=y_values[i-1], s=y_values[i-1], backgroundcolor=\"white\", size=10, blit=True)\n  line.set_xdata(x_values[:i])\n  line.set_ydata(y_values[:i])\n\n  return line, \n\ninterval = (duration  * 1000)/actual_no_of_frames #ms\nfps = 1000 / interval\n\nno_of_blank_frames = int(fps * pause_duration)\ntotal_no_of_frames = actual_no_of_frames + no_of_blank_frames\n\nfor _ in range(no_of_blank_frames):\n  x_values.append(x_values[-1])\n  y_values.append(y_values[-1])\n\n\n## print(x_values)\n\nanimation = FuncAnimation(\n  fig,\n  func=animation_frame,\n  frames=total_no_of_frames,\n  interval=interval,\n  blit=True ## comment if it causes issue\n)\n</code></pre> <pre><code>\n</code></pre> <pre><code>## setting up writer object\nWriter = writers['ffmpeg'] ## PillowWriter\nwriter = Writer(\n  fps=fps,\n  bitrate=5000,\n  metadata = dict(\n    artist = 'Ahmed Thahir'\n  )\n)\n</code></pre> <pre><code>animation.save('Line Graph Animation.gif', writer)\n## animation.save('Line Graph Animation.mp4', writer)\n</code></pre>"},{"location":"Tools/Data_Visualization/Networks/Networkx/","title":"PyVis","text":""},{"location":"Tools/Data_Visualization/Networks/Networkx/#references","title":"References","text":"<ul> <li> Python for Social Networks | Python Tutorials for Digital Humanities</li> </ul>"},{"location":"Tools/Data_Visualization/Networks/PyVis/","title":"PyVis","text":""},{"location":"Tools/Data_Visualization/Networks/PyVis/#references","title":"References","text":"<ul> <li> How to Use PyVis Library in Python Tutorials | Python Tutorials for Digital Humanities</li> </ul>"},{"location":"Tools/Data_Visualization/Plotly/","title":"Plotly","text":""},{"location":"Tools/Data_Visualization/Plotly/#references","title":"References","text":"<ul> <li>Plotly Express | Data Science for Everyone<ul> <li>Part 1</li> <li>Part 2</li> </ul> </li> </ul>"},{"location":"Tools/Data_Visualization/Plotly/01/","title":"01","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#importing","title":"Importing","text":"<pre><code>import plotly.express as px\nimport plotly.graph_objs as go\n\nimport plotly.io as pio\npio.templates.default = \"ggplot2\"\npio.renderers.default = \"notebook\"\n## injects plotly.js into the notebook for offline plotly\n## but only works for the first save, for some reason\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#plots","title":"Plots","text":"<pre><code>px.scatter()\npx.line()\npx.imshow(df, text_auto=True) ## heatmap with value\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#maps","title":"Maps","text":"<pre><code>  fig = px.scatter_geo(\n      df,\n      lat = \"Lat\",\n      lon = \"Lon\",\n      color = \"Name\"\n  ).update_traces(\n      marker = dict(size = 10),\n  ).update_layout(\n      margin = dict(t=0, l=0, r=0, b=0)\n  ).update_geos(\n      projection_type=\"orthographic\",\n      center=dict(lat=17, lon=65.5),\n      projection_rotation=dict(lon=65, lat=10),\n      showcountries=True,\n      countrycolor=\"rgba(0,0,0, 0.1)\"\n  )\n  fig.show()\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#sankey-chart","title":"Sankey Chart","text":"<pre><code>  import plotly.graph_objects as go\n\n  fig = go.Figure(data=[go.Sankey(\n    node = dict(\n      pad = 15,\n      thickness = 20,\n      line = dict(color = \"black\", width = 0.5),\n      label = my_sankey['label'],\n      color = \"blue\"\n    ),\n    link = dict(\n      source = my_sankey['source'],\n      target = my_sankey['target'],\n      value = my_sankey['value']\n  ))])\n\n  fig.write_html('test.html')\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#useful-configuration","title":"Useful Configuration","text":"<p>Only 2 series as colored</p> <p>Useful when there are a lot of colors</p> <pre><code>  df[\"order\"] = (\n    df[\"Country Name\"]\n    .map({\"Japan\": 1, \"Turkey\": 2})\n    .fillna(3)\n  )\n  ## sort by this order\n  df.sort_values(by=[\"order\",\"years\"], ascending=False, inplace=True)\n\n  ## The line which comes the latest, is drawn on the top.\n</code></pre> <pre><code>  fig.update_traces({\"line\":{\"color\":\"lightgrey\"}})\n\n  fig.update_traces(patch={\"line\":{\"color\":\"blue\", \"width\":5}}, \n                    selector={\"legendgroup\":\"Turkey\"})\n  fig.update_traces(patch={\"line\":{\"color\":\"red\", \"width\":5}}, \n                    selector={\"legendgroup\":\"Japan\"})\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#adding-text-at-the-end-of-line-instead-of-legends","title":"Adding text at the end of line, instead of legends","text":"<pre><code>  for i, d in enumerate(fig.data):\n    text = '  ' + d.name + '  ' ## str(d.y[-1])\n\n    ## last non-empty\n    last_index = pd.Series(d.y).last_valid_index()\n    ## last_index = len([x for x in d.y if x != \"nan\"])-1 ## for string/object col\n    fig.add_scatter(\n      x = [d.x[last_index]],\n      y = [d.y[last_index]], ## last non-empty\n      hoverinfo = 'skip',\n      hovertemplate = 'skip',\n      mode = 'text',\n      text = text,\n      textfont = dict(color = d.line.color),\n      textposition = 'top left',\n      showlegend = False\n    )\n\n    ## first non-empty\n    first_index = pd.Series(d.y).first_valid_index()\n    ## idk ## for string/object col\n    fig.add_scatter(\n      x = [d.x[first]],\n      y = [d.y[first]], ## last non-empty\n      hoverinfo = 'skip',\n      hovertemplate = 'skip',\n      mode = 'text',\n      text = text,\n      textfont = dict(color = d.line.color),\n      textposition = 'top right',\n      showlegend = False\n    )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#update_layout","title":"<code>update_layout()</code>","text":"<pre><code>  fig = go.Figure().update_layout(\n    ## Title and Subtitle\n    title = dict(\n      text =  \"&lt;span style='font-size:1.5em'&gt;\" +\n          \"Title\"\n        + \"&lt;/span&gt;&lt;br /&gt;&lt;sup&gt;\" +\n        \"Subtitle\"\n        + \"&lt;/sup&gt;\",\n      x = 0, xref = \"paper\",\n      #y = 0.95, yref = \"paper\",\n    ),\n\n    uirevision=\"foo\", overwrite=True, ## ensures clicks are retained on refresh\n    plot_bgcolor = \"rgba(0, 0%, 0%, 0)\",\n    paper_bgcolor = \"rgba(0, 0%, 0%, 0)\",\n    margin=dict(t=0, r=0, b=0, l=0),\n\n    ## axes titles\n    xaxis_title = \"x_title\",\n    yaxis_title = \"y_title\",\n\n    hovermode = \"x unified\",\n\n    ## legend\n    showlegend = False,\n    legend = dict(\n    groupclick=\"toggleitem\",\n      orientation = 'h',\n\n      ## positioning\n      x = 0,\n      xanchor = \"left\",\n\n      y = 1,\n      yanchor = \"bottom\",\n\n    font = dict(\n            size = 10\n      ),\n      itemsizing = 'constant',\n\n      ## click behavior\n      #itemclick = 'toggleothers',\n      #itemdoubleclick = 'toggle'\n    )\n  )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#custom-menu","title":"custom menu","text":"<p>The updatemenu method determines which plotly.js function will be used to modify the chart. There are 4 possible methods:</p> <p><code>\"restyle\"</code>: modify data or Data attributes</p> <p><code>\"relayout\"</code>: modify layout attributes</p> <p><code>\"update\"</code>: modify data and layout attributes; combination of <code>\"restyle\"</code> and <code>\"relayout\"</code></p> <p><code>\"animate\"</code>: start or pause an animation)</p> <p>Examples</p> <p>restyle</p> <p></p> <p></p> <pre><code>      fig = go.Figure()\n\n      ## Add surface trace\n      fig.add_trace(go.Surface(z=df.values.tolist(), colorscale=\"Viridis\"))\n\n      ## Update plot sizing\n      fig.update_layout(\n          width=800,\n          height=900,\n          autosize=False,\n          margin=dict(t=0, b=0, l=0, r=0),\n          template=\"plotly_white\",\n      )\n\n      ## Update 3D scene options\n      fig.update_scenes(\n          aspectratio=dict(x=1, y=1, z=0.7),\n          aspectmode=\"manual\"\n      )\n\n      ## Add dropdown\n      fig.update_layout(\n          updatemenus=[\n              dict(\n                  type = \"buttons\",\n                  direction = \"left\",\n                  buttons=list([\n                      dict(\n                          args=[\"type\", \"surface\"],\n                          label=\"3D Surface\",\n                          method=\"restyle\"\n                      ),\n                      dict(\n                          args=[\"type\", \"heatmap\"],\n                          label=\"Heatmap\",\n                          method=\"restyle\"\n                      )\n                  ]),\n                  pad={\"r\": 10, \"t\": 10},\n                  showactive=True,\n                  x=0.11,\n                  xanchor=\"left\",\n                  y=1.1,\n                  yanchor=\"top\"\n              ),\n          ]\n      )\n</code></pre> <p>relayout</p> <p></p> <pre><code>      import plotly.graph_objects as go\n\n      ## Generate dataset\n      import numpy as np\n      np.random.seed(1)\n\n      x0 = np.random.normal(2, 0.4, 400)\n      y0 = np.random.normal(2, 0.4, 400)\n      x1 = np.random.normal(3, 0.6, 600)\n      y1 = np.random.normal(6, 0.4, 400)\n      x2 = np.random.normal(4, 0.2, 200)\n      y2 = np.random.normal(4, 0.4, 200)\n\n      ## Create figure\n      fig = go.Figure()\n\n      ## Add traces\n      fig.add_trace(\n          go.Scatter(\n              x=x0,\n              y=y0,\n              mode=\"markers\",\n              marker=dict(color=\"DarkOrange\")\n          )\n      )\n\n      fig.add_trace(\n          go.Scatter(\n              x=x1,\n              y=y1,\n              mode=\"markers\",\n              marker=dict(color=\"Crimson\")\n          )\n      )\n\n      fig.add_trace(\n          go.Scatter(\n              x=x2,\n              y=y2,\n              mode=\"markers\",\n              marker=dict(color=\"RebeccaPurple\")\n          )\n      )\n\n      ## Add buttons that add shapes\n      cluster0 = [dict(type=\"circle\",\n                                  xref=\"x\", yref=\"y\",\n                                  x0=min(x0), y0=min(y0),\n                                  x1=max(x0), y1=max(y0),\n                                  line=dict(color=\"DarkOrange\"))]\n      cluster1 = [dict(type=\"circle\",\n                                  xref=\"x\", yref=\"y\",\n                                  x0=min(x1), y0=min(y1),\n                                  x1=max(x1), y1=max(y1),\n                                  line=dict(color=\"Crimson\"))]\n      cluster2 = [dict(type=\"circle\",\n                                  xref=\"x\", yref=\"y\",\n                                  x0=min(x2), y0=min(y2),\n                                  x1=max(x2), y1=max(y2),\n                                  line=dict(color=\"RebeccaPurple\"))]\n\n      fig.update_layout(\n          updatemenus=[\n              dict(\n                  type=\"buttons\",\n                  buttons=[\n                      dict(label=\"None\",\n                           method=\"relayout\",\n                           args=[\"shapes\", []]),\n                      dict(label=\"Cluster 0\",\n                           method=\"relayout\",\n                           args=[\"shapes\", cluster0]),\n                      dict(label=\"Cluster 1\",\n                           method=\"relayout\",\n                           args=[\"shapes\", cluster1]),\n                      dict(label=\"Cluster 2\",\n                           method=\"relayout\",\n                           args=[\"shapes\", cluster2]),\n                      dict(label=\"All\",\n                           method=\"relayout\",\n                           args=[\"shapes\", cluster0 + cluster1 + cluster2])\n                  ],\n              )\n          ]\n      )\n\n      ## Update remaining layout properties\n      fig.update_layout(\n          title_text=\"Highlight Clusters\",\n          showlegend=False,\n      )\n\n      fig.show()\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#update_xaxes","title":"<code>update_xaxes()</code>","text":"<pre><code>  fig.update_xaxes(autorange = 'reversed')\n  fig.update_xaxes(range = [100, -30])\n\n  ## only the first month has the year\n  fig.update_xaxes(\n    type = \"date\",\n    dtick=\"M1\",\n    tickformat=\"%b\\n%Y\"\n  )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#config","title":"<code>config</code>","text":"<pre><code>  export_width = 1000\n  export_height = export_width/2\n\n  config = dict(\n      doubleClickDelay = 400, ## (ms) affects the single click delay; default = 300ms\n      ## displayModeBar = True,\n      displaylogo = False,\n      modeBarButtonsToRemove = [\"zoom\", \"select2d\", \"lasso2d\", \"pan\", \"zoomIn\", \"zoomOut\", \"autoScale\", \"resetScale\"],\n\n      ## scrollZoom = True,\n      showTips = False,\n\n      toImageButtonOptions = dict(\n        format = 'pdf', ## pdf, svg, png, jpeg, webp\n        filename = title,\n        width = export_width,\n        height = export_height,\n        scale = 1 ## Multiply title/legend/axis/canvas sizes by this factor\n      )\n  )\n</code></pre> <pre><code>  fig.show(config = config)\n  dcc.Graph(config = config)\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#grey-out-areas-not-selected-by-marquee-select","title":"Grey out areas not selected by marquee select","text":"<pre><code>  scatter = px.scatter_matrix(df)\n  scatter.data[0].update(selected=dict(marker=dict(color='red')),\n                         unselected=dict(marker=dict(color='blue',\n                                                     opacity=0.001)))\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#animated","title":"Animated","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#autoplay","title":"Autoplay","text":"<pre><code>  config = {\n    auto_play = True\n  }\n  fig.show(config = config)\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#save-as-gif","title":"Save as GIF","text":"<p>Using moviepy</p> <pre><code>    import numpy as np\n    from scipy.spatial import Delaunay\n    import plotly.graph_objects as go\n    import  moviepy.editor as mpy\n    import io \n    from PIL import Image\n\n    def plotly_fig2array(fig):\n        #convert Plotly fig to  an array\n        fig_bytes = fig.to_image(format=\"png\")\n        buf = io.BytesIO(fig_bytes)\n        img = Image.open(buf)\n        return np.asarray(img)\n\n    n = 20 ## number of radii\n    h = 2/(n-1)\n    r = np.linspace(h, 2,  n)\n    theta = np.linspace(0, 2*np.pi, 60)\n    r, theta = np.meshgrid(r,theta)\n    r = r.flatten()\n    theta = theta.flatten()\n\n    x = r*np.cos(theta)\n    y = r*np.sin(theta)\n\n    ## Triangulate the circular  planar region\n    tri = Delaunay(np.vstack([x,y]).T)\n    faces = np.asarray(tri.simplices)\n    I, J, K = faces.T\n\n    f = lambda h: np.sinc(x**2+y**2)+np.sin(x+h)   \n\n    fig = go.Figure(go.Mesh3d(x=x,\n                         y=y,\n                         z=f(0),\n                         intensity=f(0),\n                         i=I,\n                         j=J,\n                         k=K,\n                         colorscale='matter_r', \n                         showscale=False))\n\n    fig.update_layout(title_text='My hat is flying with MoviePy',\n                      title_x=0.5,\n                      width=500, height=500, \n                      scene_xaxis_visible=False, \n                      scene_yaxis_visible=False, \n                      scene_zaxis_visible=False)\n\n    ## No Plotly frames are defined here!! Instead we define moviepy frames by\n    ## converting each Plotly figure to  an array, from which MoviePy creates a clip\n    ## The concatenated clips are saved as a gif file:\n    def make_frame(t):\n        z = f(2*np.pi*t/2)\n        fig.update_traces(z=z, intensity=z)  #These are the updates that usually are performed within Plotly go.Frame definition\n        return plotly_fig2array(fig)\n\n    animation = mpy.VideoClip(make_frame, duration=2) ## or VideoFileClip\n    animation.write_gif(\"image/my_hat.gif\", fps=20)\n    animation.write_videofile(\"gfg_intro.webm\")\n</code></pre> <p>Manual</p> <pre><code>    import plotly.express as px\n    import pandas as pd\n    import numpy as np\n    import io\n    import PIL\n\n    ## sample data\n    df = pd.DataFrame(\n        {\n            \"step\": [1, 2, 3],\n            \"x\": [10, 20, 30],\n            \"y\": [100, 200, 300],\n        }\n    )\n\n    ## smaple plotly animated figure\n    fig = px.bar(df, x=\"x\", y=\"y\", animation_frame=\"step\")\n\n    ## generate images for each step in animation\n    frames = []\n    for s, fr in enumerate(fig.frames):\n        ## set main traces to appropriate traces within plotly frame\n        fig.update(data=fr.data)\n        ## move slider to correct place\n        fig.layout.sliders[0].update(active=s)\n        ## generate image of current state\n        frames.append(PIL.Image.open(io.BytesIO(fig.to_image(format=\"png\"))))\n\n    ## create animated GIF\n    frames[0].save(\n      \"test.gif\",\n      save_all=True,\n      append_images=frames[1:],\n      optimize=True,\n      duration=500,\n      loop=0,\n    )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#scatter-plot-hans-rosling-style","title":"Scatter Plot (Hans Rosling Style)","text":"<pre><code>  fig = px.scatter(data_frame = df, \n             x = 'consumption_co2',\n             y = 'consumption_co2_per_capita', \n             size = 'population', \n             hover_name = 'country', \n             color = 'country',\n             animation_frame = 'year',\n             animation_group = 'country',\n\n             size_max=60,\n\n             log_x=True,\n\n             range_x = [0, 1.05 * np.log10(df[\"consumption_co2\"].max())],\n             range_y = [0, 1.05 * df[\"consumption_co2\"].max()]\n            )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#choropleth","title":"Choropleth","text":"<pre><code>  px.choropleth(gapminder,               \n                locations=\"iso_alpha\",               \n                color=\"lifeExp\",\n                hover_name=\"country\",  \n                animation_frame=\"year\",    \n                color_continuous_scale='Plasma',  \n                height=600             \n  )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#line-chart","title":"Line Chart","text":"<pre><code>  data = pd.read_csv(r\"https://raw.githubusercontent.com/datageekrj/ForHostingFiles/master/income_per_person_gdppercapita_ppp_inflation_adjusted.csv\")\n\n  numOfRows = data.shape[0] ## No of Countries\n  numOfCols = data.shape[1] ## No of years + one column for a country\n  numOfFrames = numOfCols - 1\n  xaxis_range = [0,numOfFrames + 2]\n\n  ## While, testing the code, test with low numbers:\n  ## Initial State of the data\n  ## First we are just seeing it for afghanistan\n\n  x_init = np.array([1])\n\n  initial_data = []\n  for cont_ind in [75,35,184,83,140]:\n      y_axis = np.array(data.iloc[cont_ind,0])\n      initial_data.append(go.Scatter(x =x_init, y = y_axis,mode = \"lines\",name = data.country[cont_ind]))\n  initial_max = 600\n\n  ## Frames\n  frames = []\n  for f in range(1,numOfFrames+1):\n      x_axis = np.arange(1,f+1)\n      curr_data = []\n      title_names = []\n      start = \"For \" + str(1800 + f + 1)\n      for cont_ind in [75,35,184,83,140]:\n          curr_country = data.country[cont_ind]\n          y_axis = np.array(data.iloc[cont_ind,1:f+1])\n          curr_data.append(go.Scatter(x = x_axis, y = y_axis,mode = \"lines\", name = curr_country))\n          title_names.append(curr_country + \": \" + str(y_axis[f-1]/1000) + \"K Dollar. \")\n      title = start + \" \" + \" \".join(title_names)\n      curr_frame = go.Frame(data = curr_data, layout = {\"title\":title})\n      frames.append(curr_frame)\n\n  fig = go.Figure(\n      data = initial_data,\n      layout = {\n          \"title\":\"Line Chart Race\",\n          \"xaxis\":{\"range\":xaxis_range, \"visible\":False, \"showline\":False},\n          \"yaxis\":{\"type\":\"log\", \"visible\":False, \"showline\":False},\n          \"updatemenus\":[{\"type\":\"buttons\",\"buttons\":[{\"method\":\"animate\",\"label\":\"play\", \"args\":[None]}]}]\n          },\n      frames = frames\n      )\n  fig.show()\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#performance","title":"Performance","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#webgl-renderer","title":"Webgl renderer","text":"<pre><code>  px.scatter(df, x=\"x\", y=\"y\", render_mode='webgl')\n  px.scatter_polar(df, x=\"x\", y=\"y\", render_mode='webgl')\n\n  px.line(df, x=\"x\", y=\"y\", render_mode='webgl')\n  px.line_polar(df, x=\"x\", y=\"y\", render_mode='webgl')\n\n  go.Scattergl()\n  go.Scatterpolargl()\n  go.Heatmapgl()\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#specify-axis-range","title":"Specify axis range","text":"<p>Letting plotly autorange means it needs to do relayouts often and requires it to calculate the range each time.</p> <pre><code>  fig = px.scatter(df, x=\"x\", y=\"y\", range_x=[2, 3], range_y=[10, 20])\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#use-heatmap-instead-of-pairplot","title":"Use heatmap instead of pairplot","text":"<pre><code>  import numpy as np\n\n  N = 1000\n  M = 500\n  xx = np.arange(N, dtype=np.float64)\n  yy = np.arange(M, dtype=np.float64)\n  x, y = np.meshgrid(xx, yy)\n  b = N/20.0\n  c = M/2.0\n  r = np.sqrt(((x-c)/b)**2 + ((y-c)/b)**2)\n  a = np.sin(r)\n\n  ## Limits\n  xmin = xx[0]\n  xmax = xx[-1]\n  ymin = yy[0]\n  ymax = yy[-1]\n  amin = np.amin(a)\n  amax = np.amax(a)\n\n  from PIL import Image\n  from matplotlib import cm\n  from matplotlib.colors import Normalize\n\n  ## Some normalization from matplotlib\n  cNorm = Normalize(vmin=amin, vmax=amax)\n  scalarMap  = cm.ScalarMappable(norm=cNorm, cmap='viridis' )\n  seg_colors = scalarMap.to_rgba(a) \n  img = Image.fromarray(np.uint8(seg_colors*255))\n\n  ## Now the plotly code\n  import plotly.graph_objects as go\n\n  ## Create figure\n  fig = go.Figure()\n\n  ## Constants\n  img_width = 900\n  img_height = 600\n\n  ## Add invisible scatter trace.\n  ## This trace is added to help the autoresize logic work.\n  ## We also add a color to the scatter points so we can have a colorbar next to our image\n  fig.add_trace(\n      go.Scatter(\n          x=[xmin, xmax],\n          y=[ymin, ymax],\n          mode=\"markers\",\n          marker={\"color\":[np.amin(a), np.amax(a)],\n                  \"colorscale\":'Viridis',\n                  \"showscale\":True,\n                  \"colorbar\":{\"title\":\"Counts\",\n                              \"titleside\": \"right\"},\n                  \"opacity\": 0\n                 }\n      )\n  )\n\n  ## Add image\n  fig.update_layout(\n      images=[go.layout.Image(\n          x=xmin,\n          sizex=xmax-xmin,\n          y=ymax,\n          sizey=ymax-ymin,\n          xref=\"x\",\n          yref=\"y\",\n          opacity=1.0,\n          layer=\"below\",\n          sizing=\"stretch\",\n          source=img)]\n  )\n\n  ## Configure other layout\n  fig.update_layout(\n          xaxis=dict(showgrid=False, zeroline=False, range=[xmin, xmax]),\n          yaxis=dict(showgrid=False, zeroline=False, range=[ymin, ymax]),\n      width=img_width,\n      height=img_height,\n  )\n\n  fig.show()\n</code></pre> <p>Use summary statistics whenever possible</p>"},{"location":"Tools/Data_Visualization/Plotly/01/#plotly-resampler","title":"Plotly Resampler","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#datashader","title":"Datashader","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#use-plotlyreact-instead-of-plotlynewplot-only-for-plotlyjs","title":"use Plotly.react instead of Plotly.newPlot (only for plotly.js)","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#tutorials","title":"Tutorials","text":"<p>https://www.youtube.com/watch?v=hSPmj7mK6ng</p> <p>https://www.youtube.com/watch?v=pGMvvq7R1IM</p> <p>https://www.youtube.com/watch?v=8d7rArayuzc</p> <p>https://www.youtube.com/watch?v=_b2KXL0wHQg</p>"},{"location":"Tools/Data_Visualization/Plotly/01/#exporting","title":"Exporting","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#static","title":"Static","text":"<pre><code>  fig.write_image(f\"{title}.pdf\")\n  fig.write_image(f\"{title}.svg\")\n  fig.write_image(f\"{title}.png\")\n  fig.write_image(f\"{title}.jpg\")\n  fig.write_image(f\"{title}.webp\")\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#interactive","title":"Interactive","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#embed-within","title":"Embed within","text":"<pre><code>    fig.write_html(\"graph_name.html\",\n                   full_html=False,\n                   include_plotlyjs = True,\n                   config = dict(\n                     doubleClickDelay = 400, ## (ms) affects the single click delay; default = 300ms\n                     displayModeBar = False,\n                     showTips = False\n                   )\n                  )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#export-a-js-file-to-the-same-directory","title":"Export a js file to the same directory","text":"<pre><code>    fig.write_html(\"graph_name.html\",\n                   full_html=False,\n                   include_plotlyjs = \"directory_path\",\n                   config = dict(\n                     doubleClickDelay = 400, ## (ms) affects the single click delay; default = 300ms\n                     displayModeBar = False,\n                     showTips = False\n                   )\n                  )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#use-external-source-useful-for-revealjs","title":"Use external source (useful for revealjs)","text":"<pre><code>    fig.write_html(\n      \"graph_name.html\",  ## no need to add _plotly to the file name, because the iframe will request\n      full_html=False,\n      include_plotlyjs = \"../../../backend/plugins/plotly/plotly-basic.min.js\", ## 3 backtracks because it is an iframe in the assets folder, so it has to an extra backtrack\n      include_mathjax = \"\",\n      config = config\n    )\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#interactive-hover","title":"Interactive Hover","text":"<pre><code>def hover_fn(trace, points, state):\n    ind = points.point_inds[0]\n    details.value = cars_df.iloc[ind].to_frame().to_html()\n\nscatter.on_hover(hover_fn)\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#multiple-traces-from-the-same","title":"Multiple Traces from the same","text":"<pre><code>for i in range(4): ## 0-3\n    subset = spf_unrate[\n        spf_unrate[\"PREDICTION_PERFORMED_LAG\"] == i\n    ]\n    fig.add_trace(go.Scattergl(\n        x = subset.index.astype(str),\n        y = subset[\"UNRATE\"],\n        name = f\"SPF (Forecast) with Lag = {i}\"\n    ))\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#maps_1","title":"Maps","text":"<p>Default</p> <pre><code>  fig = px.scatter_geo(\n    df,\n    lat=\"Lat\",\n    lon=\"Lon\",\n    hover_name=\"Name\",\n    projection=\"orthographic\",\n    ## center = (0, 0)\n  )\n\n  fig.update_geos(\n    ## (meters) : higher number --&gt; lower detail --&gt; smoother\n    resolution=110,\n    bgcolor='hsla(0, 0%, 0%, 0)',\n\n    showcountries=True, countrycolor=\"Grey\",\n    showcoastlines=True, coastlinecolor=\"Grey\",\n\n    showland=True, landcolor=\"LightYellow\",\n    showocean=True, oceancolor=\"LightBlue\",\n    ## showlakes=True, lakecolor=\"LightBlue\",\n    ## showrivers=True, rivercolor=\"LightBlue\",\n  )\n\n  fig.update_layout(\n    margin=dict(r=0, t=0, l=0, b=0),\n    uirevision=\"foo\",\n    overwrite=True,\n    paper_bgcolor='hsla(0, 0%, 0%, 0)',\n    plot_bgcolor='hsla(0, 0%, 0%, 0)',\n    modebar=dict(\n      bgcolor='hsla(0, 0%, 0%, 0.5)',\n      color='hsla(0, 0%, 100%, 0.5)',\n    )\n  )\n</code></pre> <p>Mapbox</p> <pre><code>  ## create a map of area, where houses from data set located\n  fig = px.scatter_mapbox(data, #our data set\n                          lat=\"lat\", lon=\"long\", #location\n                          color=\"price\", #select a column for ranking\n                          hover_name=\"price\", \n                          hover_data=[\"bedrooms\", \"bathrooms\"], \n                          color_discrete_sequence=[\"green\"],\n                          size_max=15, \n                          zoom=8, \n                          width=900, height=600, #map size\n                          title =  'Map of area, check location')\n  #style of map\n  fig.update_layout(mapbox_style=\"open-street-map\")\n  fig.show(config={'scrollZoom': False})\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#4d-surface","title":"4D Surface","text":"<p>3 axes, color as output</p> <pre><code>x = [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7]\ny = [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\nz = [0, 2, 3, 1, 0, 5, 6, 1, 0, 2, 3, 1, 0, 5, 6, 1]\nf = x+y+z\n\nfig = go.Figure(\n    go.Mesh3d(\n        x = x,\n        y = y,\n        z = z,\n        intensity = f,\n        showscale=True\n    )\n)\nfig\n</code></pre> <p></p>"},{"location":"Tools/Data_Visualization/Plotly/01/#ridge-plot","title":"Ridge Plot","text":""},{"location":"Tools/Data_Visualization/Plotly/01/#idk","title":"IDK","text":"<pre><code># the idea behind this ridgeline plot with Plotly is to add traces manually, each trace corresponding to a particular year's temperature distribution\n# thus, we are to store each year's data (temperatures and their respective count) in seperate arrays or pd.series that we store in a dictionnary to retrieve them easily\narray_dict = {} # instantiating an empty dictionnary\nfor year in year_list:\n    array_dict[f'x_{year}'] = temp[temp['year']==year]['Mean_TemperatureC'] # storing the temperature data for each year\n    array_dict[f'y_{year}'] = temp[temp['year']==year]['count'] # storing the temperature count for each year\n    array_dict[f'y_{year}'] = (array_dict[f'y_{year}'] - array_dict[f'y_{year}'].min()) \\\n                                / (array_dict[f'y_{year}'].max() - array_dict[f'y_{year}'].min()) # we normalize the array (min max normalization)\n\n# once all of this is done, we can create a plotly.graph_objects.Figure and add traces with fig.add_trace() method\n# since we have stored the temperatures and their respective count for each year, we can plot scatterplots (go.Scatter)\n# we thus iterate over year_list and create a 'blank line' that is placed at y = index, then the corresponding temperature count line\nfig = go.Figure()\nfor index, year in enumerate(year_list):\n    fig.add_trace(go.Scatter(\n                            x=[-20, 40], y=np.full(2, len(year_list)-index),\n                            mode='lines',\n                            line_color='white'))\n\n    fig.add_trace(go.Scatter(\n                            x=array_dict[f'x_{year}'],\n                            y=array_dict[f'y_{year}'] + (len(year_list)-index) + 0.4,\n                            fill='tonexty',\n                            name=f'{year}'))\n\n    # plotly.graph_objects' way of adding text to a figure\n    fig.add_annotation(\n                        x=-20,\n                        y=len(year_list)-index,\n                        text=f'{year}',\n                        showarrow=False,\n                        yshift=10)\n\n# here you can modify the figure and the legend titles\nfig.update_layout(\n                title='Average temperature from 1950 until 2010 in Seattle',\n                showlegend=False,\n                xaxis=dict(title='Temperature in degree Celsius'),\n                yaxis=dict(showticklabels=False) # that way you hide the y axis ticks labels\n                )\n\nfig.show()\n</code></pre>"},{"location":"Tools/Data_Visualization/Plotly/01/#idk_1","title":"IDK","text":"<pre><code>import plotly.graph_objects as go\nfrom plotly.colors import n_colors\nimport numpy as np\n\nnp.random.seed(1)\ndata = (np.linspace(1, 2, 12)[:, np.newaxis] * np.random.randn(12, 200) +\n            (np.arange(12) + 2 * np.random.random(12))[:, np.newaxis])\ncolors = n_colors('rgb(5, 200, 200)', 'rgb(200, 10, 10)', 12, colortype='rgb')\n\nfig = go.Figure()\nfor i, (data_line, color) in enumerate(zip(data, colors)):\n    fig.add_trace(\n        go.Violin(x=data_line, line_color='black', name=i, fillcolor=color)\n        )\n\n# use negative ... cuz I'm gonna flip things later\nfig = fig.update_traces(orientation='h', side='negative', width=3, points=False, opacity=1)\n# reverse the (z)-order of the traces\nfig.data = fig.data[::-1]\n# flip the y axis (negative violin is now positive and traces on the top are now on the bottom)\nfig.update_layout(legend_traceorder='reversed', yaxis_autorange='reversed')\n\nfig.show()\n</code></pre>"},{"location":"Tools/Data_Visualization/Tableau/","title":"Tableau","text":""},{"location":"Tools/Data_Visualization/Tableau/#references","title":"References","text":"<ul> <li> Tableau in Under 2 hours | Alex The Analyst</li> </ul>"},{"location":"Tools/Databases/DuckDB/","title":"DuckDB","text":"<pre><code>import duckdb as db\nimport pandas as pd\n</code></pre> <pre><code>class DB():\n  def __init__(self, db_name = \"file.db\"):\n    self.db_name = db_name\n\n  def execute(self, query):\n    with duckdb.connect(self.db_name) as con:\n      try:\n          return con.sql(query).df()\n      except:\n        return False\n\n  def create(self, table_name = \"Series\"):\n    if table_name == \"Series\":\n      query = f\"\"\"\n      create or replace\n      table {table_name}\n      (\n        Date Datetime,\n        Variable String,\n        Value Float,\n\n        PRIMARY KEY (Date, Variable)\n      )\n      \"\"\"\n    elif table_name == \"Variables\":\n      query = f\"\"\"\n      create or replace\n      table {table_name}\n      (\n        id String,\n        realtime_start Datetime,\n        realtime_end  Datetime,\n        title String,\n        observation_start Datetime,\n        observation_end Datetime,\n        frequency String,\n        frequency_short String,\n        units String,\n        units_short String,\n        seasonal_adjustment String,\n        seasonal_adjustment_short String,\n        last_updated Datetime,\n        popularity int,\n        group_popularity int,\n        notes String,\n\n        PRIMARY KEY (id)\n      )\n      \"\"\"\n\n    return self.execute(query)\n\n  def read(self, table_name, pivot=True):\n    query = f\"\"\"\n    select *\n    from {table_name}\n    \"\"\"\n\n    query_result = self.execute(query)\n\n    if query_result is False:\n      return False\n\n    df = query_result\n\n    if pivot:\n      if table_name == \"Series\":\n        df = df.pivot(\n            index = \"Date\",\n            columns = \"Variable\",\n            values = \"Value\"\n        )\n      elif table_name == \"Variables\":\n        pass\n\n    return df\n\n  def upsert(self, table_name, df, melt=True):\n    if table_name == \"Series\":\n      if melt:\n        df = (\n            df\n            .copy()\n            .reset_index()\n            .melt(\n                id_vars = \"Date\",\n                var_name=\"Variable\",\n                value_name = \"Value\"\n            )\n            .dropna()\n        )\n      query = f\"\"\"\n      INSERT INTO {table_name}\n      select * from {var(df)}\n      ON CONFLICT (Date, Variable)\n      do update set Value = EXCLUDED.Value \n      \"\"\"\n    elif table_name == \"Variables\":\n      if melt:\n        pass\n\n      query = f\"\"\"\n      INSERT OR REPLACE INTO {table_name}\n      select * from {var(df)}\n      \"\"\"\n\n    return self.execute(query)\n</code></pre> <pre><code>economic_db = DB(\"economic.db\")\n\n# economic_db.create(\"Variables\")\n# economic_db.upsert(\"Variables\", series_list_df)\neconomic_db.read(\"Variables\")\n\n# economic_db.create(\"Series\")\n# economic_db.upsert(\"Series\", series_data, melt=True)\neconomic_db.read(\"Series\", pivot=True)\n</code></pre>"},{"location":"Tools/DevOps/AWS/","title":"AWS","text":""},{"location":"Tools/DevOps/AWS/#references","title":"References","text":"<ul> <li> Deploy ML Solutions w/ FastAPI, Docker, &amp; AWS | Shaw Talebi</li> </ul>"},{"location":"Tools/DevOps/Azure/","title":"Azure","text":""},{"location":"Tools/DevOps/Azure/#references","title":"References","text":""},{"location":"Tools/DevOps/CML/","title":"CML","text":"<p>Continuous ML</p>"},{"location":"Tools/DevOps/CML/#ml-model-report","title":"ML Model Report","text":"<pre><code>name: model-wine-quality\non: [push]\njobs:\n  run:\n    runs-on: [ubuntu-latest]\n    container: docker://dvcorg/cml-py3:latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: cml_run\n        env:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n\n          # Your ML workflow goes here\n          pip install -r requirements.txt\n          python train.py\n\n          echo \"## Model metrics\" &gt; report.md\n          cat metrics.txt &gt;&gt; report.md\n\n          echo \"## Data viz\" &gt;&gt; report.md\n          cml-publish feature_importance.png --md &gt;&gt; report.md\n          cml-publish residuals.png --md &gt;&gt; report.md\n\n          cml-send-comment report.md\n</code></pre>"},{"location":"Tools/DevOps/CML/#dvc-pipeline-for-ml-model-report-compared-to-main-branch","title":"DVC Pipeline for ML Model Report Compared to <code>main</code> branch","text":""},{"location":"Tools/DevOps/CML/#dvcyaml","title":"<code>dvc.yaml</code>","text":"<pre><code>stages:\n  get_data:\n    cmd: python get_data.py\n    deps:\n    - get_data.py\n    outs:\n    - data_raw.csv  \n  process:\n    cmd: python process_data.py\n    deps:\n    - process_data.py\n    - data_raw.csv\n    outs:\n    - data_processed.csv\n  train:\n    cmd: python train.py\n    deps:\n    - train.py\n    - data_processed.csv\n    outs:\n    - by_region.png\n    metrics:\n    - metrics.json:\n        cache: false\n</code></pre>"},{"location":"Tools/DevOps/CML/#ciyml","title":"<code>ci.yml</code>","text":"<pre><code>name: farmers\non: [push]\njobs:\n  run:\n    runs-on: [ubuntu-latest]\n    container: docker://dvcorg/cml-py3:latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: cml_run\n        env:\n          repo_token: ${{ secrets.GITHUB_TOKEN }}\n        run: |\n          pip install -r requirements.txt\n          dvc repro \n\n          git fetch --prune\n          dvc metrics diff --show-md master &gt; report.md\n\n          # Add figure to the report\n          echo \"## Validating results by region\"\n          cml-publish by_region.png --md &gt;&gt; report.md\n          cml-send-comment report.md\n</code></pre>"},{"location":"Tools/DevOps/Docker/","title":"Docker","text":""},{"location":"Tools/DevOps/Docker/#references","title":"References","text":"<ul> <li> Deploy ML Solutions w/ FastAPI, Docker, &amp; AWS | Shaw Talebi</li> </ul>"},{"location":"Tools/DevOps/Git/","title":"Git","text":""},{"location":"Tools/DevOps/Git/#references","title":"References","text":"<ul> <li> GitHub Actions | Shaw Talebi</li> </ul>"},{"location":"Tools/DevOps/Git/01_Basics/","title":"Basics","text":""},{"location":"Tools/DevOps/Git/01_Basics/#cloning","title":"Cloning","text":""},{"location":"Tools/DevOps/Git/01_Basics/#sparse-checkout","title":"Sparse Checkout","text":"<pre><code>git clone --filter=blob:none --sparse --no-checkout https://github.com/user_or_org/repo_name\n\n# move to git folder\ncd repo_name\n\n# set sparse\n# git sparse-checkout set --cone\n\n# select branch\ngit checkout main\n\n# clone specific folder\ngit sparse-checkout add ./folder\n\n# clone specific file\ngit sparse-checkout add ./folder/file\n</code></pre>"},{"location":"Tools/DevOps/Git/01_Basics/#shallow","title":"Shallow","text":"<pre><code>git clone --single-branch --depth=1 --branch main https://github.com/user_or_org/repo_name\n</code></pre>"},{"location":"Tools/DevOps/Git/01_Basics/#refresh-repo","title":"Refresh Repo","text":"<p>Go to repo local folder Right-click &gt; <code>Git Bash here</code></p> <pre><code>git checkout main\ngit checkout --orphan last\ngit add -A\ngit commit -am \"Repo Refresh\"\ngit branch -D main\ngit branch -m main\ngit gc --aggressive --prune=all\ngit push -f origin main\n\ngit checkout gh-pages\ngit checkout --orphan last\ngit add -A\ngit commit -am \"Repo Refresh\"\ngit branch -D gh-pages\ngit branch -m gh-pages\ngit gc --aggressive --prune=all\ngit push -f origin gh-pages\n</code></pre>"},{"location":"Tools/DevOps/Git/01_Basics/#rebase","title":"Rebase","text":"<pre><code>git rebase -i HEAD~10\n</code></pre>"},{"location":"Tools/DevOps/Git/01_Basics/#renamemoving-file","title":"Rename/Moving File","text":"<pre><code>git mv folder_old/filename_old folder_new/filename_new\n</code></pre> <p>This avoids Git thinking that the files were deleted &amp; added, thus reducing repo size</p>"},{"location":"Tools/DevOps/Git/02_CI_CD/","title":"CI/CD","text":""},{"location":"Tools/DevOps/Git/02_CI_CD/#actions","title":"Actions","text":"<p>Create <code>~/.github/workflows/ci.yml</code></p> <pre><code>name: Deploy uni-notes using Mkdocs\non:\n  push:\n    branches:\n      - main\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    env:\n      MKDOCS_GIT_COMMITTERS_APIKEY: ${{ secrets.GITHUB_TOKEN }}\n    steps:\n      - uses: actions/checkout@v3\n        with:\n          fetch-depth: '0'\n      - uses: actions/setup-python@v3\n        with:\n          python-version: 3.x\n          cache: pip\n      - run: pip install -r requirements.txt\n      - run: mkdocs gh-deploy --force --no-history\n</code></pre> <pre><code>name: Scrape otexts.com/fpp3\non:\n  schedule:\n    - cron: '45 9 * * 3'  # Runs every Wednesday at 09:45 UTC\n  workflow_dispatch:\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n        with:\n          fetch-depth: '0'\n      - name: Check for 'docs' branch and create if it doesn't exist\n        run: |\n          git fetch origin\n          if git show-ref --verify --quiet refs/heads/docs; then\n            echo \"Branch 'docs' already exists.\"\n          else\n            echo \"Creating 'docs' branch.\"\n            git checkout -b docs\n            git push origin docs\n          fi\n      # - name: Create output directory\n      #   run: |\n      #     mkdir -p ./docs # This won't error if the directory already exists\n      #     echo \"Directory created: $(ls -d .)\"  # Confirm directory creation\n      - name: Install wget\n        run: sudo apt-get install -y wget\n      - name: Perform Scraping\n        run: wget --no-parent -r -l 2 -P . \"https://otexts.com/fpp3\"\n        continue-on-error: true\n      - name: Create output directory\n        run: |\n          cd otexts.com\n          echo \"Moving to otexts.com: $(ls -d .)\" # Confirm cd\n      - name: Configure Git\n        run: |\n          git config --local user.name \"AhmedThahir\"\n          git config --local user.email \"ahmedthahir2002@gmail.com\"\n      - name: Commit changes\n        run: |\n          git checkout docs\n          git add .\n          git commit -m \"Add current directory\" || echo \"No changes to commit\"\n      - name: Push changes\n        run: |\n          git push origin docs\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>"},{"location":"Tools/DevOps/Git/02_CI_CD/#dvc","title":"DVC","text":"<p>Data Version Control</p> <p>You can use an external storage for non-code files.</p> <p>Especially useful for large files</p>"},{"location":"Tools/DevOps/Unit-Testing/","title":"Unit Testing","text":""},{"location":"Tools/DevOps/Unit-Testing/#execution","title":"Execution","text":""},{"location":"Tools/DevOps/Unit-Testing/#install-pytest","title":"Install Pytest","text":"<pre><code>pip install pytest\n</code></pre>"},{"location":"Tools/DevOps/Unit-Testing/#run-the-tests","title":"Run the tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"Tools/DevOps/Unit-Testing/#run-a-specific-file","title":"Run a specific file","text":"<pre><code>pytest test_shopping_cart.py\n</code></pre>"},{"location":"Tools/DevOps/Unit-Testing/#run-a-specific-test","title":"Run a specific test","text":"<pre><code>pytest test_shopping_cart.py::test_can_get_total_price\n</code></pre>"},{"location":"Tools/DevOps/Unit-Testing/#file-naming-convention","title":"File Naming Convention","text":"<p>Files containing tests should start with <code>test_</code></p>"},{"location":"Tools/DevOps/Unit-Testing/#imports","title":"Imports","text":"<pre><code>from unittest.mock import Mock\nfrom item_database import ItemDatabase\nfrom shopping_cart import ShoppingCart\nimport pytest\n</code></pre>"},{"location":"Tools/DevOps/Unit-Testing/#fixture","title":"Fixture","text":"<pre><code>@pytest.fixture\ndef cart():\n    # All setup for the cart here...\n    return ShoppingCart(5)\n</code></pre>"},{"location":"Tools/DevOps/Unit-Testing/#basic-unit-tests","title":"Basic Unit-Tests","text":"<pre><code>def test_can_add_item_to_cart(cart):\n    cart.add(\"apple\")\n    assert cart.size() == 1\n</code></pre> <pre><code>def test_when_item_added_then_cart_contains_item(cart):\n    cart.add(\"apple\")\n    assert \"apple\" in cart.get_items()\n</code></pre> <pre><code>def test_when_add_more_than_max_items_should_fail(cart):\n    for _ in range(5):\n        cart.add(\"apple\")\n\n    with pytest.raises(OverflowError):\n        cart.add(\"apple\")\n</code></pre>"},{"location":"Tools/DevOps/Unit-Testing/#mocking","title":"Mocking","text":"<pre><code>def test_can_get_total_price(cart):\n    cart.add(\"apple\")\n    cart.add(\"orange\")\n    item_database = ItemDatabase()\n\n    def mock_get_item(item: str):\n        if item == \"apple\":\n            return 1.0\n        if item == \"orange\":\n            return 2.0\n\n    item_database.get = Mock(side_effect=mock_get_item)\n    assert cart.get_total_price(item_database) == 3.0\n</code></pre>"},{"location":"Tools/Documentation/Latex/","title":"Latex","text":""},{"location":"Tools/Documentation/Latex/#enclosed-text","title":"Enclosed text","text":"<pre><code>\\enclose{circle}{\\enclose{circle}{S_5}} % mathjax\n\n\\textcircled{R} % latex/katex\n</code></pre>"},{"location":"Tools/Documentation/Latex/#subset","title":"Subset","text":"<pre><code>abc\n\\overset{\n  \\substack{a=1\\\\b=2\\\\c=3}\n}{\n  =\n}\nc\n</code></pre>"},{"location":"Tools/Documentation/Latex/#mathclap","title":"Mathclap","text":"<p>Basically equivalent to <code>position: absolute</code> in CSS Its position does not affect other elements</p> <pre><code>\\mathclap{\\text{Long Text}}\n\n% always user for underbrace and overbrace\nx \\underbrace{y}_{\\text{Long Text}} z \\\\\nx \\underbrace{y}_{\\mathclap{\\text{Long Text}}} z\n</code></pre>"},{"location":"Tools/Documentation/Latex/#align","title":"Align","text":"<ul> <li><code>{aligned}</code></li> <li><code>{alignedat}{1}</code></li> </ul> <pre><code>\\begin{alignedat}{1}\nE[&amp;\\text{PVGO}]\n&amp;&amp;= P_{\\text{Growth}}\n&amp;- P_{\\text{No Growth}}\n\\\\\n&amp;\\text{PVGO}_\\text{Actual}\n&amp;&amp;= P_\\text{Actual}\n&amp;- P_{\\text{No Growth}}\n\\end{alignedat}\n</code></pre>"},{"location":"Tools/Documentation/Markdown/","title":"Markdown","text":""},{"location":"Tools/Documentation/Mermaidjs/","title":"Mermaidjs","text":""},{"location":"Tools/Documentation/Mermaidjs/#diagram-title","title":"Diagram Title","text":"<pre><code>---\ntitle: Title\n---\nflowchart LR\na --&gt; b</code></pre>"},{"location":"Tools/Documentation/Mermaidjs/#pie-chart","title":"Pie Chart","text":"<pre><code>pie\n\"A\": 1\n\"B\": 3\n\"C\": 6</code></pre>"},{"location":"Tools/Documentation/Quarto/","title":"Quarto","text":"<pre><code>name: Render and Publish\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\n# you need these permissions to publish to GitHub pages\npermissions:\n  contents: write\n  pages: write\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v4\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        env:\n          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n        #with:\n        # To install LaTeX to build PDF book\n        #tinytex: true\n        # uncomment below and fill to pin a version\n        # version: SPECIFIC-QUARTO-VERSION-HERE\n\n      # add software dependencies here and any libraries\n\n      # From https://github.com/actions/setup-python\n      # - name: Setup Python\n      #   uses: actions/setup-python@v3\n\n      # From https://github.com/r-lib/actions/tree/v2-branch/setup-r\n      - name: Setup R\n        uses: r-lib/actions/setup-r@v2\n\n      # From https://github.com/julia-actions/setup-julia\n      # - name: Setup Julia\n      #   uses: julia-actions/setup-julia@v1\n\n      # See more at https://github.com/quarto-dev/quarto-actions/blob/main/examples/example-03-dependencies.md\n\n      # To publish to Netlify, RStudio Connect, or GitHub Pages, uncomment\n      # the appropriate block below\n\n      # - name: Publish to Netlify (and render)\n      #   uses: quarto-dev/quarto-actions/publish@v2\n      #   with:\n      #     target: netlify\n      #     NETLIFY_AUTH_TOKEN: ${{ secrets.NETLIFY_AUTH_TOKEN }}\n\n      # - name: Publish to RStudio Connect (and render)\n      #   uses: quarto-dev/quarto-actions/publish@v2\n      #   with:\n      #     target: connect\n      #     CONNECT_SERVER: enter-the-server-url-here\n      #     CONNECT_API_KEY: ${{ secrets.CONNECT_API_KEY }}\n\n      # NOTE: If Publishing to GitHub Pages, set the permissions correctly (see top of this yaml)\n      - name: Publish to GitHub Pages (and render)\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions\n\n\n      # - name: Publish to confluence\n      #   uses: quarto-dev/quarto-actions/publish@v2\n      #   with:\n      #     target: confluence\n      #   env:\n      #     CONFLUENCE_USER_EMAIL: ${{ secrets.CONFLUENCE_USER_EMAIL }}\n      #     CONFLUENCE_AUTH_TOKEN: ${{ secrets.CONFLUENCE_AUTH_TOKEN }}\n      #     CONFLUENCE_DOMAIN: ${{ secrets.CONFLUENCE_DOMAIN }}\n</code></pre>"},{"location":"Tools/FEA/Abaqus/","title":"Abaqus CAE","text":"<p>CAE = Complete Abacus Environment (back-acronym); usually CAE = Computer Aided Engineering</p> <p>Software application used for modeling and analysis of mechanical components and assemblies (pre-processing) and visualizing the finite element analysis result.</p>"},{"location":"Tools/FEA/Abaqus/#references","title":"References","text":"<ul> <li> https://www.youtube.com/playlist?list=PL8JBtohft2fuXL6zj1ZETOTBtM8ydfMd6</li> <li> https://ifcuriousthenlearn.com/blog/2015/04/02/Abaqus-FEA-Scripting-with-python/</li> </ul>"},{"location":"Tools/FEA/Abaqus/01_Introduction/","title":"Introduction","text":"<pre><code>flowchart LR\nsubgraph CAE\n  GUI &amp; CLI &amp; Script --&gt;\n  |Commands| pi[Python&lt;br /&gt;Interpreter] --&gt;\n  ak[Abaqus&lt;br /&gt;Kernel] &amp; rf[Replay Files]\nend</code></pre>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#units","title":"Units","text":"<p>Abaqus does not have a unit system. You need to use everything based on SI/SI(mm) units.</p>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#interface","title":"Interface","text":""},{"location":"Tools/FEA/Abaqus/01_Introduction/#tools-tree","title":"Tools Tree","text":"<ul> <li>Model</li> <li>Analysis</li> </ul>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#analysis-tree","title":"Analysis Tree","text":"<ul> <li>Jobs</li> </ul>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#files","title":"Files","text":"Gets updated when Cleared when <code>.cae</code> Project file Interact with GUI Never <code>.rpy</code> Replay Python fileAllows to recreate the modelContains all used actionsOnly 5 recent versions of replay files will be retained Interact with GUI New session starts <code>.jnl</code> Journal/LogStores used model-related commandsAllows to recreate the model if model database gets corrupt Save model database Never <code>.rec</code> Recovery fileStores unused model-related commandsUseful if Abacus aborts unexpectedly Interact with GUI Save CAE file <code>.odb</code> Output DataBase from modelling stageAnalysis result data &amp; model-related info: Nodes, elements, surfaces, sets <code>.inp</code> Input configuration file for analysis stage <code>.rpt</code> Report file images Exported"},{"location":"Tools/FEA/Abaqus/01_Introduction/#types-of-objects","title":"Types of Objects","text":""},{"location":"Tools/FEA/Abaqus/01_Introduction/#properties","title":"Properties","text":"<ul> <li>Deformable</li> <li>Rigid Discrete</li> <li>Rigid Analytical</li> </ul> Object treated as Deformable Block that deforms due to forces Rigid Solid block that cannot be deformed Discrete \u201cmesh\u201d of atomic \u201cdiscrete/finite elements\u201d Analytical Bounding box"},{"location":"Tools/FEA/Abaqus/01_Introduction/#geometry","title":"Geometry","text":"Shell Wire Point"},{"location":"Tools/FEA/Abaqus/01_Introduction/#mesh-element-type","title":"Mesh Element Type","text":"Type TriangularCPS3R Faster computation QuadCPS4R Better geometric precision Quad-Dominated Compromise between both"},{"location":"Tools/FEA/Abaqus/01_Introduction/#views","title":"Views","text":"Feature Edges"},{"location":"Tools/FEA/Abaqus/01_Introduction/#properties-of-mesh","title":"Properties of Mesh","text":"Value when mesh is broken PHILSM 1 PSILSM 0"},{"location":"Tools/FEA/Abaqus/01_Introduction/#export","title":"Export","text":""},{"location":"Tools/FEA/Abaqus/01_Introduction/#image","title":"Image","text":"<ol> <li>Open ODB</li> <li>Display ODB to viewport</li> <li>Set field output to viewport</li> <li>Adjust view commands</li> <li>File &gt; Print &gt; File</li> </ol>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#field-report","title":"Field Report","text":"<p>Method to output data at desired locations, for a single frame within a single step at a time</p>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#procedure","title":"Procedure","text":"<ol> <li>Report</li> <li>Field Output</li> </ol>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#display-group","title":"Display Group","text":"<ol> <li>Create display group</li> <li>Pick from viewport</li> </ol>"},{"location":"Tools/FEA/Abaqus/01_Introduction/#speed-up-simulation","title":"Speed Up Simulation","text":"<ul> <li>Decrease time period to 0.1</li> <li>Increase max increment size</li> <li>Useful if you are just interested in final output only</li> <li>Use more cores</li> <li>Reduce output requests</li> <li>Reduce mesh in unnecessary portions</li> <li>Check element formulation</li> <li>Use Reduced integration/linear geometric order</li> <li>Use small artificial damping</li> </ul>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/","title":"Python Scripting","text":"<p>This assumes that you are proficient at Python</p> <p>https://www.youtube.com/watch?v=lesRkx0aPeA&amp;list=PL8JBtohft2fuXL6zj1ZETOTBtM8ydfMd6&amp;index=4</p>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#why-scripting","title":"Why Scripting?","text":"<ul> <li>Interact with underlying Abacus data structure</li> <li>Allows to extend out-of-box functionality</li> <li>Automate repetitive pre/post-processing taks</li> <li>Mathematically post-process FE data</li> <li>Custom GUI</li> <li>Perform parametric studies</li> </ul>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#run-python-scripts","title":"Run Python Scripts","text":"Mode Free Limitations Error Handling CLI Python-Only <code>abaqus python script.py</code> \u2705 Not all features are supported :/ Stop CLI CAE + Viewer <code>abaqus cae noGUI=script.py</code> \u274c Stop CLI Viewer-Only <code>abaqus viewer noGUI=script.py</code> \u274c Stop CLI <code>abaqus cae replay=abaqus.rpy</code> \u274c Ignore &amp; continue CLI <code>abaqus cae recover=my_model.jnl</code> \u274c GUI Menu <code>File &gt; Run Script</code> \u274c Stop GUI Abacus CLI <code>excefile(\"script.py\")</code> \u274c Stop"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#basics","title":"Basics","text":"<pre><code># imports\nfrom abaqus import *\nfrom abaqusConstants import *\nfrom caeModules import *\nfrom driverUtils import executeOnCaeStartup\n\n# setup\nexecuteOnCaeStartup()\n\n# Create model\nmodel = mdb.Model(name=\"Model A\")\n\n# creating sketch\ns = myModel.ConstrainedSketch(\n    name = \"__profile__\",\n  sheetSize = 200.0\n)\n\n# Drawing model sketch\ns.Line(\n    point1=(0.0, 0.0),\n  point2=(0.0, 1.0)\n)\ns.Line(\n    point1=(0.0, 1.0),\n  point2=(1.0, 1.0)\n)\ns.Line(\n    point1=(1.0, 1.0),\n  point2=(1.0, 0.0)\n)\ns.Line(\n    point1=(1.0, 0.0),\n  point2=(0.0, 0.0)\n)\n\n# Creating part object\np = (\n  model\n  .Part(\n    name = \"rect_beam\",\n    dimensionality = THREE_D,\n    type=DEFORMABLE_BODY\n  )\n)\n\n# extrude sketch to get the part\np.BaseSolidExtrude(\n    sketch=s,\n  depth=20.0\n)\ns.unsetPrimaryObject()\n\n# setting part to the viewport\n(\n  session\n  .viewports[\"Viewport: 1\"]\n  .setValues(displayedObject=p)\n)\n\n# clear\ndel model.sketches[\"__profile__\"]\n</code></pre> <pre><code># imports\nfrom abaqus import *\nfrom abaqusConstants import *\nimport visualizatino\n\n# opening the db\nmy_odb = (\n    visualization\n  .openOdb(path = \"beam_model.odb\")\n)\n\nviewport = session.viewports[session.currentViewPortName]\n(\n  viewport\n  .setValues(displayedObject=my_odb)\n)\n\n# accessing the step-1 from the ODB\nmystep = my_obd.steps[\"Step-1\"]\n\n# accessing the frames of step1\nframe1 = mystep.frames[-1]\nframe2 = mystep.frames[-2]\n\ndisp1 = frame1.fieledOutputs[\"U\"]\ndisp2 = frame2.fieledOutputs[\"U\"]\n\nstress1 = frame1.fieledOutputs[\"S\"]\nstress2 = frame2.fieledOutputs[\"S\"]\n\ndeltaDisp = disp2 - disp1\ndeltaStress = stress2 - stress1\n\n(\n  viewport\n  .obdDisplay\n  .setDeformedVariables(deltaDisp)\n)\n\n# Plotting thecontour for the new data\n(\n  viewport\n  .obdDisplay\n  .setPrimaryVariable(\n      field = deltaStress,\n    outputPosition = INTEGRATION_POINT,\n    refinement = (INVARIANT, \"Mises\")\n  )\n)\n\nviewport.odbDispaly.display.setValues(\n    plotState=(CONTOURS_ON_DEF)\n)\n</code></pre> <pre><code># saving data to a text file\nwith open(\"delta_displacement.dat\", \"w\") as fout:\n  fout.write(\"%8d, %15.8E, %15.8E, %15.8E\\n\" % tuple([value.nodeLabel, ] + list(value.data)))\n</code></pre>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#step","title":"Step","text":"<p>Attributes</p> <ul> <li>Name</li> <li>Step number</li> <li>nlgoem</li> </ul> <p>Methods</p> <ul> <li>getFrame</li> <li>frames</li> <li>setDefaultField</li> </ul> <pre><code>(\n  odb\n  .steps[\"step-1\"]\n  .frames[1]\n  .fieldOutputs[\"U\"]\n  .values[0]\n  .data\n)\n</code></pre>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#abaqus-objects","title":"Abaqus Objects","text":""},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#session","title":"Session","text":"<ul> <li>odbs</li> <li>defaultOdbDisplay</li> <li>displayGroups</li> <li>colors</li> <li>printOptions</li> <li>psOptions</li> <li>epsOptions</li> <li>pngOptions</li> <li>xyPlots</li> <li>animationController</li> <li>views</li> <li>viewports</li> <li>paths</li> </ul>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#mdb","title":"Mdb","text":"<ul> <li>models</li> <li>Model<ul> <li>amplitudes</li> <li>parts</li> <li>interactions</li> <li>loads</li> <li>materials</li> <li>steps</li> <li>sections</li> <li>rootAssembly</li> </ul> </li> <li>jobs</li> </ul>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#odb","title":"Odb","text":"<code>import visualization</code><code>openOdb()</code> <code>import odbAccess</code><code>openOdb()</code> Use in Abacus CAE \u2705 \u2705 Use in Abacus Python \u274c \u2705 Multiple ODB accessible simultaneously? \u2705 \u274c Free? \u274c \u2705 <ul> <li>rootAssembly</li> <li>parts</li> <li>sectionCategories</li> <li>steps</li> <li>name</li> <li>nlgoem</li> <li>frames</li> <li>getFrame()</li> <li>setDefaultField()</li> <li>getHistoryRegion()</li> <li>save()</li> <li>close()</li> </ul>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#journalling-options","title":"Journalling options","text":"<pre><code>(\n  session\n  .journalOptions\n  .setValues(\n    replayGeometry=COORDINATE,\n    recoverGeometry=COORDINATE\n  )\n)\n</code></pre> Human-Readable Compressed Index(default) <code>getSequenceFromMask</code> \u274c Coordinate <code>findAt()</code><code>getClosest()</code> \u2705 Index Use entity index \u274c"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#compressed-index-mode-default","title":"Compressed Index Mode (default)","text":"<pre><code>all_cells = (\n  mdb\n  .models[\"Model A\"]\n  .parts[\"rect_beam\"]\n  .cells\n)\nselected_cells = (\n  all_cells\n  .getSequencFromMask(\n    mask=(\"[#1 ]\", )\n  )\n)\n</code></pre>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#data-types","title":"Data Types","text":""},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#symbolic-constants","title":"Symbolic Constants","text":"<pre><code>from abaqusConstants import *\n</code></pre>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#abaqus-boolean","title":"Abaqus Boolean","text":"<p><code>ON, OFF</code></p>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#repositories","title":"Repositories","text":""},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#export","title":"Export","text":""},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#images","title":"Images","text":"<pre><code>(\n  session\n  .printToFile(\n    fileName = \"export\",\n    format = PNG,\n    canvasObjects = (\n        session.viewports[\"Viewport: 1\"], \n    )\n  )\n)\n</code></pre>"},{"location":"Tools/FEA/Abaqus/02_Python_Scripting/#field-report","title":"Field Report","text":"<pre><code>session.writeFieldReport(\n    filname=\"report.rpt\",\n  append=ON,\n  sortItem=\"Node Label\",\n  odb=odb,\n  step=0,\n  frame=0,\n  outputPosition=NODAL,\n  variable=((\n    \"S\", INTEGRATION_POINT\n  )),\n)\n</code></pre>"},{"location":"Tools/FEA/Abaqus/03_IDK/","title":"03 IDK","text":"<pre><code>X=[x1,x2,x3 ... xn]\nY=[y1,y2,y3 ... yn]\nZ=[z1,z2,z3 ... zn]\nfor I in range (len(X)):\nfor J in range (len(Y)):\nfor K in range (len(Z)):\nmodelname='P1_'+ str(int(X[I]))+'_'+'P2_'+str(int(Y[J]))+'_'+'P3_'+str(int(Z[K]))\nmymodel=mdb.Model(name=modelname)\n</code></pre> <pre><code># So now you have several Models in Abaqus. Then you write or use Abaqus macro to create your script. At last, you must create a job for each model.\njobname=str(int(X[I]))+'_'+str(int(Y[J]))+'_'+str(int(Z[K]))\n</code></pre> <pre><code>mdb.Job(\n  name=jobname, model=mymodel,description='', type=ANALYSIS, atTime=None, waitMinutes=0, waitHours=0,queue=None, memory=90, memoryUnits=PERCENTAGE,explicitPrecision=SINGLE, nodalOutputPrecision=SINGLE, echoPrint=OFF,modelPrint=OFF, contactPrint=OFF, historyPrint=OFF, userSubroutine='',scratch='', resultsFormat=ODB, parallelizationMethodExplicit=DOMAIN,numDomains=1, activateLoadBalancing=False, multiprocessingMode=DEFAULT,numCpus=1\n       )\n\nmbd.JobFromInputFile(\n\n)\n</code></pre> <pre><code>mdb.jobs[jobname].submit(consistencyChecking=OFF)\nmdb.jobs[jobname].waitForCompletion()\n</code></pre> <pre><code># At last, if you want to run this script without opening Abaqus, open cmd and set a new address to the script.\ncd path\n</code></pre> <pre><code># use this code to run Abaqus\nAbaqus cae noGUI=SCRIPTNAME.py\n</code></pre>"},{"location":"Tools/Google_Sheets/","title":"Google Sheets","text":""},{"location":"Tools/Google_Sheets/Custom_Form/","title":"GSheets API for Custom Form","text":""},{"location":"Tools/Google_Sheets/Custom_Form/#app-script","title":"App Script","text":"<pre><code>const DATA_ENTRY_SHEET_NAME = \"Registration\";\nconst TIME_STAMP_COLUMN_NAME = \"Timestamp\"; // You can edit the name of this column name or you can put blank like this : \"\". Ensure that the same name exist there in the sheet as well.\n\n\nvar sheet = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(DATA_ENTRY_SHEET_NAME);\n\nconst doPost = (request = {}) =&gt; {\n  const { postData: { contents, type } = {} } = request;\n  var data = parseFormData(contents);\n  try {\n    appendToGoogleSheet(data);\n  } catch (e) {\n\n  }\n\n  try {\n    send_confirmation_mail();\n  } catch (e) {\n\n  }\n\n\n return ContentService.createTextOutput(contents).setMimeType(ContentService.MimeType.JSON);\n};\n\nfunction send_confirmation_mail(data) {\n  url = \"https://btf.pythonanywhere.com/send-registration-confirmation?n=\" + data[\"Name\"].replace(\" \", \"+\") + \"&amp;i=\" + data[\"Institution\"].replace(\" \", \"+\") + \"&amp;e=\" + data[\"Email\"].replace(\" \", \"\");\n  UrlFetchApp.fetch(url);\n}\n\nfunction parseFormData(postData) {\n  var data = [];\n  var parameters = postData.split('&amp;');\n  for (var i = 0; i &lt; parameters.length; i++) {\n    var keyValue = parameters[i].split('=');\n    data[keyValue[0]] = decodeURIComponent(keyValue[1]);\n  }\n  return data;\n}\n\nfunction appendToGoogleSheet(data) {\n  if(TIME_STAMP_COLUMN_NAME !==\"\"){\n    data[TIME_STAMP_COLUMN_NAME]=new Date();\n  }\n  var headers = sheet.getRange(1, 1, 1, sheet.getLastColumn()).getValues()[0];\n  var rowData = headers.map(headerFld =&gt; data[headerFld]);\n  sheet.appendRow(rowData);\n}\n</code></pre>"},{"location":"Tools/Google_Sheets/Custom_Form/#client-side","title":"Client-Side","text":"<pre><code>const API_LINK = \"https://script.google.com/macros/s/AKfycbz_FzYhH1h0WZIhvpLicgxWQxqpFnkUGAvLN-oTUdMkImJe_hWqDlaQT8GdPn5MPsVmVA/exec\";\n\nconst Technofest = () =&gt; {\n  const handleSubmit = (event) =&gt; {\n    event.preventDefault();\n    document.getElementById(\"message\").textContent = \"Submitting..\";\n    document.getElementById(\"message\").style.display = \"block\";\n    document.getElementById(\"submit-button\").disabled = true;\n\n    // Collect the form data\n    var formData = new FormData(event.target);\n    var keyValuePairs = [];\n    for (var pair of formData.entries()) {\n      keyValuePairs.push(pair[0] + \"=\" + pair[1]);\n    }\n\n    var formDataString = keyValuePairs.join(\"&amp;\");\n\n    // Send a POST request to your Google Apps Script\n    fetch(API_LINK, {\n      redirect: \"follow\",\n      method: \"POST\",\n      body: formDataString,\n      headers: {\n        \"Content-Type\": \"text/plain;charset=utf-8\",\n      },\n    })\n      .then(function (response) {\n        // Check if the request was successful\n        if (response) {\n          return response; // Assuming your script returns JSON response\n        } else {\n          throw new Error(\"Failed to submit the form.\");\n        }\n      })\n      .then(function (data) {\n        // Display a success message\n        document.getElementById(\"message\").textContent =\n          \"Data submitted successfully!\";\n        document.getElementById(\"message\").style.display = \"block\";\n        document.getElementById(\"message\").style.backgroundColor = \"green\";\n        document.getElementById(\"message\").style.color = \"beige\";\n        document.getElementById(\"submit-button\").disabled = false;\n        event.target.reset();\n\n        setTimeout(function () {\n          document.getElementById(\"message\").textContent = \"\";\n          document.getElementById(\"message\").style.display = \"none\";\n        }, 2600);\n      })\n      .catch(function (error) {\n        // Handle errors, you can display an error message here\n        console.error(error);\n        document.getElementById(\"message\").textContent =\n          \"An error occurred while submitting the form.\" + \": \" + error;\n        document.getElementById(\"message\").style.display = \"block\";\n      });\n  };\n</code></pre>"},{"location":"Tools/Google_Sheets/Extract_Image_Metadata_From_Links/","title":"Extract Image Metadata From Links","text":"<p>Best used alongside in-built <code>IMAGE()</code></p>"},{"location":"Tools/Google_Sheets/Extract_Image_Metadata_From_Links/#app","title":"App","text":"<pre><code>/**\n * Adds a custom menu to the spreadsheet to run the script.\n */\nfunction onOpen() {\n  SpreadsheetApp.getUi()\n      .createMenu('Image Metadata')\n      .addItem('Get Metadata', 'getMetadataWithPrompts')\n      .addToUi();\n}\n\n/**\n * Prompts the user for the URL and output ranges and then runs the main function.\n */\nfunction getMetadataWithPrompts() {\n  const ui = SpreadsheetApp.getUi();\n\n  // Prompt for the URL range\n  const urlRangeResponse = ui.prompt(\n      'Range of image URLs ',\n      '(e.g., A2:A)',\n      ui.ButtonSet.OK_CANCEL);\n\n  // Exit if the user clicks \"Cancel\"\n  if (urlRangeResponse.getSelectedButton() !== ui.Button.OK) {\n    return;\n  }\n  const sourceRange = urlRangeResponse.getResponseText();\n\n  // Prompt for header inclusion\n  const headerResponse = ui.prompt(\n      'Header row included?',\n      'Leave empty to include. Type \"n\" to omit',\n      ui.ButtonSet.OK_CANCEL);\n\n  let includeHeader = true; // Set a default value of true\n\n  if (headerResponse.getSelectedButton() === ui.Button.OK) {\n    // If the user types \"no\" (or \"NO\", \"No\", etc.), set includeHeader to false.\n    if (headerResponse.getResponseText().toLowerCase().trim() === 'no') {\n      includeHeader = false;\n    }\n  } else {\n    // If the user clicks \"Cancel,\" we should exit the script.\n    return;\n  }\n\n  // Prompt for the output start cell\n  const outputCellResponse = ui.prompt(\n      'Starting output cell',\n      '(e.g., B2)',\n      ui.ButtonSet.OK_CANCEL);\n\n  // Exit if the user clicks \"Cancel\"\n  if (outputCellResponse.getSelectedButton() !== ui.Button.OK) {\n    return;\n  }\n  const outputStartCell = outputCellResponse.getResponseText();\n\n  // Run the main function with the collected parameters.\n  getImageMetadata(sourceRange, outputStartCell, includeHeader); \n}\n\n/**\n * Main function to get the image metadata.\n * @param {string} sourceRange A string representing the range of URLs.\n * @param {string} outputStartCell A string representing the starting cell for the output.\n * @param {boolean} includeHeader If true, a header row will be included.\n */\nfunction getImageMetadata(sourceRange, outputStartCell, includeHeader) {\n  const spreadsheet = SpreadsheetApp.getActiveSpreadsheet();\n  const sheet = spreadsheet.getActiveSheet();\n\n  try {\n    const urls = sheet.getRange(sourceRange).getValues().flat();\n    const outputCell = sheet.getRange(outputStartCell);\n    const allResults = [];\n\n    // Add header row based on user input\n    if (includeHeader) {\n      allResults.push([\"File Type\", \"Size (kB)\", \"Width (px)\", \"Height (px)\", \"Aspect Ratio\"]);\n    }\n\n    const chunkSize = 100;\n\n    for (let i = 0; i &lt; urls.length; i += chunkSize) {\n      const chunk = urls.slice(i, i + chunkSize);\n      const requests = [];\n\n      for (let j = 0; j &lt; chunk.length; j++) {\n        const url = chunk[j];\n        if (!url || url.toString().trim() === '' || !is_valid_url(url)) {\n          allResults.push([\"Error: Invalid/Empty URL\", null, null, null, null]);\n          continue;\n        }\n\n        const encodedUrl = encodeURI(url);\n        requests.push({ url: encodedUrl, muteHttpExceptions: true, originalUrl: url });\n      }\n\n      let responses = [];\n      if (requests.length &gt; 0) {\n        responses = UrlFetchApp.fetchAll(requests);\n      }\n\n      let responseIndex = 0;\n      for (let j = 0; j &lt; chunk.length; j++) {\n        const url = chunk[j];\n        if (!url || url.toString().trim() === '' || !is_valid_url(url)) {\n          // Already handled above\n          continue;\n        }\n\n        let metadata = [];\n        const response = responses[responseIndex];\n\n        try {\n          if (!response || response.getResponseCode() &gt;= 400) {\n            throw new Error(HTTP Error: ${response ? response.getResponseCode() : 'No Response'});\n          }\n\n          const blob = response.getBlob();\n          const headers = response.getHeaders();\n          const sizeBytes = blob.getBytes().length;\n          const sizeKB = (sizeBytes / 1024).toFixed(2);\n          const contentType = headers['Content-Type'];\n\n          let fileType = null, width = null, height = null, aspectRatio = null;\n\n          const match = /^(image\\/(\\w+));\\s*width=(\\d+);\\s*height=(\\d+)$/.exec(contentType);\n          if (match) {\n            fileType = match[2];\n            width = parseInt(match[3], 10);\n            height = parseInt(match[4], 10);\n            const commonDivisor = gcd(width, height);\n            aspectRatio = (width / commonDivisor) + \":\" + (height / commonDivisor);\n          } else {\n            fileType = contentType ? contentType.split('/')[1] : null;\n          }\n          metadata = [fileType, sizeKB, width, height, aspectRatio];\n        } catch(e) {\n          metadata = [Error: ${e.message}, null, null, null, null];\n        }\n\n        allResults.push(metadata);\n        responseIndex++;\n      }\n\n      if (i + chunkSize &lt; urls.length) {\n        Utilities.sleep(1 * 1000); // Sleep for 1 second\n      }\n    }\n\n    if (allResults.length &gt; 0) {\n      const outputRange = sheet.getRange(\n        outputCell.getRow(), \n        outputCell.getColumn(), \n        allResults.length, \n        allResults[0].length\n      );\n      outputRange.setValues(allResults);\n    }\n\n    SpreadsheetApp.getUi().alert('\u2705 Completed!');\n  } catch (e) {\n    SpreadsheetApp.getUi().alert('\u274c Error: ' + e.message);\n  }\n}\n\n// Helper function to find the greatest common divisor (GCD) using the Euclidean algorithm\nfunction gcd(a, b) {\n  return b === 0 ? a : gcd(b, a % b);\n}\n\n// Helper function to validate if a URL is in the correct format\nfunction is_valid_url(url) {\n  return url.toString().startsWith('http://') || url.toString().startsWith('https://');\n}\n</code></pre>"},{"location":"Tools/Google_Sheets/Extract_Image_Metadata_From_Links/#custom-function","title":"Custom Function","text":""},{"location":"Tools/Google_Sheets/Extract_Image_Metadata_From_Links/#usage","title":"Usage","text":"<pre><code>=IMAGE_METADATA(C3) // copy-paste for all cells\n=IMAGE_METADATA(C3:C) // for multiple-cells, but mostly will time-out\n\n=ARRAYFORMULA(IMAGE(D3:D))\n</code></pre>"},{"location":"Tools/Google_Sheets/Extract_Image_Metadata_From_Links/#source-code","title":"Source Code","text":"<pre><code>/**  \n * Gets the file type, file size (kB), width (px), and height (px) of images from a list of URLs.  \n * This function is designed to process an entire range at once, avoiding the need for ARRAYFORMULA.  \n *  \n * @param {A2:A} urls A one-dimensional range of image URLs.  \n * @param {TRUE} chunkSize Optional (default = 100). # of asynchronous requests in a single batch  \n * @param {TRUE} includeHeader Optional (default = true). If true, a header row with column names will be included in the output. If false, header row will be omitted.  \n * @returns {string[][]} A two-dimensional array containing the metadata for each URL.  \n * @customfunction  \n */  \n\nfunction IMAGE_METADATA(urls, chunkSize = 100, includeHeader = true) {  \n  const allResults = [];  \n  const urlsToProcess = Array.isArray(urls) ? urls.flat() : [urls];  \n\n  // Add header row only for a range input with more than one row and if the includeHeader parameter is true.  \n  if (Array.isArray(urls) &amp;&amp; urls.length &gt; 1 &amp;&amp; includeHeader === true) {  \n    allResults.push([\"File Type\", \"Size (kB)\", \"Width (px)\", \"Height (px)\", \"Aspect Ratio\"]);  \n  }  \n\n  for (let i = 0; i &lt; urlsToProcess.length; i += chunkSize) {  \n    const chunk = urlsToProcess.slice(i, i + chunkSize);  \n    const requests = [];  \n    const chunkMap = new Map();  \n\n    // 1. Build the array of requests for the current chunk  \n    for (let j = 0; j &lt; chunk.length; j++) {  \n      const url = chunk[j];  \n\n      if (!url || url.toString().trim() === '' || !is_valid_url(url)) {  \n        chunkMap.set(j, null);  \n        continue;  \n      }  \n\n      const encodedUrl = encodeURI(url);  \n      requests.push({ url: encodedUrl, muteHttpExceptions: true });  \n      chunkMap.set(j, encodedUrl);  \n    }  \n\n    // 2. Make all valid requests in the chunk concurrently  \n    let responses = [];  \n    if (requests.length &gt; 0) {  \n      responses = UrlFetchApp.fetchAll(requests);  \n    }  \n\n    const encodedUrlToResponseMap = new Map(requests.map((req, index) =&gt; [req.url, responses[index]]));  \n\n    // 3. Process the results for the current chunk  \n    for (let j = 0; j &lt; chunk.length; j++) {  \n      const url = chunk[j];  \n\n      let metadata = [];  \n      // Handle empty and invalid URLs without fetching  \n      if (!url || url.toString().trim() === '') {  \n        metadata = [null, null, null, null, null];  \n      } else if (!is_valid_url(url)) {  \n        metadata = [\"Error: Invalid URL\", null, null, null, null];  \n      } else {  \n\n        const encodedUrl = encodeURI(url);  \n        const response = encodedUrlToResponseMap.get(encodedUrl);  \n\n        try {  \n          if (!response || response.getResponseCode() &gt;= 400) {  \n            throw new Error(HTTP Error: ${response ? response.getResponseCode() : 'No Response'});  \n          }  \n\n          const blob = response.getBlob();  \n          const headers = response.getHeaders();  \n          const sizeBytes = blob.getBytes().length;  \n          const sizeKB = (sizeBytes / 1024).toFixed(2);  \n          const contentType = headers['Content-Type'];  \n          const match = /^(image\\/(\\w+));\\s*width=(\\d+);\\s*height=(\\d+)$/.exec(contentType);  \n\n          let fileType, width, height, aspectRatio;  \n          if (match) {  \n            fileType = match[2];  \n            width = parseInt(match[3], 10);  \n            height = parseInt(match[4], 10);  \n            const commonDivisor = gcd(width, height);  \n            aspectRatio = (width / commonDivisor) + \":\" + (height / commonDivisor);  \n          } else {  \n            fileType = contentType ? contentType.split('/')[1] : null;  \n            width = null;  \n            height = null;  \n            aspectRatio = null;  \n          }  \n          metadata = [fileType, sizeKB, width, height, aspectRatio];  \n        } catch(e) {  \n          metadata = [Error: ${e.message}, null, null, null, null];  \n        }  \n      }  \n      allResults.push(metadata);  \n\n    }  \n\n    // Add a small delay between chunks to avoid rate limits  \n    if (i + chunkSize &lt; urlsToProcess.length) {  \n      Utilities.sleep(1*1000); // Sleep for x seconds  \n    }  \n  }  \n  return allResults;  \n\n}\n\n// Helper function to find the greatest common divisor (GCD) using the Euclidean algorithm  \nfunction gcd(a, b) {  \n  return b === 0 ? a : gcd(b, a % b);  \n}  \n\n// Helper function to validate if a URL is in the correct format  \nfunction is_valid_url(url) {  \n  return url.toString().startsWith('http://') || url.toString().startsWith('https://');  \n}\n</code></pre>"},{"location":"Tools/Google_Sheets/google_form_onsubmit/","title":"Form Onsubmit","text":"<ul> <li>Trigger</li> </ul>"},{"location":"Tools/Google_Sheets/google_form_onsubmit/#email","title":"Email","text":"<pre><code>const EMAIL_SUBJECT = 'Kayal Email Test';\n\nfunction onFormSubmit(e) {\n  const responses = e.namedValues;\n\n  // const email_superuser = responses['Email Address'][0].trim();\n  const superuser_name = responses['Superuser'][0].trim();\n  person_type = responses[\"Type\"][0].trim();\n\n  let registrand_id, registrand_id_split, registrand_name, registrand_email;\n\n  if (person_type == \"Existing Member\") {\n    registrand_id = responses['Person'][0].trim();\n    registrand_id_split = registrand_id.split(\" - \");\n    registrand_name = registrand_id_split[1];\n\n    const database = SpreadsheetApp.getActiveSpreadsheet();\n\n    const search_string = registrand_id;\n    var textFinder = database.getRange(\"Database!A1:A5000\").createTextFinder(search_string);\n    var match_row = textFinder.findNext().getRow();\n\n    registrand_email = database.getRange(\"Database!B\"+match_row).getValues()[0][0];\n  } else if (person_type == \"New Member\" || person_type == \"Guest\") {\n    registrand_name = responses['Name'][0].trim();\n    registrand_email = responses['Email'][0].trim();\n  } else {\n    return\n  }\n\n  MailApp.sendEmail({\n    to: registrand_email,\n    subject: EMAIL_SUBJECT,\n    htmlBody: createEmailBody(registrand_name, superuser_name),\n  });\n\n  // Append the status on the spreadsheet to the responses' row.\n  const sheet = SpreadsheetApp.getActiveSheet();\n  var row = sheet.getActiveRange().getRow();\n  var column = e.values.length + 1;\n  sheet.getRange(row, column).setValue('Email Sent');\n}\n\nfunction createEmailBody(registrand_name, superuser_name) {\n  // Make sure to update the emailTemplateDocId at the top.\n  var emailBody = \"\" +\n  \"Dear \" + registrand_name +\n  \"&lt;br/&gt;&lt;br/&gt;\" +\n  \"You have been registered by \" + superuser_name + \".\" +\n  \"&lt;br/&gt;&lt;br/&gt;\" +\n  \"Regards\" +\n  \"&lt;br/&gt;\" +\n  \"Kayal Registration Team\";\n\n  return emailBody;\n}\n</code></pre>"},{"location":"Tools/Google_Sheets/google_form_onsubmit/#document","title":"Document","text":"<pre><code>/**\n  Replace the \"&lt;DOCID&gt;\" with your document ID, or the entire URL per say. Should be something like:\n  var EMAIL_TEMPLATE_DOC_URL = 'https://docs.google.com/document/d/asdasdakvJZasdasd3nR8kmbiphqlykM-zxcrasdasdad/edit?usp=sharing';\n*/\n\nvar EMAIL_TEMPLATE_DOC_URL = 'https://docs.google.com/document/d/&lt;DOCID&gt;/edit?usp=sharing';\nvar EMAIL_SUBJECT = 'This is an important email';\n\n/**\n * Sends a customized email for every response on a form.\n *\n * @param {Object} e - Form submit event\n */\nfunction onFormSubmit(e) {\n  var responses = e.namedValues;\n\n  // If the question title is a label, it can be accessed as an object field.\n  // If it has spaces or other characters, it can be accessed as a dictionary.\n\n  /** \n    NOTE: One common issue people are facing is an error that says 'TypeError: Cannont read properties of undefined'\n    That usually means that your heading cell in the Google Sheet is something else than exactly 'Email address'.\n    The code is Case-Sesnsitive so this HAS TO BE exactly the same on line 25 and your Google Sheet.\n  */\n  var email = responses['Email Address'][0].trim();\n  Logger.log('; responses=' + JSON.stringify(responses));\n\n  MailApp.sendEmail({\n    to: email,\n    subject: EMAIL_SUBJECT,\n    htmlBody: createEmailBody(),\n  });\n  Logger.log('email sent to: ' + email);\n\n  // Append the status on the spreadsheet to the responses' row.\n  var sheet = SpreadsheetApp.getActiveSheet();\n  var row = sheet.getActiveRange().getRow();\n  var column = e.values.length + 1;\n  sheet.getRange(row, column).setValue('Email Sent');\n}\n\n/**\n * Creates email body and includes the links based on topic.\n *\n * @param {string} name - The recipient's name.\n * @param {string[]} topics - List of topics to include in the email body.\n * @return {string} - The email body as an HTML string.\n */\nfunction createEmailBody() {\n  // Make sure to update the emailTemplateDocId at the top.\n  var docId = DocumentApp.openByUrl(EMAIL_TEMPLATE_DOC_URL).getId();\n  var emailBody = docToHtml(docId);\n  return emailBody;\n}\n\n/**\n * Downloads a Google Doc as an HTML string.\n *\n * @param {string} docId - The ID of a Google Doc to fetch content from.\n * @return {string} The Google Doc rendered as an HTML string.\n */\nfunction docToHtml(docId) {\n  // Downloads a Google Doc as an HTML string.\n  var url = 'https://docs.google.com/feeds/download/documents/export/Export?id=' +\n            docId + '&amp;exportFormat=html';\n  var param = {\n    method: 'get',\n    headers: {'Authorization': 'Bearer ' + ScriptApp.getOAuthToken()},\n    muteHttpExceptions: true,\n  };\n  return UrlFetchApp.fetch(url, param).getContentText();\n}\n</code></pre>"},{"location":"Tools/Google_Sheets/mail_merge/","title":"Mail merge","text":"<pre><code>// To learn how to use this script, refer to the documentation:\n// https://developers.google.com/apps-script/samples/automations/mail-merge\n\n/*\nCopyright 2022 Martin Hawksey\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    https://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n*/\n\n/**\n * @OnlyCurrentDoc\n*/\n\n/**\n * Change these to match the column names you are using for email \n * recipient addresses and email sent column.\n*/\nconst RECIPIENT_COL  = \"To\";\nconst CC_COL  = \"CC\";\nconst BCC_COL  = \"BCC\";\nconst EMAIL_SENT_COL = \"Email_Sent\";\nconst SUBJECT_COL = \"Subject\";\n\n/** \n * Creates the menu item \"Mail Merge\" for user to run scripts on drop-down.\n */\nfunction onOpen() {\n  const ui = SpreadsheetApp.getUi();\n  ui.createMenu('Mail Merge')\n      .addItem('Send Emails', 'sendEmails')\n      .addToUi();\n}\n\n/**\n * Sends emails from sheet data.\n * @param {string} subjectLine (optional) for the email draft message\n * @param {Sheet} sheet to read data from\n*/\nfunction sendEmails(subjectLine, sheet=SpreadsheetApp.getActiveSheet()) {\n  // option to skip browser prompt if you want to use this code in other projects\n  if (!subjectLine){\n    subjectLine = Browser.inputBox(\"Mail Merge\", \n                                      \"Type or copy/paste the subject line of the Gmail \" +\n                                      \"draft message you would like to mail merge with:\",\n                                      Browser.Buttons.OK_CANCEL);\n\n    if (subjectLine === \"cancel\" || subjectLine == \"\"){ \n    // If no subject line, finishes up\n    return;\n    }\n  }\n\n  // Gets the draft Gmail message to use as a template\n  const emailTemplate = getGmailTemplateFromDrafts_(subjectLine);\n\n  // Gets the data from the passed sheet\n  const dataRange = sheet.getDataRange();\n  // Fetches displayed values for each row in the Range HT Andrew Roberts \n  // https://mashe.hawksey.info/2020/04/a-bulk-email-mail-merge-with-gmail-and-google-sheets-solution-evolution-using-v8/#comment-187490\n  // @see https://developers.google.com/apps-script/reference/spreadsheet/range#getdisplayvalues\n  const data = dataRange.getDisplayValues();\n\n  // Assumes row 1 contains our column headings\n  const heads = data.shift(); \n\n  // Gets the index of the column named 'Email Status' (Assumes header names are unique)\n  // @see http://ramblings.mcpher.com/Home/excelquirks/gooscript/arrayfunctions\n  const emailSentColIdx = heads.indexOf(EMAIL_SENT_COL);\n\n  // Converts 2d array into an object array\n  // See https://stackoverflow.com/a/22917499/1027723\n  // For a pretty version, see https://mashe.hawksey.info/?p=17869/#comment-184945\n  const obj = data.map(r =&gt; (heads.reduce((o, k, i) =&gt; (o[k] = r[i] || '', o), {})));\n\n  // Creates an array to record sent emails\n  const out = [];\n\n  // Loops through all the rows of data\n  obj.forEach(function(row, rowIdx){\n    // Only sends emails if email_sent cell is blank and not hidden by a filter\n    if (row[EMAIL_SENT_COL] == ''){\n      try {\n        const msgObj = fillInTemplateFromObject_(emailTemplate.message, row);\n\n        // See https://developers.google.com/apps-script/reference/gmail/gmail-app#sendEmail(String,String,String,Object)\n        // If you need to send emails with unicode/emoji characters, use MailApp instead of GmailApp\n        // Uncomment advanced parameters as needed (see docs for limitations)\n        MailApp.sendEmail(\n          row[RECIPIENT_COL],\n          row[SUBJECT_COL],\n          msgObj.text,\n          {\n            htmlBody: msgObj.html,\n            bcc: row[BCC_COL],\n            cc: row[CC_COL],\n            // from: 'bitstechfest@dubai.bits-pilani.ac.in',\n            name: 'BITS Tech Fest',\n            // replyTo: row[CC_COL], // the email address that the reply message is sent when you want the reply to go to an email address that is different than the From: address \n            // noReply: true, // if the email should be sent from a generic no-reply email address (not available to gmail.com users)\n            attachments: emailTemplate.attachments,\n            inlineImages: emailTemplate.inlineImages\n          });\n        // Edits cell to record email sent date\n        out.push([new Date()]);\n      } catch(e) {\n        // modify cell to record error\n        out.push([e.message]);\n      }\n    } else {\n      out.push([row[EMAIL_SENT_COL]]);\n    }\n  });\n\n  // Updates the sheet with new data\n  sheet.getRange(2, emailSentColIdx+1, out.length).setValues(out);\n\n  /**\n   * Get a Gmail draft message by matching the subject line.\n   * @param {string} subject_line to search for draft message\n   * @return {object} containing the subject, plain and html message body and attachments\n  */\n  function getGmailTemplateFromDrafts_(subject_line){\n    try {\n      // get drafts\n      const drafts = GmailApp.getDrafts();\n      // filter the drafts that match subject line\n      const draft = drafts.filter(subjectFilter_(subject_line))[0];\n      // get the message object\n      const msg = draft.getMessage();\n\n      // Handles inline images and attachments so they can be included in the merge\n      // Based on https://stackoverflow.com/a/65813881/1027723\n      // Gets all attachments and inline image attachments\n      const allInlineImages = draft.getMessage().getAttachments({includeInlineImages: true,includeAttachments:false});\n      const attachments = draft.getMessage().getAttachments({includeInlineImages: false});\n      const htmlBody = msg.getBody(); \n\n      // Creates an inline image object with the image name as key \n      // (can't rely on image index as array based on insert order)\n      const img_obj = allInlineImages.reduce((obj, i) =&gt; (obj[i.getName()] = i, obj) ,{});\n\n      //Regexp searches for all img string positions with cid\n      const imgexp = RegExp('&lt;img.*?src=\"cid:(.*?)\".*?alt=\"(.*?)\"[^\\&gt;]+&gt;', 'g');\n      const matches = [...htmlBody.matchAll(imgexp)];\n\n      //Initiates the allInlineImages object\n      const inlineImagesObj = {};\n      // built an inlineImagesObj from inline image matches\n      matches.forEach(match =&gt; inlineImagesObj[match[1]] = img_obj[match[2]]);\n\n      return {message: {subject: subject_line, text: msg.getPlainBody(), html:htmlBody}, \n              attachments: attachments, inlineImages: inlineImagesObj };\n    } catch(e) {\n      throw new Error(\"Oops - can't find Gmail draft\");\n    }\n\n    /**\n     * Filter draft objects with the matching subject linemessage by matching the subject line.\n     * @param {string} subject_line to search for draft message\n     * @return {object} GmailDraft object\n    */\n    function subjectFilter_(subject_line){\n      return function(element) {\n        if (element.getMessage().getSubject() === subject_line) {\n          return element;\n        }\n      }\n    }\n  }\n\n  /**\n   * Fill template string with data object\n   * @see https://stackoverflow.com/a/378000/1027723\n   * @param {string} template string containing {{}} markers which are replaced with data\n   * @param {object} data object used to replace {{}} markers\n   * @return {object} message replaced with data\n  */\n  function fillInTemplateFromObject_(template, data) {\n    // We have two templates one for plain text and the html body\n    // Stringifing the object means we can do a global replace\n    let template_string = JSON.stringify(template);\n\n    // Token replacement\n    template_string = template_string.replace(/{{[^{}]+}}/g, key =&gt; {\n      return escapeData_(data[key.replace(/[{}]+/g, \"\")] || \"\");\n    });\n    return  JSON.parse(template_string);\n  }\n\n  /**\n   * Escape cell data to make JSON safe\n   * @see https://stackoverflow.com/a/9204218/1027723\n   * @param {string} str to escape JSON special characters from\n   * @return {string} escaped string\n  */\n  function escapeData_(str) {\n    return str\n      .replace(/[\\\\]/g, '\\\\\\\\')\n      .replace(/[\\\"]/g, '\\\\\\\"')\n      .replace(/[\\/]/g, '\\\\/')\n      .replace(/[\\b]/g, '\\\\b')\n      .replace(/[\\f]/g, '\\\\f')\n      .replace(/[\\n]/g, '\\\\n')\n      .replace(/[\\r]/g, '\\\\r')\n      .replace(/[\\t]/g, '\\\\t');\n  };\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/","title":"Arduino","text":""},{"location":"Tools/IoT/Arduino/#rules","title":"Rules","text":"<p>You can use Arduino to make a commercial product following some simple rules.</p> <ul> <li>if you have made your circuit as a derivative of the Arduino board you must release the design files with a CC-BY-SA license like the original cad files</li> <li>If you build your circuit as a shield that plugs on top of an Arduino board all the circuit is yours and you don't have to release anything</li> <li>The programs written on Arduino are yours. if you have modified the core files or one of the libraries you must make your modifications available to everybody</li> <li>You can call your product in any way you like as long as you don't call it Arduino</li> <li>Credits to Arduino not necessary</li> <li>If in the documentation for your product you want to write \"Powered By Arduino\" that would be appreciated</li> <li>There is no revenue sharing for any derivative work (unless it uses the Arduino name see Arduino - Home )</li> <li>If you patent something you have to do that in every place in the world you want to protect your idea. the more countries the more payments</li> <li>Patents reveal your idea to the whole world.. some people don't patent so they don't have to provide any detail about their invention</li> </ul>"},{"location":"Tools/IoT/Arduino/#references","title":"References","text":"<ul> <li>https://www.youtube.com/watch?v=DPqiIzK97K0</li> </ul>"},{"location":"Tools/IoT/Arduino/01_Basics/","title":"Basics","text":""},{"location":"Tools/IoT/Arduino/01_Basics/#arduino-ide","title":"Arduino IDE","text":"<ul> <li>Install Arduino IDE</li> <li><code>Tools</code> &gt; <code>Manage Libaries</code></li> <li>ESP8266/Node MCU</li> <li> <p><code>Preferences</code> &gt; Additional boards manager URLS</p> <ul> <li> <p>https://arduino.esp8266.com/stable/package_esp8266com_index.json</p> </li> <li> <p><code>Tools</code> &gt; <code>Board</code> &gt; <code>Boards Manager</code> &gt; Search <code>ESP8266</code> &gt; <code>Install</code></p> </li> <li> <p>Ensure <code>CH340g Driver</code> installed</p> </li> <li><code>Tools</code> &gt; <code>Board</code> &gt; Select Board</li> <li><code>Tools</code> &gt; <code>Board</code> &gt; Connect to Port</li> <li>Compile &amp; Upload</li> </ul> </li> </ul>"},{"location":"Tools/IoT/Arduino/01_Basics/#simulators","title":"Simulators","text":"<ul> <li>Wokwi (Open-Source)</li> <li>TinkerCad</li> </ul>"},{"location":"Tools/IoT/Arduino/01_Basics/#code","title":"Code","text":""},{"location":"Tools/IoT/Arduino/01_Basics/#skeleton","title":"Skeleton","text":"<pre><code>void setup(){\n  // initialization code\n}\nvoid loop(){\n  // infinitely-looping code\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#inputoutputs","title":"Input/Outputs","text":"Function Configuring A GPIO pin cannot be used for both input and output. You need to specify one. <code>pinMode(&lt;pin_number&gt;, &lt;i/o&gt;);</code> <code>pinMode(3, INPUT);</code><code>pinMode(3, OUTPUT);</code> Outputs Digital <code>digitalWrite(&lt;pin_number&gt;, &lt;state&gt;);</code> <code>digitalWrite(3, HIGH); // or digitalWrite(3, 1);</code><code>digitalWrite(3, LOW); // or digitalWrite(3, 0);</code> Analog <code>analogWrite(&lt;pin_number&gt;, value);</code> <code>analogWrite(3, 25);</code> <pre><code>// Code for blinking LED\n\nvoid setup(){\n  pinMode(3, OUTPUT);\n}\nvoid loop(){\n  digitalWrite(3, HIGH);\n  delay(1000); // 1000ms\n\n  digitalWrite(3, LOW);\n  delay(1000); // 1000ms\n}\n</code></pre> <pre><code>// Code for changing LED brightness\n\nvoid setup(){\n  pinMode(3, OUTPUT);\n}\nvoid loop(){\n  for (int i=0; i&lt;=1023; i++) {\n    analogWrite(3, i);\n    delay(1000); // 1000ms\n  }\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#serial-monitor","title":"Serial Monitor","text":"<p>Baudrate \\(\\equiv\\) Bitrate</p> <ul> <li>Bitrate is for binary</li> <li>Baudrate is for analog signal</li> </ul> <pre><code>Serial.begin(9600); // ; baudrate // initializes serial monitor\n\nSerial.read() // return ASCII values\n</code></pre> <pre><code>int reading_int;\nchar reading_char;\n\nvoid setup(){\n  Serial.begin(9600);\n}\nvoid loop(){\n  while (Serial.available()){\n    reading_int = Serial.read();\n    reading_char = reading_int;\n\n    Serial.println(reading_int);\n    Serial.println(reading_char);\n  }  \n  delay(500);\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#unique-id-for-arduino","title":"Unique ID for Arduino","text":""},{"location":"Tools/IoT/Arduino/01_Basics/#method-1-automatic-using-external-library","title":"Method 1: Automatic (using external library)","text":"<pre><code>#include &lt;ArduinoUniqueID.h&gt; // in the same folder of this note\n\nfor(size_t i = 0; i &lt; UniqueIDsize; i++)\n  Serial.println(UniqueID[i], HEX);\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#method-2-automatic","title":"Method 2: Automatic","text":"<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;unistd.h&gt;\n#include &lt;sys/fcntl.h&gt;\nint main(int ac, char **av) {\n    int fd, i;\n    unsigned char eui[8];\n    fd = open(\"/dev/random\", O_RDONLY);\n    if (fd &lt; 0) {\n        perror(\"can't open /dev/random\");\n        exit(1);\n    }\n    if (read(fd, eui, sizeof(eui)) != sizeof(eui)) {\n        fprintf(stderr, \"couldn't read %zu bytes\\n\", sizeof(eui));\n        exit(1);\n    }\n    eui[0] = (eui[0] &amp; ~1) | 2;\n    for (i = 0; i &lt; sizeof(eui); ++i) {\n        printf(\"%02X%c\", eui[i], i == sizeof(eui)-1 ? '\\n' : '-');\n    }\n    return 0;\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#method-3-manualcustom-id","title":"Method 3: Manual/Custom ID","text":"<p>Get the code from <code>TOOLS &gt; Get Board Info</code> or put a custom one</p> <p><code>write_id_to_eeprom.ino</code></p> <p><pre><code>char sID[7] = \"AE0001\";\n\n// do this only once on an Arduino, \n// write the Serial of the Arduino in the first 6 bytes of the EEPROM\n\n#include &lt;EEPROM.h&gt;\n\nvoid setup()\n{\n  Serial.begin(9600);\n  for (int i=0; i&lt;6; i++) {\n    EEPROM.write(i,sID[i]);\n  }\n}\n\nvoid loop() {\n  // \n}\n</code></pre> <code>read_id_from_eeprom.ino</code></p> <pre><code>// reads the Serial of the Arduino from the \n// first 6 bytes of the EEPROM\n\n#include &lt;EEPROM.h&gt;\nchar sID[7];\n\nvoid setup()\n{\n  Serial.begin(9600);\n  for (int i=0; i&lt;6; i++) {\n    sID[i] = EEPROM.read(i);\n  }\n  Serial.println(sID);\n}\n\nvoid loop() {\n  // \n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#multi-tasking","title":"Multi-Tasking","text":""},{"location":"Tools/IoT/Arduino/01_Basics/#interrupts","title":"Interrupts","text":"Trigger Meaning in Bits High 1 Low 0 Rising 0-1 Falling 1-0 Change 0-1 or 1-0 <pre><code>void my_func() {\n  delay_seconds = 1;\n  delayMicroseconds(delay_seconds * 1000 * 1000);\n\n  if (digitalRead(buttonPin) == LOW)\n  {\n    return ;\n  }\n\n  led_state = !led_state;\n  digitalWrite(ledPin, ledState);\n}\n\nvoid setup(){\n  pinMode(buttonPin, INPUT);\n  pinMode(ledPin, OUTPUT);\n\n  attachInterrupt(buttonPin, my_func, RISING);\n}\n\nvoid loop() {\n  while(WiFi.connected()){\n\n  }\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#millis-instead-of-delay","title":"<code>millis()</code>\u00a0instead of <code>delay()</code>","text":"<p>Arduino does not support multi-threading/processing, and hence parallel processing is not possible</p> <pre><code>millis()\n// -&gt; unsigned long\n// -&gt; returns number of ms since Arduino powered up/reset\n</code></pre> <pre><code>unsigned long prevTime = millis();\nunsigned long currentTime;\n\nvoid setup() {\n\n}\n\nvoid loop() {\n  currentTime = millis();\n\n  if (currentTime - prevTime &gt; 1000) {\n    doSomething();\n\n    prevTime = currentTime;\n  }\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#example","title":"Example","text":"<pre><code>#define LED1 13\n#define LED2 12\n#define LED3 11\n\n#define BTN 4\n\n// set LED states\nint LED1_state = LOW;\nint brightness = 0;\n\n// previous time for the tasks depending upon time.\nunsigned long prevTime_T1 = millis(); \nunsigned long prevTime_T4 = millis(); \n\n// time intervals for the tasks\nlong interval_T1 = 1000; // blink every 1 second\nlong interval_T4 = 5000; // print brightness of LED3 every 5 seconds\n\nvoid setup() {\n  // put your setup code here, to run once:\n  Serial.begin(9600);\n  pinMode(LED1, OUTPUT);\n  pinMode(LED2, OUTPUT);\n  pinMode(LED3, OUTPUT);\n  pinMode(BTN, INPUT_PULLUP);\n}\n\nvoid loop() {\n  // put your main code here, to run repeatedly:\n  unsigned long currentTime = millis();\n\n  // Task 1 : Blink LED1 (T1)\n  if (currentTime - prevTime_T1 &gt; interval_T1) {\n    LED1_state = !LED1_state;\n    digitalWrite(LED1, LED1_state);\n\n    prevTime_T1 = currentTime;\n  }\n\n  // Task 2 : Glow LED2 when BTN is pressed\n  if (digitalRead(BTN)) {\n    digitalWrite(LED2, LOW);\n  } else {\n    digitalWrite(LED2, HIGH);\n  }\n\n  // Task 3 : Read input from serial monitor (0-255) and then write to LED3\n  if (Serial.available()) {\n    brightness = Serial.parseInt();\n    if (brightness &gt;=0 &amp;&amp; brightness &lt;= 255) {\n      analogWrite(LED3, brightness);\n    }\n  }\n\n  // Task 4 : print the brightness of LED3 in the serial monitor after every 5 seconds\n  if (currentTime - prevTime_T4 &gt; interval_T4) {\n    Serial.print(\"Brightness (0-255): \");\n    Serial.println(brightness);\n\n    prevTime_T4 = currentTime;\n  }\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#code-cloning","title":"Code Cloning","text":""},{"location":"Tools/IoT/Arduino/01_Basics/#how-to","title":"How to","text":"<ul> <li>https://www.youtube.com/watch?v=csNdJIIkzo8</li> </ul>"},{"location":"Tools/IoT/Arduino/01_Basics/#protection","title":"Protection","text":"<ul> <li>https://www.youtube.com/watch?v=G3mRMedchJs</li> </ul>"},{"location":"Tools/IoT/Arduino/01_Basics/#code-security","title":"Code Security","text":""},{"location":"Tools/IoT/Arduino/01_Basics/#mainino","title":"<code>main.ino</code>","text":"<pre><code>#include \"secrets.h\"\n\nvoid setup(){\n  Serial.begin(9600);\n  Serial.println(secret_variable);\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#secretsh","title":"<code>secrets.h</code>","text":"<pre><code>#define secret_variable \"Secret\";\n</code></pre>"},{"location":"Tools/IoT/Arduino/01_Basics/#_1","title":"Basics","text":""},{"location":"Tools/IoT/Arduino/02_WiFi_Connectivity/","title":"WiFi Connectivity","text":"<pre><code>WiFi.scanNetworks();\nWiFi.SSID(i);\nWiFi.RSSI(i);\nWiFi.begin(ssid, pass);\nWiFi.status();\nWiFi.localIP();\n</code></pre> <pre><code>WiFiServer server(local_port);\nserver.begin();\n</code></pre> <pre><code>WiFiClient = server.available();\nclient.readStringUntil(\"\\r\");\n</code></pre>"},{"location":"Tools/IoT/Arduino/02_WiFi_Connectivity/#show-wifi-networks","title":"Show WiFi Networks","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n\nvoid setup(){\n    Serial.begin(9600);\n}\n\nvoid loop(){\n  Serial.println(\"Scanning WiFi\");\n\n  int no_of_networks = WiFi.scanNetworks(); // only 2.4GHz for NodeMCU\n\n  if (n==0) {\n    Serial.println(\"No networks available\");\n  } else {\n    for (int i=0; i&lt;n; i++) {\n      Serial.println(\n        String(i+1) + \" \" + WiFi.SSID(i) + \" \" + String(WiFi.RSSI(i))\n      );\n    }\n  }\n\n  delay(5000);\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/02_WiFi_Connectivity/#connect-to-network","title":"Connect to Network","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n\n// variables\n// we need to use these exact types and names, to override the one in the header file\nchar* ssid = \"WiFi Name\";\nchar* pass = \"WiFi Password\";\n\nvoid setup(){\n    Serial.begin(9600);\n  pinMode(D2, OUTPUT);\n\n  Serial.println(\"Connecting to WiFi...\");\n  WiFi.begin(ssid, pass);\n\n\n  while(WiFi.status() != WL_CONNECTED) {\n    Serial.print(\".\");\n    delay(1000);\n  }\n\n  Serial.println(\"Connected to \" + String(ssid) + \" successfully\");\n}\n\nvoid loop(){\n  // code\n\n  delay(5000);\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/02_WiFi_Connectivity/#local-server","title":"Local Server","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n\n// variables\n// we need to use these exact types and names, to override the one in the header file\nchar* ssid = \"WiFi Name\";\nchar* pass = \"WiFi Password\";\n\nint local_port = 80;\nWiFiServer server(local_port);\n\nvoid setup(){\n    Serial.begin(9600);\n  pinMode(D2, OUTPUT);\n\n  Serial.println(\"Connecting to WiFi...\");\n  WiFi.begin(ssid, pass);\n\n\n  while(WiFi.status() != WL_CONNECTED) {\n    Serial.print(\".\");\n    delay(1000);\n  }\n\n  Serial.println(\"Connected to \" + String(ssid) + \" successfully.\");\n\n  server.begin(local_port);\n\n  local_ip = WiFi.localIP();\n\n  Serial.println(\n    \"Started server on \" + String(local_ip) + \":\" + String(local_port) + \" successfully.\"\n  );\n}\n\nvoid loop(){\n  WiFiClient client = server.available();\n  if (!client) {\n    return;\n  }\n  Serial.println(\"New request received!\");\n  String request = client.readStringUntil(\"\\r\");\n\n  query_path = \"/on\"\n  /*\n  localhost/on turns on LED\n  localhost/off turns off LED\n  */\n  if (request.indexOf(query_path) != -1){\n    digitalWrite(D2, HIGH);\n    Serial.println(\"LED turned on\");\n  }\n  else if (request.indexOf(query_path) != -1){\n    digitalWrite(D2, LOW);\n    Serial.println(\"LED turned off\");\n  } else {\n    Serial.println(\"Invalid request\");\n  }\n\n  client_interaction_code = \"\" +\n    \"&lt;html&gt;&lt;body&gt;\" + \n    \"&lt;button&gt;&lt;a href='/on'&gt;On&lt;/a&gt;&lt;/button&gt;\" +\n    \"&lt;button&gt;&lt;a href='/off'&gt;Off&lt;/a&gt;&lt;/button&gt;\" +\n    \"&lt;/body&gt;&lt;/html&gt;\";\n\n  delay(5000);\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/02_WiFi_Connectivity/#client","title":"Client","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n\n// variables\n// we need to use these exact types and names, to override the one in the header file\nchar* ssid = \"WiFi Name\";\nchar* pass = \"WiFi Password\";\n\nint local_port = 80;\nWiFiClient client;\n\nchar* api_key = \"\";\nint id_server = ;\nchar ip_server[] = \"\";\n\nvoid setup() {\n  Serial.begin(9600);\n\n  Serial.println(\"Connecting to WiFi ...\");\n  WiFi.begin(ssid, pass);\n  while (WiFi.status() != WL_CONNECTED)\n  {\n    Serial.print(\".\");\n    delay(1000);\n  }\n  Serial.println(\"WiFi connected\");\n\n  // ThingSpeak.begin(client);\n}\n\nvoid loop() {\n  if (client.connect(ip_server, local_port)) {\n    ThingSpeak.setField(1, data);\n    ThingSpeak.writeFields(id_server, api);\n  }\n\n  delay(5000);\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/02_WiFi_Connectivity/#http-requests","title":"HTTP Requests","text":""},{"location":"Tools/IoT/Arduino/02_WiFi_Connectivity/#send","title":"Send","text":"<pre><code>#include &lt;ESP8266WiFi.h&gt;\n#include &lt;ESP8266HTTPClient.h&gt;\n\n// variables\n// we need to use these exact types and names, to override the one in the header file\nchar* ssid = \"WiFi Name\";\nchar* pass = \"WiFi Password\";\n\nHTTPClient client;\nString api;\nint data;\nint status_code;\nString response;\n\nvoid setup(){\n    Serial.begin(9600);\n  pinMode(D2, OUTPUT);\n\n  Serial.println(\"Connecting to WiFi...\");\n  WiFi.begin(ssid, pass);\n\n\n  while(WiFi.status() != WL_CONNECTED) {\n    Serial.print(\".\");\n    delay(1000);\n  }\n\n  Serial.println(\"Connected to \" + String(ssid) + \" successfully\");\n}\n\nvoid loop(){\n  data = 100;\n  api = \"http://.../insert.php?data=\" + String(data);\n\n  client.begin(api);\n\n  status_code = client.GET();\n  response = client.getString();\n\n  delay(5000);\n}\n</code></pre>"},{"location":"Tools/IoT/Arduino/ArduinoUniqueID_Library/","title":"ArduinoUniqueID","text":"<p>https://github.com/ricaun/ArduinoUniqueID</p>"},{"location":"Tools/NLP/","title":"NLP","text":""},{"location":"Tools/NLP/#references","title":"References","text":"<ul> <li> Topic Modeling and Text Classification with Python for Digital Humanities (DH) | Python Tutorials for Digital Humanities</li> </ul>"},{"location":"Tools/NLP/Spacy/","title":"Spacy","text":""},{"location":"Tools/NLP/Spacy/#references","title":"References","text":"<ul> <li>Advanced NLP with spaCy | Explosion</li> <li>Natural Language Processing with spaCy &amp; Python | freeCodeCamp.org</li> <li>SpaCy for Digital Humanities with Python Tutorials</li> </ul>"},{"location":"Tools/PowerPlatform/","title":"PowerPlatform","text":"<p>Useful low-code tools that come bundled with default O365 license</p>"},{"location":"Tools/PowerPlatform/PowerApps/","title":"PowerApps","text":"<p>Low-Code software that allows \u201ccitizen developers\u201d to create small/medium-scale solutions</p> <p>PowerFX is the prog. Lang, and it is very similar to javascript</p>"},{"location":"Tools/PowerPlatform/PowerApps/01_Basics/","title":"Basics","text":""},{"location":"Tools/PowerPlatform/PowerApps/01_Basics/#variables","title":"Variables","text":"Global Entire app <code>Set(variable, true);</code> Context Local variables to a screen <code>UpdateContext({variable: true});</code>"},{"location":"Tools/PowerPlatform/PowerApps/01_Basics/#basic-functions","title":"Basic Functions","text":"<pre><code>Navigate('Screen Name');\nConcurrent(\n    action1,\n    action2\n);\nSelect('Button Name'); // always should be at end of code block\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/01_Basics/#timer","title":"Timer","text":"<p>It does not work on code view</p>"},{"location":"Tools/PowerPlatform/PowerApps/01_Basics/#gallery","title":"Gallery","text":"<pre><code>Select(\n  Tab,\n  current_tab_selected,\n  Tab_Button\n);\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/01_Getting_Data/","title":"01 Getting Data","text":""},{"location":"Tools/PowerPlatform/PowerApps/01_Getting_Data/#get-data","title":"Get Data","text":""},{"location":"Tools/PowerPlatform/PowerApps/01_Getting_Data/#single-row","title":"Single Row","text":"<pre><code>Lookup(\n  List,\n  Cond1 &amp;&amp; Cond2\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/01_Getting_Data/#multiple-rows","title":"Multiple Rows","text":"<pre><code>Filter(\n  List,\n  Cond1,\n  Cond2\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/01_Getting_Data/#delegability","title":"Delegability","text":"<p>Only concerns online data sources, not collections</p> <ul> <li>Delegable</li> <li><code>Filter()</code></li> <li><code>`Lookup()</code></li> <li>Non-Delegable</li> <li><code>AddColumns</code>, <code>ShowColumns</code>, <code>DropColumns</code>, <code>RemoveColumns</code></li> </ul> <p>Magical blue squigglies only come out on operators, not on functions. So you would not see that showing a warning.</p>"},{"location":"Tools/PowerPlatform/PowerApps/01_Getting_Data/#in-vs-lookup","title":"<code>In vs LookUp</code>","text":"<pre><code>my_list = [1, 2, 3, 4, 5, ..., 1000]\nkey = 2\n\n# in\nfor i in range(len(my_list)):\n  if my_list[i] == key:\n    print(\"found\")\n\n# lookup\nfor i in range(len(my_list)):\n  if my_list[i] == key:\n    print(\"found\")\n    break\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/01_Getting_Data/#idk","title":"IDK","text":"<p>If you are testing delegability, set the delegation limit as 1, and check if everything works</p>"},{"location":"Tools/PowerPlatform/PowerApps/02_Displaying_Data/","title":"02 Displaying Data","text":""},{"location":"Tools/PowerPlatform/PowerApps/02_Displaying_Data/#gallery","title":"Gallery","text":"<p>Use gallery whenever possible instead of individual buttons/boxes</p> Disadvantage Fixed gallery Flexible gallery Loading issues in aspect ratio of app is unlocked <p>Dynamic height for menus container</p> <pre><code>Gallery_Item.Height * Gallery.AllItemsCount\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/02_Displaying_Data/#pivoted-gallery","title":"Pivoted Gallery","text":"<p>If you have a Sharepoint site that is in long-format, but you want a grid view of it.</p> <p>Nested gallery</p>"},{"location":"Tools/PowerPlatform/PowerApps/02_Forms/","title":"Forms","text":"<ul> <li>Gallery   Onselect: Set(SelectedItem, ThisItem)</li> <li>Form   Datasource: Live Source</li> <li>Item: SelectedItem</li> </ul>"},{"location":"Tools/PowerPlatform/PowerApps/02_Forms/#displaymode","title":"DisplayMode","text":"New Edit View"},{"location":"Tools/PowerPlatform/PowerApps/02_Forms/#idk","title":"IDK","text":"<p>For date inputs, Set <code>IsEditable</code> to <code>false</code></p> <p><code>Onsuccess</code></p> <pre><code>Notify(\"Success\");\nBack();\nResetForm(Form_Name);\n</code></pre> <p><code>Onfailure</code></p> <pre><code>Notify(\"Failure\", Form_Name.Error, Form_Name.ErrorKind)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/02_Forms/#dropdown-for-text-column","title":"Dropdown for text column","text":"<pre><code>// Default_selected_items \n[ LookUp(StorageLocationbyRegion, StorageLocation = Parent.Default) ]\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/02_Forms/#copy-form","title":"Copy Form","text":"<pre><code>If(\n  use_previous_data,\n  First(DropColumns(Table(Create_Item.LastSubmit), \"ID\")),\n  Blank()\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/03_Patching/","title":"Patching","text":""},{"location":"Tools/PowerPlatform/PowerApps/03_Patching/#patch","title":"<code>Patch</code>","text":"<pre><code>Patch(\n    List_Name,\n    {\n        Col1: \"foo\"\n    }\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/03_Patching/#error-handling","title":"Error Handling","text":"<pre><code>Set(\n    errors,\n    Errors(List_Name)\n);\nIf(\n  IsEmpty(errors),\n  Notify(\"Success\", Notification.Success),\n  Notify(First(error).Message, Notification.Error)\n);\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/03_Patching/#advanced","title":"Advanced","text":"<p>For creating record, use</p> <pre><code>Patch(\n  Data_Source,\n  Table({\n    Title:\"Num1\",\n      number:1\n  })\n)\n</code></pre> <p>instead of</p> <pre><code>Patch(\n    dummyData,\n  Defaults(dummyData),\n  {Title:\"Num1\",number:1}\n)\n</code></pre> <p>For updating record, use</p> <pre><code>Patch(dummyData,{ID:1},{Title:\"Num1\",number:1})\n</code></pre> <p>instead of</p> <pre><code>Patch(dummyData,\n  LookUp(dummyData,ID=1),\n  {Title:\"Num1\",number:1}\n)\n</code></pre> <p>Batch patching</p> <pre><code>Patch(\n  Data_Source_Name,\n  ShowColumns(Collection_Name, \"ID\", \"FullName\", \"Status\")\n)\n\n// idk\nForAll(\n    Add_Users_Input.SelectedItems As user_to_add,\n    Collect(\n      users_to_add,\n      Table({\n        Name: user_to_add,\n        Country_Code: LookUp(Choices([@Users].Country_Code), Value=country_code),\n        Superuser: false\n      })\n    )\n);\nIfError(\n    Patch(\n        Users,\n        users_to_add\n    );\n    Notify(\n        \"Successfully added users\",\n        NotificationType.Success\n    );\n    Reset(Add_Users_Input);\n    ,\n    Notify(\n        \"Addition of users failed\",\n        NotificationType.Error\n    );\n\n);\nClear(users_to_add);\n</code></pre> <p>instead of</p> <pre><code>ForAll(\n  colUpdateEmployees,\n  Patch(\n      Employees,\n      LookUp(Employees, ID=colUpdateEmployees[@ID]),\n      {\n        FullName: colUpdateEmployees[@FullName],\n        Active: colUpdateEmployees[@Active]\n      }\n    )\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/03_Patching/#people-column","title":"People Column","text":"<pre><code>Patch(\n  data_source,\n  {\n      Person_Column: {\n        '@odata.type': \"#Microsoft.Azure.Connectors.SharePoint.SPListExpandedUser\",\n        Department: \"\",\n        Claims: \"i:0#.f|membership|\" &amp; User().Email,\n        DisplayName: Office365Users.UserProfileV2(User().Email).displayName,\n        Email: User().Email,\n        JobTitle: \"\",\n        Picture: \"\"\n      }\n  }\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/","title":"Performance","text":""},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/#loading-data","title":"Loading Data","text":"<p>Try to do as much as possible on the server-side. \u2018Lazily load\u2019 only what is required in the current tab onto local collection for repeated operations, such as fuzzy search.</p> <pre><code>sequenceDiagram\nautonumber\nactor u as User\nparticipant a as App\nparticipant c as Current_View_Data_Collection\nparticipant il as List\n\nu -&gt;&gt; a: Open App\na -&gt;&gt; u: View Login page with countries\nu -&gt;&gt; a: Login into a single country\n\nu -&gt;&gt; a: Select View (Tab - eg: Active, Completed)\n\na -&gt;&gt; il: Request data of current 1) region 2) view\nil -&gt;&gt; c: Download\nc -&gt;&gt; a: Status filter options\nc -&gt;&gt; a: Return Current View Data\na -&gt;&gt; u: View\n\nu -&gt;&gt; a: Select Status / Search Name, ID, Code\na -&gt;&gt; c: Filter\nc -&gt;&gt; a: Return filtered Current View Data\na -&gt;&gt; u: View</code></pre> <pre><code>          flowchart LR\n          onvisible --&gt; refresh_button --&gt; t[\"TabGallery&gt;Button&gt;OnSelect\"]</code></pre> <p><code>TabGallery&gt;Button&gt;OnSelect</code></p> <pre><code>Set(\n    data_loading,\n    true\n); // this is for toggling any loading animations you have\nSet(\n    new_tab_selected,\n    ThisItem.ID\n);\nIf(\n    new_tab_selected = varTabSelected,\n    Blank(),\n    Reset(Status_Dropdown)\n);\nSet(\n    varTabSelected,\n    new_tab_selected\n);\n// repetition of filter() is required to overcome delegation issue\nClearCollect( // non-delegable\n    current_view_data,\n    Switch( // non-delegable\n      varTabSelected,\n      1,\n      Filter(\n        my_list,\n        Region.Value = country,\n        Status.Value = \"Active\"\n      ),\n      2,\n      Filter(\n        current_region_data,\n        Region.Value = country,\n        Status.Value = \"Cancelled\"\n      )\n    )\n);\nSet(\n    data_loading,\n    false\n);\n</code></pre> <p><code>Refresh Button</code></p> <pre><code>Select(\n    Tab,\n    varTabSelected,\n    Tab_Button\n);\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/#avoid-unnecessarily-data-requests","title":"Avoid unnecessarily data requests","text":"<pre><code>// Onvisible of page\nIf(\n  !loadapp,\n  ClearCollect(collection,Filter(datasource,condition));\n  UpdateContext({loadapp: true})\n)\n</code></pre> <ul> <li>Never use <code>Refresh()</code>. Data sources are already refreshed on start</li> <li>Forms &amp; patch() connected to a data source (not collection) will automatically refresh that same data source (not collection)</li> <li>Even a designated refresh button does not require this. Just use <code>ClearCollect()</code></li> </ul>"},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/#concurrent-execution","title":"Concurrent Execution","text":"<pre><code>Concurrent(\n  function_1(),\n    function_2(),\n    ...,\n    function_n()\n)\n\n// function can be Set(), clear(), collect(), ...\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/#delegable-in","title":"Delegable <code>in</code>","text":"<pre><code>Ungroup(\n  ForAll(\n    Selectbox.SelectedItems, // list of column values\n    {\n      ItemsGroupedByFilterValue: Filter(\n      ListWithDelegationIssues,\n      County.Value = CurrentFilterValue\n      )\n    }\n  ),\n  \"ItemsGroupedByFilterValue\"\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/#optimizing-gallery","title":"Optimizing Gallery","text":"<ul> <li>Set <code>DelayItemLoading</code> to <code>true</code></li> <li>Set <code>LoadingSpinner</code> to <code>LoadingSpinner.Data</code> or <code>LoadingSpinner.Controls</code></li> <li> <p>Eliminate multi-screen dependency</p> </li> <li> <p>This will prevent Powerapps from load everything from other screen</p> </li> <li> <p>For example: Use global variable instead of <code>gallery.selected</code> for form</p> <p>row selection: <code>Onselect</code> will be <code>Set(current_item, ThisItem)</code></p> </li> </ul>"},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/#settings","title":"Settings","text":"<p>Enable <code>DelayedLoad</code></p> <p>Speed up your app's start time by setting on-demand screen expression calls.</p> <p>Enable <code>Keep recently visited screens in memory</code></p> <p>Enable <code>Enhanced performance for hidden controls</code></p> <p>Hidden controls will not be created until they become visible</p>"},{"location":"Tools/PowerPlatform/PowerApps/04_Performance/#misc","title":"Misc","text":"<ul> <li>Use components wherever possible</li> <li>Use <code>Lookup()</code> instead of <code>First(Filter())</code></li> <li><code>Lookup()</code> is delegable, <code>First(Filter())</code> is non-delegable, <code>First(Filter())</code>\u00a0will load all the data into memory then perform the <code>Filter()</code>, then perform the <code>First()</code></li> <li>Lookup will stop at first match, <code>First(Filter())</code> will search the entire data even after first match and then return the first</li> <li>Change order of filters to further optimize logic</li> <li>Use Named Formulas</li> <li>Go to <code>App</code> property</li> <li>Formula</li> <li>Use Formula checker -&gt; Performance Warnings - Unused Variables troubleshooting and some unused controls in the app</li> <li>Disable <code>onstart</code></li> <li>Move things from <code>onstart</code> to <code>onvisible</code> to improve initial load</li> <li><code>Delay Output</code> of text control</li> <li>Progress Message</li> </ul>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/","title":"Miscellaneous","text":"<p>Need help with classifying these concepts</p>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#onvisible","title":"Onvisible","text":"<pre><code>Set(downtime_status, false);\nIf(\n    downtime_status,\n    Notify(\"Due to downtime associated with global deployment, please use the app after an hour.\", NotificationType.Error),\n    false\n);\n\nConcurrent(\n    Set(\n        primary_font,\n        \"Segoe UI\"\n    ),\n    Set(\n        grey_font_color,\n        RGBA(\n            0,\n            0,\n            0,\n            0.6\n        )\n    )\n);\n\nSet(\n    user_details,\n    Office365Users.MyProfile()\n);\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#filtering","title":"Filtering","text":""},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#conditional-filtering","title":"Conditional Filtering","text":"<pre><code>Filter(\n    collection,\n  If(\n    Field_1_Filter_Case_1,\n    Field_2_Filter_Case_2\n    )\n)\n// instead of \nIf(\n  Filter_1(),\n  Filter_2()\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#fuzzy-search","title":"Fuzzy Search","text":"<p>Fuzzy search only works for collections! Use the performance tips to optimize the loading of data from datasource into collections.</p> <pre><code>// &lt;- or operation of search strings\ntrue in ForAll()\n\n// &lt;- and operation of search strings\nNot(false in ForAll())\n</code></pre> <pre><code>Filter(\n  collection_name,\n  If(\n    Not(false in ForAll( // &lt;- and: match all substrings\n      Split(\n        Trim(Substitute(Search_Input.Text, \" \", \"\")), // Trim(Search_Input.Text),\n        \" \"\n      ) As substring,\n      true in ForAll( // &lt;- or: match any column\n        [\n          Col1,\n            Col2,\n            Col3\n        ] As column, // columns to search\n        substring.Value in Substitute(column, \" \", \"\")\n            // Use substring.Value.Value for choice columns\n    )\n    )),\n    true,\n    false\n  )\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#alerts","title":"Alerts","text":"<pre><code>Notify( \"Wrong\", NotificationType.Warning, 4000 )\n// Message, Type, Timeout\n</code></pre> NotificationType Purpose NotificationType.Error Displays the message as an error. NotificationType.Information (Default) Displays the message as informational. NotificationType.Success Displays the message as success. NotificationType.Warning Displays the message as a warning. <p>Set <code>App.ConfirmExit</code> to <code>true</code></p>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#alternating-colors","title":"Alternating Colors","text":"<p>https://devoworx.net/alternate-row-color-in-gallery-powerapps/#alternate-row-color-in-gallery </p> <pre><code>With(\n{\n    Items:List_or_List_Name\n},\nForAll(\n    Sequence(CountRows(Items)),\n    Patch(\n        Last(\n            FirstN(Items,Value)),\n            {rowNumber: Value}\n        )\n    )\n)\n</code></pre> <pre><code>If(\n  Mod(ThisItem.rowNumber,2) = 0,\n  RGBA(240, 240, 240, 1),RGBA(255, 255, 255, 1)\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#embed-powerbi","title":"Embed PowerBI","text":"<ul> <li> <p>PowerBI &gt; <code>Embed</code> &gt; <code>Website/Portal</code></p> </li> <li> <p>PowerApps &gt; <code>Insert</code> &gt; <code>Charts</code> &gt; <code>PowerBI Tile</code></p> </li> <li>Select it</li> <li><code>TileUrl</code> &gt; Paste embed link</li> </ul>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#idk","title":"IDK","text":"<ul> <li> <p>Use <code>Select()</code> for re-using code by calling a button</p> </li> <li> <p>Mainly useful for onvisible to call the refresh button</p> </li> <li> <p>Default for multi-select columns</p> <ul> <li><code>{Value: ThisItem.Purpose}</code></li> </ul> </li> </ul>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#home-page-onvisible","title":"Home page onvisible","text":"<pre><code>Set(downtime_status, false);\nIf(\n    downtime_status,\n    Notify(\"Due to downtime associated with global deployment, please use the app after an hour.\", NotificationType.Error),\n    false\n);\n\nConcurrent(\n    Set(\n      user_details,\n      Office365Users.MyProfile()\n  ),\n    Set(\n        primary_font,\n        Font.'Segoe UI' // \"Custom Font\"\n    ),\n    Set(\n        grey_font_color,\n      RGBA(0,0,0,0.6)\n    ),\n    Set(\n        app_name,\n        \"Thahir App\"\n    )\n);\n</code></pre> <p>Onvisible only once</p> <pre><code>If(\n  !loadapp,\n  ClearCollect(\n    collection,\n    Filter(datasource,condition)\n  );\n  UpdateContext({loadapp: true}),\n  Blank()\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#app-name","title":"App Name","text":"<pre><code>app_name &amp; \" | \" &amp; App.ActiveScreen.Name\n// set app_name globally\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#get-first-names","title":"Get first names","text":"<p>Multi-person column</p> <pre><code>// Ahmed\n// Ahamed\n// Mohammed\n\nForAll(\n      users_all As user,\n      First(\n          Split(\n              Last(\n                  Split(\n                      user.Name.DisplayName,\n                      \", \"\n                  )\n              ).Value,\n              \" \"\n          )\n      ).Value\n  )\n</code></pre> <p>From a List to a string</p> <pre><code>// Ahmed; Ahamed; Mohammed\n\nConcat(\n    ForAll(\n        users_all As user,\n        First(\n            Split(\n                Last(\n                    Split(\n                        user.Name.DisplayName,\n                        \"; \"\n                    )\n                ).Value,\n                \" \"\n            )\n        ).Value\n    ),\n    Value,\n    Char(10)\n)\n</code></pre> <p>From a table to a string for a cell in a Gallery</p> <pre><code>// Ahmed; Ahamed; Mohammed\nConcat(\n    ForAll(\n        ThisItem.Owner As ItemOwner,\n        First(\n            Split(\n                Last(\n                    Split(\n                        ItemOwner.DisplayName,\n                        \"; \"\n                    )\n                ).Value,\n                \" \"\n            )\n        ).Value\n    ),\n    Value,\n    \", \"\n)\n</code></pre> <p>default selected items for a dropdown</p> <pre><code>// Ahmed; Ahamed; Mohammed\nFilter(\n    AddColumns(\n        ForAll(\n            users_all,\n            Name\n        ),\n        \"FirstName\",\n        First(\n            Split(\n                Last(\n                    Split(\n                        DisplayName,\n                        \"; \"\n                    )\n                ).Value,\n                \" \"\n            )\n        ).Value\n    ),\n    Email in ForAll(\n        ThisItem.Owner, // don't use Parent.Default, as it gives weird results\n        Email\n    )\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#distinct-values-from-choice-column","title":"Distinct Values from Choice Column","text":"<p>Single-Select</p> <pre><code>Distinct(\n    ForAll(\n        List,\n        Column\n    ),\n    Value\n)\n</code></pre> <p>Multi-Select</p> <pre><code>Distinct(\n    Ungroup(\n        ForAll(\n            ForAll(\n                List,\n                Column\n            ),\n            Value\n        ),\n        \"Value\"\n    ),\n    Value\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#union-of-2-tables","title":"Union of 2 tables","text":"<pre><code>Ungroup(\n  Table(\n    {MyTables: TableA},\n    {MyTables: TableB}\n  ),\n  \"MyTables\"\n)\n</code></pre> <pre><code>Ungroup(\n    ForAll(\n        Conditions_Time_Points_Gallery.AllItems,\n        {\n            MyTables: ForAll(\n                Samples_Count_Gallery.AllItems,\n                Samples_Count_Input.Text\n            )\n        }\n    ),\n    \"MyTables\"\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#replicating-database-style-input","title":"Replicating database-style input","text":""},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#input-boxes","title":"Input boxes","text":"<p>Onselect</p> <pre><code>Select(Update Record Button);\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#update-record-button","title":"Update Record Button","text":"<pre><code>If(\n    LookUp(\n        collection_modified,\n        ID = ThisItem.ID,\n        true\n    ),\n    Blank(),\n    Collect(\n        collection_modified,\n        ThisItem\n    )\n);\nUpdateIf(\n    collection_modified,\n    ID = ThisItem.ID,\n    {\n        Comments: Comments_Input.Value\n    }\n);\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#submit-button","title":"Submit Button","text":"<pre><code>Patch(\n    Success_Criteria,\n    ShowColumns(\n      collection_modified,\n      \"ID\",\n      \"Col1\",\n      \"Col2\"\n    )\n);\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#deep-linking","title":"Deep Linking","text":""},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#apponvisible","title":"<code>App.Onvisible</code>","text":"<pre><code>Set(\n    param_item_id,\n    Param(\"item_id\")\n);\nIf(\n  !IsBlank(param_item_id),\n    Set(\n    selected_stability_code,\n    param_item_id\n  );\n    Select(go_to_manage_item);\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#go_to_manage_item-button","title":"<code>go_to_manage_item</code> button","text":"<p>Create a button to do the navigation, because PowerApp does not allow <code>Navigate()</code> in onvisible</p> <pre><code>Navigate('Screen_to_Manage_Item');\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerApps/05_Misc/#generate-link","title":"Generate Link","text":"<pre><code>https://&lt;applink&gt;?param1=value1&amp;param2=value2&amp;param3=value3\n</code></pre> <p>For example,</p> <pre><code>https://&lt;applink&gt;?item_id=100\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerAutomate/","title":"PowerAutomate","text":"<p>Automation tool</p> <ul> <li>Triggers: What starts the flow</li> <li>Automated: Database, Email</li> <li>Instant: Manually start, PowerApps</li> <li>Scheduled: Time-based</li> <li>Desktop</li> <li>Connectors: Actions</li> <li>Types<ul> <li>Standard</li> <li>Premium </li> </ul> </li> <li>Examples<ul> <li>Send HTTP API requests</li> <li>CRUD items</li> <li>SharePoint</li> <li>SQL</li> </ul> </li> </ul>"},{"location":"Tools/PowerPlatform/PowerAutomate/#flow-failures","title":"Flow Failures","text":"<p>If a flow keeps failing, Microsoft will automatically suspend it.</p>"},{"location":"Tools/PowerPlatform/PowerAutomate/01/","title":"01","text":""},{"location":"Tools/PowerPlatform/PowerAutomate/01/#get-items","title":"Get items","text":"<p>By default, <code>Get items</code> only returns the first 100 items. (don't believe the message it shows that <code>default = all</code>)</p> <p>Set <code>Top Count</code> to 5000.</p>"},{"location":"Tools/PowerPlatform/PowerAutomate/01/#odata-filter","title":"Odata Filter","text":"<pre><code>numeric_column eq number\nstring_column eq 'string'\n\nlookup_column/Id eq number\nlookup_column/subfield eq 'string'\n</code></pre> eq lt gt"},{"location":"Tools/PowerPlatform/PowerAutomate/01/#to-get-more-than-5000-items","title":"To get more than 5000 items","text":"<ol> <li>Create a variable <code>lower_limit_id=0</code></li> <li>Get items with ID &gt; lower_limit &amp;&amp; ID &lt; lower_limit + 5000</li> <li><code>lower_limit=lower_limit + 5000</code></li> <li>Perform step 2 until the <code>lower_limit_id &gt; max(id of items you just got)</code></li> <li>Finally, do <code>union</code></li> </ol> <p>ID = Auto-Generated column</p>"},{"location":"Tools/PowerPlatform/PowerAutomate/01/#concurrency-control","title":"Concurrency Control","text":"<p>Better to limit database related operations to 1</p> <p></p>"},{"location":"Tools/PowerPlatform/PowerAutomate/01/#copy-file","title":"Copy file","text":""},{"location":"Tools/PowerPlatform/PowerAutomate/01/#union","title":"Union","text":"<pre><code>union(\n  collection_1: object|array,\n  collection_2: object|array\n)\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerBi/","title":"PowerBi","text":"<p>Visualization software used for Business Intelligence </p>"},{"location":"Tools/PowerPlatform/PowerBi/#advantages","title":"Advantages","text":"<ul> <li>Easy to maintain</li> <li>Drag &amp; drop and Coding</li> <li>Embed everything in a single shareable \u201c.pbix\u201d file</li> <li>Does not support live queries very well. Need to use very high frequency refresh schedule. You can even use PowerAutomate to refresh</li> </ul>"},{"location":"Tools/PowerPlatform/PowerBi/#disadvantages","title":"Disadvantages","text":"<ul> <li>Not as flexible as hand-coding a dashboard in Python or so</li> <li>Might get too big for very large datasets</li> </ul>"},{"location":"Tools/PowerPlatform/PowerBi/#coding-languages","title":"Coding languages","text":"<ul> <li>PowerQuery</li> <li>DAX (Data Analysis Expressions)</li> </ul>"},{"location":"Tools/PowerPlatform/PowerBi/#idk","title":"IDK","text":"<p>PowerBi Desktop \\(\\ne\\) PowerBi Cloud</p> <p>PowerBi cloud every uploaded dashboard gets split into Report &amp; Semantic Model</p>"},{"location":"Tools/PowerPlatform/PowerBi/01/","title":"01","text":""},{"location":"Tools/PowerPlatform/PowerBi/01/#sharepoint-import-optimization","title":"SharePoint Import Optimization","text":""},{"location":"Tools/PowerPlatform/PowerBi/01/#use-version-20","title":"Use Version 2.0","text":"<ul> <li>`Default``</li> <li><code>`All</code> will request a lot of unnecessarily data</li> </ul> <p>If Version 2.0 does not work for some reason such as</p> <p>Sharepoint online list 1.0 connector is the only option for Power BI refresh data over 5K items  </p>"},{"location":"Tools/PowerPlatform/PowerBi/01/#custom-request","title":"Custom Request","text":""},{"location":"Tools/PowerPlatform/PowerBi/01/#option-1","title":"Option 1","text":"<pre><code>let\n  tenantname = \"&lt;domain&gt;\",  // eg: \"domain.sharepoint.com\"\n  sitename = \"&lt;site&gt;\",      // eg: \"SiteName\"; if a subsite use \"Site/SubSite\"\n  listname = \"&lt;list&gt;\",      // eg: \"ListName\"\n\n  siteurl = \"https://\" &amp; tenantname &amp; \"/sites/\" &amp; sitename,  // use ... /sites/&lt;your site name&gt;/&lt;your subsite name&gt; if applicable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n  itemcount = Json.Document(Web.Contents(siteurl, [RelativePath = \"_api/web/lists/GetByTitle('\" &amp; listname &amp; \"')/items?$select=ID&amp;$orderby=ID%20desc&amp;$top=1\", Headers = [Accept = \"application/json\"]]))[value]{0}[ID],\n  StartIDs = List.Numbers(0, Number.RoundUp(itemcount / 5000), 5000),\n  ConvertToTable = Table.FromList(StartIDs, Splitter.SplitByNothing(), null, null, ExtraValues.Error),\n  Add_EndIDs = Table.AddColumn(ConvertToTable, \"Addition\", each [Column1] + 4999, type number),\n  RenamedColumns = Table.RenameColumns(Add_EndIDs, {{\"Column1\", \"StartID\"}, {\"Addition\", \"EndID\"}}),\n  #\"Changed Type\" = Table.TransformColumnTypes(RenamedColumns, {{\"StartID\", type text}, {\"EndID\", type text}}),\n\n  //Comment in only one of the fieldselect lines below, defining your select and expand columns using the example syntax shown                                                                                                                            \n  // fieldselect = \"&amp;$top=5000\",  // all fields with no expansion                                                                                                                                                                                                                         \n  // fieldselect = \"&amp;$top=5000&amp;$select=ID,Title,Date,PersonColumn,ChoiceColumn,LookupColumn\", // list desired fields (no expansion) -No Spaces!                                                                                                                                            \n  fieldselect = \"&amp;$top=5000&amp;$select=ID,Title,Date,PersonColumn/LastName,PersonColumn/FirstName,ChoiceColumn,LookupColumn/Title,LookupColumn/Project,LookupColumn/ProjectStatus&amp;$expand=PersonColumn,LookupColumn\", //expand list fields - No Spaces!                                                                                                                                                                                                                                                    \n\n  GetData = Table.AddColumn(#\"Changed Type\", \"Items\", each Json.Document(Web.Contents(siteurl, [RelativePath = \"_api/web/lists/GetByTitle('\" &amp; listname &amp; \"')/items?$filter=(ID ge \" &amp; [StartID] &amp; \") and (ID le \" &amp; [EndID] &amp; \")\" &amp; fieldselect, Headers = [Accept = \"application/json\"]]))[value]),\n  #\"Removed Other Columns\" = Table.SelectColumns(GetData, {\"Items\"}),\n  #\"Expanded Items\" = Table.ExpandListColumn(#\"Removed Other Columns\", \"Items\")\nin\n  #\"Expanded Items\"\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerBi/01/#option-2-elegant-but-sequential-requests-slower","title":"Option 2: Elegant, but sequential requests (slower)","text":"<pre><code>let\n  tenantname = \"&lt;domain&gt;\",  // eg: \"domain.sharepoint.com\"\n  sitename = \"&lt;site&gt;\",      // eg: \"SiteName\"; if a subsite use \"Site/SubSite\"\n  listname = \"&lt;list&gt;\",      // eg: \"ListName\"\n\n  siteurl = \"https://\" &amp; tenantname &amp; \"/sites/\" &amp; sitename,  // use ... /sites/&lt;your site name&gt;/&lt;your subsite name&gt; if applicable                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n\n  //Comment in only one of the fieldselect lines below, defining your select and expand columns using the example syntax shown                                                                                                                            \n  // fieldselect = \"&amp;$top=5000\", // all fields with no expansion                                                              \n  // fieldselect = \"&amp;$top=5000&amp;$select=ID,Title,Date,PersonColumn,ChoiceColumn,LookupColumn\", // list desired fields (no expansion) -No Spaces!                                                                                                                                            \n  fieldselect = \"&amp;$top=5000&amp;$select=ID,Title,Date,PersonColumn/LastName,PersonColumn/FirstName,ChoiceColumn,LookupColumn/Title,LookupColumn/Project,LookupColumn/ProjectStatus&amp;$expand=PersonColumn,LookupColumn\",  //expand list fields - No Spaces!                                                                                                   \n\n  InitialWebCall = Json.Document(Web.Contents(siteurl, [RelativePath = \"_api/web/lists/GetByTitle('\" &amp; listname &amp; \"')/items?$skipToken=Paged=TRUE\" &amp; fieldselect, Headers = [Accept = \"application/json\"]])),\n  datalist = List.Generate(() =&gt; InitialWebCall, each List.Count([value]) &gt; 0, each try Json.Document(Web.Contents(siteurl, [RelativePath = \"_api\" &amp; Text.AfterDelimiter([odata.nextLink], \"_api\"), Headers = [Accept = \"application/json\"]])) otherwise [value = {}], each [value]),\n  #\"Converted to Table\" = Table.FromList(datalist, Splitter.SplitByNothing(), null, null, ExtraValues.Error),\n  #\"Expanded Column1\" = Table.ExpandListColumn(#\"Converted to Table\", \"Column1\")\nin\n  #\"Expanded Column1\"\n</code></pre>"},{"location":"Tools/PowerPlatform/PowerBi/01/#generate-range","title":"Generate Range","text":"<ul> <li>Create New column</li> </ul> <p>Type</p> <p>Number Range</p> <pre><code>{\n  1..3\n}\n</code></pre> <p>Date Range</p> <pre><code>{\n  Number.From([Start_Date]) .. Number.From([End_Date])\n}\n</code></pre> <p>Expand new column</p> <p>Change data type as required</p>"},{"location":"Tools/PowerPlatform/SharePoint/","title":"SharePoint","text":"<p>Microsoft service that has both File Storage &amp; Relational Database capabilities.</p> <p>Mix of OneDrive &amp; MySQL</p> <p>Previously it was Microsoft Lists.</p>"},{"location":"Tools/PowerPlatform/SharePoint/#advantages","title":"Advantages","text":"<ol> <li>Free (within default O365 license)</li> <li>Audit Trail (Version history of every record/file)</li> <li>Flexible &amp; Feature-Rich</li> <li>LookUp are very useful</li> <li>Easily to integrate with PowerPlatform ecosystem, and also to Python using SharePlum</li> <li>Export query, which is a read-only view into the backend</li> </ol>"},{"location":"Tools/PowerPlatform/SharePoint/#disadvantages","title":"Disadvantages","text":"<ol> <li>It does not give as feature-rich queries/API compared to other solutions like SQL Server/Dataverse</li> <li>LookUp columns has limitations</li> <li>Setting up permissions is not easy</li> <li>Export query only works on Windows</li> </ol>"},{"location":"Tools/PowerPlatform/SharePoint/#sharepoint-vs-dataverse","title":"SharePoint vs Dataverse","text":"SharePoint Dataverse Cost Advantages Disadvantages Comments"},{"location":"Tools/PowerPlatform/SharePoint/#hub-of-all-sharepoint-sites","title":"Hub of All SharePoint sites","text":"<p><code>https://&lt;subdomain&gt;.sharepoint.com/_layouts/15/sharepoint.aspx?v=activities&amp;spStartSource=spappbar</code></p>"},{"location":"Tools/PowerPlatform/SharePoint/#vocabulary","title":"Vocabulary","text":"Normal Language SharePoint Database Site Table List"},{"location":"Tools/PowerPlatform/SharePoint/#most-significant-read-only-columns","title":"Most Significant Read-Only Columns","text":"<ol> <li>ID</li> <li>Created By</li> <li>Modified By</li> <li>Created</li> <li>Modified</li> </ol>"},{"location":"Tools/PowerPlatform/SharePoint/#creating-new-site","title":"Creating New Site","text":""},{"location":"Tools/PowerPlatform/SharePoint/#steps","title":"Steps","text":""},{"location":"Tools/PowerPlatform/SharePoint/#important-configuration","title":"Important Configuration","text":"<ol> <li>Site Settings</li> <li>View all site sittings</li> <li>Regional settings</li> <li>Make sure that time zone &amp; locale are set correctly</li> </ol>"},{"location":"Tools/PowerPlatform/SharePoint/#creating-new-list","title":"Creating New List","text":"<ol> <li>Home Page of the Site</li> <li>Click <code>New</code></li> <li>Choose existing list or blank template</li> </ol>"},{"location":"Tools/PowerPlatform/SharePoint/#editing-list","title":"Editing List","text":"<p><code>Edit in Grid View</code> is your best friend!!! You can only bulk-edit only &lt;100 items at a time</p> <p>Behaves like a normal spreadsheet (copy, paste, etc)</p>"},{"location":"Tools/PowerPlatform/SharePoint/#schema-validation","title":"Schema Validation","text":"<ol> <li>Enforce unique (unique)</li> <li>Requires information (not null)</li> </ol> <p>If you use both, you are basically enforcing primary key</p>"},{"location":"Tools/PowerPlatform/SharePoint/#column-types","title":"Column Types","text":"Type Comment Advantages Disadvantages Text Max char \\([1, 255]\\) Searchable on SharePointFilterable Max limit Multiple Lines of Text No max limit I think not Searchable on SharePointNot filterable Choice Should be used when you have a pre-defined list of options Very fastLooks nice Not easy to maintain the list; hence, should not be used when options are dynamic DateTime Try to do everything in GMT Does not store date time, it stores in serial date time format Dates &amp; Times are not very well-managed in Microsoft ecosystem Person Number FloatYou can control precision to be 0 to enforce integer Yes/No Boolean LookUp Enforcing FKBecomes very slow/unusable after the list you are looking up from has &gt; 5000 items Calculated <code>Show more column types</code> &gt; CalculatedHelps creating regular database view-style calculated column Formula only gets executed when the row is updated; for eg, <code>Today()</code> cannot be used due to this"},{"location":"Tools/PowerPlatform/SharePoint/#recycle-bin","title":"Recycle Bin","text":"<ul> <li>Level 1</li> <li>Level 2</li> </ul>"},{"location":"Tools/PowerPlatform/SharePoint/#permissions","title":"Permissions","text":""},{"location":"Tools/PowerPlatform/SharePoint/#requirement","title":"Requirement","text":"Role Access Owners Should have full-control Superusers Should have privileged control over the items, but cannot access the backend Users Can only access the app No access No access"},{"location":"Tools/PowerPlatform/SharePoint/#solution","title":"Solution","text":""},{"location":"Tools/PowerPlatform/SharePoint/#maintain-sharepoint-list","title":"Maintain SharePoint List","text":"<pre><code>erDiagram\nUsers {\n    LookUp Region FK\n    Person Email \"NOT NULL\"\n    Choice User_Type \"NOT NULL; [User, SuperUser, Admin]\"\n}</code></pre>"},{"location":"Tools/PowerPlatform/SharePoint/#sharepoint-permissions","title":"SharePoint Permissions","text":"<ol> <li>Go to site permissions</li> <li>Advanced permission settings</li> <li>Create permissions group and give permissions according to the below</li> <li>Create custom permission levels according to the below</li> </ol> Role Sharepoint Permission Level List Permission Level Owners Full-control Full-control Superusers Contribute (Custom) Contribute (Custom) Users Read (Custom) Contribute (Custom) No access No access No access Level Steps Custom Read Read access permission level with only <code>Open  -  Allows users to open a Web site, list, or folder in order to access items inside that container.</code> Custom Contribute Contribute access permission level with 1. <code>Add Items  -  Add items to lists and add documents to document libraries.</code> 2. <code>Edit Items  -  Edit items in lists, edit documents in document libraries, and customize Web Part Pages in document libraries.</code> 3. <code>View Items  -  View items in lists and documents in document libraries.</code> 4. <code>View Pages  -  View pages in a Web site.</code> 5. <code>Open  -  Allows users to open a Web site, list, or folder in order to access items inside that container.</code>"},{"location":"Tools/PowerPlatform/SharePoint/#trick-to-do-this-faster","title":"Trick to do this faster","text":"<ul> <li> <p>First, edit the permission of the new group <code>Users</code> to <code>Custom Contribute</code></p> </li> <li> <p>Then go to each list\u2019s settings and specify do not inherit from parent</p> </li> <li> <p>Come back to site settings, and edit the permission to <code>Read</code></p> </li> <li> <p>Add <code>Everyone but external users</code> to <code>Users</code></p> <ul> <li>Do this last to avoid any accidental access</li> </ul> </li> <li> <p>This way you don't have to edit list settings each time, only the site settings :)</p> </li> </ul>"},{"location":"Tools/Presentation/Pandoc/","title":"Pandoc","text":""},{"location":"Tools/Presentation/Pandoc/#basic","title":"Basic","text":"<pre><code># HTML Export\npandoc -t html -s simple-presentation.md -o out/simple-presentation-website.html\n\n# HTML Presentation\npandoc -t revealjs -s simple-presentation.md -o out/simple-presentation.html\n# -t s5, slidy, slideous, dzslides, or revealjs\n\n# PDF\npandoc -t beamer .\\simple-presentation.md -o out/simple-presentation.pdf\n\n# PPT\npandoc simple-presentation.md -o out/simple-presentation.pptx\n</code></pre>"},{"location":"Tools/Presentation/Pandoc/#advanced","title":"Advanced","text":"<pre><code>pandoc -t beamer -s --bibliography bib.bib --citeproc .\\presentation.md -o out/presentation.pdf\n</code></pre>"},{"location":"Tools/Presentation/markdown_presentation.md/","title":"General information","text":""},{"location":"Tools/Presentation/markdown_presentation.md/#themes-fonts-etc","title":"Themes, fonts, etc.","text":"<ul> <li>This presentation is made with Metropolis theme.</li> </ul>"},{"location":"Tools/Presentation/markdown_presentation.md/#links","title":"Links","text":"<ul> <li>Matrix of beamer themes</li> <li>Font themes: http://www.deic.uab.es/~iblanes/beamer_gallery/index_by_font.html</li> </ul>"},{"location":"Tools/Presentation/markdown_presentation.md/#formatting","title":"Formatting","text":""},{"location":"Tools/Presentation/markdown_presentation.md/#text-formatting","title":"Text formatting","text":"<p>Normal text. Italic text and bold text. Strike out is supported.</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#notes","title":"Notes","text":"<p>This is a note.</p> <p>Nested notes are not supported. And it continues.</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#blocks","title":"Blocks","text":""},{"location":"Tools/Presentation/markdown_presentation.md/#this-is-a-block-a","title":"This is a block A","text":"<ul> <li>Line A</li> <li>Line B</li> </ul>"},{"location":"Tools/Presentation/markdown_presentation.md/#_1","title":"Pandoc Beamer","text":"<p>New block without header.</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#this-is-a-block-b","title":"This is a block B.","text":"<ul> <li>Line C</li> <li>Line D</li> </ul>"},{"location":"Tools/Presentation/markdown_presentation.md/#listings","title":"Listings","text":"<p>Listings out of the block.</p> <pre><code>#!/bin/bash\necho \"Hello world!\"\necho \"line\"\n</code></pre>"},{"location":"Tools/Presentation/markdown_presentation.md/#listings-in-the-block","title":"Listings in the block.","text":"<pre><code>print(\"Hello world!\")\n</code></pre>"},{"location":"Tools/Presentation/markdown_presentation.md/#table","title":"Table","text":"Item Description Q-ty Item A Item A description 2 Item B Item B description 5 Item C N/A 100"},{"location":"Tools/Presentation/markdown_presentation.md/#single-picture","title":"Single picture","text":"<p>This is how we insert picture. Caption is produced automatically from the alt text.</p> <pre><code>![Aleph 0](images/pandoc.png) \n</code></pre> <p> </p>"},{"location":"Tools/Presentation/markdown_presentation.md/#two-or-more-pictures-in-a-raw","title":"Two or more pictures in a raw","text":"<p>Here are two pictures in the raw. We can also change two pictures size (height or width).</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#_2","title":"Pandoc Beamer","text":"<pre><code>![](images/pandoc.png){height=10%}\\ ![](images/pandoc.png){height=30%} \n</code></pre>"},{"location":"Tools/Presentation/markdown_presentation.md/#lists","title":"Lists","text":"<ol> <li>Idea 1</li> <li>Idea 2<ul> <li>genius idea A</li> <li>more genius 2</li> </ul> </li> <li>Conclusion</li> </ol>"},{"location":"Tools/Presentation/markdown_presentation.md/#latex","title":"LaTeX","text":"<p>Hello, world^[My footnote].</p> <p>Some \\textit{\\LaTeX commands}.</p> <p>And some \\(\\sqrt{a^2 + b^2}\\) math.</p> <p>\\(\\displaystyle\\lim_{x \\to \\infty} x^2 = \\infty\\)</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#two-columns-of-equal-width","title":"Two columns of equal width","text":"<p>::: columns</p> <p>:::: column</p> <p>Left column text.</p> <p>Another text line.</p> <p>::::</p> <p>:::: column</p> <ul> <li>Item 1.</li> <li>Item 2.</li> <li>Item 3.</li> </ul> <p>::::</p> <p>:::</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#two-columns-of-with-4060-split","title":"Two columns of with 40:60 split","text":"<p>::: columns</p> <p>:::: {.column width=40%}</p> <p>Left column text.</p> <p>Another text line.</p> <p>::::</p> <p>:::: {.column width=60%}</p> <ul> <li>Item 1.</li> <li>Item 2.</li> <li>Item 3.</li> </ul> <p>::::</p> <p>:::</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#three-columns-with-304030-split","title":"Three columns with 30:40:30 split","text":"<p>::: columns</p> <p>:::: {.column width=30%}</p> <p>Left column text.</p> <p>Another text line.</p> <p>::::</p> <p>:::: {.column width=40%}</p> <p>Middle column list:</p> <ol> <li>Item 1.</li> <li>Item 2.</li> </ol> <p>::::</p> <p>:::: {.column width=30%}</p> <p>Right column list:</p> <ul> <li>Item 1.</li> <li>Item 2.</li> </ul> <p>::::</p> <p>:::</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#two-columns-image-and-text","title":"Two columns: image and text","text":"<p>::: columns</p> <p>:::: column</p> <p></p> <p>::::</p> <p>:::: column</p> <p>Text in the right column.  </p> <p>List from the right column:</p> <ul> <li>Item 1.</li> <li>Item 2. ::::</li> </ul> <p>:::</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#two-columns-image-and-table","title":"Two columns: image and table","text":"<p>::: columns</p> <p>:::: column</p> <p></p> <p>::::</p> <p>:::: column</p> Item Option Item 1 Option 1 Item 2 Option 2 <p>::::</p> <p>:::</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#references","title":"References","text":""},{"location":"Tools/Presentation/markdown_presentation.md/#citations","title":"Citations","text":"<p>As described in [@Tartarini2020a;@Tartarini2020]</p> <p>Single reference [@Tartarini2020]</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#reference-figures","title":"Reference figures","text":"<p>Reference Figure \\ref{first} and \\ref{second} </p> <p></p>"},{"location":"Tools/Presentation/markdown_presentation.md/#second-figure","title":"Second figure","text":"<p>Reference Figure \\ref{second} and </p> <p></p>"},{"location":"Tools/Presentation/markdown_presentation.md/#fancy-layout","title":"Fancy layout","text":""},{"location":"Tools/Presentation/markdown_presentation.md/#proposal","title":"Proposal","text":"<ul> <li>Point A</li> <li>Point B</li> </ul> <p>::: columns</p> <p>:::: column</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#pros","title":"Pros","text":"<ul> <li>Good</li> <li>Better</li> <li>Best</li> </ul> <p>::::</p> <p>:::: column</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#cons","title":"Cons","text":"<ul> <li>Bad</li> <li>Worse</li> <li>Worst</li> </ul> <p>::::</p> <p>:::</p>"},{"location":"Tools/Presentation/markdown_presentation.md/#conclusion","title":"Conclusion","text":"<ul> <li>Let's go for it!</li> <li>No way we go for it!</li> </ul>"},{"location":"Tools/Presentation/markdown_presentation.md/#references_1","title":"References","text":"<p>::: {#refs} :::</p>"},{"location":"Tools/Programming_Languages/PHP/","title":"PHP","text":""},{"location":"Tools/Programming_Languages/PHP/#basic-block","title":"Basic Block","text":"<pre><code>&lt;?php\n// code\necho \"Hello world!\";\n?&gt;\n</code></pre>"},{"location":"Tools/Programming_Languages/PHP/#declaration","title":"Declaration","text":"<p>Data types not required</p> <pre><code>$my_var = \"\";\n</code></pre>"},{"location":"Tools/Programming_Languages/PHP/#get-query-parameters","title":"Get query parameters","text":"<pre><code>$query_param = $_GET[\"query_param\"];\n</code></pre>"},{"location":"Tools/Programming_Languages/PHP/#dates","title":"Dates","text":"<pre><code>data_default_timezone_set(\"Asia/Kolkata\");\n\n$date = date(\"Y-m-d\");\n$time = date(\"H:i:s\");\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/","title":"Python","text":"<p>Since it is an interpreted language, it may be slow for very large projects, but should be fine for most projects</p>"},{"location":"Tools/Programming_Languages/Python/#references","title":"References","text":"<ul> <li> Certifications<ul> <li> https://www.udemy.com/course/complete-python-developer-zero-to-mastery/   python development</li> <li> https://www.udemy.com/course/python-programming-projects/ python</li> </ul> </li> </ul>"},{"location":"Tools/Programming_Languages/Python/01/","title":"Python","text":""},{"location":"Tools/Programming_Languages/Python/01/#import-package","title":"Import Package","text":"<pre><code>import foo\nfrom foo import bar\nfrom foo import *\n\nfrom foo.idk import bar\nfrom foo.idk import *\n</code></pre> <p>All the above take the same duration; no performance difference</p>"},{"location":"Tools/Programming_Languages/Python/01/#garbage-collection","title":"Garbage Collection","text":"<p>Manually collecting will be faster than automatic</p> <pre><code>import gc\n\ng0, g1, g2 = gc.get_threshold() # default: 700, 10, 10\n# gc.set_threshold(10_000, 10, 10)\n\ngc.collect(generation=0)\ngc.set_threshold(0)\ngc.disable()\ngc.freeze()\n\nheavy_code() # like ML, database\n\ngc.unfreeze()\ngc.set_threshold(10_000, 10, 10)\ngc.enable()\ngc.collect(generation=0)\n\n\n# exit\n# don't cleanup on exit\natexit.register(os._exit, 0) # only for Python &lt; 3.6\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#idk","title":"IDK","text":"<p>A collection before POSIX <code>fork()</code> call may free pages for future allocation which can cause copy-on-write too</p> <p>Hence</p> <ol> <li>Parent process</li> <li>disable garbage collector</li> <li>freeze before fork</li> <li>Child process</li> <li>Enable garbage collector</li> </ol>"},{"location":"Tools/Programming_Languages/Python/01/#machine-learning","title":"Machine Learning","text":"<pre><code>gc.set_threshold(0)\ngc.disable()\n\nfor epoch in range(n_epochs):\n  for batch in batch_data_loader:\n    # train\n    # eval\n      gc.collect(0)\n\ngc.collect()\n\n# exit\natexit.register(os._exit, 0) # only for Python &lt; 3.6\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#idk_1","title":"IDK","text":"<ul> <li><code>gc.disable()</code> will sometimes got overridden by another library calling <code>gc.enable()</code></li> </ul>"},{"location":"Tools/Programming_Languages/Python/01/#number-formatting","title":"Number Formatting","text":"<pre><code>number = 333.43\n\n\"{:02d}\".format(1)      ## leading zeroes\n\"{:2f}\".format(number)  ## floating point rounding\n\nf\"{x:z}\" ## rounds negative 0\nf\"{x:z.1f}\"\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#hex-to-rgba","title":"Hex to RGBA","text":"<pre><code>def hex_to_rgba(h, alpha):\n    '''\n    converts color value in hex format to rgba format with alpha transparency\n    '''\n    return \"rgba\" + str(tuple([int(h.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)] + [alpha]))\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#custom-rounding","title":"Custom Rounding","text":"<p><pre><code>def round_f(x, places, percentage=False):\n  if percentage:\n    x *= 100\n\n  string = f\"{x:z.{places}f}\"\n\n  if places &gt; 0:\n    string = string.rstrip('0').rstrip('.')\n\n  if percentage:\n    string += \"%\"\n\n  return string\n</code></pre> <pre><code>def round_s(x, significant_decimals, max_digits=None, percentage=False):\n  if percentage:\n    x *= 100\n\n  if max_digits is None:\n    max_digits = min(significant_decimals * 2, 4)\n\n  decimal_digits = str(x).split(\".\")[1]\n  pos_first_non_zero = len(decimal_digits) - len(decimal_digits.lstrip(\"0\")) \n  pos = pos_first_non_zero + significant_decimals\n\n  return round_f(x, min(pos, max_digits))\n</code></pre></p>"},{"location":"Tools/Programming_Languages/Python/01/#text","title":"Text","text":"<p><pre><code>names = names.split(\"\\n\")\nnames = names.split(\",\")\n\n## remove empty strings from string list\nnames = list(filter(None, names))\n</code></pre> <pre><code>class color:\n PURPLE = '\\033[95m'\n CYAN = '\\033[96m'\n DARKCYAN = '\\033[36m'\n BLUE = '\\033[94m'\n GREEN = '\\033[92m'\n YELLOW = '\\033[93m'\n RED = '\\033[91m'\n BOLD = '\\033[1m'\n UNDERLINE = '\\033[4m'\n END = '\\033[0m'\n\nprint(color.BOLD + 'Hello World !' + color.END)\n</code></pre></p>"},{"location":"Tools/Programming_Languages/Python/01/#idk_2","title":"IDK","text":""},{"location":"Tools/Programming_Languages/Python/01/#name-of-script","title":"Name of script","text":"<p><pre><code>__file__\n</code></pre> Useful for pages in Streamlit</p>"},{"location":"Tools/Programming_Languages/Python/01/#name-of-calling-function","title":"Name of calling function","text":"<p><pre><code>__name__\n</code></pre> Useful for checking if this is a program or a library</p>"},{"location":"Tools/Programming_Languages/Python/01/#input-hidden-textpassword","title":"Input Hidden Text/Password","text":"<pre><code>from getpass import getpass\nsender_password = getpass(\"Password: \")\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#date-time","title":"Date-Time","text":"<p>Refer to Python DateTime Formats <pre><code>dob = '05/02/1985'\ndob = datetime.strptime(dob, '%d/%m/%Y')\n</code></pre></p>"},{"location":"Tools/Programming_Languages/Python/01/#find-home-directory","title":"Find Home Directory","text":"<p>\u2705 This is cross-platform <pre><code>from pathlib import Path\nhome = str(Path.home())\n</code></pre></p>"},{"location":"Tools/Programming_Languages/Python/01/#delete","title":"Delete","text":""},{"location":"Tools/Programming_Languages/Python/01/#move-file-to-recycle-bin","title":"Move file to Recycle Bin","text":"<pre><code>  from send2trash import send2trash\n\n  send2trash(\"test_folder\")\n\n  send2trash(\"test.csv\")\n\n  for file_name in glob.glob(os.path.join(directory, '*.mov')):\n    file = os.path.join(directory, file_name)\n    send2trash(file)\n    print(\"Deleted\", file)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#permanently-delete-file","title":"\u274c Permanently Delete File","text":"<pre><code>  os.remove(file)\n\n  for file_name in glob.glob(os.path.join(directory, '*.mov')):\n    file = os.path.join(directory, file_name)\n    os.remove(file)\n    print(\"Deleted\", file, \"Permanently\")\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#permanently-delete-folder","title":"\u274c Permanently Delete Folder","text":"<pre><code>  import shutil\n  shutil.rmtree(path)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#copy","title":"Copy","text":"<pre><code>import shutil\n\nshutil.copy_file(src, dest) ## contents of file\nshutil.copy() ## copy_file() + permission mode\nshutil.copy2() ## copy() + copies metadata\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#list-all-files-in-a-directory","title":"List all files in a directory","text":"<pre><code>import os\n\nfor file_name in os.listdir(\"./data\"):\n  file = os.path.join(directory, file_name)\n  print(file)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#create-a-folder","title":"Create a folder","text":"<pre><code>newpath = r'C:\\Program Files\\arbitrary' \nif not os.path.exists(newpath):\n    os.makedirs(newpath)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-only-files-of-a-particular-type-using-glob","title":"Get only files of a particular type using <code>glob</code>","text":"<pre><code>for file_name in glob.glob(os.path.join(directory, '*.mp4')):\n  file = os.path.join(directory, file_name)\n    print(file)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-files-of-multiple-types-using-glob","title":"Get files of Multiple Types using <code>glob</code>","text":"<pre><code># better\n\nfrom pathlib import Path\nall_note_paths = (\n    p.resolve() for p in Path(\"./\").glob(\"**/*\") if p.suffix in [\n        \".md\", \".css\", \".js\", \".html\"\n    ]\n)\n</code></pre> <pre><code>def list_files(images_dir):\n  l = []\n\n  for type in [\"jpg\", \"jpeg\", \"png\"]:\n    this_type_files = glob.glob(\n      os.path.join(images_dir, \"**\", f\"*.{type}\"),\n      recursive = True\n    )\n    l += this_type_files\n  return l\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-filename-with-extension","title":"Get filename with extension","text":"<pre><code>import os\nfile_name_with_ext = os.path.basename(\"a/b/c\")\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-folder-name","title":"Get folder name","text":"<pre><code>filename = \"folder/file.mp4\"\nos.path.dirname(filename)\n\nfilename = \"folder/folder/file.mp4\"\nos.path.basename(os.path.dirname(filename))\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-extension-only","title":"Get extension only","text":"<pre><code>import os\next = os.path.splitext(filename)[1]\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-filename-only","title":"Get filename only","text":"<pre><code>import os\n\ndef get_filename(file):\n  file_name = os.path.basename(file)\n  file_name_without_ext = os.path.splitext(file_name)[0]\n\n  ## using the above\n  new_file_name = os.path.splitext(file_name)[0] ## + \"_Copy\" + os.path.splitext(file_name)[1]\n\n  return new_file_name\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#files-in-directory-and-sub-directory","title":"Files in directory and sub-directory","text":"<pre><code>from os import walk\nfiles = []\n\n## specific directory\nfiles = []\nfor (dirpath, dirnames, filenames) in walk(\"./data\"):\n    files.extend(filenames)\n    break\n\n## directory and subdirectories\nfor (dirpath, dirnames, filenames) in walk(\".\"):\n    files.extend(filenames)\n\nfiles\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#search-substring-in-string","title":"Search Substring in String","text":"<pre><code>my_string[:-3] == \"pdf\"\nmy_string.find(\"pdf\")\n\"pdf\" in my_string\n\nmy_string.index(\"pdf\")\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#idk_3","title":"IDK","text":"<pre><code>for (i, file) in enumerate(files):\nprint(i, \"is\", file)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#class","title":"Class","text":"<pre><code>object.__members__\nobject.__methods__\n\ndir(object)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#inspect","title":"Inspect","text":"<p>Inspect class <pre><code>def func_of_class(class_name):\n  return [\n    func for func in dir(class_name)\n    if callable(getattr(class_name, func))\n    and not func.startswith(\"__\")\n  ]\n\nobj = my_class()\nfor func in func_of_class(type(obj)):\n  getattr(obj, func)(arg)\n</code></pre> Inspect Function Getting arguments of a function <pre><code>  getfullargspec(model_equation).args\n</code></pre> Dynamically get the code of a python function <pre><code>Inspect.getsource\n</code></pre> Dynamically run python code <pre><code>python_code = \"\"\"\nprint(\"hello world\")\n\"\"\"\nexec(python_code)\n</code></pre></p>"},{"location":"Tools/Programming_Languages/Python/01/#create-virtual-environment","title":"Create virtual environment","text":"<p><pre><code>python -m venv \"./venv\"\npython -m venv \"C:blah/blah/venv\"\n</code></pre> Switch to this virtual environment If you get an error when a powershell script runs, run this code in Powershell (admin) <pre><code>  Set-ExecutionPolicy RemoteSigned\n</code></pre></p>"},{"location":"Tools/Programming_Languages/Python/01/#traverse-list-with-index-and-value","title":"Traverse list with index and value","text":"<pre><code>for i, val in enumerate(list):\nprint(i)\nprint(val)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#cli","title":"CLI","text":""},{"location":"Tools/Programming_Languages/Python/01/#argparse","title":"Argparse","text":"<pre><code>import argparse\n\nTIME_THRESHOLD = 10\nHASH_SIZE = 4\n\nif __name__ == \"__main__\":\n  parser = argparse.ArgumentParser(description = \"Group similar images\")\n\n  parser.add_argument(\"--tt\", type = int, help = f\"Time Threshold (seconds), default = {TIME_THRESHOLD}\")\n  parser.add_argument(\"--hs\", type = int, help = f\"Hash Size, default = {HASH_SIZE}\")\n\n  args = parser.parse_args()\n\n  TIME_THRESHOLD = args.tt\n  HASH_SIZE = args.hs\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#adding-to-path-using-setuptools","title":"Adding to path using setuptools","text":"<p>https://python-packaging.readthedocs.io/en/latest/command-line-scripts.html</p>"},{"location":"Tools/Programming_Languages/Python/01/#import-classesfunctions-from-another-python-file","title":"Import classes/functions from another python file","text":"<pre><code>from my_other_file import my_func, MyClass\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-classes-of-modulepython-file","title":"Get classes of module/Python file","text":"<pre><code>def get_classes_of_module(module):\n    m = []\n    import importlib, inspect\n    for name, c in inspect.getmembers(importlib.import_module(\"utils.models\"), inspect.isclass):\n        if c.__module__ == 'utils.models':\n            m.append(c)\n    return m\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#caching","title":"Caching","text":"<pre><code>from functools import cache\nimport time\n\n@cache\ndef function():\ntime.sleep(10) ## this will be skipped by cache\nreturn 1\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#get-variable-name","title":"Get variable name","text":"<pre><code>import inspect\n\ndef var(var):\n    current_frame = inspect.currentframe()\n    caller_frame = inspect.getouterframes(current_frame)[1]\n    local_vars = caller_frame.frame.f_locals\n\n    for name, value in local_vars.items():\n        if value is var:\n            return name\n\nvar = \"Hello\"\nvar_name = var(var)\n</code></pre> <pre><code># doesn't work inside a function\n\nvar = \"Hello\"\nvar_name = f\"{var=}\".split(\"=\")[0]\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#memory-usage","title":"Memory Usage","text":"<pre><code>def get_memory_usage():\n  process = Process(os.getpid())\n  mb = process.memory_info().rss/(1024**2)\n  return mb\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#lazy-imports","title":"Lazy Imports","text":"<pre><code>class LazyImport:\n  def __init__(self, module_name):\n    self.module_name = module_name\n    self._module = None\n\n  def __getattr__(self, attr):\n    if self._module is None:\n      self._module = importlib.import_module(self.module_name)\n    return getattr(self._module, attr)\n\nnp = LazyImport(\"numpy\")\nnp.array([0, 1, 2])\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#save-file","title":"Save File","text":"<pre><code>def save_file(file, file_name, location):\n    with open(os.path.join(location, file_name), \"wb\") as f:\n        f.write(file.getbuffer())\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#intersection-of-2-curves","title":"Intersection of 2 Curves","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.arange(0, 1000)\nf = np.arange(0, 1000)\ng = np.sin(np.arange(0, 10, 0.01) * 2) * 1000\n\nplt.plot(x, f, '-')\nplt.plot(x, g, '-')\n\nidx = np.argwhere(np.diff(np.sign(f - g))).flatten()\nplt.plot(x[idx], f[idx], 'ro')\nplt.show()\n</code></pre> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom shapely.geometry import LineString\n\ndf = pd.read_excel('D:/Coding Practice/data/data_supply-demand.xlsx')\n\nsupply = df['Supply']\ndemand = df['Demand']\nprice = df['Price(dollar)']\n\n#it's time for visualization\nplt.plot(supply,price)\nplt.plot(demand,price)\n\nline_1 = LineString(np.column_stack((supply, price)))\nline_2 = LineString(np.column_stack((demand, price)))\nintersection = line_1.intersection(line_2)\n\nplt.plot(*intersection.xy, 'ro')\n\nplt.show()\n\nx, y = intersection.xy\nprint(x, y)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#progress-bar","title":"Progress Bar","text":"<pre><code>for epoch in range(NUM_EPOCHS):\n    loop = tqdm(loader)\n    for idx, (x, y) in enumerate(loop):\n        scores = model(x)\n\n        # here we would compute loss, backward, optimizer step etc.\n        # you know how it goes, but now you have a nice progress bar\n        # with tqdm\n\n        # then at the bottom if you want additional info shown, you can\n        # add it here, for loss and accuracy you would obviously compute\n        # but now we just set them to random values\n        loop.set_description(f\"Epoch [{epoch}/{NUM_EPOCHS}]\")\n        loop.set_postfix(\n            loss=torch.rand(1).detatch(),\n            acc=torch.rand(1).detatch()\n        )\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/01/#idk_4","title":"IDK","text":"<pre><code>import inspect\n\nclass ClassName():\n    def __init__(self, ..., ..., ...):\n        args, _, _, values = inspect.getargvalues(inspect.currentframe())\n        values.pop(\"self\")\n        for arg, val in values.items():\n            setattr(self, arg, val)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/02_Creating_Package/","title":"Creating Packages","text":""},{"location":"Tools/Programming_Languages/Python/02_Creating_Package/#folder-structure","title":"Folder Structure","text":"<pre><code>base_folder\n- package_name\n    - init.py\n    - package_name.py\n- setup.py\n- requirements.txt\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/02_Creating_Package/#package_namepy","title":"<code>package_name.py</code>","text":"<pre><code>class Package_Name:\n  pass\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/02_Creating_Package/#initpy","title":"<code>init.py</code>","text":"<pre><code>from package_name import Package_Name\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/02_Creating_Package/#setuppy","title":"<code>setup.py</code>","text":"<pre><code>\"\"\"\nAuthor: Ahmed Thahir\n\nThis is free and unencumbered software released into the public domain.\n\nAnyone is free to copy, modify, publish, use, compile, sell, or\ndistribute this software, either in source code form or as a compiled\nbinary, for any purpose, commercial or non-commercial, and by any\nmeans.\n\nIn jurisdictions that recognize copyright laws, the author or authors\nof this software dedicate any and all copyright interest in the\nsoftware to the public domain. We make this dedication for the benefit\nof the public at large and to the detriment of our heirs and\nsuccessors. We intend this dedication to be an overt act of\nrelinquishment in perpetuity of all present and future rights to this\nsoftware under copyright law.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR\nOTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,\nARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR\nOTHER DEALINGS IN THE SOFTWARE.\n\nFor more information, please refer to &lt;http://unlicense.org/&gt;\n\"\"\"\n\ntry:\n    from setuptools import setup, find_packages\nexcept ImportError:\n    from distutils.core import setup, find_packages\n\nVERSION = \"0.0.1\"\nDESCRIPTION = \"St. Louis Federal Reserve FRED API\"\n\nimport os\nhere = os.path.abspath(os.path.dirname(__file__))\n\nwith open(os.path.join(here, \"requirements.txt\"), \"r\", encoding=\"utf-8\") as f:\n    requirements = f.read().splitlines()\n\nwith open(os.path.join(here, \"README.md\"), \"r\", encoding=\"utf-8\") as f:\n    long_description = \"\\n\" + f.read()\n\nsetup(\n    name = \"fredx\",\n    version = VERSION,\n    description = DESCRIPTION,\n\n    long_description = long_description,\n    long_description_content_type = \"text/markdown\",\n\n    keywords = [\"fred\", \"api\", \"federal reserve\", \"st. louis fed\", \"async\"],\n    author = \"Ahmed Thahir\",\n    author_email = \"ahmedthahir2002@gmail.com\",\n    url = \"https://github.com/AhmedThahir/fredx\",\n    license = \"MIT\",\n    packages = find_packages(),\n    install_requires = requirements,\n    classifiers = [\n        \"Development Status :: 1 - Planning\",\n        \"Intended Audience :: Developers\",\n        \"Programming Language :: Python :: 3\",\n        \"Operating System :: Unix\",\n        \"Operating System :: MacOS :: MacOS X\",\n        \"Operating System :: Microsoft :: Windows\",\n        \"Topic :: Internet\",\n        \"Topic :: Internet :: WWW/HTTP\",\n        \"Natural Language :: English\",\n    ],\n)\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/02_Creating_Package/#building","title":"Building","text":"<pre><code>pip install setuptools\npython setup.py sdist bdist_wheel\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/02_Creating_Package/#uploading","title":"Uploading","text":"<pre><code>pip install twine\ntwine upload dist/*\n</code></pre>"},{"location":"Tools/Programming_Languages/Python/03_Concurrency/","title":"Concurrency","text":""},{"location":"Tools/Programming_Languages/Python/03_Concurrency/#async","title":"Async","text":""},{"location":"Tools/Programming_Languages/Python/03_Concurrency/#multi-threading","title":"Multi-Threading","text":""},{"location":"Tools/Programming_Languages/Python/03_Concurrency/#multi-processing","title":"Multi-Processing","text":""},{"location":"Tools/Programming_Languages/Python/03_Concurrency/#subprocess","title":"Subprocess","text":"<p>```python for chunk in range(1, 10):         command = f\"command -- {chunk}\"</p> <pre><code>    command_list = shlex.split(command)\n    procs.append(\n        subprocess.Popen(\n    command_list,\n    shell=True,\n    text=True\n  )\n    )\n\n    time.sleep(3)\n# some gap between starting up subprocesses\n</code></pre> <p>for p in procs:   p.wait()</p>"},{"location":"Tools/PyPSA/","title":"PyPSA","text":""},{"location":"Tools/PyPSA/#references","title":"References","text":"<ul> <li>Getting Started with PyPSA-Eur | Fabian Neumann</li> <li>PyPSA meets Earth</li> <li>Open Energy Modelling | Meridien Economics</li> </ul>"},{"location":"Tools/Video/Manim/","title":"Manim","text":""},{"location":"Tools/Video/Manim/#workflow","title":"Workflow","text":"<ol> <li>render manim animation</li> <li>import into video editor</li> <li>record voiceover</li> <li>use lossless cut/shutter encoder/ffmpeg to attach the audio</li> </ol>"},{"location":"Tools/Video/Manim/#installation","title":"Installation","text":"<p>make sure to add everything to system path</p> <p>Advanced System Settings &gt; Environmental Variables &gt; Path &gt; Add &gt; folder</p>"},{"location":"Tools/Video/Manim/#dependencies","title":"Dependencies","text":"<ol> <li>python    python using anaconda</li> <li>latex</li> <li>manim</li> <li><code>conda install pycairo</code></li> <li><code>pip install manim</code></li> <li>ffmpeg</li> </ol>"},{"location":"Tools/Video/Manim/#macos","title":"Macos","text":"<pre><code>python -m pip install -r ~/Desktop/manim-master/requirements.txt\n</code></pre> <p>install latex mactex</p> <p>ffmpeg</p> <pre><code>sudo chown -R $(whoami) /usr/local/bin\nmv ffmpeg ffplay ffprobe /usr/local/bin\n</code></pre>"},{"location":"Tools/Video/Manim/#text","title":"Text","text":"<p>Tex for text</p> <p>MathTex for math</p> <p><code>self.play(Write(t1), run_time = 5), self.wait(delay)</code></p>"},{"location":"Tools/Video/Manim/#matrices","title":"Matrices","text":"<pre><code>Matrix([\n  (\"10\", \"20\", \"45\"),\n    (\"45\", \"97  \", \"123\"),\n    (\"133\", \"56\", \"75\")],\n  size= 0.5\n)\n</code></pre>"},{"location":"Tools/Video/Manim/#screen","title":"Screen","text":"<p><code>self.clear()</code> clears screen</p>"},{"location":"Tools/Video/Manim/#example-program","title":"Example Program","text":""},{"location":"Tools/Video/Manim/#test","title":"Test","text":"<pre><code>from manim import *\n\n## delay in seconds\ndelay = 0.1 ## bw animations\nendDelay = 2 ## end \n\nclass testAnimation(Scene):\n    def construct(self):\n        t1 = Tex(\"Introduction to Equations\", color = BLUE).to_corner(UP)\n        self.play(Write(t1), run_time = 5), self.wait(delay)\n\n        t2 = MathTex(\"x^2 + 2x\").to_corner(UP).next_to(t1, DOWN)\n        self.play(Write(t2)), self.wait(delay)\n\n        t3 = Tex(\"A basic quadratic equation\", color = GOLD_B).to_corner(RIGHT)\n        self.play(Transform(t1, t3)), self.wait(delay)\n\n        t4 = t3.shift(DOWN)\n        self.play(Transform(t1, t4)), self.wait(endDelay)\n\n        page1 = VGroup(t1, t2)\n\n        ## self.clear()\n\n        t5 = MathTex(r\"h(x) = \\theta X \\text{ or } X\\theta\")\n\n        self.play(Write(t5)), self.wait(endDelay)\n\n        page2 = VGroup(t5)\n</code></pre>"},{"location":"Tools/Video/Manim/#poisson-dist","title":"Poisson Dist","text":"<pre><code>from manim import *\n\n## sizing\nh1 = 2\nh2 = 1.5\npwidth = 12\npline  = 1.2\n\n## delay in seconds\ndelay = 0.1 ## b/w animations\nendDelay = 2 ## slide end\n\nclass TestAnimation(Scene):\n    def construct(self):\n        ## page 1\n        t = [0] ## start array from 1\n\n        t.append(Tex(\"Introduction to Statistics\", color = PINK).to_corner(UP)), t[-1].scale(h1)\n        t.append(Tex(\"Poisson Distribution\", color = GOLD_B).next_to(t[1], DOWN)), t[-1].scale(h2)\n        t.append(Text(\"\"\"\n                The Poisson Distribution is a discrete probability distribution\n                that measures the probability that a certain number of independent \n                events occur within a certain interval/continuum.\n                \"\"\", line_spacing= pline) )\n        t[-1].width = pwidth\n\n        for i in range(1, 3+1): ## 1 - 3\n            if(i == 3):\n                self.play(Write(t[i]), run_time = 10)\n            else:\n                self.play(Write(t[i]))\n            self.wait(delay)\n        self.wait(endDelay)\n\n        ## page 2\n        self.clear()\n        t = [0]\n\n        t.append(Tex(\"Formula\", color =  GOLD_B).to_corner(UP)), t[1].scale(h1)\n        t.append(MathTex(r\"P\\left( x \\right) = \\frac{ {e^{ - \\mu } \\mu ^x } }{ {x!} }\"))\n        t.append(MathTex(\"x = 0, 1, 2, ...\").next_to(t[2]))\n\n        for i in range(1, 3+1):\n            if (i == 2):\n                self.play(Write(t[i]), run_time = 3), self.wait(delay)\n                t[i].generate_target()\n                t[i].target.shift(LEFT * 2)\n                self.play(MoveToTarget(t[i])), self.wait(delay)\n            else:\n                self.play(Write(t[i]))\n            self.wait(delay)\n        self.wait(endDelay)\n\n        ## thank you\n        self.clear()\n\n        t = Tex(\"Thank you\", color = GOLD_B)\n        t.scale(h1)\n        self.play(Write(t)), self.wait(endDelay)\n</code></pre>"},{"location":"Tools/Video/Manim/#example","title":"Example","text":"<pre><code>from manim import *\n\n## sizing\nh1 = 2\nh2 = 1.5\npwidth = 12\npline  = 1.2\n\n## delay in seconds\ndelay = 0.1 ## b/w animations\nendDelay = 2 ## slide end\n\nclass TestAnimation(Scene):\n  def construct(self):\n      ## page 1\n      t = [0] ## start array from 1\n\n      t.append(Tex(\"Introduction to Statistics\", color = PINK).to_corner(UP)), t[-1].scale(h1)\n      t.append(Tex(\"Poisson Distribution\", color = GOLD_B).next_to(t[1], DOWN)), t[-1].scale(h2)\n      t.append(Text(\"\"\"\n              The Poisson Distribution is a discrete probability distribution\n              that measures the probability that a certain number of independent \n              events occur within a certain interval/continuum.\n              \"\"\", line_spacing= pline) )\n      t[-1].width = pwidth\n\n      for i in range(1, 3+1): ## 1 - 3\n          if(i == 3):\n              self.play(Write(t[i]), run_time = 10)\n          else:\n              self.play(Write(t[i]))\n          self.wait(delay)\n      self.wait(endDelay)\n\n      ## page 2\n      self.clear()\n      t = [0]\n\n      t.append(Tex(\"Formula\", color =  GOLD_B).to_corner(UP)), t[1].scale(h1)\n      t.append(MathTex(r\"P\\left( x \\right) = \\frac{ {e^{ - \\mu } \\mu ^x } }{ {x!} }\"))\n      t.append(MathTex(\"x = 0, 1, 2, ...\").next_to(t[2]))\n\n      for i in range(1, 3+1):\n          if (i == 2):\n              self.play(Write(t[i]), run_time = 3), self.wait(delay)\n              t[i].generate_target()\n              t[i].target.shift(LEFT * 2)\n              self.play(MoveToTarget(t[i])), self.wait(delay)\n          else:\n              self.play(Write(t[i]))\n          self.wait(delay)\n      self.wait(endDelay)\n\n      ## thank you\n      self.clear()\n\n      t = Tex(\"Thank you\", color = GOLD_B)\n      t.scale(h1)\n      self.play(Write(t)), self.wait(endDelay)\n</code></pre>"},{"location":"Tools/Video/Manim/#running","title":"Running","text":""},{"location":"Tools/Video/Manim/#cli","title":"CLI","text":"<pre><code>manim -hq -p file.py Scene_Name -w test.mp4\n\nmanimgl -o -f file.py Scene_Name -w test.mp4\n</code></pre> <ul> <li>`manim test.py -p -ql``</li> <li><code>`manim test.py -p -ql</code></li> <li>manim test.py -p -qh`</li> </ul>"},{"location":"Tools/Video/Manim/#within-py-script","title":"Within <code>.py</code> script","text":"<pre><code>command = \"manim -hq -p file.py Scene_Name\"\n\nimport subprocess\nsubprocess.Popen(command)\n</code></pre>"},{"location":"Tools/Video/Manim/#references","title":"References","text":"<ul> <li>Mathematical Animations WITH EASE | Benjamin Hackl</li> </ul>"},{"location":"Tools/Video/OBS%20Studio/01/","title":"01","text":""},{"location":"Tools/Video/OBS%20Studio/01/#live-pseudo-motion-blur","title":"Live [Pseudo] Motion Blur","text":"<p>I know this is a very old question, i found a new method where you can use more than 2 or 3 Game Capture screens by putting a second Game Capture duplicated by Duplicate (Reference) inside a Group Folder and editing the group folder's filters with Color Correction then adding 30 - 70 ms of Render delay (render delay may depend on how high your fps is. mine is currently on 40 ms on 50 PAL) then there you go.</p> <p>This method is better since using too many Window Captures (for me) lags my OBS.</p>"},{"location":"Tools/Video/auto-editor/","title":"Index","text":"<p>Always use <code>--keep-tracks-separate</code> to avoid weird syncing issues</p>"},{"location":"Tools/Video/auto-editor/#my-usual-settings","title":"My usual settings","text":"<pre><code>auto-editor input.mp4 --sounded-speed 1 --silent-speed 0 --edit \"audio:stream=1,threshold=-30dB,mincut=1s\" --my-ffmpeg --extras \"-c:v hevc_nvenc -cq 30 -c:a copy -preset ultrafast\" --keep-tracks-separate\n</code></pre>"},{"location":"Tools/Video/auto-editor/#check-file-properties","title":"Check File Properties","text":"<pre><code>auto-editor info test.mkv\n</code></pre>"},{"location":"Tools/Video/auto-editor/#default-settings","title":"Default Settings","text":"<pre><code>## all default settings\nauto-editor test.mkv --show-ffmpeg-debug\n\nauto-editor --scale --help\nauto-editor --margin --help\n</code></pre>"},{"location":"Tools/Video/auto-editor/#output-stats-preview","title":"Output Stats Preview","text":"<pre><code>auto-editor input.mp4 --stats\n</code></pre>"},{"location":"Tools/Video/auto-editor/#custom-output-name","title":"Custom Output Name","text":"<pre><code>auto-editor input.mp4 --output-file output.mp4\n</code></pre>"},{"location":"Tools/Video/auto-editor/#analyze-different-audio-tracks","title":"Analyze different audio tracks","text":"<pre><code>auto-editor multi-track.mov --edit \"audio:stream=1 audio:threshold=10%\" --keep-tracks-separate\nauto-editor multi-track.mov --edit \"(or audio:stream=0 audio:threshold=10%,stream=1)\" --keep-tracks-separate\n</code></pre>"},{"location":"Tools/Video/auto-editor/#gpu-cqp","title":"GPU + CQP","text":"<pre><code>#CQP\nauto-editor video.mp4 --video-codec hevc_nvenc --my-ffmpeg --extras \"-rc vbr_hq -qmin 0 -cq 30\" --keep-tracks-separate\n\nauto-editor test.mkv --video-codec hevc_nvenc --my-ffmpeg --keep-tracks-separate\nauto-editor test.mkv --video-codec h264_nvenc --my-ffmpeg --keep-tracks-separate\n</code></pre>"},{"location":"Tools/Video/auto-editor/#premiere","title":"Premiere","text":"<pre><code>auto-editor example.mp4 --export premiere --keep-tracks-separate\n</code></pre>"},{"location":"Tools/Video/auto-editor/#speed-of-quiet-and-loud-parts","title":"Speed of quiet and loud parts","text":"<pre><code>auto-editor video.mp4 --silent-speed 10.0 --sounded-speed 1.5 --keep-tracks-separate\n</code></pre>"},{"location":"Tools/Video/auto-editor/#analyze-only-a-particular-track","title":"Analyze only a particular track","text":"<pre><code>auto-editor video.mp4 --edit \"audio:stream=2 audio:threshold=4%\" --keep-tracks-separate\n\nauto-editor video.mp4 --edit \"(or audio:stream=2 audio:threshold=4%,stream=0)\" --keep-tracks-separate\n</code></pre>"},{"location":"Tools/Video/auto-editor/#running-from-python-script","title":"Running from Python Script","text":""},{"location":"Tools/Video/auto-editor/#process-single-video","title":"Process Single Video","text":"<pre><code>  import subprocess\n\n  video = \"test.mp4\"\n\n  command = r'auto-editor \"{}\" --video-codec hevc_nvenc --my-ffmpeg --keep-tracks-separate'.format(video)\n  subprocess.Popen(command)\n</code></pre>"},{"location":"Tools/Video/auto-editor/#process-multiple-videos","title":"Process Multiple Videos","text":"<pre><code>  import subprocess\n  import os\n\n  def find_videos(directory):\n    videos = []\n    for filename in os.listdir(directory):\n      extension = filename.split(\".\")[-1]\n      if(extension in [\"mp4\", \"mkv\"]):\n        video = os.path.join(directory, filename)\n        videos.append(video)\n    return videos\n\n  def process_video(video):\n    command = r'auto-editor \"{}\" --video-codec hevc_nvenc --my-ffmpeg --keep-tracks-separate'.format(video)\n    subprocess.Popen(command)\n\n  if __name__ == \"__main__\":\n    directory = os.getcwd()\n    videos = find_videos(directory)\n\n    for video in videos:\n      process_video(video)\n</code></pre>"},{"location":"Tools/Video/auto-editor/#lossless","title":"Lossless","text":"<pre><code>import numpy as np\nimport time\nimport re\nimport sys\nimport json\nimport os\nimport concurrent.futures as multi\n\ndef cleanup():\n  files_to_remove = []\n  for file in os.listdir():\n    for unwanted in [\"_segment\"]:\n      if unwanted in file.lower():\n        files_to_remove.append(file)\n  with multi.ThreadPoolExecutor() as executor:\n    executor.map(os.remove, files_to_remove)\n\ndef get_fps(input_file):\n  info = os.popen(f'ffprobe -i \"{input_file}\" 2&gt;&amp;1').read()\n  match = re.search(r'\\s([\\d\\.]*)\\sfps', info)\n  if match:\n    return float(match.group(1))\n  return 0.0\n\ndef get_keyframe_interval(input_file):\n  \"\"\"\n  Get average keyframe interval\n  \"\"\"\n\n  start_time_to_read = 1\n  max_seconds_to_read = 5\n  info = os.popen(f\"\"\"\n  ffprobe -read_intervals {start_time_to_read}%+{max_seconds_to_read} -select_streams v -show_entries frame=pts_time -of csv=p=0 -skip_frame nokey -v 0 -hide_banner -i {input_file}\n  \"\"\").read()\n\n  keyframe_time_points = np.array(info.split(\"\\n\"))\n  keyframe_time_points = keyframe_time_points[\n    (keyframe_time_points != \"\")\n  ]\n  keyframe_time_points = keyframe_time_points.astype(np.float32)\n  keyframe_interval = np.round(np.mean(np.diff(keyframe_time_points))).astype(int)\n  return keyframe_interval\n\ndef process_json(input_file, fps, json):\n  extension = os.path.splitext(input_file)[1]\n  cmd = []\n  with open('_segments.txt', 'w') as f:\n    sounded_chunks = json[\"v\"][0]\n    for segment_number, sounded_chunk in enumerate(sounded_chunks):\n      segment_file_name = f\"_segment{segment_number}{extension}\"\n\n      f.write(f'file {segment_file_name}\\n')\n\n      offset_time = sounded_chunk[\"offset\"] / fps\n      start_time = sounded_chunk[\"start\"] / fps\n      speed = sounded_chunk[\"speed\"]\n      duration = (sounded_chunk[\"dur\"]/speed) / fps\n\n      cmd.append(f\"\"\"\n      ffmpeg -hide_banner -loglevel error \\\n      -ss {offset_time + start_time} \\\n      {(\n        f\"-itsscale {1/speed}\"\n        if speed==1\n        else \"\"\n      )} \\\n      -i \"{input_file}\" \\\n      -t {duration} \\\n      -avoid_negative_ts make_zero \\\n      {(\n        \"-c:a copy\"\n        if speed==1\n        else f\"-af volume=0 -af atempo={speed}\"\n      )} \\\n      -c:v copy \\\n      -map_metadata 0 -movflags use_metadata_tags -movflags '+faststart' -default_mode infer_no_subs -ignore_unknown -y \\\n      {segment_file_name}\n      \"\"\")\n\n    with multi.ProcessPoolExecutor() as executor:\n      executor.map(os.system, cmd)\n\ndef combine_segments(input_file):\n  os.system(f\"\"\"\n  ffmpeg  -hide_banner -loglevel error \\\n  -f concat -safe 0 -protocol_whitelist 'file,pipe,fd' \\\n  -i _segments.txt \\\n  -c copy \\\n  '-disposition' default -movflags use_metadata_tags -movflags '+faststart' -default_mode infer_no_subs -ignore_unknown -y \\\n  \"{os.path.splitext(input_file)[0]}_STRIPPED{os.path.splitext(input_file)[1]}\"\n  \"\"\")\n\ndef process_file(input_file):\n  fps_val = get_fps(input_file)\n  keyframe_interval = get_keyframe_interval(input_file)\n\n  if fps_val &lt;= 0.0:\n    print(f'Unable to determine FPS of {input_file}')\n    return\n\n  os.system(f'auto-editor \"{input_file}\" --edit \"audio:threshold=-40dB,mincut={max([1, 1 + keyframe_interval])}s\" --export json')\n  json_file = os.path.splitext(input_file)[0] + '_ALTERED.json'\n  with open(json_file) as f:\n    json_data = json.load(f)\n  process_json(input_file, fps_val, json_data)\n  os.remove(json_file)\n  combine_segments(input_file)\n\ndef iterate_files():\n  for input_file in sys.argv[1:]:\n    process_file(input_file)\n\ndef main():\n  cleanup()\n\n  start_time = time.time()\n  iterate_files()\n  print(\"--- %s seconds ---\" % (time.time() - start_time))\n\n  cleanup()\n\nif __name__ == \"__main__\":\n  main()\n</code></pre>"},{"location":"Tools/Video/auto-editor/#editing-logic","title":"Editing logic","text":"<pre><code>default: audio (only)\n\nEditing Methods:\n - audio: General audio detection\n - motion: Motion detection specialized for real life noisy video\n - pixeldiff: Detect when a certain amount of pixels have changed between frames\n - random: Set silent/loud randomly based on a random or preset seed\n - none: Do not modify the media in anyway (Mark all sections as \"loud\")\n - all: Cut out everything out (Mark all sections as \"silent\")\n\nAttribute Defaults:\n - audio\n    - threshold: 4% (number)\n    - stream: 0 (natural | \"all\")\n - motion\n    - threshold: 2% (number)\n    - stream: 0 (natural | \"all\")\n    - blur: 9 (natural)\n    - width: 400 (natural)\n - pixeldiff\n    - threshold: 1 (natural)\n    - stream: 0 (natural | \"all\")\n - random\n    - threshold: 0.5 (number)\n    - seed: RANDOMLY-GENERATED (int)\n\nOperators:\n - and\n   - usage: $METHOD and $METHOD\n - or\n   - usage: $METHOD or $METHOD\n - xor\n   - usage: $METHOD xor $METHOD\n - not\n   - usage: not $METHOD\nExamples:\n  --edit audio\n  --edit audio:stream=1\n  --edit audio:threshold=4%\n  --edit audio:threshold=0.03\n  --edit motion\n  --edit motion:threshold=2%,blur=3\n  --edit audio:threshold=4% or motion:threshold=2%,blur=3\n  --edit none\n  --edit all\n</code></pre>"},{"location":"Tools/Video/ffmpeg/","title":"Index","text":""},{"location":"Tools/Video/ffmpeg/#installation","title":"Installation","text":""},{"location":"Tools/Video/ffmpeg/#macos","title":"Macos","text":""},{"location":"Tools/Video/ffmpeg/#download-ffmpeg-and-ffprobe","title":"Download ffmpeg and ffprobe","text":"<p>Go to https://ffmpeg.org/download.html and click the Apple logo in the \"Get packages &amp; executable files\" section.</p> <p>Click \"Static builds for macOS 64-bit\".</p> <p>You'll see two options for downloading ffmpeg. Choose the one with the shorter filename; this will look like  <code>ffmpeg-&lt;versionNumber&gt;.7z</code> , where  <code>&lt;versionNumber&gt;</code>  is something like  <code>4.3.1</code> .</p> <p>Underneath this heading, click \"Download as ZIP\".</p> <p>Scroll down the page until you see ffprobe. Choosing the shorter filename, under  <code>ffprobe-&lt;versionNumber&gt;.7z</code> , click \"Download the file as ZIP\".</p> <p>If a popup appears after clicking the download link, press \"allow\" or \"save\".</p> <p>Open your Downloads folder, and double-click  <code>ffmpeg-&lt;versionNumber&gt;.zip</code> . This will extract it using the Archive Utility and create an executable  <code>ffmpeg</code>  file in Downloads.</p> <p>Repeat this step for  <code>ffprobe</code> .</p> <p>You should now have two executables, called  <code>ffmpeg</code>  and  <code>ffprobe</code> .</p>"},{"location":"Tools/Video/ffmpeg/#move-the-downloaded-files-to-the-right-location","title":"Move the downloaded files to the right location","text":"<p>Open your home folder.</p> <p>Your home folder has the same name as your user account. The easiest way to find it is to open Finder, and use the keyboard shortcut  <code>command + shift + H</code>  or in the menu bar select Go &gt; Home.</p> <p>You should see folders such as Desktop, Applications, and Downloads in this folder.</p> <p>Create a new folder called  <code>audio-orchestrator-ffmpeg</code>  in your home folder.</p> <p>Go to File &gt; New folder or use the shortcut  <code>command + shift + N</code> , type or enter the folder name, and press  <code>return</code>  to confirm.</p> <p>Open your new  <code>audio-orchestrator-ffmpeg</code>  folder by double-clicking it.</p> <p>Create a new folder called  <code>bin</code>  in  <code>audio-orchestrator-ffmpeg</code> .</p> <p>Move the  <code>ffmpeg</code>  and  <code>ffprobe</code>  files from  <code>Downloads</code>  into this  <code>bin</code>  folder.</p> <p>You should now have two files,  <code>ffmpeg</code>  and  <code>ffprobe</code> , in your  <code>~/audio-orchestrator-ffmpeg/bin/</code>  folder      ffmpeg and ffprobe executables with the required folder structure </p>"},{"location":"Tools/Video/ffmpeg/#authorise-ffmpeg-and-ffprobe","title":"Authorise ffmpeg and ffprobe","text":"<p>Double-click the file called  <code>ffmpeg</code> .</p> <p>You should see an error message \"ffmpeg can\u2019t be opened because it is from an unidentified developer\". Click \"OK\".</p> <p>Go to System Preferences &gt; Security and Privacy and click on the General tab.</p> <p>At the bottom of the window you will see a message saying that ffmpeg was blocked. Click \"Open Anyway\".</p> <p>If you do not see this message in the General tab, double-click  <code>ffmpeg</code>  again.</p> <p>You may have to click the \"unlock\" button and enter your password to be able to click \"Open Anyway\".</p> <p>If you see another popup that says \u201cffmpeg is from an unidentified developer. Are you sure you want to open it?\u201d, click \"Open\". If you don\u2019t get this popup, just go to the same file and double-click it again.</p> <p>When you double-click the file, a Terminal window may open. Keep the terminal open until you see a message confirming you can close it.</p> <p>Repeat authorisation steps (a) to (f) for the file called  <code>ffprobe</code> .</p>"},{"location":"Tools/Video/ffmpeg/#arguments","title":"Arguments","text":"<p>-ss seek</p> <p>-t duration</p> <p>-to end time point</p> <p>-i video.mp4 (must come after the above)</p> <p>-c codec</p> <p>-o output</p>"},{"location":"Tools/Video/ffmpeg/#list-of-encoders","title":"List of encoders","text":"<pre><code>ffmpeg -encoders\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#get-video-fps","title":"Get video FPS","text":"<pre><code>ffmpeg -i filename 2&gt;&amp;1 | sed -n \"s/.*, \\(.*\\) fp.*/\\1/p\"\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#collect-all-keyframes","title":"Collect all keyframes","text":"<pre><code>ffmpeg -skip_frame nokey -i 2.flv -vsync 0 -r 30 -f\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#preview","title":"Preview","text":"<pre><code>ffplay -i video.mp4 -ss 00:01:02 -t 00:30:00\n</code></pre> <p>Start at 1 minute 2 seconds with a duration of 30 seconds</p>"},{"location":"Tools/Video/ffmpeg/#lossless","title":"Lossless","text":""},{"location":"Tools/Video/ffmpeg/#losslessly-trim","title":"Losslessly Trim","text":"<p>Leave a bit of extra padding in cut points to prevent overcut</p> <pre><code>  ffmpeg -ss 00:01:02 -t 00:30:00 -i video.mp4 -c copy video_clip.mp4\n</code></pre> <p>If you have trouble using the video in Final Cut Pro, try the .mov extension like this:</p> <pre><code>    ffmpeg -i video.mp4 -ss 00:01:02 -t 00:30:00 -codec copy video_clip.mov\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#lossless-concatmerge","title":"Lossless Concat/Merge","text":"<pre><code>  ffmpeg -f concat -safe 0 -i file_list.txt -c copy output.mp4\n</code></pre> <p><code>file_list.txt</code></p> <pre><code>    file 'clip1.mp4'\n    file 'clip2.mp4'\n    file 'clip3.mp4'\n</code></pre> <p>With chapters</p> <pre><code>    import subprocess\n    import os\n    import re\n\n    def make_chapters_metadata(list_mp4: list):\n        print(f\"Making metadata source file\")\n\n        chapters = {}\n        for single_mp4 in list_mp4:\n            number = single_mp4.removesuffix(\".m4a\")\n            cmd = f\"ffprobe -v quiet -of csv=p=0 -show_entries format=duration '{folder}/{single_mp4}'\"\n            print(f\"{cmd=}\")\n            duration_in_microseconds_ = subprocess.run(cmd, shell=True, capture_output=True)\n            duration_in_microseconds__ = duration_in_microseconds_.stdout.decode().strip().replace(\".\", \"\")\n            print(f\"{duration_in_microseconds_=}\")\n            duration_in_microseconds = int(duration_in_microseconds__)\n            chapters[number] = {\"duration\": duration_in_microseconds}\n\n        print(f\"{chapters=}\")\n        chapters[list_mp4[0].removesuffix(\".m4a\")][\"start\"] = 0\n        for n in range(1, len(chapters)):\n            chapter = list_mp4[n-1].removesuffix(\".m4a\")\n            next_chapter = list_mp4[n].removesuffix(\".m4a\")\n            chapters[chapter][\"end\"] = chapters[chapter][\"start\"] + chapters[chapter][\"duration\"]\n            chapters[next_chapter][\"start\"] = chapters[chapter][\"end\"] + 1\n        last_chapter = list_mp4[len(chapters)-1].removesuffix(\".m4a\")\n        chapters[last_chapter][\"end\"] = chapters[last_chapter][\"start\"] + chapters[last_chapter][\"duration\"]\n\n        metadatafile = f\"{folder}/combined.metadata.txt\"\n        with open(metadatafile, \"w+\") as m:\n            m.writelines(\";FFMETADATA1\\n\")\n            for chapter in chapters:\n                ch_meta = \"\"\"\n    [CHAPTER]\n    TIMEBASE=1/1000000\n    START={}\n    END={}\n    title={}\n    \"\"\".format(chapters[chapter][\"start\"], chapters[chapter][\"end\"], chapter)\n                m.writelines(ch_meta)\n\n\n    def concatenate_all_to_one_with_chapters():\n        print(f\"Concatenating list of mp4 to combined.mp4\")\n        metadatafile = f\"{folder}/combined.metadata.txt\"\n        subprocess.run([\"ffmpeg\", \"-hide_banner\", \"-y\", \"-safe\", \"0\", \"-f\", \"concat\", \"-i\", \"list_mp4.txt\", \"-c\", \"copy\", \"-i\", f\"{metadatafile}\", \"-map_metadata\", \"1\", \"combined.m4a\"])\n\n    if __name__ == '__main__':\n\n        folder = \".\"  ## Specify folder where the files 0001.mp4... are\n        ## concatenate_all_to_one_with_chapters()\n        ## exit(0)\n\n        list_mp4 = [f for f in os.listdir(folder) if f.endswith('.m4a')]\n        list_mp4.sort()\n        print(f\"{list_mp4=}\")\n\n        ## Make the list of mp4 in ffmpeg format\n        if os.path.isfile(\"list_mp4.txt\"):\n            os.remove(\"list_mp4.txt\")\n        for filename_mp4 in list_mp4:\n            with open(\"list_mp4.txt\", \"a\") as f:\n                line = f\"file '{filename_mp4}'\\n\"\n                f.write(line)\n\n        make_chapters_metadata(list_mp4)\n        concatenate_all_to_one_with_chapters()\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#lossless-speed-change","title":"Lossless Speed Change","text":"<pre><code>  ffmpeg -itsscale 1/{new_speed} -i input.mp4 -c copy output.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#lossless-compressiontimelapse-extract-only-i-frames","title":"Lossless Compression/Timelapse (extract only i-frames)","text":"<pre><code>  ## drop non-keyframes\n  ffmpeg -itsscale 1/{new_speed} -i input.mov -c:v copy -an -bsf:v \"noise=drop=not(key)\" output.mp4\n\n  ## select every k frames\n  ## won't work all some frames won't be keyframes (use method 3 instead)\n  ffmpeg -itsscale 1/{new_speed} -i input.mov -c:v copy -an -bsf:v \"noise=drop=mod(n\\,{select_frame_frequency})\" output.mp4\n\n  ## both\n  ffmpeg -itsscale 1/{new_speed} -i input.mov -c:v copy -an -bsf:v \"noise=drop=not(key),noise=drop=mod(n\\,select_frame_frequency)\" output.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#ffprobe","title":"ffprobe","text":""},{"location":"Tools/Video/ffmpeg/#limit-frames","title":"Limit frames","text":"<pre><code>  ffprobe -read_intervals {intervals} -i {input_file}\n</code></pre> <pre><code>  INTERVAL  ::= [START|+START_OFFSET][%[END|+END_OFFSET]]\n  INTERVALS ::= INTERVAL[,INTERVALS]\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#get-keyframe-timestamps","title":"Get keyframe timestamps","text":"<pre><code>  ffprobe -select_streams v -show_entries frame=pict_type,pts_time -of csv=p=0 -skip_frame nokey -v 0 -hide_banner -i input.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#get-number-of-keyframes","title":"Get number of keyframes","text":"<pre><code>  ffprobe -hide_banner -of compact=p=0:nk=1 -select_streams v:0 -count_frames -show_entries stream=nb_read_frames -skip_frame nokey -v 0 -i input.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#get-video-duration","title":"Get video duration","text":"<pre><code>  ## only time points\n  ffprobe -select_streams v -show_entries frame=pts_time -of csv=p=0 -skip_frame nokey -v 0 -hide_banner -i INPUT.mov\n\n  ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 -i input.mp4\n</code></pre> <p>Get keyframe interval</p> <pre><code>  ffprobe -read_intervals {start_time_to_read}%+{max_seconds_to_read} -select_streams v -show_entries frame=pts_time -of csv=p=0 -skip_frame nokey -v 0 -hide_banner -i {input_file}\n\n  ## another approach\n  ffprobe -loglevel error -skip_frame nokey -select_streams v:0 -show_entries frame=pkt_pts_time -of csv=print_section=0 input.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#ffplay","title":"ffplay","text":"<pre><code>ffplay -fs -noborder -nostats input.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#video-filters","title":"Video Filters","text":""},{"location":"Tools/Video/ffmpeg/#split-screen","title":"Split Screen","text":"<pre><code>  ffmpeg -i input_1.mp4 -i input_2.mp4 -filter_complex \"[0:v:0]pad=iw*2:ih[bg]; [bg][1:v:0]overlay=w\" output.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#lens-correction","title":"Lens Correction","text":"<pre><code>  ffmpeg -i in.mp4 -vf \"lenscorrection=cx=0.5:cy=0.5:k1=-0.227:k2=-0.022\" out.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#stabilization","title":"Stabilization","text":"<pre><code>  ffmpeg -i input.mp4 -vf vidstabdetect=shakiness=10 -f null -\n  ffmpeg -i input.mp4 -vf vidstabtransform=smoothing=50,unsharp=5:5:0.8:3:3:0.4 output.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#color-correction","title":"Color Correction","text":"<pre><code>  ffmpeg -i input.mp4 -vf eq=brightness=1.2:contrast=1.2:saturation=2 -c:a copy output.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#remove-duplicate-frames","title":"Remove Duplicate Frames","text":"<p>Mpdecimate</p> <pre><code>    ffmpeg -i input.mp4 -vf mpdecimate,setpts=N/FRAME_RATE/TB -vsync vfr -an -c:a copy output.mp4\n</code></pre> <p>Lossless</p> <pre><code>    #!/bin/bash\n\n    ## lld -- lossless decimator/de-duplicator\n\n    ## This script takes a compatible all-I-frame video file and losslessly deduplicates to a new video file.\n    ## The new file will have the same fps as the old file, though. Changing fps is left to the user --\n    ##   it's not simple for e.g. ProRes to do this and remain \"legal\".\n    #\n    ## You may want to tweak the configuration of mpdecimate below. For me, \"hi\" is disabled, because even between my\n    ## duplicate frames there typically existed one 8x8 block that would exceed a high value, for some reason.\n    ## lo and frac may need tweaking for your source material: https://ffmpeg.org/ffmpeg-filters.html#mpdecimate\n    ## After running, you can investigate the output of mpdecimate in the temp directory file mpdecimate.txt.\n    #\n    ## This script assumes no audio associated with the footage -- it would likely need to be modified to handle\n    ## footage with audio\n    #\n    ## max frame number in file is 99,999,999 frames (~38 days at 29.97fps)\n    #\n    ## Development/discussion thread here: https://forum.videohelp.com/threads/383274-de-duplicating-decimating-ProRes-losslessly#post2483571\n\n    echo -e \"\\nlld version 1.0\\n\"\n\n    if [ -z $1 ]; then echo -e \"Usage: ddpr file [expected_fps [debug]]\\n  where expected_fps is the actual frame rate (used for info purposes only -- will not affect processing)\\n  note: lld will create file.tempdir in current directory\\n  If you specify \\\"debug\\\", lld will leave the temporary directory behind for evaluating logs, etc.\\n\"; exit; fi\n\n    fname=$1\n    newfps=$2\n    debug=$3\n\n    if [ ! -f \"$fname\" ]; then\n      echo \"$fname does not exist. Doing nothing.\"\n      exit 1\n    fi\n\n    if [ -e \"$fname\".tempdir ]; then\n      echo \"$fname\".tempdir already exists. Doing nothing.\n      exit 1\n    fi\n\n    if [ -e \"$fname.dedup.mov\" ]; then\n      echo \"$fname.dedup.mov already exists. Doing nothing.\"\n      exit 1\n    fi\n\n    fext=`echo $fname | sed -r 's/.*(\\.[^.]*)$/\\1/'`\n    fextcnt=`echo -n $fext | wc -c`\n\n    if [ $fextcnt -le 1 ]; then\n      echo \"Couldn't detect filename extension. Doing nothing.\"\n      exit 1\n    fi\n\n    mkdir \"$fname\".tempdir\n    mkdir \"$fname\".tempdir/frames\n\n    cd \"$fname\".tempdir\n\n    fps=`ffprobe -v 0 -of compact=p=0 -select_streams 0 -show_entries stream=r_frame_rate ../$fname | sed 's/^r_frame_rate=/scale=15;/g' | bc` \n\n    echo \"$fps fps detected. Detecting duplicates...\"\n\n    flen=`echo \"scale=15;1/$fps\" | bc`\n    flenoffset=`echo \"scale=15;.1*$flen\" | bc`\n\n    ffmpeg -i ../$fname -vf mpdecimate=max=1:hi=999999999:lo=64*3:frac=0.4 -loglevel debug -f null - &gt; mpdecimate.txt 2&gt;&amp;1\n\n    fcnt=`cat mpdecimate.txt | grep \"frames successfully decoded\" | sed -r 's/^(.*) frames .*$/\\1/'`\n\n    cat mpdecimate.txt | grep Parsed | grep keep | sed -r 's/^.*pts_time:(.*) drop.*/\\1/' &gt; ts.txt\n\n    if [ ! -f ts.txt ]; then\n      echo \"ts.txt not created. Exiting.\"\n      exit 1\n    fi\n\n    res=`cat ts.txt | wc -l`\n\n    if [ $res -le \"0\" ]; then\n     echo \"ts.txt didn't generate correctly. Exiting.\"\n     exit 1\n    fi\n\n    ## The offset version is necessary because apparently ffmpeg doesn't find the nearest frame to the timestamp, but the next frame.\n    ## As a result, occasional rounding errors mean that the wrong frame would be targeted when extracting them from the original file.\n    ## The offset is a 10% backwards shift in the timestamp to guarantee that the next frame found will be the correct frame.\n    cat ts.txt | awk \"{print \\$1-$flenoffset}\" | bc &gt; ts2.txt\n\n    if [ ! -f ts2.txt ]; then\n      echo \"ts2.txt not created. Exiting.\"\n      exit 1\n    fi\n\n    res=`cat ts2.txt | wc -l`\n\n    if [ $res -le \"0\" ]; then\n     echo \"ts2.txt didn't generate correctly. Exiting.\"\n     exit 1\n    fi\n\n    newfr=`echo \"scale=3;$fps*($res/$fcnt)\" | bc`\n\n    echo \"Detected $res good frames out of $fcnt total frames = detected actual frame rate of $newfr fps\"\n\n    if [ ! -z $newfps ]; then\n      fpserr=`echo \"scale=3;100*($newfr/$newfps - 1)\" | bc`\n\n      fpserrfirstchar=`echo $fpserr | sed -r 's/^(.).*$/\\1/g'`\n      if [ $fpserrfirstchar == \".\" ]; then\n        fpserr=`echo 0$fpserr`\n      fi\n      fpserrfirstchars=`echo $fpserr | sed -r 's/^(..).*$/\\1/g'`\n      if [ $fpserrfirstchars == \"-.\" ]; then\n        fpserr=`echo $fpserr | sed -r 's/^.(.*)$/\\1/g'`\n        fpserr=`echo \"-0\"$fpserr`\n      fi\n\n      echo \"$fpserr% error from expected $newfps fps.\"\n    fi\n\n    echo \"Generating segment video files...\"\n\n    ## doing -ss after -i because before is not accurate in this case for some reason (first few seconds work fine, then starts going off the rails)\n    cat ts2.txt | awk \"{printf \\\"ffmpeg -i ../$1 -ss %s -t 0$flen -vcodec copy -acodec copy frames/%08d$fext\\n\\\",\\$1,f;f++}\" &gt; ffmpeg_frame_extraction_commands.txt\n\n    if [ ! -f ffmpeg_frame_extraction_commands.txt ]; then\n      echo \"ffmpeg_frame_extraction_commands.txt not created. Exiting.\"\n      exit 1\n    fi\n\n    res=`cat ffmpeg_frame_extraction_commands.txt | wc -l`\n\n    if [ $res -le \"0\" ]; then\n     echo \"ffmpeg_frame_extraction_commands.txt didn't generate correctly. Exiting.\"\n     exit 1\n    fi\n\n    source ffmpeg_frame_extraction_commands.txt &gt; ffmpeg_frame_extraction_results.log 2&gt;&amp;1\n\n    res=`/bin/ls -1 frames/*$fext | wc -l`\n\n    if [ $res -le \"0\" ]; then\n      echo \"No segment files generated. Exiting.\"\n      exit 1\n    fi\n\n    echo \"Generating segment logfile for concatenation and concatenating...\"\n\n    /bin/ls -1 frames/*$fext | sed -r \"s/(.*)/file '\\1'/\" &gt; segment_files_list.txt\n\n    if [ ! -f segment_files_list.txt ]; then\n      echo \"segment_files_list.txt not created. Exiting.\"\n      exit 1\n    fi\n\n    res=`cat segment_files_list.txt | wc -l`\n\n    if [ $res -le \"0\" ]; then\n     echo \"segment_files_list.txt didn't generate correctly. Exiting.\"\n     exit 1\n    fi\n\n    ffmpeg -f concat -i segment_files_list.txt -c copy ../$fname.dedup$fext &gt; ffmpeg_concatenation_results.log 2&gt;&amp;1\n\n    if [ -z $debug ]; then\n     echo \"Deleting temporary directory. (Use e.g. \\\"lld file.mov 18 debug\\\" to prevent this.)\"\n     echo \"Removing temporary directory: $fname.tempdir\"\n     cd ..\n     rm -rf \"$fname\".tempdir\n    else\n     echo \"Temporary directory $fname.tempdir left behind.\"\n    fi\n\n    echo -e \"Done. Resulting filename: $fname.dedup$fext\\n\"\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#motion-blur","title":"Motion Blur","text":"<pre><code>  ffmpeg -i input.mp4 -vf tmix=frames={no_of_frames_to_blend} output.mp4\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#upscaling","title":"Upscaling","text":"<pre><code>  ffmpeg -i input.mp4 -vf \"scale={scale}:flags=neighbor\" -c:v nvenc_hevc -crf 30 -preset ultrafast output.mp4\n</code></pre> <p>Scale</p> <pre><code>    3840:-1\n    -1:2160\n    iw*2:ih*2\n</code></pre>"},{"location":"Tools/Video/ffmpeg/#web-optimization","title":"Web Optimization","text":"<pre><code>ffmpeg -i input.mp4 -c copy -movflags faststart output.mp4\n</code></pre> <p>Fast start is for internet streaming as it puts header at the begining of the file. When you play file from HDD it doesn't matter</p> <p>Only for MP4, M4A, M4V, MOV</p>"},{"location":"Tools/Web_Dev/","title":"Web Development","text":"HTML CSS JS Hyper Text Markup Language Cascading StyleSheets JavaScript Body, Structure Styling, Interactions UI UI UX Very similar to XML"},{"location":"Tools/Web_Dev/#colors","title":"Colors","text":"HSL Hue, Saturation, Luminosity RGB Red, Green, Blue HEX Hexadecimal LAB Luminosity, A, B Hue Type of color (red, green, blue) Saturation Intensity of color Luminosity Brightness of color <p>Optional parameter - A: Alpha (Opacity)</p> Transparency Opacity How much transparent How much opaque 0% Completely visible Completely invisible 100% Completely invisible Completely visible"},{"location":"Tools/Web_Dev/#references","title":"References","text":"<ul> <li> Web Dev Simplified | Introduction to Web Development</li> <li> w3schools</li> <li> IAP 2025 | MIT</li> </ul>"},{"location":"Tools/Web_Dev/HTML/","title":"HTML","text":"<p>Redirect</p> <pre><code>&lt;meta http-equiv=\"refresh\" content=\"0; url=https://www.conductor.com\"&gt;\n</code></pre> <p>Auto-refresh page every 5sec</p> <pre><code>&lt;meta http-equiv=\"refresh\" content=\"5\"&gt;\n</code></pre>"},{"location":"Tools/Web_Dev/HTML/#autocompletesuggestions","title":"Autocomplete/Suggestions","text":""},{"location":"Tools/Web_Dev/HTML/#text","title":"Text","text":"<pre><code>&lt;label for=\"city_input\"&gt;City&lt;/label&gt;\n&lt;input type=\"text\" id=\"city_input\" list=\"cities_list\" /&gt;\n&lt;datalist id=\"cities_list\"&gt;\n    &lt;option value=\"Dubai\"&gt;My city&lt;/option&gt;\n    &lt;option value=\"Kayal\"&gt;My hometown&lt;/option&gt;\n&lt;/datalist&gt;\n</code></pre>"},{"location":"Tools/Web_Dev/HTML/#colors","title":"Colors","text":"<pre><code>&lt;label for=\"color_picker\"&gt;Pick a color&lt;/label&gt;\n&lt;input type=\"color\" id=\"color_picker\" list=\"colors_list\" /&gt;\n&lt;datalist id=\"colors_list\"&gt;\n    &lt;option value=\"#155AF0\"&gt;Primary Color&lt;/option&gt;\n    &lt;option value=\"#FFF\"&gt;Secondary Color&lt;/option&gt;\n&lt;/datalist&gt;\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/","title":"MERN Stack","text":"Role MongoDB Database Express.js Code web server in javascript React.js Front-end Node.js Server-side javascript"},{"location":"Tools/Web_Dev/MERN/#references","title":"References","text":"<ul> <li> FreeCodeCamp | MERN Stack Course</li> </ul>"},{"location":"Tools/Web_Dev/MERN/MongoDB/","title":"MongoDB","text":"<p>MongoDB does not require explicit creation. If you try to access something that doesn\u2019t exist, MongoDB will create it for you.</p>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#install","title":"Install","text":"<ol> <li>Install <code>MongoDB Community</code></li> <li>Install <code>mongosh</code> (shell)</li> </ol>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#vocabulary","title":"Vocabulary","text":"Relational MongoDB Database Database Table Collection Column Key Row Document Index Index Join $lookup Foreign Key Reference"},{"location":"Tools/Web_Dev/MERN/MongoDB/#data-format","title":"Data Format","text":"<p>BSON (Binary JSON): very similar to json</p>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#mongosh","title":"Mongosh","text":"<pre><code>mongosh // enter\nexit // exit\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#ddl","title":"DDL","text":"<pre><code>show dbs\nuse appdb\nshow collections\ndb.dropDatabase()\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#dml","title":"DML","text":""},{"location":"Tools/Web_Dev/MERN/MongoDB/#create","title":"Create","text":"<pre><code>db.users.insertOne({\n    name: \"Ahmed\"\n})\ndb.users.insertMany([\n  {\n    name: \"Ahmed\"\n  },\n    {\n    name: \"Thahir\"\n  }\n])\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#read","title":"Read","text":"<pre><code>db.users.findOne()\ndb.users.find() // equiv to select *\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#find-functions","title":"Find functions","text":"<pre><code>.sort({\n    name:1, // -1\n    age: 1\n})\n.skip(5)\n.limit(10)\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#count","title":"Count","text":"<pre><code>db.users.countDocuments({\n  age: 10\n})\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#update","title":"Update","text":"<p><code>$set</code></p> <pre><code>db.users.updateOne(\n  {\n    age: 26\n    },\n  {\n    $set: {age: 27}\n  }\n)\ndb.users.updateMany(\n  {\n    age: 26\n    },\n  {\n    $set: {age: 27}\n  }\n)\n</code></pre> <pre><code>$set\n$inc\n$rename: {name: \"Ahmed\"}\n$unset: {name: \"\"} // removes key; doesn't set to null\n$push: {hobbies: \"Swimming\"} // adding to array key\n$pull: {hobbies: \"Swimming\"} // remove from array key\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#replace","title":"Replace","text":"<pre><code>db.users.replaceOne(\n  {\n    age: 26\n    },\n  {\n    name: \"Thahir\"\n  }\n)\ndb.users.replace(\n  {\n    age: 26\n    },\n  {\n    name: \"Thahir\"\n  }\n)\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#delete","title":"Delete","text":"<pre><code>db.users.deleteOne(\n  {\n    name: \"Thahir\"\n  }\n)\ndb.users.deleteMany(\n  {\n    name: \"Thahir\"\n  }\n)\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#filtering","title":"Filtering","text":"<pre><code>// filter Thahir and return only name and age\ndb.users.find(\n  {\n    name: \"Thahir\"\n  },\n  {\n    name: 1,\n    age:1,\n    _id: 0\n  }\n)\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#complex-filters","title":"Complex Filters","text":"<pre><code>db.users.find(\n  {\n    first_name: {$eq: \"Ahmed\"},\n    age: {$gte: 50},\n  },\n  {\n    name: 1,\n    age:1,\n    _id: 0\n  }\n)\n</code></pre> <pre><code>{$eq: \"Thahir\"}\n{$ne: \"Thahir\"}\n{$gte: 10}\n{$in: [\n  \"Ahmed\",\n  \"Thahir\",\n  5\n]}\n{$nin: [\n  \"Ahmed\",\n  \"Thahir\",\n  5\n]}\n{$exists: true} // only checks if key exists; hence includes documents with null\n{$exists: false}\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#filter-operations","title":"Filter Operations","text":"<pre><code>// not\n{\n    not: [\n    {filter_1: \"enset\"}\n  ]\n}\n\n// and\n{\n    filter_1: \"enset\",\n  filter_2: \"enset\"\n}\n\n{\n    $and: [\n    {filter_1: \"enset\"},\n      {filter_2: \"enset\"}\n  ]\n}\n\n// or\n{\n    $or: [\n    {filter_1: \"enset\"},\n      {filter_2: \"enset\"}\n  ]\n}\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#comparing-keys","title":"Comparing keys","text":"<pre><code>db.users.find({\n  $expr: {\n    $gt: [\"$debt\", \"$balance\"]\n  }\n})\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#nested-keys","title":"Nested keys","text":"<pre><code>db.users.find({\n  \"address.street\": \"Testing\"\n})\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/MongoDB/#_1","title":"MongoDB","text":""},{"location":"Tools/Web_Dev/MERN/MongoDB/#references","title":"References","text":"<ul> <li> Web Dev Simplified | MongoDB Crash Course</li> </ul>"},{"location":"Tools/Web_Dev/MERN/Node/","title":"NodeJS","text":"<p>Open source server environment, that allows you to run JavaScript on the server, ie allows JS to run outside the browser.</p>"},{"location":"Tools/Web_Dev/MERN/Node/#installation","title":"Installation","text":"<p>https://nodejs.org</p>"},{"location":"Tools/Web_Dev/MERN/Node/#web-server","title":"Web Server","text":""},{"location":"Tools/Web_Dev/MERN/Node/#indexhtml","title":"<code>index.html</code>","text":"<pre><code>&lt;html&gt;\n  &lt;body&gt;\n    \"Hello world!\"\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node/#appjs","title":"<code>app.js</code>","text":"<pre><code>// imports\nconst http = require(\"http\")\nconst fs = require(\"fs\") // file system\n\nconst port = 3000\n\nconst server = http.createServer(function (req, res){\n\n  fs.readFile(\n    \"index.html\",\n    function(error, data) {\n      if (error) {\n        res.writeHead(404)\n        res.write(\"Error: File not found\")\n      } else {\n        res.writeHead(200, {\n          \"Content-Type\": \"text/html\"\n        })\n        res.write(data)\n      }\n    }\n    res.end()\n  )\n\n  // res.end()\n})\n\nserver.listen(port, function(error) {\n  if (error) {\n    console.log(\"Something went wrong: \", error)\n  } else {\n    console.log(\"Server listening on port \" + port)\n  }\n})\n</code></pre> <pre><code>node app.js\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/","title":"Node &amp; Express","text":"<pre><code>cd folder\nnpm init -y\n</code></pre> <pre><code>npm install -g express cors mongodb dotenv nodemon\n</code></pre> <code>nodemon</code> Automatically restarts node application when file changes"},{"location":"Tools/Web_Dev/MERN/Node_Express/#usage","title":"Usage","text":"<ol> <li>Start up server</li> </ol> <pre><code>nodemon server\n</code></pre> <ol> <li>Go to <code>localhost:5000/api/v1/restaurants</code></li> </ol>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#file-tree","title":"File Tree","text":"<pre><code>- backend\n    - api\n        - restaurants.controller.js\n        - restaurants.route.js\n        - reviews.controller.js\n  - dao (Data Access Object)\n      - restaurantsDAO.js\n        - reviewsDAO.js\n    - node_modules\n\n  - .env\n  - index.js\n  - package-lock.json\n  - package.json\n  - server.js\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#packagejson","title":"<code>package.json</code>","text":"<pre><code>{\n  \"name\": \"backend\",\n  \"version\": \"1.0.0\",\n  \"description\": \"\",\n  \"main\": \"index.js\",\n  \"type\": \"module\", // allows use to import statements from es6\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\"\n  },\n  \"keywords\": [],\n  \"author\": \"\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"body-parser\": \"^1.19.0\",\n    \"bson\": \"^4.2.2\",\n    \"cors\": \"^2.8.5\",\n    \"dotenv\": \"^8.2.0\",\n    \"express\": \"^4.17.1\",\n    \"mongodb\": \"^3.6.4\"\n  }\n}\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#serverjs","title":"<code>server.js</code>","text":"<pre><code>import express from \"express\"\nimport cors from \"cors\"\nimport restaurants from \"./api/restaurants.route.js\"\n\nconst app = express()\n\napp.use(cors())\napp.use(express.json()) // allow server to accept &amp; read json in requests\n\n// default route\napp.use(\n  \"/api/v1/restaurants\",\n  restaurants\n)\n\n// fallback route\napp.use(\n  \"*\",\n  (req, res) =&gt; res.status(404).json({ error: \"not found\"})\n)\n\n// export the app as a module,\n// so that it can be imported in another file that accesses the database\nexport default app\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#env","title":"<code>.env</code>","text":"<p>Set the uri of the database</p> <pre><code>PORT = 5000\n\nDB_URI = blah_blah\nNS = sample_restaurants\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#indexjs","title":"<code>index.js</code>","text":"<pre><code>import app from \"./server.js\"\nimport mongodb from \"mongodb\"\nimport dotenv from \"dotenv\"\nimport RestaurantsDAO from \"./dao/restaurantsDAO.js\"\nimport ReviewsDAO from \"./dao/reviewsDAO.js\"\n</code></pre> <pre><code>dotenv.config()\nconst MongoClient = mongodb.MongoClient\n\nconst port = process.env.PORT || 8000\n\nMongoClient.connect(\n  process.env.RESTREVIEWS_DB_URI, // connect to database\n  {\n    poolSize: 50,\n    wtimeout: 2500,\n    useNewUrlParse: true }\n  )\n  .catch(err =&gt; {                                   // check for error\n    console.error(err.stack)\n    process.exit(1)\n  })\n  .then(async client =&gt; {                   // start webserver\n    await RestaurantsDAO.injectDB(client)\n    await ReviewsDAO.injectDB(client)\n    app.listen(port, () =&gt; {\n      console.log(`listening on port ${port}`)\n    })\n  })\n)\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#restaurantscontrollerjs","title":"<code>restaurants.controller.js</code>","text":"<pre><code>import RestaurantsDAO from \"../dao/restaurantsDAO.js\"\n\nexport default class RestaurantsController {\n  static async apiGetRestaurants(req, res, next) {\n    const restaurantsPerPage = req.query.restaurantsPerPage ? parseInt(req.query.restaurantsPerPage, 10) : 20\n    const page = req.query.page ? parseInt(req.query.page, 10) : 0\n\n    let filters = {}\n    if (req.query.cuisine) {\n      filters.cuisine = req.query.cuisine\n    } else if (req.query.zipcode) {\n      filters.zipcode = req.query.zipcode\n    } else if (req.query.name) {\n      filters.name = req.query.name\n    }\n\n    const { restaurantsList, totalNumRestaurants } = await RestaurantsDAO.getRestaurants({\n      filters,\n      page,\n      restaurantsPerPage,\n    })\n\n    let response = {\n      restaurants: restaurantsList,\n      page: page,\n      filters: filters,\n      entries_per_page: restaurantsPerPage,\n      total_results: totalNumRestaurants,\n    }\n    res.json(response)\n  }\n  static async apiGetRestaurantById(req, res, next) {\n    try {\n      let id = req.params.id || {}\n      let restaurant = await RestaurantsDAO.getRestaurantByID(id)\n      if (!restaurant) {\n        res.status(404).json({ error: \"Not found\" })\n        return\n      }\n      res.json(restaurant)\n    } catch (e) {\n      console.log(`api, ${e}`)\n      res.status(500).json({ error: e })\n    }\n  }\n\n  static async apiGetRestaurantCuisines(req, res, next) {\n    try {\n      let cuisines = await RestaurantsDAO.getCuisines()\n      res.json(cuisines)\n    } catch (e) {\n      console.log(`api, ${e}`)\n      res.status(500).json({ error: e })\n    }\n  }\n}\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#restaurantsroutejs","title":"<code>restaurants.route.js</code>","text":"<pre><code>import express from \"express\"\nimport RestaurantsCtrl from \"./restaurants.controller.js\"\nimport ReviewsCtrl from \"./reviews.controller.js\"\n\nconst router = express.Router()\n\nrouter.route(\"/\").get(RestaurantsCtrl.apiGetRestaurants)\nrouter.route(\"/id/:id\").get(RestaurantsCtrl.apiGetRestaurantById)\nrouter.route(\"/cuisines\").get(RestaurantsCtrl.apiGetRestaurantCuisines)\n\nrouter\n  .route(\"/review\")\n  .post(ReviewsCtrl.apiPostReview)\n  .put(ReviewsCtrl.apiUpdateReview)\n  .delete(ReviewsCtrl.apiDeleteReview)\n\nexport default router\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#reviewscontrollerjs","title":"<code>reviews.controller.js</code>","text":"<pre><code>import ReviewsDAO from \"../dao/reviewsDAO.js\"\n\nexport default class ReviewsController {\n  static async apiPostReview(req, res, next) {\n    try {\n      const restaurantId = req.body.restaurant_id\n      const review = req.body.text\n      const userInfo = {\n        name: req.body.name,\n        _id: req.body.user_id\n      }\n      const date = new Date()\n\n      const ReviewResponse = await ReviewsDAO.addReview(\n        restaurantId,\n        userInfo,\n        review,\n        date,\n      )\n      res.json({ status: \"success\" })\n    } catch (e) {\n      res.status(500).json({ error: e.message })\n    }\n  }\n\n  static async apiUpdateReview(req, res, next) {\n    try {\n      const reviewId = req.body.review_id\n      const text = req.body.text\n      const date = new Date()\n\n      const reviewResponse = await ReviewsDAO.updateReview(\n        reviewId,\n        req.body.user_id,\n        text,\n        date,\n      )\n\n      var { error } = reviewResponse\n      if (error) {\n        res.status(400).json({ error })\n      }\n\n      if (reviewResponse.modifiedCount === 0) {\n        throw new Error(\n          \"unable to update review - user may not be original poster\",\n        )\n      }\n\n      res.json({ status: \"success\" })\n    } catch (e) {\n      res.status(500).json({ error: e.message })\n    }\n  }\n\n  static async apiDeleteReview(req, res, next) {\n    try {\n      const reviewId = req.query.id\n      const userId = req.body.user_id\n      console.log(reviewId)\n      const reviewResponse = await ReviewsDAO.deleteReview(\n        reviewId,\n        userId,\n      )\n      res.json({ status: \"success\" })\n    } catch (e) {\n      res.status(500).json({ error: e.message })\n    }\n  }\n\n}\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#restaurantsdaojs","title":"<code>restaurantsDAO.js</code>","text":"<pre><code>import mongodb from \"mongodb\"\nconst ObjectId = mongodb.ObjectID\nlet restaurants\n\nexport default class RestaurantsDAO {\n  static async injectDB(conn) {\n    if (restaurants) {\n      return\n    }\n    try {\n      restaurants = await conn.db(process.env.RESTREVIEWS_NS).collection(\"restaurants\")\n    } catch (e) {\n      console.error(\n        `Unable to establish a collection handle in restaurantsDAO: ${e}`,\n      )\n    }\n  }\n\n  static async getRestaurants({\n    filters = null,\n    page = 0,\n    restaurantsPerPage = 20,\n  } = {}) {\n    let query\n    if (filters) {\n      if (\"name\" in filters) {\n        query = { $text: { $search: filters[\"name\"] } } // $text needs to be configured in mongodb\n      } else if (\"cuisine\" in filters) {\n        query = { \"cuisine\": { $eq: filters[\"cuisine\"] } }\n      } else if (\"zipcode\" in filters) {\n        query = { \"address.zipcode\": { $eq: filters[\"zipcode\"] } }\n      }\n    }\n\n    let cursor\n\n    try {\n      cursor = await restaurants\n        .find(query)\n    } catch (e) {\n      console.error(`Unable to issue find command, ${e}`)\n      return { restaurantsList: [], totalNumRestaurants: 0 }\n    }\n\n    const displayCursor = cursor.limit(restaurantsPerPage).skip(restaurantsPerPage * page)\n\n    try {\n      const restaurantsList = await displayCursor.toArray()\n      const totalNumRestaurants = await restaurants.countDocuments(query)\n\n      return { restaurantsList, totalNumRestaurants }\n    } catch (e) {\n      console.error(\n        `Unable to convert cursor to array or problem counting documents, ${e}`,\n      )\n      return { restaurantsList: [], totalNumRestaurants: 0 }\n    }\n  }\n  static async getRestaurantByID(id) {\n    try {\n      const pipeline = [\n        {\n            $match: {\n                _id: new ObjectId(id),\n            },\n        },\n              {\n                  $lookup: {\n                      from: \"reviews\",\n                      let: {\n                          id: \"$_id\",\n                      },\n                      pipeline: [\n                          {\n                              $match: {\n                                  $expr: {\n                                      $eq: [\"$restaurant_id\", \"$$id\"],\n                                  },\n                              },\n                          },\n                          {\n                              $sort: {\n                                  date: -1,\n                              },\n                          },\n                      ],\n                      as: \"reviews\",\n                  },\n              },\n              {\n                  $addFields: {\n                      reviews: \"$reviews\",\n                  },\n              },\n          ]\n      return await restaurants.aggregate(pipeline).next()\n    } catch (e) {\n      console.error(`Something went wrong in getRestaurantByID: ${e}`)\n      throw e\n    }\n  }\n\n  static async getCuisines() {\n    let cuisines = []\n    try {\n      cuisines = await restaurants.distinct(\"cuisine\")\n      return cuisines\n    } catch (e) {\n      console.error(`Unable to get cuisines, ${e}`)\n      return cuisines\n    }\n  }\n}\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#reviewsdaojs","title":"<code>reviewsDAO.js</code>","text":"<pre><code>import mongodb from \"mongodb\"\nconst ObjectId = mongodb.ObjectID\n\nlet reviews\n\nexport default class ReviewsDAO {\n  static async injectDB(conn) {\n    if (reviews) {\n      return\n    }\n    try {\n      reviews = await conn.db(process.env.RESTREVIEWS_NS).collection(\"reviews\")\n    } catch (e) {\n      console.error(`Unable to establish collection handles in userDAO: ${e}`)\n    }\n  }\n\n  static async addReview(restaurantId, user, review, date) {\n    try {\n      const reviewDoc = { name: user.name,\n          user_id: user._id,\n          date: date,\n          text: review,\n          restaurant_id: ObjectId(restaurantId), }\n\n      return await reviews.insertOne(reviewDoc)\n    } catch (e) {\n      console.error(`Unable to post review: ${e}`)\n      return { error: e }\n    }\n  }\n\n  static async updateReview(reviewId, userId, text, date) {\n    try {\n      const updateResponse = await reviews.updateOne(\n        { user_id: userId, _id: ObjectId(reviewId)},\n        { $set: { text: text, date: date  } },\n      )\n\n      return updateResponse\n    } catch (e) {\n      console.error(`Unable to update review: ${e}`)\n      return { error: e }\n    }\n  }\n\n  static async deleteReview(reviewId, userId) {\n\n    try {\n      const deleteResponse = await reviews.deleteOne({\n        _id: ObjectId(reviewId),\n        user_id: userId,\n      })\n\n      return deleteResponse\n    } catch (e) {\n      console.error(`Unable to delete review: ${e}`)\n      return { error: e }\n    }\n  }\n\n}\n</code></pre>"},{"location":"Tools/Web_Dev/MERN/Node_Express/#references","title":"References","text":"<ul> <li> Web Dev Simplified | Your First Node.js Web Server</li> <li> Wed Dev Simplified | Learn Express JS In 35 Minutes</li> <li> Web Dev Simplified | Build A REST API With Node.js, Express, &amp; MongoDB - Quick</li> </ul>"},{"location":"Tools/Web_Dev/MERN/React/","title":"React","text":""}]}